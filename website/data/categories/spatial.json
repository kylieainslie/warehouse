[
  {
    "id": 22727,
    "package_name": "sf",
    "title": "Simple Features for R",
    "description": "Support for simple feature access, a standardized way to\nencode and analyze spatial vector data. Binds to 'GDAL'\n<doi:10.5281/zenodo.5884351> for reading and writing data, to\n'GEOS' <doi:10.5281/zenodo.11396894> for geometrical\noperations, and to 'PROJ' <doi:10.5281/zenodo.5884394> for\nprojection conversions and datum transformations. Uses by\ndefault the 's2' package for geometry operations on geodetic\n(long/lat degree) coordinates.",
    "version": "1.0-24",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://r-spatial.github.io/sf/, https://github.com/r-spatial/sf",
    "exports": [
      [".degAxis"],
      [".get_layout"],
      [".image_scale"],
      [".image_scale_factor"],
      [".stop_geos"],
      ["%>%"],
      ["as_Spatial"],
      ["dbDataType"],
      ["dbWriteTable"],
      ["FULL_bbox_"],
      ["gdal_addo"],
      ["gdal_create"],
      ["gdal_crs"],
      ["gdal_extract"],
      ["gdal_inv_geotransform"],
      ["gdal_metadata"],
      ["gdal_polygonize"],
      ["gdal_rasterize"],
      ["gdal_read"],
      ["gdal_read_mdim"],
      ["gdal_subdatasets"],
      ["gdal_utils"],
      ["gdal_write"],
      ["gdal_write_mdim"],
      ["get_key_pos"],
      ["NA_agr_"],
      ["NA_bbox_"],
      ["NA_crs_"],
      ["NA_m_range_"],
      ["NA_z_range_"],
      ["plot_sf"],
      ["rawToHex"],
      ["read_sf"],
      ["sf_add_proj_units"],
      ["sf_extSoftVersion"],
      ["sf_proj_info"],
      ["sf_proj_network"],
      ["sf_proj_pipelines"],
      ["sf_proj_search_paths"],
      ["sf_project"],
      ["sf_use_s2"],
      ["sf.colors"],
      ["st_agr"],
      ["st_agr<-"],
      ["st_area"],
      ["st_as_binary"],
      ["st_as_grob"],
      ["st_as_s2"],
      ["st_as_sf"],
      ["st_as_sfc"],
      ["st_as_text"],
      ["st_axis_order"],
      ["st_bbox"],
      ["st_bind_cols"],
      ["st_boundary"],
      ["st_break_antimeridian"],
      ["st_buffer"],
      ["st_can_transform"],
      ["st_cast"],
      ["st_centroid"],
      ["st_collection_extract"],
      ["st_combine"],
      ["st_concave_hull"],
      ["st_contains"],
      ["st_contains_properly"],
      ["st_convex_hull"],
      ["st_coordinates"],
      ["st_covered_by"],
      ["st_covers"],
      ["st_crop"],
      ["st_crosses"],
      ["st_crs"],
      ["st_crs<-"],
      ["st_delete"],
      ["st_difference"],
      ["st_dimension"],
      ["st_disjoint"],
      ["st_distance"],
      ["st_drivers"],
      ["st_drop_geometry"],
      ["st_equals"],
      ["st_equals_exact"],
      ["st_exterior_ring"],
      ["st_filter"],
      ["st_geometry"],
      ["st_geometry_type"],
      ["st_geometry<-"],
      ["st_geometrycollection"],
      ["st_graticule"],
      ["st_inscribed_circle"],
      ["st_interpolate_aw"],
      ["st_intersection"],
      ["st_intersects"],
      ["st_is"],
      ["st_is_empty"],
      ["st_is_full"],
      ["st_is_longlat"],
      ["st_is_simple"],
      ["st_is_valid"],
      ["st_is_within_distance"],
      ["st_jitter"],
      ["st_join"],
      ["st_layers"],
      ["st_length"],
      ["st_line_interpolate"],
      ["st_line_merge"],
      ["st_line_project"],
      ["st_line_sample"],
      ["st_linestring"],
      ["st_m_range"],
      ["st_make_grid"],
      ["st_make_valid"],
      ["st_minimum_bounding_circle"],
      ["st_minimum_rotated_rectangle"],
      ["st_multilinestring"],
      ["st_multipoint"],
      ["st_multipolygon"],
      ["st_nearest_feature"],
      ["st_nearest_points"],
      ["st_node"],
      ["st_normalize"],
      ["st_overlaps"],
      ["st_perimeter"],
      ["st_point"],
      ["st_point_on_surface"],
      ["st_polygon"],
      ["st_polygonize"],
      ["st_precision"],
      ["st_precision<-"],
      ["st_read"],
      ["st_read_db"],
      ["st_relate"],
      ["st_reverse"],
      ["st_sample"],
      ["st_segmentize"],
      ["st_set_agr"],
      ["st_set_crs"],
      ["st_set_geometry"],
      ["st_set_precision"],
      ["st_sf"],
      ["st_sfc"],
      ["st_shift_longitude"],
      ["st_simplify"],
      ["st_snap"],
      ["st_sym_difference"],
      ["st_touches"],
      ["st_transform"],
      ["st_triangulate"],
      ["st_triangulate_constrained"],
      ["st_union"],
      ["st_viewport"],
      ["st_voronoi"],
      ["st_within"],
      ["st_wrap_dateline"],
      ["st_write"],
      ["st_write_db"],
      ["st_z_range"],
      ["st_zm"],
      ["vec_cast.sfc"],
      ["vec_ptype2.sfc"],
      ["write_sf"]
    ],
    "topics": [
      ["gdal"],
      ["geos"],
      ["proj"],
      ["spatial"],
      ["cpp"]
    ],
    "score": 22.6999,
    "stars": 1413
  },
  {
    "id": 23812,
    "package_name": "stars",
    "title": "Spatiotemporal Arrays, Raster and Vector Data Cubes",
    "description": "Reading, manipulating, writing and plotting spatiotemporal\narrays (raster and vector data cubes) in 'R', using 'GDAL'\nbindings provided by 'sf', and 'NetCDF' bindings by 'ncmeta'\nand 'RNetCDF'.",
    "version": "0.7-1",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://r-spatial.github.io/stars/,\nhttps://github.com/r-spatial/stars/",
    "exports": [
      ["%in%"],
      ["as.tbl_cube.stars"],
      ["detect.driver"],
      ["expand_dimensions"],
      ["geom_stars"],
      ["make_intervals"],
      ["read_mdim"],
      ["read_ncdf"],
      ["read_stars"],
      ["st_apply"],
      ["st_as_stars"],
      ["st_cells"],
      ["st_contour"],
      ["st_dim_to_attr"],
      ["st_dimensions"],
      ["st_dimensions<-"],
      ["st_downsample"],
      ["st_extract"],
      ["st_flip"],
      ["st_geotransform"],
      ["st_geotransform<-"],
      ["st_get_dimension_values"],
      ["st_mosaic"],
      ["st_raster_type"],
      ["st_rasterize"],
      ["st_redimension"],
      ["st_res"],
      ["st_rgb"],
      ["st_rotate"],
      ["st_set_bbox"],
      ["st_set_dimensions"],
      ["st_sfc2xy"],
      ["st_tile"],
      ["st_warp"],
      ["st_xy2sfc"],
      ["write_mdim"],
      ["write_stars"]
    ],
    "topics": [
      ["raster"],
      ["satellite-images"],
      ["spatial"]
    ],
    "score": 18.3623,
    "stars": 593
  },
  {
    "id": 24466,
    "package_name": "terra",
    "title": "Spatial Data Analysis",
    "description": "Methods for spatial data analysis with vector (points,\nlines, polygons) and raster (grid) data. Methods for vector\ndata include geometric operations such as intersect and buffer.\nRaster methods include local, focal, global, zonal and\ngeometric operations. The predict and interpolate methods\nfacilitate the use of regression type (interpolation, machine\nlearning) models for spatial prediction, including with\nsatellite remote sensing data. Processing of very large files\nis supported. See the manual and tutorials on\n<https://rspatial.org/> to get started.",
    "version": "1.8-91",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "https://rspatial.org/, https://rspatial.github.io/terra/",
    "exports": [
      ["%in%"],
      ["activeCat"],
      ["activeCat<-"],
      ["add_abline"],
      ["add_box"],
      ["add_grid"],
      ["add_legend"],
      ["add_mtext"],
      ["add<-"],
      ["addCats"],
      ["adjacent"],
      ["aggregate"],
      ["align"],
      ["all.equal"],
      ["allNA"],
      ["animate"],
      ["app"],
      ["approximate"],
      ["ar_info"],
      ["area"],
      ["Arith"],
      ["as.array"],
      ["as.bool"],
      ["as.contour"],
      ["as.data.frame"],
      ["as.factor"],
      ["as.int"],
      ["as.lines"],
      ["as.list"],
      ["as.matrix"],
      ["as.points"],
      ["as.polygons"],
      ["as.raster"],
      ["atan_2"],
      ["atan2"],
      ["autocor"],
      ["barplot"],
      ["bestMatch"],
      ["blocks"],
      ["boundaries"],
      ["boxplot"],
      ["buffer"],
      ["cartogram"],
      ["catalyze"],
      ["categories"],
      ["cats"],
      ["cbind2"],
      ["cellFromRowCol"],
      ["cellFromRowColCombine"],
      ["cellFromXY"],
      ["cells"],
      ["cellSize"],
      ["centroids"],
      ["chunk"],
      ["clamp"],
      ["clamp_ts"],
      ["classify"],
      ["clearance"],
      ["clearVSIcache"],
      ["click"],
      ["colFromCell"],
      ["colFromX"],
      ["colMeans"],
      ["colorize"],
      ["colSums"],
      ["coltab"],
      ["coltab<-"],
      ["combineGeoms"],
      ["combineLevels"],
      ["compare"],
      ["Compare"],
      ["compareGeom"],
      ["concats"],
      ["contour"],
      ["convHull"],
      ["costDist"],
      ["countNA"],
      ["cover"],
      ["crds"],
      ["crop"],
      ["crosstab"],
      ["crs"],
      ["crs<-"],
      ["datatype"],
      ["deepcopy"],
      ["delaunay"],
      ["densify"],
      ["density"],
      ["depth"],
      ["depth<-"],
      ["depthName"],
      ["depthName<-"],
      ["depthUnit"],
      ["depthUnit<-"],
      ["describe"],
      ["diff"],
      ["direction"],
      ["disagg"],
      ["distance"],
      ["divide"],
      ["dots"],
      ["draw"],
      ["droplevels"],
      ["elongate"],
      ["emptyGeoms"],
      ["erase"],
      ["expanse"],
      ["ext"],
      ["ext<-"],
      ["extend"],
      ["extract"],
      ["extractAlong"],
      ["extractRange"],
      ["fileBlocksize"],
      ["fillHoles"],
      ["fillTime"],
      ["flip"],
      ["flowAccumulation"],
      ["focal"],
      ["focal3D"],
      ["focalCpp"],
      ["focalMat"],
      ["focalPairs"],
      ["focalReg"],
      ["focalValues"],
      ["forceCCW"],
      ["free_RAM"],
      ["freq"],
      ["gaps"],
      ["gdal"],
      ["gdalCache"],
      ["geom"],
      ["geomtype"],
      ["getGDALconfig"],
      ["getTileExtents"],
      ["global"],
      ["graticule"],
      ["gridDist"],
      ["gridDistance"],
      ["halo"],
      ["has.colors"],
      ["has.RGB"],
      ["has.time"],
      ["hasMinMax"],
      ["hasValues"],
      ["head"],
      ["hist"],
      ["hull"],
      ["identical"],
      ["ifel"],
      ["image"],
      ["impose"],
      ["inext"],
      ["init"],
      ["inMemory"],
      ["inset"],
      ["interpIDW"],
      ["interpNear"],
      ["interpolate"],
      ["intersect"],
      ["is.bool"],
      ["is.empty"],
      ["is.factor"],
      ["is.flipped"],
      ["is.int"],
      ["is.lines"],
      ["is.lonlat"],
      ["is.num"],
      ["is.points"],
      ["is.polygons"],
      ["is.related"],
      ["is.rotated"],
      ["is.valid"],
      ["isFALSE"],
      ["isTRUE"],
      ["k_means"],
      ["lapp"],
      ["layerCor"],
      ["levels"],
      ["libVersion"],
      ["linearUnits"],
      ["lines"],
      ["logic"],
      ["Logic"],
      ["longnames"],
      ["longnames<-"],
      ["makeNodes"],
      ["makeTiles"],
      ["makeValid"],
      ["makeVRT"],
      ["map_extent"],
      ["map.pal"],
      ["mask"],
      ["match"],
      ["math"],
      ["Math"],
      ["Math2"],
      ["mean"],
      ["median"],
      ["mem_info"],
      ["merge"],
      ["mergeLines"],
      ["mergeTime"],
      ["meta"],
      ["metags"],
      ["metags<-"],
      ["minmax"],
      ["modal"],
      ["mosaic"],
      ["na.omit"],
      ["NAflag"],
      ["NAflag<-"],
      ["names"],
      ["nany"],
      ["ncell"],
      ["ncol"],
      ["ncol<-"],
      ["nearby"],
      ["nearest"],
      ["NIDP"],
      ["nlyr"],
      ["nlyr<-"],
      ["noNA"],
      ["normalize.longitude"],
      ["north"],
      ["not.na"],
      ["nrow"],
      ["nrow<-"],
      ["nseg"],
      ["nsrc"],
      ["origin"],
      ["origin<-"],
      ["pairs"],
      ["panel"],
      ["patches"],
      ["perim"],
      ["persp"],
      ["pitfinder"],
      ["plet"],
      ["plot"],
      ["plotRGB"],
      ["points"],
      ["polys"],
      ["prcomp"],
      ["predict"],
      ["princomp"],
      ["proj_ok"],
      ["project"],
      ["quantile"],
      ["query"],
      ["rangeFill"],
      ["rapp"],
      ["rast"],
      ["rasterize"],
      ["rasterizeGeom"],
      ["rasterizeWin"],
      ["rcl"],
      ["readRDS"],
      ["readStart"],
      ["readStop"],
      ["readValues"],
      ["rectify"],
      ["regress"],
      ["relate"],
      ["removeDupNodes"],
      ["res"],
      ["res<-"],
      ["resample"],
      ["rescale"],
      ["rev"],
      ["RGB"],
      ["RGB<-"],
      ["roll"],
      ["rotate"],
      ["round"],
      ["rowColCombine"],
      ["rowColFromCell"],
      ["rowFromCell"],
      ["rowFromY"],
      ["rowMeans"],
      ["rowSums"],
      ["same.crs"],
      ["sapp"],
      ["saveRDS"],
      ["sbar"],
      ["scale"],
      ["scale_linear"],
      ["scoff"],
      ["scoff<-"],
      ["sds"],
      ["segregate"],
      ["sel"],
      ["selectHighest"],
      ["selectRange"],
      ["serialize"],
      ["set.cats"],
      ["set.crs"],
      ["set.ext"],
      ["set.names"],
      ["set.RGB"],
      ["set.values"],
      ["set.window"],
      ["setGDALconfig"],
      ["setMinMax"],
      ["setValues"],
      ["shade"],
      ["sharedPaths"],
      ["shift"],
      ["sieve"],
      ["simplifyGeom"],
      ["simplifyLevels"],
      ["size"],
      ["snap"],
      ["sort"],
      ["sources"],
      ["spatSample"],
      ["spin"],
      ["split"],
      ["sprc"],
      ["stdev"],
      ["stretch"],
      ["subset"],
      ["subst"],
      ["summary"],
      ["Summary"],
      ["surfArea"],
      ["svc"],
      ["symdif"],
      ["t"],
      ["tail"],
      ["tapp"],
      ["terrain"],
      ["terraOptions"],
      ["text"],
      ["thresh"],
      ["tighten"],
      ["time"],
      ["time<-"],
      ["timeInfo"],
      ["tmpFiles"],
      ["toMemory"],
      ["trans"],
      ["trim"],
      ["union"],
      ["unique"],
      ["units"],
      ["units<-"],
      ["unloadGDALdrivers"],
      ["unserialize"],
      ["unwrap"],
      ["update"],
      ["values"],
      ["values<-"],
      ["varnames"],
      ["varnames<-"],
      ["vect"],
      ["vector_layers"],
      ["viewshed"],
      ["voronoi"],
      ["vrt"],
      ["vrt_tiles"],
      ["watershed"],
      ["weighted.mean"],
      ["where.max"],
      ["where.min"],
      ["which.lyr"],
      ["which.max"],
      ["which.min"],
      ["width"],
      ["window"],
      ["window<-"],
      ["wrap"],
      ["wrapCache"],
      ["writeCDF"],
      ["writeRaster"],
      ["writeStart"],
      ["writeStop"],
      ["writeValues"],
      ["writeVector"],
      ["xapp"],
      ["xFromCell"],
      ["xFromCol"],
      ["xmax"],
      ["xmax<-"],
      ["xmin"],
      ["xmin<-"],
      ["xres"],
      ["xyFromCell"],
      ["yFromCell"],
      ["yFromRow"],
      ["ymax"],
      ["ymax<-"],
      ["ymin"],
      ["ymin<-"],
      ["yres"],
      ["zonal"],
      ["zoom"]
    ],
    "topics": [
      ["geospatial"],
      ["raster"],
      ["spatial"],
      ["vector"],
      ["proj"],
      ["gdal"],
      ["geos"],
      ["cpp"]
    ],
    "score": 17.946,
    "stars": 594
  },
  {
    "id": 20972,
    "package_name": "raster",
    "title": "Geographic Data Analysis and Modeling",
    "description": "Reading, writing, manipulating, analyzing and modeling of\nspatial data. This package has been superseded by the \"terra\"\npackage <https://CRAN.R-project.org/package=terra>.",
    "version": "3.6-32",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "https://rspatial.org/raster",
    "exports": [
      ["%in%"],
      ["addLayer"],
      ["adjacent"],
      ["aggregate"],
      ["alignExtent"],
      ["all.equal"],
      ["animate"],
      ["approxNA"],
      ["area"],
      ["Arith"],
      ["as.array"],
      ["as.data.frame"],
      ["as.factor"],
      ["as.list"],
      ["as.matrix"],
      ["as.raster"],
      ["asFactor"],
      ["atan2"],
      ["bandnr"],
      ["barplot"],
      ["bbox"],
      ["beginCluster"],
      ["bind"],
      ["blockSize"],
      ["boundaries"],
      ["boxplot"],
      ["brick"],
      ["buffer"],
      ["calc"],
      ["canProcessInMemory"],
      ["ccodes"],
      ["cellFromCol"],
      ["cellFromLine"],
      ["cellFromPolygon"],
      ["cellFromRow"],
      ["cellFromRowCol"],
      ["cellFromRowColCombine"],
      ["cellFromXY"],
      ["cellsFromExtent"],
      ["cellStats"],
      ["clamp"],
      ["clearValues"],
      ["click"],
      ["clump"],
      ["clusterR"],
      ["colFromCell"],
      ["colFromX"],
      ["colortable"],
      ["colortable<-"],
      ["colSums"],
      ["Compare"],
      ["compareCRS"],
      ["compareRaster"],
      ["contour"],
      ["coordinates"],
      ["corLocal"],
      ["couldBeLonLat"],
      ["cover"],
      ["crop"],
      ["crosstab"],
      ["crs"],
      ["crs<-"],
      ["cut"],
      ["cv"],
      ["dataSigned"],
      ["dataSize"],
      ["dataType"],
      ["dataType<-"],
      ["density"],
      ["deratify"],
      ["direction"],
      ["disaggregate"],
      ["distance"],
      ["distanceFromPoints"],
      ["drawExtent"],
      ["drawLine"],
      ["drawPoly"],
      ["dropLayer"],
      ["endCluster"],
      ["erase"],
      ["extend"],
      ["extension"],
      ["extension<-"],
      ["extent"],
      ["extent<-"],
      ["extentFromCells"],
      ["extract"],
      ["factorValues"],
      ["filename"],
      ["filledContour"],
      ["flip"],
      ["flowPath"],
      ["focal"],
      ["focalWeight"],
      ["fourCellsFromXY"],
      ["freq"],
      ["fromDisk"],
      ["gain"],
      ["gain<-"],
      ["Geary"],
      ["GearyLocal"],
      ["geom"],
      ["getCluster"],
      ["getData"],
      ["getValues"],
      ["getValuesBlock"],
      ["getValuesFocal"],
      ["getZ"],
      ["gridDistance"],
      ["hasValues"],
      ["hdr"],
      ["head"],
      ["hillShade"],
      ["hist"],
      ["image"],
      ["init"],
      ["inMemory"],
      ["interpolate"],
      ["intersect"],
      ["is.factor"],
      ["isLonLat"],
      ["KML"],
      ["labels"],
      ["layerize"],
      ["layerStats"],
      ["levels"],
      ["lines"],
      ["localFun"],
      ["Logic"],
      ["mask"],
      ["match"],
      ["Math"],
      ["Math2"],
      ["maxValue"],
      ["mean"],
      ["merge"],
      ["metadata"],
      ["metadata<-"],
      ["minValue"],
      ["modal"],
      ["Moran"],
      ["MoranLocal"],
      ["mosaic"],
      ["movingFun"],
      ["NAvalue"],
      ["NAvalue<-"],
      ["nbands"],
      ["ncell"],
      ["ncol"],
      ["ncol<-"],
      ["nlayers"],
      ["nrow"],
      ["nrow<-"],
      ["offs"],
      ["offs<-"],
      ["origin"],
      ["origin<-"],
      ["overlay"],
      ["pairs"],
      ["pbClose"],
      ["pbCreate"],
      ["pbStep"],
      ["persp"],
      ["plot"],
      ["plotRGB"],
      ["pointDistance"],
      ["predict"],
      ["print"],
      ["proj4string"],
      ["projectExtent"],
      ["projection"],
      ["projection<-"],
      ["projectRaster"],
      ["quantile"],
      ["raster"],
      ["rasterFromCells"],
      ["rasterFromXYZ"],
      ["rasterize"],
      ["rasterOptions"],
      ["rasterTmpFile"],
      ["rasterToContour"],
      ["rasterToPoints"],
      ["rasterToPolygons"],
      ["ratify"],
      ["readAll"],
      ["readIniFile"],
      ["readStart"],
      ["readStop"],
      ["reclassify"],
      ["rectify"],
      ["removeTmpFiles"],
      ["res"],
      ["res<-"],
      ["resample"],
      ["returnCluster"],
      ["RGB"],
      ["rotate"],
      ["rotated"],
      ["rowColFromCell"],
      ["rowFromCell"],
      ["rowFromY"],
      ["rowSums"],
      ["sampleInt"],
      ["sampleRandom"],
      ["sampleRegular"],
      ["sampleStratified"],
      ["scale"],
      ["scalebar"],
      ["select"],
      ["setExtent"],
      ["setMinMax"],
      ["setValues"],
      ["setZ"],
      ["shapefile"],
      ["shift"],
      ["showTmpFiles"],
      ["slopeAspect"],
      ["SpExtent"],
      ["spLines"],
      ["spplot"],
      ["SpPoly"],
      ["spPolygons"],
      ["SpPolygons"],
      ["SpPolyPart"],
      ["stack"],
      ["stackApply"],
      ["stackOpen"],
      ["stackSave"],
      ["stackSelect"],
      ["stretch"],
      ["subs"],
      ["subset"],
      ["summary"],
      ["Summary"],
      ["symdif"],
      ["t"],
      ["tail"],
      ["terrain"],
      ["text"],
      ["tmpDir"],
      ["trim"],
      ["union"],
      ["unique"],
      ["unstack"],
      ["update"],
      ["validCell"],
      ["validCol"],
      ["validNames"],
      ["validRow"],
      ["values"],
      ["values<-"],
      ["weighted.mean"],
      ["Which"],
      ["which.max"],
      ["which.min"],
      ["whiches.max"],
      ["whiches.min"],
      ["wkt"],
      ["writeFormats"],
      ["writeRaster"],
      ["writeStart"],
      ["writeStop"],
      ["writeValues"],
      ["xFromCell"],
      ["xFromCol"],
      ["xmax"],
      ["xmax<-"],
      ["xmin"],
      ["xmin<-"],
      ["xres"],
      ["xyFromCell"],
      ["yFromCell"],
      ["yFromRow"],
      ["ymax"],
      ["ymax<-"],
      ["ymin"],
      ["ymin<-"],
      ["yres"],
      ["zApply"],
      ["zonal"],
      ["zoom"]
    ],
    "topics": [
      ["cpp"]
    ],
    "score": 16.9071,
    "stars": 163
  },
  {
    "id": 23538,
    "package_name": "spdep",
    "title": "Spatial Dependence: Weighting Schemes, Statistics",
    "description": "A collection of functions to create spatial weights matrix\nobjects from polygon 'contiguities', from point patterns by\ndistance and tessellations, for summarizing these objects, and\nfor permitting their use in spatial data analysis, including\nregional aggregation by minimum spanning tree; a collection of\ntests for spatial 'autocorrelation', including global 'Morans\nI' and 'Gearys C' proposed by 'Cliff' and 'Ord' (1973, ISBN:\n0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel'\ngeneral cross product statistic, Empirical Bayes estimates and\n'Assunção/Reis' (1999)\n<doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO;2-I>\nIndex, 'Getis/Ord' G ('Getis' and 'Ord' 1992)\n<doi:10.1111/j.1538-4632.1992.tb00261.x> and multicoloured join\ncount statistics, 'APLE' ('Li et al.' )\n<doi:10.1111/j.1538-4632.2007.00708.x>, local 'Moran's I',\n'Gearys C' ('Anselin' 1995)\n<doi:10.1111/j.1538-4632.1995.tb00338.x> and 'Getis/Ord' G\n('Ord' and 'Getis' 1995)\n<doi:10.1111/j.1538-4632.1995.tb00912.x>, 'saddlepoint'\napproximations ('Tiefelsdorf' 2002)\n<doi:10.1111/j.1538-4632.2002.tb01084.x> and exact tests for\nglobal and local 'Moran's I' ('Bivand et al.' 2009)\n<doi:10.1016/j.csda.2008.07.021> and 'LOSH' local indicators of\nspatial heteroscedasticity ('Ord' and 'Getis')\n<doi:10.1007/s00168-011-0492-y>. The implementation of most of\nthese measures is described in 'Bivand' and 'Wong' (2018)\n<doi:10.1007/s11749-018-0599-x>, with further extensions in\n'Bivand' (2022) <doi:10.1111/gean.12319>. 'Lagrange' multiplier\ntests for spatial dependence in linear models are provided\n('Anselin et al'. 1996) <doi:10.1016/0166-0462(95)02111-6>, as\nare 'Rao' score tests for hypothesised spatial 'Durbin' models\nbased on linear models ('Koley' and 'Bera' 2023)\n<doi:10.1080/17421772.2023.2256810>. Additions in 2024 include\nLocal Indicators for Categorical Data based on 'Carrer et al.'\n(2021) <doi:10.1016/j.jas.2020.105306> and 'Bivand et al.'\n(2017) <doi:10.1016/j.spasta.2017.03.003>; also Weighted\nMultivariate Spatial Autocorrelation Measures ('Bavaud' 2024)\n<doi:10.1111/gean.12390>. <doi:10.1080/17421772.2023.2256810>.\nA local indicators for categorical data (LICD) implementation\nbased on 'Carrer et al.' (2021) <doi:10.1016/j.jas.2020.105306>\nand 'Bivand et al.' (2017) <doi:10.1016/j.spasta.2017.03.003>\nwas added in 1.3-7. Multivariate 'spatialdelta' ('Bavaud' 2024)\n<doi:10.1111/gean.12390> was added in 1.3-13 ('Bivand' 2025\n<doi:10.26034/la.cdclsl.2025.8343>). From 'spdep' and\n'spatialreg' versions >= 1.2-1, the model fitting functions\npreviously present in this package are defunct in 'spdep' and\nmay be found in 'spatialreg'.",
    "version": "1.4-2",
    "maintainer": "Roger Bivand <Roger.Bivand@nhh.no>",
    "url": "https://github.com/r-spatial/spdep/,\nhttps://r-spatial.github.io/spdep/",
    "exports": [
      ["addlinks1"],
      ["aggregate.nb"],
      ["airdist"],
      ["as.data.frame.localmoranex"],
      ["as.data.frame.localmoransad"],
      ["autocov_dist"],
      ["card"],
      ["cell2nb"],
      ["chkIDs"],
      ["choynowski"],
      ["coerce"],
      ["complement.nb"],
      ["cornish_fisher"],
      ["df2sn"],
      ["diffnb"],
      ["dnearneigh"],
      ["droplinks"],
      ["EBest"],
      ["EBImoran.mc"],
      ["EBlocal"],
      ["edit.nb"],
      ["factorial_coordinates"],
      ["gabrielneigh"],
      ["geary"],
      ["geary.mc"],
      ["geary.test"],
      ["get.ClusterOption"],
      ["get.coresOption"],
      ["get.mcOption"],
      ["get.NoNeighbourOption"],
      ["get.spChkOption"],
      ["get.SubgraphCeiling"],
      ["get.SubgraphOption"],
      ["get.VerboseOption"],
      ["get.ZeroPolicyOption"],
      ["globalG.test"],
      ["graph_distance_weights"],
      ["graph2nb"],
      ["grid2nb"],
      ["have_factor_preds_mf"],
      ["hotspot"],
      ["include.self"],
      ["intersect.nb"],
      ["is.symmetric.glist"],
      ["is.symmetric.nb"],
      ["iterative_proportional_fitting_weights"],
      ["joincount.mc"],
      ["joincount.multi"],
      ["joincount.test"],
      ["knearneigh"],
      ["knn2nb"],
      ["lag.listw"],
      ["lee"],
      ["lee.mc"],
      ["lee.test"],
      ["licd_multi"],
      ["linearised_diffusive_weights"],
      ["listw2lines"],
      ["listw2mat"],
      ["listw2sn"],
      ["listw2star"],
      ["listw2U"],
      ["listw2WB"],
      ["lm.LMtests"],
      ["lm.morantest"],
      ["lm.morantest.exact"],
      ["lm.morantest.sad"],
      ["lm.RStests"],
      ["local_joincount_bv"],
      ["local_joincount_uni"],
      ["localC"],
      ["localC_perm"],
      ["localdelta"],
      ["localG"],
      ["localG_perm"],
      ["localGS"],
      ["localmoran"],
      ["localmoran_bv"],
      ["localmoran_perm"],
      ["localmoran.exact"],
      ["localmoran.exact.alt"],
      ["localmoran.sad"],
      ["LOSH"],
      ["LOSH.cs"],
      ["LOSH.mc"],
      ["make.sym.nb"],
      ["mat2listw"],
      ["metropolis_hastings_weights"],
      ["moran"],
      ["moran_bv"],
      ["moran.mc"],
      ["moran.plot"],
      ["moran.test"],
      ["mstree"],
      ["n.comp.nb"],
      ["nb2blocknb"],
      ["nb2INLA"],
      ["nb2lines"],
      ["nb2listw"],
      ["nb2listwdist"],
      ["nb2mat"],
      ["nb2WB"],
      ["nbcost"],
      ["nbcosts"],
      ["nbdists"],
      ["nblag"],
      ["nblag_cumul"],
      ["old.make.sym.nb"],
      ["p.adjustSP"],
      ["plot_factorialcoords"],
      ["plot_factorialscree"],
      ["plot_moran"],
      ["plot_spatialcoords"],
      ["plot_spatialscree"],
      ["plot.Gabriel"],
      ["plot.listw"],
      ["plot.mc.sim"],
      ["plot.mst"],
      ["plot.nb"],
      ["plot.relative"],
      ["plot.skater"],
      ["plot.spcor"],
      ["poly2nb"],
      ["print.jclist"],
      ["print.jcmulti"],
      ["print.localmoranex"],
      ["print.localmoransad"],
      ["print.moranex"],
      ["print.moransad"],
      ["print.spcor"],
      ["print.summary.localmoransad"],
      ["print.summary.moransad"],
      ["probmap"],
      ["prunecost"],
      ["prunemst"],
      ["read_swm_dbf"],
      ["read.dat2listw"],
      ["read.gal"],
      ["read.geoda"],
      ["read.gwt2nb"],
      ["read.swmdbf2listw"],
      ["relativeneigh"],
      ["remove.self"],
      ["Rotation"],
      ["SD.RStests"],
      ["set.ClusterOption"],
      ["set.coresOption"],
      ["set.mcOption"],
      ["set.NoNeighbourOption"],
      ["set.spChkOption"],
      ["set.SubgraphCeiling"],
      ["set.SubgraphOption"],
      ["set.VerboseOption"],
      ["set.ZeroPolicyOption"],
      ["setdiff.nb"],
      ["skater"],
      ["sn2listw"],
      ["soi.graph"],
      ["sp.correlogram"],
      ["sp.mantel.mc"],
      ["spatialdelta"],
      ["spdep"],
      ["spNamedVec"],
      ["spweights.constants"],
      ["ssw"],
      ["subset.listw"],
      ["subset.nb"],
      ["summary.localmoransad"],
      ["summary.moransad"],
      ["sym.attr.nb"],
      ["Szero"],
      ["tolerance.nb"],
      ["tri2nb"],
      ["union.nb"],
      ["vi2mrc"],
      ["warn_factor_preds"],
      ["write_swm_dbf"],
      ["write.nb.gal"],
      ["write.sn2dat"],
      ["write.sn2DBF"],
      ["write.sn2gwt"],
      ["write.swmdbf"]
    ],
    "topics": [
      ["spatial-autocorrelation"],
      ["spatial-dependence"],
      ["spatial-weights"]
    ],
    "score": 16.8279,
    "stars": 141
  },
  {
    "id": 10294,
    "package_name": "classInt",
    "title": "Choose Univariate Class Intervals",
    "description": "Selected commonly used methods for choosing univariate\nclass intervals for mapping or other graphics purposes.",
    "version": "0.4-11",
    "maintainer": "Roger Bivand <Roger.Bivand@nhh.no>",
    "url": "https://r-spatial.github.io/classInt/,\nhttps://github.com/r-spatial/classInt/",
    "exports": [
      ["classify_intervals"],
      ["classIntervals"],
      ["classIntervals2shingle"],
      ["findColours"],
      ["findCols"],
      ["getBclustClassIntervals"],
      ["getHclustClassIntervals"],
      ["jenks.tests"],
      ["nPartitions"]
    ],
    "topics": [
      ["fortran"]
    ],
    "score": 16.4971,
    "stars": 35
  },
  {
    "id": 23511,
    "package_name": "spatstat",
    "title": "Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests",
    "description": "Comprehensive open-source toolbox for analysing Spatial\nPoint Patterns. Focused mainly on two-dimensional point\npatterns, including multitype/marked points, in any spatial\nregion. Also supports three-dimensional point patterns,\nspace-time point patterns in any number of dimensions, point\npatterns on a linear network, and patterns of other geometrical\nobjects. Supports spatial covariate data such as pixel images.\nContains over 3000 functions for plotting spatial data,\nexploratory data analysis, model-fitting, simulation, spatial\nsampling, model diagnostics, and formal inference. Data types\ninclude point patterns, line segment patterns, spatial windows,\npixel images, tessellations, and linear networks. Exploratory\nmethods include quadrat counts, K-functions and their\nsimulation envelopes, nearest neighbour distance and empty\nspace statistics, Fry plots, pair correlation function, kernel\nsmoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation\nfunctions, segregation indices, mark dependence diagnostics,\nand kernel estimates of covariate effects. Formal hypothesis\ntests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte\nCarlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage\nMonte Carlo) and tests for covariate effects\n(Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also\nsupported. Parametric models can be fitted to point pattern\ndata using the functions ppm(), kppm(), slrm(), dppm() similar\nto glm(). Types of models include Poisson, Gibbs and Cox point\nprocesses, Neyman-Scott cluster processes, and determinantal\npoint processes. Models may involve dependence on covariates,\ninter-point interaction, cluster formation and dependence on\nmarks. Models are fitted by maximum likelihood, logistic\nregression, minimum contrast, and composite likelihood methods.\nA model can be fitted to a list of point patterns (replicated\npoint pattern data) using the function mppm(). The model can\ninclude random effects and fixed effects depending on the\nexperimental design, in addition to all the features listed\nabove. Fitted point process models can be simulated,\nautomatically. Formal hypothesis tests of a fitted model are\nsupported (likelihood ratio test, analysis of deviance, Monte\nCarlo tests) along with basic tools for model selection\n(stepwise(), AIC()) and variable selection (sdr). Tools for\nvalidating the fitted model include simulation envelopes,\nresiduals, residual plots and Q-Q plots, leverage and influence\ndiagnostics, partial residuals, and added variable plots.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 16.3734,
    "stars": 0
  },
  {
    "id": 14762,
    "package_name": "gstat",
    "title": "Spatial and Spatio-Temporal Geostatistical Modelling, Prediction\nand Simulation",
    "description": "Variogram modelling; simple, ordinary and universal point\nor block (co)kriging; spatio-temporal kriging; sequential\nGaussian or indicator (co)simulation; variogram and variogram\nmap plotting utility functions; supports sf and stars.",
    "version": "2.1-5",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://github.com/r-spatial/gstat/,\nhttps://r-spatial.github.io/gstat/",
    "exports": [
      ["[.gstat"],
      ["as.vgm.variomodel"],
      ["cross.name"],
      ["estiStAni"],
      ["extractPar"],
      ["extractParNames"],
      ["fit.lmc"],
      ["fit.StVariogram"],
      ["fit.variogram"],
      ["fit.variogram.gls"],
      ["fit.variogram.reml"],
      ["get_gstat_progress"],
      ["get.contr"],
      ["gstat"],
      ["gstat.cv"],
      ["hscat"],
      ["idw"],
      ["idw0"],
      ["krige"],
      ["krige.cv"],
      ["krige0"],
      ["krigeSimCE"],
      ["krigeST"],
      ["krigeSTSimTB"],
      ["krigeSTTg"],
      ["krigeTg"],
      ["map.to.lev"],
      ["ossfim"],
      ["panel.pointPairs"],
      ["set_gstat_progress"],
      ["show.vgms"],
      ["spplot.vcov"],
      ["variogram"],
      ["variogramLine"],
      ["variogramST"],
      ["variogramSurface"],
      ["vgm"],
      ["vgm.panel.xyplot"],
      ["vgmArea"],
      ["vgmAreaST"],
      ["vgmST"],
      ["xyz2img"]
    ],
    "topics": [
      ["openblas"]
    ],
    "score": 15.728,
    "stars": 205
  },
  {
    "id": 22138,
    "package_name": "s2",
    "title": "Spherical Geometry Operators Using the S2 Geometry Library",
    "description": "Provides R bindings for Google's s2 library for geometric\ncalculations on the sphere. High-performance constructors and\nexporters provide high compatibility with existing spatial\npackages, transformers construct new geometries from existing\ngeometries, predicates provide a means to select geometries\nbased on spatial relationships, and accessors extract\ninformation about geometries.",
    "version": "1.1.9",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://r-spatial.github.io/s2/, https://github.com/r-spatial/s2,\nhttp://s2geometry.io/",
    "exports": [
      ["as_s2_cell"],
      ["as_s2_cell_union"],
      ["as_s2_geography"],
      ["as_s2_lnglat"],
      ["as_s2_point"],
      ["new_s2_cell"],
      ["s2_area"],
      ["s2_as_binary"],
      ["s2_as_text"],
      ["s2_boundary"],
      ["s2_bounds_cap"],
      ["s2_bounds_rect"],
      ["s2_buffer_cells"],
      ["s2_cell"],
      ["s2_cell_area"],
      ["s2_cell_area_approx"],
      ["s2_cell_boundary"],
      ["s2_cell_center"],
      ["s2_cell_child"],
      ["s2_cell_common_ancestor_level"],
      ["s2_cell_common_ancestor_level_agg"],
      ["s2_cell_contains"],
      ["s2_cell_debug_string"],
      ["s2_cell_distance"],
      ["s2_cell_edge_neighbour"],
      ["s2_cell_invalid"],
      ["s2_cell_is_face"],
      ["s2_cell_is_leaf"],
      ["s2_cell_is_valid"],
      ["s2_cell_level"],
      ["s2_cell_max_distance"],
      ["s2_cell_may_intersect"],
      ["s2_cell_parent"],
      ["s2_cell_polygon"],
      ["s2_cell_sentinel"],
      ["s2_cell_to_lnglat"],
      ["s2_cell_union"],
      ["s2_cell_union_contains"],
      ["s2_cell_union_difference"],
      ["s2_cell_union_intersection"],
      ["s2_cell_union_intersects"],
      ["s2_cell_union_normalize"],
      ["s2_cell_union_union"],
      ["s2_cell_vertex"],
      ["s2_centroid"],
      ["s2_centroid_agg"],
      ["s2_closest_edges"],
      ["s2_closest_feature"],
      ["s2_closest_point"],
      ["s2_contains"],
      ["s2_contains_matrix"],
      ["s2_convex_hull"],
      ["s2_convex_hull_agg"],
      ["s2_coverage_union_agg"],
      ["s2_covered_by"],
      ["s2_covered_by_matrix"],
      ["s2_covering_cell_ids"],
      ["s2_covering_cell_ids_agg"],
      ["s2_covers"],
      ["s2_covers_matrix"],
      ["s2_data_cities"],
      ["s2_data_countries"],
      ["s2_data_timezones"],
      ["s2_difference"],
      ["s2_dimension"],
      ["s2_disjoint"],
      ["s2_disjoint_matrix"],
      ["s2_distance"],
      ["s2_distance_matrix"],
      ["s2_dwithin"],
      ["s2_dwithin_matrix"],
      ["s2_earth_radius_meters"],
      ["s2_equals"],
      ["s2_equals_matrix"],
      ["s2_farthest_feature"],
      ["s2_geog_from_text"],
      ["s2_geog_from_wkb"],
      ["s2_geog_point"],
      ["s2_geography"],
      ["s2_geography_writer"],
      ["s2_hemisphere"],
      ["s2_interpolate"],
      ["s2_interpolate_normalized"],
      ["s2_intersection"],
      ["s2_intersects"],
      ["s2_intersects_box"],
      ["s2_intersects_matrix"],
      ["s2_is_collection"],
      ["s2_is_empty"],
      ["s2_is_valid"],
      ["s2_is_valid_detail"],
      ["s2_length"],
      ["s2_lnglat"],
      ["s2_make_line"],
      ["s2_make_polygon"],
      ["s2_max_distance"],
      ["s2_max_distance_matrix"],
      ["s2_may_intersect_matrix"],
      ["s2_minimum_clearance_line_between"],
      ["s2_num_points"],
      ["s2_options"],
      ["s2_perimeter"],
      ["s2_plot"],
      ["s2_point"],
      ["s2_point_crs"],
      ["s2_point_on_surface"],
      ["s2_prepared_dwithin"],
      ["s2_project"],
      ["s2_project_normalized"],
      ["s2_projection_mercator"],
      ["s2_projection_orthographic"],
      ["s2_projection_plate_carree"],
      ["s2_rebuild"],
      ["s2_rebuild_agg"],
      ["s2_simplify"],
      ["s2_snap_distance"],
      ["s2_snap_identity"],
      ["s2_snap_level"],
      ["s2_snap_precision"],
      ["s2_snap_to_grid"],
      ["s2_sym_difference"],
      ["s2_tessellate_tol_default"],
      ["s2_touches"],
      ["s2_touches_matrix"],
      ["s2_trans_lnglat"],
      ["s2_trans_point"],
      ["s2_union"],
      ["s2_union_agg"],
      ["s2_within"],
      ["s2_within_matrix"],
      ["s2_world_plate_carree"],
      ["s2_x"],
      ["s2_y"]
    ],
    "topics": [
      ["openssl"],
      ["cpp"]
    ],
    "score": 14.4825,
    "stars": 77
  },
  {
    "id": 14010,
    "package_name": "geosphere",
    "title": "Spherical Trigonometry",
    "description": "Spherical trigonometry for geographic applications. That\nis, compute distances and related measures for angular\n(longitude/latitude) locations.",
    "version": "1.5-20",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "",
    "exports": [
      ["alongTrackDistance"],
      ["antipodal"],
      ["antipode"],
      ["areaPolygon"],
      ["bearing"],
      ["bearingRhumb"],
      ["centroid"],
      ["daylength"],
      ["destPoint"],
      ["destPointRhumb"],
      ["dist2gc"],
      ["dist2Line"],
      ["distCosine"],
      ["distGeo"],
      ["distHaversine"],
      ["distm"],
      ["distMeeus"],
      ["distRhumb"],
      ["distVincentyEllipsoid"],
      ["distVincentySphere"],
      ["finalBearing"],
      ["gcIntermediate"],
      ["gcIntersect"],
      ["gcIntersectBearing"],
      ["gcLat"],
      ["gcLon"],
      ["gcMaxLat"],
      ["geodesic"],
      ["geodesic_inverse"],
      ["geomean"],
      ["greatCircle"],
      ["greatCircleBearing"],
      ["horizon"],
      ["lengthLine"],
      ["makeLine"],
      ["makePoly"],
      ["mercator"],
      ["midPoint"],
      ["onGreatCircle"],
      ["OSGB"],
      ["perimeter"],
      ["plotArrows"],
      ["randomCoordinates"],
      ["refEllipsoids"],
      ["regularCoordinates"],
      ["span"]
    ],
    "topics": [
      ["cpp"]
    ],
    "score": 14.1574,
    "stars": 41
  },
  {
    "id": 21496,
    "package_name": "rgee",
    "title": "R Bindings for Calling the 'Earth Engine' API",
    "description": "Earth Engine <https://earthengine.google.com/> client\nlibrary for R. All of the 'Earth Engine' API classes, modules,\nand functions are made available. Additional functions\nimplemented include importing (exporting) of Earth Engine\nspatial objects, extraction of time series, interactive map\ndisplay, assets management interface, and metadata display. See\n<https://r-spatial.github.io/rgee/> for further details.",
    "version": "1.1.8.9000",
    "maintainer": "Matthieu Stigler <Matthieu.Stigler@gmail.com>",
    "url": "https://github.com/r-spatial/rgee/,\nhttps://r-spatial.github.io/rgee/,\nhttps://github.com/google/earthengine-api/",
    "exports": [
      ["%>%"],
      ["ee"],
      ["ee_as_rast"],
      ["ee_as_raster"],
      ["ee_as_sf"],
      ["ee_as_stars"],
      ["ee_as_thumbnail"],
      ["ee_Authenticate"],
      ["ee_check"],
      ["ee_check_credentials"],
      ["ee_check_gcloud"],
      ["ee_check_python"],
      ["ee_check_python_packages"],
      ["ee_check_task_status"],
      ["ee_clean_container"],
      ["ee_clean_pyenv"],
      ["ee_clean_user_credentials"],
      ["ee_drive_to_local"],
      ["ee_extract"],
      ["ee_gcs_to_local"],
      ["ee_get_assethome"],
      ["ee_get_date_ic"],
      ["ee_get_date_img"],
      ["ee_get_earthengine_path"],
      ["ee_help"],
      ["ee_image_info"],
      ["ee_image_to_asset"],
      ["ee_image_to_drive"],
      ["ee_image_to_gcs"],
      ["ee_imagecollection_to_local"],
      ["ee_Initialize"],
      ["ee_install"],
      ["ee_install_set_pyenv"],
      ["ee_install_upgrade"],
      ["ee_manage_asset_access"],
      ["ee_manage_asset_size"],
      ["ee_manage_assetlist"],
      ["ee_manage_cancel_all_running_task"],
      ["ee_manage_copy"],
      ["ee_manage_create"],
      ["ee_manage_delete"],
      ["ee_manage_delete_properties"],
      ["ee_manage_move"],
      ["ee_manage_quota"],
      ["ee_manage_set_properties"],
      ["ee_manage_task"],
      ["ee_monitoring"],
      ["ee_print"],
      ["ee_table_to_asset"],
      ["ee_table_to_drive"],
      ["ee_table_to_gcs"],
      ["ee_user_info"],
      ["ee_users"],
      ["ee_utils_cog_metadata"],
      ["ee_utils_create_json"],
      ["ee_utils_create_manifest_image"],
      ["ee_utils_create_manifest_table"],
      ["ee_utils_dataset_display"],
      ["ee_utils_future_value"],
      ["ee_utils_get_crs"],
      ["ee_utils_py_to_r"],
      ["ee_utils_pyfunc"],
      ["ee_utils_sak_copy"],
      ["ee_utils_sak_validate"],
      ["ee_utils_shp_to_zip"],
      ["ee_version"],
      ["eedate_to_rdate"],
      ["gcs_to_ee_image"],
      ["gcs_to_ee_table"],
      ["local_to_gcs"],
      ["Map"],
      ["R6Map"],
      ["raster_as_ee"],
      ["rdate_to_eedate"],
      ["sf_as_ee"],
      ["stars_as_ee"]
    ],
    "topics": [
      ["earth-engine"],
      ["earthengine"],
      ["google-earth-engine"],
      ["googleearthengine"],
      ["spatial-analysis"],
      ["spatial-data"]
    ],
    "score": 13.9993,
    "stars": 753
  },
  {
    "id": 23503,
    "package_name": "spatialreg",
    "title": "Spatial Regression Analysis",
    "description": "A collection of all the estimation functions for spatial\ncross-sectional models (on lattice/areal data using spatial\nweights matrices) contained up to now in 'spdep'. These model\nfitting functions include maximum likelihood methods for\ncross-sectional models proposed by 'Cliff' and 'Ord' (1973,\nISBN:0850860369) and (1981, ISBN:0850860814), fitting methods\ninitially described by 'Ord' (1975)\n<doi:10.1080/01621459.1975.10480272>. The models are further\ndescribed by 'Anselin' (1988) <doi:10.1007/978-94-015-7799-1>.\nSpatial two stage least squares and spatial general method of\nmoment models initially proposed by 'Kelejian' and 'Prucha'\n(1998) <doi:10.1023/A:1007707430416> and (1999)\n<doi:10.1111/1468-2354.00027> are provided. Impact methods and\nMCMC fitting methods proposed by 'LeSage' and 'Pace' (2009)\n<doi:10.1201/9781420064254> are implemented for the family of\ncross-sectional spatial regression models. Methods for fitting\nthe log determinant term in maximum likelihood and MCMC fitting\nare compared by 'Bivand et al.' (2013)\n<doi:10.1111/gean.12008>, and model fitting methods by 'Bivand'\nand 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both of these\narticles include extensive lists of references. A recent review\nis provided by 'Bivand', 'Millo' and 'Piras' (2021)\n<doi:10.3390/math9111276>. 'spatialreg' >= 1.1-* corresponded\nto 'spdep' >= 1.1-1, in which the model fitting functions were\ndeprecated and passed through to 'spatialreg', but masked those\nin 'spatialreg'. From versions 1.2-*, the functions have been\nmade defunct in 'spdep'. From version 1.3-6, add\nAnselin-Kelejian (1997) test to `stsls` for residual spatial\nautocorrelation <doi:10.1177/016001769702000109>.",
    "version": "1.4-2",
    "maintainer": "Roger Bivand <Roger.Bivand@nhh.no>",
    "url": "https://github.com/r-spatial/spatialreg/,\nhttps://r-spatial.github.io/spatialreg/",
    "exports": [
      ["aple"],
      ["aple.mc"],
      ["aple.plot"],
      ["as_dgRMatrix_listw"],
      ["as_dsCMatrix_I"],
      ["as_dsCMatrix_IrW"],
      ["as_dsTMatrix_listw"],
      ["as.spam.listw"],
      ["bptest.Sarlm"],
      ["can.be.simmed"],
      ["cheb_setup"],
      ["coerce"],
      ["create_WX"],
      ["do_ldet"],
      ["eigen_pre_setup"],
      ["eigen_setup"],
      ["eigenw"],
      ["errorsarlm"],
      ["get.ClusterOption"],
      ["get.coresOption"],
      ["get.mcOption"],
      ["get.VerboseOption"],
      ["get.ZeroPolicyOption"],
      ["GMargminImage"],
      ["GMerrorsar"],
      ["griffith_sone"],
      ["gstsls"],
      ["Hausman.test"],
      ["impacts"],
      ["intImpacts"],
      ["invIrM"],
      ["invIrW"],
      ["Jacobian_W"],
      ["jacobianSetup"],
      ["l_max"],
      ["lagmess"],
      ["lagsarlm"],
      ["lextrB"],
      ["lextrS"],
      ["lextrW"],
      ["listw2U_Matrix"],
      ["listw2U_spam"],
      ["lmSLX"],
      ["localAple"],
      ["LR.Sarlm"],
      ["LR1.Lagmess"],
      ["LR1.Sarlm"],
      ["LR1.Spautolm"],
      ["LU_prepermutate_setup"],
      ["LU_setup"],
      ["Matrix_J_setup"],
      ["Matrix_setup"],
      ["mcdet_setup"],
      ["MCMCsamp"],
      ["ME"],
      ["mom_calc"],
      ["mom_calc_int2"],
      ["moments_setup"],
      ["powerWeights"],
      ["sacsarlm"],
      ["SE_classic_setup"],
      ["SE_interp_setup"],
      ["SE_whichMin_setup"],
      ["set.ClusterOption"],
      ["set.coresOption"],
      ["set.mcOption"],
      ["set.VerboseOption"],
      ["set.ZeroPolicyOption"],
      ["similar.listw"],
      ["spam_setup"],
      ["spam_update_setup"],
      ["SpatialFiltering"],
      ["spautolm"],
      ["spBreg_err"],
      ["spBreg_lag"],
      ["spBreg_sac"],
      ["stsls"],
      ["subgraph_eigenw"],
      ["trW"],
      ["Wald1.Sarlm"]
    ],
    "topics": [
      ["bayesian"],
      ["impacts"],
      ["maximum-likelihood"],
      ["spatial-dependence"],
      ["spatial-econometrics"],
      ["spatial-regression"],
      ["openblas"]
    ],
    "score": 13.6798,
    "stars": 52
  },
  {
    "id": 16339,
    "package_name": "leaflet.extras",
    "title": "Extra Functionality for 'leaflet' Package",
    "description": "The 'leaflet' JavaScript library provides many plugins\nsome of which are available in the core 'leaflet' package, but\nthere are many more. It is not possible to support them all in\nthe core 'leaflet' package. This package serves as an add-on to\nthe 'leaflet' package by providing extra functionality via\n'leaflet' plugins.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 13.1776,
    "stars": 0
  },
  {
    "id": 13979,
    "package_name": "geojsonsf",
    "title": "GeoJSON to Simple Feature Converter",
    "description": "Converts Between GeoJSON and simple feature objects.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 13.0711,
    "stars": 0
  },
  {
    "id": 16767,
    "package_name": "lwgeom",
    "title": "Bindings to Selected 'liblwgeom' Functions for Simple Features",
    "description": "Access to selected functions found in 'liblwgeom'\n<https://github.com/postgis/postgis/tree/master/liblwgeom>, the\nlight-weight geometry library used by 'PostGIS'\n<http://postgis.net/>.",
    "version": "0.2-15",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://r-spatial.github.io/lwgeom/,\nhttps://github.com/r-spatial/lwgeom",
    "exports": [
      ["lwgeom_extSoftVersion"],
      ["lwgeom_make_valid"],
      ["st_asewkt"],
      ["st_astext"],
      ["st_endpoint"],
      ["st_force_polygon_cw"],
      ["st_geod_area"],
      ["st_geod_azimuth"],
      ["st_geod_covered_by"],
      ["st_geod_covers"],
      ["st_geod_distance"],
      ["st_geod_length"],
      ["st_geod_segmentize"],
      ["st_geohash"],
      ["st_geom_from_geohash"],
      ["st_is_polygon_cw"],
      ["st_linesubstring"],
      ["st_minimum_bounding_circle"],
      ["st_perimeter"],
      ["st_perimeter_2d"],
      ["st_perimeter_lwgeom"],
      ["st_snap_to_grid"],
      ["st_split"],
      ["st_startpoint"],
      ["st_subdivide"],
      ["st_transform_proj"],
      ["st_wrap_x"]
    ],
    "topics": [
      ["proj"],
      ["geos"],
      ["cpp"]
    ],
    "score": 13.0266,
    "stars": 63
  },
  {
    "id": 12760,
    "package_name": "exactextractr",
    "title": "Fast Extraction from Raster Datasets using Polygons",
    "description": "Quickly and accurately summarizes raster values over\npolygonal areas (\"zonal statistics\").",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 13.005,
    "stars": 0
  },
  {
    "id": 23398,
    "package_name": "spData",
    "title": "Datasets for Spatial Analysis",
    "description": "Diverse spatial datasets for demonstrating, benchmarking\nand teaching spatial data analysis. It includes R data of class\nsf (defined by the package 'sf'), Spatial ('sp'), and nb\n('spdep'). Unlike other spatial data packages such as\n'rnaturalearth' and 'maps', it also contains data stored in a\nrange of file formats including GeoJSON and GeoPackage, but\nfrom version 2.3.4, no longer ESRI Shapefile - use GeoPackage\ninstead. Some of the datasets are designed to illustrate\nspecific analysis techniques. cycle_hire() and\ncycle_hire_osm(), for example, is designed to illustrate point\npattern analysis techniques.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 12.6392,
    "stars": 0
  },
  {
    "id": 16244,
    "package_name": "landscapemetrics",
    "title": "Landscape Metrics for Categorical Map Patterns",
    "description": "Calculates landscape metrics for categorical landscape\npatterns in a tidy workflow. 'landscapemetrics' reimplements\nthe most common metrics from 'FRAGSTATS'\n(<https://www.fragstats.org/>) and new ones from the current\nliterature on landscape metrics. This package supports 'terra'\nSpatRaster objects as input arguments. It further provides\nutility functions to visualize patches, select metrics and\nbuilding blocks to develop new metrics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 12.5962,
    "stars": 0
  },
  {
    "id": 11791,
    "package_name": "dismo",
    "title": "Species Distribution Modeling",
    "description": "Methods for species distribution modeling, that is,\npredicting the environmental similarity of any site to that of\nthe locations of known occurrences of a species.",
    "version": "1.3-15",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "https://rspatial.org/raster/sdm/",
    "exports": [
      ["bioclim"],
      ["biovars"],
      ["calc.deviance"],
      ["circleHull"],
      ["circles"],
      ["convHull"],
      ["dcEvaluate"],
      ["domain"],
      ["ecocrop"],
      ["ecolim"],
      ["evaluate"],
      ["evaluateROCR"],
      ["gbif"],
      ["gbm.fixed"],
      ["gbm.holdout"],
      ["gbm.interactions"],
      ["gbm.perspec"],
      ["gbm.plot"],
      ["gbm.plot.fits"],
      ["gbm.simplify"],
      ["gbm.step"],
      ["geocode"],
      ["geoDist"],
      ["geoIDW"],
      ["getCrop"],
      ["gmap"],
      ["gridSample"],
      ["kfold"],
      ["mahal"],
      ["maxent"],
      ["Mercator"],
      ["mess"],
      ["nicheEquivalency"],
      ["nicheOverlap"],
      ["nullRandom"],
      ["plot"],
      ["points"],
      ["pointValues"],
      ["predict"],
      ["prepareData"],
      ["pwdSample"],
      ["randomPoints"],
      ["rectHull"],
      ["response"],
      ["ssb"],
      ["threshold"],
      ["voronoi"],
      ["voronoiHull"]
    ],
    "topics": [
      ["cpp"]
    ],
    "score": 12.1707,
    "stars": 33
  },
  {
    "id": 22523,
    "package_name": "sdmTMB",
    "title": "Spatial and Spatiotemporal SPDE-Based GLMMs with 'TMB'",
    "description": "Implements spatial and spatiotemporal GLMMs (Generalized\nLinear Mixed Effect Models) using 'TMB', 'fmesher', and the\nSPDE (Stochastic Partial Differential Equation) Gaussian Markov\nrandom field approximation to Gaussian random fields. One\ncommon application is for spatially explicit species\ndistribution models (SDMs). See Anderson et al. (2024)\n<doi:10.1101/2022.03.24.485545>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 12.1519,
    "stars": 0
  },
  {
    "id": 13010,
    "package_name": "fasterize",
    "title": "Fast Polygon to Raster Conversion",
    "description": "Provides a drop-in replacement for rasterize() from the\n'raster' package that takes polygon vector or data frame\nobjects, and is much faster. There is support for the main\noptions provided by the rasterize() function, including setting\nthe field used and background value, and options for\naggregating multi-layer rasters. Uses the scan line algorithm\nattributed to Wylie et al. (1967)\n<doi:10.1145/1465611.1465619>. Note that repository originally\nwas hosted at 'Github' 'ecohealthalliance/fasterize' but was\nmigrated to 'hypertidy/fasterize' in March 2025, and can be\nfound indexed on 'R universe'\n<https://cran.r-universe.dev/fasterize>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.986,
    "stars": 0
  },
  {
    "id": 22747,
    "package_name": "sfnetworks",
    "title": "Tidy Geospatial Networks",
    "description": "Provides a tidy approach to spatial network analysis, in\nthe form of classes and functions that enable a seamless\ninteraction between the network analysis package 'tidygraph'\nand the spatial analysis package 'sf'.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.8254,
    "stars": 0
  },
  {
    "id": 17008,
    "package_name": "matlib",
    "title": "Matrix Functions for Teaching and Learning Linear Algebra and\nMultivariate Statistics",
    "description": "A collection of matrix functions for teaching and learning\nmatrix linear algebra as used in multivariate statistical\nmethods. Many of these functions are designed for tutorial\npurposes in learning matrix algebra ideas using R. In some\ncases, functions are provided for concepts available elsewhere\nin R, but where the function call or name is not obvious. In\nother cases, functions are provided to show or demonstrate an\nalgorithm. In addition, a collection of functions are provided\nfor drawing vector diagrams in 2D and 3D and for rendering\nmatrix expressions and equations in LaTeX.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.8138,
    "stars": 0
  },
  {
    "id": 23525,
    "package_name": "spatstat.utils",
    "title": "Utility Functions for 'spatstat'",
    "description": "Contains utility functions for the 'spatstat' family of\npackages which may also be useful for other purposes.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.7088,
    "stars": 0
  },
  {
    "id": 13959,
    "package_name": "geodata",
    "title": "Access Geographic Data",
    "description": "Functions for downloading of geographic data for use in\nspatial analysis and mapping. The package facilitates access to\nclimate, crops, elevation, land use, soil, species occurrence,\naccessibility, administrative boundaries and other data.",
    "version": "0.6-8",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "https://rspatial.github.io/geodata/",
    "exports": [
      ["bio_oracle"],
      ["cmip6_tile"],
      ["cmip6_world"],
      ["country_codes"],
      ["crop_calendar_sacks"],
      ["crop_monfreda"],
      ["crop_spam"],
      ["cropland"],
      ["elevation_30s"],
      ["elevation_3s"],
      ["elevation_global"],
      ["footprint"],
      ["gadm"],
      ["geodata_path"],
      ["landcover"],
      ["monfredaCrops"],
      ["osm"],
      ["population"],
      ["rice_calendar"],
      ["sacksCrops"],
      ["soil_af"],
      ["soil_af_elements"],
      ["soil_af_isda"],
      ["soil_af_isda_vsi"],
      ["soil_af_water"],
      ["soil_world"],
      ["soil_world_vsi"],
      ["sp_genus"],
      ["sp_occurrence"],
      ["sp_occurrence_split"],
      ["spamCrops"],
      ["travel_time"],
      ["world"],
      ["worldclim_country"],
      ["worldclim_global"],
      ["worldclim_tile"]
    ],
    "topics": [
      ["agriculture"],
      ["climate"],
      ["data"],
      ["ecology"],
      ["soil"],
      ["spatial"]
    ],
    "score": 11.4661,
    "stars": 184
  },
  {
    "id": 16927,
    "package_name": "mapsf",
    "title": "Thematic Cartography",
    "description": "Create and integrate thematic maps in your workflow. This\npackage helps to design various cartographic representations\nsuch as proportional symbols, choropleth or typology maps. It\nalso offers several functions to display layout elements that\nimprove the graphic presentation of maps (e.g. scale bar, north\narrow, title, labels). 'mapsf' maps 'sf' objects on 'base'\ngraphics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.4631,
    "stars": 0
  },
  {
    "id": 25397,
    "package_name": "usmap",
    "title": "US Maps Including Alaska and Hawaii",
    "description": "Obtain United States map data frames of varying region\ntypes (e.g. county, state). The map data frames include Alaska\nand Hawaii conveniently placed to the bottom left, as they\nappear in most maps of the US. Convenience functions for\nplotting choropleths, visualizing spatial data, and working\nwith FIPS codes are also provided.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.4337,
    "stars": 0
  },
  {
    "id": 23515,
    "package_name": "spatstat.explore",
    "title": "Exploratory Data Analysis for the 'spatstat' Family",
    "description": "Functionality for exploratory data analysis and\nnonparametric analysis of spatial data, mainly spatial point\npatterns, in the 'spatstat' family of packages. (Excludes\nanalysis of spatial data on a linear network, which is covered\nby the separate package 'spatstat.linnet'.) Methods include\nquadrat counts, K-functions and their simulation envelopes,\nnearest neighbour distance and empty space statistics, Fry\nplots, pair correlation function, kernel smoothed intensity,\nrelative risk estimation with cross-validated bandwidth\nselection, mark correlation functions, segregation indices,\nmark dependence diagnostics, and kernel estimates of covariate\neffects. Formal hypothesis tests of random pattern\n(chi-squared, Kolmogorov-Smirnov, Monte Carlo,\nDiggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte\nCarlo) and tests for covariate effects\n(Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also\nsupported.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.0779,
    "stars": 0
  },
  {
    "id": 23514,
    "package_name": "spatstat.data",
    "title": "Datasets for 'spatstat' Family",
    "description": "Contains all the datasets for the 'spatstat' family of\npackages.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 11.0113,
    "stars": 0
  },
  {
    "id": 16335,
    "package_name": "leafgl",
    "title": "High-Performance 'WebGl' Rendering for Package 'leaflet'",
    "description": "Provides bindings to the 'Leaflet.glify' JavaScript\nlibrary which extends the 'leaflet' JavaScript library to\nrender large data in the browser using 'WebGl'.",
    "version": "0.2.2",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://github.com/r-spatial/leafgl,\nhttps://r-spatial.github.io/leafgl/",
    "exports": [
      ["addGlPoints"],
      ["addGlPolygons"],
      ["addGlPolylines"],
      ["clearGlGroup"],
      ["clearGlLayers"],
      ["leafglOutput"],
      ["makeColorMatrix"],
      ["makePopup"],
      ["removeGlPoints"],
      ["removeGlPolygons"],
      ["removeGlPolylines"],
      ["renderLeafgl"]
    ],
    "topics": [],
    "score": 10.8645,
    "stars": 284
  },
  {
    "id": 8609,
    "package_name": "apache.sedona",
    "title": "R Interface for Apache Sedona",
    "description": "R interface for 'Apache Sedona' based on 'sparklyr'\n(<https://sedona.apache.org>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.8497,
    "stars": 0
  },
  {
    "id": 14367,
    "package_name": "giscoR",
    "title": "Download Map Data from GISCO API - Eurostat",
    "description": "Tools to download data from the GISCO (Geographic\nInformation System of the Commission) Eurostat database\n<https://ec.europa.eu/eurostat/web/gisco>. Global and European\nmap data available.  This package is in no way officially\nrelated to or endorsed by Eurostat.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.8492,
    "stars": 0
  },
  {
    "id": 16340,
    "package_name": "leaflet.extras2",
    "title": "Extra Functionality for 'leaflet' Package",
    "description": "Several 'leaflet' plugins are integrated, which are\navailable as extension to the 'leaflet' package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.5766,
    "stars": 0
  },
  {
    "id": 22752,
    "package_name": "sftime",
    "title": "Classes and Methods for Simple Feature Objects that Have a Time\nColumn",
    "description": "Classes and methods for spatial objects that have a\nregistered time column, in particular for irregular\nspatiotemporal data. The time column can be of any type, but\nneeds to be ordinal. Regularly laid out spatiotemporal data\n(vector or raster data cubes) are handled by package 'stars'.",
    "version": "0.3.1.9000",
    "maintainer": "Henning Teickner <henning.teickner@uni-muenster.de>",
    "url": "https://r-spatial.github.io/sftime/,\nhttps://github.com/r-spatial/sftime",
    "exports": [
      ["is_sortable"],
      ["st_as_sftime"],
      ["st_drop_time"],
      ["st_set_time"],
      ["st_sftime"],
      ["st_time"],
      ["st_time<-"]
    ],
    "topics": [],
    "score": 10.5419,
    "stars": 50
  },
  {
    "id": 25853,
    "package_name": "whitebox",
    "title": "'WhiteboxTools' R Frontend",
    "description": "An R frontend for the 'WhiteboxTools' library, which is an\nadvanced geospatial data analysis platform developed by Prof.\nJohn Lindsay at the University of Guelph's Geomorphometry and\nHydrogeomatics Research Group. 'WhiteboxTools' can be used to\nperform common geographical information systems (GIS) analysis\noperations, such as cost-distance analysis, distance buffering,\nand raster reclassification. Remote sensing and image\nprocessing tasks include image enhancement (e.g. panchromatic\nsharpening, contrast adjustments), image mosaicing, numerous\nfiltering operations, simple classification (k-means), and\ncommon image transformations. 'WhiteboxTools' also contains\nadvanced tooling for spatial hydrological analysis (e.g.\nflow-accumulation, watershed delineation, stream network\nanalysis, sink removal), terrain analysis (e.g. common terrain\nindices such as slope, curvatures, wetness index, hillshading;\nhypsometric analysis; multi-scale topographic position\nanalysis), and LiDAR data processing. Suggested citation:\nLindsay (2016) <doi:10.1016/j.cageo.2016.07.003>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.5396,
    "stars": 0
  },
  {
    "id": 13823,
    "package_name": "gdalraster",
    "title": "Bindings to 'GDAL'",
    "description": "API bindings to the Geospatial Data Abstraction Library\n('GDAL', <https://gdal.org>). Implements the 'GDAL' Raster and\nVector Data Models. Bindings are implemented with 'Rcpp'\nmodules. Exposed C++ classes and stand-alone functions wrap\nmuch of the 'GDAL' API and provide additional functionality.\nCalling signatures resemble the native C, C++ and Python APIs\nprovided by the 'GDAL' project. Class 'GDALRaster' encapsulates\na 'GDALDataset' and its raster band objects. Class 'GDALVector'\nencapsulates an 'OGRLayer' and the 'GDALDataset' that contains\nit. Initial bindings are provided to the unified 'gdal' command\nline interface added in 'GDAL' 3.11. C++ stand-alone functions\nprovide bindings to most 'GDAL' \"traditional\" raster and vector\nutilities, including 'OGR' facilities for vector geoprocessing,\nseveral algorithms, as well as the Geometry API ('GEOS' via\n'GDAL' headers), the Spatial Reference Systems API, and methods\nfor coordinate transformation. Bindings to the Virtual Systems\nInterface ('VSI') API implement standard file system operations\nabstracted for URLs, cloud storage services,\n'Zip'/'GZip'/'7z'/'RAR', in-memory files, as well as regular\nlocal file systems. This provides a single interface for\noperating on file system objects that works the same for any\nstorage backend. A custom raster calculator evaluates a\nuser-defined R expression on a layer or stack of layers, with\npixel x/y available as variables in the expression. Raster\n'combine()' identifies and counts unique pixel combinations\nacross multiple input layers, with optional raster output of\nthe pixel-level combination IDs. Basic plotting capability is\nprovided for raster and vector display. 'gdalraster' leans\ntoward minimalism and the use of simple, lightweight objects\nfor holding raw data. Currently, only minimal S3 class\ninterfaces have been implemented for selected R objects that\ncontain spatial data. 'gdalraster' may be useful in\napplications that need scalable, low-level I/O, or prefer a\ndirect 'GDAL' API.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.4849,
    "stars": 0
  },
  {
    "id": 16345,
    "package_name": "leafpop",
    "title": "Include Tables, Images and Graphs in Leaflet Pop-Ups",
    "description": "Creates 'HTML' strings to embed tables, images or graphs\nin pop-ups of interactive maps created with packages like\n'leaflet' or 'mapview'. Handles local images located on the\nfile system or via remote URL. Handles graphs created with\n'lattice' or 'ggplot2' as well as interactive plots created\nwith 'htmlwidgets'.",
    "version": "0.1.0.9000",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://github.com/r-spatial/leafpop",
    "exports": [
      ["addPopupGraphs"],
      ["addPopupImages"],
      ["popupGraph"],
      ["popupImage"],
      ["popupTable"]
    ],
    "topics": [],
    "score": 10.3713,
    "stars": 118
  },
  {
    "id": 23271,
    "package_name": "smoothr",
    "title": "Smooth and Tidy Spatial Features",
    "description": "Tools for smoothing and tidying spatial features (i.e.\nlines and polygons) to make them more aesthetically pleasing.\nSmooth curves, fill holes, and remove small fragments from\nlines and polygons.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.3227,
    "stars": 0
  },
  {
    "id": 14562,
    "package_name": "googleway",
    "title": "Accesses Google Maps APIs to Retrieve Data and Plot Maps",
    "description": "Provides a mechanism to plot a 'Google Map' from 'R' and\noverlay it with shapes and markers. Also provides access to\n'Google Maps' APIs, including places, directions, roads,\ndistances, geocoding, elevation and timezone.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.1743,
    "stars": 0
  },
  {
    "id": 16899,
    "package_name": "mapdeck",
    "title": "Interactive Maps Using 'Mapbox GL JS' and 'Deck.gl'",
    "description": "Provides a mechanism to plot an interactive map using\n'Mapbox GL' (<https://docs.mapbox.com/mapbox-gl-js/api/>), a\njavascript library for interactive maps, and 'Deck.gl'\n(<https://deck.gl/>), a javascript library which uses 'WebGL'\nfor visualising large data sets.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.0898,
    "stars": 0
  },
  {
    "id": 19136,
    "package_name": "ows4R",
    "title": "Interface to OGC Web-Services (OWS)",
    "description": "Provides an Interface to Web-Services defined as standards\nby the Open Geospatial Consortium (OGC), including Web Feature\nService (WFS) for vector data, Web Coverage Service (WCS),\nCatalogue Service (CSW) for ISO/OGC metadata, Web Processing\nService (WPS) for data processes, and associated standards such\nas the common web-service specification (OWS) and OGC Filter\nEncoding. Partial support is provided for the Web Map Service\n(WMS). The purpose is to add support for additional OGC service\nstandards such as Web Coverage Processing Service (WCPS), the\nSensor Observation Service (SOS), or even new standard services\nemerging such OGC API or SensorThings.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 10.0661,
    "stars": 0
  },
  {
    "id": 23494,
    "package_name": "spatialEco",
    "title": "Spatial Analysis and Modelling Utilities",
    "description": "Utilities to support spatial data manipulation, query,\nsampling and modelling in ecological applications. Functions\ninclude models for species population density, spatial\nsmoothing, multivariate separability, point process model for\ncreating pseudo- absences and sub-sampling, Quadrant-based\nsampling and analysis, auto-logistic modeling, sampling models,\ncluster optimization, statistical exploratory tools and\nraster-based metrics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.7388,
    "stars": 0
  },
  {
    "id": 11241,
    "package_name": "cytomapper",
    "title": "Visualization of highly multiplexed imaging data in R",
    "description": "Highly multiplexed imaging acquires the single-cell\nexpression of selected proteins in a spatially-resolved\nfashion. These measurements can be visualised across multiple\nlength-scales. First, pixel-level intensities represent the\nspatial distributions of feature expression with highest\nresolution. Second, after segmentation, expression values or\ncell-level metadata (e.g. cell-type information) can be\nvisualised on segmented cell areas. This package contains\nfunctions for the visualisation of multiplexed read-outs and\ncell-level information obtained by multiplexed imaging\ntechnologies. The main functions of this package allow 1. the\nvisualisation of pixel-level information across multiple\nchannels, 2. the display of cell-level information (expression\nand/or metadata) on segmentation masks and 3. gating and\nvisualisation of single cells.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.663,
    "stars": 0
  },
  {
    "id": 23520,
    "package_name": "spatstat.model",
    "title": "Parametric Statistical Modelling and Inference for the\n'spatstat' Family",
    "description": "Functionality for parametric statistical modelling and\ninference for spatial data, mainly spatial point patterns, in\nthe 'spatstat' family of packages. (Excludes analysis of\nspatial data on a linear network, which is covered by the\nseparate package 'spatstat.linnet'.) Supports parametric\nmodelling, formal statistical inference, and model validation.\nParametric models include Poisson point processes, Cox point\nprocesses, Neyman-Scott cluster processes, Gibbs point\nprocesses and determinantal point processes. Models can be\nfitted to data using maximum likelihood, maximum\npseudolikelihood, maximum composite likelihood and the method\nof minimum contrast. Fitted models can be simulated and\npredicted. Formal inference includes hypothesis tests (quadrat\ncounting tests, Cressie-Read tests, Clark-Evans test, Berman\ntest, Diggle-Cressie-Loosmore-Ford test, scan test, studentised\npermutation test, segregation test, ANOVA tests of fitted\nmodels, adjusted composite likelihood ratio test, envelope\ntests, Dao-Genton test, balanced independent two-stage test),\nconfidence intervals for parameters, and prediction intervals\nfor point counts. Model validation techniques include leverage,\ninfluence, partial residuals, added variable plots, diagnostic\nplots, pseudoscore residual plots, model compensators and Q-Q\nplots.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.4663,
    "stars": 0
  },
  {
    "id": 11673,
    "package_name": "dggridR",
    "title": "Discrete Global Grids",
    "description": "Spatial analyses involving binning require that every bin\nhave the same area, but this is impossible using a rectangular\ngrid laid over the Earth or over any projection of the Earth.\nDiscrete global grids use hexagons, triangles, and diamonds to\novercome this issue, overlaying the Earth with equally-sized\nbins. This package provides utilities for working with discrete\nglobal grids, along with utilities to aid in plotting such\ndata.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.4379,
    "stars": 0
  },
  {
    "id": 20530,
    "package_name": "qgisprocess",
    "title": "Use 'QGIS' Processing Algorithms",
    "description": "Provides seamless access to the 'QGIS'\n(<https://qgis.org>) processing toolbox using the standalone\n'qgis_process' command-line utility.  Both native and\nthird-party (plugin) processing providers are supported.\nBeside referring data sources from file, also common objects\nfrom 'sf', 'terra' and 'stars' are supported. The native\nprocessing algorithms are documented by QGIS.org (2024)\n<https://docs.qgis.org/latest/en/docs/user_manual/processing_algs/>.",
    "version": "0.4.1.9000",
    "maintainer": "Floris Vanderhaeghe <floris.vanderhaeghe@inbo.be>",
    "url": "https://r-spatial.github.io/qgisprocess/,\nhttps://github.com/r-spatial/qgisprocess",
    "exports": [
      ["as_qgis_argument"],
      ["has_qgis"],
      ["qgis_algorithms"],
      ["qgis_arguments"],
      ["qgis_as_brick"],
      ["qgis_as_raster"],
      ["qgis_as_terra"],
      ["qgis_clean_argument"],
      ["qgis_clean_result"],
      ["qgis_clean_tmp"],
      ["qgis_configure"],
      ["qgis_description"],
      ["qgis_detect_macos"],
      ["qgis_detect_macos_paths"],
      ["qgis_detect_paths"],
      ["qgis_detect_windows"],
      ["qgis_detect_windows_paths"],
      ["qgis_dict_input"],
      ["qgis_disable_plugins"],
      ["qgis_enable_plugins"],
      ["qgis_extract_output"],
      ["qgis_extract_output_by_class"],
      ["qgis_extract_output_by_name"],
      ["qgis_extract_output_by_position"],
      ["qgis_function"],
      ["qgis_get_argument_specs"],
      ["qgis_get_description"],
      ["qgis_get_output_specs"],
      ["qgis_has_algorithm"],
      ["qgis_has_plugin"],
      ["qgis_has_provider"],
      ["qgis_list_input"],
      ["qgis_output"],
      ["qgis_outputs"],
      ["qgis_path"],
      ["qgis_pipe"],
      ["qgis_plugins"],
      ["qgis_providers"],
      ["qgis_result_args"],
      ["qgis_result_clean"],
      ["qgis_result_single"],
      ["qgis_result_status"],
      ["qgis_result_stderr"],
      ["qgis_result_stdout"],
      ["qgis_run"],
      ["qgis_run_algorithm"],
      ["qgis_run_algorithm_p"],
      ["qgis_search_algorithms"],
      ["qgis_show_help"],
      ["qgis_tmp_base"],
      ["qgis_tmp_clean"],
      ["qgis_tmp_file"],
      ["qgis_tmp_folder"],
      ["qgis_tmp_raster"],
      ["qgis_tmp_vector"],
      ["qgis_unconfigure"],
      ["qgis_use_json_input"],
      ["qgis_use_json_output"],
      ["qgis_using_json_input"],
      ["qgis_using_json_output"],
      ["qgis_version"]
    ],
    "topics": [],
    "score": 9.4359,
    "stars": 216
  },
  {
    "id": 16900,
    "package_name": "mapedit",
    "title": "Interactive Editing of Spatial Data in R",
    "description": "Suite of interactive functions and helpers for selecting\nand editing geospatial data.",
    "version": "0.7.0.9001",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://github.com/r-spatial/mapedit",
    "exports": [
      ["%>%"],
      ["createFeatures"],
      ["drawFeatures"],
      ["editAttributes"],
      ["editFeatures"],
      ["editMap"],
      ["editMod"],
      ["editModUI"],
      ["selectFeatures"],
      ["selectMap"],
      ["selectMod"],
      ["selectModUI"]
    ],
    "topics": [],
    "score": 9.362,
    "stars": 220
  },
  {
    "id": 21244,
    "package_name": "redist",
    "title": "Simulation Methods for Legislative Redistricting",
    "description": "Enables researchers to sample redistricting plans from a\npre-specified target distribution using Sequential Monte Carlo\nand Markov Chain Monte Carlo algorithms. The package allows for\nthe implementation of various constraints in the redistricting\nprocess such as geographic compactness and population parity\nrequirements. Tools for analysis such as computation of various\nsummary statistics and plotting functionality are also\nincluded. The package implements the SMC algorithm of McCartan\nand Imai (2023) <doi:10.1214/23-AOAS1763>, the enumeration\nalgorithm of Fifield, Imai, Kawahara, and Kenny (2020)\n<doi:10.1080/2330443X.2020.1791773>, the Flip MCMC algorithm of\nFifield, Higgins, Imai and Tarr (2020)\n<doi:10.1080/10618600.2020.1739532>, the\nMerge-split/Recombination algorithms of Carter et al. (2019)\n<doi:10.48550/arXiv.1911.01503> and DeFord et al. (2021)\n<doi:10.1162/99608f92.eb30390f>, and the Short-burst\noptimization algorithm of Cannon et al. (2020)\n<doi:10.48550/arXiv.2011.02288>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.3614,
    "stars": 0
  },
  {
    "id": 16890,
    "package_name": "mapSpain",
    "title": "Administrative Boundaries of Spain",
    "description": "Administrative Boundaries of Spain at several levels\n(Autonomous Communities, Provinces, Municipalities) based on\nthe 'GISCO' 'Eurostat' database\n<https://ec.europa.eu/eurostat/web/gisco> and 'CartoBase SIANE'\nfrom 'Instituto Geografico Nacional' <https://www.ign.es/>.  It\nalso provides a 'leaflet' plugin and the ability of downloading\nand processing static tiles.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.3584,
    "stars": 0
  },
  {
    "id": 16910,
    "package_name": "mapme.biodiversity",
    "title": "Efficient Monitoring of Global Biodiversity Portfolios",
    "description": "Biodiversity areas, especially primary forest, serve a\nmultitude of functions for local economy, regional\nfunctionality of the ecosystems as well as the global health of\nour planet. Recently, adverse changes in human land use\npractices and climatic responses to increased greenhouse gas\nemissions, put these biodiversity areas under a variety of\ndifferent threats. The present package helps to analyse a\nnumber of biodiversity indicators based on freely available\ngeographical datasets. It supports computational efficient\nroutines that allow the analysis of potentially global\nbiodiversity portfolios. The primary use case of the package is\nto support evidence based reporting of an organization's effort\nto protect biodiversity areas under threat and to identify\nregions were intervention is most duly needed.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.325,
    "stars": 0
  },
  {
    "id": 16346,
    "package_name": "leafsync",
    "title": "Small Multiples for Leaflet Web Maps",
    "description": "Create small multiples of several leaflet web maps with\n(optional) synchronised panning and zooming control. When\nsyncing is enabled all maps respond to mouse actions on one\nmap. This allows side-by-side comparisons of different\nattributes of the same geometries. Syncing can be adjusted so\nthat any combination of maps can be synchronised.",
    "version": "0.1.1.9002",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://github.com/r-spatial/leafsync",
    "exports": [
      ["latticeview"],
      ["latticeView"],
      ["sync"]
    ],
    "topics": [],
    "score": 9.1885,
    "stars": 36
  },
  {
    "id": 14551,
    "package_name": "googlePolylines",
    "title": "Encoding Coordinates into 'Google' Polylines",
    "description": "Encodes simple feature ('sf') objects and coordinates, and\ndecodes polylines using the 'Google' polyline encoding\nalgorithm\n(<https://developers.google.com/maps/documentation/utilities/polylinealgorithm>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.088,
    "stars": 0
  },
  {
    "id": 21996,
    "package_name": "rstac",
    "title": "Client Library for SpatioTemporal Asset Catalog",
    "description": "Provides functions to access, search and download\nspacetime earth observation data via SpatioTemporal Asset\nCatalog (STAC). This package supports the version 1.0.0 (and\nolder) of the STAC specification\n(<https://github.com/radiantearth/stac-spec>). For further\ndetails see Simoes et al. (2021)\n<doi:10.1109/IGARSS47720.2021.9553518>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 9.0108,
    "stars": 0
  },
  {
    "id": 13822,
    "package_name": "gdalcubes",
    "title": "Earth Observation Data Cubes from Satellite Image Collections",
    "description": "Processing collections of Earth observation images as\non-demand multispectral, multitemporal raster data cubes. Users\ndefine cubes by spatiotemporal extent, resolution, and spatial\nreference system and let 'gdalcubes' automatically apply\ncropping, reprojection, and resampling using the 'Geospatial\nData Abstraction Library' ('GDAL'). Implemented functions on\ndata cubes include reduction over space and time, applying\narithmetic expressions on pixel band values, moving window\naggregates over time, filtering by space, time, bands, and\npredicates on pixel values, exporting data cubes as 'netCDF' or\n'GeoTIFF' files, plotting, and extraction from spatial and or\nspatiotemporal features. All computational parts are\nimplemented in C++, linking to the 'GDAL', 'netCDF', 'CURL',\nand 'SQLite' libraries. See Appel and Pebesma (2019)\n<doi:10.3390/data4030092> for further details.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.9636,
    "stars": 0
  },
  {
    "id": 16492,
    "package_name": "link2GI",
    "title": "Linking Geographic Information Systems, Remote Sensing and Other\nCommand Line Tools",
    "description": "Functions and tools for using open GIS and remote sensing\ncommand-line interfaces in a reproducible environment.",
    "version": "0.7-4",
    "maintainer": "Chris Reudenbach <reudenbach@uni-marburg.de>",
    "url": "https://github.com/r-spatial/link2GI/,\nhttps://r-spatial.github.io/link2GI/",
    "exports": [
      ["add2Path"],
      ["createFolders"],
      ["findGDAL"],
      ["findGRASS"],
      ["findOTB"],
      ["findSAGA"],
      ["gdal_build_args"],
      ["gdal_context"],
      ["gdal_context_from_link"],
      ["gdal_fingerprint"],
      ["gdal_help"],
      ["gdal_skeleton"],
      ["gvec2sf"],
      ["initProj"],
      ["linkGDAL"],
      ["linkGRASS"],
      ["linkOTB"],
      ["linkSAGA"],
      ["loadEnvi"],
      ["otb_args_spec"],
      ["otb_build_cmd"],
      ["otb_capabilities"],
      ["otb_optional"],
      ["otb_required"],
      ["otb_required_with_output"],
      ["otb_set_out"],
      ["otb_show"],
      ["parseOTBAlgorithms"],
      ["parseOTBFunction"],
      ["run_gdal"],
      ["runOTB"],
      ["runOTB_isolated"],
      ["saveEnvi"],
      ["searchGDALW"],
      ["searchGDALX"],
      ["searchGRASSW"],
      ["searchGRASSX"],
      ["searchOTBW"],
      ["searchOTBX"],
      ["searchSAGAW"],
      ["searchSAGAX"],
      ["setup_default"],
      ["setupProj"],
      ["sf2gvec"]
    ],
    "topics": [],
    "score": 8.8263,
    "stars": 28
  },
  {
    "id": 16858,
    "package_name": "malariaAtlas",
    "title": "An R Interface to Open-Access Malaria Data, Hosted by the\n'Malaria Atlas Project'",
    "description": "A suite of tools to allow you to download all publicly\navailable parasite rate survey points, mosquito occurrence\npoints and raster surfaces from the 'Malaria Atlas Project'\n<https://malariaatlas.org/> servers as well as utility\nfunctions for plotting the downloaded data.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.7798,
    "stars": 0
  },
  {
    "id": 6019,
    "package_name": "RSAGA",
    "title": "SAGA Geoprocessing and Terrain Analysis",
    "description": "Provides access to geocomputing and terrain analysis\nfunctions of the geographical information system (GIS) 'SAGA'\n(System for Automated Geoscientific Analyses) from within R by\nrunning the command line version of SAGA. This package\nfurthermore provides several R functions for handling ASCII\ngrids, including a flexible framework for applying local\nfunctions (including predict methods of fitted models) and\nfocal functions to multiple grids. SAGA GIS is available under\nGPL-2 / LGPL-2 licences from\n<https://sourceforge.net/projects/saga-gis/>.",
    "version": "1.4.2",
    "maintainer": "Alexander Brenning <alexander.brenning@uni-jena.de>",
    "url": "https://github.com/r-spatial/RSAGA",
    "exports": [
      ["centervalue"],
      ["create.variable.name"],
      ["default.file.extension"],
      ["focal.function"],
      ["gapply"],
      ["get.file.extension"],
      ["grid.predict"],
      ["grid.to.xyz"],
      ["internal.pick.from.ascii.grid"],
      ["local.function"],
      ["match.arg.ext"],
      ["multi.focal.function"],
      ["multi.local.function"],
      ["pick.from.ascii.grid"],
      ["pick.from.ascii.grids"],
      ["pick.from.points"],
      ["pick.from.saga.grid"],
      ["pick.from.shapefile"],
      ["read.ascii.grid"],
      ["read.ascii.grid.header"],
      ["read.Rd.grid"],
      ["read.sgrd"],
      ["relative.position"],
      ["relative.rank"],
      ["resid.median"],
      ["resid.minmedmax"],
      ["resid.quantile"],
      ["resid.quartiles"],
      ["rsaga.add.grid.values.to.points"],
      ["rsaga.aspect"],
      ["rsaga.close.gaps"],
      ["rsaga.close.one.cell.gaps"],
      ["rsaga.contour"],
      ["rsaga.copy.sgrd"],
      ["rsaga.curvature"],
      ["rsaga.env"],
      ["rsaga.esri.to.sgrd"],
      ["rsaga.esri.wrapper"],
      ["rsaga.fill.sinks"],
      ["rsaga.filter.gauss"],
      ["rsaga.filter.simple"],
      ["rsaga.geoprocessor"],
      ["rsaga.get.lib.modules"],
      ["rsaga.get.libraries"],
      ["rsaga.get.modules"],
      ["rsaga.get.modules.path"],
      ["rsaga.get.usage"],
      ["rsaga.get.version"],
      ["rsaga.grid.calculus"],
      ["rsaga.grid.to.points"],
      ["rsaga.grid.to.points.randomly"],
      ["rsaga.hillshade"],
      ["rsaga.html.help"],
      ["rsaga.import.gdal"],
      ["rsaga.insolation"],
      ["rsaga.intersect.polygons"],
      ["rsaga.inverse.distance"],
      ["rsaga.lib.prefix"],
      ["rsaga.linear.combination"],
      ["rsaga.local.morphometry"],
      ["rsaga.modified.quadratic.shephard"],
      ["rsaga.module.exists"],
      ["rsaga.nearest.neighbour"],
      ["rsaga.parallel.processing"],
      ["rsaga.pisr"],
      ["rsaga.pisr2"],
      ["rsaga.plan.curvature"],
      ["rsaga.profile.curvature"],
      ["rsaga.search.modules"],
      ["rsaga.set.env"],
      ["rsaga.sgrd.to.esri"],
      ["rsaga.sink.removal"],
      ["rsaga.sink.route"],
      ["rsaga.slope"],
      ["rsaga.slope.asp.curv"],
      ["rsaga.solar.radiation"],
      ["rsaga.target"],
      ["rsaga.topdown.processing"],
      ["rsaga.triangulation"],
      ["rsaga.union.polygons"],
      ["rsaga.wetness.index"],
      ["set.file.extension"],
      ["wind.shelter"],
      ["wind.shelter.prep"],
      ["write.ascii.grid"],
      ["write.ascii.grid.header"],
      ["write.Rd.grid"],
      ["write.sgrd"]
    ],
    "topics": [],
    "score": 8.5789,
    "stars": 25
  },
  {
    "id": 14988,
    "package_name": "hereR",
    "title": "'sf'-Based Interface to the 'HERE' REST APIs",
    "description": "Interface to the 'HERE' REST APIs\n<https://developer.here.com/develop/rest-apis>: (1) geocode and\nautosuggest addresses or reverse geocode POIs using the\n'Geocoder' API; (2) route directions, travel distance or time\nmatrices and isolines using the 'Routing', 'Matrix Routing' and\n'Isoline Routing' APIs; (3) request real-time traffic flow and\nincident information from the 'Traffic' API; (4) find request\npublic transport connections and nearby stations from the\n'Public Transit' API; (5) request intermodal routes using the\n'Intermodal Routing' API; (6) get weather forecasts, reports on\ncurrent weather conditions, astronomical information and alerts\nat a specific location from the 'Destination Weather' API.\nLocations, routes and isolines are returned as 'sf' objects.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.5082,
    "stars": 0
  },
  {
    "id": 10306,
    "package_name": "cleanNLP",
    "title": "A Tidy Data Model for Natural Language Processing",
    "description": "Provides a set of fast tools for converting a textual\ncorpus into a set of normalized tables. Users may make use of\nthe 'udpipe' back end with no external dependencies, or a\nPython back ends with 'spaCy' <https://spacy.io>. Exposed\nannotation tasks include tokenization, part of speech tagging,\nnamed entity recognition, and dependency parsing.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.4953,
    "stars": 0
  },
  {
    "id": 8664,
    "package_name": "arcgislayers",
    "title": "Harness ArcGIS Data Services",
    "description": "Enables users of 'ArcGIS Enterprise', 'ArcGIS Online', or\n'ArcGIS Platform' to read, write, publish, or manage vector and\nraster data via ArcGIS location services REST API endpoints\n<https://developers.arcgis.com/rest/>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.3379,
    "stars": 0
  },
  {
    "id": 18593,
    "package_name": "nominatimlite",
    "title": "Interface with 'Nominatim' API Service",
    "description": "Lite interface for getting data from 'OSM' service\n'Nominatim' <https://nominatim.org/release-docs/latest/>.\nExtract coordinates from addresses, find places near a set of\ncoordinates and return spatial objects on 'sf' format.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.3257,
    "stars": 0
  },
  {
    "id": 21501,
    "package_name": "rgeoda",
    "title": "R Library for Spatial Data Analysis",
    "description": "Provides spatial data analysis functionalities including\nExploratory Spatial Data Analysis, Spatial Cluster Detection\nand Clustering Analysis, Regionalization, etc. based on the C++\nsource code of 'GeoDa', which is an open-source software tool\nthat serves as an introduction to spatial data analysis. The\n'GeoDa' software and its documentation are available at\n<https://geodacenter.github.io>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 8.2971,
    "stars": 0
  },
  {
    "id": 20151,
    "package_name": "predicts",
    "title": "Spatial Prediction Tools",
    "description": "Methods for spatial predictive modeling, especially for\nspatial distribution models. This includes algorithms for model\nfitting and prediction, as well as methods for model\nevaluation.",
    "version": "0.1-17",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "https://rspatial.org/sdm/",
    "exports": [
      ["backgroundSample"],
      ["bcvars"],
      ["cm_evaluate"],
      ["divider"],
      ["envelope"],
      ["folds"],
      ["geometry"],
      ["hullModel"],
      ["MaxEnt"],
      ["mess"],
      ["pa_evaluate"],
      ["partialResponse"],
      ["partialResponse2"],
      ["plot"],
      ["predict"],
      ["pwd_sample"],
      ["pycnophy"],
      ["RMSE"],
      ["RMSE_null"],
      ["stripper"],
      ["threshold"],
      ["varImportance"]
    ],
    "topics": [],
    "score": 7.6207,
    "stars": 10
  },
  {
    "id": 23409,
    "package_name": "spNetwork",
    "title": "Spatial Analysis on Network",
    "description": "Perform spatial analysis on network. Implement several\nmethods for spatial analysis on network: Network Kernel Density\nestimation, building of spatial matrices based on network\ndistance ('listw' objects from 'spdep' package), K functions\nestimation for point pattern analysis on network, k nearest\nneighbours on network, reachable area calculation, and graph\ngeneration References: Okabe et al (2019)\n<doi:10.1080/13658810802475491>; Okabe et al (2012,\nISBN:978-0470770818);Baddeley et al (2015, ISBN:9781482210200).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.6062,
    "stars": 0
  },
  {
    "id": 22559,
    "package_name": "sedonadb",
    "title": "Bindings for Apache SedonaDB",
    "description": "Provides bindings for Apache SedonaDB, a lightweight query\nengine optimized for spatial workflows.",
    "version": "0.2.0.9000",
    "maintainer": "Dewey Dunnington <dewey@dunnington.ca>",
    "url": "",
    "exports": [
      ["as_sd_expr"],
      ["as_sedonadb_dataframe"],
      ["as_sedonadb_literal"],
      ["is_sd_expr"],
      ["sd_collect"],
      ["sd_compute"],
      ["sd_configure_proj"],
      ["sd_count"],
      ["sd_drop_view"],
      ["sd_expr_aggregate_function"],
      ["sd_expr_alias"],
      ["sd_expr_binary"],
      ["sd_expr_cast"],
      ["sd_expr_column"],
      ["sd_expr_factory"],
      ["sd_expr_literal"],
      ["sd_expr_negative"],
      ["sd_expr_scalar_function"],
      ["sd_preview"],
      ["sd_read_parquet"],
      ["sd_register_udf"],
      ["sd_sql"],
      ["sd_to_view"],
      ["sd_view"],
      ["sd_write_parquet"],
      ["sedonadb_adbc"]
    ],
    "topics": [
      ["c"],
      ["database"],
      ["geospatial"],
      ["hacktoberfest"],
      ["python"],
      ["rust"],
      ["spatial-analysis"],
      ["spatial-query"],
      ["spatial-sql"],
      ["cargo"],
      ["geos"]
    ],
    "score": 7.423,
    "stars": 379
  },
  {
    "id": 21524,
    "package_name": "rgugik",
    "title": "Search and Retrieve Spatial Data from 'GUGiK'",
    "description": "Automatic open data acquisition from resources of Polish\nHead Office of Geodesy and Cartography ('Główny Urząd Geodezji\ni Kartografii') (<https://www.gov.pl/web/gugik>). Available\ndatasets include various types of numeric, raster and vector\ndata, such as orthophotomaps, digital elevation models (digital\nterrain models, digital surface model, point clouds), state\nregister of borders, spatial databases, geometries of cadastral\nparcels, 3D models of buildings, and more. It is also possible\nto geocode addresses or objects using the geocodePL_get()\nfunction.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.3901,
    "stars": 0
  },
  {
    "id": 13009,
    "package_name": "fasterRaster",
    "title": "Faster Raster and Spatial Vector Processing Using 'GRASS'",
    "description": "Processing of large-in-memory/large-on disk rasters and\nspatial vectors using 'GRASS' <https://grass.osgeo.org/>. Most\nfunctions in the 'terra' package are recreated. Processing of\nmedium-sized and smaller spatial objects will nearly always be\nfaster using 'terra' or 'sf', but for\nlarge-in-memory/large-on-disk objects, 'fasterRaster' may be\nfaster. To use most of the functions, you must have the\nstand-alone version (not the 'OSGeoW4' installer version) of\n'GRASS' 8.0 or higher.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.3848,
    "stars": 0
  },
  {
    "id": 18954,
    "package_name": "openrouteservice",
    "title": "An 'openrouteservice' API Client",
    "description": "The client streamlines access to the services provided by\n<https://api.openrouteservice.org>. It allows you to painlessly\nquery for directions, isochrones, time-distance matrices,\ngeocoding, elevation, points of interest, and more.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.2587,
    "stars": 0
  },
  {
    "id": 13970,
    "package_name": "geoflow",
    "title": "Orchestrate Geospatial (Meta)Data Management Workflows and\nManage FAIR Services",
    "description": "An engine to facilitate the orchestration and execution of\nmetadata-driven data management workflows, in compliance with\n'FAIR' (Findable, Accessible, Interoperable and Reusable) data\nmanagement principles. By means of a pivot metadata model,\nrelying on the 'DublinCore' standard\n(<https://dublincore.org/>), a unique source of metadata can be\nused to operate multiple and inter-connected data management\nactions. Users can also customise their own workflows by\ncreating specific actions but the library comes with a set of\nnative actions targeting common geographic information and data\nmanagement, in particular actions oriented to the publication\non the web of metadata and data resources to provide standard\ndiscovery and access services. At first, default actions of the\nlibrary were meant to focus on providing turn-key actions for\ngeospatial (meta)data: 1) by creating manage geospatial\n(meta)data complying with 'ISO/TC211'\n(<https://committee.iso.org/home/tc211>) and 'OGC'\n(<https://www.ogc.org/standards/>) geographic information\nstandards (eg 19115/19119/19110/19139) and related best\npractices (eg. 'INSPIRE'); and 2) by facilitating extraction,\nreading and publishing of standard geospatial (meta)data within\nwidely used software that compound a Spatial Data\nInfrastructure ('SDI'), including spatial databases (eg.\n'PostGIS'), metadata catalogues (eg. 'GeoNetwork', 'CSW'\nservers), data servers (eg. 'GeoServer'). The library was then\nextended to actions for other domains: 1) biodiversity\n(meta)data standard management including handling of 'EML'\nmetadata, and their management with 'DataOne' servers, 2) in\nsitu sensors, remote sensing and model outputs (meta)data\nstandard management by handling part of 'CF' conventions,\n'NetCDF' data format and 'OPeNDAP' access protocol, and their\nmanagement with 'Thredds' servers, 3) generic / domain agnostic\n(meta)data standard managers ('DublinCore', 'DataCite'), to\nfacilitate the publication of data within (meta)data\nrepositories such as 'Zenodo' (<https://zenodo.org>) or\nDataVerse (<https://dataverse.org/>). The execution of several\nactions will then allow to cross-reference (meta)data resources\nin each action performed, offering a way to bind resources\nbetween each other (eg. reference 'Zenodo' 'DOI' in\n'GeoNetwork'/'GeoServer' metadata, or vice versa reference\n'GeoNetwork'/'GeoServer' links in 'Zenodo' or 'EML' metadata).\nThe use of standardized configuration files ('JSON' or 'YAML'\nformats) allow fully reproducible workflows to facilitate the\nwork of data and information managers.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.1174,
    "stars": 0
  },
  {
    "id": 1154,
    "package_name": "CatastRo",
    "title": "Interface to the API 'Sede Electronica Del Catastro'",
    "description": "Access public spatial data available under the 'INSPIRE'\ndirective. Tools for downloading references and addresses of\nproperties, as well as map images.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.0704,
    "stars": 0
  },
  {
    "id": 25398,
    "package_name": "usmapdata",
    "title": "Mapping Data for 'usmap' Package",
    "description": "Provides a container for data used by the 'usmap' package.\nThe data used by 'usmap' has been extracted into this package\nso that the file size of the 'usmap' package can be reduced\ngreatly. The data in this package will be updated roughly once\nper year as new map data files are provided by the US Census\nBureau.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.0324,
    "stars": 0
  },
  {
    "id": 14005,
    "package_name": "geosapi",
    "title": "GeoServer REST API R Interface",
    "description": "Provides an R interface to the GeoServer REST API,\nallowing to upload and publish data in a GeoServer\nweb-application and expose data to OGC Web-Services. The\npackage currently supports all CRUD (Create,Read,Update,Delete)\noperations on GeoServer workspaces, namespaces, datastores\n(stores of vector data), featuretypes, layers, styles, as well\nas vector data upload operations. For more information about\nthe GeoServer REST API, see\n<https://docs.geoserver.org/stable/en/user/rest/>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.0224,
    "stars": 0
  },
  {
    "id": 22165,
    "package_name": "sabre",
    "title": "Spatial Association Between Regionalizations",
    "description": "Calculates a degree of spatial association between\nregionalizations or categorical maps using the\ninformation-theoretical V-measure (Nowosad and Stepinski (2018)\n<doi:10.1080/13658816.2018.1511794>). It also offers an R\nimplementation of the MapCurve method (Hargrove et al. (2006)\n<doi:10.1007/s10109-006-0025-x>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 7.0035,
    "stars": 0
  },
  {
    "id": 10313,
    "package_name": "cleangeo",
    "title": "Cleaning Geometries from Spatial Objects",
    "description": "Provides a set of utility tools to inspect spatial\nobjects, facilitate handling and reporting of topology errors\nand geometry validity issue with sp objects. Finally, it\nprovides a geometry cleaner that will fix all geometry\nproblems, and eliminate (at least reduce) the likelihood of\nhaving issues when doing spatial data processing.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.8802,
    "stars": 0
  },
  {
    "id": 14585,
    "package_name": "gpkg",
    "title": "Utilities for the Open Geospatial Consortium 'GeoPackage' Format",
    "description": "Build Open Geospatial Consortium 'GeoPackage' files\n(<https://www.geopackage.org/>). 'GDAL' utilities for reading\nand writing spatial data are provided by the 'terra' package.\nAdditional 'GeoPackage' and 'SQLite' features for attributes\nand tabular data are implemented with the 'RSQLite' package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.7604,
    "stars": 0
  },
  {
    "id": 23509,
    "package_name": "spatialwidget",
    "title": "Formats Spatial Data for Use in Htmlwidgets",
    "description": "Many packages use 'htmlwidgets'\n<https://CRAN.R-project.org/package=htmlwidgets> for\ninteractive plotting of spatial data. This package provides\nfunctions for converting R objects, such as simple features,\ninto structures suitable for use in 'htmlwidgets' mapping\nlibraries.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.7276,
    "stars": 0
  },
  {
    "id": 10334,
    "package_name": "climateR",
    "title": "climateR",
    "description": "Find, subset, and retrive geospatial data by AOI.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.6837,
    "stars": 0
  },
  {
    "id": 16344,
    "package_name": "leafpm",
    "title": "Leaflet Map Plugin for Drawing and Editing",
    "description": "A collection of tools for interactive manipulation of\n(spatial) data layers on leaflet web maps. Tools include\nediting of existing layers, creation of new layers through\ndrawing of shapes (points, lines, polygons), deletion of shapes\nas well as cutting holes into existing shapes. Provides control\nover options to e.g. prevent self-intersection of polygons and\nlines or to enable/disable snapping to align shapes.",
    "version": "0.1.0",
    "maintainer": "Kenton Russell <kent.russell@timelyportfolio.com>",
    "url": "https://github.com/r-spatial/leafpm",
    "exports": [
      ["addPmToolbar"],
      ["pmCutOptions"],
      ["pmDependencies"],
      ["pmDrawOptions"],
      ["pmEditOptions"],
      ["pmToolbarOptions"],
      ["removePmToolbar"]
    ],
    "topics": [],
    "score": 6.6756,
    "stars": 23
  },
  {
    "id": 22794,
    "package_name": "shar",
    "title": "Species-Habitat Associations",
    "description": "Analyse species-habitat associations in R. Therefore,\ninformation about the location of the species (as a point\npattern) is needed together with environmental conditions (as a\ncategorical raster). To test for significance habitat\nassociations, one of the two components is randomized. Methods\nare mainly based on Plotkin et al. (2000)\n<doi:10.1006/jtbi.2000.2158> and Harms et al. (2001)\n<doi:10.1111/j.1365-2745.2001.00615.x>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.6725,
    "stars": 0
  },
  {
    "id": 6713,
    "package_name": "SESraster",
    "title": "Raster Randomization for Null Hypothesis Testing",
    "description": "Randomization of presence/absence species distribution\nraster data with or without including spatial structure for\ncalculating standardized effect sizes and testing null\nhypothesis. The randomization algorithms are based on classical\nalgorithms for matrices (Gotelli 2000, <doi:10.2307/177478>)\nimplemented for raster data.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.6635,
    "stars": 0
  },
  {
    "id": 22744,
    "package_name": "sfhotspot",
    "title": "Hot-Spot Analysis with Simple Features",
    "description": "Identify and understand clusters of points (typically\nrepresenting the locations of places or events) stored in\nsimple-features (SF) objects. This is useful for analysing, for\nexample, hot-spots of crime events. The package emphasises\nproducing results from point SF data in a single step using\nreasonable default values for all other arguments, to aid rapid\ndata analysis by users who are starting out. Functions\navailable include kernel density estimation (for details, see\nYip (2020) <doi:10.22224/gistbok/2020.1.12>), analysis of\nspatial association (Getis and Ord (1992)\n<doi:10.1111/j.1538-4632.1992.tb00261.x>) and hot-spot\nclassification (Chainey (2020) ISBN:158948584X).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.6191,
    "stars": 0
  },
  {
    "id": 10610,
    "package_name": "comat",
    "title": "Creates Co-Occurrence Matrices of Spatial Data",
    "description": "Builds co-occurrence matrices based on spatial raster\ndata. It includes creation of weighted co-occurrence matrices\n(wecoma) and integrated co-occurrence matrices (incoma; Vadivel\net al. (2007) <doi:10.1016/j.patrec.2007.01.004>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.6075,
    "stars": 0
  },
  {
    "id": 24616,
    "package_name": "tidyUSDA",
    "title": "A Minimal Tool Set for Gathering USDA Quick Stat Data for\nAnalysis and Visualization",
    "description": "Provides a consistent API to pull United States Department\nof Agriculture census and survey data from the National\nAgricultural Statistics Service (NASS) QuickStats service.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.5109,
    "stars": 0
  },
  {
    "id": 18462,
    "package_name": "nhdR",
    "title": "Tools for Working with the National Hydrography Dataset",
    "description": "Tools for working with the National Hydrography Dataset,\nwith functions for querying, downloading, and networking both\nthe NHD <https://www.usgs.gov/national-hydrography> and NHDPlus\n<https://www.epa.gov/waterdata/nhdplus-national-hydrography-dataset-plus>\ndatasets.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.5075,
    "stars": 0
  },
  {
    "id": 18323,
    "package_name": "ndi",
    "title": "Neighborhood Deprivation Indices",
    "description": "Computes various geospatial indices of socioeconomic\ndeprivation and disparity in the United States. Some indices\nare considered \"spatial\" because they consider the values of\nneighboring (i.e., adjacent) census geographies in their\ncomputation, while other indices are \"aspatial\" because they\nonly consider the value within each census geography. Two types\nof aspatial neighborhood deprivation indices (NDI) are\navailable: including: (1) based on Messer et al. (2006)\n<doi:10.1007/s11524-006-9094-x> and (2) based on Andrews et al.\n(2020) <doi:10.1080/17445647.2020.1750066> and Slotman et al.\n(2022) <doi:10.1016/j.dib.2022.108002> who use variables chosen\nby Roux and Mair (2010) <doi:10.1111/j.1749-6632.2009.05333.x>.\nBoth are a decomposition of multiple demographic\ncharacteristics from the U.S. Census Bureau American Community\nSurvey 5-year estimates (ACS-5; 2006-2010 onward). Using data\nfrom the ACS-5 (2005-2009 onward), the package can also compute\nindices of racial or ethnic residential segregation, including\nbut limited to those discussed in Massey & Denton (1988)\n<doi:10.1093/sf/67.2.281>, and additional indices of\nsocioeconomic disparity.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.4728,
    "stars": 0
  },
  {
    "id": 14064,
    "package_name": "gfwr",
    "title": "Access data from Global Fishing Watch APIs",
    "description": "This package connects to several Global Fishing Watch APIs\nto get vessel and events information in an R-friendly format.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.4651,
    "stars": 0
  },
  {
    "id": 4185,
    "package_name": "MTA",
    "title": "Multiscalar Territorial Analysis",
    "description": "Build multiscalar territorial analysis based on various\ncontexts.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.4014,
    "stars": 0
  },
  {
    "id": 13943,
    "package_name": "geoAr",
    "title": "Argentina's Spatial Data Toolbox",
    "description": "Collection of tools that facilitates data access and\nworkflow for spatial analysis of Argentina. Includes historical\ninformation from censuses, administrative limits at different\nlevels of aggregation, location of human settlements, among\nothers. Since it is expected that the majority of users will be\nSpanish-speaking, the documentation of the package prioritizes\nthis language, although an effort is made to also offer\nannotations in English.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.3687,
    "stars": 0
  },
  {
    "id": 14201,
    "package_name": "ggmapinset",
    "title": "Add Inset Panels to Maps",
    "description": "Helper to add insets based on geom_sf() from 'ggplot2'.\nThis package gives you a drop-in replacement for geom_sf() that\nsupports adding a zoomed inset map without having to create and\nembed a separate plot.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.3469,
    "stars": 0
  },
  {
    "id": 21497,
    "package_name": "rgeedim",
    "title": "Search, Composite, and Download 'Google Earth Engine' Imagery\nwith the 'Python' Module 'geedim'",
    "description": "Search, composite, and download 'Google Earth Engine'\nimagery with 'reticulate' bindings for the 'Python' module\n'geedim' by Dugal Harris. Read the 'geedim' documentation here:\n<https://geedim.readthedocs.io/>. Wrapper functions are\nprovided to make it more convenient to use 'geedim' to download\nimages larger than the 'Google Earth Engine' size limit\n<https://developers.google.com/earth-engine/apidocs/ee-image-getdownloadurl>.\nBy default the \"High Volume\" API endpoint\n<https://developers.google.com/earth-engine/cloud/highvolume>\nis used to download data and this URL can be customized during\ninitialization of the package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.3461,
    "stars": 0
  },
  {
    "id": 23399,
    "package_name": "spDataLarge",
    "title": "Large datasets for spatial analysis",
    "description": "Large datasets for spatial analysis. The data from this\npackage could be retrived using the spData package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.2362,
    "stars": 0
  },
  {
    "id": 5998,
    "package_name": "RPyGeo",
    "title": "ArcGIS Geoprocessing via Python",
    "description": "Provides access to ArcGIS geoprocessing tools by building\nan interface between R and the ArcPy Python side-package via\nthe reticulate package.",
    "version": "1.0.1",
    "maintainer": "Alexander Brenning <alexander.brenning@uni-jena.de>",
    "url": "https://github.com/r-spatial/RPyGeo",
    "exports": [
      ["%rpygeo_-%"],
      ["%rpygeo_*%"],
      ["%rpygeo_/%"],
      ["%rpygeo_+%"],
      ["rpygeo_build_env"],
      ["rpygeo_help"],
      ["rpygeo_load"],
      ["rpygeo_save"],
      ["rpygeo_search"]
    ],
    "topics": [],
    "score": 6.2095,
    "stars": 30
  },
  {
    "id": 13955,
    "package_name": "geocmeans",
    "title": "Implementing Methods for Spatial Fuzzy Unsupervised\nClassification",
    "description": "Provides functions to apply spatial fuzzy unsupervised\nclassification, visualize and interpret results. This method is\nwell suited when the user wants to analyze data with a fuzzy\nclustering algorithm and to account for the spatial dimension\nof the dataset. In addition, indexes for estimating the spatial\nconsistency and classification quality are proposed. The\nmethods were originally proposed in the field of brain imagery\n(seed Cai and al. 2007 <doi:10.1016/j.patcog.2006.07.011> and\nZaho and al. 2013 <doi:10.1016/j.dsp.2012.09.016>) and recently\napplied in geography (see Gelb and Apparicio\n<doi:10.4000/cybergeo.36414>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.1755,
    "stars": 0
  },
  {
    "id": 23498,
    "package_name": "spatialRF",
    "title": "Easy Spatial Modeling with Random Forest",
    "description": "Automatic generation and selection of spatial predictors\nfor Random Forest models fitted to spatially structured data.\nSpatial predictors are constructed from a distance matrix among\ntraining samples using Moran's Eigenvector Maps (MEMs; Dray,\nLegendre, and Peres-Neto 2006\n<DOI:10.1016/j.ecolmodel.2006.02.015>) or the RFsp approach\n(Hengl et al. <DOI:10.7717/peerj.5518>). These predictors are\nused alongside user-supplied explanatory variables in Random\nForest models. The package provides functions for model\nfitting, multicollinearity reduction, interaction\nidentification, hyperparameter tuning, evaluation via spatial\ncross-validation, and result visualization using partial\ndependence and interaction plots. Model fitting relies on the\n'ranger' package (Wright and Ziegler 2017\n<DOI:10.18637/jss.v077.i01>).",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.1135,
    "stars": 0
  },
  {
    "id": 20983,
    "package_name": "rasterpic",
    "title": "Convert Digital Images into 'SpatRaster' Objects",
    "description": "Generate 'SpatRaster' objects, as defined by the 'terra'\npackage, from digital images, using a specified spatial object\nas a geographical reference.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.1052,
    "stars": 0
  },
  {
    "id": 4873,
    "package_name": "OpenLand",
    "title": "Quantitative Analysis and Visualization of LUCC",
    "description": "Tools for the analysis of land use and cover (LUC) time\nseries. It includes support for loading spatiotemporal raster\ndata and synthesized spatial plotting. Several LUC change\n(LUCC) metrics in regular or irregular time intervals can be\nextracted and visualized through one- and multistep sankey and\nchord diagrams. A complete intensity analysis according to\nAldwaik and Pontius (2012)\n<doi:10.1016/j.landurbplan.2012.02.010> is implemented,\nincluding tools for the generation of standardized multilevel\noutput graphics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.1009,
    "stars": 0
  },
  {
    "id": 732,
    "package_name": "BioTIMEr",
    "title": "Tools to Use and Explore the 'BioTIME' Database",
    "description": "The 'BioTIME' database was first published in 2018 and\ninspired ideas, questions, project and research article. To\nmake it even more accessible, an R package was created. The\n'BioTIMEr' package provides tools designed to interact with the\n'BioTIME' database. The functions provided include the\n'BioTIME' recommended methods for preparing (gridding and\nrarefaction) time series data, a selection of standard\nbiodiversity metrics (including species richness, numerical\nabundance and exponential Shannon) alongside examples on how to\ndisplay change over time. It also includes a sample subset of\nboth the query and meta data, the full versions of which are\nfreely available on the 'BioTIME' website\n<https://biotime.st-andrews.ac.uk/home.php>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.0792,
    "stars": 0
  },
  {
    "id": 24734,
    "package_name": "tilegramsR",
    "title": "R Spatial Data for Tilegrams",
    "description": "R spatial objects for Tilegrams. Tilegrams are tiled maps\nwhere the region size is proportional to the certain\ncharacteristics of the dataset.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 6.0382,
    "stars": 0
  },
  {
    "id": 19783,
    "package_name": "plainview",
    "title": "Plot Raster Images Interactively on a Plain HTML Canvas",
    "description": "Provides methods for plotting potentially large (raster)\nimages interactively on a plain HTML canvas. In contrast to\npackage 'mapview' data are plotted without background map, but\ndata can be projected to any spatial coordinate reference\nsystem. Supports plotting of classes 'RasterLayer',\n'RasterStack', 'RasterBrick' (from package 'raster') as well as\n'png' files located on disk. Interactivity includes zooming,\npanning, and mouse location information. In case of multi-layer\n'RasterStacks' or 'RasterBricks', RGB image plots are created\n(similar to 'raster::plotRGB' - but interactive).",
    "version": "0.2.2",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://r-spatial.github.io/plainview/,\nhttps://github.com/r-spatial/plainview",
    "exports": [
      ["plainview"],
      ["plainView"],
      ["plainViewOutput"],
      ["renderPlainView"]
    ],
    "topics": [],
    "score": 5.9959,
    "stars": 13
  },
  {
    "id": 6715,
    "package_name": "SEraster",
    "title": "Rasterization Preprocessing Framework for Scalable Spatial Omics\nData Analysis",
    "description": "SEraster is a rasterization preprocessing framework that\naggregates cellular information into spatial pixels to reduce\nresource requirements for spatial omics data analysis. SEraster\nreduces the number of spatial points in spatial omics datasets\nfor downstream analysis through a process of rasterization\nwhere single cells’ gene expression or cell-type labels are\naggregated into equally sized pixels based on a user-defined\nresolution. SEraster is built on an R/Bioconductor S4 class\ncalled SpatialExperiment. SEraster can be incorporated with\nother packages to conduct downstream analyses for spatial omics\ndatasets, such as detecting spatially variable genes.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.9948,
    "stars": 0
  },
  {
    "id": 26155,
    "package_name": "zonal",
    "title": "Performant zonal statistics over flexible units",
    "description": "Given gridded and vector based input, compute summary\nstatistics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.903,
    "stars": 0
  },
  {
    "id": 22400,
    "package_name": "scatterbar",
    "title": "Scattered Stacked Bar Chart Plots",
    "description": "Provides a powerful and flexible tool for visualizing\nproportional data across spatially resolved contexts. By\ncombining the concepts of scatter plots and stacked bar charts,\n`scatterbar` allows users to create scattered bar chart plots,\nwhich effectively display the proportions of different\ncategories at each (x, y) location. This visualization is\nparticularly useful for applications where understanding the\ndistribution of categories across spatial coordinates is\nessential. This package features automatic determination of\noptimal scaling factors based on data, customizable scaling and\npadding options for both x and y axes, flexibility to specify\ncustom colors for each category, options to customize the\nlegend title, and integration with `ggplot2` for robust and\nhigh-quality visualizations. For more details, see Velazquez et\nal. (2024) <doi:10.1101/2024.08.14.606810>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.8407,
    "stars": 0
  },
  {
    "id": 9185,
    "package_name": "belg",
    "title": "Boltzmann Entropy of a Landscape Gradient",
    "description": "Calculates the Boltzmann entropy of a landscape gradient.\nThis package uses the analytical method created by Gao, P.,\nZhang, H. and Li, Z., 2018 (<doi:10.1111/tgis.12315>) and by\nGao, P. and Li, Z., 2019 (<doi:10.1007/s10980-019-00854-3>). It\nalso extend the original ideas by allowing calculations on data\nwith missing values.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.7973,
    "stars": 0
  },
  {
    "id": 13306,
    "package_name": "flexpolyline",
    "title": "Flexible Polyline Encoding",
    "description": "Binding to the C++ implementation of the flexible polyline\nencoding by HERE\n<https://github.com/heremaps/flexible-polyline>. The flexible\npolyline encoding is a lossy compressed representation of a\nlist of coordinate pairs or coordinate triples. The encoding is\nachieved by: (1) Reducing the decimal digits of each value; (2)\nencoding only the offset from the previous point; (3) using\nvariable length for each coordinate delta; and (4) using 64\nURL-safe characters to display the result.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.7536,
    "stars": 0
  },
  {
    "id": 8661,
    "package_name": "arcgeocoder",
    "title": "Geocoding with the 'ArcGIS' REST API Service",
    "description": "Lite interface for finding locations of addresses or\nbusinesses around the world using the 'ArcGIS' REST API service\n<https://developers.arcgis.com/rest/geocode/api-reference/overview-world-geocoding-service.htm>.\nAddress text can be converted to location candidates and a\nlocation can be converted into an address. No API key required.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.5185,
    "stars": 0
  },
  {
    "id": 20959,
    "package_name": "rapr",
    "title": "Interface to 'Rangeland Analysis Platform' (RAP) Products",
    "description": "Provides access to 'Rangeland Analysis Platform' (RAP)\nproducts <https://rangelands.app/products> for arbitrary\nextents via 'GDAL' virtual file system.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.4472,
    "stars": 0
  },
  {
    "id": 23204,
    "package_name": "slideview",
    "title": "Compare Raster Images Side by Side with a Slider",
    "description": "Create a side-by-side view of raster(image)s with an\ninteractive slider to switch between regions of the images.\nThis can be especially useful for image comparison of the same\nregion at different time stamps.",
    "version": "0.2.1",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "https://r-spatial.github.io/slideview/,\nhttps://github.com/r-spatial/slideview",
    "exports": [
      ["slideview"],
      ["slideView"]
    ],
    "topics": [],
    "score": 5.2175,
    "stars": 25
  },
  {
    "id": 104,
    "package_name": "AOI",
    "title": "Areas of Interest",
    "description": "A consistent tool kit for forward and reverse geocoding\nand defining boundaries for spatial analysis.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.214,
    "stars": 0
  },
  {
    "id": 20855,
    "package_name": "raceland",
    "title": "Pattern-Based Zoneless Method for Analysis and Visualization of\nRacial Topography",
    "description": "Implements a computational framework for a pattern-based,\nzoneless analysis, and visualization of (ethno)racial\ntopography (Dmowska, Stepinski, and Nowosad (2020)\n<doi:10.1016/j.apgeog.2020.102239>). It is a reimagined\napproach for analyzing residential segregation and racial\ndiversity based on the concept of 'landscape’ used in the\ndomain of landscape ecology.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.2095,
    "stars": 0
  },
  {
    "id": 12437,
    "package_name": "emodnet.wcs",
    "title": "Access EMODnet Web Coverage Service data through R",
    "description": "Access and interrogate EMODnet Web Coverage Service data\nthrough R.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.1072,
    "stars": 0
  },
  {
    "id": 14099,
    "package_name": "ggautomap",
    "title": "Create Maps from a Column of Place Names",
    "description": "Mapping tools that convert place names to coordinates on\nthe fly. These 'ggplot2' extensions make maps from a data frame\nwhere one of the columns contains place names, without having\nto directly work with the underlying geospatial data and tools.\nThe corresponding map data must be registered with\n'cartographer' either by the user or by another package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.0607,
    "stars": 0
  },
  {
    "id": 14008,
    "package_name": "geospark",
    "title": "Bring Local Sf to Spark",
    "description": "R binds 'GeoSpark' <http://geospark.datasyslab.org/>\nextending 'sparklyr' <https://spark.rstudio.com/> R package to\nmake distributed 'geocomputing' easier. Sf is a package that\nprovides [simple features]\n<https://en.wikipedia.org/wiki/Simple_Features> access for R\nand which is a leading 'geospatial' data processing tool.\n'Geospark' R package bring the same simple features access like\nsf but running on Spark distributed system.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.0569,
    "stars": 0
  },
  {
    "id": 20622,
    "package_name": "qualmap",
    "title": "Opinionated Approach for Digitizing Semi-Structured Qualitative\nGIS Data",
    "description": "Provides a set of functions for taking qualitative GIS\ndata, hand drawn on a map, and converting it to a simple\nfeatures object. These tools are focused on data that are drawn\non a map that contains some type of polygon features. For each\narea identified on the map, the id numbers of these polygons\ncan be entered as vectors and transformed using qualmap.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.0212,
    "stars": 0
  },
  {
    "id": 18783,
    "package_name": "oceanexplorer",
    "title": "Explore Our Planet's Oceans with NOAA",
    "description": "Provides tools for easy exploration of the world ocean\natlas of the US agency National Oceanic and Atmospheric\nAdministration (NOAA). It includes functions to extract NetCDF\ndata from the repository and code to visualize several physical\nand chemical parameters of the ocean. A Shiny app further\nallows interactive exploration of the data. The methods for\ndata collecting and quality checks are described in several\npapers, which can be found here:\n<https://www.ncei.noaa.gov/products/world-ocean-atlas>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 5.0149,
    "stars": 0
  },
  {
    "id": 25488,
    "package_name": "vaster",
    "title": "Tools for Raster Grid Logic",
    "description": "Provides raster grid logic, operations that describe a\ndiscretized rectangular domain and don't require access to\nmaterialized data. Grids are arrays with dimension and extent,\nand many operations are functions of just the dimension\n'nrows', 'ncols' or a combination of the dimension and the\nextent 'xmin', 'xmax', 'ymin', 'ymax'. Here we provide direct\naccess to this logic without need for connection to any\nmaterialized data or formats. Grid logic includes functions\nthat relate the cell index to row and column, or row and column\nto cell index, row, column or cell index to position.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.9133,
    "stars": 0
  },
  {
    "id": 19074,
    "package_name": "osbng",
    "title": "Geospatial Grid Indexing with the British National Grid",
    "description": "Offers a streamlined programmatic interface to Ordnance\nSurvey's British National Grid (BNG) index system, enabling\nefficient spatial indexing and analysis based on grid\nreferences. It supports a range of geospatial applications,\nincluding statistical aggregation, data visualisation, and\ninteroperability across datasets. Designed for developers and\nanalysts working with geospatial data in Great Britain, 'osbng'\nsimplifies integration with geospatial workflows and provides\nintuitive tools for exploring the structure and logic of the\nBNG system.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.9031,
    "stars": 0
  },
  {
    "id": 14368,
    "package_name": "gisr",
    "title": "Geospatial Analytics Utility functions",
    "description": "R Spatial functions for HIV/AIDS related Geospatial\nAnalytics.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.8921,
    "stars": 0
  },
  {
    "id": 16225,
    "package_name": "lakemorpho",
    "title": "Lake Morphometry Metrics",
    "description": "Lake morphometry metrics are used by limnologists to\nunderstand, among other things, the ecological processes in a\nlake. Traditionally, these metrics are calculated by hand, with\nplanimeters, and increasingly with commercial GIS products. All\nof these methods work; however, they are either outdated,\ndifficult to reproduce, or require expensive licenses to use.\nThe 'lakemorpho' package provides the tools to calculate a\ntypical suite of these metrics from an input elevation model\nand lake polygon. The metrics currently supported are: fetch,\nmajor axis, minor axis, major/minor axis ratio, maximum length,\nmaximum width, mean width, maximum depth, mean depth, shoreline\ndevelopment, shoreline length, surface area, and volume.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.8811,
    "stars": 0
  },
  {
    "id": 14666,
    "package_name": "greenSD",
    "title": "Access and Analyze Global GreenSpace Spatial Data",
    "description": "Access and analyze multi-band greenspace seasonality data\ncubes (available for 1,028 major global cities), global\nNormalized Difference Vegetation Index / land cover data from\nthe European Space Agency WorldCover 10m Dataset, and\nSentinel-2-l2a images. Users can download data using bounding\nboxes, city names, and filter by year or seasonal time window.\nThe package also supports calculating human exposure to\ngreenspace using a population-weighted greenspace exposure\nmodel introduced by Chen et al. (2022)\n<doi:10.1038/s41467-022-32258-4> based on Global Human\nSettlement Layer population data, and calculating a set of\ngreenspace morphology metrics at patch and landscape levels.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.8451,
    "stars": 0
  },
  {
    "id": 10979,
    "package_name": "cppSim",
    "title": "Fast and Memory Efficient Spatial Interaction Models",
    "description": "Building on top of the 'RcppArmadillo' linear algebra\nfunctionalities to do fast spatial interaction models in the\ncontext of urban analytics, geography, transport modelling. It\nuses the Newton root search algorithm to determine the optimal\ncost exponent and can run country level models with thousands\nof origins and destinations. It aims at implementing an easy\napproach based on matrices, that can originate from various\nrouting and processing steps earlier in an workflow. Currently,\nthe simplest form of production, destination and doubly\nconstrained models are implemented. Schlosser et al. (2023)\n<doi:10.48550/arXiv.2309.02112>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.8388,
    "stars": 0
  },
  {
    "id": 12496,
    "package_name": "envi",
    "title": "Environmental Interpolation using Spatial Kernel Density\nEstimation",
    "description": "Estimates an ecological niche using occurrence data,\ncovariates, and kernel density-based estimation methods. For a\nsingle species with presence and absence data, the 'envi'\npackage uses the spatial relative risk function that is\nestimated using the 'sparr' package. Details about the 'sparr'\npackage methods can be found in the tutorial: Davies et al.\n(2018) <doi:10.1002/sim.7577>. Details about kernel density\nestimation can be found in J. F. Bithell (1990)\n<doi:10.1002/sim.4780090616>. More information about relative\nrisk functions using kernel density estimation can be found in\nJ. F. Bithell (1991) <doi:10.1002/sim.4780101112>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.8195,
    "stars": 0
  },
  {
    "id": 13610,
    "package_name": "funcMapper",
    "title": "Map User-Created Functions",
    "description": "Create an interactive function map by analyzing a\nspecified R script. It uses the find_dependencies() function\nfrom the 'functiondepends' package to recursively trace all\nuser-defined function dependencies.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.7782,
    "stars": 0
  },
  {
    "id": 911,
    "package_name": "CDSE",
    "title": "'Copernicus Data Space Ecosystem' API Wrapper",
    "description": "Provides interface to the 'Copernicus Data Space\nEcosystem' API <https://dataspace.copernicus.eu/analyse/apis>,\nmainly for searching the catalog of available data from\nCopernicus Sentinel missions and obtaining the images for just\nthe area of interest based on selected spectral bands. The\npackage uses the 'Sentinel Hub' REST API interface\n<https://dataspace.copernicus.eu/analyse/apis/sentinel-hub>\nthat provides access to various satellite imagery archives. It\nallows you to access raw satellite data, rendered images,\nstatistical analysis, and other features. This package is in no\nway officially related to or endorsed by Copernicus.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.7559,
    "stars": 0
  },
  {
    "id": 9494,
    "package_name": "blvim",
    "title": "Boltzmann–Lotka–Volterra Interaction Model",
    "description": "Estimates Boltzmann–Lotka–Volterra (BLV) interaction model\nefficiently. Enables programmatic and graphical exploration of\nthe solution space of BLV models when parameters are varied.\nSee Wilson, A. (2008) <dx.doi.org/10.1098/rsif.2007.1288>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.7482,
    "stars": 0
  },
  {
    "id": 5541,
    "package_name": "QRAGadget",
    "title": "A 'Shiny' Gadget for Interactive 'QRA' Visualizations",
    "description": "Upload raster data and easily create interactive\nquantitative risk analysis 'QRA' visualizations. Select from\nnumerous color palettes, base-maps, and different\nconfigurations.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.6021,
    "stars": 0
  },
  {
    "id": 8452,
    "package_name": "aldvmm",
    "title": "Adjusted Limited Dependent Variable Mixture Models",
    "description": "The goal of the package 'aldvmm' is to fit adjusted\nlimited dependent variable mixture models of health state\nutilities. Adjusted limited dependent variable mixture models\nare finite mixtures of normal distributions with an\naccumulation of density mass at the limits, and a gap between\n100% quality of life and the next smaller utility value. The\npackage 'aldvmm' uses the likelihood and expected value\nfunctions proposed by Hernandez Alava and Wailoo (2015)\n<doi:10.1177/1536867X1501500307> using normal component\ndistributions and a multinomial logit model of probabilities of\ncomponent membership.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.6021,
    "stars": 0
  },
  {
    "id": 16755,
    "package_name": "luna",
    "title": "Tools for Satellite Remote Sensing (Earth Observation) Data\nProcessing",
    "description": "Tools for acquiring and (pre-) processing satellite remote\nsensing data. Including for downloading data from NASA such as\nLANDSAT and MODIS.",
    "version": "0.3-7",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "",
    "exports": [
      ["fillVI"],
      ["filterVI"],
      ["getAVHRR"],
      ["getLandsat"],
      ["getNASA"],
      ["getProducts"],
      ["mesma"],
      ["modis_mask"],
      ["modisDate"],
      ["modisExtent"],
      ["panSharpen"],
      ["productInfo"]
    ],
    "topics": [
      ["openblas"],
      ["cpp"]
    ],
    "score": 4.5306,
    "stars": 39
  },
  {
    "id": 25841,
    "package_name": "whatarelief",
    "title": "Get topography elevation and online imagery data",
    "description": "Obtain elevation data, topography relief for any region on\nthe Earth. Topography and bathymetry data is supported by\ndefault. Sensible defaults exist for usage, with a matrix of\nentire planet topography(and bathymetry) returned. The\ngeographic extent can be modified (from whole-planet) to a\nsimple region in longitude/latitude by 'xmin,xmax,ymin,ymax'\nrange, or by specifying a grid exactly with extent, dimension,\nprojection in generic or spatial formats ('terra' or 'raster').\nOnline sources for data are used, 'GEBCO' General Bathymetric\nChart of the Oceans (GEBCO) as a background (to ~500m\nresolution), and Copernicus GLO-30 Digital Elevation Model for\nhigher resolution (to ~30m resolution). Custom source/s of\ntopography may be input to override defaults, links to file/s\nor URLs as required.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.5205,
    "stars": 0
  },
  {
    "id": 19130,
    "package_name": "overturemapsr",
    "title": "Download Overture Maps Data in R",
    "description": "Overture Maps offers free and open geospatial map data\nsourced from various providers and standardized to a common\nschema. This tool allows you to download Overture Maps data for\na specific region of interest and convert it to several\ndifferent file formats. For more information, visit\n<https://overturemaps.org/download/>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.4594,
    "stars": 0
  },
  {
    "id": 9919,
    "package_name": "cat2cat",
    "title": "Handling an Inconsistently Coded Categorical Variable in a\nLongitudinal Dataset",
    "description": "Unifying an inconsistently coded categorical variable\nbetween two different time points in accordance with a mapping\ntable. The main rule is to replicate the observation if it\ncould be assigned to a few categories. Then using frequencies\nor statistical methods to approximate the probabilities of\nbeing assigned to each of them. This procedure was invented and\nimplemented in the paper by Nasinski, Majchrowska, and\nBroniatowska (2020) <doi:10.24425/cejeme.2020.134747>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.3979,
    "stars": 0
  },
  {
    "id": 16520,
    "package_name": "listcompr",
    "title": "List Comprehension for R",
    "description": "Syntactic shortcuts for creating synthetic lists, vectors,\ndata frames, and matrices using list comprehension.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.3979,
    "stars": 0
  },
  {
    "id": 23402,
    "package_name": "spEcula",
    "title": "Spatial Prediction Methods In R",
    "description": "Advanced spatial prediction methods based on various\nspatial relationships.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.3424,
    "stars": 0
  },
  {
    "id": 13777,
    "package_name": "gateR",
    "title": "Flow/Mass Cytometry Gating via Spatial Kernel Density Estimation",
    "description": "Estimates statistically significant marker combination\nvalues within which one immunologically distinctive group\n(i.e., disease case) is more associated than another group\n(i.e., healthy control), successively, using various\ncombinations (i.e., \"gates\") of markers to examine features of\ncells that may be different between groups. For a two-group\ncomparison, the 'gateR' package uses the spatial relative risk\nfunction estimated using the 'sparr' package. Details about the\n'sparr' package methods can be found in the tutorial: Davies et\nal. (2018) <doi:10.1002/sim.7577>. Details about kernel density\nestimation can be found in J. F. Bithell (1990)\n<doi:10.1002/sim.4780090616>. More information about relative\nrisk functions using kernel density estimation can be found in\nJ. F. Bithell (1991) <doi:10.1002/sim.4780101112>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.301,
    "stars": 0
  },
  {
    "id": 24686,
    "package_name": "tidyrgeoda",
    "title": "A tidy interface for rgeoda",
    "description": "An interface for 'rgeoda' to integrate with 'sf' objects\nand the 'tidyverse'.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.2304,
    "stars": 0
  },
  {
    "id": 22393,
    "package_name": "scapesClassification",
    "title": "User-Defined Classification of Raster Surfaces",
    "description": "Series of algorithms to translate users' mental models of\nseascapes, landscapes and, more generally, of geographic\nfeatures into computer representations (classifications).\nSpaces and geographic objects are classified with user-defined\nrules taking into account spatial data as well as spatial\nrelationships among different classes and objects.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.2175,
    "stars": 0
  },
  {
    "id": 23519,
    "package_name": "spatstat.local",
    "title": "Extension to 'spatstat' for Local Composite Likelihood",
    "description": "Extension to the 'spatstat' package, enabling the user to\nfit point process models to point pattern data by local\ncomposite likelihood ('geographically weighted regression').",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4.0607,
    "stars": 0
  },
  {
    "id": 2751,
    "package_name": "GREENeR",
    "title": "Geospatial Regression Equation for European Nutrient Losses\n(GREEN)",
    "description": "Tools and methods to apply the model Geospatial Regression\nEquation for European Nutrient losses (GREEN); Grizzetti et al.\n(2005) <doi:10.1016/j.jhydrol.2004.07.036>; Grizzetti et al.\n(2008); Grizzetti et al. (2012)\n<doi:10.1111/j.1365-2486.2011.02576.x>; Grizzetti et al. (2021)\n<doi:10.1016/j.gloenvcha.2021.102281>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4,
    "stars": 0
  },
  {
    "id": 18886,
    "package_name": "onemapsgapi",
    "title": "R Wrapper for the 'OneMap.Sg API'",
    "description": "An R wrapper for the 'OneMap.Sg' API\n<https://www.onemap.gov.sg/docs/>. Functions help users query\ndata from the API and return raw JSON data in \"tidy\" formats.\nSupport is also available for users to retrieve data from\nmultiple API calls and integrate results into single\ndataframes, without needing to clean and merge the data\nthemselves. This package is best suited for users who would\nlike to perform analyses with Singapore's spatial data without\nhaving to perform excessive data cleaning.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 4,
    "stars": 0
  },
  {
    "id": 13841,
    "package_name": "gecko",
    "title": "Geographical Ecology and Conservation Knowledge Online",
    "description": "Includes a collection of geographical analysis functions\naimed primarily at ecology and conservation science studies,\nallowing processing of both point and raster data. Now\nintegrates SPECTRE\n(<https://biodiversityresearch.org/spectre/>), a dataset of\nglobal geospatial threat data, developed by the authors.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.8751,
    "stars": 0
  },
  {
    "id": 22728,
    "package_name": "sf2",
    "title": "Spatial Analysis tools",
    "description": "sf2 extends the function of sf package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.8293,
    "stars": 0
  },
  {
    "id": 6098,
    "package_name": "RWmisc",
    "title": "Miscellaneous Spatial Functions",
    "description": "Contains convenience functions for working with spatial\ndata across multiple UTM zones, raster-vector operations common\nin the analysis of conflict data, and converting degrees,\nminutes, and seconds latitude and longitude coordinates to\ndecimal degrees.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.7782,
    "stars": 0
  },
  {
    "id": 13964,
    "package_name": "geodk",
    "title": "Access Danish Geospatial Data",
    "description": "This package provides access to all geospatial data\nprovided by the danish agency called Klimadatastyrelsen. Under\nthe hood it wraps the `{dawaR}` and `{dkdata}` packages which\nprovide access to the agency APIs.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.7324,
    "stars": 0
  },
  {
    "id": 20168,
    "package_name": "prepr",
    "title": "Automatic Repair of Spatial Polygons",
    "description": "Automatically repair broken spatial polygons using\nconstrained triangulation. The computational methodology is\nderived from Ledoux et al. (2014)\n<doi:10.1016/j.cageo.2014.01.009>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.7076,
    "stars": 0
  },
  {
    "id": 15020,
    "package_name": "hfsubsetR",
    "title": "Hydrofabric Subsetter",
    "description": "Subset Hydrofabric Data in R.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.7024,
    "stars": 0
  },
  {
    "id": 3246,
    "package_name": "ICvectorfields",
    "title": "Vector Fields from Spatial Time Series of Population Abundance",
    "description": "Functions for converting time series of spatial abundance\nor density data in raster format to vector fields of population\nmovement using the digital image correlation technique. More\nspecifically, the functions in the package compute\ncross-covariance using discrete fast Fourier transforms for\ncomputational efficiency. Vectors in vector fields point in the\ndirection of highest two dimensional cross-covariance. The\npackage has a novel implementation of the digital image\ncorrelation algorithm that is designed to detect persistent\ndirectional movement when image time series extend beyond a\nsequence of two raster images.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.699,
    "stars": 0
  },
  {
    "id": 20199,
    "package_name": "pricelevels",
    "title": "Spatial Price Level Comparisons",
    "description": "Price comparisons within or between countries provide an\noverall measure of the relative difference in prices, often\ndenoted as price levels. This package provides index number\nmethods for such price comparisons (e.g., The World Bank, 2011,\n<doi:10.1596/978-0-8213-9728-2>). Moreover, it contains\nfunctions for sampling and characterizing price data.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.699,
    "stars": 0
  },
  {
    "id": 20359,
    "package_name": "pseudohouseholds",
    "title": "Generate Pseudohouseholds on Road Networks in Regions",
    "description": "Given an arbitrary set of spatial regions and road\nnetworks, generate a set of representative points, or\npseudohouseholds, that can be used for travel burden analysis.\nParallel processing is supported.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.699,
    "stars": 0
  },
  {
    "id": 23978,
    "package_name": "streetscape",
    "title": "Collect And Investigate Street Views For Urban Science",
    "description": "A collection of functions to search and download street\nview imagery ('Mapilary'\n<https://www.mapillary.com/developer/api-documentation>) and to\nextract, quantify, and visualize visual features. Moreover,\nthere are functions provided to generate Qualtrics survey in\nTXT format using the collection of street views for various\nresearch purposes.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.699,
    "stars": 0
  },
  {
    "id": 20121,
    "package_name": "pragr",
    "title": "Tools for visualising Prague data",
    "description": "A bridge between Prague geodata and R to enable\nvisualisation. Currently, it provides access to raster map\nlayers provided by the Prague geoportal and several utilities.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.6021,
    "stars": 0
  },
  {
    "id": 21990,
    "package_name": "rspatial",
    "title": "rspatial.org data",
    "description": "Data to support the examples on rspatial.org",
    "version": "1.0-0",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "",
    "exports": [
      ["sp_data"],
      ["sp_download"]
    ],
    "topics": [],
    "score": 3.5611,
    "stars": 7
  },
  {
    "id": 13966,
    "package_name": "geodrawr",
    "title": "Making Geospatial Objects",
    "description": "Draw geospatial objects by clicks on the map. This\npackages can help data analyst who want to check their own\ngeospatial hypothesis but has no ready-made geospatial objects.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.4771,
    "stars": 0
  },
  {
    "id": 19367,
    "package_name": "pavement",
    "title": "Analyzing Spatial Events on Roadways",
    "description": "Pavement is a package designed to analyze spatial events\noccurring on roadways. It provides a comprehensive toolkit for\nworking with spatial data, empowering users to understand\npatterns and trends in road-related phenomena.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.4771,
    "stars": 0
  },
  {
    "id": 25450,
    "package_name": "valuemap",
    "title": "Making Choropleth Map",
    "description": "You can easily visualize your 'sf' polygons or data.frame\nwith h3 address. While 'leaflet' package is too raw for data\nanalysis, this package can save data analysts' efforts & time\nwith pre-set visualize options.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.1761,
    "stars": 0
  },
  {
    "id": 1253,
    "package_name": "CityShadeMapper",
    "title": "Generate High Resolution Shade Maps and Shaded Routes from\nRemote Sensing Data",
    "description": "CityShadeMapper can generate high resolution shade maps\n(e.g. for every square meter and every hour of the year) for\nany city or town from open remote sensing (LiDAR) data.\nCityShadeMapper can also return optimal routes within any two\npoints in the city that maximise the amount of shade for\npedestrians.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3.1139,
    "stars": 0
  },
  {
    "id": 10784,
    "package_name": "controlledburn",
    "title": "Rasterize Index",
    "description": "Rasterize without materializing any pixel values.\nRasterization of polygons starts with classifying pixels by\npolygon, and in terms of scanline algorithms this is natively\nstored very efficiently as an index of start and stops of edges\nby scanline. We produce these intermediate structures, so they\ncan be used as an efficient format of polygon rasterization, or\nfor the complement of this, data extraction from materialized\nrasters. This package was derived from 'fasterize', removing\nArmadillo and the raster package.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3,
    "stars": 0
  },
  {
    "id": 12813,
    "package_name": "extRatum",
    "title": "Summary Statistics for Geospatial Features",
    "description": "Provides summary statistics of local geospatial features\nwithin a given geographic area. It does so by calculating the\narea covered by a target geospatial feature (i.e. buildings,\nparks, lakes, etc.). The geospatial features can be of any type\nof geospatial data, including point, polygon or line data.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3,
    "stars": 0
  },
  {
    "id": 18714,
    "package_name": "nswgeo",
    "title": "Geospatial Data and Maps for New South Wales, Australia",
    "description": "Geospatial data for creating maps of New South Wales\n(NSW), Australia, and some helpers to work with common problems\nlike normalising postcodes. Registers its data with\n'cartographer'.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 3,
    "stars": 0
  },
  {
    "id": 20607,
    "package_name": "quad",
    "title": "Intermediate Forms of Raster Grids",
    "description": "Raster grids and quads as first class types with helpers.\nProvides a low level API for generating mesh index and vertices\nfrom the simplest abstraction of raster grid, input dimension\nand (optionally) extent to generate components of meshes for\ndownstream visualization and efficient coordinate\ntransformation. API functions may be 'Linked To' in the R\nheaders library way.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 2.7782,
    "stars": 0
  },
  {
    "id": 25056,
    "package_name": "trigpoints",
    "title": "Data Set of Trig Points in Great Britain in British National\nGrid Coordinates",
    "description": "A complete data set of historic GB trig points in British\nNational Grid (OSGB36) coordinate reference system. Trig points\n(aka triangulation stations) are fixed survey points used to\nimprove the accuracy of map making in Great Britain during the\n20th Century. Trig points are typically located on hilltops so\nstill serve as a useful navigational aid for walkers and hikers\ntoday.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 2.699,
    "stars": 0
  },
  {
    "id": 25367,
    "package_name": "urbioconnect",
    "title": "Urban Habitat Connectivity Analysis",
    "description": "Analyse and visualise habitat connectivity in urban\nlandscapes, accounting for barriers and buffer distances.\nIncludes Shiny app for interactive analysis and report\ngeneration. Based on methods developed by Kirk et al (2023)\n<doi:10.1016/j.mex.2022.101989>.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 2.699,
    "stars": 0
  },
  {
    "id": 21989,
    "package_name": "rspat",
    "title": "rspatial.org data -- terra version",
    "description": "Data to support the examples on rspatial.org",
    "version": "1.0-1",
    "maintainer": "Robert J. Hijmans <r.hijmans@gmail.com>",
    "url": "",
    "exports": [
      ["spat_data"],
      ["spat_download"]
    ],
    "topics": [],
    "score": 2.6435,
    "stars": 2
  },
  {
    "id": 13298,
    "package_name": "flexfont",
    "title": "Flexible Font",
    "description": "Flexible font.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 2.1761,
    "stars": 0
  },
  {
    "id": 10083,
    "package_name": "certegis",
    "title": "A Certe R Package for Geographic Information Science",
    "description": "A Certe R package for geographic information science\n(GIS), using the 'sf' package and Dutch reference data. This\npackage is part of the 'certedata' universe.",
    "version": "",
    "maintainer": "",
    "url": "",
    "exports": [],
    "topics": [],
    "score": 1.699,
    "stars": 0
  },
  {
    "id": 10,
    "package_name": "ABRSQOL",
    "title": "Quality-of-Life Solver for \"Measuring Quality of Life under\nSpatial Frictions\"",
    "description": "This toolkit implements a numerical solution algorithm \n    to invert a quality of life measure from observed data. Unlike\n    the traditional Rosen-Roback measure, this measure accounts for\n    mobility frictions—generated by idiosyncratic tastes and local\n    ties — and trade frictions — generated by trade costs and\n    non-tradable services, thereby reducing non-classical\n    measurement error. The QoL measure is based on Ahlfeldt, Bald,\n    Roth, Seidel (2024)\n    <https://econpapers.repec.org/RePEc:boc:bocode:s459382>\n    \"Measuring Quality of Life under Spatial Frictions\". When using\n    this programme or the toolkit in your work, please cite the paper.",
    "version": "1.0.0",
    "maintainer": "Max von Mylius <max.mylius@hu-berlin.de>",
    "url": "https://github.com/Ahlfeldt/ABRSQOL-toolkit#readme",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 51,
    "package_name": "AF",
    "title": "Model-Based Estimation of Confounder-Adjusted Attributable\nFractions",
    "description": "Estimates the attributable fraction in different sampling designs\n    adjusted for measured confounders using logistic regression (cross-sectional\n    and case-control designs), conditional logistic regression (matched case-control\n    design), Cox proportional hazard regression (cohort design with time-to-\n    event outcome), gamma-frailty model with a Weibull baseline hazard and instrumental variables analysis.\n    An exploration of the AF with a genetic exposure can be found in the package 'AFheritability' Dahlqwist E et al. (2019) <doi:10.1007/s00439-019-02006-8>.",
    "version": "0.1.5",
    "maintainer": "Elisabeth Dahlqwist <elisabeth.dahlqwist88@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 58,
    "package_name": "AGPRIS",
    "title": "AGricultural PRoductivity in Space",
    "description": "Functionalities to simulate space-time data and to estimate dynamic-spatial panel data models. \n             Estimators implemented are the BCML (Elhorst (2010), <doi:10.1016/j.regsciurbeco.2010.03.003>), the MML (Elhorst (2010) <doi:10.1016/j.regsciurbeco.2010.03.003>) and the INLA Bayesian estimator (Lindgren and Rue, (2015) <doi:10.18637/jss.v063.i19>; Bivand, Gomez-Rubio and Rue, (2015) <doi:10.18637/jss.v063.i20>) \n             adapted to panel data. The package contains functions to replicate the analyses of the scientific article entitled \"Agricultural Productivity in Space\" (Baldoni and Esposti (2021), <doi:10.1111/ajae.12155>)).",
    "version": "2.0",
    "maintainer": "Edoardo Baldoni <edoardo.baldoni@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 123,
    "package_name": "AQuadtree",
    "title": "Confidentiality of Spatial Point Data",
    "description": "Provides an automatic aggregation tool to manage point data privacy, \n    intended to be helpful for the production of official spatial data and for researchers.\n    The package pursues the data accuracy at the smallest possible areas preventing \n    individual information disclosure. The methodology, based on hierarchical geographic \n    data structures performs aggregation and local suppression of point data to ensure privacy\n    as described in Lagonigro, R., Oller, R., Martori J.C. (2017) <doi:10.2436/20.8080.02.55>.\n    The data structures are created following the guidelines for grid datasets from the\n    European Forum for Geography and Statistics. ",
    "version": "1.0.4",
    "maintainer": "Raymond Lagonigro <raymond.lagonigro@uvic.cat>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 144,
    "package_name": "ASGS.foyer",
    "title": "Interface to the Australian Statistical Geography Standard",
    "description": "The Australian Statistical Geography Standard ('ASGS') is \n  a set of shapefiles by the Australian Bureau of Statistics. This package\n  provides an interface to those shapefiles, as well as methods for converting\n  coordinates to shapefiles.",
    "version": "0.3.3",
    "maintainer": "Hugh Parsonage <hugh.parsonage@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 149,
    "package_name": "ASMbook",
    "title": "Functions for the Book \"Applied Statistical Modeling for\nEcologists\"",
    "description": "Provides functions to accompany the book \"Applied Statistical Modeling for Ecologists\" by Marc Kéry and Kenneth F. Kellner (2024, ISBN: 9780443137150). Included are functions for simulating and customizing the datasets used for the example models in each chapter, summarizing output from model fitting engines, and running custom Markov Chain Monte Carlo.",
    "version": "1.0.2",
    "maintainer": "Ken Kellner <contact@kenkellner.com>",
    "url": "https://shop.elsevier.com/books/applied-statistical-modelling-for-ecologists/kery/978-0-443-13715-0",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 155,
    "package_name": "AST",
    "title": "Age-Spatial-Temporal Model",
    "description": "Fits a model to adjust and consider additional variations in three dimensions of age groups, time, and space on residuals excluded from a prediction model that have residual such as: linear regression, mixed model and so on. Details are given in Foreman et al. (2015) <doi:10.1186/1478-7954-10-1>.",
    "version": "0.1.0",
    "maintainer": "Ali Ghanbari  <a.ghanbari541@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 163,
    "package_name": "ATE.ERROR",
    "title": "Estimating ATE with Misclassified Outcomes and Mismeasured\nCovariates",
    "description": "Addressing measurement error in covariates and misclassification in binary outcome variables within causal inference, the 'ATE.ERROR' package implements inverse probability weighted estimation methods proposed by Shu and Yi (2017, <doi:10.1177/0962280217743777>; 2019, <doi:10.1002/sim.8073>). These methods correct errors to accurately estimate average treatment effects (ATE). The package includes two main functions: ATE.ERROR.Y() for handling misclassification in the outcome variable and ATE.ERROR.XY() for correcting both outcome misclassification and covariate measurement error. It employs logistic regression for treatment assignment and uses bootstrap sampling to calculate standard errors and confidence intervals, with simulated datasets provided for practical demonstration.",
    "version": "1.0.0",
    "maintainer": "Aryan Rezanezhad <Aryan.rzn@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 222,
    "package_name": "AgroReg",
    "title": "Regression Analysis Linear and Nonlinear for Agriculture",
    "description": "Linear and nonlinear regression analysis common in agricultural science articles (Archontoulis & Miguez (2015). <doi:10.2134/agronj2012.0506>). The package includes polynomial, exponential, gaussian, logistic, logarithmic, segmented, non-parametric models, among others. The functions return the model coefficients and their respective p values, coefficient of determination, root mean square error, AIC, BIC, as well as graphs with the equations automatically.",
    "version": "1.2.11",
    "maintainer": "Gabriel Danilo Shimizu <gabrield.shimizu@gmail.com>",
    "url": "https://fisher.uel.br/AgroReg_shiny/,\nhttps://fisher.uel.br/AgroReg_shiny.pt/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 226,
    "package_name": "AirExposure",
    "title": "Exposure Model to Air Pollutants Based on Mobility and Daily\nActivities",
    "description": "Model that assesses daily exposure to air pollution, which considers daily population mobility on a geographical scale and the spatial and temporal variability of pollutant concentrations, in addition to traditional parameters such as exposure time and pollutant concentration.",
    "version": "1.0",
    "maintainer": "Josefina Urquiza <jurquiza@conicet.gov.ar>",
    "url": "https://github.com/flortames/Air-Exposure-Model",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 227,
    "package_name": "AirMonitor",
    "title": "Air Quality Data Analysis",
    "description": "Utilities for working with hourly air quality monitoring data\n    with a focus on small particulates (PM2.5). A compact data model is \n    structured as a list with two dataframes. A 'meta' dataframe contains \n    spatial and measuring device metadata associated with deployments at known \n    locations. A 'data' dataframe contains a 'datetime' column followed by \n    columns of measurements associated with each \"device-deployment\".\n    Algorithms to calculate NowCast and the associated Air Quality Index (AQI)\n    are defined at the US Environmental Projection Agency AirNow program:\n    <https://document.airnow.gov/technical-assistance-document-for-the-reporting-of-daily-air-quailty.pdf>.",
    "version": "0.4.3",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "url": "https://github.com/MazamaScience/AirMonitor,\nhttps://mazamascience.github.io/AirMonitor/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 324,
    "package_name": "AtlasMaker",
    "title": "Make Multiple 'leaflet' Maps in 'Shiny'",
    "description": "Simplify creating multiple, related 'leaflet' maps across tabs for a 'shiny' application. Users build lists of any polygons, points, and polylines needed for the project, use the map_server() function to assign built lists and other chosen aesthetics into each tab, and the package leverages modules to generate all map tabs.",
    "version": "0.1.0",
    "maintainer": "Rachel Greenlee <rachellynn.greenlee@gmail.com>",
    "url": "https://github.com/rachel-greenlee/AtlasMaker",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 346,
    "package_name": "AzureContainers",
    "title": "Interface to 'Container Instances', 'Docker Registry' and\n'Kubernetes' in 'Azure'",
    "description": "An interface to container functionality in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/en-us/products/category/containers/>. Manage 'Azure Container Instance' (ACI), 'Azure Container Registry' (ACR) and 'Azure Kubernetes Service' (AKS) resources, push and pull images, and deploy services. On the client side, lightweight shells to the 'docker', 'docker-compose', 'kubectl' and 'helm' commandline tools are provided. Part of the 'AzureR' family of packages.",
    "version": "1.3.3",
    "maintainer": "Hong Ooi <hongooi73@gmail.com>",
    "url": "https://github.com/Azure/AzureContainers\nhttps://github.com/Azure/AzureR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 348,
    "package_name": "AzureGraph",
    "title": "Simple Interface to 'Microsoft Graph'",
    "description": "A simple interface to the 'Microsoft Graph' API <https://learn.microsoft.com/en-us/graph/overview>. 'Graph' is a comprehensive framework for accessing data in various online Microsoft services. This package was originally intended to provide an R interface only to the 'Azure Active Directory' part, with a view to supporting interoperability of R and 'Azure': users, groups, registered apps and service principals. However it has since been expanded into a more general tool for interacting with Graph. Part of the 'AzureR' family of packages.",
    "version": "1.3.5",
    "maintainer": "Hong Ooi <hongooi73@gmail.com>",
    "url": "https://github.com/Azure/AzureGraph\nhttps://github.com/Azure/AzureR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 381,
    "package_name": "BAwiR",
    "title": "Analysis of Basketball Data",
    "description": "Collection of tools to work with European basketball data. Functions available are related to friendly \n\tweb scraping, data management and visualization. Data were obtained from <https://www.euroleaguebasketball.net/euroleague/>, \n\t<https://www.euroleaguebasketball.net/eurocup/> and <https://www.acb.com/>, following the instructions \n        of their respectives robots.txt files, when available. Box score data are available for the three leagues. \n\tPlay-by-play and spatial shooting data are also available for the Spanish league. Methods for analysis include a \n\tpopulation pyramid, 2D plots, circular plots of players' percentiles, plots of players' monthly/yearly stats, \n\tteam heatmaps, team shooting plots, team four factors plots, cross-tables with the results of regular season games,\n\tmaps of nationalities, combinations of lineups, possessions-related variables, timeouts,\n\tperformance by periods, personal fouls, offensive rebounds and different types of shooting charts. \n\tPlease see Vinue (2020) <doi:10.1089/big.2018.0124> and Vinue (2024) <doi:10.1089/big.2023.0177>. ",
    "version": "1.4.3",
    "maintainer": "Guillermo Vinue <guillermo.vinue@uv.es>",
    "url": "https://www.uv.es/vivigui/basketball_platform.html,\nhttps://www.uv.es/vivigui/, https://www.R-project.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 422,
    "package_name": "BFI",
    "title": "Bayesian Federated Inference",
    "description": "The Bayesian Federated Inference ('BFI') method combines inference results obtained from local data sets in the separate centers. In this version of the package, the 'BFI' methodology is programmed for linear, logistic and survival regression models. For GLMs, see Jonker, Pazira and Coolen (2024) <doi:10.1002/sim.10072>; for survival models, see Pazira, Massa, Weijers, Coolen and Jonker (2025) <doi:10.48550/arXiv.2404.17464>; and for heterogeneous populations, see Jonker, Pazira and Coolen (2025) <doi:10.1017/rsm.2025.6>.",
    "version": "3.1.0",
    "maintainer": "Hassan Pazira <hassan.pazira@radboudumc.nl>",
    "url": "https://hassanpazira.github.io/BFI/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 434,
    "package_name": "BH",
    "title": "Boost C++ Header Files",
    "description": "Boost provides free peer-reviewed portable C++ source \n libraries.  A large part of Boost is provided as C++ template code\n which is resolved entirely at compile-time without linking.  This \n package aims to provide the most useful subset of Boost libraries \n for template use among CRAN packages. By placing these libraries in \n this package, we offer a more efficient distribution system for CRAN \n as replication of this code in the sources of other packages is \n avoided. As of release 1.84.0-0, the following Boost libraries are\n included: 'accumulators' 'algorithm' 'align' 'any' 'atomic' 'beast'\n 'bimap' 'bind' 'circular_buffer' 'compute' 'concept' 'config'\n 'container' 'date_time' 'detail' 'dynamic_bitset' 'exception'\n 'flyweight' 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap'\n 'icl' 'integer' 'interprocess' 'intrusive' 'io' 'iostreams'\n 'iterator' 'lambda2' 'math' 'move' 'mp11' 'mpl' 'multiprecision'\n 'numeric' 'pending' 'phoenix' 'polygon' 'preprocessor' 'process'\n 'propery_tree' 'qvm' 'random' 'range' 'scope_exit' 'smart_ptr' 'sort'\n 'spirit' 'tuple' 'type_traits' 'typeof' 'unordered' 'url' 'utility'\n 'uuid'.",
    "version": "1.90.0-1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "url": "https://github.com/eddelbuettel/bh,\nhttps://dirk.eddelbuettel.com/code/bh.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 443,
    "package_name": "BIFIEsurvey",
    "title": "Tools for Survey Statistics in Educational Assessment",
    "description": "\n    Contains tools for survey statistics (especially in educational\n    assessment) for datasets with replication designs (jackknife, \n    bootstrap, replicate weights; see Kolenikov, 2010;\n    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,\n    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, \n    <doi:10.1080/02331889708802523>). \n    Descriptive statistics, linear and logistic regression, \n    path models for manifest variables with measurement error \n    correction and two-level hierarchical regressions for weighted \n    samples are included. Statistical inference can be conducted for \n    multiply imputed datasets and nested multiply imputed datasets\n    and is in particularly suited for the analysis of plausible values\n    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; \n    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &\n    Yanagida, 2016). The package development was supported by BIFIE \n    (Federal Institute for Educational Research, Innovation and Development \n    of the Austrian School System; Salzburg, Austria).",
    "version": "3.8.0",
    "maintainer": "Konrad Oberwimmer <konrad.oberwimmer@iqs.gv.at>",
    "url": "https://github.com/konradoberwimmer/BIFIEsurvey,\nhttps://konradoberwimmer.github.io/BIFIEsurvey/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 445,
    "package_name": "BIGL",
    "title": "Biochemically Intuitive Generalized Loewe Model",
    "description": "Response surface methods for drug synergy analysis. Available\n    methods include generalized and classical Loewe formulations as well as Highest\n    Single Agent methodology. Response surfaces can be plotted in an interactive\n    3-D plot and formal statistical tests for presence of synergistic effects are\n    available. Implemented methods and tests are described in the article \n    \"BIGL: Biochemically Intuitive Generalized Loewe null model for prediction \n    of the expected combined effect compatible with partial agonism and antagonism\"\n    by Koen Van der Borght, Annelies Tourny, Rytis Bagdziunas, Olivier Thas, \n    Maxim Nazarov, Heather Turner, Bie Verbist & Hugo Ceulemans (2017) \n    <doi:10.1038/s41598-017-18068-5>.",
    "version": "1.9.3",
    "maintainer": "Kathy Mutambanengwe <kathy.mutambanengwe@openanalytics.eu>",
    "url": "https://github.com/openanalytics/BIGL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 449,
    "package_name": "BIOMASS",
    "title": "Estimating Aboveground Biomass and Its Uncertainty in Tropical\nForests",
    "description": "Contains functions for estimating above-ground biomass/carbon and its uncertainty in tropical forests. These functions allow to (1) retrieve and correct taxonomy, (2) estimate wood density and its uncertainty, (3) build height-diameter models, (4) manage tree and plot coordinates, (5) estimate above-ground biomass/carbon at stand level with associated uncertainty. To cite ‘BIOMASS’, please use citation(‘BIOMASS’). For more information, see Réjou-Méchain et al. (2017) <doi:10.1111/2041-210X.12753>.",
    "version": "2.2.4-1",
    "maintainer": "Dominique Lamonica <dominique.lamonica@ird.fr>",
    "url": "https://umr-amap.github.io/BIOMASS/,\nhttps://github.com/umr-amap/BIOMASS/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 450,
    "package_name": "BIOdry",
    "title": "Multilevel Modeling of Dendroclimatical Fluctuations",
    "description": "Multilevel ecological data series (MEDS) are sequences of observations ordered according to temporal/spatial hierarchies that are defined by sample designs, with sample variability confined to ecological factors. Dendroclimatic MEDS of tree rings and climate are modeled into normalized fluctuations of tree growth and aridity.  Modeled fluctuations (model frames) are compared with Mantel correlograms on multiple levels defined by sample design. Package implementation can be understood by running examples in modelFrame(), and muleMan() functions. ",
    "version": "0.9.1",
    "maintainer": "Wilson Lara <wilarhen@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 453,
    "package_name": "BKP",
    "title": "Beta Kernel Process Modeling",
    "description": "Implements the Beta Kernel Process (BKP) for nonparametric modeling of spatially varying binomial probabilities, together with its extension, the Dirichlet Kernel Process (DKP), for categorical or multinomial data.\n The package provides functions for model fitting, predictive inference with uncertainty quantification, posterior simulation, and visualization in one-and two-dimensional input spaces.\n Multiple kernel functions (Gaussian, Matern 5/2, and Matern 3/2) are supported, with hyperparameters optimized through multi-start gradient-based search.\n For more details, see Zhao, Qing, and Xu (2025) <doi:10.48550/arXiv.2508.10447>.",
    "version": "0.2.3",
    "maintainer": "Jiangyan Zhao <zhaojy2017@126.com>",
    "url": "https://github.com/Jiangyan-Zhao/BKP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 455,
    "package_name": "BKTR",
    "title": "Bayesian Kernelized Tensor Regression",
    "description": "Facilitates scalable spatiotemporally varying coefficient\n    modelling with Bayesian kernelized tensor regression.\n    The important features of this package are:\n    (a) Enabling local temporal and spatial modeling of the relationship between\n    the response variable and covariates.\n    (b) Implementing the model described by Lei et al. (2023) <doi:10.48550/arXiv.2109.00046>.\n    (c) Using a Bayesian Markov Chain Monte Carlo (MCMC) algorithm to sample from the posterior\n    distribution of the model parameters.\n    (d) Employing a tensor decomposition to reduce the number of estimated parameters.\n    (e) Accelerating tensor operations and enabling graphics processing unit (GPU) acceleration\n    with the 'torch' package.",
    "version": "0.2.0",
    "maintainer": "Julien Lanthier <julien.lanthier@hec.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 465,
    "package_name": "BLRShiny",
    "title": "Interactive Document for Working with Binary Logistic Regression\nAnalysis",
    "description": "An interactive document on  the topic of binary logistic regression  analysis using 'rmarkdown' and 'shiny' packages. Runtime examples are provided in the package function as well as at  <https://analyticmodels.shinyapps.io/BinaryLogisticRegressionModelling/>.",
    "version": "0.1.0",
    "maintainer": "Kartikeya Bolar <kartikeya.bolar@tapmi.edu.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 466,
    "package_name": "BLRShiny2",
    "title": "Interactive Document for Working with Binary Logistic Regression\nAnalysis",
    "description": "An interactive document on  the topic of binary logistic regression  analysis using 'rmarkdown' and 'shiny' packages. Runtime examples are provided in the package function as well as at  <https://analyticmodels.shinyapps.io/BinaryLogisticRegressionModelling/>.",
    "version": "0.1.0",
    "maintainer": "Kartikeya Bolar <kartikeya.bolar@tapmi.edu.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 467,
    "package_name": "BLSM",
    "title": "Bayesian Latent Space Model",
    "description": "Provides a Bayesian latent space \n    model for complex networks, either weighted or unweighted.\n    Given an observed input graph, the estimates for the latent coordinates \n    of the nodes are obtained through a Bayesian MCMC algorithm. \n    The overall likelihood of the graph depends on a fundamental probability \n    equation, which is defined so that ties are more likely to exist \n    between nodes whose latent space coordinates are close. \n    The package is mainly based on the model by Hoff, Raftery and Handcock (2002)\n    <doi:10.1198/016214502388618906> and contains some extra features \n    (e.g., removal of the Procrustean step, weights implemented as \n    coefficients of the latent distances, 3D plots). \n    The original code related to the above model was retrieved from\n    <https://www.stat.washington.edu/people/pdhoff/Code/hoff_raftery_handcock_2002_jasa/>.\n    Users can inspect the MCMC simulation, create and customize insightful \n    graphical representations or apply clustering techniques. ",
    "version": "0.1.0",
    "maintainer": "Alberto Donizetti <albe.donizetti@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 471,
    "package_name": "BMEmapping",
    "title": "Spatial Interpolation using Bayesian Maximum Entropy (BME)",
    "description": "\n    Provides an accessible and robust implementation of core BME \n    methodologies for spatial prediction. It enables the systematic integration \n    of heterogeneous data sources including both hard data (precise \n    measurements) and soft interval data (bounded or uncertain observations) \n    while incorporating prior knowledge and supporting variogram-based spatial \n    modeling. The BME methodology is described in Christakos (1990) \n    <doi:10.1007/BF00890661> and Serre and Christakos (1999) \n    <doi:10.1007/s004770050029>.",
    "version": "1.2.2",
    "maintainer": "Kinspride Duah <kinspride2020@gmail.com>",
    "url": "https://github.com/KinsprideDuah/BMEmapping",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 488,
    "package_name": "BOLDconnectR",
    "title": "Retrieve, Transform and Analyze the Barcode of Life Data Systems\nData",
    "description": "Facilitates retrieval, transformation and analysis of the data\n    from the Barcode of Life Data Systems (BOLD) database <https://boldsystems.org/>. \n    This package allows both public and private user data to be easily downloaded into the R\n    environment using a variety of inputs such as: IDs (processid, sampleid), BINs, dataset codes, \n    project codes, taxonomy, geography etc. It provides frictionless data conversion  \n    into formats compatible with other R-packages and third-party tools, \n    as well as functions for sequence alignment & clustering, biodiversity analysis and spatial mapping.",
    "version": "1.0.0",
    "maintainer": "Sameer Padhye <spadhye@uoguelph.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 502,
    "package_name": "BRISC",
    "title": "Fast Inference for Large Spatial Datasets using BRISC",
    "description": "Fits bootstrap with univariate spatial regression models using Bootstrap for Rapid Inference on Spatial Covariances (BRISC) for large datasets using nearest neighbor Gaussian processes detailed in Saha and Datta (2018) <doi:10.1002/sta4.184>.",
    "version": "1.0.6",
    "maintainer": "Arkajyoti Saha <arkajyotisaha93@gmail.com>",
    "url": "https://github.com/ArkajyotiSaha/BRISC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 509,
    "package_name": "BSPADATA",
    "title": "Bayesian Proposal to Fit Spatial Econometric Models",
    "description": "The purpose of this package is to fit the three Spatial Econometric Models proposed\n  in Anselin (1988, ISBN:9024737354) in the homoscedastic and the heteroscedatic case. The fit is made through MCMC algorithms\n  and observational working variables approach.",
    "version": "1.1.0",
    "maintainer": "Jorge Sicacha-Parada <jasicachap@unal.edu.co>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 513,
    "package_name": "BSSoverSpace",
    "title": "Blind Source Separation for Multivariate Spatial Data using\nEigen Analysis",
    "description": "Provides functions for blind source separation over multivariate spatial data, and useful statistics for evaluating performance of estimation on mixing matrix. 'BSSoverSpace' is based on an eigen analysis of a positive definite matrix defined in terms of multiple normalized spatial local covariance matrices, and thus can handle moderately high-dimensional random fields. This package is an implementation of the method described in Zhang, Hao and Yao (2022)<arXiv:2201.02023>.",
    "version": "0.1.0",
    "maintainer": "Sixing Hao <s.hao3@lse.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 515,
    "package_name": "BSTFA",
    "title": "Bayesian Spatio-Temporal Factor Analysis Model",
    "description": "Implements Bayesian spatio-temporal factor analysis models for multivariate data observed across space and time. The package provides tools for model fitting via Markov chain Monte Carlo (MCMC), spatial and temporal interpolation, and visualization of latent factors and loadings to support inference and exploration of underlying spatio-temporal patterns. Designed for use in environmental, ecological, or public health applications, with support for posterior prediction and uncertainty quantification. Includes functions such as BSTFA() for model fitting and plot_factor() to visualize the latent processes.  Functions are based on and extended from methods described in Berrett, et al. (2020) <doi:10.1002/env.2609>.",
    "version": "0.1.0",
    "maintainer": "Candace Berrett <cberrett@stat.byu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 548,
    "package_name": "BalancedSampling",
    "title": "Balanced and Spatially Balanced Sampling",
    "description": "Select balanced and spatially balanced probability samples in multi-dimensional spaces\n    with any prescribed inclusion probabilities. It contains fast (C++ via Rcpp) implementations of\n    the included sampling methods. The local pivotal method by Grafström, Lundström and Schelin (2012)\n    <doi:10.1111/j.1541-0420.2011.01699.x> and spatially correlated Poisson sampling by Grafström (2012)\n    <doi:10.1016/j.jspi.2011.07.003> are included. Also the cube method (for balanced sampling) and\n    the local cube method (for doubly balanced sampling) are included, see Grafström and Tillé (2013)\n    <doi:10.1002/env.2194>.",
    "version": "2.1.1",
    "maintainer": "Anton Grafström <anton.grafstrom@gmail.com>",
    "url": "https://www.envisim.se/,\nhttps://github.com/envisim/BalancedSampling/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 550,
    "package_name": "BallMapper",
    "title": "The Ball Mapper Algorithm",
    "description": "The core algorithm is described in \"Ball mapper: a shape summary for topological data analysis\" by Pawel Dlotko, (2019) <arXiv:1901.07410>. Please consult the following youtube video <https://www.youtube.com/watch?v=M9Dm1nl_zSQfor> the idea of functionality. Ball Mapper provide a topologically accurate summary of a data in a form of an abstract graph. To create it, please provide the coordinates of points (in the points array), values of a function of interest at those points (can be initialized randomly if you do not have it) and the value epsilon which is the radius of the ball in the Ball Mapper construction. It can be understood as the minimal resolution on which we use to create the model of the data. ",
    "version": "0.2.0",
    "maintainer": "Pawel Dlotko <pdlotko@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 573,
    "package_name": "BayesBrainMap",
    "title": "Estimate Brain Networks and Connectivity with Population-Derived\nPriors",
    "description": "Implements Bayesian brain mapping models, including the prior \n    ICA (independent components analysis) model proposed in Mejia et al. (2020) \n    <doi:10.1080/01621459.2019.1679638> and the spatial prior ICA model \n    proposed in proposed in Mejia et al. (2022) \n    <doi:10.1080/10618600.2022.2104289>. Both models estimate subject-level \n    brain as deviations from known population-level networks, which are \n    estimated using standard ICA algorithms. Both models employ an \n    expectation-maximization algorithm for estimation of the latent brain \n    networks and unknown model parameters. Includes direct support for 'CIFTI',\n    'GIFTI', and 'NIFTI' neuroimaging file formats.",
    "version": "0.1.3",
    "maintainer": "Amanda Mejia <mandy.mejia@gmail.com>",
    "url": "https://github.com/mandymejia/BayesBrainMap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 587,
    "package_name": "BayesERtools",
    "title": "Bayesian Exposure-Response Analysis Tools",
    "description": "Suite of tools that facilitate\n    exposure-response analysis using Bayesian methods. The package\n    provides a streamlined workflow for fitting types of models that are\n    commonly used in exposure-response analysis - linear and Emax for continuous\n    endpoints, logistic linear and logistic Emax for binary endpoints, as well\n    as performing simulation and visualization. Learn more about the workflow\n    at <https://genentech.github.io/BayesERbook/>.",
    "version": "0.2.4",
    "maintainer": "Kenta Yoshida <yoshida.kenta.6@gmail.com>",
    "url": "https://genentech.github.io/BayesERtools/,\nhttps://genentech.github.io/BayesERbook/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 611,
    "package_name": "BayesNSGP",
    "title": "Bayesian Analysis of Non-Stationary Gaussian Process Models",
    "description": "Enables off-the-shelf functionality for fully Bayesian, nonstationary Gaussian process modeling. The approach to nonstationary modeling involves a closed-form, convolution-based covariance function with spatially-varying parameters; these parameter processes can be specified either deterministically (using covariates or basis functions) or stochastically (using approximate Gaussian processes). Stationary Gaussian processes are a special case of our methodology, and we furthermore implement approximate Gaussian process inference to account for very large spatial data sets (Finley, et al (2017) <doi:10.48550/arXiv.1702.00434>). Bayesian inference is carried out using Markov chain Monte Carlo methods via the \"nimble\" package, and posterior prediction for the Gaussian process at unobserved locations is provided as a post-processing step.",
    "version": "0.2.0",
    "maintainer": "Daniel Turek <danielturek@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 616,
    "package_name": "BayesPieceHazSelect",
    "title": "Variable Selection in a Hierarchical Bayesian Model for a Hazard\nFunction",
    "description": "Fits a piecewise exponential hazard to survival data using a\n    Hierarchical Bayesian model with an Intrinsic Conditional Autoregressive\n    formulation for the spatial dependency in the hazard rates for each piece.\n    This function uses Metropolis- Hastings-Green MCMC to allow the number of split\n    points to vary and also uses Stochastic Search Variable Selection to determine\n    what covariates drive the risk of the event. This function outputs trace plots\n    depicting the number of split points in the hazard and the number of variables\n    included in the hazard. The function saves all posterior quantities to the\n    desired path.",
    "version": "1.1.0",
    "maintainer": "Andrew Chapple <AndrewChapple21@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 639,
    "package_name": "BayesfMRI",
    "title": "Spatial Bayesian Methods for Task Functional MRI Studies",
    "description": "Performs a spatial Bayesian general linear model (GLM) for task \n    functional magnetic resonance imaging (fMRI) data on the cortical surface. \n    Additional models include group analysis and inference to detect thresholded\n    areas of activation. Includes direct support for the 'CIFTI' neuroimaging \n    file format. For more information see A. F. Mejia, Y. R. Yue, D. Bolin, F. \n    Lindgren, M. A. Lindquist (2020) <doi:10.1080/01621459.2019.1611582> and D. \n    Spencer, Y. R. Yue, D. Bolin, S. Ryan, A. F. Mejia (2022) \n    <doi:10.1016/j.neuroimage.2022.118908>.",
    "version": "0.11.0",
    "maintainer": "Amanda Mejia <mandy.mejia@gmail.com>",
    "url": "https://github.com/mandymejia/BayesfMRI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 658,
    "package_name": "BeSS",
    "title": "Best Subset Selection in Linear, Logistic and CoxPH Models",
    "description": "An implementation of best subset selection in generalized linear model and Cox proportional hazard model via the primal dual active set algorithm proposed by Wen, C., Zhang, A., Quan, S. and Wang, X. (2020) <doi:10.18637/jss.v094.i04>. The algorithm formulates coefficient parameters and residuals as primal and dual variables and utilizes efficient active set selection strategies based on the complementarity of the primal and dual variables.",
    "version": "2.0.4",
    "maintainer": "Canhong Wen <wencanhong@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 672,
    "package_name": "BetterReg",
    "title": "Better Statistics for OLS and Binomial Logistic Regression",
    "description": "Provides squared semi partial correlations, tolerance, Mahalanobis, Likelihood Ratio Chi Square, and Pseudo R Square. Aberson, C. L. (2022) <doi:10.31234/osf.io/s2yqn>.",
    "version": "0.2.0",
    "maintainer": "Chris Aberson <cla18@humboldt.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 689,
    "package_name": "BiVariAn",
    "title": "Bivariate Automatic Analysis",
    "description": "Simplify bivariate and regression analyses by automating\n    result generation, including summary tables, statistical tests, and\n    customizable graphs. It supports tests for continuous and dichotomous\n    data, as well as stepwise regression for linear, logistic, and Firth\n    penalized logistic models.  While not a substitute for tailored\n    analysis, 'BiVariAn' accelerates workflows and is expanding features\n    like multilingual interpretations of results.The methods for selecting\n    significant statistical tests, as well as the predictor selection in\n    prediction functions, can be referenced in the works of Marc Kery\n    (2003) <doi:10.1890/0012-9623(2003)84[92:NORDIG]2.0.CO;2> and Rainer\n    Puhr (2017) <doi:10.1002/sim.7273>.",
    "version": "1.0.2",
    "maintainer": "José Andrés Flores-García <andres.flores@uaslp.mx>",
    "url": "https://github.com/AndresFloresG/BiVariAn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 734,
    "package_name": "BioTrajectory",
    "title": "Image Processing Tools for Barnes Maze Experiments",
    "description": "Tools to process the information obtained from experiments conducted in the Barnes Maze. These tools enable the detection of trajectories generated by subjects during trials, as well as the acquisition of precise coordinates and relevant statistical data regarding the results. Through this approach, it aims to facilitate the analysis and interpretation of observed behaviors, thereby contributing to a deeper understanding of learning and memory processes in such experiments.",
    "version": "1.1.0",
    "maintainer": "Antonio Guerrero <jaguerrero@correo.uaa.mx>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 761,
    "package_name": "BiodiversityR",
    "title": "Package for Community Ecology and Suitability Analysis",
    "description": "Graphical User Interface (via the R-Commander) and utility functions (often based on the vegan package) for statistical analysis of biodiversity and ecological communities, including species accumulation curves, diversity indices, Renyi profiles, GLMs for analysis of species abundance and presence-absence, distance matrices, Mantel tests, and cluster, constrained and unconstrained ordination analysis. A book on biodiversity and community ecology analysis is available for free download from the website. In 2012, methods for (ensemble) suitability modelling and mapping were expanded in the package.",
    "version": "2.17-4",
    "maintainer": "Roeland Kindt <RoelandCEKindt@gmail.com>",
    "url": "http://www.worldagroforestry.org/output/tree-diversity-analysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 764,
    "package_name": "Biostatistics",
    "title": "Statistics Tutorials for Biologists",
    "description": "Tutorials for statistics, aimed at biological scientists. \n    Subjects range from basic descriptive statistics \n    through to complex linear modelling. The tutorials\n    include text, videos, interactive coding exercises\n    and multiple choice quizzes. The package also \n    includes 19 datasets which are used in the \n    tutorials.",
    "version": "1.0.4",
    "maintainer": "Rob Knell <r.knell@qmul.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 860,
    "package_name": "CAOP.RAA.2024",
    "title": "Official Administrative Map of the Azores (CAOP 2024)",
    "description": "Provides the official administrative boundaries of the Azores \n    (Região Autónoma dos Açores (RAA)) as defined in the 2024 edition of the \n    Carta Administrativa Oficial de Portugal (CAOP), published by the \n    Direção-Geral do Território (DGT). The package includes convenience\n    functions to import these boundaries as 'sf' objects for spatial analysis in\n    R.\n    Source: <https://geo2.dgterritorio.gov.pt/caop/CAOP_RAA_2024-gpkg.zip>.",
    "version": "0.0.5",
    "maintainer": "Ramiro Magno <rmagno@pattern.institute>",
    "url": "https://github.com/patterninstitute/CAOP.RAA.2024,\nhttps://www.pattern.institute/CAOP.RAA.2024/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 861,
    "package_name": "CARBayes",
    "title": "Spatial Generalised Linear Mixed Models for Areal Unit Data",
    "description": "Implements a class of univariate and multivariate spatial generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation using a single or multiple Markov chains. The response variable can be binomial, Gaussian, multinomial, Poisson or zero-inflated Poisson (ZIP), and spatial autocorrelation is modelled by a set of random effects that are assigned a conditional autoregressive (CAR) prior distribution. A number of different models are available for univariate spatial data, including models with no random effects as well as random effects modelled by different types of CAR prior, including the BYM model (Besag et al., 1991, <doi:10.1007/BF00116466>) and Leroux model (Leroux et al., 2000, <doi:10.1007/978-1-4612-1284-3_4>). Additionally,  a multivariate CAR (MCAR) model for multivariate spatial data is available, as is a two-level hierarchical model for modelling data relating to individuals within areas. Full details are given in the vignette accompanying this package. The initial creation of this package was supported by the Economic and Social Research Council (ESRC) grant RES-000-22-4256, and on-going development has been supported by the Engineering and Physical Science Research Council (EPSRC) grant EP/J017442/1, ESRC grant ES/K006460/1, Innovate UK / Natural Environment Research Council (NERC) grant NE/N007352/1 and the TB Alliance. ",
    "version": "6.1.1",
    "maintainer": "Duncan Lee <Duncan.Lee@glasgow.ac.uk>",
    "url": "https://github.com/duncanplee/CARBayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 865,
    "package_name": "CARME",
    "title": "CAR-MM Modelling in Stan",
    "description": "'Stan' based functions to estimate CAR-MM models. These models allow to estimate Generalised Linear Models with CAR (conditional autoregressive) spatial random effects for spatially and temporally misaligned data, provided a suitable Multiple Membership matrix. The main references are Gramatica, Liverani and Congdon (2023) <doi:10.1214/23-BA1370>, Petrof, Neyens, Nuyts, Nackaerts, Nemery and Faes (2020) <doi:10.1002/sim.8697> and Gramatica, Congdon and Liverani <doi:10.1111/rssc.12480>.",
    "version": "0.1.1",
    "maintainer": "Marco Gramatica <gramaticamarco@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 879,
    "package_name": "CBAModel",
    "title": "Stochastic 3D Structure Model for Binder-Conductive Additive\nPhase",
    "description": "Simulation of the stochastic 3D structure model for the nanoporous binder-conductive additive phase in battery cathodes introduced in P. Gräfensteiner, M. Osenberg, A. Hilger, N. Bohn, J. R. Binder, I. Manke, V. Schmidt, M. Neumann (2024) <doi:10.48550/arXiv.2409.11080>. The model is developed for a binder-conductive additive phase of consisting of carbon black, polyvinylidene difluoride binder and graphite particles. For its stochastic 3D modeling, a three-step procedure based on methods from stochastic geometry is used. First, the graphite particles are described by a Boolean model with ellipsoidal grains. Second, the mixture of carbon black and binder is modeled by an excursion set of a Gaussian random field in the complement of the graphite particles. Third, large pore regions within the mixture of carbon black and binder are described by a Boolean model with spherical grains.  ",
    "version": "0.0.1.2",
    "maintainer": "Matthias Neumann <neumann@tugraz.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 885,
    "package_name": "CBPE",
    "title": "Correlation-Based Penalized Estimators",
    "description": "Provides correlation-based penalty estimators for both linear and logistic regression models by implementing a new regularization method that incorporates correlation structures within the data. This method encourages a grouping effect where strongly correlated predictors tend to be in or out of the model together. See Tutz and Ulbricht (2009) <doi:10.1007/s11222-008-9088-5> and Algamal and Lee (2015) <doi:10.1016/j.eswa.2015.08.016>.",
    "version": "0.1.0",
    "maintainer": "Mina Norouzirad <mina.norouzirad@gmail.com>",
    "url": "https://github.com/mnrzrad/CBPE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 894,
    "package_name": "CCAMLRGIS",
    "title": "Antarctic Spatial Data Manipulation",
    "description": "Loads and creates spatial data, including layers and tools that are relevant\n    to the activities of the Commission for the Conservation of Antarctic Marine Living \n    Resources. Provides two categories of functions: load functions and create functions.\n    Load functions are used to import existing spatial layers from the online CCAMLR GIS\n    such as the ASD boundaries. Create functions are used to create layers from user data\n    such as polygons and grids.",
    "version": "4.2.1",
    "maintainer": "Stephane Thanassekos <stephane.thanassekos@ccamlr.org>",
    "url": "https://github.com/ccamlr/CCAMLRGIS#ccamlrgis-r-package",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 901,
    "package_name": "CCSRfind",
    "title": "Convert ICD-10 Codes to CCSR Codes",
    "description": "Provides a tool for matching ICD-10 codes to corresponding Clinical Classification Software Refined (CCSR) codes. The main function, CCSRfind(), identifies each CCSR code that applies to an individual given their diagnosis codes. It also provides a summary of CCSR codes that are matched to a dataset. The package contains 3 datasets: 'DXCCSR' (mapping of ICD-10 codes to CCSR codes), 'Legend' (conversion of DXCCSR to CCSRfind-usable format for CCSR codes with less than or equal to 1000 ICD-10 diagnosis codes), and 'LegendExtend' (conversion of DXCCSR to CCSRfind-usable format for CCSR codes with more than 1000 ICD-10 dx codes). The disc() function applies grepl() ('base') to multiple columns and is used in CCSRfind().",
    "version": "0.1.0",
    "maintainer": "Mark Ramos <mlr6219@psu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 917,
    "package_name": "CDsampling",
    "title": "Constrained Sampling in Paid Research Studies",
    "description": "In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the 'CDsampling' package, which integrates optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy with limited model information. Our package offers functions for the computation of the Fisher information matrix under generalized linear models (including regular linear regression model) and multinomial logistic models.To demonstrate the applications, we also provide a simulated dataset and a real dataset embedded in the package. Yifei Huang, Liping Tong, and Jie Yang (2025)<doi:10.5705/ss.202022.0414>. ",
    "version": "0.1.6",
    "maintainer": "Yifei Huang <yhuan39@uic.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 929,
    "package_name": "CFM",
    "title": "Analyzing Censored Factor Models",
    "description": "Provides generation and estimation of censored factor models for high-dimensional data with censored errors (normal, t, logistic). Includes Sparse Orthogonal Principal Components (SOPC), and evaluation metrics.  Based on Guo G. (2023) <doi:10.1007/s00180-022-01270-z>.",
    "version": "0.8.0",
    "maintainer": "Guangbao Guo <ggb11111111@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 932,
    "package_name": "CFtime",
    "title": "Using CF-Compliant Calendars with Climate Projection Data",
    "description": "Support for all calendars as specified in the Climate and Forecast \n    (CF) Metadata Conventions for climate and forecasting data. The CF Metadata \n    Conventions is widely used for distributing files with climate observations \n    or projections, including the Coupled Model Intercomparison Project (CMIP) \n    data used by climate change scientists and the Intergovernmental Panel on\n    Climate Change (IPCC). This package specifically allows the user to work \n    with any of the CF-compliant calendars (many of which are not compliant with \n    POSIXt). The CF time coordinate is formally defined in the CF Metadata \n    Conventions document available at <https://cfconventions.org/Data/cf-conventions/cf-conventions-1.12/cf-conventions.html#time-coordinate>.",
    "version": "1.7.2",
    "maintainer": "Patrick Van Laake <patrick@vanlaake.net>",
    "url": "https://r-cf.github.io/CFtime/, https://github.com/R-CF/CFtime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 960,
    "package_name": "CIMTx",
    "title": "Causal Inference for Multiple Treatments with a Binary Outcome",
    "description": "Different methods to conduct causal inference for multiple treatments with a binary outcome, including regression adjustment, vector matching, Bayesian additive regression trees, targeted maximum likelihood and inverse probability of treatment weighting using different generalized propensity score models such as multinomial logistic regression, generalized boosted models and super learner. For more details, see the paper by Hu et al. <doi:10.1177/0962280220921909>.",
    "version": "1.2.0",
    "maintainer": "Jiayi Ji <jjy2876@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 971,
    "package_name": "CIplot",
    "title": "Functions to Plot Confidence Interval",
    "description": "Plot confidence interval from the objects of statistical tests such as\n  t.test(), var.test(), cor.test(), prop.test() and fisher.test() ('htest' class),\n  Tukey test [TukeyHSD()], Dunnett test [glht() in 'multcomp' package],\n  logistic regression [glm()], and Tukey or Games-Howell test [posthocTGH() in\n  'userfriendlyscience' package].\n  Users are able to set the styles of lines and points.\n  This package contains the function to calculate odds ratios and their confidence\n  intervals from the result of logistic regression.",
    "version": "1.0",
    "maintainer": "Toshiaki Ara <toshiaki.ara@gmail.com>",
    "url": "https://github.com/toshi-ara/CIplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 985,
    "package_name": "CLimd",
    "title": "Generating Rainfall Rasters from IMD NetCDF Data",
    "description": "The developed function is a comprehensive tool for the analysis of India Meteorological Department (IMD) NetCDF rainfall data. Specifically designed to process high-resolution daily\n             gridded rainfall datasets. It provides four key functions to process IMD NetCDF rainfall data and create rasters for various temporal scales, including annual, seasonal, monthly, and weekly\n             rainfall. For method details see, Malik, A. (2019).<DOI:10.1007/s12517-019-4454-5>. It supports different aggregation methods, such as sum, min, max, mean, and standard deviation. These functions\n             are designed for spatio-temporal analysis of rainfall patterns, trend analysis,geostatistical modeling of rainfall variability, identifying rainfall anomalies and extreme events and can be an input\n             for hydrological and agricultural models.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1052,
    "package_name": "CPC",
    "title": "Implementation of Cluster-Polarization Coefficient",
    "description": "Implements cluster-polarization coefficient for measuring distributional\n\tpolarization in single or multiple dimensions, as well as associated functions.\n\tContains support for hierarchical clustering, k-means, partitioning around medoids,\n\tdensity-based spatial clustering with noise, and manually imposed cluster membership.\n\tMehlhaff (2024) <doi:10.1017/S0003055423001041>.",
    "version": "2.6.2",
    "maintainer": "Isaac Mehlhaff <isaac.mehlhaff@gmail.com>",
    "url": "https://imehlhaff.net/CPC/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1063,
    "package_name": "CRANsearcher",
    "title": "RStudio Addin for Searching Packages in CRAN Database Based on\nKeywords",
    "description": "One of the strengths of R is its vast package ecosystem. Indeed, R packages extend from visualization to Bayesian inference and from spatial analyses to pharmacokinetics (<https://cran.r-project.org/web/views/>). There is probably not an area of quantitative research that isn't represented by at least one R package. At the time of this writing, there are more than 10,000 active CRAN packages. Because of this massive ecosystem, it is important to have tools to search and learn about packages related to your personal R needs. For this reason, we developed an RStudio addin capable of searching available CRAN packages directly within RStudio.",
    "version": "1.0.0",
    "maintainer": "Agustin Calatroni <agustin_calatroni@rhoworld.com>",
    "url": "https://github.com/RhoInc/CRANsearcher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1081,
    "package_name": "CSDownscale",
    "title": "Statistical Downscaling of Climate Predictions",
    "description": "Statistical downscaling and bias correction of climate predictions.\n    It includes implementations of commonly used methods such as Analogs,\n    Linear Regression, Logistic Regression, and Bias Correction techniques,\n    as well as interpolation functions for regridding and point-based applications.\n    It facilitates the production of high-resolution and local-scale climate\n    information from coarse-scale predictions, which is essential for impact analyses.\n    The package can be applied in a wide range of sectors and studies,\n    including agriculture, water management, energy, heatwaves, and other\n    climate-sensitive applications. The package was developed within the framework of\n    the European Union Horizon Europe projects Impetus4Change (101081555) and ASPECT (101081460),\n    the Wellcome Trust supported HARMONIZE project (224694/Z/21/Z), and the Spanish national project\n    BOREAS (PID2022-140673OA-I00). Implements the methods described in\n    Duzenli et al. (2024) <doi:10.5194/egusphere-egu24-19420>.",
    "version": "0.0.1",
    "maintainer": "Theertha Kariyathan <theertha.kariyathan@bsc.es>",
    "url": "https://gitlab.earth.bsc.es/es/csdownscale",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1083,
    "package_name": "CSHShydRology",
    "title": "Canadian Hydrological Analyses",
    "description": "A collection of user-submitted functions to aid in the analysis of hydrological data, particularly for users in Canada. The functions focus on the use of Canadian data sets, and are suited to Canadian hydrology, such as the important cold region hydrological processes and will work with Canadian hydrological models. The functions are grouped into several themes, currently including Statistical hydrology, Basic data manipulations, Visualization, and Spatial hydrology. Functions developed by the Floodnet project are also included. CSHShydRology has been developed with the assistance of the Canadian Society for Hydrological Sciences (CSHS) which is an affiliated society of the Canadian Water Resources Association (CWRA). As of version 1.2.6, functions now fail gracefully when attempting to download data from a url which is unavailable.",
    "version": "1.4.4",
    "maintainer": "Kevin Shook <kevin.shook@usask.ca>",
    "url": "https://github.com/CSHS-hydRology/CSHShydRology",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1090,
    "package_name": "CSeQTL",
    "title": "Cell Type-Specific Expression Quantitative Trail Loci Mapping",
    "description": "Perform bulk and cell type-specific expression quantitative trail loci mapping with our novel method (Little et al. (2023) <doi:10.1038/s41467-023-38795-w>).",
    "version": "1.0.0",
    "maintainer": "Paul Little <pllittle321@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1130,
    "package_name": "CalibratR",
    "title": "Mapping ML Scores to Calibrated Predictions",
    "description": "Transforms your uncalibrated Machine Learning scores to well-calibrated prediction estimates that can be interpreted as probability estimates. The implemented BBQ (Bayes Binning in Quantiles) model is taken from Naeini (2015, ISBN:0-262-51129-0). Please cite this paper: Schwarz J and Heider D, Bioinformatics 2019, 35(14):2458-2465.",
    "version": "0.1.2",
    "maintainer": "Dominik Heider <heiderd@mathematik.uni-marburg.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1141,
    "package_name": "CardioCurveR",
    "title": "Nonlinear Modeling of R-R Interval Dynamics",
    "description": "Automated and robust framework for analyzing R-R interval (RRi) signals using advanced nonlinear modeling and preprocessing techniques. The package implements a dual-logistic model to capture the rapid drop and subsequent recovery of RRi during exercise, as described by Castillo-Aguilar et al. (2025) <doi:10.1038/s41598-025-93654-6>. In addition, 'CardioCurveR' includes tools for filtering RRi signals using zero-phase Butterworth low-pass filtering and for cleaning ectopic beats via adaptive outlier replacement using local regression and robust statistics. These integrated methods preserve the dynamic features of RRi signals and facilitate accurate cardiovascular monitoring and clinical research.",
    "version": "1.0.0",
    "maintainer": "Matías Castillo-Aguilar <m99castillo@gmail.com>",
    "url": "https://github.com/matcasti/CardioCurveR,\nhttps://matcasti.github.io/CardioCurveR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1145,
    "package_name": "Carlson",
    "title": "Carlson Elliptic Integrals and Incomplete Elliptic Integrals",
    "description": "Evaluation of the Carlson elliptic integrals and the\n    incomplete elliptic integrals with complex arguments. The\n    implementations use Carlson's algorithms <doi:10.1007/BF02198293>.\n    Applications of elliptic integrals include probability distributions,\n    geometry, physics, mechanics, electrodynamics, statistical mechanics,\n    astronomy, geodesy, geodesics on conics, and magnetic field\n    calculations.",
    "version": "3.0.0",
    "maintainer": "Stéphane Laurent <laurent_step@outlook.fr>",
    "url": "https://github.com/stla/Carlson",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1153,
    "package_name": "CatReg",
    "title": "Solution Paths for Linear and Logistic Regression Models with\nCategorical Predictors, with SCOPE Penalty",
    "description": "Computes solutions for linear and logistic regression models with potentially high-dimensional categorical predictors. This is done by applying a nonconvex penalty (SCOPE) and computing solutions in an efficient path-wise fashion. The scaling of the solution paths is selected automatically. Includes functionality for selecting tuning parameter lambda by k-fold cross-validation and early termination based on information criteria. Solutions are computed by cyclical block-coordinate descent, iterating an innovative dynamic programming algorithm to compute exact solutions for each block.",
    "version": "2.0.4",
    "maintainer": "Daniel Grose <dan.grose@lancaster.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1182,
    "package_name": "CensSpatial",
    "title": "Censored Spatial Models",
    "description": "It fits linear regression models for censored spatial data. It provides different estimation methods as the SAEM (Stochastic Approximation of Expectation Maximization) algorithm and seminaive that uses Kriging prediction to estimate the response at censored locations and predict new values at unknown locations. It also offers graphical tools for assessing the fitted model. More details can be found in Ordonez et al. (2018) <doi:10.1016/j.spasta.2017.12.001>.",
    "version": "3.6",
    "maintainer": "Alejandro Ordonez <ordonezjosealejandro@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1254,
    "package_name": "Ckmeans.1d.dp",
    "title": "Optimal, Fast, and Reproducible Univariate Clustering",
    "description": "Fast, optimal, and reproducible weighted univariate\n clustering by dynamic programming. Four problems are solved, including\n univariate k-means (Wang & Song 2011) <doi:10.32614/RJ-2011-015>\n (Song & Zhong 2020) <doi:10.1093/bioinformatics/btaa613>, k-median,\n k-segments, and multi-channel weighted k-means. Dynamic programming\n is used to minimize the sum of (weighted) within-cluster distances\n using respective metrics. Its advantage over heuristic clustering in\n efficiency and accuracy is pronounced when there are many clusters.\n Multi-channel weighted k-means groups multiple univariate\n signals into k clusters. An auxiliary function generates histograms\n adaptive to patterns in data. This package provides a powerful set\n of tools for univariate data analysis with guaranteed optimality,\n efficiency, and reproducibility, useful for peak calling on temporal,\n spatial, and spectral data.",
    "version": "4.3.5",
    "maintainer": "Joe Song <joemsong@cs.nmsu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1274,
    "package_name": "ClimaRep",
    "title": "Estimating Climate Representativeness",
    "description": "Offers tools to estimate the climate representativeness of reference polygons and quantifies its transformation under future climate change scenarios. Approaches described in Mingarro and Lobo (2018) <doi:10.32800/abc.2018.41.0333> and Mingarro and Lobo (2022) <doi:10.1017/S037689292100014X>.",
    "version": "1.0",
    "maintainer": "Mario Mingarro <mario_mingarro@mncn.csic.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1278,
    "package_name": "ClinicalUtilityRecal",
    "title": "Recalibration Methods for Improved Clinical Utility of Risk\nScores",
    "description": "Recalibrate risk scores (predicting binary outcomes) to improve clinical utility of risk score using weighted logistic or constrained logistic recalibration methods. Additionally, produces plots to assess the potential for recalibration to improve the clinical utility of a risk model. Methods are described in detail in Mishra, A. (2019) \"Methods for Risk Markers that Incorporate Clinical Utility\" <http://hdl.handle.net/1773/44068>.",
    "version": "0.1.0",
    "maintainer": "Anu Mishra <anmishra@uw.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1294,
    "package_name": "ClustGeo",
    "title": "Hierarchical Clustering with Spatial Constraints",
    "description": "Implements a Ward-like hierarchical clustering\n    algorithm including soft spatial/geographical constraints.",
    "version": "2.1",
    "maintainer": "Marie Chavent <Marie.Chavent@u-bordeaux.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1321,
    "package_name": "CoRpower",
    "title": "Power Calculations for Assessing Correlates of Risk in Clinical\nEfficacy Trials",
    "description": "Calculates power for assessment of intermediate biomarker responses as correlates of risk in the active treatment group in clinical efficacy trials, as described in Gilbert, Janes, and Huang, Power/Sample Size Calculations for Assessing Correlates of Risk in Clinical Efficacy Trials (2016, Statistics in Medicine). The methods differ from past approaches by accounting for the level of clinical treatment efficacy overall and in biomarker response subgroups, which enables the correlates of risk results to be interpreted in terms of potential correlates of efficacy/protection. The methods also account for inter-individual variability of the observed biomarker response that is not biologically relevant (e.g., due to technical measurement error of the laboratory assay used to measure the biomarker response), which is important because power to detect a specified correlate of risk effect size is heavily affected by the biomarker's measurement error. The methods can be used for a general binary clinical endpoint model with a univariate dichotomous, trichotomous, or continuous biomarker response measured in active treatment recipients at a fixed timepoint after randomization, with either case-cohort Bernoulli sampling or case-control without-replacement sampling of the biomarker (a baseline biomarker is handled as a trivial special case). In a specified two-group trial design, the computeN() function can initially be used for calculating additional requisite design parameters pertaining to the target population of active treatment recipients observed to be at risk at the biomarker sampling timepoint. Subsequently, the power calculation employs an inverse probability weighted logistic regression model fitted by the tps() function in the 'osDesign' package. Power results as well as the relationship between the correlate of risk effect size and treatment efficacy can be visualized using various plotting functions. To link power calculations for detecting a correlate of risk and a correlate of treatment efficacy, a baseline immunogenicity predictor (BIP) can be simulated according to a specified classification rule (for dichotomous or trichotomous BIPs) or correlation with the biomarker response (for continuous BIPs), then outputted along with biomarker response data under assignment to treatment, and clinical endpoint data for both treatment and placebo groups.",
    "version": "1.0.4",
    "maintainer": "Michal Juraska <mjuraska@fredhutch.org>",
    "url": "https://github.com/mjuraska/CoRpower",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1325,
    "package_name": "CoastCR",
    "title": "Coastal Changes Estimation Based on Baseline and Transect Approach",
    "description": "Computing coastline time series and trend analysis using the",
    "version": "1.2.0",
    "maintainer": "Alejandro Gomez-Pazo <a.gomez@usc.es>",
    "url": "https://github.com/alejandro-gomez/CoastCR",
    "exports": [],
    "topics": ["climate-change", "coastal-change", "coastal-dynamics", "coastal-engineering", "coastal-modelling", "gis"],
    "score": "NA",
    "stars": 12
  },
  {
    "id": 1350,
    "package_name": "CommEcol",
    "title": "Community Ecology Analyses",
    "description": "Autosimilarity curves, standardization of spatial extent, dissimilarity indexes that overweight rare species, phylogenetic and functional (pairwise and multisample) dissimilarity indexes and nestedness for phylogenetic, functional and other diversity metrics. The methods for phylogenetic and functional nestedness is described in Melo, Cianciaruso and Almeida-Neto (2014) <doi:10.1111/2041-210X.12185>. This should be a complement to available packages, particularly 'vegan'. ",
    "version": "1.8.1",
    "maintainer": "Adriano Sanches Melo <asm.adrimelo@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1378,
    "package_name": "CompositionalSR",
    "title": "Spatial Regression Models with Compositional Data",
    "description": "Spatial regression models with compositional responses using the alpha--transformation. Relevant papers include: Tsagris M. (2025), <doi:10.48550/arXiv.2510.12663>, Tsagris M. (2015), <https://soche.cl/chjs/volumes/06/02/Tsagris(2015).pdf>, Tsagris M.T., Preston S. and Wood A.T.A. (2011), <doi:10.48550/arXiv.1106.1451>. ",
    "version": "1.0",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1393,
    "package_name": "ConfMatrix",
    "title": "Confusion Matrix",
    "description": "Thematic quality indices are provided to facilitate the evaluation\n    and quality control of geospatial data products (e.g. thematic maps, remote\n    sensing classifications, etc.). The indices offered are based on the\n    so-called confusion matrix. This matrix is constructed by comparing the\n    assigned classes or attributes of a set of pairs of positions or objects\n    in the product and the ground truth. In this package it is considered that\n    the classes of the ground truth correspond to the columns and that the\n    classes of the product to be valued correspond to the rows. The package\n    offers two object classes with their methods: 'ConfMatrix' (Confusion\n    matrix) and 'QCCS' (Quality Control Columns Set). The 'ConfMatrix' class of\n    objects offers more than 20 methods based on the confusion matrix. The\n    'QCCS' class of objects offers a different perspective in which the ground\n    truth is considered to allow the values of the column marginals to be fixed,\n    see Ariza López et al. (2019) <doi:10.3390/app9204240> and Canran Liu et al.\n    (2007) <doi:10.1016/j.rse.2006.10.010> for more details. The package was\n    created with 'R6'.",
    "version": "0.1.0",
    "maintainer": "Silverio Vilchez-Lopez <svilchez@ujaen.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1425,
    "package_name": "CopernicusDEM",
    "title": "Copernicus Digital Elevation Models",
    "description": "Copernicus Digital Elevation Model datasets (DEM) of 90 and 30 meters resolution using the 'awscli' command line tool. The Copernicus (DEM) is included in the Registry of Open Data on 'AWS (Amazon Web Services)' and represents the surface of the Earth including buildings, infrastructure and vegetation.",
    "version": "1.0.5",
    "maintainer": "Lampros Mouselimis <mouselimislampros@gmail.com>",
    "url": "https://github.com/mlampros/CopernicusDEM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1430,
    "package_name": "CopulaCenR",
    "title": "Copula-Based Regression Models for Multivariate Censored Data",
    "description": "Copula-based regression models for multivariate censored data, including \n bivariate right-censored data, bivariate interval-censored data, and right/interval-censored \n semi-competing risks data. Currently supports Clayton, Gumbel, Frank, Joe, AMH and \n Copula2 copula models. For marginal models, it supports parametric (Weibull, Loglogistic, \n Gompertz) and semiparametric (Cox and transformation) models. Includes methods for \n convenient prediction and plotting. Also provides a bivariate time-to-event simulation \n function and an information ratio-based goodness-of-fit test for copula. Method details \n can be found in Sun et.al (2019) Lifetime Data Analysis, Sun et.al (2021) Biostatistics, \n Sun et.al (2022) Statistical Methods in Medical Research, Sun et.al (2022) Biometrics, and\n Sun et al. (2023+) JRSSC.",
    "version": "1.2.4",
    "maintainer": "Tao Sun <sun.tao@ruc.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1478,
    "package_name": "CrossExpression",
    "title": "Cross-Expression Analysis of Spatial Transcriptomics Data",
    "description": "Analyzes spatial transcriptomic data using cells-by-genes and cell location matrices to find gene pairs that coordinate their expression between spatially adjacent cells. It enables quantitative analysis and graphical assessment of these cross-expression patterns. See Sarwar et al. (2025) <doi:10.1101/2024.09.17.613579> and <https://github.com/gillislab/CrossExpression/> for more details.",
    "version": "1.0.0",
    "maintainer": "Ameer Sarwar <dogar.ameer@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1509,
    "package_name": "D3mirt",
    "title": "Descriptive 3D Multidimensional Item Response Theory Modelling",
    "description": "For identifying, estimating, and plotting descriptive multidimensional item response theory models, restricted to 3D and dichotomous or polytomous data that fit the two-parameter logistic model or the graded response model. The method is foremost explorative and centered around the plot function that exposes item characteristics and constructs, represented by vector arrows, located in a three-dimensional interactive latent space. The results can be useful for item-level analysis as well as test development.",
    "version": "2.0.4",
    "maintainer": "Erik Forsberg <forsbergpsychometrics@gmail.com>",
    "url": "https://github.com/ForsbergPyschometrics/D3mirt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1554,
    "package_name": "DCluster",
    "title": "Functions for the Detection of Spatial Clusters of Diseases",
    "description": "A set of functions for the detection of spatial clusters\n        of disease using count data. Bootstrap is used to estimate\n        sampling distributions of statistics.",
    "version": "0.2-10",
    "maintainer": "Virgilio Gómez-Rubio <Virgilio.Gomez@uclm.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1555,
    "package_name": "DClusterm",
    "title": "Model-Based Detection of Disease Clusters",
    "description": "Model-based methods for the detection of disease clusters\n  using GLMs, GLMMs and zero-inflated models. These methods are described\n  in 'V. Gómez-Rubio et al.' (2019) <doi:10.18637/jss.v090.i14> and\n  'V. Gómez-Rubio et al.' (2018) <doi:10.1007/978-3-030-01584-8_1>.",
    "version": "1.0-2",
    "maintainer": "Virgilio Gomez-Rubio <virgilio.gomez@uclm.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1560,
    "package_name": "DDM",
    "title": "Death Registration Coverage Estimation",
    "description": "A set of three two-census methods to the estimate the degree of death registration coverage for a population. Implemented methods include the Generalized Growth Balance method (GGB), the Synthetic Extinct Generation method (SEG), and a hybrid of the two, GGB-SEG. Each method offers automatic estimation, but users may also specify exact parameters or use a graphical interface to guess parameters in the traditional way if desired.",
    "version": "1.0-0",
    "maintainer": "Tim Riffe <riffe@demogr.mpg.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1582,
    "package_name": "DEPONS2R",
    "title": "Read, Plot and Analyse Output from the DEPONS Model",
    "description": "Methods for analyzing population dynamics and movement tracks simulated using the DEPONS model <https://www.depons.eu> (v.3.0), for manipulating input raster files, shipping routes and for analyzing sound propagated from ships.",
    "version": "1.2.8",
    "maintainer": "Jacob Nabe-Nielsen <jnn@ecos.au.dk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1619,
    "package_name": "DHSr",
    "title": "Create Large Scale Repeated Regression Summary Statistics\nDataset and Visualization Seamlessly",
    "description": "Mapping, spatial analysis, and statistical modeling of microdata from sources such as the Demographic and Health Surveys <https://www.dhsprogram.com/> and Integrated Public Use Microdata Series <https://www.ipums.org/>. It can also be extended to other datasets. The package supports spatial correlation index construction and visualization, along with empirical Bayes approximation of regression coefficients in a multistage setup.  The main functionality is repeated regression — for example, if we have to run regression for n groups, the group ID should be vertically composed into the variable for the parameter `location_var`. It can perform various kinds of regression, such as Generalized Regression Models, logit, probit, and more. Additionally, it can incorporate interaction effects. The key benefit of the package is its ability to store the regression results performed repeatedly on a dataset by the group ID, along with respective p-values and map those estimates. ",
    "version": "0.1.0",
    "maintainer": "Arnab Samanta <arnob.shamanta62@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1627,
    "package_name": "DIFM",
    "title": "Dynamic ICAR Spatiotemporal Factor Models",
    "description": "Bayesian factor models are effective tools for dimension reduction. This is especially applicable to multivariate large-scale datasets. It allows researchers to understand the latent factors of the data which are the linear or non-linear combination of the variables. Dynamic Intrinsic Conditional Autocorrelative Priors (ICAR) Spatiotemporal Factor Models 'DIFM' package provides function to run Markov Chain Monte Carlo (MCMC), evaluation methods and visual plots from Shin and Ferreira (2023)<doi:10.1016/j.spasta.2023.100763>. Our method is a class of Bayesian factor model which can account for spatial and temporal correlations. By incorporating these correlations, the model can capture specific behaviors and provide predictions. ",
    "version": "1.0.1",
    "maintainer": "Hwasoo Shin <hshin2@hfhs.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1642,
    "package_name": "DIconvex",
    "title": "Finding Patterns of Monotonicity and Convexity in Data",
    "description": "Given  an initial set of points, this package minimizes the number of elements to discard from this set such that there exists at least one monotonic and convex mapping within pre-specified upper and lower bounds.",
    "version": "1.0.0",
    "maintainer": "Liudmila Karagyaur <liudmila.karagyaur@usi.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1663,
    "package_name": "DMTL",
    "title": "Tools for Applying Distribution Mapping Based Transfer Learning",
    "description": "\n\tImplementation of a transfer learning framework employing distribution mapping based domain transfer. Uses the renowned concept of histogram matching (see Gonzalez and Fittes (1977) <doi:10.1016/0094-114X(77)90062-3>, Gonzalez and Woods (2008) <isbn:9780131687288>) and extends it to include distribution measures like kernel density estimates (KDE; see Wand and Jones (1995) <isbn:978-0-412-55270-0>, Jones et al. (1996) <doi:10.2307/2291420). In the typical application scenario, one can use the underlying sample distributions (histogram or KDE) to generate a map between two distinct but related domains to transfer the target data to the source domain and utilize the available source data for better predictive modeling design. Suitable for the case where a one-to-one sample matching is not possible, thus one needs to transform the underlying data distribution to utilize the more available data for modeling. ",
    "version": "0.1.2",
    "maintainer": "Saugato Rahman Dhruba <dhruba018@gmail.com>",
    "url": "https://github.com/dhruba018/DMTL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1676,
    "package_name": "DNMF",
    "title": "Discriminant Non-Negative Matrix Factorization",
    "description": "Discriminant Non-Negative Matrix Factorization aims to extend the Non-negative Matrix Factorization algorithm in order to extract features that enforce not only the spatial locality, but also the separability between classes in a discriminant manner. It refers to three article, Zafeiriou, Stefanos, et al. \"Exploiting discriminant information in nonnegative matrix factorization with application to frontal face verification.\" Neural Networks, IEEE Transactions on 17.3 (2006): 683-695. Kim, Bo-Kyeong, and Soo-Young Lee. \"Spectral Feature Extraction Using dNMF for Emotion Recognition in Vowel Sounds.\" Neural Information Processing. Springer Berlin Heidelberg, 2013. and Lee, Soo-Young, Hyun-Ah Song, and Shun-ichi Amari. \"A new discriminant NMF algorithm and its application to the extraction of subtle emotional differences in speech.\" Cognitive neurodynamics 6.6 (2012): 525-535.",
    "version": "1.4.2",
    "maintainer": "Zhilong Jia <zhilongjia@gmail.com>",
    "url": "https://github.com/zhilongjia/DNMF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1829,
    "package_name": "DendroSync",
    "title": "A Set of Tools for Calculating Spatial Synchrony Between\nTree-Ring Chronologies",
    "description": "Provides functions for the calculation and plotting of synchrony in \n      tree growth from tree-ring width chronologies (TRW index). It combines\n      variance-covariance (VCOV) mixed modelling with functions that quantify \n      the degree to which the TRW chronologies contain a common temporal \n      signal. It also implements temporal trends in spatial synchrony using a \n      moving window. These methods can also be used with other kind of ecological\n      variables that have temporal autocorrelation corrected.",
    "version": "0.1.5",
    "maintainer": "Josu G. Alday <josucham@gmail.com>",
    "url": "https://bitbucket.org/josucham/dendrosync/src/issues/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1856,
    "package_name": "DiSSMod",
    "title": "Fitting Sample Selection Models for Discrete Response Variables",
    "description": "Tools to fit sample selection models in case of discrete response \n  variables, through a parametric formulation which represents a natural \n  extension of the well-known Heckman selection model are provided in the \n  package. The response variable can be of Bernoulli, Poisson or Negative \n  Binomial type. The sample selection mechanism allows to choose among a \n  Normal, Logistic or Gumbel distribution.",
    "version": "1.0.0",
    "maintainer": "Sang Kyu Lee <lsk0816@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1890,
    "package_name": "DisasterAlert",
    "title": "Disaster Alert and Sentiment Analysis",
    "description": "By systematically aggregating and processing textual reports from earthquakes, floods, storms,\n  wildfires, and other natural disasters, the framework enables a holistic assessment of crisis narratives.  \n  Intelligent cleaning and normalization techniques transform raw commentary into structured data, ensuring\n  precise extraction of disaster-specific insights. Collective sentiments of affected communities are  \n  quantitatively scored and qualitatively categorized, providing a multifaceted view of societal responses  \n  under duress. Interactive geographic maps and temporal charts illustrate the evolution and spatial dispersion\n  of emotional reactions and impact indicators. ",
    "version": "1.0.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 1957,
    "package_name": "DynClust",
    "title": "Denoising and Clustering for Dynamical Image Sequence (2D or\n3D)+t",
    "description": "A two-stage procedure for the denoising and clustering of stack of noisy images acquired over time. Clustering only assumes that the data contain an unknown but small number of dynamic features. The method first denoises the signals using local spatial and full temporal information. The clustering step uses the previous output to aggregate voxels based on the knowledge of their spatial neighborhood. Both steps use a single keytool based on the statistical comparison of the difference of two signals with the null signal. No assumption is therefore required on the shape of the signals. The data are assumed to be normally distributed (or at least follow a symmetric distribution) with a known constant variance. Working pixelwise, the method can be time-consuming depending on the size of the data-array but harnesses the power of multicore cpus.",
    "version": "3.24",
    "maintainer": "Yves Rozenholc <yves.rozenholc@u-paris.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2021,
    "package_name": "EIAapi",
    "title": "Query Data from the 'EIA' API",
    "description": "Provides a function to query and extract data from the 'US Energy Information Administration' ('EIA') API V2  <https://www.eia.gov/opendata/>. The 'EIA' API provides a variety of information, in a time series format, about the energy sector in the US. The API is open, free, and requires an access key and registration at <https://www.eia.gov/opendata/>.",
    "version": "0.2.0",
    "maintainer": "Rami Krispin <rami.krispin@gmail.com>",
    "url": "https://github.com/RamiKrispin/EIAapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2022,
    "package_name": "EIEntropy",
    "title": "Ecological Inference Applying Entropy",
    "description": "Implements two estimations related to the foundations of info metrics applied to ecological inference. These methodologies assess the lack of disaggregated data and provide an approach to obtaining disaggregated territorial-level data. For more details, see the following references: Fernández-Vázquez, E., Díaz-Dapena, A., Rubiera-Morollón, F. et al. (2020) \"Spatial Disaggregation of Social Indicators: An Info-Metrics Approach.\" <doi:10.1007/s11205-020-02455-z>. Díaz-Dapena, A., Fernández-Vázquez, E., Rubiera-Morollón, F., & Vinuela, A. (2021) \"Mapping poverty at the local level in Europe: A consistent spatial disaggregation of the AROPE indicator for France, Spain, Portugal and the United Kingdom.\" <doi:10.1111/rsp3.12379>.",
    "version": "0.0.1.4",
    "maintainer": "Silvia María Franco Anaya <sfrana@unileon.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2024,
    "package_name": "EJAM",
    "title": "Environmental Justice Analysis Multisite tool",
    "description": "Actively maintained non-EPA version of EJAM, the web app",
    "version": "2.32.6.003",
    "maintainer": "Mark A. Corrales <ejam@ejanalysis.com>",
    "url": "https://github.com/ejanalysis/EJAM",
    "exports": [],
    "topics": ["census-block-group", "census-blocks", "census-data", "climate-data", "demographic-analysis", "demographics-data", "disparities", "disparity-maps", "ej", "environmental", "environmental-data", "ethnicity", "gis", "gis-data", "mapping-tools", "open-source", "poverty-mapping", "r", "racial", "shiny"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 2029,
    "package_name": "ELISAtools",
    "title": "ELISA Data Analysis with Batch Correction",
    "description": "To run data analysis for enzyme-link immunosorbent assays (ELISAs). \n\tEither the five- or four-parameter logistic model will be fitted for data of single ELISA. \n\tMoreover, the batch effect correction/normalization will be carried out, when there are more than one batches of ELISAs. \n\tFeng (2018) <doi:10.1101/483800>.",
    "version": "0.1.8",
    "maintainer": "Feng Feng <ffeng@BU.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2058,
    "package_name": "EMSNM",
    "title": "EM Algorithm for Sigmoid Normal Model",
    "description": "It provides a method based on EM algorithm to estimate the parameter of a mixture model, Sigmoid-Normal Model, where the samples come from several normal distributions (also call them subgroups) whose mean is determined by co-variable Z and coefficient alpha while the variance are homogeneous. Meanwhile, the subgroup each item belongs to is determined by co-variables X and coefficient eta through Sigmoid link function which is the extension of Logistic Link function. It uses bootstrap to estimate the standard error of parameters. When sample is indeed separable, removing estimation with abnormal sigma, the estimation of alpha is quite well. I used this method to explore the subgroup structure of HIV patients and it can be used in other domains where exists subgroup structure.",
    "version": "1.0",
    "maintainer": "Linsui Deng <denglinsui@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2066,
    "package_name": "ENMeval",
    "title": "Automated Tuning and Evaluations of Ecological Niche Models",
    "description": "Runs ecological niche models over all combinations of user-defined settings (i.e., tuning), performs cross validation to evaluate models, and returns data tables to aid in selection of optimal model settings that balance goodness-of-fit and model complexity. Also has functions to partition data spatially (or not) for cross validation, to plot multiple visualizations of results, to run null models to estimate significance and effect sizes of performance metrics, and to calculate range overlap between model predictions, among others. The package was originally built for Maxent models (Phillips et al. 2006, Phillips et al. 2017), but the current version allows possible extensions for any modeling algorithm. The extensive vignette, which guides users through most package functionality but unfortunately has a file size too big for CRAN, can be found here on the package's Github Pages website: <https://jamiemkass.github.io/ENMeval/articles/ENMeval-2.0-vignette.html>.",
    "version": "2.0.5.2",
    "maintainer": "Jamie M. Kass <jamie.m.kass@gmail.com>",
    "url": "https://jamiemkass.github.io/ENMeval/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2120,
    "package_name": "EcoCleanR",
    "title": "Automated and Controlled Extraction, Cleaning, and Processing of\nOccurrence Data for Generating Biogeographic Ranges of Marine\nOrganisms",
    "description": "Provides step-by-step automation for integrating biodiversity data from multiple online aggregators, merging and cleaning datasets while addressing challenges such as taxonomic inconsistencies, georeferencing issues, and spatial or environmental outliers. Includes functions to extract environmental data and to define the biogeographic ranges in which species are most likely to occur.",
    "version": "1.0.1",
    "maintainer": "Priyanka Soni <sonip@usc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2140,
    "package_name": "EgoCor",
    "title": "Simple Presentation of Estimated Exponential Semi-Variograms",
    "description": "User friendly interface based on the R package 'gstat' to fit\n    exponential parametric models to empirical semi-variograms in order to\n    model the spatial correlation structure of health data. Geo-located\n    health outcomes of survey participants may be used to model spatial\n    effects on health in an ego-centred approach.  The package contains a\n    range of functions to help explore the spatial structure of the data\n    as well as visualize the fit of exponential models for various\n    metaparameter combinations with respect to the number of lag intervals\n    and maximal distance.  Furthermore, the outcome of interest can be\n    adjusted for covariates by fitting a linear regression in a\n    preliminary step before the semi-variogram fitting process.",
    "version": "1.3.4",
    "maintainer": "Julia Dyck <j.dyck@uni-bielefeld.de>",
    "url": "https://github.com/julia-dyck/EgoCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2144,
    "package_name": "Elja",
    "title": "Linear, Logistic and Generalized Linear Models Regressions for\nthe EnvWAS/EWAS Approach",
    "description": "Tool for Environment-Wide Association Studies (EnvWAS / EWAS) \n    which are repeated analysis. It includes three functions. One function for\n    linear regression, a second for logistic regression and a last one for\n    generalized linear models.",
    "version": "1.0.0",
    "maintainer": "Marwan El Homsi <marwan.el-homsi@inserm.fr>",
    "url": "https://github.com/EHMarwan/Elja",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2206,
    "package_name": "EquiSurv",
    "title": "Modeling, Confidence Intervals and Equivalence of Survival\nCurves",
    "description": "We provide a non-parametric and a parametric approach to investigate the equivalence (or non-inferiority) of two survival curves, obtained from two given datasets. The test is based on the creation of confidence intervals at pre-specified time points.\n    For the non-parametric approach, the curves are given by Kaplan-Meier curves and the variance for calculating the confidence intervals is obtained by Greenwood's formula.\n    The parametric approach is based on estimating the underlying distribution, where the user can choose between a Weibull, Exponential, Gaussian, Logistic, Log-normal or a Log-logistic distribution. Estimates for the variance for calculating the confidence bands are obtained by a (parametric) bootstrap approach. For this bootstrap censoring is assumed to be exponentially distributed and estimates are obtained from the datasets under consideration.\n    All details can be found in K.Moellenhoff and A.Tresch: Survival analysis under non-proportional hazards: investigating non-inferiority or equivalence in time-to-event data <arXiv:2009.06699>.",
    "version": "0.1.0",
    "maintainer": "Kathrin Moellenhoff <kathrin.moellenhoff@rub.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2249,
    "package_name": "ExceedanceTools",
    "title": "Confidence/Credible Regions for Exceedance Sets and Contour\nLines",
    "description": "Provides methods for constructing confidence or credible regions\n    for exceedance sets and contour lines.",
    "version": "1.3.6",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2266,
    "package_name": "ExplodeLayout",
    "title": "Calculate Exploded Coordinates Based on Original Node\nCoordinates and Node Clustering Membership",
    "description": "Current layout algorithms such as Kamada Kawai do not take into consideration disjoint clusters in a network, often resulting in a high overlap among the clusters, resulting in a visual “hairball” that often is uninterpretable. The ExplodeLayout algorithm takes as input (1) an edge list of a unipartite or bipartite network, (2) node layout coordinates (x, y) generated by a layout algorithm such as Kamada Kawai, (3) node cluster membership generated from a clustering algorithm such as modularity maximization, and (4) a radius to enable the node clusters to be “exploded” to reduce their overlap. The algorithm uses these inputs to generate new layout coordinates of the nodes which “explodes” the clusters apart, such that the edge lengths within the clusters are preserved, while the edge lengths between clusters are recalculated. The modified network layout with nodes and edges are displayed in two dimensions. The user can experiment with different explode radii to generate a layout which has sufficient separation of clusters, while reducing the overall layout size of the network. This package is a basic version of an earlier version called [epl]<https://github.com/UTMB-DIVA-Lab/epl> that searched for an optimal explode radius, and offered multiple ways to separate clusters in a network (Bhavnani et al(2017) <https://pmc.ncbi.nlm.nih.gov/articles/PMC5543384/>). The example dataset is for a bipartite network, but the algorithm can work also for unipartite networks.",
    "version": "0.1.3",
    "maintainer": "Weibin Zhang  <weibzhan@utmb.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2270,
    "package_name": "ExtDist",
    "title": "Extending the Range of Functions for Probability Distributions",
    "description": "A consistent, unified and extensible\n    framework for estimation of parameters for probability distributions,\n    including parameter estimation procedures that allow for weighted samples;\n    the current set of distributions included are: the standard beta,\n    The four-parameter beta, Burr, gamma, Gumbel, Johnson SB and SU, Laplace,\n    logistic, normal, symmetric truncated normal, truncated normal,\n    symmetric-reflected truncated beta, standard symmetric-reflected truncated\n    beta, triangular, uniform, and Weibull distributions; decision criteria\n    and selections based on these decision criteria.",
    "version": "0.7-4",
    "maintainer": "Oleksii Nikolaienko <oleksii.nikolaienko@gmail.com>",
    "url": "https://github.com/oleksii-nikolaienko/ExtDist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2274,
    "package_name": "ExtrPatt",
    "title": "Spatial Dependencies and Indices for Extremes",
    "description": "An implementation of \n              1) the tail pairwise dependence matrix (TPDM) as described in Jiang & Cooley (2020) <doi:10.1175/JCLI-D-19-0413.1>  \n              2) the extremal pattern index (EPI) as described in Szemkus & Friederichs ('Spatial patterns and indices for heatwave and droughts over Europe using a decomposition of extremal dependency'; submitted to ASCMO 2023). ",
    "version": "0.1-4",
    "maintainer": "Svenja Szemkus <sszemkus@uni-bonn.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2275,
    "package_name": "ExtractTrainData",
    "title": "Extract Values from Raster",
    "description": "By using a multispectral image and ESRI shapefile (Point/ Line/ Polygon), a data table will be generated for classification, regression or other processing. The data table will be contained by band wise raster values and shapefile ids (User Defined).",
    "version": "9.1.6",
    "maintainer": "Subhadip Datta <subhadipdatta007@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2276,
    "package_name": "ExtremalDep",
    "title": "Extremal Dependence Models",
    "description": "A set of procedures for parametric and non-parametric modelling of the dependence structure of multivariate extreme-values is provided. The statistical inference is performed with non-parametric estimators, likelihood-based estimators and Bayesian techniques. It adapts the methodologies of Beranger and Padoan (2015) <doi:10.48550/arXiv.1508.05561>, Marcon et al. (2016) <doi:10.1214/16-EJS1162>, Marcon et al. (2017) <doi:10.1002/sta4.145>, Marcon et al. (2017) <doi:10.1016/j.jspi.2016.10.004> and Beranger et al. (2021) <doi:10.1007/s10687-019-00364-0>. This package also allows for the modelling of spatial extremes using flexible max-stable processes. It provides simulation algorithms and fitting procedures relying on the Stephenson-Tawn likelihood as per Beranger at al. (2021) <doi:10.1007/s10687-020-00376-1>.",
    "version": "1.0.0",
    "maintainer": "Simone Padoan <simone.padoan@unibocconi.it>",
    "url": "https://faculty.unibocconi.it/simonepadoan/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2282,
    "package_name": "FADA",
    "title": "Variable Selection for Supervised Classification in High\nDimension",
    "description": "The functions provided in the FADA (Factor Adjusted Discriminant Analysis) package aim at performing supervised classification of high-dimensional and correlated profiles. The procedure combines a decorrelation step based on a  \n   factor modeling of the dependence among covariates and a classification method. The available methods are Lasso regularized logistic model\n    (see Friedman et al. (2010)), sparse linear discriminant analysis (see\n    Clemmensen et al. (2011)), shrinkage linear and diagonal discriminant\n    analysis (see M. Ahdesmaki et al. (2010)). More methods of classification can be used on the decorrelated data provided by the package FADA.",
    "version": "1.3.5",
    "maintainer": "David Causeur <david.causeur@agrocampus-ouest.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2321,
    "package_name": "FEprovideR",
    "title": "Fixed Effects Logistic Model with High-Dimensional Parameters",
    "description": "A structured profile likelihood algorithm for the logistic fixed effects model and an approximate expectation maximization (EM) algorithm for the logistic mixed effects model. Based on He, K., Kalbfleisch, J.D., Li, Y. and Li, Y. (2013) <doi:10.1007/s10985-013-9264-6>.",
    "version": "1.1",
    "maintainer": "Michael Kleinsasser <mkleinsa@umich.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2325,
    "package_name": "FGLMtrunc",
    "title": "Truncated Functional Generalized Linear Models",
    "description": "An implementation of the methodologies described in Xi Liu, Afshin A. Divani, and Alexander Petersen (2022) <doi:10.1016/j.csda.2022.107421>, including \n                truncated functional linear and truncated functional logistic regression models.",
    "version": "0.2.0",
    "maintainer": "Chau Tran <cbtr@ucdavis.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2333,
    "package_name": "FIESTAutils",
    "title": "Utility Functions for Forest Inventory Estimation and Analysis",
    "description": "A set of tools for data wrangling, spatial data analysis,\n    statistical modeling (including direct, model-assisted, photo-based, and\n    small area tools), and USDA Forest Service data base tools. These tools are\n    aimed to help Foresters, Analysts, and Scientists extract and perform\n    analyses on USDA Forest Service data.",
    "version": "1.3.2",
    "maintainer": "Grayson White <graysonwhite13@gmail.com>",
    "url": "https://github.com/USDAForestService/FIESTAutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2349,
    "package_name": "FLSSS",
    "title": "Mining Rigs for Problems in the Subset Sum Family",
    "description": "Specialized solvers for combinatorial optimization problems in the Subset Sum family. The solvers differ from the mainstream in the options of (i) restricting subset size, (ii) bounding subset elements, (iii) mining real-value multisets with predefined subset sum errors, (iv) finding one or more subsets in limited time. A novel algorithm for mining the one-dimensional Subset Sum induced algorithms for the multi-Subset Sum and the multidimensional Subset Sum. The multi-threaded framework for the latter offers exact algorithms to the multidimensional Knapsack and the Generalized Assignment problems. Historical updates include (a) renewed implementation of the multi-Subset Sum, multidimensional Knapsack and Generalized Assignment solvers; (b) availability of bounding solution space in the multidimensional Subset Sum; (c) fundamental data structure and architectural changes for enhanced cache locality and better chance of SIMD vectorization; (d) option of mapping floating-point instance to compressed 64-bit integer instance with user-controlled precision loss, which could yield substantial speedup due to the dimension reduction and efficient compressed integer arithmetic via bit-manipulations; (e) distributed computing infrastructure for multidimensional subset sum; (f) arbitrary-precision zero-margin-of-error multidimensional Subset Sum accelerated by a simplified Bloom filter. The package contains a copy of 'xxHash' from <https://github.com/Cyan4973/xxHash>. Package vignette (<doi:10.48550/arXiv.1612.04484>) detailed a few historical updates. Functions prefixed with 'aux' (auxiliary) are independent implementations of published algorithms for solving optimization problems less relevant to Subset Sum.",
    "version": "9.2.8",
    "maintainer": "Charlie Wusuo Liu <liuwusuo@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2378,
    "package_name": "FRESA.CAD",
    "title": "Feature Selection Algorithms for Computer Aided Diagnosis",
    "description": "Contains a set of utilities for building and testing statistical models (linear, logistic,ordinal or COX) for Computer Aided Diagnosis/Prognosis applications. Utilities include data adjustment, univariate analysis, model building, model-validation, longitudinal analysis, reporting and visualization.",
    "version": "3.4.8",
    "maintainer": "Jose Gerardo Tamez-Pena <jose.tamezpena@tec.mx>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2381,
    "package_name": "FRK",
    "title": "Fixed Rank Kriging",
    "description": "A tool for spatial/spatio-temporal modelling and prediction with large datasets. The approach models the field, and hence the covariance function, using a set of basis functions. This fixed-rank basis-function representation facilitates the modelling of big data, and the method naturally allows for non-stationary, anisotropic covariance functions. Discretisation of the spatial domain into so-called basic areal units (BAUs) facilitates the use of observations with varying support (i.e., both point-referenced and areal supports, potentially simultaneously), and prediction over arbitrary user-specified regions. `FRK` also supports inference over various manifolds, including the 2D plane and 3D sphere, and it provides helper functions to model, fit, predict, and plot with relative ease. Version 2.0.0 and above also supports the modelling of non-Gaussian data (e.g., Poisson, binomial, negative-binomial, gamma, and inverse-Gaussian) by employing a generalised linear mixed model (GLMM) framework. Zammit-Mangion and Cressie <doi:10.18637/jss.v098.i04> describe `FRK` in a Gaussian setting, and detail its use of basis functions and BAUs, while Sainsbury-Dale, Zammit-Mangion, and Cressie <doi:10.18637/jss.v108.i10> describe `FRK` in a non-Gaussian setting; two vignettes are available that summarise these papers and provide additional examples.",
    "version": "2.3.1",
    "maintainer": "Andrew Zammit-Mangion <andrewzm@gmail.com>",
    "url": "https://andrewzm.github.io/FRK/, https://github.com/andrewzm/FRK/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2398,
    "package_name": "FaaSr",
    "title": "FaaS (Function as a Service) Package",
    "description": "Allows users to create and deploy the workflow with multiple functions\n    in Function-as-a-Service (FaaS) cloud computing platforms.\n    The 'FaaSr' package makes it simpler for R developers to use FaaS platforms by providing the following functionality:\n    1) Parsing and validating a JSON-based payload compliant to 'FaaSr' schema supporting multiple FaaS platforms\n    2) Invoking user functions written in R in a Docker container (derived from rocker), using a list generated from\n       the parser as argument\n    3) Downloading/uploading of files from/to S3 buckets using simple primitives\n    4) Logging to files in S3 buckets\n    5) Triggering downstream actions supporting multiple FaaS platforms\n    6) Generating FaaS-specific API calls to simplify the registering of a user's workflow with a FaaS platform\n    Supported FaaS platforms:\n    Apache OpenWhisk <https://openwhisk.apache.org/>\n    GitHub Actions <https://github.com/features/actions>\n    Amazon Web Services (AWS) Lambda <https://aws.amazon.com/lambda/>\n    Supported cloud data storage for persistent storage:\n    Amazon Web Services (AWS) Simple Storage Service (S3) <https://aws.amazon.com/s3/>.",
    "version": "1.4.4",
    "maintainer": "Figueiredo Renato <renato.figueiredo@oregonstate.edu>",
    "url": "https://github.com/FaaSr/FaaSr-package",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2401,
    "package_name": "FactoClass",
    "title": "Combination of Factorial Methods and Cluster Analysis",
    "description": "Some functions of 'ade4' and 'stats' are combined in order to obtain \n             a partition of the rows of a data table, with columns representing \n             variables of scales: quantitative, qualitative or frequency. \n             First, a principal axes method is performed and then, a combination \n             of Ward agglomerative hierarchical classification and K-means is \n             performed, using some of the first coordinates obtained from the \n             previous principal axes method. \n             In order to permit different weights of the elements to be clustered, \n             the function 'kmeansW', programmed in C++, is included. \n             It is a modification of 'kmeans'. Some graphical functions include \n             the option: 'gg=FALSE'.  When 'gg=TRUE', they  use the 'ggplot2' \n             and 'ggrepel' packages to avoid  the super-position of the labels.   ",
    "version": "1.2.9",
    "maintainer": "Campo Elias Pardo <cepardot@unal.edu.co>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2407,
    "package_name": "FactorHet",
    "title": "Estimate Heterogeneous Effects in Factorial Experiments Using\nGrouping and Sparsity",
    "description": "Estimates heterogeneous effects in factorial (and conjoint)\n    models. The methodology employs a Bayesian finite mixture of\n    regularized logistic regressions, where moderators can affect each\n    observation's probability of group membership and a sparsity-inducing\n    prior fuses together levels of each factor while respecting\n    ANOVA-style sum-to-zero constraints. Goplerud, Imai, and Pashley\n    (2024) <doi:10.48550/ARXIV.2201.01357> provide further details.",
    "version": "1.0.0",
    "maintainer": "Max Goplerud <mgoplerud@austin.utexas.edu>",
    "url": "https://github.com/mgoplerud/FactorHet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2426,
    "package_name": "FastMapping",
    "title": "Web-based application developed to easily map within field variability",
    "description": "Software to create field maps and identify management zones in precision agriculture.",
    "version": "0.0.0.9001",
    "maintainer": "",
    "url": "https://github.com/PPaccioretti/FastMapping",
    "exports": [],
    "topics": ["r", "shiny-app", "spatial-analysis", "statistical"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 2443,
    "package_name": "FedIRT",
    "title": "Federated Item Response Theory Models",
    "description": "Integrate Item Response Theory (IRT) and Federated Learning to estimate traditional IRT models, including the 2-Parameter Logistic (2PL) and the Graded Response Models, with enhanced privacy. It allows for the estimation in a distributed manner without compromising accuracy. A user-friendly 'shiny' application is included. ",
    "version": "1.1.0",
    "maintainer": "Biying Zhou <zby.zhou@mail.utoronto.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2450,
    "package_name": "FieldSimR",
    "title": "Simulation of Plot Errors and Phenotypes in Plant Breeding Field\nTrials",
    "description": "Simulates plot data in multi-environment field trials with one or more traits. \n  Its core function generates plot errors that capture spatial trend, random error (noise), \n  and extraneous variation, which are combined at a user-defined ratio. \n  Phenotypes can be generated by combining the plot errors with simulated genetic values that capture \n  genotype-by-environment (GxE) interaction using wrapper functions for the R package `AlphaSimR`.",
    "version": "1.4.0",
    "maintainer": "Christian Werner <werner.christian@proton.me>",
    "url": "https://github.com/crWerner/fieldsimr,\nhttps://crwerner.github.io/fieldsimr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2476,
    "package_name": "FlexRL",
    "title": "A Flexible Model for Record Linkage",
    "description": "Implementation of the Stochastic Expectation Maximisation (StEM) approach to Record Linkage described in the paper by K. Robach, S. L. van der Pas, M. A. van de Wiel and M. H. Hof (2024, <doi:10.1093/jrsssc/qlaf016>); see citation(\"FlexRL\") for details. This is a record linkage method, for finding the common set of records among 2 data sources based on Partially Identifying Variables (PIVs) available in both sources. It includes modelling of dynamic Partially Identifying Variables (e.g. postal code) that may evolve over time and registration errors (missing values and mistakes in the registration). Low memory footprint.",
    "version": "0.1.1",
    "maintainer": "Kayané ROBACH <k.c.robach@amsterdamumc.nl>",
    "url": "https://github.com/robachowyk/FlexRL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2478,
    "package_name": "FlexScan",
    "title": "Flexible Scan Statistics",
    "description": "An easy way to conduct flexible scan.\n    Monte-Carlo method is used to test the spatial clusters given the cases, population, and shapefile.\n    A table with formal style and a map with clusters are included in the result report.\n    The method can be referenced at: Toshiro Tango and Kunihiko Takahashi (2005) <doi:10.1186/1476-072X-4-11>.",
    "version": "0.2.2",
    "maintainer": "Zhicheng Du <dgdzc@hotmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2504,
    "package_name": "ForestDisc",
    "title": "Forest Discretization",
    "description": "Supervised, multivariate, and non-parametric discretization algorithm based on tree ensembles learning and moment matching optimization. This version of the algorithm relies on random forest algorithm to learn a large set of split points that conserves the relationship between attributes and the target class, and on moment matching optimization to transform this set into a reduced number of cut points matching as well as possible statistical properties of the initial set of split points. For each attribute to be discretized, the set S of its related split points extracted through random forest is mapped to a reduced set C of cut points of size k. This mapping relies on minimizing, for each continuous attribute to be discretized, the distance between the four first moments of S and the four first moments of C subject to some constraints. This non-linear optimization problem is performed using k values ranging from 2 to 'max_splits', and the best solution returned correspond to the value k which optimum solution is the lowest one over the different realizations. ForestDisc is a generalization of RFDisc discretization method initially proposed by Berrado and Runger (2009) <doi:10.1109/AICCSA.2009.5069327>, and improved by Berrado et al. in 2012 by adopting the idea of moment matching optimization related by Hoyland and Wallace (2001) <doi: 10.1287/mnsc.47.2.295.9834>.",
    "version": "0.1.0",
    "maintainer": "Haddouchi Maïssae <maissaem7@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2520,
    "package_name": "FracKrigingR",
    "title": "Spatial Multivariate Data Modeling",
    "description": "Aim is to provide fractional Brownian vector field generation algorithm, Hurst parameter estimation method and fractional kriging model for multivariate data modeling.",
    "version": "1.0.0",
    "maintainer": "Neringa Urbonaite <neringa.urbonaite@mif.vu.lt>",
    "url": "https://github.com/NidaGreen/FracKriging",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2563,
    "package_name": "GAGAs",
    "title": "Global Adaptive Generative Adjustment Algorithm for Generalized\nLinear Models",
    "description": "Fits linear regression, logistic and multinomial regression models, Poisson regression, Cox model via Global Adaptive Generative Adjustment Algorithm.  \n For more detailed information, see Bin Wang, Xiaofei Wang and Jianhua Guo (2022) <arXiv:1911.00658>. \n This paper provides the theoretical properties of Gaga linear model when the load matrix is orthogonal. \n Further study is going on for the nonorthogonal cases and generalized linear models. \n These works are in part supported by the National Natural Foundation of China (No.12171076). ",
    "version": "0.6.2",
    "maintainer": "Bin Wang <eatingbeen@hotmail.com>",
    "url": "https://arxiv.org/abs/1911.00658",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2566,
    "package_name": "GALAHAD",
    "title": "Geometry-Adaptive Lyapunov-Assured Hybrid Optimizer",
    "description": "Implements the GALAHAD algorithm (Geometry-Adaptive \n    'Lyapunov'-Assured Hybrid Optimizer), combining 'Riemannian' metrics, \n    'Lyapunov' stability checks, and trust-region methods for stable \n    optimization of mixed-geometry parameters. Designed for biological \n    modeling (germination, dose-response, survival) where rates, \n    concentrations, and unconstrained variables coexist. Developed at \n    the Minnesota Center for Prion Research and Outreach (MNPRO), \n    University of Minnesota. Based on Conn et al. (2000) \n    <doi:10.1137/1.9780898719857>, Amari (1998) \n    <doi:10.1162/089976698300017746>, Beck & Teboulle (2003) \n    <doi:10.1016/S0167-6377(02)00231-6>, Nesterov (2017) \n    <https://www.jstor.org/stable/resrep30722>, and Walne et al. (2020) \n    <doi:10.1002/agg2.20098>.",
    "version": "1.0.0",
    "maintainer": "Richard A. Feiss <feiss026@umn.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2595,
    "package_name": "GD",
    "title": "Geographical Detectors for Assessing Spatial Factors",
    "description": "Geographical detectors for measuring spatial stratified heterogeneity,\n             as described in Jinfeng Wang (2010) <doi:10.1080/13658810802443457> and \n             Jinfeng Wang (2016) <doi:10.1016/j.ecolind.2016.02.052>. Includes the\n             optimal discretization of continuous data, four primary functions of \n             geographical detectors, comparison of size effects of spatial unit and \n             the visualizations of results. To use the package and to refer the \n             descriptions of the package, methods and case datasets, please cite \n             Yongze Song (2020) <doi:10.1080/15481603.2020.1760434>. The model has \n             been applied in factor exploration of road performance and multi-scale \n             spatial segmentation for network data, as described in \n             Yongze Song (2018) <doi:10.3390/rs10111696> and \n             Yongze Song (2020) <doi:10.1109/TITS.2020.3001193>, respectively. ",
    "version": "10.8",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://github.com/ausgis/GD, https://ausgis.github.io/GD/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2611,
    "package_name": "GEInfo",
    "title": "Gene-Environment Interaction Analysis Incorporating Prior\nInformation",
    "description": "Realize three approaches for Gene-Environment interaction analysis. All of them adopt Sparse Group Minimax Concave Penalty to identify important G variables and G-E interactions, and simultaneously respect the hierarchy between main G and G-E interaction effects. All the three approaches are available for Linear, Logistic, and Poisson regression. Also realize to mine and construct prior information for G variables and G-E interactions.",
    "version": "1.0",
    "maintainer": "Xiaoyan Wang <xywang@hnu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2623,
    "package_name": "GEOmap",
    "title": "Topographic and Geologic Mapping",
    "description": "Set of routines for making map projections (forward and inverse), topographic maps, perspective plots, geological maps, geological map symbols, geological databases, interactive plotting and selection of focus regions.",
    "version": "2.5-11",
    "maintainer": "Jonathan M. Lees <jonathan.lees@unc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2653,
    "package_name": "GGally",
    "title": "Extension to 'ggplot2'",
    "description": "The R package 'ggplot2' is a plotting system based on the\n    grammar of graphics.  'GGally' extends 'ggplot2' by adding several\n    functions to reduce the complexity of combining geometric objects with\n    transformed data.  Some of these functions include a pairwise plot\n    matrix, a two group pairwise plot matrix, a parallel coordinates plot,\n    a survival plot, and several functions to plot networks.",
    "version": "2.4.0",
    "maintainer": "Barret Schloerke <schloerke@gmail.com>",
    "url": "https://ggobi.github.io/ggally/, https://github.com/ggobi/ggally",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2661,
    "package_name": "GIFT",
    "title": "Access to the Global Inventory of Floras and Traits (GIFT)",
    "description": "Retrieving regional plant checklists, species traits and\n  distributions, and environmental data from the Global Inventory of Floras and\n  Traits (GIFT). More information about the GIFT database can be found at\n  <https://gift.uni-goettingen.de/about> and the map of available floras can be\n  visualized at <https://gift.uni-goettingen.de/map>. The API and associated\n  queries can be accessed according the following scheme:\n  <https://gift.uni-goettingen.de/api/extended/index2.0.php?query=env_raster>.",
    "version": "1.3.3",
    "maintainer": "Pierre Denelle <pierre.denelle@gmail.com>",
    "url": "https://github.com/BioGeoMacro/GIFT,\nhttps://biogeomacro.github.io/GIFT/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2668,
    "package_name": "GISINTEGRATION",
    "title": "GIS Integration",
    "description": "Designed to facilitate the preprocessing and linking of GIS (Geographic Information System) databases\n  <https://www.sciencedirect.com/topics/computer-science/gis-database>,\n  the R package 'GISINTEGRATION' offers a robust solution for efficiently preparing  GIS data for advanced \n  spatial analyses. This package excels in simplifying intrica  procedures like data cleaning, normalization, \n  and format conversion, ensuring that the data are optimally primed for precise and thorough analysis.",
    "version": "1.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2669,
    "package_name": "GISSB",
    "title": "Network Analysis on the Norwegian Road Network",
    "description": "A collection of GIS (Geographic Information System) functions in R, created for use in Statistics Norway. The functions are primarily related to network analysis on the Norwegian road network. ",
    "version": "1.1",
    "maintainer": "Sindre Mikael Haugen <sindre.haugen@ssb.no>",
    "url": "https://statisticsnorway.github.io/GISSB/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2670,
    "package_name": "GISTools",
    "title": "Further Capabilities in Geographic Information Science",
    "description": "Mapping and spatial data manipulation tools - in particular\n    drawing thematic maps with nice looking legends,  and aggregation of point\n    data to polygons.",
    "version": "1.0-2",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2677,
    "package_name": "GLCMTextures",
    "title": "GLCM Textures of Raster Layers",
    "description": "Calculates grey level co-occurrence matrix (GLCM) based texture measures (Hall-Beyer (2017) <https://prism.ucalgary.ca/bitstream/handle/1880/51900/texture%20tutorial%20v%203_0%20180206.pdf>; Haralick et al. (1973) <doi:10.1109/TSMC.1973.4309314>) of raster layers using a sliding rectangular window. It also includes functions to quantize a raster into grey levels as well as tabulate a glcm and calculate glcm texture metrics for a matrix.",
    "version": "0.6.3",
    "maintainer": "Alexander Ilich <ailich@usf.edu>",
    "url": "https://ailich.github.io/GLCMTextures/,\nhttps://github.com/ailich/GLCMTextures",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2680,
    "package_name": "GLMMRR",
    "title": "Generalized Linear Mixed Model (GLMM) for Binary Randomized\nResponse Data",
    "description": "Generalized Linear Mixed Model (GLMM) for Binary Randomized Response Data.\n    Includes Cauchit, Compl. Log-Log, Logistic, and Probit link functions for Bernoulli Distributed RR data.\n    RR Designs: Warner, Forced Response, Unrelated Question, Kuk, Crosswise, and Triangular. \n    Reference: Fox, J-P, Veen, D. and Klotzke, K. (2018). Generalized Linear Mixed Models for Randomized Responses. Methodology. <doi:10.1027/1614-2241/a000153>.",
    "version": "0.6.0",
    "maintainer": "Jean-Paul Fox <jpfox00@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2720,
    "package_name": "GPAbin",
    "title": "Unifying Multiple Biplot Visualisations into a Single Display",
    "description": "Aligning multiple visualisations by utilising generalised orthogonal Procrustes analysis (GPA) before combining coordinates into a single biplot display as described in Nienkemper-Swanepoel, le Roux and Lubbe (2023)<doi:10.1080/03610918.2021.1914089>. This is mainly suitable to combine visualisations constructed from multiple imputations, however, it can be generalised to combine variations of visualisations from the same datasets (i.e. resamples).",
    "version": "1.1.1",
    "maintainer": "Johané Nienkemper-Swanepoel <nienkemperj@sun.ac.za>",
    "url": "https://jnienk.github.io/GPAbin/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2723,
    "package_name": "GPBayes",
    "title": "Tools for Gaussian Process Modeling in Uncertainty\nQuantification",
    "description": "Gaussian processes ('GPs') have been widely used to model spatial data, 'spatio'-temporal data, and computer experiments in diverse areas of statistics including spatial statistics, 'spatio'-temporal statistics, uncertainty quantification, and machine learning. This package creates basic tools for fitting and prediction based on 'GPs' with spatial data, 'spatio'-temporal data, and computer experiments. Key characteristics for this GP tool include: (1) the comprehensive implementation of various covariance functions including the 'Matérn' family and the Confluent 'Hypergeometric' family with isotropic form, tensor form, and automatic relevance determination form, where the isotropic form is widely used in spatial statistics, the tensor form is widely used in design and analysis of computer experiments and uncertainty quantification, and the automatic relevance determination form is widely used in machine learning; (2) implementations via Markov chain Monte Carlo ('MCMC') algorithms and optimization algorithms for GP models with all the implemented covariance functions. The methods for fitting and prediction are mainly implemented in a Bayesian framework; (3) model evaluation via Fisher information and predictive metrics such as predictive scores; (4) built-in functionality for simulating 'GPs' with all the implemented covariance functions; (5) unified implementation to allow easy specification of various 'GPs'. ",
    "version": "0.1.0-6",
    "maintainer": "Pulong Ma <mpulong@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2727,
    "package_name": "GPEMR",
    "title": "Growth Parameter Estimation Method",
    "description": "Provides functions for simulating and estimating parameters of various growth models, including Logistic, Exponential, Theta-logistic, Von-Bertalanffy, and Gompertz models. The package supports both simulated and real data analysis, including parameter estimation, visualization, and calculation of global and local estimates. The methods are based on research described by Md Aktar Ul Karim and Amiya Ranjan Bhowmick (2022) in (<https://www.researchsquare.com/article/rs-2363586/v1>). An interactive web application is also available at [GPEMR Web App](<https://gpem-r.shinyapps.io/GPEM-R/>).",
    "version": "0.1.0",
    "maintainer": "Ruqaiya Shaikh <ruqaiyashaikh41@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2733,
    "package_name": "GPRMortality",
    "title": "Gaussian Process Regression for Mortality Rates",
    "description": "A Bayesian statistical model for estimating child (under-five age group) and adult (15-60 age group) mortality.  The main challenge is how to combine and integrate these different time series and how to produce unified estimates of mortality rates during a specified time span. GPR is a Bayesian statistical model for estimating child and adult mortality rates which its data likelihood is mortality rates from different data sources such as: Death Registration System, Censuses or surveys. There are also various hyper-parameters for completeness of DRS, mean, covariance functions and variances as priors. This function produces estimations and uncertainty (95% or any desirable percentiles) based on sampling and non-sampling errors due to variation in data sources. The GP model utilizes Bayesian inference to update predicted mortality rates as a posterior in Bayes rule by combining data and a prior probability distribution over parameters in mean, covariance function, and the regression model. This package uses Markov Chain Monte Carlo (MCMC) to sample from posterior probability distribution by 'rstan' package in R. Details are given in Wang H, Dwyer-Lindgren L, Lofgren KT, et al. (2012) <doi:10.1016/S0140-6736(12)61719-X>, Wang H, Liddell CA, Coates MM, et al. (2014) <doi:10.1016/S0140-6736(14)60497-9> and Mohammadi, Parsaeian, Mehdipour et al. (2017) <doi:10.1016/S2214-109X(17)30105-5>.",
    "version": "0.1.0",
    "maintainer": "Ali Ghanbari <a.ghanbari541@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2741,
    "package_name": "GPoM",
    "title": "Generalized Polynomial Modelling",
    "description": "Platform dedicated to the Global Modelling technique. Its aim\n    is to obtain ordinary differential equations of polynomial form directly\n    from time series. It can be applied to single or multiple time series under\n    various conditions of noise, time series lengths, sampling, etc. This platform\n    is developped at the Centre d'Etudes Spatiales de la Biosphere (CESBIO),\n    UMR 5126 UPS/CNRS/CNES/IRD, 18 av. Edouard Belin, 31401 TOULOUSE, FRANCE.\n    The developments were funded by the French program Les Enveloppes Fluides\n    et l'Environnement (LEFE, MANU, projets GloMo, SpatioGloMo and MoMu). The\n    French program Defi InFiNiTi (CNRS) and PNTS are also acknowledged (projects\n    Crops'IChaos and Musc & SlowFast). The method is described in the article :\n    Mangiarotti S. and Huc M. (2019) <doi:10.1063/1.5081448>.",
    "version": "1.4",
    "maintainer": "Mireille Huc <mireille.huc@u-paris2.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2744,
    "package_name": "GPvecchia",
    "title": "Scalable Gaussian-Process Approximations",
    "description": "Fast scalable Gaussian process approximations, particularly well suited to spatial (aerial, remote-sensed) and environmental data, described in more detail in Katzfuss and Guinness (2017) <arXiv:1708.06302>. Package also contains a fast implementation of the incomplete Cholesky decomposition (IC0), based on Schaefer et al. (2019) <arXiv:1706.02205> and MaxMin ordering proposed in Guinness (2018) <arXiv:1609.05372>.",
    "version": "0.1.7",
    "maintainer": "Marcin Jurek <marcinjurek1988@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2791,
    "package_name": "GTDL",
    "title": "The Generalized Time-Dependent Logistic Family",
    "description": "Computes the  probability density, survival function,\n   the hazard rate functions and generates random samples from the \n   GTDL distribution given by Mackenzie, G. (1996) <doi:10.2307/2348408>. \n   The likelihood estimates, the randomized quantile (Louzada, F., et al. \n   (2020) <doi:10.1109/ACCESS.2020.3040525>)\n   residuals and the normally transformed randomized survival \n   probability (Li,L., et al. (2021) <doi:10.1002/sim.8852>)\n   residuals are obtained for the GTDL model. ",
    "version": "1.0.0",
    "maintainer": "Jalmar Carrasco <carrascojalmar@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2802,
    "package_name": "GVS",
    "title": "'Geocoordinate Validation Service'",
    "description": "The 'Geocoordinate Validation Service' (GVS) runs checks of coordinates in latitude/longitude format. It returns annotated coordinates with additional flags and metadata that can be used in data cleaning.  Additionally, the package has functions related to attribution and metadata information. More information can be found at <https://github.com/ojalaquellueva/gvs/tree/master/api>.",
    "version": "0.0.1",
    "maintainer": "Brian Maitner <bmaitner@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2812,
    "package_name": "GWLelast",
    "title": "Geographically Weighted Logistic Elastic Net Regression",
    "description": "Fit a geographically weighted logistic elastic net regression. Detailed explanations can be found in Yoneoka et al. (2016): New algorithm for constructing area-based index with geographical heterogeneities and variable selection: An application to gastric cancer screening <doi:10.1038/srep26582>.",
    "version": "1.2.2",
    "maintainer": "Daisuke Yoneoka <blue.sky.sea.dy@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2813,
    "package_name": "GWRLASSO",
    "title": "A Hybrid Model for Spatial Prediction Through Local Regression",
    "description": "It implements a hybrid spatial model for improved spatial prediction by combining the variable selection capability of\n             LASSO (Least Absolute Shrinkage and Selection Operator) with the Geographically Weighted Regression (GWR) model that \n             captures the spatially varying relationship efficiently. For method details see, Wheeler, D.C.(2009).<DOI:10.1068/a40256>.\n             The developed hybrid model efficiently selects the relevant variables by using LASSO as the first step; these selected variables\n             are then incorporated into the GWR framework, allowing the estimation of spatially varying regression coefficients at unknown locations\n             and finally predicting the values of the response variable at unknown test locations while taking into account the spatial heterogeneity of the data. \n             Integrating the LASSO and GWR models enhances prediction accuracy by considering spatial heterogeneity and capturing the local relationships between \n             the predictors and the response variable. The developed hybrid spatial model can be useful for spatial modeling, especially in scenarios involving complex \n             spatial patterns and large datasets with multiple predictor variables.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2818,
    "package_name": "GWmodel",
    "title": "Geographically-Weighted Models",
    "description": "Techniques from a particular branch of spatial statistics,termed geographically-weighted (GW) models. GW models suit situations when data are not described well by some global model, but where there are spatial regions where a suitably localised calibration provides a better description. 'GWmodel' includes functions to calibrate: GW summary statistics (Brunsdon et al., 2002)<doi: 10.1016/s0198-9715(01)00009-6>, GW principal components analysis (Harris et al., 2011)<doi: 10.1080/13658816.2011.554838>, GW discriminant analysis (Brunsdon et al., 2007)<doi: 10.1111/j.1538-4632.2007.00709.x> and various forms of GW regression (Brunsdon et al., 1996)<doi: 10.1111/j.1538-4632.1996.tb00936.x>; some of which are provided in basic and robust (outlier resistant) forms.",
    "version": "2.4-1",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "url": "http://gwr.nuim.ie/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2819,
    "package_name": "GWmodelVis",
    "title": "Visualization Tools for Geographically Weighted Models",
    "description": "\n    The increasing popularity of geographically weighted (GW) techniques has resulted in the development of several R packages, such as 'GWmodel'. To facilitate their usages, 'GWmodelVis' provides a 'shiny'-based interactive visualization toolkit for geographically weighted (GW) models.\n    It includes a number of visualization tools, including dynamic mapping of parameter surfaces, statistical visualization, sonification and exporting  videos via 'FFmpeg'. ",
    "version": "1.0.1",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "url": "http://gwmodel.whu.edu.cn/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2821,
    "package_name": "GWpcor",
    "title": "Geographically Weighted Partial Correlation Coefficient",
    "description": "Implements a geographically weighted partial correlation which is an extension from gwss() function in the 'GWmodel' package (Percival and Tsutsumida (2017) <doi:10.1553/giscience2017_01_s36>).",
    "version": "0.1.7",
    "maintainer": "Narumasa Tsutsumida <rsnaru.jp@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2832,
    "package_name": "GeNetIt",
    "title": "Spatial Graph-Theoretic Genetic Gravity Modelling",
    "description": "Implementation of spatial graph-theoretic genetic gravity models.",
    "version": "0.1-6",
    "maintainer": "Jeffrey S. Evans <jeffrey_evans@tnc.org>",
    "url": "https://github.com/jeffreyevans/GeNetIt",
    "exports": [],
    "topics": ["cran", "landscape-genetics", "r", "r-package", "r-spatial", "rstats", "spatial", "statistics"],
    "score": "NA",
    "stars": 11
  },
  {
    "id": 2897,
    "package_name": "GeoAdjust",
    "title": "Accounting for Random Displacements of True GPS Coordinates of\nData",
    "description": "The purpose is to account for the random displacements \n (jittering) of true survey household cluster center coordinates in geostatistical \n analyses of Demographic and Health Surveys program (DHS) data. Adjustment for \n jittering can be implemented either in the spatial random effect, or in the \n raster/distance based covariates, or in both. Detailed information about the methods \n behind the package functionality can be found in our two papers.\n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2024) <doi:10.32614/RJ-2024-027>. \n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2023) <doi:10.1177/1471082X231219847>. ",
    "version": "2.0.1",
    "maintainer": "Umut Altay <altayumut.ua@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2899,
    "package_name": "GeoFIS",
    "title": "Spatial Data Processing for Decision Making",
    "description": "Methods for processing spatial data for decision-making. \n  This package is an R implementation of methods provided by the open source software GeoFIS <https://www.geofis.org> (Leroux et al. 2018) <doi:10.3390/agriculture8060073>. \n  The main functionalities are the management zone delineation (Pedroso et al. 2010) <doi:10.1016/j.compag.2009.10.007> and data aggregation (Mora-Herrera et al. 2020) <doi:10.1016/j.compag.2020.105624>.",
    "version": "1.1.1",
    "maintainer": "Jean-Luc Lablée <jean-luc.lablee@inrae.fr>",
    "url": "https://www.geofis.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2900,
    "package_name": "GeoModels",
    "title": "Procedures for Gaussian and Non Gaussian Geostatistical (Large)\nData Analysis",
    "description": "Functions for Gaussian and Non Gaussian (bivariate) spatial and spatio-temporal data analysis are provided for a) (fast) simulation of random fields,  b) inference  for random fields using standard likelihood and a likelihood approximation  method called  weighted composite likelihood based on pairs and b) prediction using (local) best linear unbiased prediction. Weighted composite likelihood can be very efficient for estimating massive datasets. Both regression and spatial (temporal) dependence analysis can be jointly performed. Flexible covariance models for spatial and spatial-temporal data on Euclidean domains and spheres are provided. There are also many useful functions for plotting and performing diagnostic analysis. Different non Gaussian random fields can be considered in the analysis. Among them, random fields with marginal distributions such as Skew-Gaussian, Student-t, Tukey-h, Sin-Arcsin, Two-piece, Weibull, Gamma, Log-Gaussian, Binomial, Negative Binomial  and Poisson. See the URL for the papers associated with this package, as for instance, Bevilacqua and Gaetan (2015) <doi:10.1007/s11222-014-9460-6>, Bevilacqua et al. (2016) <doi:10.1007/s13253-016-0256-3>, Vallejos et al. (2020) <doi:10.1007/978-3-030-56681-4>, Bevilacqua et. al (2020) <doi:10.1002/env.2632>, Bevilacqua et. al (2021) <doi:10.1111/sjos.12447>, Bevilacqua et al. (2022) <doi:10.1016/j.jmva.2022.104949>, Morales-Navarrete et al. (2023) <doi:10.1080/01621459.2022.2140053>, and a large class of examples and tutorials.",
    "version": "2.2.1",
    "maintainer": "Moreno Bevilacqua <moreno.bevilacqua89@gmail.com>",
    "url": "https://vmoprojs.github.io/GeoModels-page/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2901,
    "package_name": "GeoMongo",
    "title": "Geospatial Queries Using 'PyMongo'",
    "description": "Utilizes methods of the 'PyMongo' 'Python' library to initialize, insert and query 'GeoJson' data (see <https://github.com/mongodb/mongo-python-driver> for more information on 'PyMongo'). Furthermore, it allows the user to validate 'GeoJson' objects and to use the console for 'MongoDB' (bulk) commands. The 'reticulate' package provides the 'R' interface to 'Python' modules, classes and functions.",
    "version": "1.0.3",
    "maintainer": "Lampros Mouselimis <mouselimislampros@gmail.com>",
    "url": "https://github.com/mlampros/GeoMongo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2904,
    "package_name": "GeoThinneR",
    "title": "Efficient Spatial Thinning of Species Occurrences",
    "description": "Provides efficient geospatial thinning algorithms to reduce\n    the density of coordinate data while maintaining spatial\n    relationships. Implements K-D Tree and brute-force distance-based\n    thinning, as well as grid-based and precision-based thinning methods.\n    For more information on the methods, see Elseberg et al. (2012)\n    <https://hdl.handle.net/10446/86202>.",
    "version": "2.1.0",
    "maintainer": "Jorge Mestre-Tomás <jorge.mestre.tomas@csic.es>",
    "url": "https://github.com/jmestret/GeoThinneR,\nhttps://jmestret.github.io/GeoThinneR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2906,
    "package_name": "GeoWeightedModel",
    "title": "User-Friendly Interface for Geographically-Weighted Models",
    "description": "Contains the development of a tool that provides a web-based\n    graphical user interface (GUI) to perform Techniques from a subset of\n    spatial statistics known as geographically weighted (GW) models.\n    Contains methods described by Brunsdon et al., 1996\n    <doi:10.1111/j.1538-4632.1996.tb00936.x>, Brunsdon et al., 2002\n    <doi:10.1016/s0198-9715(01)00009-6>, Harris et al., 2011\n    <doi:10.1080/13658816.2011.554838>, Brunsdon et al., 2007\n    <doi:10.1111/j.1538-4632.2007.00709.x>.",
    "version": "1.0.3",
    "maintainer": "Javier De La Hoz Maestre <jdelahozmaestre@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2907,
    "package_name": "Geocomputation with R",
    "title": "Geocomputation with R",
    "description": "Open source book on R for reproducible,",
    "version": "0.0.5",
    "maintainer": "",
    "url": "https://github.com/geocompx/geocompr",
    "exports": [],
    "topics": ["book", "course", "education", "gdal", "geo", "geocomputation", "geocompx", "geography", "geos", "geospatial", "geospatial-data", "mapping-tools", "maps", "postgis", "r", "raster", "rspatial", "rstats", "simple-features", "spatial"],
    "score": "NA",
    "stars": 1727
  },
  {
    "id": 2927,
    "package_name": "GillespieSSA",
    "title": "Gillespie's Stochastic Simulation Algorithm (SSA)",
    "description": "Provides a simple to use, intuitive, and\n  extensible interface to several stochastic simulation\n  algorithms for generating simulated trajectories of finite\n  population continuous-time model. Currently it implements\n  Gillespie's exact stochastic simulation algorithm (Direct\n  method) and several approximate methods (Explicit tau-leap,\n  Binomial tau-leap, and Optimized tau-leap). The package also\n  contains a library of template models that can be run as demo\n  models and can easily be customized and extended. Currently the\n  following models are included, 'Decaying-Dimerization' reaction\n  set, linear chain system, logistic growth model, 'Lotka'\n  predator-prey model, Rosenzweig-MacArthur predator-prey model,\n  'Kermack-McKendrick' SIR model, and a 'metapopulation' SIRS model.\n  Pineda-Krch et al. (2008) <doi:10.18637/jss.v025.i12>.",
    "version": "0.6.2",
    "maintainer": "Robrecht Cannoodt <rcannood@gmail.com>",
    "url": "https://github.com/rcannood/GillespieSSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2951,
    "package_name": "GofKmt",
    "title": "Khmaladze Martingale Transformation Goodness-of-Fit Test",
    "description": "Consider a goodness-of-fit (GOF) problem of \n            testing whether a random sample comes from one \n            sample location-scale model where location and\n            scale parameters are unknown. It is well known \n            that Khmaladze martingale transformation method\n            proposed by Khmaladze (1981) <doi:10.1137/1126027> \n            provides asymptotic distribution free test for the GOF problem.\n            This package provides test statistic and critical \n            value of GOF test for normal, Cauchy, and logistic \n            distributions. This package used the main algorithm\n            proposed by Kim (2020) <doi:10.1007/s00180-020-00971-7>\n            and tests for other distributions will be available \n            at the later version.",
    "version": "2.3.1",
    "maintainer": "Jiwoong Kim <jwboys26@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2959,
    "package_name": "GpGp",
    "title": "Fast Gaussian Process Computation Using Vecchia's Approximation",
    "description": "Functions for fitting and doing predictions with\n    Gaussian process models using Vecchia's (1988) approximation. \n    Package also includes functions for reordering input locations, \n    finding ordered nearest neighbors (with help from 'FNN' package), \n    grouping operations, and conditional simulations.\n    Covariance functions for spatial and spatial-temporal data\n    on Euclidean domains and spheres are provided. The original \n    approximation is due to Vecchia (1988) \n    <http://www.jstor.org/stable/2345768>, and the reordering and\n    grouping methods are from Guinness (2018) \n    <doi:10.1080/00401706.2018.1437476>.\n    Model fitting employs a Fisher scoring algorithm described\n    in Guinness (2019) <doi:10.48550/arXiv.1905.08374>.",
    "version": "1.0.0",
    "maintainer": "Joseph Guinness <joeguinness@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2961,
    "package_name": "GrabSVG",
    "title": "Granularity-Based Spatially Variable Genes Identifications",
    "description": "Identifying spatially variable genes is critical in linking molecular cell functions with tissue phenotypes. This package implemented a granularity-based dimension-agnostic tool for the identification of spatially variable genes. The detailed description of this method is available at Wang, J. and Li, J. et al. 2023 (Wang, J. and Li, J. (2023), <doi:10.1038/s41467-023-43256-5>).",
    "version": "0.0.2",
    "maintainer": "Jinpu Li <castle.lee.f@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2973,
    "package_name": "GreenExp",
    "title": "Greenspace exposure",
    "description": "A robust package to calculte the green spaces",
    "version": "0.0.2",
    "maintainer": "",
    "url": "https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/GreenExp_R",
    "exports": [],
    "topics": ["greenspace", "nature", "osm", "satellite-data", "spatial-analysis", "spatialdata"],
    "score": "NA",
    "stars": 48
  },
  {
    "id": 2986,
    "package_name": "GrowthCurveME",
    "title": "Mixed-Effects Modeling for Growth Data",
    "description": "Simple and  user-friendly wrappers to the 'saemix' package for \n    performing linear and non-linear mixed-effects regression modeling for \n    growth data to account for clustering or longitudinal analysis via repeated\n    measurements. The package allows users to fit a variety of growth\n    models, including linear, exponential, logistic, and 'Gompertz'\n    functions. For non-linear models, starting values are automatically\n    calculated using initial least-squares estimates. The package includes \n    functions for summarizing models, visualizing data and results, \n    calculating doubling time and other key statistics, and generating model \n    diagnostic plots and residual summary statistics. It also provides \n    functions for generating publication-ready summary tables for reports. \n    Additionally, users can fit linear and non-linear least-squares \n    regression models if clustering is not applicable. The mixed-effects \n    modeling methods in this package are based on Comets, Lavenu, and \n    Lavielle (2017) <doi:10.18637/jss.v080.i03> as implemented in the \n    'saemix' package. Please contact us at models@dfci.harvard.edu \n    with any questions.",
    "version": "0.1.11",
    "maintainer": "Anand Panigrahy <anand_panigrahy@dfci.harvard.edu>",
    "url": "https://github.com/cancermodels-org/GrowthCurveME",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 2990,
    "package_name": "Guerry",
    "title": "Maps, Data and Methods Related to Guerry (1833) \"Moral\nStatistics of France\"",
    "description": "Maps of France in 1830, multivariate datasets from A.-M. Guerry and others, and statistical and \n\tgraphic methods related to Guerry's \"Moral Statistics of France\". The goal is to facilitate the exploration and\n\tdevelopment of statistical and graphic methods for multivariate data in a geospatial context of historical interest.",
    "version": "1.8.3",
    "maintainer": "Michael Friendly <friendly@yorku.ca>",
    "url": "https://github.com/friendly/Guerry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3007,
    "package_name": "HCUPtools",
    "title": "Access and Work with HCUP Resources and Datasets",
    "description": "A comprehensive R package for accessing and working with publicly \n    available and free resources from the Agency for Healthcare Research and Quality \n    (AHRQ) Healthcare Cost and Utilization Project (HCUP). The package provides \n    streamlined access to HCUP's Clinical Classifications Software Refined (CCSR) \n    mapping files and Summary Trend Tables, enabling researchers and analysts to \n    efficiently map ICD-10-CM diagnosis codes and ICD-10-PCS procedure codes to \n    CCSR categories and access HCUP statistical reports. Key features include: \n    direct download from HCUP website, multiple output formats (long/wide/default), \n    cross-classification support, version management, citation generation, and \n    intelligent caching. The package does not redistribute HCUP data files but \n    facilitates direct download from the official HCUP website, ensuring users \n    always have access to the latest versions and maintain compliance with HCUP \n    data use policies. This package only accesses free public tools and reports; \n    it does NOT access HCUP databases (NIS, KID, SID, NEDS, etc.) that require \n    purchase. For more information, see <https://hcup-us.ahrq.gov/>.",
    "version": "1.0.0",
    "maintainer": "Vikrant Dev Rathore <rathore.vikrant@gmail.com>",
    "url": "https://github.com/vikrant31/HCUPtools,\nhttps://vikrant31.github.io/HCUPtools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3027,
    "package_name": "HDSpatialScan",
    "title": "Multivariate and Functional Spatial Scan Statistics",
    "description": "Allows to detect spatial clusters of abnormal values on multivariate or functional data (Frévent et al. (2022) <doi:10.32614/RJ-2022-045>). See also:\n    Frévent et al. (2023) <doi:10.1093/jrsssc/qlad017>,\n    Smida et al. (2022) <doi:10.1016/j.csda.2021.107378>, \n    Frévent et al. (2021) <doi:10.1016/j.spasta.2021.100550>. \n    Cucala et al. (2019) <doi:10.1016/j.spasta.2018.10.002>, \n    Cucala et al. (2017) <doi:10.1016/j.spasta.2017.06.001>, \n    Jung and Cho (2015) <doi:10.1186/s12942-015-0024-6>, \n    Kulldorff et al. (2009) <doi:10.1186/1476-072X-8-58>. ",
    "version": "1.0.5",
    "maintainer": "Camille FREVENT <camille.frevent@univ-lille.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3028,
    "package_name": "HDStIM",
    "title": "High Dimensional Stimulation Immune Mapping ('HDStIM')",
    "description": "A method for identifying responses to experimental stimulation in mass or flow cytometry that uses high dimensional analysis of measured parameters and can be performed with an end-to-end unsupervised approach. In the context of in vitro stimulation assays where high-parameter cytometry was used to monitor intracellular response markers, using cell populations annotated either through automated clustering or manual gating for a combined set of stimulated and unstimulated samples, 'HDStIM' labels cells as responding or non-responding. The package also provides auxiliary functions to rank intracellular markers based on their contribution to identifying responses and generating diagnostic plots.",
    "version": "0.1.0",
    "maintainer": "Rohit Farmer <rohit.farmer@gmail.com>",
    "url": "https://github.com/niaid/HDStIM, https://niaid.github.io/HDStIM/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3034,
    "package_name": "HDcpDetect",
    "title": "Detect Change Points in Means of High Dimensional Data",
    "description": "Objective: Implement new methods for detecting change points in high-dimensional time series data. These new methods can be applied to non-Gaussian data, account for spatial and temporal dependence, and detect a wide variety of change-point configurations, including changes near the boundary and changes in close proximity. Additionally, this package helps address the “small n, large p” problem, which occurs in many research contexts. This problem arises when a dataset contains changes that are visually evident but do not rise to the level of statistical significance due to the small number of observations and large number of parameters. The problem is overcome by treating the dimensions as a whole and scaling the test statistics only by its standard deviation, rather than scaling each dimension individually. Due to the computational complexity of the functions, the package runs best on datasets with a relatively large number of attributes but no more than a few hundred observations.",
    "version": "0.1.0",
    "maintainer": "Natasha Stewart <natashastewart@utexas.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3056,
    "package_name": "HK80",
    "title": "Conversion Tools for HK80 Geographical Coordinate System",
    "description": "This is a collection of functions for converting coordinates between WGS84UTM, WGS84GEO, HK80UTM, HK80GEO and HK1980GRID Coordinate Systems used in Hong Kong SAR, based on the algorithms described in Explanatory Notes on Geodetic Datums in Hong Kong by Survey and Mapping Office Lands Department, Hong Kong Government (1995).",
    "version": "0.0.2",
    "maintainer": "Jinlong Zhang <jinlongzhang01@gmail.com>",
    "url": "https://github.com/helixcn/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3074,
    "package_name": "HMTL",
    "title": "Heterogeneous Multi-Task Feature Learning",
    "description": "The heterogeneous multi-task feature learning is a data integration method to conduct joint feature selection across multiple related data sets with different distributions. The algorithm can combine different types of learning tasks, including linear regression, Huber regression, adaptive Huber, and logistic regression. The modified version of Bayesian Information Criterion (BIC) is produced to measure the model performance. Package is based on Yuan Zhong, Wei Xu, and Xin Gao (2022) <https://www.fields.utoronto.ca/talk-media/1/53/65/slides.pdf>.",
    "version": "0.1.0",
    "maintainer": "Yuan Zhong <aqua.zhong@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3085,
    "package_name": "HSAR",
    "title": "Hierarchical Spatial Autoregressive Model",
    "description": "A Hierarchical Spatial Autoregressive Model (HSAR), based on a Bayesian Markov Chain Monte Carlo (MCMC) algorithm (Dong and Harris (2014) <doi:10.1111/gean.12049>). The creation of this package was supported by the Economic and Social Research Council (ESRC) through the Applied Quantitative Methods Network: Phase II, grant number ES/K006460/1.",
    "version": "0.6.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://spatlyu.github.io/HSAR/, https://github.com/spatlyu/HSAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3099,
    "package_name": "HTSeed",
    "title": "Fitting of Hydrotime Model for Seed Germination Time Course",
    "description": "The seed germination process starts with water uptake by the seed and ends with the protrusion of radicle and plumule under varying temperatures and soil water potential. Hydrotime is a way to describe the relationship between water potential and seed germination rates at germination percentages. One important quantity before applying hydrotime modeling of germination percentages is to consider the proportion of viable seeds that could germinate under saturated conditions. This package can be used to apply correction factors at various water potentials before estimating parameters like stress tolerance, and uniformity of the hydrotime model. Three different distributions namely, Gaussian, Logistic, and Extreme value distributions have been considered to fit the model to the seed germination time course. Details can be found in Bradford (2002) <https://www.jstor.org/stable/4046371>, and Bradford and Still(2004) <https://www.jstor.org/stable/23433495>. ",
    "version": "0.1.0",
    "maintainer": "Dr. Himadri Ghosh <hghosh@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3100,
    "package_name": "HTSeedGLM",
    "title": "Hydro Thermal Time Analysis of Seed Germination Using\nGeneralised Linear Model",
    "description": "Seed germinates through the physical process of water uptake by dry seed driven by the difference in water potential between the seed and the water. There exists seed-to-seed variability in the base seed water potential. Hence, there is a need for a distribution such that a viable seed with its base seed water potential germinates if and only if the soil water potential is more than the base seed water potential. This package estimates the stress tolerance and uniformity parameters of the seed lot for germination under various temperatures by using the hydro-time model of counts of germinated seeds under various water potentials. The distribution of base seed water potential has been considered to follow Normal, Logistic and Extreme value distribution. The estimated proportion of germinated seeds along with the estimates of stress and uniformity parameters are obtained using a generalised linear model. The significance test of the above parameters for within and between temperatures is also performed in the analysis. Details can be found in Kebreab and Murdoch (1999) <doi:10.1093/jxb/50.334.655> and Bradford (2002) <https://www.jstor.org/stable/4046371>. ",
    "version": "0.1.0",
    "maintainer": "Dr. Himadri Ghosh <hghosh@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3147,
    "package_name": "HiClimR",
    "title": "Hierarchical Climate Regionalization",
    "description": "A tool for Hierarchical Climate Regionalization applicable to any correlation-based clustering.\n             It adds several features and a new clustering method (called, 'regional' linkage) to hierarchical\n             clustering in R ('hclust' function in 'stats' library): data regridding, coarsening spatial resolution,\n             geographic masking, contiguity-constrained clustering, data filtering by mean and/or variance\n             thresholds, data preprocessing (detrending, standardization, and PCA), faster correlation function\n             with preliminary big data support, different clustering methods, hybrid hierarchical clustering,\n             multivariate clustering (MVC), cluster validation, visualization of regionalization results, and\n             exporting region map and mean timeseries into NetCDF-4 file.\n             The technical details are described in Badr et al. (2015) <doi:10.1007/s12145-015-0221-7>.",
    "version": "2.2.1",
    "maintainer": "Hamada S. Badr <badr@jhu.edu>",
    "url": "https://hsbadr.github.io/HiClimR/,\nhttps://github.com/hsbadr/HiClimR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3182,
    "package_name": "HotellingEllipse",
    "title": "Hotelling’s T-Squared Statistic and Ellipse",
    "description": "Functions to calculate the Hotelling’s T-squared statistic and corresponding confidence ellipses. Provides the semi-axes of the Hotelling’s T-squared ellipses at 95% and 99% confidence levels. Enables users to obtain the coordinates in two or three dimensions at user-defined confidence levels, allowing for the construction of 2D or 3D ellipses with customized confidence levels. Bro and Smilde (2014) <DOI:10.1039/c3ay41907j>. Brereton (2016) <DOI:10.1002/cem.2763>.",
    "version": "1.2.0",
    "maintainer": "Christian L. Goueguel <christian.goueguel@gmail.com>",
    "url": "https://github.com/ChristianGoueguel/HotellingEllipse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3234,
    "package_name": "ICSNP",
    "title": "Tools for Multivariate Nonparametrics",
    "description": "Tools for multivariate nonparametrics, as location tests based on marginal ranks, spatial median and spatial signs computation, Hotelling's T-test, estimates of shape are implemented.",
    "version": "1.1-2",
    "maintainer": "Klaus Nordhausen <klausnordhausenR@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3248,
    "package_name": "IDE",
    "title": "Integro-Difference Equation Spatio-Temporal Models",
    "description": "The Integro-Difference Equation model is a linear, dynamical model used to model\n   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,\n   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the\n   heart of the model is the kernel, which dictates how the process evolves from one time\n   point to the next. Both process and parameter reduction are used to facilitate computation,\n   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed\n   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted\n   by maximum likelihood, and estimation is carried out using an evolution algorithm. ",
    "version": "0.3.1",
    "maintainer": "Andrew Zammit-Mangion <andrewzm@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3273,
    "package_name": "IFTPredictor",
    "title": "Predictions Using Item-Focused Tree Models",
    "description": "This function predicts item response probabilities and item \n  responses using the item-focused tree model. The item-focused tree model\n  combines logistic regression with recursive partitioning to detect \n  Differential Item Functioning in dichotomous items. The model applies \n  partitioning rules to the data, splitting it into homogeneous subgroups, and \n  uses logistic regression within each subgroup to explain the data. \n  Differential Item Functioning detection is achieved by examining potential \n  group differences in item response patterns. This method is useful for \n  understanding how different predictors, such as demographic or psychological \n  factors, influence item responses across subgroups.",
    "version": "0.1.0",
    "maintainer": "Muditha L. Bodawatte Gedara <muditha.lakmali.1993@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3303,
    "package_name": "INLABMA",
    "title": "Bayesian Model Averaging with INLA",
    "description": "Fit Spatial Econometrics models using Bayesian model averaging \n  on models fitted with INLA. The INLA package can be obtained from \n  <https://www.r-inla.org>. ",
    "version": "0.1-12",
    "maintainer": "Virgilio Gómez-Rubio <virgilio.gomez@uclm.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3305,
    "package_name": "INLAspacetime",
    "title": "Spatial and Spatio-Temporal Models using 'INLA'",
    "description": "Prepare objects to implement models over spatial and \n  spacetime domains with the 'INLA' package (<https://www.r-inla.org>).\n  These objects contain data to for the 'cgeneric' interface in\n  'INLA', enabling fast parallel computations.\n  We implemented the spatial barrier model, see Bakka et. al. (2019) \n  <doi:10.1016/j.spasta.2019.01.002>, and some of the spatio-temporal \n  models proposed in Lindgren et. al. (2024) \n  <https://raco.cat/index.php/SORT/article/view/428665>. \n  Details are provided in the available vignettes and from the URL bellow.",
    "version": "0.1.13",
    "maintainer": "Elias Teixeira Krainski <eliaskrainski@gmail.com>",
    "url": "https://github.com/eliaskrainski/INLAspacetime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3307,
    "package_name": "INLAutils",
    "title": "Utility Functions for 'INLA'",
    "description": "A number of utility functions for 'INLA' <http://www.r-inla.org>. Additional diagnostic plots",
    "version": "0.0.6",
    "maintainer": "",
    "url": "https://github.com/timcdlucas/INLAutils",
    "exports": [],
    "topics": ["bayesian-inference", "bayesian-methods", "inla", "mixed-effects", "plotting", "spatial-analysis", "species-distribution-modelling"],
    "score": "NA",
    "stars": 31
  },
  {
    "id": 3319,
    "package_name": "IPDfromKM",
    "title": "Map Digitized Survival Curves Back to Individual Patient Data",
    "description": "\n      An implementation to reconstruct individual patient data from Kaplan-Meier (K-M) survival curves, visualize and assess the accuracy of the reconstruction, then perform secondary analysis on the reconstructed data. We involve a simple function to extract the coordinates form the published K-M curves. The function is developed based on Poisot T. ’s digitize package (2011)  <doi:10.32614/RJ-2011-004> . For more complex and tangled together graphs, digitizing software, such as 'DigitizeIt' (for MAC or windows) or 'ScanIt'(for windows) can be used to get the coordinates. Additional information should also be involved to increase the accuracy, like numbers of patients at risk (often reported at 5-10 time points under the x-axis of the K-M graph), total number of patients, and total number of events. The package implements the modified iterative K-M estimation algorithm (modified-iKM) improved upon the approach proposed by Guyot (2012) <doi:10.1186/1471-2288-12-9> with some modifications. ",
    "version": "0.1.10",
    "maintainer": "Na Liu <nliu1104@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3334,
    "package_name": "IRTBEMM",
    "title": "Family of Bayesian EMM Algorithm for Item Response Models",
    "description": "Applying the family of the Bayesian Expectation-Maximization-Maximization (BEMM) algorithm to estimate: (1) Three parameter logistic (3PL) model proposed by Birnbaum (1968, ISBN:9780201043105); (2) four parameter logistic (4PL) model proposed by Barton & Lord (1981) <doi:10.1002/j.2333-8504.1981.tb01255.x>; (3) one parameter logistic guessing (1PLG) and (4) one parameter logistic ability-based guessing (1PLAG) models proposed by San Martín et al (2006) <doi:10.1177/0146621605282773>. The BEMM family includes (1) the BEMM algorithm for 3PL model proposed by Guo & Zheng (2019) <doi:10.3389/fpsyg.2019.01175>; (2) the BEMM algorithm for 1PLG model and (3) the BEMM algorithm for 1PLAG model proposed by Guo, Wu, Zheng, & Chen (2021) <doi:10.1177/0146621621990761>; (4) the BEMM algorithm for 4PL model proposed by Zheng, Guo, & Kern (2021) <doi:10.1177/21582440211052556>; and (5) their maximum likelihood estimation versions proposed by Zheng, Meng, Guo, & Liu (2018) <doi:10.3389/fpsyg.2017.02302>. Thus, both Bayesian modal estimates and maximum likelihood estimates are available.",
    "version": "1.0.8",
    "maintainer": "Shaoyang Guo <syguo1992@outlook.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3344,
    "package_name": "ISAT",
    "title": "Extract Cell Density and Nearest Distance Based on 'PerkinElmer\nInForm' Software Output",
    "description": "Reads the output of the 'PerkinElmer InForm' software <http://www.perkinelmer.com/product/inform-cell-analysis-one-seat-cls135781>. In addition to cell-density count, it can derive statistics of intercellular spatial distance for each cell-type.",
    "version": "1.0.5",
    "maintainer": "Minyu Wang <minyu.wang@petermac.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3373,
    "package_name": "Icarus",
    "title": "Spatial-Temporal analysis on PREDICTS data",
    "description": "A little package to deal various explatory analysis and formatting",
    "version": "1.0",
    "maintainer": "Martin Jung <martinjung@zoho.com>",
    "url": "https://github.com/Martin-Jung/Icarus",
    "exports": [],
    "topics": ["r", "raster", "remote-sensing", "spatial", "spatial-analysis"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 3421,
    "package_name": "Inquilab",
    "title": "Dissipation Kinetics Analysis, Half Life Period, Rate Constant,\nPlots",
    "description": "For environmental chemists, ecologists, researchers and agricultural scientists to understand the dissipation kinetics, calculate the half-life periods and rate constants of compounds, pesticides, contaminants in different matrices.",
    "version": "0.1.0",
    "maintainer": "Jajati Mandal <J.Mandal2@salford.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3441,
    "package_name": "InterpolateR",
    "title": "A Comprehensive Toolkit for Fast and Efficient Spatial\nInterpolation",
    "description": "Spatial interpolation toolkit designed for environmental and geospatial applications. It includes a range of methods, from traditional techniques to advanced machine learning approaches, ensuring accurate and efficient estimation of values in unobserved locations.",
    "version": "1.4-3",
    "maintainer": "Jonnathan Landi <jonnathan.landi@outlook.com>",
    "url": "https://github.com/Jonnathan-Landi/InterpolateR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3448,
    "package_name": "InvasionCorrection",
    "title": "Invasion Correction",
    "description": "The correction is achieved under the assumption that non-migrating cells of the essay approximately form a quadratic flow profile due to frictional effects, compare law of Hagen-Poiseuille for flow in a tube. The script fits a conical plane to give xyz-coordinates of the cells. It outputs the number of migrated cells and the new corrected coordinates.",
    "version": "0.1",
    "maintainer": "Marcus Rosenblatt <marcus.rosenblatt@fdm.uni-freiburg.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3449,
    "package_name": "Irescale",
    "title": "Calculate and Rectify Moran's I",
    "description": "Provides a scaling method to obtain a standardized Moran's I measure. Moran's I is a measure for the spatial autocorrelation of a data set, it gives a measure of similarity between data and its surrounding. The range of this value must be [-1,1], but this does not happen in practice. This package scale the Moran's I value and map it into the theoretical range of [-1,1]. Once the Moran's I value is rescaled, it facilitates the comparison between projects, for instance, a researcher can calculate Moran's I in a city in China, with a sample size of n1 and area of interest a1. Another researcher runs a similar experiment in a city in Mexico with different sample size, n2, and an area of interest a2. Due to the differences between the conditions, it is not possible to compare Moran's I in a straightforward way. In this version of the package, the spatial autocorrelation Moran's I is calculated as proposed in Chen(2013) <arXiv:1606.03658>.",
    "version": "2.3.0",
    "maintainer": "Ivan Fuentes <jivfur@tamu.edu>",
    "url": "https://github.tamu.edu/jivfur/rectifiedI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3453,
    "package_name": "IsingFit",
    "title": "Fitting Ising Models Using the ELasso Method",
    "description": "This network estimation procedure eLasso, which is based on the Ising model, combines l1-regularized logistic regression with model selection based on the Extended Bayesian Information Criterion (EBIC). EBIC is a fit measure that identifies relevant relationships between variables. The resulting network consists of variables as nodes and relevant relationships as edges. Can deal with binary data.",
    "version": "0.4",
    "maintainer": "Sacha Epskamp <mail@sachaepskamp.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3466,
    "package_name": "IsoriX",
    "title": "Isoscape Computation and Inference of Spatial Origins using\nMixed Models",
    "description": "Building isoscapes using mixed models and inferring the geographic\n  origin of samples based on their isotopic ratios. This package is essentially a\n  simplified interface to several other packages which implements a new\n  statistical framework based on mixed models. It uses 'spaMM' for fitting and\n  predicting isoscapes, and assigning an organism's origin depending on its\n  isotopic ratio. 'IsoriX' also relies heavily on the package 'rasterVis' for\n  plotting the maps produced with 'terra' using 'lattice'.",
    "version": "0.9.3",
    "maintainer": "Alexandre Courtiol <alexandre.courtiol@gmail.com>",
    "url": "https://github.com/courtiol/IsoriX,\nhttps://bookdown.org/content/782",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3493,
    "package_name": "JQL",
    "title": "Jump Q-Learning for Individualized Interval-Valued Dose Rule",
    "description": "We provide tools to estimate the individualized interval-valued dose rule (I2DR) that maximizes the expected beneficial clinical outcome for each individual and returns an optimal interval-valued dose, by using the jump Q-learning (JQL) method. The jump Q-learning method directly models the conditional mean of the response given the dose level and the baseline covariates via jump penalized least squares regression under the framework of Q learning. We develop a searching algorithm by dynamic programming in order to find the optimal I2DR with the time complexity O(n2) and spatial complexity O(n). To alleviate the effects of misspecification of the Q-function, a residual jump Q-learning is further proposed to estimate the optimal I2DR. The outcome of interest includes the best partition of the entire dosage of interest, the regression coefficients of each partition, and the value function under the estimated I2DR as well as the Wald-type confidence interval of value function constructed through the Bootstrap.",
    "version": "3.6.9",
    "maintainer": "Hengrui Cai <hcai5@ncsu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3494,
    "package_name": "JSDNE",
    "title": "Estimating the Age using Auricular Surface by DNE",
    "description": "The age is estimated by calculating the Dirichlet Normal Energy (DNE) on the whole auricular surface and the apex of the auricular surface. It involves three estimation methods: principal component discriminant analysis (PCQDA), and principal component logistic regression analysis (PCLR) methods, principal component regression analysis with Southeast Asian (A_PCR), and principal component regression analysis with multipopulation (M_PCR). The package is created with the data from the Louis Lopes Collection in Lisbon, the 21st Century Identified Human Remains Collection in Coimbra, and the CAL Milano Cemetery Skeletal Collection in Milan, and  the skeletal collection at Khon Kaen University (KKU) Human Skeletal Research Centre (HSRC), housed in the Department of Anatomy in the Faculty of Medicine at KKU in Khon Kaen.",
    "version": "4.6",
    "maintainer": "Jisun Jang <jisun.jang.19@ucl.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3541,
    "package_name": "KMLtoSHAPE",
    "title": "Preserving Attribute Values: Converting KML to Shapefile",
    "description": "The developed function is designed to facilitate the seamless conversion of KML (Keyhole Markup Language)\n             files to Shapefiles while preserving attribute values. It provides a straightforward interface for users\n             to effortlessly import KML data, extract relevant attributes, and export them into the widely compatible\n             Shapefile format. The package ensures accurate representation of spatial data while maintaining the integrity\n             of associated attribute information. For details see, Flores, G. (2021). <DOI:10.1007/978-3-030-63665-4_15>.\n             Whether for spatial analysis, visualization, or data interoperability, it simplifies the conversion process and \n             empowers users to seamlessly work with geospatial datasets.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3565,
    "package_name": "Karen",
    "title": "Kalman Reaction Networks",
    "description": "This is a stochastic framework that combines biochemical reaction networks with extended Kalman filter and Rauch-Tung-Striebel smoothing. \n  This framework allows to investigate the dynamics of cell differentiation from high-dimensional clonal tracking data subject to measurement noise, false negative errors, and systematically unobserved cell types. \n  Our tool can provide statistical support to biologists in gene therapy clonal tracking studies for a deeper understanding of clonal reconstitution dynamics. Further details on the methods can be found in L. Del Core et al., (2022) <doi:10.1101/2022.07.08.499353>.",
    "version": "1.0",
    "maintainer": "Luca Del Core <l.del.core@rug.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3589,
    "package_name": "KnowBR",
    "title": "Discriminating Well Surveyed Spatial Units from Exhaustive\nBiodiversity Databases",
    "description": "It uses species accumulation curves and diverse estimators to assess, at the same time, the levels of survey coverage in multiple geographic cells of a size defined by the user or polygons. It also enables the geographical depiction of observed species richness, survey effort and completeness values including a background with administrative areas.",
    "version": "2.2",
    "maintainer": "Castor Guisande Gonzalez <castor@uvigo.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3600,
    "package_name": "L1pack",
    "title": "Routines for L1 Estimation",
    "description": "L1 estimation for linear regression using Barrodale and Roberts' method\n    <doi:10.1145/355616.361024> and the EM algorithm <doi:10.1023/A:1020759012226>.\n    Estimation of mean and covariance matrix using the multivariate Laplace distribution,\n    density, distribution function, quantile function and random number generation\n    for univariate and multivariate Laplace distribution <doi:10.1080/03610929808832115>.\n    Implementation of Naik and Plungpongpun <doi:10.1007/0-8176-4487-3_7> for the \n    Generalized spatial median estimator is included.",
    "version": "0.60",
    "maintainer": "Felipe Osorio <faosorios.stat@gmail.com>",
    "url": "https://github.com/faosorios/L1pack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3603,
    "package_name": "L2hdchange",
    "title": "L2 Inference for Change Points in High-Dimensional Time Series",
    "description": "Provides a method for detecting multiple change points in high-dimensional time\n    series, targeting dense or spatially clustered signals. See Li et al. (2023) \n    \"L2 Inference for Change Points in High-Dimensional Time Series via a Two-Way MOSUM\". \n    arXiv preprint <arXiv:2208.13074>.",
    "version": "1.0",
    "maintainer": "Rui Lin <ruilin1081@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3607,
    "package_name": "LAGOSNE",
    "title": "Interface to the Lake Multi-Scaled Geospatial and Temporal\nDatabase",
    "description": "Client for programmatic access to the Lake\n    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions\n    for accessing lake water quality and ecological context data for the US.",
    "version": "2.0.4",
    "maintainer": "Jemma Stachelek <jemma.stachelek@gmail.com>",
    "url": "https://github.com/cont-limno/LAGOSNE,\nhttps://cont-limno.github.io/LAGOSNE/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3646,
    "package_name": "LGDtoolkit",
    "title": "Collection of Tools for LGD Rating Model Development",
    "description": "The goal of this package is to cover the most common steps in Loss Given Default (LGD) rating model development.\n             The main procedures available are those that refer to bivariate and multivariate analysis. In particular two statistical methods for \n             multivariate analysis are currently implemented – OLS regression and fractional logistic regression.\n             Both methods are also available within different blockwise model designs and both have customized stepwise algorithms. \n             Descriptions of these customized designs are available in Siddiqi (2016) <doi:10.1002/9781119282396.ch10> and \n             Anderson, R.A. (2021) <doi:10.1093/oso/9780192844194.001.0001>. \n             Although they are explained for PD model, the same designs are applicable for LGD model with different underlying regression methods \n             (OLS and fractional logistic regression). To cover other important steps for LGD model development, it is recommended to use \n             'LGDtoolkit' package along with 'PDtoolkit', and 'monobin' (or 'monobinShiny') packages.\n             Additionally, 'LGDtoolkit' provides set of procedures handy for initial and periodical model validation. ",
    "version": "0.2.0",
    "maintainer": "Andrija Djurovic <djandrija@gmail.com>",
    "url": "https://github.com/andrija-djurovic/LGDtoolkit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3654,
    "package_name": "LKT",
    "title": "Logistic Knowledge Tracing",
    "description": "Computes Logistic Knowledge Tracing ('LKT') which is a general method for tracking human learning in an educational software system. Please see Pavlik, Eglington, and Harrel-Williams (2021) <https://ieeexplore.ieee.org/document/9616435>. 'LKT' is a method to compute features of student data that are used as predictors of subsequent performance. 'LKT' allows great flexibility in the choice of predictive components and features computed for these predictive components. The system is built on top of 'LiblineaR', which enables extremely fast solutions compared to base glm() in R.",
    "version": "1.7.0",
    "maintainer": "Philip I. Pavlik Jr. <imrryr@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3664,
    "package_name": "LMMsolver",
    "title": "Linear Mixed Models with Sparse Matrix Methods and Smoothing",
    "description": "Provides tools for fitting linear mixed models using sparse matrix \n    methods and variance component estimation. Applications include spline-based \n    modeling of spatial and temporal trends using penalized splines (Boer, 2023) \n    <doi:10.1177/1471082X231178591>.",
    "version": "1.0.12",
    "maintainer": "Bart-Jan van Rossum <bart-jan.vanrossum@wur.nl>",
    "url": "https://biometris.github.io/LMMsolver/index.html,\nhttps://github.com/Biometris/LMMsolver/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3669,
    "package_name": "LMfilteR",
    "title": "Filter Methods for Parameter Estimation in Linear and Non Linear\nRegression Models",
    "description": "We present a method based on filtering algorithms to estimate the parameters of linear, i.e. the coefficients and the variance of the error term. The proposed algorithms make use of Particle Filters following Ristic, B., Arulampalam, S., Gordon, N. (2004, ISBN: 158053631X) resampling methods. Parameters of logistic regression models are also estimated using an evolutionary particle filter method.",
    "version": "0.1.3.1",
    "maintainer": "Christian Llano Robayo <info@cecareus.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3677,
    "package_name": "LOMAR",
    "title": "Localization Microscopy Data Analysis",
    "description": "Read, register and compare point sets from single molecule localization microscopy.",
    "version": "0.5.1",
    "maintainer": "Jean-Karim Heriche <heriche@embl.de>",
    "url": "https://git.embl.org/heriche/lomar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3699,
    "package_name": "LS2Wstat",
    "title": "A Multiscale Test of Spatial Stationarity for LS2W Processes",
    "description": "Wavelet-based methods for testing stationarity and quadtree segmenting of images, see Taylor et al (2014) <doi:10.1080/00401706.2013.823890>.",
    "version": "2.1-5",
    "maintainer": "Matt Nunes <nunesrpackages@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3713,
    "package_name": "LSRS",
    "title": "Land Surface Remote Sensing",
    "description": "Rapid satellite data streams in operational applications\n    have clear benefits for monitoring land cover, \n    especially when information can be delivered as fast as changing\n    surface conditions. Over the past decade,\n    remote sensing has become a key tool for monitoring and predicting\n    environmental variables by using satellite data. \n    This package presents the main applications in remote sensing for \n    land surface monitoring and land cover mapping (soil, vegetation, water...).\n     Tomlinson, C.J., Chapman, L., Thornes, E., Baker, C (2011) <doi:10.1002/met.287>.",
    "version": "0.2.0",
    "maintainer": "Mehdi Sarparast <mehdisarparast@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3714,
    "package_name": "LST",
    "title": "Land Surface Temperature Retrieval for Landsat 8",
    "description": "Calculates Land Surface Temperature from Landsat band 10 and 11.\n  Revision of the Single-Channel Algorithm for Land Surface Temperature Retrieval From Landsat Thermal-Infrared Data. Jimenez-Munoz JC, Cristobal J, Sobrino JA, et al (2009). <doi: 10.1109/TGRS.2008.2007125>.\n  Land surface temperature retrieval from LANDSAT TM 5. Sobrino JA, Jiménez-Muñoz JC, Paolini L (2004). <doi:10.1016/j.rse.2004.02.003>.\n  Surface temperature estimation in Singhbhum Shear Zone of India using Landsat-7 ETM+ thermal infrared data. Srivastava PK, Majumdar TJ, Bhattacharya AK (2009). <doi: 10.1016/j.asr.2009.01.023>.\n  Mapping land surface emissivity from NDVI: Application to European, African, and South American areas. Valor E (1996). <doi:10.1016/0034-4257(96)00039-9>.\n  On the relationship between thermal emissivity and the normalized difference vegetation index for natural surfaces. Van de Griend AA, Owe M (1993). <doi:10.1080/01431169308904400>.\n  Land Surface Temperature Retrieval from Landsat 8 TIRS—Comparison between Radiative Transfer Equation-Based Method, Split Window Algorithm and Single Channel Method. Yu X, Guo X, Wu Z (2014). <doi:10.3390/rs6109829>.\n  Calibration and Validation of land surface temperature for Landsat8-TIRS sensor. Land product validation and evolution. Skoković D, Sobrino JA, Jimenez-Munoz JC, Soria G, Julien Y, Mattar C, Cristóbal J. (2014).",
    "version": "2.0.0",
    "maintainer": "Bappa Das <bappa.iari.1989@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3722,
    "package_name": "LTCDM",
    "title": "Latent Transition Cognitive Diagnosis Model with Covariates",
    "description": "Implementation of the three-step approach of (latent transition) cognitive diagnosis model (CDM) with covariates. This approach can be used for single time-point situations (cross-sectional data) and multiple time-point situations (longitudinal data) to investigate how the covariates are associated with attribute mastery. For multiple time-point situations, the three-step approach of latent transition CDM with covariates allows researchers to assess changes in attribute mastery status and to evaluate the covariate effects on both the initial states and transition probabilities over time using latent logistic regression. Because stepwise approaches often yield biased estimates, correction for classification error probabilities (CEPs) is considered in this approach. The three-step approach for latent transition CDM with covariates involves the following steps: (1) fitting a CDM to the response data without covariates at each time point separately, (2) assigning examinees to latent states at each time point and computing the associated CEPs, and (3) estimating the latent transition CDM with the known CEPs and computing the regression coefficients. The method was proposed in Liang et al. (2023) <doi:10.3102/10769986231163320> and demonstrated using mental health data in Liang et al. (in press; annotated R code and data utilized in this example are available in Mendeley data) <doi:10.17632/kpjp3gnwbt.1>.",
    "version": "1.1.0",
    "maintainer": "Qianru Liang <liangqr@jnu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3735,
    "package_name": "LabourMarketAreas",
    "title": "Identification, Tuning, Visualisation and Analysis of Labour\nMarket Areas",
    "description": "Produces Labour Market Areas from commuting flows available at elementary territorial units. It provides tools for automatic tuning based on spatial contiguity. It also allows for statistical analyses and visualisation of the new functional geography.",
    "version": "3.4",
    "maintainer": "Luisa Franconi <franconi@istat.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3741,
    "package_name": "LandComp",
    "title": "Analysing Landscape Composition and Structure at Multiple Scales",
    "description": "Changes of landscape diversity and structure can be detected\n    soon if relying on landscape class combinations and analysing patterns\n    at multiple scales. 'LandComp' provides such an opportunity, based on\n    Juhász-Nagy's functions (Juhász-Nagy P, Podani J 1983\n    <doi:10.1007/BF00129432>). Functions can handle multilayered data.\n    Requirements of the input: binary data contained by a regular square\n    or hexagonal grid, and the grid should have projected coordinates.",
    "version": "0.0.5",
    "maintainer": "Krisztina Dóra Konrád <konrad.krisztina@ecolres.hu>",
    "url": "https://github.com/ladylavender/LandComp,\nhttps://ladylavender.github.io/LandComp/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3749,
    "package_name": "Latamverse",
    "title": "Latin American Data via 'RESTful' APIs and Curated Datasets",
    "description": "Brings together a comprehensive collection \n    of R packages providing access to API functions and curated datasets from Argentina, Brazil, \n    Chile, Colombia, and Peru. Includes real-time and historical data through public \n    'RESTful' APIs ('Nager.Date', World Bank API, REST Countries API, and country-specific APIs) and \n    extensive curated collections of open datasets covering economics, demographics, public health, \n    environmental data, political indicators, social metrics, and cultural information. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to Latin American data sources, facilitating \n    reproducible research, comparative analysis, and teaching applications focused \n    on these five major Latin American countries.\n    Included packages:\n    - 'ArgentinAPI': API functions and curated datasets for Argentina covering exchange rates, inflation, political figures, national holidays and more.\n    - 'BrazilDataAPI': API functions and curated datasets for Brazil covering postal codes, banks, economic indicators, holidays, company registrations and more.\n    - 'ChileDataAPI': API functions and curated datasets for Chile covering financial indicators ('UF', UTM, Dollar, Euro, Yen, Copper, Bitcoin, 'IPSA' index), holidays and more.\n    - 'ColombiAPI': API functions and curated datasets for Colombia covering geographic locations, cultural attractions, economic indicators, demographic data, national holidays and more.\n    - 'PeruAPIs': API functions and curated datasets for Peru covering economic indicators, demographics, national holidays, administrative divisions, electoral data, biodiversity and more.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    World Bank API <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    REST Countries API <https://restcountries.com/>,\n    'ArgentinaDatos' API <https://argentinadatos.com/>,\n    'BrasilAPI' <https://brasilapi.com.br/>,\n    'FINDIC' <https://findic.cl/>,\n    and API-Colombia <https://api-colombia.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "url": "https://github.com/lightbluetitan/latamverse,\nhttps://lightbluetitan.github.io/latamverse/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3750,
    "package_name": "LatentBMA",
    "title": "Bayesian Model Averaging for Univariate Link Latent Gaussian\nModels",
    "description": "Bayesian model averaging (BMA) algorithms for univariate link latent Gaussian models (ULLGMs). For detailed information, refer to Steel M.F.J. & Zens G. (2024) \"Model Uncertainty in Latent Gaussian Models with Univariate Link Function\" <doi:10.48550/arXiv.2406.17318>. The package supports various g-priors and a beta-binomial prior on the model space. It also includes auxiliary functions for visualizing and tabulating BMA results. Currently, it offers an out-of-the-box solution for model averaging of Poisson log-normal (PLN) and binomial logistic-normal (BiL) models. The codebase is designed to be easily extendable to other likelihoods, priors, and link functions.",
    "version": "0.1.2",
    "maintainer": "Gregor Zens <zens@iiasa.ac.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3753,
    "package_name": "LatticeKrig",
    "title": "Multi-Resolution Kriging Based on Markov Random Fields",
    "description": "Methods for the interpolation of large spatial\n  datasets. This package uses a basis function approach that\n  provides a surface fitting method\n  that can approximate standard spatial data models.\n  Using a large number of basis functions allows for estimates that\n  can come close to interpolating the observations (a spatial model\n  with a small nugget variance.)  Moreover, the covariance model for\n  this method can approximate the Matern covariance family but also\n  allows for a multi-resolution model and supports efficient\n  computation of the profile likelihood for estimating covariance\n  parameters. This is accomplished through compactly supported basis\n  functions and a Markov random field model for the basis\n  coefficients. These features lead to sparse matrices for the\n  computations and this package makes of the R spam package for sparse\n  linear algebra.\n  An extension of this version over previous ones ( < 5.4 ) is the\n  support for different geometries besides a rectangular domain. The\n  Markov random field approach combined with a basis function\n  representation makes the implementation of different geometries\n  simple where only a few specific R functions need to be added with\n  most of the computation and evaluation done by generic routines that\n  have been tuned to be efficient.  One benefit of this package's\n  model/approach is the facility to do unconditional and conditional\n  simulation of the field for large numbers of arbitrary points. There\n  is also the flexibility for estimating non-stationary covariances\n  and also the case when the observations are a linear combination\n  (e.g. an integral) of the spatial process. Included are generic\n  methods for prediction, standard errors for prediction, plotting of\n  the estimated surface and conditional and unconditional simulation.\n  See the 'LatticeKrigRPackage' GitHub repository for a vignette of this\n  package.\n  Development of this package was supported in part by the National\n  Science Foundation  Grant 1417857 and the National Center for\n  Atmospheric Research. ",
    "version": "9.3.0",
    "maintainer": "Douglas Nychka <nychka@mines.edu>",
    "url": "https://www.r-project.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3762,
    "package_name": "LearnGeom",
    "title": "Learning Plane Geometry",
    "description": "Contains some functions to learn and teach basic plane Geometry at undergraduate level with the aim of being helpful to young students with little programming skills.",
    "version": "1.5",
    "maintainer": "Alvaro Briz-Redon <albrizre@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3815,
    "package_name": "LogRegEquiv",
    "title": "Logistic Regression Equivalence",
    "description": "Tools for assessing equivalence of similar Logistic Regression models.",
    "version": "0.1.5",
    "maintainer": "Guy Ashiri-Prossner <guy.ashiri@mail.huji.ac.il>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3818,
    "package_name": "LogisticCopula",
    "title": "A Copula Based Extension of Logistic Regression",
    "description": "An implementation of a method of extending a logistic regression\n    model beyond linear effects of the co-variates. The extension in is\n    constructed by first equating the logistic regression model to a naive Bayes\n    model where all the margins are specified to follow natural exponential \n    distributions conditional on Y, that is, a model for Y given X that is\n    specified through the distribution of X given Y, where the columns of X are\n    assumed to be mutually independent conditional on Y. Subsequently, the\n    model is expanded by adding vine - copulas to relax the assumption of\n    mutual independence, where pair-copulas are added in a stage-wise, forward\n    selection manner. Some heuristics are employed during the process of\n    selecting edges, as well as the families of pair-copula models. After each\n    component is added, the parameters are updated by a (smaller) number of\n    gradient steps to maximise the likelihood. When the algorithm has stopped\n    adding edges, based the criterion that a new edge should improve the\n    likelihood more than k times the number new parameters, the parameters are\n    updated with a larger number of gradient steps, or until convergence. ",
    "version": "0.1.0",
    "maintainer": "Simon Boge Brant <simbrant91@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3819,
    "package_name": "LogisticCurveFitting",
    "title": "Logistic Curve Fitting by Rhodes Method",
    "description": "A system for fitting Logistic Curve by Rhodes Method. Method for fitting logistic curve by Rhodes Method is described in A.M.Gun,M.K.Gupta and B.Dasgupta(2019,ISBN:81-87567-81-3).",
    "version": "0.1.0",
    "maintainer": "Debarghya Baul <debarghyabaul@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3820,
    "package_name": "LogisticEnsembles",
    "title": "Automatically Runs 24 Logistic Models (Individual and Ensembles)",
    "description": "Automatically returns 24 logistic models including 13 individual models and 11 ensembles of models of logistic data. The package also returns 25 plots, 5 tables, and a summary report. The package automatically\n    builds all 24 models, reports all results, and provides graphics to show how the models performed. This can be used for a wide range of data, such as sports or medical data. The package includes medical data (the Pima Indians data set), and\n    information about the performance of Lebron James. The package can be used to analyze many other examples, such as stock market data. The package automatically returns many values for each model, such as\n    True Positive Rate, True Negative Rate, False Positive Rate, False Negative Rate, Positive Predictive Value, Negative Predictive Value, F1 Score, Area Under the Curve. The package also returns 36 Receiver\n    Operating Characteristic (ROC) curves for each of the 24 models.",
    "version": "0.8.2",
    "maintainer": "Russ Conte <russconte@mac.com>",
    "url": "https://github.com/InfiniteCuriosity/LogisticEnsembles",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3821,
    "package_name": "LogisticRCI",
    "title": "Linear and Logistic Regression-Based Reliable Change Index",
    "description": "Here we provide an implementation of the linear and logistic regression-based Reliable Change Index (RCI), to be used with lm and binomial glm model objects, respectively, following Moral et al. <https://psyarxiv.com/gq7az/>. The RCI function returns a score assumed to be approximately normally distributed, which is helpful to detect patients that may present cognitive decline.",
    "version": "1.1",
    "maintainer": "Rafael de Andrade Moral <rafael.deandrademoral@mu.ie>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3878,
    "package_name": "MARSGWR",
    "title": "A Hybrid Spatial Model for Capturing Spatially Varying\nRelationships Between Variables in the Data",
    "description": "It is a hybrid spatial model that combines the strength of two widely used regression models, MARS (Multivariate Adaptive Regression Splines) and\n             GWR (Geographically Weighted Regression) to provide an effective approach for predicting a response variable at unknown locations. The MARS model\n             is used in the first step of the development of a hybrid model to identify the most important predictor variables that assist in predicting the response\n             variable. For method details see, Friedman, J.H. (1991). <DOI:10.1214/aos/1176347963>.The GWR model is then used to predict the response variable at \n             testing locations based on these selected variables that account for spatial variations in the relationships between the variables. This hybrid model \n             can improve the accuracy of the predictions compared to using an individual model alone.This developed hybrid spatial model can be useful particularly in \n             cases where the relationship between the response variable and predictor variables is complex and non-linear, and varies across locations.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3885,
    "package_name": "MAT",
    "title": "Multidimensional Adaptive Testing",
    "description": "Simulates Multidimensional Adaptive Testing using the multidimensional three-parameter logistic model as described in Segall (1996) <doi:10.1007/BF02294343>, van der Linden (1999) <doi:10.3102/10769986024004398>, Reckase (2009) <doi:10.1007/978-0-387-89976-3>, and Mulder & van der Linden (2009) <doi:10.1007/s11336-008-9097-5>.",
    "version": "2.3.2",
    "maintainer": "Seung W. Choi <schoi@austin.utexas.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3892,
    "package_name": "MBA",
    "title": "Multilevel B-Spline Approximation",
    "description": "Functions to interpolate irregularly and regularly spaced data using Multilevel B-spline Approximation (MBA). Functions call portions of the SINTEF Multilevel B-spline Library written by Øyvind Hjelle which implements methods developed by Lee, Wolberg and Shin (1997; <doi:10.1109/2945.620490>).",
    "version": "0.1-2",
    "maintainer": "Andrew Finley <finleya@msu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3902,
    "package_name": "MBHdesign",
    "title": "Spatial Designs for Ecological and Environmental Surveys",
    "description": "Provides spatially survey balanced designs using the quasi-random number method described Robinson et al. (2013) <doi:10.1111/biom.12059> and adjusted in Robinson et al. (2017) <doi:10.1016/j.spl.2017.05.004>. Designs using MBHdesign can: 1) accommodate, without substantial detrimental effects on spatial balance, legacy sites (Foster et al., 2017 <doi:10.1111/2041-210X.12782>); 2) be based on points or transects (foster et al. 2020 <doi:10.1111/2041-210X.13321> and produce clustered samples (Foster et al. (in press). Additional information about the package use itself is given in Foster (2021) <doi:10.1111/2041-210X.13535>.",
    "version": "2.3.15",
    "maintainer": "Scott Foster <scott.foster@data61.csiro.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3914,
    "package_name": "MCBackscattering",
    "title": "Monte Carlo Simulation for Surface Backscattering",
    "description": "Monte Carlo simulation is a stochastic method computing trajectories of photons in media. Surface backscattering is performing calculations in semi-infinite media and summarizing photon flux leaving the surface. This simulation is modeling the optical measurement of diffuse reflectance using an incident light beam. The semi-infinite media is considered to have flat surface. Media, typically biological tissue, is described by four optical parameters: absorption coefficient, scattering coefficient, anisotropy factor, refractive index. The media is assumed to be homogeneous.\n    Computational parameters of the simulation include: number of photons, radius of incident light beam, lowest photon energy threshold, intensity profile (halo) radius, spatial resolution of intensity profile.\n    You can find more information and validation in the Open Access paper.\n    Laszlo Baranyai (2020) <doi:10.1016/j.mex.2020.100958>.",
    "version": "0.1.1",
    "maintainer": "Laszlo Baranyai <Baranyai.Laszlo@etk.szie.hu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3945,
    "package_name": "MDMAPR",
    "title": "Molecular Detection Mapping and Analysis Platform",
    "description": "Runs a Shiny web application that merges raw 'qPCR' fluorescence data with related \n    metadata to visualize species presence/absence detection patterns and assess data quality. \n    The application calculates threshold values from raw fluorescence data using a method based \n    on the second derivative method, Luu-The et al (2005) <doi:10.2144/05382RR05>,  and utilizes \n    the ‘chipPCR’ package by Rödiger, Burdukiewicz, & Schierack (2015) <doi:10.1093/bioinformatics/btv205> \n    to calculate Cq values. The application has the ability to connect to a custom developed MySQL \n    database to populate the applications interface. The application allows users to interact with \n    visualizations such as a dynamic map, amplification curves and standard curves, that allow for \n    zooming and/or filtering. It also enables the generation of customized exportable reports based\n    on filtered mapping data. ",
    "version": "0.2.3",
    "maintainer": "Alka Benawra <alkabenawra@rogers.com>",
    "url": "https://github.com/HannerLab/MDMAPR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3950,
    "package_name": "MDSGUI",
    "title": "A GUI for interactive MDS in R",
    "description": "A graphical user interface (GUI) for performing Multidimensional Scaling applications and interactively analysing the results all within the GUI environment. The MDS-GUI provides means of performing Classical Scaling, Least Squares Scaling, Metric SMACOF, Non-Metric SMACOF, Kruskal's Analysis and Sammon Mapping with animated optimisation.",
    "version": "0.1.6",
    "maintainer": "Andrew Timm <timmand@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3951,
    "package_name": "MDSMap",
    "title": "High Density Genetic Linkage Mapping using Multidimensional\nScaling",
    "description": "Estimate genetic linkage maps for markers on a single chromosome (or in a single linkage group) from pairwise recombination fractions or intermarker distances using weighted metric multidimensional scaling. The methods are suitable for autotetraploid as well as diploid populations. Options for assessing the fit to a known map are also provided. Methods are discussed in detail in Preedy and Hackett (2016) <doi:10.1007/s00122-016-2761-8>.",
    "version": "1.3",
    "maintainer": "Bram Boskamp <bram.boskamp@bioss.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3955,
    "package_name": "MDimNormn",
    "title": "Multi-Dimensional MA Normalization for Plate Effect",
    "description": "Normalize data to minimize the difference between sample plates \n    (batch effects). For given data in a matrix and grouping variable (or\n\tplate), the function 'normn_MA' normalizes the data on MA coordinates. \n\tMore details are in the citation. The primary method is 'Multi-MA'. Other \n\tfitting functions on MA coordinates can also be employed e.g. loess.  ",
    "version": "0.8.0",
    "maintainer": "Mun-Gwan Hong <mun-gwan.hong@scilifelab.se>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 3972,
    "package_name": "MERINGUE",
    "title": "Characterizing spatial gene expression heterogeneity in spatially resolved single-cell transcriptomics data with non-uniform cellular densities",
    "description": "MERINGUE is a computational framework based on spatial auto-correlation and cross-correlation analysis to identify genes with spatially heterogeneous expression patterns, derive putative cell-cell communication, and perform spatially informed cell clustering in 2D and 3D in a density-agnostic manner using spatially resolved transcriptomics data.",
    "version": "1.0",
    "maintainer": "",
    "url": "https://github.com/JEFworks-Lab/MERINGUE",
    "exports": [],
    "topics": ["cell-cell-communication", "gene-expression", "rstats", "single-cell", "spatial-analysis", "spatial-transcriptomics"],
    "score": "NA",
    "stars": 82
  },
  {
    "id": 3992,
    "package_name": "MGPSDK",
    "title": "Interact with the Maxar 'MGP' Application Programming Interfaces",
    "description": "Provides an interface to the Maxar Geospatial Platform (MGP) Application Programming Interface. <https://www.maxar.com/maxar-geospatial-platform>\n    It facilitates imagery searches using the MGP Streaming Application Programming Interface via the Web Feature Service (WFS) method, and supports image downloads through Web Map Service (WMS) and Web Map Tile Service (WMTS)\n    Open Geospatial Consortium (OGC) methods. \n    Additionally, it integrates with the Maxar Geospatial Platform Basemaps Application Programming Interface for accessing Maxar basemaps imagery and seamlines. \n    The package also offers seamless integration with the Maxar Geospatial Platform Discovery Application Programming Interface, allowing users to search, filter, and sort Maxar content, \n    while retrieving detailed metadata in formats like SpatioTemporal Asset Catalog (STAC) and GeoJSON.",
    "version": "1.0.0",
    "maintainer": "Nathan Carr <nathan.carr@maxar.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4001,
    "package_name": "MHTrajectoryR",
    "title": "Bayesian Model Selection in Logistic Regression for the\nDetection of Adverse Drug Reactions",
    "description": "Spontaneous adverse event reports have a high potential for detecting adverse drug reactions. However, due to their dimension, the analysis of such databases requires statistical methods. We propose to use a logistic regression whose sparsity is viewed as a model selection challenge. Since the model space is huge, a Metropolis-Hastings algorithm carries out the model selection by maximizing the BIC criterion.",
    "version": "1.0.1",
    "maintainer": "Mohammed Sedki <Mohammed.sedki@u-psud.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4002,
    "package_name": "MIAmaxent",
    "title": "A Modular, Integrated Approach to Maximum Entropy Distribution\nModeling",
    "description": "Tools for training, selecting, and evaluating maximum entropy\n    (and standard logistic regression) distribution models. This package \n    provides tools for user-controlled transformation of explanatory variables, \n    selection of variables by nested model comparison, and flexible model \n    evaluation and projection. It follows principles based on the maximum-\n    likelihood interpretation of maximum entropy modeling, and uses infinitely-\n    weighted logistic regression for model fitting. The package is described in \n    Vollering et al. (2019; <doi:10.1002/ece3.5654>).",
    "version": "1.4.1",
    "maintainer": "Julien Vollering <julienvollering@gmail.com>",
    "url": "https://github.com/julienvollering/MIAmaxent",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4030,
    "package_name": "ML2Pvae",
    "title": "Variational Autoencoder Models for IRT Parameter Estimation",
    "description": "Based on the work of Curi, Converse, Hajewski, and Oliveira (2019) <doi:10.1109/IJCNN.2019.8852333>. This package provides easy-to-use functions which create a variational autoencoder (VAE) to be used for parameter estimation in Item Response Theory (IRT) - namely the Multidimensional Logistic 2-Parameter (ML2P) model. To use a neural network as such, nontrivial modifications to the architecture must be made, such as restricting the nonzero weights in the decoder according to some binary matrix Q. The functions in this package allow for straight-forward construction, training, and evaluation so that minimal knowledge of 'tensorflow' or 'keras' is required. ",
    "version": "1.0.0.1",
    "maintainer": "Geoffrey Converse <converseg@gmail.com>",
    "url": "https://converseg.github.io",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4080,
    "package_name": "MNLR",
    "title": "Interactive Shiny Presentation for Working with Multinomial\nLogistic Regression",
    "description": "An interactive presentation on  the topic of Multinomial Logistic Regression. It is helpful to those who want to learn Multinomial Logistic Regression quickly and get a hands on experience. The presentation has a template for solving problems on Multinomial Logistic Regression. Runtime examples are provided in the package function as well as at  <https://jarvisatharva.shinyapps.io/MultinomPresentation>. ",
    "version": "0.1.0",
    "maintainer": "Kartikeya Bolar <kartikeya.bolar@tapmi.edu.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4081,
    "package_name": "MNM",
    "title": "Multivariate Nonparametric Methods. An Approach Based on Spatial\nSigns and Ranks",
    "description": "Multivariate tests, estimates and methods based on the identity score, spatial sign score and spatial rank score are provided. The methods include one and c-sample problems, shape estimation and testing, linear regression and principal components. The methodology is described in Oja (2010) <doi:10.1007/978-1-4419-0468-3> and Nordhausen and Oja (2011) <doi:10.18637/jss.v043.i05>.  ",
    "version": "1.0-4",
    "maintainer": "Klaus Nordhausen <klausnordhausenR@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4087,
    "package_name": "MODISTools",
    "title": "Interface to the 'MODIS Land Products Subsets' Web Services",
    "description": "Programmatic interface to the Oak Ridge National Laboratories\n    'MODIS Land Products Subsets' web services \n    (<https://modis.ornl.gov/data/modis_webservice.html>). Allows for easy\n    downloads of 'MODIS' time series directly to your R workspace or\n    your computer.",
    "version": "1.1.5",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "url": "https://github.com/bluegreen-labs/MODISTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4097,
    "package_name": "MOQA",
    "title": "Basic Quality Data Assurance for Epidemiological Research",
    "description": "With the provision of several tools and templates the MOSAIC project (DFG-Grant Number HO 1937/2-1) supports the implementation of a central data management in epidemiological research projects. The 'MOQA' package enables epidemiologists with none or low experience in R to generate basic data quality reports for a wide range of application scenarios. See <https://mosaic-greifswald.de/> for more information. Please read and cite the corresponding open access publication (using the former package-name) in METHODS OF INFORMATION IN MEDICINE by M. Bialke, H. Rau, T. Schwaneberg, R. Walk, T. Bahls and W. Hoffmann (2017) <doi:10.3414/ME16-01-0123>. <https://methods.schattauer.de/en/contents/most-recent-articles/issue/2483/issue/special/manuscript/27573/show.html>.",
    "version": "2.0.0",
    "maintainer": "Martin Bialke <mosaic-projekt@uni-greifswald.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4113,
    "package_name": "MPS",
    "title": "Estimating Through the Maximum Product Spacing Approach",
    "description": "Developed for computing the probability density function, computing the cumulative distribution function, computing the quantile function, random generation, drawing q-q plot, and estimating the parameters of 24 G-family of statistical distributions via the maximum product spacing approach introduced in <https://www.jstor.org/stable/2345411>. The set of families contains: beta G distribution, beta exponential G distribution, beta extended G distribution, exponentiated G distribution, exponentiated exponential Poisson G distribution, exponentiated generalized G distribution, exponentiated Kumaraswamy G distribution, gamma type I G distribution, gamma type II G distribution, gamma uniform G distribution, gamma-X generated of log-logistic family of G distribution, gamma-X family of modified beta exponential G distribution, geometric exponential Poisson G distribution, generalized beta G distribution, generalized transmuted G distribution, Kumaraswamy G distribution, log gamma type I G distribution, log gamma type II G distribution, Marshall Olkin G distribution, Marshall Olkin Kumaraswamy G distribution, modified beta G distribution, odd log-logistic G distribution, truncated-exponential skew-symmetric G distribution, and Weibull G distribution.",
    "version": "2.3.1",
    "maintainer": "Mahdi Teimouri <teimouri@aut.ac.ir>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4121,
    "package_name": "MRAM",
    "title": "Multivariate Regression Association Measure",
    "description": "Implementations of an estimator for the multivariate regression association measure (MRAM) proposed in Shih and Chen (2026) <doi:10.1016/j.csda.2025.108288> and its associated variable selection algorithm. The MRAM quantifies the predictability of a random vector Y from a random vector X given a random vector Z. It takes the maximum value 1 if and only if Y is almost surely a measurable function of X and Z, and the minimum value of 0 if Y is conditionally independent of X given Z. The MRAM generalizes the Kendall's tau copula correlation ratio proposed in Shih and Emura (2021) <doi:10.1016/j.jmva.2020.104708> by employing the spatial sign function. The estimator is based on the nearest neighbor method, and the associated variable selection algorithm is adapted from the feature ordering by conditional independence (FOCI) algorithm of Azadkia and Chatterjee (2021) <doi:10.1214/21-AOS2073>. For further details, see the paper Shih and Chen (2026) <doi:10.1016/j.csda.2025.108288>.",
    "version": "1.0.0",
    "maintainer": "Jia-Han Shih <jhshih@math.nsysu.edu.tw>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4124,
    "package_name": "MRFA",
    "title": "Fitting and Predicting Large-Scale Nonlinear Regression Problems\nusing Multi-Resolution Functional ANOVA (MRFA) Approach",
    "description": "Performs the MRFA approach proposed by Sung et al. (2020) <doi:10.1080/01621459.2019.1595630> to fit\n    and predict nonlinear regression problems, particularly for large-scale and\n    high-dimensional problems. The application includes deterministic or stochastic\n    computer experiments, spatial datasets, and so on.",
    "version": "0.6",
    "maintainer": "Chih-Li Sung <sungchih@msu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4129,
    "package_name": "MRMCbinary",
    "title": "Multi-Reader Multi-Case Analysis of Binary Diagnostic Tests",
    "description": "The goal of 'MRMCbinary' is to compare the performance of diagnostic tests (i.e., sensitivity and specificity) for binary outcomes in multi-reader multi-case (MRMC) studies. It is based on conditional logistic regression and Cochran’s Q test (or McNemar’s test when the number of modalities is equal to 2).",
    "version": "1.0.5",
    "maintainer": "Seungjae Lee <seungjae2525@gmail.com>",
    "url": "https://github.com/seungjae2525/MRMCbinary",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4154,
    "package_name": "MSMwRA",
    "title": "Multivariate Statistical Methods with R Applications",
    "description": "Data sets in the book entitled \"Multivariate Statistical Methods with R Applications\", H.Bulut (2018). \n             The book was published in Turkish and the original name of this book will be \"R Uygulamalari ile Cok Degiskenli Istatistiksel Yontemler\".",
    "version": "1.5",
    "maintainer": "Hasan BULUT <hasan.bulut@omu.edu.tr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4189,
    "package_name": "MTLR",
    "title": "Survival Prediction with Multi-Task Logistic Regression",
    "description": "An implementation of Multi-Task Logistic Regression (MTLR) for R. \n  This package is based on the method proposed by Yu et al. (2011) which utilized MTLR for generating individual survival curves\n  by learning feature weights which vary across time. This model was further extended to account for left and interval censored data.",
    "version": "0.2.1",
    "maintainer": "Humza Haider <hshaider@ualberta.ca>",
    "url": "https://github.com/haiderstats/MTLR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4232,
    "package_name": "MandalaR",
    "title": "Building Mandalas from Parametric Equations of Classical Curves",
    "description": "Provides an algorithm for creating mandalas. From the perspective of classic mathematical curves and rigid movements on the plane, the package allows you to select curves and produce mandalas from the curve. The algorithm was developed based on the book by Alcoforado et. al. entitled \"Art, Geometry and Mandalas with R\" (2022) in press by the USP Open Books Portal.",
    "version": "0.1.0",
    "maintainer": "Luciane Ferreira Alcoforado <lucianea@id.uff.br>",
    "url": "https://lucianealcoforado.shinyapps.io/Mandala/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4243,
    "package_name": "MapGAM",
    "title": "Mapping Smoothed Effect Estimates from Individual-Level Data",
    "description": "Contains functions for mapping odds ratios, hazard ratios, or other effect estimates using individual-level data such as case-control study data, using generalized additive models (GAMs) or Cox models for smoothing with a two-dimensional predictor (e.g., geolocation or exposure to chemical mixtures) while adjusting linearly for confounding variables, using methods described by Kelsall and Diggle (1998), Webster at al. (2006), and Bai et al. (2020).  Includes convenient functions for mapping point estimates and confidence intervals, efficient control sampling, and permutation tests for the null hypothesis that the two-dimensional predictor is not associated with the outcome variable (adjusting for confounders).     ",
    "version": "1.3-1",
    "maintainer": "Scott Bartell <sbartell@uci.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4244,
    "package_name": "Mapinguari",
    "title": "Process-Based Biogeographical Analysis",
    "description": "Facilitates the incorporation of biological processes in biogeographical analyses. It offers conveniences in fitting, comparing and extrapolating models of biological processes such as physiology and phenology. These spatial extrapolations can be informative by themselves, but also complement traditional correlative species distribution models, by mixing environmental and process-based predictors. Caetano et al (2020) <doi:10.1111/oik.07123>.",
    "version": "2.0.1",
    "maintainer": "Gabriel Caetano <gabrielhoc@gmail.com>",
    "url": "https://github.com/gabrielhoc/Mapinguari",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4278,
    "package_name": "MaxWiK",
    "title": "Machine Learning Method Based on Isolation Kernel Mean Embedding",
    "description": "Incorporates Approximate Bayesian Computation to get a posterior distribution and to select a model optimal parameter for an observation point. Additionally, the meta-sampling heuristic algorithm is realized for parameter estimation, which requires no model runs and is dimension-independent. A sampling scheme is also presented that allows model runs and uses the meta-sampling for point generation. A predictor is realized as the meta-sampling for the model output. All the algorithms leverage a machine learning method utilizing the maxima weighted Isolation Kernel approach, or 'MaxWiK'. The method involves transforming raw data to a Hilbert space (mapping) and measuring the similarity between simulated points and the maxima weighted Isolation Kernel mapping corresponding to the observation point. Comprehensive details of the methodology can be found in the papers Iurii Nagornov (2024) <doi:10.1007/978-3-031-66431-1_16> and Iurii Nagornov (2023) <doi:10.1007/978-3-031-29168-5_18>.",
    "version": "1.0.6",
    "maintainer": "Yuri Nagornov <nagornov.yuri@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4282,
    "package_name": "MazamaLocationUtils",
    "title": "Manage Spatial Metadata for Known Locations",
    "description": "Utility functions for discovering and managing metadata \n    associated with spatially unique \"known locations\". Applications include\n    all fields of environmental monitoring (e.g. air and water quality) where \n    data are collected at stationary sites.",
    "version": "0.4.4",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "url": "https://github.com/MazamaScience/MazamaLocationUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4284,
    "package_name": "MazamaSpatialPlots",
    "title": "Thematic Plots for Mazama Spatial Datasets",
    "description": "A suite of convenience functions for generating US state and county\n    thematic maps using datasets from the MazamaSpatialUtils package.",
    "version": "0.3.0",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "url": "https://github.com/MazamaScience/MazamaSpatialPlots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4286,
    "package_name": "MazamaTimeSeries",
    "title": "Core Functionality for Environmental Time Series",
    "description": "Utility functions for working with environmental time series data from known \n    locations. The compact data model is structured as a list with two dataframes. A \n    'meta' dataframe contains spatial and measuring device metadata associated with \n    deployments at known locations. A 'data' dataframe contains a 'datetime' column \n    followed by columns of measurements associated with each \"device-deployment\".\n    Ephemerides calculations are based on code originally found in NOAA's\n    \"Solar Calculator\" <https://gml.noaa.gov/grad/solcalc/>.",
    "version": "0.3.1",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "url": "https://github.com/MazamaScience/MazamaTimeSeries,\nhttps://mazamascience.github.io/MazamaTimeSeries/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4428,
    "package_name": "ModStatR",
    "title": "Statistical Modelling in Action with R",
    "description": "Datasets and functions for the book \"Modélisation statistique par la pratique avec R\", F. Bertrand, E. Claeys and M. Maumy-Bertrand (2019, ISBN:9782100793525, Dunod, Paris). The first chapter of the book is dedicated to an introduction to the R statistical software. The second chapter deals with correlation analysis: Pearson, Spearman and Kendall simple, multiple and partial correlation coefficients. New wrapper functions for permutation tests or bootstrap of matrices of correlation are provided with the package. The third chapter is dedicated to data exploration with factorial analyses (PCA, CA, MCA, MDA) and clustering. The fourth chapter is dedicated to regression analysis: fitting and model diagnostics are detailed. The exercises focus on covariance analysis, logistic regression, Poisson regression, two-way analysis of variance for fixed or random factors. Various example datasets are shipped with the package: for instance on pokemon, world of warcraft, house tasks or food nutrition analyses.",
    "version": "1.4.1",
    "maintainer": "Frederic Bertrand <frederic.bertrand@lecnam.net>",
    "url": "https://fbertran.github.io/homepage/,\nhttps://fbertran.github.io/ModStatR/,\nhttps://github.com/fbertran/ModStatR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4431,
    "package_name": "ModelMap",
    "title": "Modeling and Map Production using Random Forest and Related\nStochastic Models",
    "description": "Creates sophisticated models of training data and validates the models with an independent test set, cross validation, or Out Of Bag (OOB) predictions on the training data. Create graphs and tables of the model validation results. Applies these models to GIS .img files of predictors to create detailed prediction surfaces. Handles large predictor files for map making, by reading in the .img files in chunks, and output to the .txt file the prediction for each data chunk, before reading the next chunk of data.",
    "version": "3.4.0.8",
    "maintainer": "Elizabeth Freeman <elizabeth.a.freeman@usda.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4453,
    "package_name": "MorphoTools2",
    "title": "Multivariate Morphometric Analysis",
    "description": "Tools for multivariate analyses of morphological data, wrapped in one package, to make the workflow convenient and fast. Statistical and graphical tools provide a comprehensive framework for checking and manipulating input data, statistical analyses, and visualization of results. Several methods are provided for the analysis of raw data, to make the dataset ready for downstream analyses. Integrated statistical methods include hierarchical classification, principal component analysis, principal coordinates analysis, non-metric multidimensional scaling, and multiple discriminant analyses: canonical, stepwise, and classificatory (linear, quadratic, and the non-parametric k nearest neighbours). The philosophy of the package is described in Šlenker et al. 2022.",
    "version": "1.0.2.1",
    "maintainer": "Marek Šlenker <marek.slenker@savba.sk>",
    "url": "https://github.com/MarekSlenker/MorphoTools2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4486,
    "package_name": "MullerPlot",
    "title": "Generates Muller Plot from Population/Abundance/Frequency\nDynamics Data",
    "description": "Generates Muller plot from parental/genealogy/phylogeny information and population/abundance/frequency dynamics data.\n    Muller plots are plots which combine information about succession of different OTUs (genotypes, phenotypes, species, ...) and information about dynamics of their abundances (populations or frequencies) over time. They are powerful and fascinating tools to visualize evolutionary dynamics. They may be employed also in study of diversity and its dynamics, i.e. how diversity emerges and how changes over time. They are called Muller plots in honor of Hermann Joseph Muller which used them to explain his idea of Muller's ratchet (Muller, 1932, American Naturalist).\n    A big difference between Muller plots and normal box plots of abundances is that a Muller plot depicts not only the relative abundances but also succession of OTUs based on their genealogy/phylogeny/parental relation. In a Muller plot, horizontal axis is time/generations and vertical axis represents relative abundances of OTUs at the corresponding times/generations. Different OTUs are usually shown with polygons with different colors and each OTU originates somewhere in the middle of its parent area in order to illustrate their succession in evolutionary process.\n    To generate a Muller plot one needs the genealogy/phylogeny/parental relation of OTUs and their abundances over time.\n    MullerPlot package has the tools to generate Muller plots which clearly depict the origin of successors of OTUs.",
    "version": "0.1.3",
    "maintainer": "Farnoush Farahpour <farnoush.farahpour@uni-due.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4490,
    "package_name": "MultIS",
    "title": "Reconstruction of Clones from Integration Site Readouts and\nVisualization",
    "description": "Tools necessary to reconstruct clonal affiliations from\n    temporally and/or spatially separated measurements of viral\n    integration sites. For this means it utilizes correlations present\n    in the relative readouts of the integration sites. Furthermore,\n    facilities for filtering of the data and visualization of different\n    steps in the pipeline are provided with the package.",
    "version": "0.6.2",
    "maintainer": "Sebastian Wagner <sebastian.wagner3@tu-dresden.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4530,
    "package_name": "MultiscaleDTM",
    "title": "Multi-Scale Geomorphometric Terrain Attributes",
    "description": "Calculates multi-scale geomorphometric terrain attributes from regularly gridded digital terrain models using a variable focal windows size (Ilich et al. (2023) <doi:10.1111/tgis.13067>).",
    "version": "1.0.1",
    "maintainer": "Alexander Ilich <ailich@usf.edu>",
    "url": "https://ailich.github.io/MultiscaleDTM/,\nhttps://github.com/ailich/MultiscaleDTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4580,
    "package_name": "NGBVS",
    "title": "Bayesian Variable Selection for SNP Data using Normal-Gamma",
    "description": "Posterior distribution of case-control fine-mapping. Specifically, Bayesian variable selection for single-nucleotide polymorphism (SNP) data using the normal-gamma prior. Alenazi A.A., Cox A., Juarez M,. Lin W-Y. and Walters, K. (2019) Bayesian variable selection using partially observed categorical prior information in fine-mapping association studies, Genetic Epidemiology. <doi:10.1002/gepi.22213>.",
    "version": "0.3.0",
    "maintainer": "Abdulaziz Alenazi <a.alenazi@nbu.edu.sa>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4643,
    "package_name": "NScluster",
    "title": "Simulation and Estimation of the Neyman-Scott Type Spatial\nCluster Models",
    "description": "Simulation and estimation for Neyman-Scott spatial cluster point\n process models and their extensions, based on the methodology in Tanaka, Ogata,\n and Stoyan (2008) <doi:10.1002/bimj.200610339>. To estimate parameters by the\n simplex method, parallel computation using 'OpenMP' application programming\n interface is available. For more details see Tanaka, Saga and Nakano\n <doi:10.18637/jss.v098.i06>.",
    "version": "1.3.6-4",
    "maintainer": "Masami Saga <msaga@mtb.biglobe.ne.jp>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4646,
    "package_name": "NTSS",
    "title": "Nonparametric Tests in Spatial Statistics",
    "description": "Nonparametric test of independence between a pair of spatial objects\n    (random fields, point processes) based on random shifts with torus or variance correction. See\n    Mrkvička et al. (2021) <doi:10.1016/j.spasta.2020.100430>,\n    Dvořák et al. (2022) <doi:10.1111/insr.12503>,\n    Dvořák and Mrkvička (2024) <doi:10.1080/10618600.2024.2357626>.",
    "version": "0.1.3",
    "maintainer": "Jiří Dvořák <dvorak@karlin.mff.cuni.cz>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4680,
    "package_name": "NetLogoR",
    "title": "Build and Run Spatially Explicit Agent-Based Models",
    "description": "Build and run spatially explicit\n    agent-based models using only the R platform. 'NetLogoR' follows the same\n    framework as the 'NetLogo' software\n    (Wilensky (1999) <https://www.netlogo.org>) and is a translation\n    in R of the structure and functions of 'NetLogo'.\n    'NetLogoR' provides new R classes to define model agents and functions to\n    implement spatially explicit agent-based models in the R environment.\n    This package allows benefiting of the fast and easy coding phase from the\n    highly developed 'NetLogo' framework, coupled with the versatility, power\n    and massive resources of the R software.\n    Examples of two models from the NetLogo software repository \n    (Ants <https://ccl.northwestern.edu/netlogo/models/Ants>) and \n    Wolf-Sheep-Predation \n    (<https://ccl.northwestern.edu/netlogo/models/WolfSheepPredation>),\n    and a third, Butterfly, from \n    Railsback and Grimm (2012) <https://www.railsback-grimm-abm-book.com/>, all\n    written using 'NetLogoR' are available. \n    The 'NetLogo' code of the original version of these\n    models is provided alongside.\n    A programming guide inspired from the 'NetLogo' Programming Guide\n    (<https://docs.netlogo.org/programming.html>) and a dictionary\n    of 'NetLogo' primitives (<https://docs.netlogo.org/dictionary.html>)\n    equivalences are also available.\n    NOTE: To increment 'time', these functions can use a for loop or can be\n    integrated with a discrete event simulator, such as 'SpaDES'\n    (<https://cran.r-project.org/package=SpaDES>).",
    "version": "1.0.6",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "url": "https://netlogor.predictiveecology.org,\nhttps://github.com/PredictiveEcology/NetLogoR/,\nhttps://groups.google.com/g/netlogor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4712,
    "package_name": "NipponMap",
    "title": "Japanese Map Data and Functions",
    "description": "Digital map data of Japan for choropleth mapping, including a circle cartogram.",
    "version": "0.2",
    "maintainer": "Susumu Tanimura <aruminat@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4723,
    "package_name": "NonNorMvtDist",
    "title": "Multivariate Lomax (Pareto Type II) and Its Related\nDistributions",
    "description": "Implements calculation of probability density function, cumulative distribution function, equicoordinate quantile function and survival function, and random numbers generation for the following multivariate distributions: Lomax (Pareto Type II), generalized Lomax, Mardia’s Pareto of Type I, Logistic, Burr, Cook-Johnson’s uniform, F and Inverted Beta. See Tapan Nayak (1987) <doi:10.2307/3214068>.",
    "version": "1.1.0",
    "maintainer": "Zhixin Lun <zhixin.lun@cuanschutz.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4744,
    "package_name": "OBASpatial",
    "title": "Objective Bayesian Analysis for Spatial Regression Models",
    "description": "It makes an objective Bayesian analysis of the spatial regression model using both the normal (NSR) and student-T (TSR) distributions. The functions provided give prior and posterior objective densities and allow default Bayesian estimation of the model regression parameters. Details can be found in Ordonez et al. (2020) <arXiv:2004.04341>.",
    "version": "1.9",
    "maintainer": "Alejandro Ordonez <ordonezjosealejandro@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4770,
    "package_name": "ONEST",
    "title": "Observers Needed to Evaluate Subjective Tests",
    "description": "\n    This ONEST software implements the method of assessing the pathologist agreement in reading PD-L1 assays (Reisenbichler et al. (2020 <doi:10.1038/s41379-020-0544-x>)), to determine the minimum number of evaluators needed to estimate agreement involving a large number of raters. Input to the program should be binary(1/0) pathology data, where “0” may stand for negative and “1” for positive. Additional examples were given using the data from Rimm et al. (2017 <doi:10.1001/jamaoncol.2017.0013>). ",
    "version": "0.1.0",
    "maintainer": "Gang Han <hangang.true@gmail.com>",
    "url": "https://github.com/hangangtrue/ONEST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4798,
    "package_name": "OSMscale",
    "title": "Add a Scale Bar to 'OpenStreetMap' Plots",
    "description": "Functionality to handle and project lat-long coordinates, easily download background maps\n    and add a correct scale bar to 'OpenStreetMap' plots in any map projection.",
    "version": "0.5.23",
    "maintainer": "Berry Boessenkool <berry-b@gmx.de>",
    "url": "https://github.com/brry/OSMscale",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4799,
    "package_name": "OSMtidy",
    "title": "OSMtidy is an R package for anyone who needs to tidy Open Street Map data into a concise yet complex geospatial dataset with a consistent naming convention.",
    "description": "OSMtidy is a software code, created in R.",
    "version": "0.0.6",
    "maintainer": "Dr Annie Visser-Quinn <a.visser-quinn@hw.ac.uk> and Dr Melissa Bedinger <m.bedinger@ed.ac.uk>",
    "url": "https://github.com/anniequinn/OSMtidy",
    "exports": [],
    "topics": ["geospatial", "mapping", "openstreetmap", "r", "software"],
    "score": "NA",
    "stars": 9
  },
  {
    "id": 4802,
    "package_name": "OTBsegm",
    "title": "Apply Unsupervised Segmentation Algorithms from 'OTB'",
    "description": "Apply unsupervised segmentation algorithms included in 'Orfeo ToolBox' software (<https://www.orfeo-toolbox.org/>), such as mean shift or watershed segmentation.",
    "version": "0.1.0",
    "maintainer": "Adrián Cidre González <adrian.cidre@gmail.com>",
    "url": "https://cidree.github.io/OTBsegm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4816,
    "package_name": "OasisR",
    "title": "Outright Tool for the Analysis of Spatial Inequalities and\nSegregation",
    "description": "A comprehensive set of indexes and tests for social segregation analysis,\n              as described in Tivadar (2019) - 'OasisR': An R Package to Bring Some Order\n              to the World of Segregation Measurement <doi:10.18637/jss.v089.i07>.\n              The package  is the most complete existing tool and it clarifies\n              many ambiguities and errors regarding the definition of segregation\n              indices. Additionally, 'OasisR' introduces several resampling methods\n              that enable testing their statistical significance\n              (randomization tests, bootstrapping, and jackknife methods).",
    "version": "3.1.1",
    "maintainer": "Mihai Tivadar <mihai.tivadar@inrae.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4819,
    "package_name": "OddsPlotty",
    "title": "Odds Plot to Visualise a Logistic Regression Model",
    "description": "Uses the outputs of a logistic regression model, from caret <https://CRAN.R-project.org/package=caret>, to build an odds plot.\n    This allows for the rapid visualisation of odds plot ratios and works best with the outputs of CARET's GLM model class, by returning the final trained model. ",
    "version": "1.0.2",
    "maintainer": "Gary Hutson <hutsons-hacks@outlook.com>",
    "url": "https://github.com/StatsGary/OddsPlotty",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4882,
    "package_name": "OpenStreetMap",
    "title": "Access to Open Street Map Raster Images",
    "description": "Accesses high resolution raster maps using the OpenStreetMap\n    protocol. Dozens of road, satellite, and topographic map servers are directly\n    supported. Additionally raster maps\n    may be constructed using custom tile servers.  Maps can be\n    plotted using either base graphics, or ggplot2. This package is not affiliated\n    with the OpenStreetMap.org mapping project.",
    "version": "0.4.1",
    "maintainer": "Ian Fellows <ian@fellstat.com>",
    "url": "https://github.com/ifellows/ROSM https://www.fellstat.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4884,
    "package_name": "Opt5PL",
    "title": "Optimal Designs for the 5-Parameter Logistic Model",
    "description": "Obtain and evaluate various optimal designs for the 3, 4, and 5-parameter logistic models. The optimal designs are obtained based on the numerical algorithm in Hyun, Wong, Yang (2018) <doi:10.18637/jss.v083.i05>. ",
    "version": "0.1.1",
    "maintainer": "Seung Won Hyun <yellowatom09@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4918,
    "package_name": "OtsuFire",
    "title": "Fire Scars, Severity and Regeneration Mapping Using 'Otsu'\nThresholding",
    "description": "\n    Tools to segment fire scars and assess severity and vegetation regeneration using \n    'Otsu' thresholding on Relative Burn Ratio (RBR) and differenced Normalized Burn Ratio (dNBR) image composites. \n    Includes support for mosaic handling, polygon metrics, post-fire regeneration detection, day-of-year flagging, \n    and validation against reference datasets. Designed for analysis of fire history in the Iberian Peninsula. \n    Input Landsat composites follow the methodology described in Quintero et al. (2025) <doi:10.2139/ssrn.4929831>.",
    "version": "0.1.4",
    "maintainer": "Olga Viedma <olga.viedma@uclm.es>",
    "url": "https://github.com/olgaviedma/OtsuFire",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4919,
    "package_name": "OtsuSeg",
    "title": "Raster Thresholding Using Otsu´s Algorithm",
    "description": "Provides tools to process raster data and apply Otsu-based thresholding for burned area mapping and other image segmentation tasks. Implements the method described by Otsu (1979) <doi:10.1109/TSMC.1979.4310076>, a data-driven technique that determines an optimal threshold by maximizing the inter-class variance of pixel intensities. It includes validation functions to assess segmentation accuracy against reference data using standard accuracy metrics such as precision, recall, and F1-score.",
    "version": "0.1.0",
    "maintainer": "Olga Viedma <olga.viedma@uclm.es>",
    "url": "https://github.com/olgaviedma/OtsuSeg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4942,
    "package_name": "PAMscapes",
    "title": "Tools for Summarising and Analysing Soundscape Data",
    "description": "A variety of tools relevant to the analysis\n    of marine soundscape data. There are tools for downloading AIS (automatic identification system)\n    data from Marine Cadastre <https://hub.marinecadastre.gov>,\n    connecting AIS data to GPS coordinates, plotting summaries of various soundscape\n    measurements, and downloading relevant environmental variables (wind, swell height) from the\n    National Center for Atmospheric Research data server <https://rda.ucar.edu/datasets/ds084.1/>.\n    Most tools were developed to work well with output from 'Triton' software, but can be adapted\n    to work with any similar measurements.",
    "version": "0.14.5",
    "maintainer": "Taiki Sakai <taiki.sakai@noaa.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4961,
    "package_name": "PBSmapping",
    "title": "Mapping Fisheries Data and Spatial Analysis Tools",
    "description": "This software has evolved from fisheries research conducted at the\n   Pacific Biological Station (PBS) in 'Nanaimo', British Columbia, Canada. It\n   extends the R language to include two-dimensional plotting features similar\n   to those commonly available in a Geographic Information System (GIS).\n   Embedded C code speeds algorithms from computational geometry, such as\n   finding polygons that contain specified point events or converting between\n   longitude-latitude and Universal Transverse Mercator (UTM) coordinates.\n   Additionally, we include 'C++' code developed by Angus Johnson for the\n   'Clipper' library, data for a global shoreline, and other data sets in the\n   public domain. Under the user's R library directory '.libPaths()',\n   specifically in './PBSmapping/doc', a complete user's guide is offered and\n   should be consulted to use package functions effectively.",
    "version": "2.74.1",
    "maintainer": "Rowan Haigh <rowan.haigh@dfo-mpo.gc.ca>",
    "url": "https://github.com/pbs-software/pbs-mapping,\nhttps://github.com/pbs-software/pbs-mapx,\nhttps://www.angusj.com/clipper2/Docs/Overview.htm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4962,
    "package_name": "PBSmodelling",
    "title": "GUI Tools Made Easy: Interact with Models and Explore Data",
    "description": "Provides software to facilitate the design, testing, and operation\n   of computer models. It focuses particularly on tools that make it easy to\n   construct and edit a customized graphical user interface ('GUI'). Although our\n   simplified 'GUI' language depends heavily on the R interface to the 'Tcl/Tk'\n   package, a user does not need to know 'Tcl/Tk'. Examples illustrate models\n   built with other R packages, including 'PBSmapping', 'PBSddesolve', and 'BRugs'. \n   A complete user's guide 'PBSmodelling-UG.pdf' shows how to use this package\n   effectively.",
    "version": "2.70.2",
    "maintainer": "Nick Fisch <nick.fisch@dfo-mpo.gc.ca>",
    "url": "https://github.com/pbs-software/pbs-modelling",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4982,
    "package_name": "PCPS",
    "title": "Principal Coordinates of Phylogenetic Structure",
    "description": "Set of functions for analysis of Principal Coordinates of Phylogenetic Structure (PCPS).",
    "version": "1.0.8",
    "maintainer": "Vanderlei Julio Debastiani <vanderleidebastiani@yahoo.com.br>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 4994,
    "package_name": "PDMIF",
    "title": "Fits Heterogeneous Panel Data Models",
    "description": "Fits heterogeneous panel data models with interactive effects for linear regression, logistic, count, probit, quantile, and clustering. Based on Ando, T. and Bai, J. (2015) \"A simple new test for slope homogeneity in panel data models with interactive effects\" <doi: 10.1016/j.econlet.2015.09.019>, Ando, T. and Bai, J. (2015) \"Asset Pricing with a General Multifactor Structure\" <doi: 10.1093/jjfinex/nbu026> , Ando, T. and Bai, J. (2016) \"Panel data models with grouped factor structure under unknown group membership\" <doi: 10.1002/jae.2467>, Ando, T. and Bai, J. (2017) \"Clustering huge number of financial time series: A panel data approach with high-dimensional predictors and factor structures\" <doi: 10.1080/01621459.2016.1195743>, Ando, T. and Bai, J. (2020) \"Quantile co-movement in financial markets\" <doi: 10.1080/01621459.2018.1543598>, Ando, T., Bai, J. and Li, K. (2021) \"Bayesian and maximum likelihood analysis of large-scale panel choice models with unobserved heterogeneity\" <doi: 10.1016/j.jeconom.2020.11.013.>.",
    "version": "0.1.0",
    "maintainer": "Tomohiro Ando <t.ando@mbs.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5006,
    "package_name": "PELVIS",
    "title": "Probabilistic Sex Estimate using Logistic Regression, Based on\nVISual Traits of the Human Os Coxae",
    "description": "An R-Shiny application implementing a method of sexing the human os coxae based on logistic regressions and Bruzek's nonmetric traits <doi:10.1002/ajpa.23855>.",
    "version": "2.0.4",
    "maintainer": "Frédéric Santos <frederic.santos@u-bordeaux.fr>",
    "url": "https://gitlab.com/f-santos/pelvis/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5009,
    "package_name": "PERMANOVA",
    "title": "Multivariate Analysis of Variance Based on Distances and\nPermutations",
    "description": "Calculates multivariate analysis of variance based on permutations and some associated pictorial representations. The pictorial representation is based on the principal coordinates of the group means. There are some original results that will be published soon. ",
    "version": "0.2.0",
    "maintainer": "Laura Vicente-Gonzalez <laura20vg@usal.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5066,
    "package_name": "PHENTHAUproc",
    "title": "Phenology Modelling of Thaumetopoea Processionea",
    "description": "Methods to calculate and present 'PHENTHAUproc', an early warning and decision support system for hazard assessment and control of oak processionary moth (OPM) using local and spatial temperature data. It was created by Halbig et al. 2024 (<doi:10.1016/j.foreco.2023.121525>) at FVA (<https://www.fva-bw.de/en/homepage/>) Forest Research Institute Baden-Wuerttemberg, Germany and at BOKU - University of Natural Ressources and Life Sciences, Vienna, Austria.",
    "version": "1.1.1",
    "maintainer": "Lorenz Bachfischer <lorenz.bachfischer@posteo.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5068,
    "package_name": "PHInfiniteEstimates",
    "title": "Tools for Inference in the Presence of a Monotone Likelihood",
    "description": "Proportional hazards estimation in the presence of a partially monotone likelihood has difficulties, in that finite estimators do not exist.  These difficulties are related to those arising from logistic and multinomial regression.  References for methods are given in the separate function documents.  Supported by grant NSF DMS 1712839.",
    "version": "2.9.5",
    "maintainer": "John E. Kolassa <kolassa@stat.rutgers.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5073,
    "package_name": "PICBayes",
    "title": "Bayesian Models for Partly Interval-Censored Data",
    "description": "Contains functions to fit proportional hazards (PH) model to partly interval-censored (PIC) data (Pan et al. (2020) <doi:10.1177/0962280220921552>), PH model with spatial frailty to spatially dependent PIC data (Pan and Cai (2021) <doi:10.1080/03610918.2020.1839497>), and mixed effects PH model to clustered PIC data. Each random intercept/random effect can follow both a normal prior and a Dirichlet process mixture prior. It also includes the corresponding functions for general interval-censored data.",
    "version": "1.0",
    "maintainer": "Chun Pan <chunpan2003@hotmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5105,
    "package_name": "PLreg",
    "title": "Power Logit Regression for Modeling Bounded Data",
    "description": "Power logit regression models for bounded\n  continuous data, in which the density generator may be normal, Student-t, \n  power exponential, slash, hyperbolic, sinh-normal, or type II logistic. \n  Diagnostic tools associated with the fitted model, such as the residuals, \n  local influence measures, leverage measures, and goodness-of-fit statistics,\n  are implemented. The estimation process follows the maximum likelihood approach\n  and, currently, the package supports two types of estimators: the usual maximum \n  likelihood estimator and the penalized maximum likelihood estimator. More details\n  about power logit regression models are described in \n  Queiroz and Ferrari (2022) <arXiv:2202.01697>.",
    "version": "0.4.1",
    "maintainer": "Felipe Queiroz <ffelipeq@outlook.com>",
    "url": "https://github.com/ffqueiroz/PLreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5152,
    "package_name": "PRECAST",
    "title": "Embedding and Clustering with Alignment for Spatial Omics\nDatasets",
    "description": "An efficient data integration method is provided for multiple spatial transcriptomics data with non-cluster-relevant effects such as the complex batch effects. It unifies spatial factor analysis simultaneously with spatial clustering and embedding alignment, requiring only partially shared cell/domain clusters across datasets. More details can be referred to Wei Liu, et al. (2023) <doi:10.1038/s41467-023-35947-w>.",
    "version": "1.8",
    "maintainer": "Wei Liu <liuweideng@gmail.com>",
    "url": "https://github.com/feiyoung/PRECAST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5164,
    "package_name": "PROJ",
    "title": "Generic Coordinate System Transformations Using 'PROJ'",
    "description": "A wrapper around the generic coordinate transformation software 'PROJ'\n  that transforms coordinates from one coordinate reference system ('CRS')\n  to another. This includes cartographic projections as well as geodetic transformations.  The intention is for this\n  package to be used by user-packages such as 'reproj', and that the older 'PROJ.4' and version 5\n  pathways be provided by the 'proj4' package.",
    "version": "0.6.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/PROJ,\nhttps://hypertidy.github.io/PROJ/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5179,
    "package_name": "PReMiuM",
    "title": "Dirichlet Process Bayesian Clustering, Profile Regression",
    "description": "Bayesian clustering using a Dirichlet process mixture model. This model is an alternative to regression models, non-parametrically linking a response vector to covariate data through cluster membership. The package allows Bernoulli, Binomial, Poisson, Normal, survival and categorical response, as well as Normal and discrete covariates. It also allows for fixed effects in the response model, where a spatial CAR (conditional autoregressive) term can be also included. Additionally, predictions may be made for the response, and missing values for the covariates are handled. Several samplers and label switching moves are implemented along with diagnostic tools to assess convergence. A number of R functions for post-processing of the output are also provided. In addition to fitting mixtures, it may additionally be of interest to determine which covariates actively drive the mixture components. This is implemented in the package as variable selection. The main reference for the package is Liverani, Hastie, Azizi, Papathomas and Richardson (2015) <doi:10.18637/jss.v064.i07>.",
    "version": "3.2.13",
    "maintainer": "Silvia Liverani <liveranis@gmail.com>",
    "url": "https://www.silvialiverani.com/software/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5182,
    "package_name": "PSAboot",
    "title": "Bootstrapping for Propensity Score Analysis",
    "description": "It is often advantageous to test a hypothesis more than once\n    in the context of propensity score analysis (Rosenbaum, 2012)\n    <doi:10.1093/biomet/ass032>. The functions in this package facilitate\n    bootstrapping for propensity score analysis (PSA). By default,\n    bootstrapping using two classification tree methods (using 'rpart' and\n    'ctree' functions), two matching methods (using 'Matching' and\n    'MatchIt' packages), and stratification with logistic regression.  A\n    framework is described for users to implement additional propensity\n    score methods.  Visualizations are emphasized for diagnosing balance;\n    exploring the correlation relationships between bootstrap samples and\n    methods; and to summarize results.",
    "version": "1.3.9",
    "maintainer": "Jason Bryer <jason@bryer.org>",
    "url": "https://github.com/jbryer/PSAboot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5215,
    "package_name": "PUPMCR",
    "title": "Image-Based Identification of Color Based on Rayner (1970)\nTerminology and Known Fungal Pigments",
    "description": "Image-based color matching using the \"Mycological Colour Chart\" by Rayner (1970, ISBN:9780851980263) and its associated fungal pigments. This package will assist mycologists in identifying color during morphological analysis.",
    "version": "0.2.0",
    "maintainer": "Chester Deocaris <ccdeocaris@pup.edu.ph>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5266,
    "package_name": "PartialNetwork",
    "title": "Estimating Peer Effects Using Partial Network Data",
    "description": "Implements IV-estimator and Bayesian estimator for linear-in-means Spatial Autoregressive (SAR) model (see LeSage, 1997 <doi:10.1177/016001769702000107>; Lee, 2004 <doi:10.1111/j.1468-0262.2004.00558.x>; Bramoullé et al., 2009 <doi:10.1016/j.jeconom.2008.12.021>), while assuming that only a partial information about the network structure is available. Examples are when the adjacency matrix is not fully observed or when only consistent estimation of the network formation model is available (see Boucher and Houndetoungan, 2025 <doi:10.48550/arXiv.2509.08145>).",
    "version": "1.1.2",
    "maintainer": "Aristide Houndetoungan <ahoundetoungan@ecn.ulaval.ca>",
    "url": "https://github.com/ahoundetoungan/PartialNetwork",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5342,
    "package_name": "PhytoIn",
    "title": "Vegetation Analysis and Forest Inventory",
    "description": "Provides functions and example datasets for phytosociological \n    analysis, forest inventory, biomass and carbon estimation, and visualization \n    of vegetation data. Includes functions to compute structural parameters \n    [phytoparam(), summary.param(), stats()], estimate above-ground biomass \n    and carbon [AGB()], stratify wood volume by diameter at breast height (DBH) \n    classes [stratvol()], generate collector and rarefaction curves [collector.curve(), \n    rarefaction()], and visualize basal areas on quadrat maps [BAplot(), including \n    rectangular plots and individual coordinates]. Several example datasets are provided \n    to demonstrate the functionality of these tools. For more details see FAO \n    (1981, ISBN:92-5-101132-X) \"Manual of forest inventory\", IBGE (2012, ISBN:9788524042720) \n    \"Manual técnico da vegetação brasileira\" and Heringer et al. (2020) \"Phytosociology in \n    R: A routine to estimate phytosociological parameters\" <doi:10.22533/at.ed.3552009033>.",
    "version": "0.2.0",
    "maintainer": "Rodrigo Augusto Santinelo Pereira <raspereira@usp.br>",
    "url": "https://github.com/PhytoIn/PhytoIn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5379,
    "package_name": "PointedSDMs",
    "title": "Fit Models Derived from Point Processes to Species Distributions\nusing 'inlabru'",
    "description": "Integrated species distribution modeling is a rising field in quantitative ecology thanks to significant rises in the quantity of data available, increases in computational speed and the proven benefits of using such models. \n  Despite this, the general software to help ecologists construct such models in an easy-to-use framework is lacking. \n  We therefore introduce the R package 'PointedSDMs': which provides the tools to help ecologists set up integrated models and perform inference on them.\n  There are also functions within the package to help run spatial cross-validation for model selection, as well as generic plotting and predicting functions.\n  An introduction to these methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O’Hara (2020) <doi:10.1016/j.tree.2019.08.006>.",
    "version": "2.1.4",
    "maintainer": "Philip Mostert <philip.s.mostert@ntnu.no>",
    "url": "https://github.com/PhilipMostert/PointedSDMs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5392,
    "package_name": "Poly4AT",
    "title": "Access 'INVEKOS' API for Field Polygons",
    "description": "A 'shiny' app that allows to access and use the 'INVEKOS' API for field polygons in Austria. API documentation is available at <https://gis.lfrz.gv.at/api/geodata/i009501/ogc/features/v1/>.",
    "version": "1.0.1",
    "maintainer": "Sebastian Wieser <poly4at@gmail.com>",
    "url": "https://github.com/farmse988/Poly4AT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5409,
    "package_name": "PopGenReport",
    "title": "A Simple Framework to Analyse Population and Landscape Genetic\nData",
    "description": "Provides beginner friendly framework to analyse population genetic\n    data. Based on 'adegenet' objects it uses 'knitr' to create comprehensive reports on spatial genetic data. \n    For detailed information how to use the package refer to the comprehensive\n    tutorials or visit <http://www.popgenreport.org/>.",
    "version": "3.1.3",
    "maintainer": "Bernd Gruber <bernd.gruber@canberra.edu.au>",
    "url": "https://github.com/green-striped-gecko/PopGenReport",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5420,
    "package_name": "PosteriorBootstrap",
    "title": "Non-Parametric Sampling with Parallel Monte Carlo",
    "description": "An implementation of a non-parametric statistical model using a\n    parallelised Monte Carlo sampling scheme. The method implemented in this\n    package allows non-parametric inference to be regularized for small sample\n    sizes, while also being more accurate than approximations such as\n    variational Bayes. The concentration parameter is an effective sample size\n    parameter, determining the faith we have in the model versus the data. When\n    the concentration is low, the samples are close to the exact Bayesian\n    logistic regression method; when the concentration is high, the samples are\n    close to the simplified variational Bayes logistic regression. The method is\n    described in full in the paper Lyddon, Walker, and Holmes (2018),\n    \"Nonparametric learning from Bayesian models with randomized objective\n    functions\" <arXiv:1806.11544>.",
    "version": "0.1.2",
    "maintainer": "James Robinson <james.em.robinson@gmail.com>",
    "url": "https://github.com/alan-turing-institute/PosteriorBootstrap/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5448,
    "package_name": "PrivateLR",
    "title": "Differentially Private Regularized Logistic Regression",
    "description": "Implements two differentially private algorithms for \n  estimating L2-regularized logistic regression coefficients. A randomized\n  algorithm F is epsilon-differentially private (C. Dwork, Differential\n  Privacy, ICALP 2006 <DOI:10.1007/11681878_14>), if \n     |log(P(F(D) in S)) - log(P(F(D') in S))| <= epsilon\n  for any pair D, D' of datasets that differ in exactly one record, any\n  measurable set S, and the randomness is taken over the choices F makes. ",
    "version": "1.2-22",
    "maintainer": "Staal A. Vinterbo <Staal.Vinterbo@ntnu.no>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5452,
    "package_name": "ProFAST",
    "title": "Probabilistic Factor Analysis for Spatially-Aware Dimension\nReduction",
    "description": "Probabilistic factor analysis for spatially-aware dimension reduction across multi-section spatial transcriptomics data with millions of spatial locations.\n    More details can be referred to Wei Liu, et al. (2023) <doi:10.1101/2023.07.11.548486>.",
    "version": "1.7",
    "maintainer": "Wei Liu <liuweideng@gmail.com>",
    "url": "https://github.com/feiyoung/ProFAST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5453,
    "package_name": "ProPublicaR",
    "title": "Access Functions for ProPublica's APIs",
    "description": "Provides wrapper functions to access the ProPublica's Congress and Campaign Finance APIs.\n    The Congress API provides near real-time access to legislative data from the House of \n    Representatives, the Senate and the Library of Congress.\n    The Campaign Finance API provides data from United States Federal Election Commission \n    filings and other sources. The API covers summary information for candidates and \n    committees, as well as certain types of itemized data.\n    For more information about these APIs go to: <https://www.propublica.org/datastore/apis>.",
    "version": "1.1.4",
    "maintainer": "Aleksander Dietrichson <dietrichson@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5464,
    "package_name": "ProbitSpatial",
    "title": "Probit with Spatial Dependence, SAR, SEM and SARAR Models",
    "description": "Fast estimation of binomial spatial probit regression models with spatial autocorrelation for big datasets.",
    "version": "1.1",
    "maintainer": "Davide Martinetti <davide.martinetti@inrae.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5497,
    "package_name": "Publish",
    "title": "Format Output of Various Routines in a Suitable Way for Reports\nand Publication",
    "description": "A bunch of convenience functions that transform the results of some basic statistical analyses\n       into table format nearly ready for publication. This includes descriptive tables, tables of\n       logistic regression and Cox regression results as well as forest plots. ",
    "version": "2025.07.24",
    "maintainer": "Thomas A. Gerds <tag@biostat.ku.dk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5561,
    "package_name": "Qindex",
    "title": "Continuous and Dichotomized Index Predictors Based on\nDistribution Quantiles",
    "description": "Select optimal functional regression or dichotomized\n       quantile predictors for survival/logistic/numeric outcome\n       and perform optimistic bias correction for any optimally\n       dichotomized numeric predictor(s), as in Yi, et. al.\n       (2023) <doi:10.1016/j.labinv.2023.100158>.",
    "version": "0.1.7",
    "maintainer": "Tingting Zhan <tingtingzhan@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5593,
    "package_name": "Qval",
    "title": "The Q-Matrix Validation Methods Framework",
    "description": "Provide a variety of Q-matrix validation methods for the generalized\n    cognitive diagnosis models, including the method based on the generalized\n    deterministic input, noisy, and gate model (G-DINA) by de la Torre (2011)\n    <DOI:10.1007/s11336-011-9207-7> discrimination index (the GDI method) by\n    de la Torre and Chiu (2016) <DOI:10.1007/s11336-015-9467-8>, the Hull method\n    by Najera et al. (2021) <DOI:10.1111/bmsp.12228>, the stepwise Wald test method\n    (the Wald method) by Ma and de la Torre (2020) <DOI:10.1111/bmsp.12156>, the\n    multiple logistic regression‑based Q‑matrix validation method (the MLR-B method)\n    by Tu et al. (2022) <DOI:10.3758/s13428-022-01880-x>, the beta method based on\n    signal detection theory by Li and Chen (2024) <DOI:10.1111/bmsp.12371> and\n    Q-matrix validation based on relative fit index by Chen et al. (2013)\n    <DOI:10.1111/j.1745-3984.2012.00185.x>. Different research methods and iterative\n    procedures during Q-matrix validating are available\n    <DOI:10.3758/s13428-024-02547-5>.",
    "version": "1.2.4",
    "maintainer": "Haijiang Qin <haijiang133@outlook.com>",
    "url": "https://haijiangqin.com/Qval/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5636,
    "package_name": "RAC",
    "title": "R Package for Aqua Culture",
    "description": "Solves the individual bioenergetic balance for different aquaculture sea fish (Sea Bream and Sea Bass; Brigolin et al., 2014 <doi:10.3354/aei00093>) and shellfish (Mussel and Clam; Brigolin et al., 2009 <doi:10.1016/j.ecss.2009.01.029>; Solidoro et al., 2000 <doi:10.3354/meps199137>). Allows for spatialized model runs and population simulations.",
    "version": "1.5.5",
    "maintainer": "Baldan D. <damiano.baldan91@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5650,
    "package_name": "RAPTOR",
    "title": "Row and Position Tracheid Organizer",
    "description": "Performs wood cell anatomical data analyses on spatially explicit xylem (tracheids) datasets \n                  derived from thin sections of woody tissue. The package includes functions for visualisation, \n                  detection and alignment of continuous tracheid radial file (defined as rows) and individual tracheid position \n                  within an annual ring of coniferous species. This package is designed to be used with elaborate cell output, \n                  e.g. as provided with ROXAS (von Arx & Carrer, 2014 <doi:10.1016/j.dendro.2013.12.001>). The package has been validated for Picea abies, \n                  Larix Siberica, Pinus cembra and Pinus sylvestris.",
    "version": "1.0.1",
    "maintainer": "Richard L. Peters <richardlouispeters3@hotmail.com>",
    "url": "https://the-hull.github.io/raptor/,\nhttps://github.com/the-hull/RAPTOR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5658,
    "package_name": "RApiDatetime",
    "title": "R API for 'Date' and 'Datetime'",
    "description": "Access to the C-level R date and 'datetime' code is provided for\n C-level API use by other packages via registration of native functions.\n Client packages simply include a single header 'RApiDatetime.h' provided\n by this package, and also 'import' it.  The R Core group is the original\n author of the code made available with slight modifications by this package. ",
    "version": "0.0.9",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "url": "https://github.com/eddelbuettel/rapidatetime,\nhttps://dirk.eddelbuettel.com/code/rapidatetime.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5678,
    "package_name": "RCALI",
    "title": "Calculation of the Integrated Flow of Particles Between Polygons",
    "description": "Calculate the flow of particles between polygons by two integration methods:\n  integration by a cubature method and integration on a grid of points.\n  Annie Bouvier, Kien Kieu, Kasia Adamczyk and Herve Monod (2009)\n  <doi:10.1016/j.envsoft.2008.11.006>.",
    "version": "0.3.7",
    "maintainer": "Jean-Francois Rey <jean-francois.rey@inrae.fr>",
    "url": "https://gitlab.paca.inrae.fr/biosp/RCALI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5709,
    "package_name": "RCognito",
    "title": "A Simplified Interface for 'Amazon Cognito'",
    "description": "Simplifies integration with 'Amazon Cognito' (<https://aws.amazon.com/cognito/>) for R developers, enabling easy management of user authentication, registration, and password flows.",
    "version": "0.1.0",
    "maintainer": "Sanjaya J Shetty <shettysanjaya01@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5711,
    "package_name": "RColorBrewer",
    "title": "ColorBrewer Palettes",
    "description": "Provides color schemes for maps (and other graphics)\n        designed by Cynthia Brewer as described at http://colorbrewer2.org.",
    "version": "1.1-3",
    "maintainer": "Erich Neuwirth <erich.neuwirth@univie.ac.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5719,
    "package_name": "RCzechia",
    "title": "Spatial Objects of the Czech Republic",
    "description": "Administrative regions and other spatial objects of the Czech Republic.",
    "version": "1.12.8",
    "maintainer": "Jindra Lacko <jindra.lacko@gmail.com>",
    "url": "https://rczechia.jla-data.net",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5724,
    "package_name": "RDP",
    "title": "The Ramer-Douglas-Peucker Algorithm",
    "description": "Pretty fast implementation of the Ramer-Douglas-Peucker algorithm for reducing the number of points on a 2D curve.\n    Urs Ramer (1972), \"An iterative procedure for the polygonal approximation of plane curves\" <doi:10.1016/S0146-664X(72)80017-0>.\n    David H. Douglas and Thomas K. Peucker (1973), \"Algorithms for the Reduction of the Number of Points Required to Represent a Digitized Line or its Caricature\" <doi:10.3138/FM57-6770-U75U-7727>.",
    "version": "0.3.0",
    "maintainer": "Robert Dahl Jacobsen <cran@dahl-jacobsen.dk>",
    "url": "https://github.com/robertdj/RDP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5732,
    "package_name": "REAT",
    "title": "Regional Economic Analysis Toolbox",
    "description": "Collection of models and analysis methods used in regional and urban economics and (quantitative) economic geography, e.g. measures of inequality, regional disparities and convergence, regional specialization as well as accessibility and spatial interaction models.",
    "version": "3.0.3",
    "maintainer": "Thomas Wieland <thomas.wieland.geo@googlemail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5777,
    "package_name": "RFplus",
    "title": "Machine Learning for Merging Satellite and Ground Precipitation\nData",
    "description": "A machine learning algorithm that merges satellite and ground precipitation data using Random Forest for spatial prediction, residual modeling for bias correction, and quantile mapping for adjustment, ensuring accurate estimates across temporal scales and regions.",
    "version": "1.5-4",
    "maintainer": "Jonnathan Augusto Landi Bermeo <jonnathan.landi@outlook.com>",
    "url": "https://github.com/Jonnathan-Landi/RFplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5785,
    "package_name": "RGENERATEPREC",
    "title": "Tools to Generate Daily-Precipitation Time Series",
    "description": "The method 'generate()' is extended for spatial multi-site\n    stochastic generation of daily precipitation. It generates precipitation\n    occurrence in several sites using logit regression (Generalized Linear\n    Models) and the approach by D.S. Wilks (1998) <doi:10.1016/S0022-1694(98)00186-3> . ",
    "version": "1.3.2",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "url": "https://ecor.github.io/RGENERATEPREC/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5813,
    "package_name": "RIA",
    "title": "Radiomics Image Analysis Toolbox for Medial Images",
    "description": "Radiomics image analysis toolbox for 2D and 3D radiological images. RIA supports DICOM, NIfTI,\n             nrrd and npy (numpy array) file formats.\n             RIA calculates first-order, gray level co-occurrence matrix, gray level run length matrix and\n             geometry-based statistics. Almost all calculations are done using vectorized formulas to\n             optimize run speeds. Calculation of several thousands of parameters only takes minutes\n             on a single core of a conventional PC. Detailed methodology has been published: Kolossvary\n             et al. Circ: Cardiovascular Imaging. 2017;10(12):e006843 <doi: 10.1161/CIRCIMAGING.117.006843>.",
    "version": "1.7.2",
    "maintainer": "Marton Kolossvary <marton.kolossvary@gmail.com>",
    "url": "https://pubmed.ncbi.nlm.nih.gov/29233836/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5822,
    "package_name": "RImageJROI",
    "title": "Read and Write 'ImageJ' Region of Interest (ROI) Files",
    "description": "Provides functions to read and write 'ImageJ' (<https://imagej.net>)\n    Region of Interest (ROI) files, to plot the ROIs and to convert them to\n    'spatstat' (<https://spatstat.org/>) spatial patterns.",
    "version": "0.1.3",
    "maintainer": "David C Sterratt <david.c.sterratt@ed.ac.uk>",
    "url": "https://github.com/davidcsterratt/RImageJROI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5905,
    "package_name": "RNCEP",
    "title": "Obtain, Organize, and Visualize NCEP Weather Data",
    "description": "Contains functions to retrieve, organize, and visualize weather data from the NCEP/NCAR Reanalysis (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html>) and NCEP/DOE Reanalysis II (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis2.html>) datasets.  Data are queried via the Internet and may be obtained for a specified spatial and temporal extent or interpolated to a point in space and time.  We also provide functions to visualize these weather data on a map.  There are also functions to simulate flight trajectories according to specified behavior using either NCEP wind data or data specified by the user.",
    "version": "1.0.11",
    "maintainer": "Michael U. Kemp <mukemp+RNCEP@gmail.com>",
    "url": "https://psl.noaa.gov/data/gridded/index.html\nhttps://sites.google.com/site/michaelukemp/home",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5912,
    "package_name": "RNetCDF",
    "title": "Interface to 'NetCDF' Datasets",
    "description": "An interface to the 'NetCDF' file formats designed by Unidata\n  for efficient storage of array-oriented scientific data and descriptions.\n  Most capabilities of 'NetCDF' version 4 are supported. Optional conversions\n  of time units are enabled by 'UDUNITS' version 2, also from Unidata.",
    "version": "2.11-1",
    "maintainer": "Milton Woods <miltonjwoods@gmail.com>",
    "url": "https://github.com/mjwoods/RNetCDF\nhttps://www.unidata.ucar.edu/software/netcdf/\nhttps://www.unidata.ucar.edu/software/udunits/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5915,
    "package_name": "RNifti",
    "title": "Fast R and C++ Access to NIfTI Images",
    "description": "Provides very fast read and write access to images stored in the\n    NIfTI-1, NIfTI-2 and ANALYZE-7.5 formats, with seamless synchronisation\n    of in-memory image objects between compiled C and interpreted R code. Also\n    provides a simple image viewer, and a C/C++ API that can be used by other\n    packages. Not to be confused with 'RNiftyReg', which performs image\n    registration and applies spatial transformations.",
    "version": "1.8.0",
    "maintainer": "Jon Clayden <code@clayden.org>",
    "url": "https://github.com/jonclayden/RNifti",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5916,
    "package_name": "RNiftyReg",
    "title": "Image Registration Using the 'NiftyReg' Library",
    "description": "Provides an 'R' interface to the 'NiftyReg' image registration tools\n    <https://github.com/KCL-BMEIS/niftyreg>. Linear and nonlinear registration\n    are supported, in two and three dimensions.",
    "version": "2.8.4",
    "maintainer": "Jon Clayden <code@clayden.org>",
    "url": "https://github.com/jonclayden/RNiftyReg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5965,
    "package_name": "ROpenFIGI",
    "title": "R Interface to OpenFIGI",
    "description": "Provide a simple interface to Bloomberg's OpenFIGI API. Please\n    see <https://openfigi.com> for API details and registration. You may be\n    eligible to have an API key to accelerate your loading process.",
    "version": "0.2.8",
    "maintainer": "Ruokun Huang <hruokun.2008@gmail.com>",
    "url": "https://github.com/HuangRicky/ROpenFIGI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5985,
    "package_name": "RPhosFate",
    "title": "Soil and Chemical Substance Emission and Transport Model",
    "description": "An enhanced version of the semi-empirical, spatially distributed\n    emission and transport model PhosFate implemented in 'R' and 'C++'. It is \n    based on the D-infinity, but also supports the D8 flow method. The currently\n    available substances are suspended solids (SS) and particulate phosphorus \n    (PP). A major feature is the allocation of substance loads entering surface \n    waters to their sources of origin, which is a basic requirement for the \n    identification of critical source areas and in consequence a cost-effective\n    implementation of mitigation measures. References: Hepp et al. (2022)\n    <doi:10.1016/j.jenvman.2022.114514>; Hepp and Zessner (2019)\n    <doi:10.3390/w11102161>; Kovacs (2013)\n    <http://hdl.handle.net/20.500.12708/9468>.",
    "version": "2.0.1",
    "maintainer": "Gerold Hepp <gisler@hepp.cc>",
    "url": "https://gisler.github.io/RPhosFate/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5987,
    "package_name": "RPostgreSQL",
    "title": "R Interface to the 'PostgreSQL' Database System",
    "description": "Database interface and 'PostgreSQL' driver for 'R'.\n This package provides a Database Interface 'DBI' compliant \n driver for 'R' to access 'PostgreSQL' database systems.  \n In order to build and install this package from source, 'PostgreSQL' \n itself must be present your system to provide 'PostgreSQL' functionality \n via its libraries and header files. These files are provided as\n 'postgresql-devel' package under some Linux distributions.\n On 'macOS' and 'Microsoft Windows' system the attached 'libpq' library source will be used.",
    "version": "0.7-8",
    "maintainer": "Tomoaki Nishiyama <tomoaki@sci.u-toyama.ac.jp>",
    "url": "https://github.com/tomoakin/RPostgreSQL,\nhttps://cran.r-project.org/package=DBI,\nhttps://www.postgresql.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 5997,
    "package_name": "RPushbullet",
    "title": "R Interface to the Pushbullet Messaging Service",
    "description": "An R interface to the Pushbullet messaging service which\n provides fast and efficient notifications (and file transfer) between\n computers, phones and tablets.  An account has to be registered at the \n site <https://www.pushbullet.com> site to obtain a (free) API key.",
    "version": "0.3.5",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "url": "https://github.com/eddelbuettel/rpushbullet,\nhttps://dirk.eddelbuettel.com/code/rpushbullet.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6006,
    "package_name": "RRMLRfMC",
    "title": "Reduced-Rank Multinomial Logistic Regression for Markov Chains",
    "description": "Fit the reduced-rank multinomial logistic regression model for Markov\n    chains developed by Wang, Abner, Fardo, Schmitt, Jicha, Eldik and Kryscio\n    (2021)<doi:10.1002/sim.8923> in R. It combines the ideas of multinomial\n    logistic regression in Markov chains and reduced-rank. It is very useful in \n    a study where multi-states model is assumed and each transition among the \n    states is controlled by a series of covariates. The key advantage is to \n    reduce the number of parameters to be estimated. The final coefficients for \n    all the covariates and the p-values for the interested covariates will be \n    reported. The p-values for the whole coefficient matrix can be calculated by \n    two bootstrap methods.",
    "version": "0.4.0",
    "maintainer": "Pei Wang <wangp33@miamioh.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6023,
    "package_name": "RSCAT",
    "title": "Shadow-Test Approach to Computerized Adaptive Testing",
    "description": "As an advanced approach to computerized adaptive testing (CAT), \n  shadow testing (van der Linden(2005) <doi:10.1007/0-387-29054-0>) dynamically \n  assembles entire shadow tests as a part of \n  selecting items throughout the testing process.\n  Selecting items from shadow tests guarantees the compliance of all content \n  constraints defined by the blueprint. 'RSCAT' is an R package for the \n  shadow-test approach to CAT. The objective of \n  'RSCAT' is twofold: 1) Enhancing the effectiveness of shadow-test CAT simulation;\n  2) Contributing to the academic and scientific community for CAT research.\n  RSCAT is currently designed for dichotomous items based on the three-parameter logistic (3PL) model.",
    "version": "1.1.3",
    "maintainer": "Bingnan Jiang <bnjiangece@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6106,
    "package_name": "RaSEn",
    "title": "Random Subspace Ensemble Classification and Variable Screening",
    "description": "We propose a general ensemble classification framework, RaSE algorithm, for the sparse classification problem. In RaSE algorithm, for each weak learner, some random subspaces are generated and the optimal one is chosen to train the model on the basis of some criterion. To be adapted to the problem, a novel criterion, ratio information criterion (RIC) is put up with based on Kullback-Leibler divergence. Besides minimizing RIC, multiple criteria can be applied, for instance, minimizing extended Bayesian information criterion (eBIC), minimizing training error, minimizing the validation error, minimizing the cross-validation error, minimizing leave-one-out error. There are various choices of base classifier, for instance, linear discriminant analysis, quadratic discriminant analysis, k-nearest neighbour, logistic regression, decision trees, random forest, support vector machines. RaSE algorithm can also be applied to do feature ranking, providing us the importance of each feature based on the selected percentage in multiple subspaces. RaSE framework can be extended to the general prediction framework, including both classification and regression. We can use the selected percentages of variables for variable screening. The latest version added the variable screening function for both regression and classification problems. ",
    "version": "3.0.0",
    "maintainer": "Ye Tian <ye.t@columbia.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6124,
    "package_name": "RandomForestsGLS",
    "title": "Random Forests for Dependent Data",
    "description": "Fits non-linear regression models on dependant data with Generalised Least Square (GLS) based Random Forest (RF-GLS) detailed in Saha, Basu and Datta (2021) <doi:10.1080/01621459.2021.1950003>.",
    "version": "0.1.5",
    "maintainer": "Arkajyoti Saha <arkajyotisaha93@gmail.com>",
    "url": "https://github.com/ArkajyotiSaha/RandomForestsGLS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6141,
    "package_name": "RapidPolygonLookup",
    "title": "POLYGON LOOKUP USING KD TREES",
    "description": "Facilitates efficient polygon search using kd trees.\n    Coordinate level spatial data can be aggregated to higher geographical\n    identities like census blocks, ZIP codes or police district boundaries.\n    This process requires mapping each point in the given data set to a\n    particular identity of the desired geographical hierarchy. Unless efficient\n    data structures are used, this can be a daunting task. The operation\n    point.in.polygon() from the package sp is computationally expensive.\n    Here, we exploit kd-trees as efficient nearest neighbor search algorithm\n    to dramatically reduce the effective number of polygons being searched.",
    "version": "0.1.1",
    "maintainer": "Markus Loecher <markus.loecher@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6162,
    "package_name": "RblDataLicense",
    "title": "R Interface to 'Bloomberg Data License'",
    "description": "R interface to access prices and market data with the \n    'Bloomberg Data License' service from \n    <https://www.bloomberg.com/professional/product/data-license/>. \n    As a prerequisite, a valid Data License from 'Bloomberg' is needed \n    together with the corresponding SFTP credentials and whitelisting \n    of the IP from which accessing the service. \n    This software and its author are in no way affiliated, \n    endorsed, or approved by 'Bloomberg' or any of its affiliates.\n    'Bloomberg' is a registered trademark.",
    "version": "0.2.6",
    "maintainer": "Emanuele Guidotti <emanuele.guidotti@usi.ch>",
    "url": "https://rbldatalicense.eguidotti.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6169,
    "package_name": "RcamelsCL",
    "title": "Easy Handling of the CAMELS-CL Dataset",
    "description": "Download and handle spatial and temporal data from the CAMELS-CL dataset (Catchment Attributes and Meteorology for Large Sample Studies, Chile) <https://camels.cr2.cl/>, developed by Alvarez-Garreton et al. (2018) <doi:10.5194/hess-22-5817-2018>. The package does not generate new data, it only facilitates direct access to the original dataset for hydrological analyses.",
    "version": "0.1-11",
    "maintainer": "Hector Garces-Figueroa <hegarcesf@gmail.com>",
    "url": "https://gitlab.com/hgarcesf/RcamelsCL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6170,
    "package_name": "Rcan",
    "title": "Cancer Registry Data Analysis and Visualisation",
    "description": "Tools for basic and advance cancer statistics and graphics.\n\tGroups individual data, merges registry data and population data, calculates age-specific rate, age-standardized rate, cumulative risk, estimated annual percentage rate with standards error. Creates graphics across variable and\n    time, such as age-specific trends, bar chart and period-cohort trends.",
    "version": "1.3.92",
    "maintainer": "Mathieu Laversanne <laversannem@iarc.who.int>",
    "url": "https://github.com/timat35/Rcan",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6174,
    "package_name": "RcensusPkg",
    "title": "Easily Access US Census Bureau Survey and Geographic Data",
    "description": "The key function 'get_vintage_data()' returns a dataframe and is \n    the window into the Census Bureau API requiring just a dataset name, \n    vintage(year), and vector of variable names for survey estimates/percentages. \n    Other functions assist in searching for available datasets, geographies, \n    group/variable concepts of interest.  Also provided are functions to access \n    and layer (via standard piping) displayable geometries for the US, states, \n    counties, blocks/tracts, roads, landmarks, places, and bodies of water. \n    Joining survey data with many of the geometry functions is built-in to \n    produce choropleth maps.",
    "version": "0.1.5",
    "maintainer": "Rick Dean <deanr3@bardstown.com>",
    "url": "https://github.com/deandevl/RcensusPkg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6227,
    "package_name": "RcppCGAL",
    "title": "'Rcpp' Integration for 'CGAL'",
    "description": "Creates a header only package to link to the 'CGAL' \n  (Computational Geometry Algorithms Library)\n  header files in 'Rcpp'. There are a variety of potential uses for \n  the software such as Hilbert sorting, K-D Tree nearest neighbors, \n  and convex hull algorithms. For more information about how to use the header files, \n  see the 'CGAL' documentation at <https://www.cgal.org>. Currently\n  downloads version 6.1 of the 'CGAL' header files.",
    "version": "6.1",
    "maintainer": "Eric Dunipace <edunipace@mail.harvard.edu>",
    "url": "https://github.com/ericdunipace/RcppCGAL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6316,
    "package_name": "ReadDIM",
    "title": "Read ESA SNAP Processed Raster Format in R",
    "description": "It helps you to read (.dim) images with CRS directly into R programming. One can import both Sentinel 1 and 2 images or any processed data with this software.",
    "version": "0.2.11",
    "maintainer": "Subhadip Datta <subhadipdatta007@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6347,
    "package_name": "RegrCoeffsExplorer",
    "title": "Efficient Visualization of Regression Coefficients for Lm(),\nGlm(), and Glmnet() Objects",
    "description": "The visualization tool offers a nuanced understanding of regression dynamics, going beyond traditional per-unit interpretation of continuous variables versus categorical ones. It highlights the impact of unit changes as well as larger shifts like interquartile changes, acknowledging the distribution of empirical data. Furthermore, it generates visualizations depicting alterations in Odds Ratios for predictors across minimum, first quartile, median, third quartile, and maximum values, aiding in comprehending predictor-outcome interplay within empirical data distributions, particularly in logistic regression frameworks.",
    "version": "1.2.0",
    "maintainer": "Vadim Tyuryaev <vadim.tyuryaev@gmail.com>",
    "url": "https://vadimtyuryaev.github.io/RegrCoeffsExplorer/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6362,
    "package_name": "Renvlp",
    "title": "Computing Envelope Estimators",
    "description": "Provides a general routine, envMU, which allows  estimation of the M envelope of span(U) given root n consistent estimators of M and U. The routine envMU does not presume a model.  This package implements response envelopes,  partial response envelopes,  envelopes in the predictor space,  heteroscedastic envelopes,  simultaneous envelopes,  scaled response envelopes,  scaled envelopes in the predictor space,  groupwise envelopes, weighted envelopes,  envelopes in logistic regression, envelopes in Poisson regression envelopes in function-on-function linear regression, envelope-based Partial Partial Least Squares,  envelopes with non-constant error covariance, envelopes with t-distributed errors, reduced rank envelopes and reduced rank envelopes with non-constant error covariance. For each of these model-based routines the package provides inference tools including bootstrap, cross validation, estimation and prediction, hypothesis testing on coefficients are included except for weighted envelopes. Tools for selection of dimension include AIC, BIC and likelihood ratio testing.   Background is available at Cook, R. D., Forzani, L. and Su, Z. (2016) <doi:10.1016/j.jmva.2016.05.006>. Optimization is based on a clockwise coordinate descent algorithm.",
    "version": "3.4.5",
    "maintainer": "Minji Lee <minjilee101@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6411,
    "package_name": "RgoogleMaps",
    "title": "Overlays on Static Maps",
    "description": "Serves two purposes: (i) Provide a\n        comfortable R interface to query the Google server for static\n        maps, and (ii) Use the map as a background image to overlay\n        plots within R. This requires proper coordinate scaling.",
    "version": "1.5.3",
    "maintainer": "Markus Loecher <markus.loecher@gmail.com>",
    "url": "https://github.com/markusloecher/rgooglemaps/blob/master/rgooglemaps/www/QuickTutorial.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6426,
    "package_name": "Rirt",
    "title": "Data Analysis and Parameter Estimation Using Item Response\nTheory",
    "description": "Parameter estimation, computation of probability, information, and \n    (log-)likelihood, and visualization of item/test characteristic curves and\n    item/test information functions for three uni-dimensional item response theory\n    models: the 3-parameter-logistic model, generalized partial credit model, \n    and graded response model. The full documentation and tutorials are at \n    <https://github.com/xluo11/Rirt>.",
    "version": "0.0.2",
    "maintainer": "Xiao Luo <xluo1986@gmail.com>",
    "url": "https://github.com/xluo11/Rirt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6429,
    "package_name": "RiskMap",
    "title": "Geostatistical Modeling of Spatially Referenced Data",
    "description": "Geostatistical analysis of continuous and count data.\n  Implements stationary Gaussian processes with Matérn correlation for spatial prediction,\n  as described in Diggle and Giorgi (2019, ISBN: 978-1-138-06102-7).",
    "version": "1.0.0",
    "maintainer": "Emanuele Giorgi <e.giorgi@bham.ac.uk>",
    "url": "https://claudiofronterre.github.io/RiskMap/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6435,
    "package_name": "RiverBuilder",
    "title": "River Generation for Given Data Sets",
    "description": "Generates graphs, CSV files, and coordinates related to river valleys when calling the riverbuilder() function.",
    "version": "0.1.1",
    "maintainer": "Gregory Pasternack <gpast@ucdavis.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6442,
    "package_name": "Rlibkdv",
    "title": "A Versatile Kernel Density Visualization Library for Geospatial\nAnalytics (Heatmap)",
    "description": "Unlock the power of large-scale geospatial analysis, \n    quickly generate high-resolution kernel density visualizations, \n    supporting advanced analysis tasks such as bandwidth-tuning and spatiotemporal analysis. \n    Regardless of the size of your dataset, our library delivers efficient and accurate results.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu, Reynold Cheng (2023) <doi:10.1145/3555041.3589401>.\n    Tsz Nam Chan, Rui Zang, Pak Lon Ip, Leong Hou U, Jianliang Xu (2023) <doi:10.1145/3555041.3589711>.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.1145/3514221.3517823>.\n    Tsz Nam Chan, Pak Lon Ip, Kaiyan Zhao, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3554821.3554855>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3503585.3503591>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3494124.3494135>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Weng Hou Tong, Shivansh Mittal, Ye Li, Reynold Cheng (2021) <doi:10.14778/3476311.3476312>.\n    Tsz Nam Chan, Zhe Li, Leong Hou U, Jianliang Xu, Reynold Cheng (2021) <doi:10.14778/3461535.3461540>.\n    Tsz Nam Chan, Reynold Cheng, Man Lung Yiu (2020) <doi:10.1145/3318464.3380561>.\n    Tsz Nam Chan, Leong Hou U, Reynold Cheng, Man Lung Yiu, Shivansh Mittal (2020) <doi:10.1109/TKDE.2020.3018376>.\n    Tsz Nam Chan, Man Lung Yiu, Leong Hou U (2019) <doi:10.1109/ICDE.2019.00055>.",
    "version": "1.1",
    "maintainer": "Bojian Zhu <bjzhu999@gmail.com>",
    "url": "https://github.com/bojianzhu/Rlibkdv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6456,
    "package_name": "Rmoji",
    "title": "Interactively Insert Emojis in 'R' Documents",
    "description": "Provides an intuitive and user-friendly interface for working with emojis in 'R'. It allows users to search, insert, and manage emojis by keyword, category, or through an interactive 'shiny'-based drop-down. The package enables integration of emojis into 'R' scripts, 'R Markdown', 'Quarto', 'shiny' apps, and 'ggplot2' plots. Also includes built-in mappings for commit messages, useful for version control. It builds on established emoji libraries and Unicode standards, adding expressiveness and visual cues to documentation, user interfaces, and reports. For more details see 'Emojipedia' (2024) <https://emojipedia.org> and GitHub Emoji Cheat Sheet <https://github.com/ikatyang/emoji-cheat-sheet/tree/master>.",
    "version": "0.1.0",
    "maintainer": "Berhe Etsay Tesfay <berhe.etsay@gmail.com>",
    "url": "https://github.com/3p1d3m/Rmoji",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6531,
    "package_name": "Rprofet",
    "title": "WOE Transformation and Scorecard Builder",
    "description": "Performs all steps in the credit scoring process. This package allows the user to follow all the necessary steps for building an effective scorecard. It provides the user functions for coarse binning of variables, Weights of Evidence (WOE) transformation, variable clustering, custom binning, visualization, and scaling of logistic regression coefficients. The results will generate a scorecard that can be used as an effective credit scoring tool to evaluate risk. For complete details on the credit scoring process, see Siddiqi (2005, ISBN:047175451X).  ",
    "version": "3.1.1",
    "maintainer": "Thomas Brandenburger <thomas.brandenburger@sdstate.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6540,
    "package_name": "Rsagacmd",
    "title": "Linking R with the Open-Source 'SAGA-GIS' Software",
    "description": "Provides an R scripting interface to the open-source 'SAGA-GIS' \n    (System for Automated Geoscientific Analyses Geographical Information\n    System) software. 'Rsagacmd' dynamically generates R functions for every\n    'SAGA-GIS' geoprocessing tool based on the user's currently installed\n    'SAGA-GIS' version. These functions are contained within an S3 object\n    and are accessed as a named list of libraries and tools. This structure\n    facilitates an easier scripting experience by organizing the large number\n    of 'SAGA-GIS' geoprocessing tools (>700) by their respective library.\n    Interactive scripting can fully take advantage of code autocompletion tools\n    (e.g. in 'RStudio'), allowing for each tools syntax to be quickly\n    recognized. Furthermore, the most common types of spatial data (via the\n    'terra', 'sp', and 'sf' packages) along with non-spatial data are\n    automatically passed from R to the 'SAGA-GIS' command line tool for\n    geoprocessing operations, and the results are loaded as the appropriate R\n    object. Outputs from individual 'SAGA-GIS' tools can also be chained using\n    pipes from the 'magrittr' and 'dplyr' packages to combine complex\n    geoprocessing operations together in a single statement. 'SAGA-GIS' is\n    available under a GPLv2 / LGPLv2 licence from\n    <https://sourceforge.net/projects/saga-gis/> including Windows x86/x64\n    and macOS binaries. SAGA-GIS is also included in Debian/Ubuntu default software\n    repositories. Rsagacmd has currently been tested on 'SAGA-GIS' versions\n    from 2.3.1 to 9.5.1 on Windows, Linux and macOS.",
    "version": "0.4.3",
    "maintainer": "Steven Pawley <dr.stevenpawley@gmail.com>",
    "url": "https://stevenpawley.github.io/Rsagacmd/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6566,
    "package_name": "Rtrack",
    "title": "Spatial Navigation Strategy Analysis",
    "description": "A toolkit for the analysis of paths from spatial tracking experiments and calculation of goal-finding strategies. \n    This package is centered on an approach using machine learning for path classification.",
    "version": "2.0.4",
    "maintainer": "Rupert Overall <rtrack@rupertoverall.net>",
    "url": "https://rupertoverall.net/Rtrack/,\nhttps://github.com/rupertoverall/Rtrack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6568,
    "package_name": "Rtropical",
    "title": "Data Analysis Tools over Space of Phylogenetic Trees Using\nTropical Geometry",
    "description": "Process phylogenetic trees with tropical support vector machine and principal component analysis defined with tropical geometry. Details about tropical support vector machine are available in : Tang, X., Wang, H. & Yoshida, R. (2020) <arXiv:2003.00677>. Details about tropical principle component analysis are available in : Page, R., Yoshida, R. & Zhang L. (2020) <doi:10.1093/bioinformatics/btaa564> and Yoshida, R., Zhang, L. & Zhang, X. (2019) <doi:10.1007/s11538-018-0493-4>.",
    "version": "1.2.1",
    "maintainer": "Houjie Wang <wanghoujie6688@gmail.com>",
    "url": "https://github.com/HoujieWang/Rtropical",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6595,
    "package_name": "SAFD",
    "title": "Statistical Analysis of Fuzzy Data",
    "description": "The aim of the package is to provide some basic functions\n        for doing statistics with one dimensional Fuzzy Data (in the\n        form of polygonal fuzzy numbers). In particular, the package\n        contains functions for the basic operations on the class of\n        fuzzy numbers (sum, scalar product, mean, median, Hukuhara difference) \n        as well as for calculating (Bertoluzza) distance and sample variance. \n        Moreover a function to simulate fuzzy random variables and bootstrap tests \n        for the equality of means is included. Version 2.1 fixes some bugs\n        of previous versions.",
    "version": "2.1",
    "maintainer": "Asun Lubiano\n<lubiano@uniovi.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6597,
    "package_name": "SAGM",
    "title": "Spatial Autoregressive Graphical Model",
    "description": "Implements the methodological developments found in Hermes, van Heerwaarden, and Behrouzi (2023) <doi:10.48550/arXiv.2308.04325>, and allows for the statistical modeling of asymmetric between-location effects, as well as within-location effects using spatial autoregressive graphical models. The package allows for the generation of spatial weight matrices to capture asymmetric effects for strip-type intercropping designs, although it can handle any type of spatial data commonly found in other sciences.  ",
    "version": "1.0.0",
    "maintainer": "Sjoerd Hermes <sjoerd.hermes@wur.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6602,
    "package_name": "SALTSampler",
    "title": "Efficient Sampling on the Simplex",
    "description": "The SALTSampler package facilitates Monte Carlo Markov Chain (MCMC)\n    sampling of random variables on a simplex. A Self-Adjusting Logit Transform\n    (SALT) proposal is used so that sampling is still efficient even in difficult\n    cases, such as those in high dimensions or with parameters that differ by orders\n    of magnitude. Special care is also taken to maintain accuracy even when some\n    coordinates approach 0 or 1 numerically. Diagnostic and graphic functions are\n    included in the package, enabling easy assessment of the convergence and mixing\n    of the chain within the constrained space.",
    "version": "1.1.0",
    "maintainer": "Scott Vander Wiel <scottv@lanl.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6650,
    "package_name": "SCDA",
    "title": "Spatially-Clustered Data Analysis",
    "description": "Contains functions for statistical data analysis based on spatially-clustered techniques.\n    The package allows estimating the spatially-clustered spatial regression models presented in Cerqueti, Maranzano \\& Mattera (2024), \"Spatially-clustered spatial autoregressive models\n    with application to agricultural market concentration in Europe\", arXiv preprint 2407.15874 <doi:10.48550/arXiv.2407.15874>.\n    Specifically, the current release allows the estimation of the spatially-clustered linear regression model (SCLM), the spatially-clustered spatial autoregressive model (SCSAR),\n    the spatially-clustered spatial Durbin model (SCSEM), and the spatially-clustered linear regression model with spatially-lagged exogenous covariates (SCSLX).\n    From release 0.0.2, the library contains functions to estimate spatial clustering based on Adiajacent Matrix K-Means (AMKM) as described in Zhou, Liu \\& Zhu (2019), \"Weighted adjacent matrix for K-means clustering\", Multimedia Tools and Applications, 78 (23) <doi:10.1007/s11042-019-08009-x>.  ",
    "version": "0.0.2",
    "maintainer": "Paolo Maranzano <pmaranzano.ricercastatistica@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6657,
    "package_name": "SCFMonitor",
    "title": "Clear Monitor and Graphing Software Processing Gaussian .log\nFile",
    "description": "Self-Consistent Field(SCF) calculation method is one of the most important steps in the calculation methods of quantum chemistry. Ehrenreich, H., & Cohen, M. H. (1959). <doi:10.1103/PhysRev.115.786> However, the most prevailing software in this area, 'Gaussian''s SCF convergence process is hard to monitor, especially while the job is still running, causing researchers difficulty in knowing whether the oscillation has started or not, wasting time and energy on useless configurations or abandoning the jobs that can actually work. M.J. Frisch, G.W. Trucks, H.B. Schlegel et al. (2016). <https://gaussian.com> 'SCFMonitor' enables 'Gaussian' quantum chemistry calculation software users to easily read the 'Gaussian' .log files and monitor the SCF convergence and geometry optimization process with little effort and clear, beautiful, and clean outputs. It can generate graphs using 'tidyverse' to let users check SCF convergence and geometry optimization processes in real-time. The software supports processing .log files remotely using with rbase::url(). This software is a suitcase for saving time and energy for the researchers, supporting multiple versions of 'Gaussian'.",
    "version": "0.3.5",
    "maintainer": "Pengjun Guo <pengjun.guo@outlook.com>",
    "url": "https://github.com/AzuleneG/SCFMonitor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6673,
    "package_name": "SChangeBlock",
    "title": "Spatial Structural Change Detection by an Analysis of\nVariability Between Blocks of Observations",
    "description": "Provides methods to detect structural changes in time series or random fields (spatial data). Focus is on the detection of abrupt changes or trends in independent data, but the package also provides a function to de-correlate data with dependence. The functions are based on the test suggested in Schmidt (2024) <DOI:10.3150/23-BEJ1686> and the work in Görz and Fried (2025) <DOI:10.48550/arXiv.2512.11599>.",
    "version": "0.1.0",
    "maintainer": "Sheila Goerz <sheila.goerz@tu-dortmund.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6675,
    "package_name": "SCoRES",
    "title": "Simultaneous Confidence Region Excursion Sets",
    "description": "Provides computational tools for estimating inverse regions and \n  constructing the corresponding simultaneous outer and inner confidence regions. \n  Acceptable input includes both one-dimensional and two-dimensional data for linear, \n  logistic, functional, and spatial generalized least squares regression models. \n  Functions are also available for constructing simultaneous confidence bands (SCBs) \n  for these models. The definition of simultaneous confidence regions (SCRs) follows \n  Sommerfeld et al. (2018) <doi:10.1080/01621459.2017.1341838>. Methods for estimating \n  inverse regions, SCRs, and the nonparametric bootstrap are based on \n  Ren et al. (2024) <doi:10.1093/jrsssc/qlae027>. Methods for constructing SCBs \n  are described in Crainiceanu et al. (2024) <doi:10.1201/9781003278726> \n  and Telschow et al. (2022) <doi:10.1016/j.jspi.2021.05.008>.",
    "version": "0.1.2",
    "maintainer": "Zhuoran Yu <angela.yu@emory.edu>",
    "url": "https://angelayustat.github.io/SCoRES/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6688,
    "package_name": "SDPDmod",
    "title": "Spatial Dynamic Panel Data Modeling",
    "description": "Spatial model calculation for static and dynamic panel data models, weights matrix creation and  Bayesian model comparison.\n  Bayesian model comparison methods were described by 'LeSage' (2014) <doi:10.1016/j.spasta.2014.02.002>.\n  The 'Lee'-'Yu' transformation approach is described in 'Yu', 'De Jong' and 'Lee' (2008) <doi:10.1016/j.jeconom.2008.08.002>, 'Lee' and 'Yu' (2010) <doi:10.1016/j.jeconom.2009.08.001> and 'Lee' and 'Yu' (2010) <doi:10.1017/S0266466609100099>.",
    "version": "0.0.7",
    "maintainer": "Rozeta Simonovska <simonovska.r@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6695,
    "package_name": "SEAHORS",
    "title": "Spatial Exploration of ArcHaeological Objects in R Shiny",
    "description": "An R 'Shiny' application dedicated to the intra-site spatial analysis of piece-plotted archaeological remains, making the two and three-dimensional spatial exploration of archaeological data as user-friendly as possible.  Documentation about 'SEAHORS' is provided by the vignette included in this package and by the companion scientific paper: Royer, Discamps, Plutniak, Thomas (2023, PCI Archaeology, <doi:10.5281/zenodo.7674698>).",
    "version": "1.9.0",
    "maintainer": "Sebastien Plutniak <sebastien.plutniak@posteo.net>",
    "url": "https://github.com/AurelienRoyer/SEAHORS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6729,
    "package_name": "SGPR",
    "title": "Sparse Group Penalized Regression for Bi-Level Variable\nSelection",
    "description": "Fits the regularization path of regression models\n    (linear and logistic) with additively combined penalty terms. All\n    possible combinations with Least Absolute Shrinkage and Selection Operator (LASSO), \n    Smoothly Clipped Absolute Deviation (SCAD), Minimax Concave Penalty (MCP) and \n    Exponential Penalty (EP) are supported. This includes Sparse Group LASSO (SGL), \n    Sparse Group SCAD (SGS), Sparse Group MCP (SGM) and Sparse Group EP (SGE).\n    For more information, see Buch, G., Schulz, A., Schmidtmann, I., Strauch, K., & Wild, P. S. (2024) <doi:10.1002/bimj.202200334>.",
    "version": "0.1.2",
    "maintainer": "Gregor Buch <buchgregor@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6735,
    "package_name": "SHARK4R",
    "title": "Accessing and Validating Marine Environmental Data from 'SHARK'\nand Related Databases",
    "description": "Provides functions to retrieve, process, analyze, and\n    quality-control marine physical, chemical, and biological data. The\n    main focus is on Swedish monitoring data available through the 'SHARK'\n    database <https://shark.smhi.se/en/>, with additional API support for 'Nordic\n    Microalgae' <https://nordicmicroalgae.org/>, 'Dyntaxa'\n    <https://artfakta.se/>, World Register of Marine Species ('WoRMS') <https://www.marinespecies.org>,\n    'AlgaeBase' <https://www.algaebase.org>, OBIS 'xylookup' web service \n    <https://iobis.github.io/xylookup/> and Intergovernmental Oceanographic Commission (IOC) - \n    UNESCO databases on harmful algae  <https://www.marinespecies.org/hab/> and toxins\n    <https://toxins.hais.ioc-unesco.org/>.",
    "version": "1.0.2",
    "maintainer": "Anders Torstensson <anders.torstensson@smhi.se>",
    "url": "https://sharksmhi.github.io/SHARK4R/,\nhttps://github.com/sharksmhi/SHARK4R",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6759,
    "package_name": "SIMPLE.REGRESSION",
    "title": "OLS, Moderated, Logistic, and Count Regressions Made Simple",
    "description": "Provides SPSS- and SAS-like output for least squares multiple regression,\n    logistic regression, and count variable regressions. Detailed output is also provided for\n    OLS moderated regression, interaction plots, and Johnson-Neyman\n    regions of significance. The output includes standardized\n    coefficients, partial and semi-partial correlations, collinearity diagnostics,\n    plots of residuals, and detailed information about simple slopes for interactions. \n    The output for some functions includes Bayes Factors and, if requested,  \n    regression coefficients from Bayesian Markov Chain Monte Carlo analyses.\n    There are numerous options for model plots.\n    The REGIONS_OF_SIGNIFICANCE function also provides\n    Johnson-Neyman regions of significance and plots of interactions for both lm\n    and lme models. There is also a function for partial and semipartial\n    correlations and a function for conducting Cohen's\n    set correlation analyses.",
    "version": "0.2.8",
    "maintainer": "Brian P. O'Connor  <brian.oconnor@ubc.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6782,
    "package_name": "SLFPCA",
    "title": "Sparse Logistic Functional Principal Component Analysis",
    "description": "Implementation for sparse logistic functional principal component analysis (SLFPCA). SLFPCA is specifically developed for functional binary data, and the estimated eigenfunction can be strictly zero on some sub-intervals, which is helpful for interpretation. The crucial function of this package is SLFPCA().",
    "version": "3.0",
    "maintainer": "Rou Zhong <zhong_rou@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6783,
    "package_name": "SLGP",
    "title": "Spatial Logistic Gaussian Process for Field Density Estimation",
    "description": "Provides tools for conditional and spatially dependent \n    density estimation using Spatial Logistic Gaussian Processes (SLGPs). \n    The approach represents probability densities through finite-rank \n    Gaussian process priors transformed via a spatial logistic density \n    transformation, enabling flexible non-parametric modeling of \n    heterogeneous data. Functionality includes density prediction, \n    quantile and moment estimation, sampling methods, and preprocessing \n    routines for basis functions. Applications arise in spatial statistics, \n    machine learning, and uncertainty quantification. \n    The methodology builds on the framework of Leonard (1978) \n    <doi:10.1111/j.2517-6161.1978.tb01655.x>, Lenk (1988) <doi:10.1080/01621459.1988.10478625>, \n    Tokdar (2007) <doi:10.1198/106186007X210206>, Tokdar (2010) <doi:10.1214/10-BA605>, \n    and is further aligned with recent developments \n    in Bayesian non-parametric modelling: see Gautier (2023) <https://boristheses.unibe.ch/4377/>, \n    and Gautier (2025) <doi:10.48550/arXiv.2110.02876>).",
    "version": "1.0.0",
    "maintainer": "Athénaïs Gautier <athenais.gautier@onera.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6799,
    "package_name": "SMARTp",
    "title": "Sample Size for SMART Designs in Non-Surgical Periodontal Trials",
    "description": "Sample size calculation to detect dynamic treatment regime (DTR) effects based on change in clinical attachment level (CAL) outcomes from a non-surgical chronic periodontitis treatments study. The experiment is performed under a Sequential Multiple Assignment Randomized Trial (SMART) design. The clustered tooth (sub-unit) level CAL outcomes are skewed, spatially-referenced, and non-randomly missing. The implemented algorithm is available in Xu et al. (2019+) <arXiv:1902.09386>.",
    "version": "0.1.1",
    "maintainer": "Dipankar Bandyopadhyay <bandyopd@gmail.com>",
    "url": "https://github.com/bandyopd/SMARTp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6806,
    "package_name": "SMLE",
    "title": "Joint Feature Screening via Sparse MLE",
    "description": "Feature screening is a powerful tool in processing ultrahigh dimensional data. It attempts to screen out most irrelevant features in preparation for a more elaborate analysis. Xu and Chen (2014)<doi:10.1080/01621459.2013.879531> proposed an effective screening method SMLE, which naturally incorporates the joint effects among features in the screening process. This package provides an efficient implementation of SMLE-screening for high-dimensional linear, logistic, and Poisson models. The package also provides a function for conducting accurate post-screening feature selection based on an iterative hard-thresholding procedure and a user-specified selection criterion.",
    "version": "2.2-2",
    "maintainer": "Qianxiang Zang <SMLEmaintainer@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6810,
    "package_name": "SMMT",
    "title": "The Swiss Municipal Data Merger Tool Maps Municipalities Over\nTime",
    "description": "In Switzerland, the landscape of municipalities is changing rapidly\n  mainly due to mergers. The Swiss Municipal Data Merger Tool \n  automatically detects these mutations and maps municipalities over time, i.e. municipalities of an old state\n  to municipalities of a new state. This functionality is helpful when working \n  with datasets that are based on different spatial references. The package's idea and use \n  case is discussed in the following article: <doi:10.1111/spsr.12487>.",
    "version": "1.2.0",
    "maintainer": "Valentin Knechtl <valentinknechtl@gmail.com>",
    "url": "https://github.com/ValValetl/SMMT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6830,
    "package_name": "SNSequate",
    "title": "Standard and Nonstandard Statistical Models and Methods for Test\nEquating",
    "description": "Contains functions to perform various models and\n    methods for test equating (Kolen and Brennan, 2014 \n    <doi:10.1007/978-1-4939-0317-7> ; Gonzalez and Wiberg, 2017 \n    <doi:10.1007/978-3-319-51824-4> ; von Davier et. al, 2004 \n    <doi:10.1007/b97446>). It currently implements the traditional mean, linear \n    and equipercentile equating methods. Both IRT observed-score and true-score \n    equating are also supported, as well as the mean-mean, mean-sigma, Haebara \n    and Stocking-Lord IRT linking methods. It also supports newest methods such \n    that local equating, kernel equating (using Gaussian, logistic, \n    Epanechnikov, uniform and adaptive kernels) with presmoothing, and IRT \n    parameter linking methods based on asymmetric item characteristic functions. \n    Functions to obtain both standard error of equating (SEE) and standard error \n    of equating differences between two equating functions (SEED) are also \n    implemented for the kernel method of equating.",
    "version": "1.3-5",
    "maintainer": "Jorge Gonzalez <jorge.gonzalez@mat.uc.cl>",
    "url": "https://www.mat.uc.cl/~jorge.gonzalez/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6836,
    "package_name": "SOIL",
    "title": "Sparsity Oriented Importance Learning",
    "description": "Sparsity Oriented Importance Learning (SOIL) provides a new variable importance measure for high dimensional linear regression and logistic regression from a sparse penalization perspective, by taking into account the variable selection uncertainty via the use of a sensible model weighting. The package is an implementation of Ye, C., Yang, Y., and Yang, Y. (2017+).",
    "version": "1.1",
    "maintainer": "Yi Yang <yi.yang6@mcgill.ca>",
    "url": "https://github.com/emeryyi/SOIL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6846,
    "package_name": "SOR",
    "title": "Estimation using Sequential Offsetted Regression",
    "description": "Estimation for longitudinal data following outcome dependent sampling using the sequential offsetted regression technique.  Includes support for binary, count, and continuous data.  The first regression is a logistic regression, which uses a known ratio (the probability of being sampled given that the subject/observation was referred divided by the probability of being sampled given that the subject/observation was no referred) as an offset to estimate the probability of being referred given outcome and covariates.  The second regression uses this estimated probability to calculate the mean population response given covariates.",
    "version": "0.23.1",
    "maintainer": "Lee McDaniel <lmcda4@lsuhsc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6860,
    "package_name": "SPEDInstabR",
    "title": "Estimation of the Relative Importance of Factors Affecting\nSpecies Distribution Based on Stability Concept",
    "description": "From output files obtained from the software 'ModestR', the relative contribution of factors to explain species distribution is depicted using several plots. A global geographic raster file for each environmental variable may be also obtained with the mean relative contribution, considering all species present in each raster cell, of the factor to explain species distribution. Finally, for each variable it is also possible to compare the frequencies of any variable obtained in the cells where the species is present with the frequencies of the same variable in the cells of the extent.",
    "version": "2.2",
    "maintainer": "Castor Guisande Gonzalez <castor@uvigo.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6891,
    "package_name": "SQUAREM",
    "title": "Squared Extrapolation Methods for Accelerating EM-Like Monotone\nAlgorithms",
    "description": "Algorithms for accelerating the convergence of slow,\n        monotone sequences from smooth, contraction mapping such as the\n        EM algorithm. It can be used to accelerate any smooth, linearly\n        convergent acceleration scheme.  A tutorial style introduction\n        to this package is available in a vignette on the CRAN download\n        page or, when the package is loaded in an R session, with\n        vignette(\"SQUAREM\"). Refer to the J Stat Software article: <doi:10.18637/jss.v092.i07>. ",
    "version": "2021.1",
    "maintainer": "Ravi Varadhan <ravi.varadhan@jhu.edu>",
    "url": "https://coah.jhu.edu/people/Faculty_personal_Pages/Varadhan.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6892,
    "package_name": "SQUIRE",
    "title": "Statistical Quality-Assured Integrated Response Estimation",
    "description": "Provides systematic geometry-adaptive parameter optimization with \n    statistical validation for experimental biological data. Combines ANOVA-based \n    validation with systematic constraint configuration testing (log-scale, \n    positive domain, Euclidean) through T,P,E testing. Only proceeds with \n    parameter optimization when statistically significant biological effects \n    are detected, preventing over-fitting to noise. Uses 'GALAHAD' trust region methods with constraint projection from Conn et al. (2000) \n    <doi:10.1137/S1052623497325107>, ANOVA-based validation following Fisher \n    (1925) <doi:10.1007/978-1-4612-4380-9_6>, and effect size calculations \n    per Cohen (1988, ISBN:0805802835). Designed for structured experimental \n    data including kinetic curves, dose-response studies, and treatment \n    comparisons where appropriate parameter constraints and statistical \n    justification are important for meaningful biological interpretation. \n    Developed at the Minnesota Center for Prion Research and Outreach at \n    the University of Minnesota.",
    "version": "1.0.1",
    "maintainer": "Richard A. Feiss <feiss026@umn.edu>",
    "url": "https://github.com/RFeissIV/SQUIRE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6904,
    "package_name": "SSGL",
    "title": "Spike-and-Slab Group Lasso for Group-Regularized Generalized\nLinear Models",
    "description": "Fits group-regularized generalized linear models (GLMs) using the spike-and-slab group lasso (SSGL) prior of Bai et al. (2022) <doi:10.1080/01621459.2020.1765784> and extended to GLMs by Bai (2023) <doi:10.48550/arXiv.2007.07021>. This package supports fitting the SSGL model for the following GLMs with group sparsity: Gaussian linear regression, binary logistic regression, and Poisson regression.",
    "version": "2.0",
    "maintainer": "Ray Bai <raybaistat@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6906,
    "package_name": "SSIMmap",
    "title": "The Structural Similarity Index Measure for Maps",
    "description": "Extends the classical SSIM method proposed by 'Wang', 'Bovik', 'Sheikh', and 'Simoncelli'(2004) <doi:10.1109/TIP.2003.819861>. \n  for irregular lattice-based maps and raster images.\n  The geographical SSIM method incorporates well-developed 'geographically weighted summary statistics'('Brunsdon', 'Fotheringham' and 'Charlton' 2002) <doi:10.1016/S0198-9715(01)00009-6> \n  with an adaptive bandwidth kernel function for irregular lattice-based maps.",
    "version": "0.1.1",
    "maintainer": "Hui Jeong (Hailyee) Ha <hha24@uwo.ca>",
    "url": "https://github.com/Hailyee-Ha/SSIMmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6908,
    "package_name": "SSLfmm",
    "title": "Semi-Supervised Learning under a Mixed-Missingness Mechanism in\nFinite Mixture Models",
    "description": "Implements a semi-supervised learning framework for finite mixture\n    models under a mixed-missingness mechanism. The approach models both\n    missing completely at random (MCAR) and entropy-based missing at random\n    (MAR) processes using a logistic–entropy formulation. Estimation is carried\n    out via an Expectation–-Conditional Maximisation (ECM) algorithm with robust\n    initialisation routines for stable convergence. The methodology relates to\n    the statistical perspective and informative missingness behaviour discussed\n    in Ahfock and McLachlan (2020) <doi:10.1007/s11222-020-09971-5> and\n    Ahfock and McLachlan (2023) <doi:10.1016/j.ecosta.2022.03.007>. The package\n    provides functions for data simulation, model estimation, prediction, and\n    theoretical Bayes error evaluation for analysing partially labelled data\n    under a mixed-missingness mechanism.",
    "version": "0.1.0",
    "maintainer": "Jinran Wu <jinran.wu@uq.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6910,
    "package_name": "SSN2",
    "title": "Spatial Modeling on Stream Networks",
    "description": "Spatial statistical modeling and prediction for data on stream networks, including models based on in-stream distance (Ver Hoef, J.M. and Peterson, E.E., (2010) <DOI:10.1198/jasa.2009.ap08248>.) Models are created using moving average constructions. Spatial linear models, including explanatory variables, can be fit with (restricted) maximum likelihood.  Mapping and other graphical functions are included. ",
    "version": "0.4.0",
    "maintainer": "Michael Dumelle <Dumelle.Michael@epa.gov>",
    "url": "https://usepa.github.io/SSN2/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6912,
    "package_name": "SSNbler",
    "title": "Assemble 'SSN' Objects",
    "description": "Import, create and assemble data needed to fit spatial-statistical stream-network models using the 'SSN2' package for 'R'. Streams, observations, and prediction locations are represented as simple features and specific tools provided to define topological relationships between features; calculate the hydrologic distances (with flow-direction preserved) and the spatial additive function used to weight converging stream segments; and export the topological, spatial, and attribute information to an `SSN` (spatial stream network) object, which can be efficiently stored, accessed and analysed in 'R'. A detailed description of methods used to calculate and format the spatial data can be found in Peterson, E.E. and Ver Hoef, J.M., (2014) <doi:10.18637/jss.v056.i02>.",
    "version": "1.1.1",
    "maintainer": "Erin Peterson <erin@peterson-consulting.com>",
    "url": "https://github.com/pet221/SSNbler",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6913,
    "package_name": "SSOSVM",
    "title": "Stream Suitable Online Support Vector Machines",
    "description": "Soft-margin support vector machines (SVMs) are a common class of classification models. The training of SVMs usually requires that the data be available all at once in a single batch, however the Stochastic majorization-minimization (SMM) algorithm framework allows for the training of SVMs on streamed data instead Nguyen, Jones & McLachlan(2018)<doi:10.1007/s42081-018-0001-y>. This package utilizes the SMM framework to provide functions for training SVMs with hinge loss, squared-hinge loss, and logistic loss.",
    "version": "0.2.2",
    "maintainer": "Andrew Thomas Jones <andrewthomasjones@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6930,
    "package_name": "STCCGEV",
    "title": "Conditional Copula Model for Crop Yield Forecasting",
    "description": "Provides functions to model and forecast crop yields using a spatial temporal conditional copula approach. \n    The package incorporates extreme weather covariates and Bayesian Structural Time Series models to analyze crop \n    yield dependencies across multiple regions. Includes tools for fitting, simulating, and visualizing results. \n    This method build upon established R packages, including 'Hofert' 'et' 'al'. (2025) <doi:10.32614/CRAN.package.copula>, \n    'Scott' (2024) <doi:10.32614/CRAN.package.bsts>, and 'Stephenson' 'et' 'al'. (2024) <doi:10.32614/CRAN.package.evd>.",
    "version": "1.0.0",
    "maintainer": "Yongkun Li <yongkun.li@concordia.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6932,
    "package_name": "STDistance",
    "title": "Spatial Transcriptomics Distance Calculation and Visualization",
    "description": "Analysis of spatial relationships between cell types in spatial transcriptomics data. Spatial proximity is a critical factor in cell-cell communication. The package calculates nearest neighbor distances between specified cell types and provides visualization tools to explore spatial patterns. Applications include studying cell-cell interactions, immune microenvironment characterization, and spatial organization of tissues.",
    "version": "0.6.6",
    "maintainer": "Zixiang Wang <wangzixiang@sdu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6934,
    "package_name": "STExplorer",
    "title": "A package to explore Spatial Transcriptomics data using geographical methods",
    "description": "This is the public repository of STExplorer.",
    "version": "1.0.0",
    "maintainer": "",
    "url": "https://github.com/LefterisZ/STExplorer",
    "exports": [],
    "topics": ["bioconductor", "exploratory-data-analysis", "exploratory-data-visualizations", "omics", "r", "r-package", "rstats", "spatial", "spatial-analysis", "spatial-statistics", "spatial-transcriptomics"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 6937,
    "package_name": "STMotif",
    "title": "Discovery of Motifs in Spatial-Time Series",
    "description": "Allow to identify motifs in spatial-time series. A motif is a previously unknown subsequence of a (spatial) time series with relevant number of occurrences. For this purpose, the Combined Series Approach (CSA) is used.",
    "version": "2.0.2",
    "maintainer": "Heraldo Borges <stmotif@eic.cefet-rj.br>",
    "url": "https://github.com/heraldoborges/STMotif/wiki",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6944,
    "package_name": "STcompare",
    "title": "Framework for Spatial Transcriptomic Data Comparision",
    "description": "STcompare is an R package for comparing spatial gene expression patterns across spatial transcriptomics (ST) datasets.",
    "version": "0.1.0",
    "maintainer": "",
    "url": "https://github.com/JEFworks-Lab/STcompare",
    "exports": [],
    "topics": ["differential-expression", "rstats", "spatial-analysis", "spatial-omics", "spatial-transcriptomics", "statistics"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 6963,
    "package_name": "SWTools",
    "title": "Helper Tools for Australian Hydrologists",
    "description": "Functions to speed up work flow for hydrological analysis. \n    Focused on Australian climate data (SILO climate data), hydrological models (eWater Source) and in particular South Australia (<https://water.data.sa.gov.au> hydrological data).",
    "version": "1.1.0",
    "maintainer": "Matt Gibbs <gibbs.ms@gmail.com>",
    "url": "https://github.com/matt-s-gibbs/SWTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6974,
    "package_name": "SamplingBigData",
    "title": "Sampling Methods for Big Data",
    "description": "Select sampling methods for probability samples using large data sets.  This includes spatially balanced sampling in multi-dimensional spaces with any prescribed inclusion probabilities. All implementations are written in C with efficient data structures such as k-d trees that easily scale to several million rows on a modern desktop computer. ",
    "version": "1.0.0",
    "maintainer": "Jonathan Lisic <jlisic@gmail.com>",
    "url": "https://github.com/jlisic/SamplingBigData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6975,
    "package_name": "SamplingStrata",
    "title": "Optimal Stratification of Sampling Frames for Multipurpose\nSampling Surveys",
    "description": "Tools for the optimization of stratified sampling design. It determines a stratification of a sampling frame that minimizes sample cost while satisfying precision constraints in a multivariate and multidomain context. The approach relies on a genetic algorithm; each candidate partition of the frame is an individual whose fitness is evaluated via the Bethel-Chromy allocation to meet target precisions. Functions support analysis of optimization results, labeling of the frame with new strata, and drawing a sample according to the optimal allocation. Algorithmic components adapt code from the 'genalg' package. See M. Ballin and G. Barcaroli (2020) \"R package SamplingStrata: new developments and extension to Spatial Sampling\" <doi:10.48550/arXiv.2004.09366>.",
    "version": "1.5-5",
    "maintainer": "Giulio Barcaroli <gbarcaroli@gmail.com>",
    "url": "https://barcaroli.github.io/SamplingStrata/,\nhttps://github.com/barcaroli/SamplingStrata/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 6998,
    "package_name": "SeaGraphs",
    "title": "Sea Currents to Connectivity Transformation",
    "description": "Transformation of sea currents to connectivity data. Two files of\n horizontal and vertical currents flows are transformed into connectivity data\n in the form of 'sfnetwork', shapefile, edge list and adjacency matrix. An\n application example is shown at Nagkoulis et al. (2025)\n <doi:10.1016/j.dib.2024.111268>.",
    "version": "0.1.3",
    "maintainer": "Christos Adam <econp266@econ.soc.uoc.gr>",
    "url": "https://github.com/cadam00/SeaGraphs,\nhttps://cadam00.github.io/SeaGraphs/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7001,
    "package_name": "SearchTrees",
    "title": "Spatial Search Trees",
    "description": "The QuadTree data structure is useful for fast,\n\t     neighborhood-restricted lookups. We use it to implement fast k-Nearest\n        Neighbor and Rectangular range lookups in 2 dimenions. The\n        primary target is high performance interactive graphics.",
    "version": "0.5.5",
    "maintainer": "Gabriel Becker <gabembecker@gmail.com>",
    "url": "https://github.com/gmbecker/SearchTrees",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7030,
    "package_name": "SensMap",
    "title": "Sensory and Consumer Data Mapping",
    "description": "Provides Sensory and Consumer Data \n    mapping and analysis <doi:10.14569/IJACSA.2017.081266>. The mapping visualization is made available\n    from several features : options in dimension reduction methods and prediction models ranging from \n    linear to non linear regressions. A smoothed version of the map performed using locally weighted regression algorithm \n    is available. A selection process of map stability is provided. A 'shiny' application is included. \n    It presents an easy GUI for the implemented functions as well as a comparative tool of fit models\n    using several criteria. Basic analysis such as characterization of products,\n    panelists and sessions likewise consumer segmentation are also made available.",
    "version": "0.7",
    "maintainer": "Ibtihel Rebhi <ibtihel.rebhi@enit.utm.tn>",
    "url": "https://github.com/IbtihelRebhi/SensMap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7052,
    "package_name": "SeuratObject",
    "title": "Data Structures for Single Cell Data",
    "description": "\n  Defines S4 classes for single-cell genomic data and associated\n  information, such as dimensionality reduction embeddings, nearest-neighbor\n  graphs, and spatially-resolved coordinates. Provides data access methods and\n  R-native hooks to ensure the Seurat object is familiar to other R users. See\n  Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>,\n  Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>,\n  and Stuart T, Butler A, et al (2019) <doi:10.1016/j.cell.2019.05.031>,\n  Hao Y, Hao S, et al (2021) <doi:10.1016/j.cell.2021.04.048> and\n  Hao Y, et al (2023) <doi:10.1101/2022.02.24.481684> for\n  more details.",
    "version": "5.3.0",
    "maintainer": "Rahul Satija <seurat@nygenome.org>",
    "url": "https://satijalab.github.io/seurat-object/,\nhttps://github.com/satijalab/seurat-object",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7056,
    "package_name": "ShapePattern",
    "title": "Tools for Analyzing Shapes and Patterns",
    "description": "This is an evolving and growing collection of tools for the quantification, assessment, and comparison of shape and pattern. This collection provides tools for: (1) the spatial decomposition of planar shapes using 'ShrinkShape' to incrementally shrink shapes to extinction while computing area, perimeter, and number of parts at each iteration of shrinking; the spectra of results are returned in graphic and tabular formats (Remmel 2015) <doi:10.1111/cag.12222>, (2) simulating landscape patterns, (3) provision of tools for estimating composition and configuration parameters from a categorical (binary) landscape map (grid) and then simulates a selected number of statistically similar landscapes. Class-focused pattern metrics are computed for each simulated map to produce empirical distributions against which statistical comparisons can be made. The code permits the analysis of single maps or pairs of maps (Remmel and Fortin 2013) <doi:10.1007/s10980-013-9905-x>, (4) counting the number of each first-order pattern element and converting that information into both frequency and empirical probability vectors (Remmel 2020) <doi:10.3390/e22040420>, and (5) computing the porosity of raster patches <doi:10.3390/su10103413>. NOTE: This is a consolidation of existing packages ('PatternClass', 'ShapePattern') to begin warehousing all shape and pattern code in a common package. Additional utility tools for handling data are provided and this package will be added to as more tools are created, cleaned-up, and documented.  Note that all future developments will appear in this package and that 'PatternClass' will eventually be archived.",
    "version": "3.1.0",
    "maintainer": "Tarmo K. Remmel <remmelt@yorku.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7090,
    "package_name": "SightabilityModel",
    "title": "Wildlife Sightability Modeling",
    "description": "Uses logistic regression to model the probability of detection as a function of covariates. \n             This model is then used with observational survey data to estimate population size, while\n             accounting for uncertain detection.  See Steinhorst and Samuel (1989).",
    "version": "1.5.5",
    "maintainer": "Schwarz Carl James <cschwarz.stat.sfu.ca@gmail.com>",
    "url": "https://github.com/jfieberg/SightabilityModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7107,
    "package_name": "SimDissolution",
    "title": "Modeling and Assessing Similarity of Drug Dissolutions Profiles",
    "description": "Implementation of a model-based bootstrap approach for testing whether two formulations are similar. The package provides a function for fitting a pharmacokinetic model to time-concentration data and comparing the results for all five candidate models regarding the Residual Sum of Squares (RSS). The candidate set contains a First order, Hixson-Crowell, Higuchi, Weibull and a logistic model. The assessment of similarity implemented in this package is performed regarding the maximum deviation of the profiles. See Moellenhoff et al. (2018) <doi:10.1002/sim.7689> for details.",
    "version": "0.1.0",
    "maintainer": "Kathrin Moellenhoff <kathrin.moellenhoff@rub.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7141,
    "package_name": "SiteExploitationTerritories",
    "title": "SiteExploitationTerritories",
    "description": "A collection of functions for spatial analysis in archaeology.",
    "version": "0.1.0",
    "maintainer": "Dirk Seidensticker <dirk.seidensticker@uni-tuebingen.de>",
    "url": "https://github.com/DH-Center-Tuebingen/SiteExploitationTerritories",
    "exports": [],
    "topics": ["rstats", "spatial-analysis"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 7179,
    "package_name": "SoilSaltIndex",
    "title": "Soil Salinity Indices Generation using Satellite Data",
    "description": "The developed function generates soil salinity indices using satellite data, utilizing multiple spectral bands such as Blue, Green, Red, Near-Infrared (NIR),\n             and Shortwave Infrared (SWIR1, SWIR2). It computes 24 different salinity indices crucial for monitoring and analyzing salt-affected soils efficiently.\n             For more details see, Rani, et al. (2022). <DOI: 10.1007/s12517-022-09682-3>. One of the key features of the developed function is its flexibility.\n             Users can provide any combination of the required spectral bands, and the function will automatically calculate only the relevant indices based on the available data.\n             This dynamic capability ensures that users can maximize the utility of their data without the need for all spectral bands, making the package versatile and user-friendly.\n             Outputs are provided as GeoTIFF file format, facilitating easy integration with GIS workflows.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7187,
    "package_name": "SongEvo",
    "title": "An Individual-Based Model of Bird Song Evolution",
    "description": "Simulates the cultural evolution of quantitative traits of bird song. 'SongEvo' is an individual- (agent-) based model. 'SongEvo' is spatially-explicit and can be parameterized with, and tested against, measured song data. Functions are available for model implementation, sensitivity analyses, parameter optimization, model validation, and hypothesis testing. ",
    "version": "1.0.0",
    "maintainer": "Raymond Danner <dannerR@uncw.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7195,
    "package_name": "SpATS",
    "title": "Spatial Analysis of Field Trials with Splines",
    "description": "Analysis of field trial experiments by modelling spatial trends using two-dimensional Penalised spline (P-spline) models.",
    "version": "1.0-19",
    "maintainer": "Maria Xose Rodriguez-Alvarez <mxrodriguez@uvigo.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7197,
    "package_name": "SpPOP",
    "title": "Generation of Spatial Population under Different Levels of\nRelationships among Variables",
    "description": "The developed package can be used to generate a spatial population for different\n             levels of relationships among the dependent and auxiliary variables along with spatially\n             varying model parameters. A spatial layout is designed as a [0,k-1]x[0,k-1] square region on which observations\n             are collected at (k x k) lattice points with a unit distance between any two neighbouring points along the horizontal\n             and vertical axes. For method details see Chao, Liu., Chuanhua, Wei. and Yunan, Su. (2018).<doi:10.1080/10485252.2018.1499907>.\n             The generated spatial population can be utilized in Geographically Weighted Regression model based analysis for studying the \n             spatially varying relationships among the variables. Furthermore, various statistical analysis can be performed on this spatially \n             generated data.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul<nobin.niasm@outlook.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7200,
    "package_name": "SpaCOAP",
    "title": "High-Dimensional Spatial Covariate-Augmented Overdispersed\nPoisson Factor Model",
    "description": "A spatial covariate-augmented overdispersed Poisson factor model is proposed to perform efficient latent representation learning method for high-dimensional large-scale spatial count data with additional covariates.",
    "version": "1.3",
    "maintainer": "Wei Liu <liuwei8@scu.edu.cn>",
    "url": "https://github.com/feiyoung/SpaCOAP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7201,
    "package_name": "SpaDES",
    "title": "Develop and Run Spatially Explicit Discrete Event Simulation\nModels",
    "description": "Metapackage for implementing a variety of event-based models, with\n    a focus on spatially explicit models. These include raster-based,\n    event-based, and agent-based models. The core simulation components\n    (provided by 'SpaDES.core') are built upon a discrete event simulation (DES;\n    see Matloff (2011) ch 7.8.3 <https://nostarch.com/artofr.htm>)\n    framework that facilitates modularity, and easily enables the user to\n    include additional functionality by running user-built simulation modules\n    (see also 'SpaDES.tools'). Included are numerous tools to visualize rasters\n    and other maps (via 'quickPlot'), and caching methods for reproducible\n    simulations (via 'reproducible'). Tools for running simulation experiments are\n    provided by 'SpaDES.experiment'. Additional functionality is provided by\n    the 'SpaDES.addins' and 'SpaDES.shiny' packages.",
    "version": "2.0.11",
    "maintainer": "Alex M Chubaty <achubaty@for-cast.ca>",
    "url": "https://spades.predictiveecology.org,\nhttps://github.com/PredictiveEcology/SpaDES",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7202,
    "package_name": "SpaDES.core",
    "title": "Core Utilities for Developing and Running Spatially Explicit\nDiscrete Event Models",
    "description": "Provides the core framework for a discrete event system to \n    implement a complete data-to-decisions, reproducible workflow.\n    The core components facilitate the development of modular pieces, \n    and enable the user to include additional functionality by running user-built modules.\n    Includes conditional scheduling, restart after interruption, packaging of\n    reusable modules, tools for developing arbitrary automated workflows,\n    automated interweaving of modules of different temporal resolution,\n    and tools for visualizing and understanding the within-project dependencies. \n    The suggested package 'NLMR' can be installed from the repository \n    (<https://PredictiveEcology.r-universe.dev>).",
    "version": "2.1.8",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "url": "https://spades-core.predictiveecology.org/,\nhttps://github.com/PredictiveEcology/SpaDES.core",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7203,
    "package_name": "SpaDES.tools",
    "title": "Additional Tools for Developing Spatially Explicit Discrete\nEvent Simulation (SpaDES) Models",
    "description": "Provides GIS and map utilities, plus additional modeling\n    tools for developing cellular automata, dynamic raster models, and\n    agent based models in 'SpaDES'.  Included are various methods for\n    spatial spreading, spatial agents, GIS operations, random map\n    generation, and others.  See '?SpaDES.tools' for an categorized\n    overview of these additional tools.  The suggested package 'NLMR' can\n    be installed from the following repository:\n    (<https://PredictiveEcology.r-universe.dev>).",
    "version": "2.0.9",
    "maintainer": "Alex M Chubaty <achubaty@for-cast.ca>",
    "url": "https://spades-tools.predictiveecology.org,\nhttps://github.com/PredictiveEcology/SpaDES.tools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7205,
    "package_name": "SpaTopic",
    "title": "Topic Inference to Identify Tissue Architecture in Multiplexed\nImages",
    "description": "A novel spatial topic model to integrate both cell type and spatial information to identify the complex spatial tissue architecture on multiplexed tissue images without human intervention. The Package implements a collapsed Gibbs sampling algorithm for inference. 'SpaTopic' is scalable to large-scale image datasets without extracting neighborhood information for every single cell. For more details on the methodology, see <https://xiyupeng.github.io/SpaTopic/>.",
    "version": "1.2.0",
    "maintainer": "Xiyu Peng <pansypeng124@gmail.com>",
    "url": "https://github.com/xiyupeng/SpaTopic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7225,
    "package_name": "SpatEntropy",
    "title": "Spatial Entropy Measures",
    "description": "The heterogeneity of spatial data presenting a finite number of categories can be measured via computation of spatial entropy. Functions are available for the computation of the main entropy and spatial entropy measures in the literature. They include the traditional version of Shannon's entropy (Shannon, 1948 <doi:10.1002/j.1538-7305.1948.tb01338.x>), Batty's spatial entropy (Batty, 1974 <doi:10.1111/j.1538-4632.1974.tb01014.x>), O'Neill's entropy (O'Neill et al., 1998 <doi:10.1007/BF00162741>), Li and Reynolds' contagion index (Li and Reynolds, 1993 <doi:10.1007/BF00125347>), Karlstrom and Ceccato's entropy (Karlstrom and Ceccato, 2002 <https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-61351>), Leibovici's entropy (Leibovici, 2009 <doi:10.1007/978-3-642-03832-7_24>), Parresol and Edwards' entropy (Parresol and Edwards, 2014 <doi:10.3390/e16041842>) and Altieri's entropy (Altieri et al., 2018, <doi:10.1007/s10651-017-0383-1>). Full references for all measures can be found under the topic 'SpatEntropy'. The package is able to work with lattice and point data. The updated version works with the updated 'spatstat' package (>= 3.0-2). ",
    "version": "2.2-4",
    "maintainer": "Altieri Linda <linda.altieri@unibo.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7226,
    "package_name": "SpatFD",
    "title": "Functional Geostatistics: Univariate and Multivariate Functional\nSpatial Prediction",
    "description": "Performance of functional kriging, cokriging, optimal sampling and simulation for spatial prediction of functional data. The framework of spatial prediction, optimal sampling and simulation are extended from scalar to functional data. 'SpatFD' is based on the Karhunen-Loève expansion that allows to represent the observed functions in terms of its empirical functional principal components. Based on this approach, the functional auto-covariances and cross-covariances required for  spatial functional predictions and optimal sampling, are completely determined by the sum of the spatial auto-covariances and cross-covariances of the respective score components. The package provides new classes of data and functions for modeling spatial dependence structure among curves. The spatial prediction of curves at unsampled locations can be carried out using two types of predictors, and both of them report, the respective variances of the prediction error. In addition, there is a function for the determination of spatial locations sampling configuration that ensures minimum variance of spatial functional prediction. There are also two functions for plotting predicted curves at each location and mapping the surface at each time point, respectively. References Bohorquez, M., Giraldo, R., and Mateu, J. (2016) <doi:10.1007/s10260-015-0340-9>, Bohorquez, M., Giraldo, R., and Mateu, J. (2016) <doi:10.1007/s00477-016-1266-y>, Bohorquez M., Giraldo R. and Mateu J. (2021) <doi:10.1002/9781119387916>.",
    "version": "0.0.1",
    "maintainer": "Martha Patricia Bohorquez Castañeda <mpbohorquezc@unal.edu.co>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7227,
    "package_name": "SpatGC",
    "title": "Bayesian Modeling of Spatial Count Data",
    "description": "Provides a collection of functions for preparing data and fitting Bayesian count spatial regression models, with a specific focus on the Gamma-Count (GC) model. The GC model is well-suited for modeling dispersed count data, including under-dispersed or over-dispersed counts, or counts with equivalent dispersion, using Integrated Nested Laplace Approximations (INLA). The package includes functions for generating data from the GC model, as well as spatially correlated versions of the model. See Nadifar, Baghishani, Fallah (2023) <doi:10.1007/s13253-023-00550-5>.",
    "version": "0.1.0",
    "maintainer": "Mahsa Nadifar <mahsa.nst@gmail.com>",
    "url": "https://github.com/mahsanst/SpatGC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7228,
    "package_name": "SpatGRID",
    "title": "Spatial Grid Generation from Longitude and Latitude List",
    "description": "The developed function is designed for the generation of spatial grids based on user-specified longitude and latitude coordinates. The function first validates the input longitude and latitude values,\n              ensuring they fall within the appropriate geographic ranges. It then creates a polygon from the coordinates and determines the appropriate Universal Transverse Mercator zone based on the provided \n              hemisphere and longitude values. Subsequently, transforming the input Shapefile to the Universal Transverse Mercator projection when necessary. Finally, a spatial grid is generated with the specified interval and saved as a Shapefile. \n              For method details see, Brus,D.J.(2022).<DOI:10.1201/9781003258940>. The function takes into account crucial parameters such as the hemisphere (north or south), desired grid interval, and the output Shapefile path.\n              The developed function is an efficient tool, simplifying the process of empty spatial grid generation for applications such as, geo-statistical analysis, digital soil mapping product generation, etc. Whether for environmental studies, \n              urban planning, or any other geo-spatial analysis, this package caters to the diverse needs of users working with spatial data, enhancing the accessibility and ease of spatial data processing and visualization.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7231,
    "package_name": "SpatialAcc",
    "title": "Spatial Accessibility Measures",
    "description": "Provides a set of spatial accessibility measures from a set of locations \n             (demand) to another set of locations (supply). It aims, among others, \n             to support research on spatial accessibility to health care facilities. \n             Includes the locations and some characteristics of major public hospitals in Greece.",
    "version": "0.1-5",
    "maintainer": "Stamatis Kalogirou <stamatis.science@gmail.com>",
    "url": "https://stamatisgeoai.eu/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7232,
    "package_name": "SpatialBSS",
    "title": "Blind Source Separation for Multivariate Spatial Data",
    "description": "Blind source separation for multivariate spatial data based on simultaneous/joint diagonalization of (robust) local covariance matrices. This package is an implementation of the methods described in Bachoc, Genton, Nordhausen, Ruiz-Gazen and Virta (2020) <doi:10.1093/biomet/asz079>.",
    "version": "0.16-0",
    "maintainer": "Klaus Nordhausen <klausnordhausenR@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7240,
    "package_name": "SpatialGEV",
    "title": "Fit Spatial Generalized Extreme Value Models",
    "description": "Fit latent variable models with the GEV distribution as the data likelihood and the GEV parameters following latent Gaussian processes. The models in this package are built using the template model builder 'TMB' in R, which has the fast ability to integrate out the latent variables using Laplace approximation. This package allows the users to choose in the fit function which GEV parameter(s) is considered as a spatially varying random effect following a Gaussian process, so the users can fit spatial GEV models with different complexities to their dataset without having to write the models in 'TMB' by themselves. This package also offers methods to sample from both fixed and random effects posteriors as well as the posterior predictive distributions at different spatial locations. Methods for fitting this class of models are described in Chen, Ramezan, and Lysy (2024) <doi:10.48550/arXiv.2110.07051>.",
    "version": "1.0.1",
    "maintainer": "Meixi Chen <meixi.chen@uwaterloo.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7241,
    "package_name": "SpatialGraph",
    "title": "The SpatialGraph Class and Utilities",
    "description": "Provision of the S4 SpatialGraph class built on top of objects provided by 'igraph' and 'sp' packages, and associated utilities. See the documentation of the SpatialGraph-class within this package for further description. An example of how from a few points one can arrive to a SpatialGraph is provided in the function sl2sg().  ",
    "version": "1.0-4",
    "maintainer": "Javier Garcia-Pintado <jgarciapintado@marum.de>",
    "url": "https://github.com/garciapintado/SpatialGraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7242,
    "package_name": "SpatialKDE",
    "title": "Kernel Density Estimation for Spatial Data",
    "description": "Calculate Kernel Density Estimation (KDE) for spatial data. \n  The algorithm is inspired by the tool 'Heatmap' from 'QGIS'. The method is described by:\n  Hart, T., Zandbergen, P. (2014) <doi:10.1108/PIJPSM-04-2013-0039>, \n  Nelson, T. A., Boots, B. (2008) <doi:10.1111/j.0906-7590.2008.05548.x>,\n  Chainey, S., Tompson, L., Uhlig, S.(2008) <doi:10.1057/palgrave.sj.8350066>.",
    "version": "0.8.2",
    "maintainer": "Jan Caha <jan.caha@outlook.com>",
    "url": "https://jancaha.github.io/SpatialKDE/index.html,\nhttps://github.com/JanCaha/SpatialKDE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7243,
    "package_name": "SpatialNP",
    "title": "Multivariate Nonparametric Methods Based on Spatial Signs and\nRanks",
    "description": "Test and estimates of location, tests of independence, tests of sphericity and several estimates of shape all based on spatial signs, symmetrized signs, ranks and signed ranks. For details, see Oja and Randles (2004) <doi:10.1214/088342304000000558> and Oja (2010) <doi:10.1007/978-1-4419-0468-3>.",
    "version": "1.1-6",
    "maintainer": "Klaus Nordhausen <klausnordhausenr@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7245,
    "package_name": "SpatialPOP",
    "title": "Generation of Spatial Data with Spatially Varying Model\nParameter",
    "description": "A spatial population can be generated based on spatially varying regression model under the assumption that observations are collected from a uniform two-dimensional grid consist of (m * m) lattice points with unit distance between any two neighbouring points. For method details see Chao, Liu., Chuanhua, Wei. and Yunan, Su. (2018).<DOI:10.1080/10485252.2018.1499907>.  This spatially generated data can be used to test different issues related to the statistical analysis of spatial data.\n This generated spatial data can be utilized in geographically weighted regression analysis for studying the spatially varying relationships among the variables.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul<ncp375@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7246,
    "package_name": "SpatialPack",
    "title": "Tools for Assessment the Association Between Two Spatial\nProcesses",
    "description": "Tools to assess the association between two spatial processes. Currently,\n  several methodologies are implemented: A modified t-test to perform hypothesis testing\n  about the independence between the processes, a suitable nonparametric correlation\n  coefficient, the codispersion coefficient, and an F test for assessing the multiple\n  correlation between one spatial process and several others. Functions for image\n  processing and computing the spatial association between images are also provided.\n  Functions contained in the package are intended to accompany Vallejos, R., Osorio, F.,\n  Bevilacqua, M. (2020). Spatial Relationships Between Two Georeferenced Variables:\n  With Applications in R. Springer, Cham <doi:10.1007/978-3-030-56681-4>.",
    "version": "0.4-1",
    "maintainer": "Felipe Osorio <felipe.osorios@usm.cl>",
    "url": "http://spatialpack.mat.utfsm.cl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7247,
    "package_name": "SpatialPosition",
    "title": "Spatial Position Models",
    "description": "Computes spatial position models: the potential model as defined",
    "version": "2.1.3",
    "maintainer": "",
    "url": "https://github.com/riatelab/SpatialPosition",
    "exports": [],
    "topics": ["accessibility", "cran", "potential", "r", "r-package", "spatial-analysis", "stewart-potentials"],
    "score": "NA",
    "stars": 32
  },
  {
    "id": 7249,
    "package_name": "SpatialRegimes",
    "title": "Spatial Constrained Clusterwise Regression",
    "description": "A collection of functions for estimating spatial regimes, aggregations of neighboring spatial units that are homogeneous in functional terms. The term spatial regime, therefore, should not be understood as a synonym for cluster. More precisely, the term cluster does not presuppose any functional relationship between the variables considered, while the term regime is linked to a regressive relationship underlying the spatial process. ",
    "version": "1.2",
    "maintainer": "Francesco Vidoli <fvidoli@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7251,
    "package_name": "SpatialTools",
    "title": "Tools for Spatial Data Analysis",
    "description": "Tools for spatial data analysis.  Emphasis on kriging.  Provides functions for prediction and simulation.  Intended to be relatively straightforward, fast, and flexible.",
    "version": "1.0.5",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7253,
    "package_name": "SpatialVx",
    "title": "Spatial Forecast Verification",
    "description": "Spatial forecast verification refers to verifying weather forecasts when the verification set (forecast and observations) is on a spatial field, usually a high-resolution gridded spatial field.  Most of the functions here require the forecast and observed fields to be gridded and on the same grid. For a thorough review of most of the methods in this package, please see Gilleland et al. (2009) <doi: 10.1175/2009WAF2222269.1> and for a tutorial on some of the main functions available here, see Gilleland (2022) <doi: 10.5065/4px3-5a05>. ",
    "version": "1.0-3",
    "maintainer": "Eric Gilleland <eric.gilleland@colostate.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7254,
    "package_name": "Spbsampling",
    "title": "Spatially Balanced Sampling",
    "description": "Selection of spatially balanced samples. In particular, the implemented sampling designs allow to select probability samples well spread over the population of interest, in any dimension and using any distance function (e.g. Euclidean distance, Manhattan distance). For more details, Pantalone F, Benedetti R, and Piersimoni F (2022) <doi:10.18637/jss.v103.c02>, Benedetti R and Piersimoni F (2017) <doi:10.1002/bimj.201600194>, and Benedetti R and Piersimoni F (2017) <arXiv:1710.09116>. The implementation has been done in C++ through the use of 'Rcpp' and 'RcppArmadillo'. ",
    "version": "1.3.5",
    "maintainer": "Francesco Pantalone <pantalone.fra@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7270,
    "package_name": "SphericalCubature",
    "title": "Numerical Integration over Spheres and Balls in n-Dimensions;\nMultivariate Polar Coordinates",
    "description": "Provides several methods to integrate functions over the unit\n sphere and ball in n-dimensional Euclidean space.  Routines for converting to/from\n multivariate polar/spherical coordinates are also provided.",
    "version": "1.5",
    "maintainer": "John P. Nolan <jpnolan@american.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7276,
    "package_name": "Splinets",
    "title": "Functional Data Analysis using Splines and Orthogonal Spline\nBases",
    "description": "Splines are efficiently represented through their Taylor expansion at the knots. The representation accounts for the support sets and is thus suitable for sparse functional data. Two cases of boundary conditions are considered: zero-boundary or periodic-boundary for all derivatives except the last. The periodical splines are represented graphically using polar coordinates. The B-splines and orthogonal bases of splines that reside on small total support are implemented. The orthogonal bases are referred to as 'splinets' and are utilized for functional data analysis. Random spline generator is implemented as well as  all fundamental algebraic and calculus operations on splines.  The optimal, in the least square sense, functional fit by 'splinets' to data consisting of sampled values of functions as well as splines build over another set of knots is obtained and used for functional data analysis. The S4-version of the object oriented R is used.  <doi:10.48550/arXiv.2102.00733>, <doi:10.1016/j.cam.2022.114444>, <doi:10.48550/arXiv.2302.07552>. ",
    "version": "1.5.1",
    "maintainer": "Krzysztof Podgorski <Krzysztof.Podgorski@stat.lu.se>",
    "url": "https://github.com/ranibasna/R-Splinets,\nhttps://ranibasna.github.io/R-Splinets/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7293,
    "package_name": "Sstack",
    "title": "Bootstrap Stacking of Random Forest Models for Heterogeneous\nData",
    "description": "Generates and predicts a set of linearly stacked Random Forest models using bootstrap sampling. Individual datasets may be heterogeneous (not all samples have full sets of features). Contains support for parallelization but the user should register their cores before running. This is an extension of the method found in Matlock (2018) <doi:10.1186/s12859-018-2060-2>.",
    "version": "1.0.1",
    "maintainer": "Kevin Matlock <kevin.matlock@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7325,
    "package_name": "StepGWR",
    "title": "A Hybrid Spatial Model for Prediction and Capturing Spatial\nVariation in the Data",
    "description": "It is a hybrid spatial model that combines the variable selection capabilities of stepwise regression methods with the predictive power of the Geographically \n             Weighted Regression(GWR) model.The developed hybrid model follows a two-step approach where the stepwise variable selection method is applied first to identify \n             the subset of predictors that have the most significant impact on the response variable, and then a GWR model is fitted using those selected variables for spatial \n             prediction at test or unknown locations. For method details,see Leung, Y., Mei, C. L. and Zhang, W. X. (2000).<DOI:10.1068/a3162>.This hybrid spatial model aims to \n             improve the accuracy and interpretability of GWR predictions by selecting a subset of relevant variables through a stepwise selection process.This approach is particularly \n             useful for modeling spatially varying relationships and improving the accuracy of spatial predictions.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7326,
    "package_name": "StepReg",
    "title": "Stepwise Regression Analysis",
    "description": "Stepwise regression is a statistical technique used for model selection. This package streamlines stepwise regression analysis by supporting multiple regression types(linear, Cox, logistic, Poisson, Gamma, and negative binomial), incorporating popular selection strategies(forward, backward, bidirectional, and subset), and offering essential metrics. It enables users to apply multiple selection strategies and metrics in a single function call, visualize variable selection processes, and export results in various formats. StepReg offers a data-splitting option to address potential issues with invalid statistical inference and a randomized forward selection option to avoid overfitting. We validated StepReg's accuracy using public datasets within the SAS software environment. For an interactive web interface, users can install the companion 'StepRegShiny' package.",
    "version": "1.6.1",
    "maintainer": "Junhui Li <junhui.li11@umassmed.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7327,
    "package_name": "StepRegShiny",
    "title": "Graphical User Interface for 'StepReg'",
    "description": "A web-based 'shiny' interface for the 'StepReg' package enables stepwise regression analysis across linear, generalized linear (including logistic, Poisson, Gamma, and negative binomial), and Cox models. It supports forward, backward, bidirectional, and best-subset selection under a range of criteria. The package also supports stepwise regression to multivariate settings, allowing multiple dependent variables to be modeled simultaneously. Users can explore and combine multiple selection strategies and criteria to optimize model selection. For enhanced robustness, the package offers optional randomized forward selection to reduce overfitting, and a data-splitting workflow for more reliable post-selection inference. Additional features include logging and visualization of the selection process, as well as the ability to export results in common formats.",
    "version": "1.6.1",
    "maintainer": "Junhui Li <junhui.li11@umassmed.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7359,
    "package_name": "SuRF.vs",
    "title": "Subsampling Ranking Forward Selection (SuRF)",
    "description": "Performs variable selection based on subsampling, ranking forward selection. Details of the method are published in Lihui Liu, Hong Gu, Johan Van Limbergen, Toby Kenney (2020) SuRF: A new method for sparse variable selection, with application in microbiome data analysis  Statistics in Medicine 40 897-919 <doi:10.1002/sim.8809>. Xo is the matrix of predictor variables. y is the response variable. Currently only binary responses using logistic regression are supported. X is a matrix of additional predictors which should be scaled to have sum 1 prior to analysis. fold is the number of folds for cross-validation. Alpha is the parameter for the elastic net method used in the subsampling procedure: the default value of 1 corresponds to LASSO. prop is the proportion of variables to remove in the each subsample. weights indicates whether observations should be weighted by class size. When the class sizes are unbalanced, weighting observations can improve results. B is the number of subsamples to use for ranking the variables. C is the number of permutations to use for estimating the critical value of the null distribution. If the 'doParallel' package is installed, the function can be run in parallel by setting ncores to the number of threads to use. If the default value of 1 is used, or if the 'doParallel' package is not installed, the function does not run in parallel. display.progress indicates whether the function should display messages indicating its progress. family is a family variable for the glm() fitting. Note that the 'glmnet' package does not permit the use of nonstandard link functions, so will always use the default link function. However, the glm() fitting will use the specified link. The default is binomial with logistic regression, because this is a common use case. pval is the p-value for inclusion of a variable in the model. Under the null case, the number of false positives will be geometrically distributed with this as probability of success, so if this parameter is set to p, the expected number of false positives should be p/(1-p).",
    "version": "1.1.0.1",
    "maintainer": "Toby Kenney <tkenney@mathstat.dal.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7368,
    "package_name": "SumcaVer1",
    "title": "Mean Square Prediction Error Estimation in Small Area Estimation",
    "description": "Estimation of mean squared prediction error of a small area predictor is provided. In particular, the recent method of Simple, Unified, Monte-Carlo Assisted approach for the mean squared prediction error estimation of small area predictor is provided. We also provide other existing methods of mean squared prediction error estimation such as jackknife method for the mixed logistic model.",
    "version": "0.1.0",
    "maintainer": "Mahmoud Torabi <mahmoud.torabi@umanitoba.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7387,
    "package_name": "SurfaceTortoise",
    "title": "Find Optimal Sampling Locations Based on Spatial Covariate(s)",
    "description": "Create sampling designs using the surface reconstruction algorithm.\n  Original method by: Olsson, D. 2002. A method to optimize soil sampling from \n  ancillary data. Poster presenterad at: NJF seminar no. 336, \n  Implementation of Precision Farming in Practical Agriculture, 10-12 \n  June 2002, Skara, Sweden.",
    "version": "2.0.1",
    "maintainer": "Kristin Persson <kristin.persson@slu.se>",
    "url": "https://CRAN.R-project.org/package=SurfaceTortoise",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7463,
    "package_name": "TCHazaRds",
    "title": "Tropical Cyclone (Hurricane, Typhoon) Spatial Hazard Modelling",
    "description": "Methods for generating modelled parametric Tropical Cyclone (TC) spatial hazard fields and time series output at point locations from TC tracks.  R's compatibility to simply use fast 'cpp' code via the 'Rcpp' package and the wide range spatial analysis tools via the 'terra' package makes it an attractive open source environment to study 'TCs'.  This package estimates TC vortex wind and pressure fields using parametric equations originally coded up in 'python' by 'TCRM' <https://github.com/GeoscienceAustralia/tcrm> and then coded up in 'Cuda' 'cpp' by 'TCwindgen' <https://github.com/CyprienBosserelle/TCwindgen>.",
    "version": "1.1.5",
    "maintainer": "Julian O'Grady <julian.ogrady@csiro.au>",
    "url": "https://github.com/AusClimateService/TCHazaRds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7517,
    "package_name": "TML",
    "title": "Tropical Geometry Tools for Machine Learning",
    "description": "Suite of tropical geometric tools for use in machine learning applications. These methods may be summarized in the following references: Yoshida, et al. (2022) <doi:10.2140/astat.2023.14.37>, Barnhill et al. (2023) <doi:10.48550/arXiv.2303.02539>, Barnhill and Yoshida (2023) <doi:10.3390/math11153433>, Aliatimis et al. (2023) <doi:10.1007/s11538-024-01327-8>, Yoshida et al. (2022) <doi:10.1109/TCBB.2024.3420815>, and Yoshida et al. (2019) <doi:10.1007/s11538-018-0493-4>.",
    "version": "2.3.0",
    "maintainer": "David Barnhill <david.barnhill@nps.edu>",
    "url": "https://github.com/barnhilldave/TML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7524,
    "package_name": "TOC",
    "title": "Total Operating Characteristic Curve and ROC Curve",
    "description": "Construction of the Total Operating Characteristic (TOC) Curve and the Receiver (aka Relative) Operating Characteristic (ROC) Curve for spatial and non-spatial data. The TOC method is a modification of the ROC method which measures the ability of an index variable to diagnose either presence or absence of a characteristic. The diagnosis depends on whether the value of an index variable is above a threshold. Each threshold generates a two-by-two contingency table, which contains four entries: hits (H), misses (M), false alarms (FA), and correct rejections (CR). While ROC shows for each threshold only two ratios, H/(H + M) and FA/(FA + CR), TOC reveals the size of every entry in the contingency table for each threshold (Pontius Jr., R.G., Si, K. 2014. <doi:10.1080/13658816.2013.862623>). ",
    "version": "0.0-6",
    "maintainer": "Ali Santacruz <amsantac@unal.edu.co>",
    "url": "https://github.com/amsantac/TOC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7544,
    "package_name": "TR8",
    "title": "A Tool for Downloading Functional Traits Data for Plant Species",
    "description": "Plant ecologists often need to collect \"traits\" data\n    about plant species which are often scattered among various\n    databases: TR8 contains a set of tools which take care of\n    automatically retrieving some of those functional traits data\n    for plant species from publicly available databases (The Ecological Flora\n    of the British Isles, LEDA traitbase, Ellenberg\n    values for Italian Flora, Mycorrhizal intensity databases, BROT,\n    PLANTS, Jepson Flora Project).\n    The TR8 name, inspired by \"car plates\" jokes, was chosen since\n    it both reminds of the main object of the package and is\n    extremely short to type.",
    "version": "0.9.23",
    "maintainer": "Gionata Bocci <boccigionata@gmail.com>",
    "url": "https://github.com/GioBo/TR8",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7559,
    "package_name": "TSCS",
    "title": "Time Series Cointegrated System",
    "description": "A set of functions to implement Time Series Cointegrated System (TSCS)\n    spatial interpolation and relevant data visualization.",
    "version": "0.1.1",
    "maintainer": "Tianjian Yang <yangtj5@mail2.sysu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7609,
    "package_name": "Taba",
    "title": "Taba Robust Correlations",
    "description": "Calculates the robust Taba linear, Taba rank (monotonic), TabWil, and TabWil rank \n    correlations. Test statistics as well as one sided or two sided p-values are provided \n    for all correlations. Multiple correlations and p-values can be calculated \n    simultaneously across multiple variables. In addition, users will have the option to use \n    the partial, semipartial, and generalized partial correlations; where the partial and \n    semipartial correlations use linear, logistic, or Poisson regression to modify the specified\n    variable. ",
    "version": "1.0.0",
    "maintainer": "Derek Wilus <dwilus@mmc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7618,
    "package_name": "TangledFeatures",
    "title": "Feature Selection in Highly Correlated Spaces",
    "description": "Feature selection algorithm that extracts features in highly\n    correlated spaces. The extracted features are meant to be fed into\n    simple explainable models such as linear or logistic regressions. The\n    package is useful in the field of explainable modelling as a\n    way to understand variable behavior.",
    "version": "0.1.1",
    "maintainer": "Allen Sunny <allensunny1242@gmail.com>",
    "url": "https://allen-1242.github.io/TangledFeatures/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7649,
    "package_name": "TestDataImputation",
    "title": "Missing Item Responses Imputation for Test and Assessment Data",
    "description": "Functions for imputing missing item responses for dichotomous and\n    polytomous test and assessment data. This package enables missing imputation\n    methods that are suitable for test and assessment data, including: \n    listwise (LW) deletion (see De Ayala et al. 2001 <doi:10.1111/j.1745-3984.2001.tb01124.x>), \n    treating as incorrect (IN, see Lord, 1974 <doi: 10.1111/j.1745-3984.1974.tb00996.x>; \n    Mislevy & Wu, 1996 <doi: 10.1002/j.2333-8504.1996.tb01708.x>; \n    Pohl et al., 2014 <doi: 10.1177/0013164413504926>), person mean imputation (PM), \n    item mean imputation (IM), two-way (TW) and response function (RF) imputation,\n    (see Sijtsma & van der Ark, 2003 <doi: 10.1207/s15327906mbr3804_4>),\n    logistic regression (LR) imputation, predictive mean matching (PMM), and expectation–maximization (EM) \n    imputation (see Finch, 2008 <doi: 10.1111/j.1745-3984.2008.00062.x>).",
    "version": "2.3",
    "maintainer": "Shenghai Dai <s.dai@wsu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7695,
    "package_name": "Tivy",
    "title": "Toolkit for Investigation and Visualization of Young Anchovies",
    "description": "Specialized toolkit for processing biological and fisheries data from Peru's anchovy (Engraulis ringens) fishery. Provides functions to analyze fishing logbooks, calculate biological indicators (length-weight relationships, juvenile percentages), generate spatial fishing indicators, and visualize regulatory measures from Peru's Ministry of Production. Features automated data processing from multiple file formats, coordinate validation, spatial analysis of fishing zones, and tools for analyzing fishing closure announcements and regulatory compliance. Includes built-in datasets of Peruvian coastal coordinates and parallel lines for analyzing fishing activities within regulatory zones.",
    "version": "0.1.1",
    "maintainer": "Hans Ttito <kvttitos@gmail.com>",
    "url": "https://github.com/HansTtito/Tivy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7701,
    "package_name": "Toothnroll",
    "title": "Dental Tissues Landmarking Measuring and Mapping",
    "description": "Two- and three-dimensional morphometric maps of enamel and \n\tdentine thickness and multivariate analysis. \n\tVolume calculation of dental materials. \n\tPrincipal component analysis of thickness maps with \n\tassociated morphometric map variations.",
    "version": "1.11",
    "maintainer": "Antonio Profico <antonio.profico@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7740,
    "package_name": "TreeRingShape",
    "title": "Recording Tree-Ring Shapes of Tree Disks with Manual Digitizing\nand Interpolating Model",
    "description": "Record all tree-ring Shapefile of tree disk with GIS soft 'Qgis' and interpolating model from high resolution tree disk image. ",
    "version": "3.0.5",
    "maintainer": "Megumi ISHIDA <ishidam@sanchikanri.com>",
    "url": "https://CRAN.R-project.org/package=TreeRingShape,\nhttps://github.com/ishidamgm/TreeRingShape,\nhttps://ishidamgm.github.io/TreeRingShape/,\nhttps://www.sanchikanri.com/treering/TreeRingShape.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7762,
    "package_name": "TroublemakeR",
    "title": "Generates Spatial Problems in R for 'AMPL'",
    "description": "Provides methods for generating .dat files for use with the 'AMPL' \n    software using spatial data, particularly rasters. It includes support for \n    various spatial data formats and different problem types. By automating the \n    process of generating 'AMPL' datasets, this package can help streamline \n    optimization workflows and make it easier to solve complex optimization \n    problems. The methods implemented in this package are described in detail\n    in a publication by Fourer et al. (<doi:10.1287/mnsc.36.5.519>).",
    "version": "0.0.1",
    "maintainer": "Derek Corcoran <derek.corcoran.barrios@gmail.com>",
    "url": "https://github.com/Sustainscapes/TroublemakeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7775,
    "package_name": "Twitmo",
    "title": "Twitter Topic Modeling and Visualization for R",
    "description": "Tailored for topic modeling with tweets and fit for visualization tasks in R.",
    "version": "0.1.5",
    "maintainer": "",
    "url": "https://github.com/abuchmueller/Twitmo",
    "exports": [],
    "topics": ["ctm", "geospatial", "lda", "nlp", "r", "r-package", "rstats", "stm", "topic-modeling", "twitter", "twitter-api"],
    "score": "NA",
    "stars": 20
  },
  {
    "id": 7781,
    "package_name": "TwoStepCLogit",
    "title": "Conditional Logistic Regression: A Two-Step Estimation Method",
    "description": "Conditional logistic regression with longitudinal follow up and\n    individual-level random coefficients: A stable and efficient\n    two-step estimation method.",
    "version": "1.2.6",
    "maintainer": "Thierry Duchesne <thierry.duchesne@mat.ulaval.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7789,
    "package_name": "UAHDataScienceUC",
    "title": "Learn Clustering Techniques Through Examples and Code",
    "description": "A comprehensive educational package combining clustering algorithms with \n    detailed step-by-step explanations. Provides implementations of both traditional \n    (hierarchical, k-means) and modern (Density-Based Spatial Clustering of Applications with Noise (DBSCAN), \n    Gaussian Mixture Models (GMM), genetic k-means) clustering methods \n    as described in Ezugwu et. al., (2022) <doi:10.1016/j.engappai.2022.104743>. \n    Includes educational datasets highlighting different clustering challenges, based on \n    'scikit-learn' examples (Pedregosa et al., 2011) \n    <https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html>. Features detailed \n    algorithm explanations, visualizations, and weighted distance calculations for \n    enhanced learning.",
    "version": "1.0.1",
    "maintainer": "Andriy Protsak Protsak <andriy.protsak@edu.uah.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7866,
    "package_name": "VBTree",
    "title": "Vector Binary Tree to Make Your Data Management More Efficient",
    "description": "Vector binary tree provides a new data structure, to\n make your data visiting and management more efficient. If the\n data has structured column names, it can read these names and\n factorize them through specific split pattern, then build the mappings\n within double list, vector binary tree, array and tensor mutually, through\n which the batched data processing is achievable easily. The methods of\n array and tensor are also applicable. Detailed methods are described in\n Chen Zhang et al. (2020) <doi:10.35566/isdsa2019c8>.",
    "version": "0.1.1",
    "maintainer": "Chen Zhang <chen.zhang_06sept@foxmail.com>",
    "url": "https://github.com/CubicZebra/VBTree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7869,
    "package_name": "VBphenoR",
    "title": "Variational Bayes for Latent Patient Phenotypes in EHR",
    "description": "Identification of Latent Patient Phenotype from Electronic Health Records (EHR) Data using Variational Bayes Gaussian Mixture Model for Latent Class Analysis and Variational Bayes regression for Biomarker level shifts, both implemented by Coordinate Ascent Variational Inference algorithms.  Variational methods are used to enable Bayesian analysis of very large Electronic Health Records data. For VB GMM details see Bishop (2006,ISBN:9780-387-31073-2). For Logistic VB see Jaakkola and Jordan (2000) <doi:10.1023/A:1008932416310>. Please see preprint of JSS-submitted paper <doi:10.48550/arXiv.2512.14272>.",
    "version": "1.1.0",
    "maintainer": "Brian Buckley <brian.buckley.1@ucdconnect.ie>",
    "url": "https://github.com/buckleybrian/VBphenoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7908,
    "package_name": "VWPre",
    "title": "Tools for Preprocessing Visual World Data",
    "description": "Gaze data from the Visual World Paradigm requires significant\n    preprocessing prior to plotting and analyzing the data. This package \n    provides functions for preparing visual world eye-tracking data for \n    statistical analysis and plotting. It can prepare data for linear \n    analyses (e.g., ANOVA, Gaussian-family LMER, Gaussian-family GAMM) as\n    well as logistic analyses (e.g., binomial-family LMER and binomial-family GAMM).\n    Additionally, it contains various plotting functions for creating grand average and\n    conditional average plots. See the vignette for samples of the functionality.\n    Currently, the functions in this package are designed for handling data\n    collected with SR Research Eyelink eye trackers using Sample Reports created\n    in SR Research Data Viewer.  While we would like to add functionality \n    for data collected with other systems in the future, the current package is \n    considered to be feature-complete; further updates will mainly entail maintenance\n\tand the addition of minor functionality.",
    "version": "1.2.5",
    "maintainer": "Vincent Porretta <vincentporretta@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7955,
    "package_name": "VoxR",
    "title": "Trees Geometry and Morphology from Unstructured TLS Data",
    "description": "Tools for 3D point cloud voxelisation, projection, geometrical and morphological description of trees (DBH, height, volume, crown diameter), analyses of temporal changes between different measurement times, distance based clustering and visualisation of 3D voxel clouds and 2D projection. Most analyses and algorithms provided in the package are based on the concept of space exploration and are described in Lecigne et al. (2018, <doi:10.1093/aob/mcx095>).",
    "version": "1.0.0",
    "maintainer": "Bastien Lecigne <lecignebastien@gmail.com>",
    "url": "https://github.com/Blecigne/VoxR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7975,
    "package_name": "WEGE",
    "title": "A Metric to Rank Locations for Biodiversity Conservation",
    "description": "Calculates the WEGE (Weighted Endemism including Global \n    Endangerment index) index for a particular area. Additionally it also \n    calculates rasters of KBA's (Key Biodiversity Area) criteria (A1a, A1b, A1e, \n    and B1), Weighted endemism (WE), the EDGE (Evolutionarily Distinct and\n    Globally Endangered) score, Evolutionary Distinctiveness (ED) and Extinction\n    risk (ER). Farooq, H., Azevedo, J., Belluardo F., Nanvonamuquitxo, C.,\n    Bennett, D., Moat, J., Soares, A., Faurby, S. & Antonelli, A. (2020)\n    <doi:10.1101/2020.01.17.910299>.",
    "version": "0.1.0",
    "maintainer": "Harith Farooq <harithmorgadinho@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7982,
    "package_name": "WLogit",
    "title": "Variable Selection in High-Dimensional Logistic Regression\nModels using a Whitening Approach",
    "description": "It proposes a novel variable selection approach in classification problem that takes into account the correlations that may exist between the predictors of the design matrix in a high-dimensional logistic model. Our approach consists in rewriting the initial high-dimensional logistic model to remove the correlation between the predictors and in applying the generalized Lasso criterion.",
    "version": "2.1",
    "maintainer": "Wencan Zhu <wencan.zhu@yahoo.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 7989,
    "package_name": "WQM",
    "title": "Wavelet-Based Quantile Mapping for Postprocessing Numerical\nWeather Predictions",
    "description": "The wavelet-based quantile mapping (WQM) technique is designed to correct biases in spatio-temporal precipitation forecasts across multiple time scales. The WQM method effectively enhances forecast accuracy by generating an ensemble of precipitation forecasts that account for uncertainties in the prediction process. For a comprehensive overview of the methodologies employed in this package, please refer to Jiang, Z., and Johnson, F. (2023) <doi:10.1029/2022EF003350>. The package relies on two packages for continuous wavelet transforms: 'WaveletComp', which can be installed automatically, and 'wmtsa', which is optional and available from the CRAN archive <https://cran.r-project.org/src/contrib/Archive/wmtsa/>. Users need to manually install 'wmtsa' from this archive if they prefer to use 'wmtsa' based decomposition.",
    "version": "0.1.4",
    "maintainer": "Ze Jiang <ze.jiang@unsw.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8004,
    "package_name": "WaveSampling",
    "title": "Weakly Associated Vectors (WAVE) Sampling",
    "description": "Spatial data are generally auto-correlated, meaning that if two \n  units selected are close to each other, then it is likely that they share the\n  same properties. For this reason, when sampling in the population it is often\n  needed that the sample is well spread over space. A new method to draw a sample\n  from a population with spatial coordinates is proposed. This method is called\n  wave (Weakly Associated Vectors) sampling. It uses the less correlated vector\n  to a spatial weights matrix to update the inclusion probabilities vector\n  into a sample. For more details see Raphaël Jauslin and Yves Tillé (2019) <doi:10.1007/s13253-020-00407-1>.",
    "version": "0.1.4",
    "maintainer": "Raphaël Jauslin <raphael.jauslin@bfs.admin.ch>",
    "url": "https://github.com/RJauslin/WaveSampling",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8020,
    "package_name": "Waypoint",
    "title": "Convert, Validate, Format and Print Geographic Coordinates and\nWaypoints",
    "description": "Convert, validate, format and elegantly print geographic coordinates and waypoints\n   (paired latitude and longitude values) in decimal degrees, degrees and minutes, and degrees,\n   minutes and seconds using high performance C++ code to enable rapid conversion and formatting\n   of large coordinate and waypoint datasets.",
    "version": "1.2.1",
    "maintainer": "Mark Eisler <mark.eisler@bristol.ac.uk>",
    "url": "https://mark-eis.github.io/Waypoint/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8026,
    "package_name": "WebPower",
    "title": "Basic and Advanced Statistical Power Analysis",
    "description": "This is a collection of tools for conducting both basic and advanced statistical power analysis including correlation, proportion, t-test, one-way ANOVA, two-way ANOVA, linear regression, logistic regression, Poisson regression, mediation analysis, longitudinal data analysis, structural equation modeling and multilevel modeling. It also serves as the engine for conducting power analysis online at <https://webpower.psychstat.org>.",
    "version": "0.9.4",
    "maintainer": "Zhiyong Zhang <johnnyzhz@gmail.com>",
    "url": "https://webpower.psychstat.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8039,
    "package_name": "WeightedTreemaps",
    "title": "Generate and Plot Voronoi or Sunburst Treemaps from Hierarchical\nData",
    "description": "Treemaps are a visually appealing graphical representation of\n    numerical data using a space-filling approach. A plane or 'map' is\n    subdivided into smaller areas called cells.  The cells in the map are\n    scaled according to an underlying metric which allows to grasp the\n    hierarchical organization and relative importance of many objects at\n    once. This package contains two different implementations of treemaps,\n    Voronoi treemaps and Sunburst treemaps.  The Voronoi treemap function\n    subdivides the plot area in polygonal cells according to the highest\n    hierarchical level, then continues to subdivide those parental cells\n    on the next lower hierarchical level, and so on. The Sunburst treemap\n    is a computationally less demanding treemap that does not require\n    iterative refinement, but simply generates circle sectors that are\n    sized according to predefined weights.  The Voronoi tesselation is\n    based on functions from Paul Murrell (2012)\n    <https://www.stat.auckland.ac.nz/~paul/Reports/VoronoiTreemap/voronoiTreeMap.html>.",
    "version": "0.1.4",
    "maintainer": "Michael Jahn <jahn@mpusp.mpg.de>",
    "url": "https://github.com/m-jahn/WeightedTreemaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8043,
    "package_name": "WhiteStripe",
    "title": "White Matter Normalization for Magnetic Resonance Images",
    "description": "Shinohara (2014) <doi:10.1016/j.nicl.2014.08.008>\n    introduced 'WhiteStripe', an intensity-based normalization of T1 \n    and T2 images, where normal \n    appearing white matter performs well, but requires segmentation.\n    This method performs white matter mean and standard deviation\n    estimates on data that has been rigidly-registered to the 'MNI'\n    template and uses histogram-based methods.",
    "version": "2.5.0",
    "maintainer": "John Muschelli <muschellij2@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8051,
    "package_name": "WoodburyMatrix",
    "title": "Fast Matrix Operations via the Woodbury Matrix Identity",
    "description": "A hierarchy of classes and methods for manipulating matrices formed implicitly from the sums of the inverses of other matrices, a situation commonly encountered in spatial statistics and related fields. Enables easy use of the Woodbury matrix identity and the matrix determinant lemma to allow computation (e.g., solving linear systems) without having to form the actual matrix. More information on the underlying linear algebra can be found in Harville, D. A. (1997) <doi:10.1007/b98818>.",
    "version": "0.0.4",
    "maintainer": "Michael Bertolacci <m.bertolacci@gmail.com>",
    "url": "https://github.com/mbertolacci/WoodburyMatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8057,
    "package_name": "WorldMapR",
    "title": "Worldwide or Coordinates-Based Heat Maps",
    "description": "Easily plot heat maps of the world, based on continuous or categorical data. Country labels can also be added to the map. ",
    "version": "1.3.0",
    "maintainer": "Luigi Annicchiarico <luigi.annic@gmail.com>",
    "url": "https://github.com/Luigi-Annic/WorldMapR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8134,
    "package_name": "aPCoA",
    "title": "Covariate Adjusted PCoA Plot",
    "description": "In fields such as ecology, microbiology, and genomics, non-Euclidean distances are widely applied to describe pairwise dissimilarity between samples. Given these pairwise distances, principal coordinates analysis (PCoA) is commonly used to construct a visualization of the data. However, confounding covariates can make patterns related to the scientific question of interest difficult to observe. We provide 'aPCoA' as an easy-to-use tool to improve data visualization in this context, enabling enhanced presentation of the effects of interest. Details are described in Yushu Shi, Liangliang Zhang, Kim-Anh Do, Christine Peterson and Robert Jenq (2020) Bioinformatics, Volume 36, Issue 13, 4099-4101.",
    "version": "1.3",
    "maintainer": "Yushu Shi <shiyushu2006@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8164,
    "package_name": "abms",
    "title": "Augmented Bayesian Model Selection for Regression Models",
    "description": "Tools to perform model selection alongside estimation under Linear, Logistic, Negative binomial, Quantile, and Skew-Normal regression. Under the spike-and-slab method, a probability for each possible model is estimated with the posterior mean, credibility interval, and standard deviation of coefficients and parameters under the most probable model.",
    "version": "0.2",
    "maintainer": "Francisco Segovia <fasegovia@uc.cl>",
    "url": "https://github.com/SirCornflake/BMS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8191,
    "package_name": "acdcR",
    "title": "Agro-Climatic Data by County",
    "description": "The functions are designed to calculate the most widely-used county-level variables in \n  agricultural production or agricultural-climatic and weather analyses. To operate some functions \n  in this package needs download of the bulk PRISM raster. See the examples, testing versions and \n  more details from: <https://github.com/ysd2004/acdcR>.",
    "version": "1.0.0",
    "maintainer": "Seong D. Yun <seong.yun@msstate.edu>",
    "url": "https://github.com/ysd2004/acdcR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8202,
    "package_name": "aclhs",
    "title": "Autocorrelated Conditioned Latin Hypercube Sampling",
    "description": "Implementation of the autocorrelated conditioned Latin\n    Hypercube Sampling (acLHS) algorithm for 1D (time-series) and 2D (spatial)\n    data. The acLHS algorithm is an extension of the conditioned Latin Hypercube \n    Sampling (cLHS) algorithm that allows sampled data to have similar \n    correlative and statistical features of the original data. Only a properly \n    formatted dataframe needs to be provided to yield subsample indices from \n    the primary function. For more details about the cLHS algorithm, see Minasny\n    and McBratney (2006), <doi:10.1016/j.cageo.2005.12.009>. For acLHS, see Le \n    and Vargas (2024) <doi:10.1016/j.cageo.2024.105539>.",
    "version": "1.0.1",
    "maintainer": "Gabriel Laboy <glaboy1@asu.edu>",
    "url": "https://github.com/vargaslab/acLHS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8233,
    "package_name": "ada",
    "title": "The R Package Ada for Stochastic Boosting",
    "description": "Performs discrete, real, and gentle boost under both exponential and \n             logistic loss on a given data set.  The package ada provides a straightforward, \n             well-documented, and broad boosting routine for classification, ideally suited \n             for small to moderate-sized data sets.",
    "version": "2.0-5",
    "maintainer": "Mark Culp <mvculp@mail.wvu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8271,
    "package_name": "ade4",
    "title": "Analysis of Ecological Data: Exploratory and Euclidean Methods\nin Environmental Sciences",
    "description": "Tools for multivariate data analysis. Several methods are provided for the analysis (i.e., ordination) of one-table (e.g., principal component analysis, correspondence analysis), two-table (e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ analysis) and K-table (e.g., STATIS, multiple coinertia analysis). The philosophy of the package is described in Dray and Dufour (2007) <doi:10.18637/jss.v022.i04>.",
    "version": "1.7-23",
    "maintainer": "Aurélie Siberchicot <aurelie.siberchicot@univ-lyon1.fr>",
    "url": "https://adeverse.github.io/ade4/, http://pbil.univ-lyon1.fr/ADE-4/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8276,
    "package_name": "adehabitatHR",
    "title": "Home Range Estimation",
    "description": "A collection of tools for the estimation of animals home range.",
    "version": "0.4.22",
    "maintainer": "Clement Calenge <clement.calenge@ofb.gouv.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8277,
    "package_name": "adehabitatHS",
    "title": "Analysis of Habitat Selection by Animals",
    "description": "A collection of tools for the analysis of habitat selection.",
    "version": "0.3.18",
    "maintainer": "Clement Calenge <clement.calenge@ofb.gouv.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8278,
    "package_name": "adehabitatLT",
    "title": "Analysis of Animal Movements",
    "description": "A collection of tools for the analysis of animal movements.",
    "version": "0.3.29",
    "maintainer": "Clement Calenge <clement.calenge@ofb.gouv.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8279,
    "package_name": "adehabitatMA",
    "title": "Tools to Deal with Raster Maps",
    "description": "A collection of tools to deal with raster maps.",
    "version": "0.3.17",
    "maintainer": "Clement Calenge <clement.calenge@ofb.gouv.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8285,
    "package_name": "adespatial",
    "title": "Multivariate Multiscale Spatial Analysis",
    "description": "Tools for the multiscale spatial analysis of multivariate data.\n    Several methods are based on the use of a spatial weighting matrix and its\n    eigenvector decomposition (Moran's Eigenvectors Maps, MEM). \n    Several approaches are described in the review Dray et al (2012)\n    <doi:10.1890/11-1183.1>.",
    "version": "0.3-28",
    "maintainer": "Aurélie Siberchicot <aurelie.siberchicot@univ-lyon1.fr>",
    "url": "https://github.com/adeverse/adespatial,\nhttp://adeverse.github.io/adespatial/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8324,
    "package_name": "adventr",
    "title": "Interactive R Tutorials to Accompany Field (2016), \"An Adventure\nin Statistics\"",
    "description": "Interactive 'R' tutorials written using 'learnr' for Field (2016), \"An Adventure in Statistics\", <ISBN:9781446210451>.\n    Topics include general workflow in 'R' and 'Rstudio', the 'R' environment and 'tidyverse', summarizing data, model fitting, central tendency, \n    visualising data using 'ggplot2', inferential statistics and robust estimation, hypothesis testing, the general linear model, comparing means,\n    repeated measures designs, factorial designs, multilevel models, growth models, and generalized linear models (logistic regression).",
    "version": "0.1.8",
    "maintainer": "Andy Field <andyf@sussex.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8341,
    "package_name": "affinity",
    "title": "Raster Georeferencing, Grid Affine Transforms, Cell Abstraction",
    "description": "Tools for raster georeferencing, grid affine transforms, and general raster logic. \n These functions provide converters between raster specifications, world vector, geotransform, \n 'RasterIO' window, and 'RasterIO window' in 'sf' package list format. There are functions to offset\n a matrix by padding any of four corners (useful for vectorizing neighbourhood operations), and\n helper functions to harvesting user clicks on a graphics device to use for simple georeferencing\n of images.  Methods used are available from <https://en.wikipedia.org/wiki/World_file> and\n <https://gdal.org/user/raster_data_model.html>. ",
    "version": "0.2.5",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/affinity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8343,
    "package_name": "affluenceIndex",
    "title": "Affluence (Richness) Indices",
    "description": "Enables to compute the statistical indices of affluence (richness) with bootstrap errors, and inequality and polarization indices. Moreover, gives the possibility of calculation of affluence line. Some simple errors are fixed and it works with new version of Spatial Statistics packaged.",
    "version": "2.2",
    "maintainer": "Alicja Wolny-Dominiak <alicja.wolny-dominiak@ue.katowice.pl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8357,
    "package_name": "afrilearnr",
    "title": "Tutorials on spatial data in R using African data",
    "description": "Tutorials to introduce spatial data manipulation in R using African data.",
    "version": "0.0.0.9006",
    "maintainer": "",
    "url": "https://github.com/afrimapr/afrilearnr",
    "exports": [],
    "topics": ["africa", "gis", "learnr", "r", "rspatial", "rstats"],
    "score": "NA",
    "stars": 6
  },
  {
    "id": 8388,
    "package_name": "agriwater",
    "title": "Evapotranspiration and Energy Fluxes Spatial Analysis",
    "description": "Spatial modeling of energy balance and actual \n    evapotranspiration using satellite images and meteorological data. \n    Options of satellite are: Landsat-8 (with and without thermal bands), \n    Sentinel-2 and MODIS. Respectively spatial resolutions are 30, 100, \n    10 and 250 meters. User can use data from a single meteorological \n    station or a grid of meteorological stations (using any spatial \n    interpolation method). Silva, Teixeira, and Manzione (2019) <doi:10.1016/j.envsoft.2019.104497>.",
    "version": "1.0.2",
    "maintainer": "Cesar de Oliveira Ferreira Silva <cesaroliveira.f.silva@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8406,
    "package_name": "aimsir17",
    "title": "Irish Weather Observing Stations Hourly Records for 2017",
    "description": "Named after the Irish name for weather, this package contains \n    tidied data from the Irish Meteorological Service's hourly observations for 2017. \n    In all, the data sets include observations from 25 weather stations, and also\n    latitude and longitude coordinates for each weather station. Now includes energy \n    generation data for Ireland and Northern Ireland (2017), including Wind Generation data.",
    "version": "0.0.2",
    "maintainer": "Jim Duggan <jim.duggan@nuigalway.ie>",
    "url": "https://github.com/JimDuggan/aimsir17, https://www.met.ie,\nhttp://www.eirgridgroup.com/how-the-grid-works/renewables/,\nhttp://www.eirgridgroup.com/site-files/library/EirGrid/SNSP-Formula-External-Publication.pdf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8427,
    "package_name": "akgfmaps",
    "title": "Alaska Groundfish, Crab, and Ecosystem Survey Area Mapping",
    "description": "Functions and vector geometry layers ('shapefiles') for making maps and conducting spatial analyses in Alaska marine regions.",
    "version": "4.2.1",
    "maintainer": "Sean Rohan <sean.rohan@noaa.gov>",
    "url": "https://github.com/afsc-gap-products/akgfmaps",
    "exports": [],
    "topics": ["shapefiles", "spatial-analysis"],
    "score": "NA",
    "stars": 19
  },
  {
    "id": 8450,
    "package_name": "alcyon",
    "title": "Spatial Network Analysis",
    "description": "Interface package for 'sala', the spatial network analysis library\n    from the 'depthmapX' software application. The R parts of the code are based\n    on the 'rdepthmap' package. Allows for the analysis of urban and\n    building-scale networks and provides metrics and methods usually found\n    within the Space Syntax domain. Methods in this package are described by K.\n    Al-Sayed, A. Turner, B. Hillier, S. Iida and A. Penn (2014) \"Space Syntax\n    methodology\", and also by A. Turner (2004)\n    <https://discovery.ucl.ac.uk/id/eprint/2651> \"Depthmap 4: a researcher's\n    handbook\".",
    "version": "0.8.1",
    "maintainer": "Petros Koutsolampros <r-devel@pklampros.net>",
    "url": "https://github.com/spatialnous/alcyon,\nhttps://spatialnous.github.io/alcyon/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8503,
    "package_name": "amadeus",
    "title": "Accessing and Analyzing Large-Scale Environmental Data",
    "description": "Functions are designed to facilitate access to and utility with large scale, publicly available environmental data in R. The package contains functions for downloading raw data files from web URLs (download_data()), processing the raw data files into clean spatial objects (process_covariates()), and extracting values from the spatial data objects at point and polygon locations (calculate_covariates()). These functions call a series of source-specific functions which are tailored to each data sources/datasets particular URL structure, data format, and spatial/temporal resolution. The functions are tested, versioned, and open source and open access. For sum_edc() method details, see Messier, Akita, and Serre (2012) <doi:10.1021/es203152a>.",
    "version": "1.2.4.9",
    "maintainer": "Kyle Messier <kyle.messier@nih.gov>",
    "url": "https://niehs.github.io/amadeus/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8567,
    "package_name": "annotator",
    "title": "Image Annotation and Polygon Outlining using Free Drawing",
    "description": "Provides functions to create image annotations through polygon outlining. Annotator has the same function as 'graphics::locator()' but achieves its purpose through drawing, rather than multiple mouse clicks. It is based on the 'htmlwidgets' package and 'fabric.js' JavaScript library <https://fabricjs.com/>. ",
    "version": "0.0.3.2",
    "maintainer": "Mihai Valcu <mvalcu@gwdg.de>",
    "url": "https://github.com/valcu/annotator",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8600,
    "package_name": "aopdata",
    "title": "Data from the 'Access to Opportunities Project (AOP)'",
    "description": "Download data from the 'Access to Opportunities Project (AOP)'. The \n             'aopdata' package brings annual estimates of access to employment, \n             health, education and social assistance services by transport mode, \n             as well as data  on the spatial distribution of population, jobs, \n             health care, schools and social assistance facilities at a fine \n             spatial resolution for all cities included in the project. More \n             info on the 'AOP' website <https://www.ipea.gov.br/acessooportunidades/en/>.",
    "version": "1.1.2",
    "maintainer": "Rafael H. M. Pereira <rafa.pereira.br@gmail.com>",
    "url": "https://ipeagit.github.io/aopdata/,\nhttps://github.com/ipeaGIT/aopdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8612,
    "package_name": "apcf",
    "title": "Adapted Pair Correlation Function",
    "description": "The adapted pair correlation function transfers the concept of the\n  pair correlation function from point patterns to patterns of objects of\n  finite size and irregular shape (e.g. lakes within a country).  The pair\n  correlation function describes the spatial distribution of objects, e.g.\n  random, aggregated or regularly spaced. This is a reimplementation of the\n  method suggested by Nuske et al. (2009) <doi:10.1016/j.foreco.2009.09.050>\n  using the library 'GEOS' <doi:10.5281/zenodo.11396894>. ",
    "version": "0.3.3",
    "maintainer": "Robert Nuske <robert.nuske@mailbox.org>",
    "url": "https://rnuske.github.io/apcf/, https://github.com/rnuske/apcf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8625,
    "package_name": "aplore3",
    "title": "Datasets from Hosmer, Lemeshow and Sturdivant, \"Applied Logistic\nRegression\" (3rd Ed., 2013)",
    "description": "An unofficial companion to \"Applied\n    Logistic Regression\" by D.W. Hosmer, S. Lemeshow and\n    R.X. Sturdivant (3rd ed., 2013) containing the dataset used in the book.",
    "version": "0.9",
    "maintainer": "Luca Braglia <lbraglia@gmail.com>",
    "url": "https://github.com/lbraglia/aplore3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8639,
    "package_name": "apportion",
    "title": "Apportion Seats",
    "description": "Convert populations into integer number of seats for legislative \n    bodies. Implements apportionment methods used historically and currently in the\n    United States for reapportionment after the Census, as described in \n    <https://www.census.gov/history/www/reference/apportionment/methods_of_apportionment.html>. ",
    "version": "0.0.2",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/christopherkenny/apportion,\nhttp://christophertkenny.com/apportion/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8657,
    "package_name": "arakno",
    "title": "ARAchnid KNowledge Online",
    "description": "Allows the user to connect with the World Spider Catalogue (WSC; <https://wsc.nmbe.ch/>) and the World Spider Trait (WST; <https://spidertraits.sci.muni.cz/>) databases. Also performs several basic functions such as checking names validity, retrieving coordinate data from the Global Biodiversity Information Facility (GBIF; <https://www.gbif.org/>), and mapping.",
    "version": "1.3.1",
    "maintainer": "Pedro Cardoso <pmcardoso@ciencias.ulisboa.pt>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8658,
    "package_name": "aramappings",
    "title": "Computes Adaptable Radial Axes Mappings",
    "description": "Computes low-dimensional point representations of high-dimensional numerical data according to the data visualization method Adaptable Radial Axes described in: Manuel Rubio-Sánchez, Alberto Sanchez, and Dirk J. Lehmann (2017) \"Adaptable radial axes plots for improved multivariate data visualization\" <doi:10.1111/cgf.13196>.",
    "version": "0.1.2",
    "maintainer": "Manuel Rubio-Sánchez <manuel.rubio@urjc.es>",
    "url": "https://github.com/manuelrubio/aramappings,\nhttps://manuelrubio.github.io/aramappings/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8662,
    "package_name": "arcgis",
    "title": "ArcGIS Location Services Meta-Package",
    "description": "Provides easy installation and loading of core ArcGIS\n    location services packages 'arcgislayers', 'arcgisutils',\n    'arcgisgeocode', and 'arcgisplaces'. Enabling developers to interact\n    with spatial data and services from 'ArcGIS Online', 'ArcGIS\n    Enterprise', and 'ArcGIS Platform'. Learn more about the 'arcgis'\n    meta-package at <https://developers.arcgis.com/r-bridge/>.",
    "version": "0.2.0",
    "maintainer": "Josiah Parry <josiah.parry@gmail.com>",
    "url": "https://github.com/R-ArcGIS/arcgis/,\nhttps://developers.arcgis.com/r-bridge/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8663,
    "package_name": "arcgisgeocode",
    "title": "A Robust Interface to ArcGIS 'Geocoding Services'",
    "description": "A very fast and robust interface to ArcGIS 'Geocoding\n    Services'. Provides capabilities for reverse geocoding, finding\n    address candidates, character-by-character search autosuggestion, and\n    batch geocoding. The public 'ArcGIS World Geocoder' is accessible for\n    free use via 'arcgisgeocode' for all services except batch geocoding.\n    'arcgisgeocode' also integrates with 'arcgisutils' to provide access\n    to custom locators or private 'ArcGIS World Geocoder' hosted on\n    'ArcGIS Enterprise'. Learn more in the 'Geocode service' API reference\n    <https://developers.arcgis.com/rest/geocode/api-reference/overview-world-geocoding-service.htm>.",
    "version": "0.4.0",
    "maintainer": "Josiah Parry <josiah.parry@gmail.com>",
    "url": "https://github.com/r-arcgis/arcgisgeocode,\nhttps://developers.arcgis.com/r-bridge/api-reference/arcgisgeocode",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8665,
    "package_name": "arcgisplaces",
    "title": "Search for POIs using ArcGIS 'Places Service'",
    "description": "The ArcGIS 'Places service' is a ready-to-use location",
    "version": "0.1.2",
    "maintainer": "",
    "url": "https://github.com/R-ArcGIS/arcgisplaces",
    "exports": [],
    "topics": ["arcgis", "esri", "location-services", "poi", "r-spatial", "rstats"],
    "score": "NA",
    "stars": 13
  },
  {
    "id": 8666,
    "package_name": "arcgisutils",
    "title": "R-ArcGIS Bridge Utility Functions",
    "description": "Developer oriented utility functions designed to be used as",
    "version": "0.4.0.9001",
    "maintainer": "",
    "url": "https://github.com/R-ArcGIS/arcgisutils",
    "exports": [],
    "topics": ["arcgis", "r-spatial", "rstats"],
    "score": "NA",
    "stars": 20
  },
  {
    "id": 8670,
    "package_name": "archeofrag.gui",
    "title": "Spatial Analysis in Archaeology from Refitting Fragments (GUI)",
    "description": "A 'Shiny' application to access the functionalities and datasets of the 'archeofrag' package for spatial analysis in archaeology from refitting data. Quick and seamless exploration of archaeological refitting datasets, focusing on physical refits only. Features include: built-in documentation and convenient workflow, plot generation and exports, exploration of spatial units merging solutions, simulation of archaeological site formation processes, support for parallel computing, R code generation to re-execute simulations and ensure reproducibility, code generation for the 'openMOLE' model exploration software. A demonstration of the app is available at <https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/>.",
    "version": "1.1.0",
    "maintainer": "Sebastien Plutniak <sebastien.plutniak@posteo.net>",
    "url": "https://github.com/sebastien-plutniak/archeofrag.gui",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8679,
    "package_name": "arcpbf",
    "title": "Process ArcGIS Protocol Buffer FeatureCollections",
    "description": "Fast processing of ArcGIS FeatureCollection protocol buffers in R.\n  It is designed to work seamlessly with 'httr2' and integrates with 'sf'. ",
    "version": "0.2.0",
    "maintainer": "Josiah Parry <josiah.parry@gmail.com>",
    "url": "https://r.esri.com/arcpbf/, https://github.com/R-ArcGIS/arcpbf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8680,
    "package_name": "arcpullr",
    "title": "Pull Data from an 'ArcGIS REST' API",
    "description": "\n  Functions to efficiently query 'ArcGIS REST' APIs \n  <https://developers.arcgis.com/rest/>. \n  Both spatial and SQL queries can be used to retrieve data. \n  Simple Feature (sf) objects are utilized to perform spatial queries. \n  This package was neither produced nor is maintained by Esri.",
    "version": "0.3.2",
    "maintainer": "Paul Frater <paul.frater@wisconsin.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8681,
    "package_name": "arcpy",
    "title": "Interface to 'ArcGIS' 'Python' Modules",
    "description": "An interface to the 'ArcGIS' 'arcpy' and 'arcgis' 'python' API\n    <https://pro.arcgis.com/en/pro-app/latest/arcpy/get-started/arcgis-api-for-python.htm>.\n    Provides various tools for installing and configuring a 'Conda' environment\n    for accessing 'ArcGIS' geoprocessing functions. Helper functions for\n    manipulating and converting 'ArcGIS' objects from R are also provided.",
    "version": "0.4-0",
    "maintainer": "Michael Koohafkan <michael.koohafkan@gmail.com>",
    "url": "https://github.com/mkoohafkan/arcpy,\nhttps://hydroecology.net/arcpy/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8685,
    "package_name": "area",
    "title": "Calculate Area of Triangles and Polygons",
    "description": "Calculate the area of triangles and polygons using the shoelace \n formula. Area may be signed, taking into account path orientation, or unsigned, \n ignoring path orientation. The shoelace formula is described at \n <https://en.wikipedia.org/wiki/Shoelace_formula>. ",
    "version": "0.2.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/area",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8687,
    "package_name": "areal",
    "title": "Areal Weighted Interpolation",
    "description": "A pipeable, transparent implementation of areal weighted interpolation\n    with support for interpolating multiple variables in a single function call.\n    These tools provide a full-featured workflow for validation and estimation\n    that fits into both modern data management (e.g. tidyverse) and spatial \n    data (e.g. sf) frameworks.",
    "version": "0.1.8",
    "maintainer": "Christopher Prener <chris.prener@gmail.com>",
    "url": "https://chris-prener.github.io/areal/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8688,
    "package_name": "arealDB",
    "title": "Harmonise and Integrate Heterogeneous Areal Data",
    "description": "Many relevant applications in the environmental and socioeconomic \n    sciences use areal data, such as biodiversity checklists, agricultural statistics, \n    or socioeconomic surveys. For applications that surpass the spatial, temporal or \n    thematic scope of any single data source, data must be integrated from several \n    heterogeneous sources. Inconsistent concepts, definitions, or messy data tables \n    make this a tedious and error-prone process. 'arealDB' tackles those problems and \n    helps the user to integrate a harmonised databases of areal data. Read the paper\n    at Ehrmann, Seppelt & Meyer (2020) <doi:10.1016/j.envsoft.2020.104799>.",
    "version": "0.9.4",
    "maintainer": "Steffen Ehrmann <steffen.ehrmann@posteo.de>",
    "url": "https://github.com/luckinet/arealDB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8689,
    "package_name": "areaplot",
    "title": "Plot Stacked Areas and Confidence Bands as Filled Polygons",
    "description": "Plot stacked areas and confidence bands as filled polygons, or add\n  polygons to existing plots. A variety of input formats are supported,\n  including vectors, matrices, data frames, formulas, etc.",
    "version": "2.1.3",
    "maintainer": "Arni Magnusson <thisisarni@gmail.com>",
    "url": "https://github.com/arni-magnusson/areaplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8728,
    "package_name": "arse",
    "title": "Area of Resilience to Stress Event",
    "description": "A method for quantifying resilience after a stress event. A set of functions\n    calculate the area of resilience that is created by the departure of baseline \n    'y' (i.e., robustness) and the time taken 'x' to return to baseline \n    (i.e., rapidity) after a stress event using the Cartesian coordinates of the \n    data. This package has the capability to calculate areas of resilience,\n    growth, and cases in which resilience is not achieved \n    (e.g., diminished performance without return to baseline).",
    "version": "1.0.0",
    "maintainer": "Nathaniel Ratcliff <nr3xe@virginia.edu>",
    "url": "https://github.com/nr3xe/arse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8761,
    "package_name": "asnipe",
    "title": "Animal Social Network Inference and Permutations for Ecologists",
    "description": "Implements several tools that are used in animal social network analysis, as described in Whitehead (2007) Analyzing Animal Societies <University of Chicago Press> and Farine & Whitehead (2015) <doi: 10.1111/1365-2656.12418>. In particular, this package provides the tools to infer groups and generate networks from observation data, perform permutation tests on the data, calculate lagged association rates, and performed multiple regression analysis on social network data.",
    "version": "1.1.17",
    "maintainer": "Damien R. Farine <dfarine@ab.mpg.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8762,
    "package_name": "aspace",
    "title": "Functions for Estimating Centrographic Statistics",
    "description": "A collection of functions for computing centrographic\n        statistics (e.g., standard distance, standard deviation\n        ellipse, standard deviation box) for observations taken at\n        point locations. Separate plotting functions have been\n        developed for each measure. Users interested in writing results\n        to ESRI shapefiles can do so by using results from 'aspace'\n        functions as inputs to the convert.to.shapefile() and\n        write.shapefile() functions in the 'shapefiles' library. We intend to\n        provide 'terra' integration for geographic data in a future release.\n        The 'aspace' package was originally conceived to aid in the analysis of\n        spatial patterns of travel behaviour (see Buliung and Remmel 2008\n        <doi:10.1007/s10109-008-0063-7>).",
    "version": "4.1.2",
    "maintainer": "Tarmo K. Remmel <remmelt@yorku.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8766,
    "package_name": "asremlPlus",
    "title": "Augments 'ASReml-R' in Fitting Mixed Models and Packages\nGenerally in Exploring Prediction Differences",
    "description": "Assists in automating the selection of terms to include in mixed models when  \n  'asreml' is used to fit the models. Procedures are available for choosing models that \n  conform to the hierarchy or marginality principle, for fitting and choosing between \n  two-dimensional spatial models using correlation, natural cubic smoothing spline and \n  P-spline models. A history of the fitting of a sequence of models is kept in a data frame. \n  Also used to compute functions and contrasts of, to investigate differences between and \n  to plot predictions obtained using any model fitting function. The content  falls into \n  the following natural groupings: (i) Data, (ii) Model modification functions, (iii) Model \n  selection and description functions, (iv) Model diagnostics and simulation functions, \n  (v) Prediction production and presentation functions, (vi) Response transformation \n  functions, (vii) Object manipulation functions, and (viii) Miscellaneous functions \n  (for further details see 'asremlPlus-package' in help). The 'asreml' package provides a \n  computationally efficient algorithm for fitting a wide range of linear mixed models using \n  Residual Maximum Likelihood. It is a commercial package and a license for it can be \n  purchased from 'VSNi' <https://vsni.co.uk/> as 'asreml-R', who will supply a zip file \n  for local installation/updating (see <https://asreml.kb.vsni.co.uk/>). It is not needed \n  for functions that are methods for 'alldiffs'  and 'data.frame' objects. The package \n  'asremPlus' can also be installed from <http://chris.brien.name/rpackages/>.",
    "version": "4.4.55",
    "maintainer": "Chris Brien <chris.brien@adelaide.edu.au>",
    "url": "http://chris.brien.name",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8782,
    "package_name": "asteRisk",
    "title": "Computation of Satellite Position",
    "description": "Provides basic functionalities to calculate the position of\n    satellites given a known state vector. The package includes implementations\n    of the SGP4 and SDP4 simplified perturbation models to propagate orbital\n    state vectors, as well as utilities to read TLE files and convert coordinates\n    between different frames of reference. Several of the functionalities of the\n    package (including the high-precision numerical orbit propagator) require\n    the coefficients and data included in the 'asteRiskData' package, available\n    in a 'drat' repository. To install this data package, run \n    'install.packages(\"asteRiskData\", repos=\"https://rafael-ayala.github.io/drat/\")'.\n    Felix R. Hoots, Ronald L. Roehrich and T.S. Kelso (1988) <https://celestrak.org/NORAD/documentation/spacetrk.pdf>.\n    David Vallado, Paul Crawford, Richard Hujsak and T.S. Kelso (2012) <doi:10.2514/6.2006-6753>.\n    Felix R. Hoots, Paul W. Schumacher Jr. and Robert A. Glover (2014) <doi:10.2514/1.9161>.",
    "version": "1.4.5",
    "maintainer": "Rafael Ayala <rafaelayalahernandez@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8803,
    "package_name": "atakrig",
    "title": "Area-to-Area Kriging",
    "description": "Point-scale variogram deconvolution from irregular/regular spatial support according to Goovaerts, P., (2008) <doi: 10.1007/s11004-007-9129-1>; ordinary area-to-area (co)Kriging and area-to-point (co)Kriging.",
    "version": "0.9.8.1",
    "maintainer": "Maogui Hu <humg@lreis.ac.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8810,
    "package_name": "atpolR",
    "title": "ATPOL Grid Implementation",
    "description": "ATPOL is a rectangular grid system used for botanical studies in Poland. The ATPOL grid was developed in Institute of Botany, Jagiellonian University, Krakow, Poland in '70. Since then it is widely used to represent distribution of plants in Poland. \n    'atpolR' provides functions to translate geographic coordinates to the grid and vice versa. It also allows to create a choreograph map.",
    "version": "0.1.1",
    "maintainer": "Grzegorz Sapijaszko <grzegorz@sapijaszko.net>",
    "url": "https://github.com/gsapijaszko/atpolR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8834,
    "package_name": "aussiemaps",
    "title": "Maps of Australia",
    "description": "Granular maps of Australia using ABS boundaries from 2006-2021.",
    "version": "0.2.2.0002",
    "maintainer": "",
    "url": "https://github.com/carlosyanez/aussiemaps",
    "exports": [],
    "topics": ["australia", "maps", "r", "r-spatial", "sf-objects"],
    "score": "NA",
    "stars": 1
  },
  {
    "id": 8844,
    "package_name": "autoReg",
    "title": "Automatic Linear and Logistic Regression and Survival Analysis",
    "description": "Make summary tables for descriptive statistics and select explanatory variables \n    automatically in various regression models. Support linear models, generalized linear \n    models and cox-proportional hazard models. Generate publication-ready tables summarizing \n    result of regression analysis and plots. The tables and plots can be exported in \"HTML\", \n    \"pdf('LaTex')\", \"docx('MS Word')\" and \"pptx('MS Powerpoint')\" documents.",
    "version": "0.3.3",
    "maintainer": "Keon-Woong Moon <cardiomoon@gmail.com>",
    "url": "https://github.com/cardiomoon/autoReg,\nhttps://cardiomoon.github.io/autoReg/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8853,
    "package_name": "autoimage",
    "title": "Multiple Heat Maps for Projected Coordinates",
    "description": "Functions for displaying multiple images  or scatterplots with a color \n    scale, i.e., heat maps, possibly with projected coordinates.  The\n    package relies on the base graphics system, so graphics are\n    rendered rapidly.",
    "version": "2.2.3",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8857,
    "package_name": "automap",
    "title": "Automatic Interpolation Package",
    "description": "An automatic interpolation is done by automatically estimating the variogram and then calling gstat. An overview is given by Hiemstra et al (2008) <doi:10.1016/j.cageo.2008.10.011>.",
    "version": "1.1-20",
    "maintainer": "Jon Olav Skoien <jon.skoien@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8862,
    "package_name": "automultinomial",
    "title": "Models for Spatially Correlated Data",
    "description": "Fits the autologistic model described in Besag's famous 1974 paper on auto- models <http://www.jstor.org/stable/2984812>. Fits a multicategory generalization of the autologistic model when there are more than 2 response categories. Provides support for both asymptotic and bootstrap confidence intervals. For full model descriptions and a guide to the use of this package, please see the vignette.",
    "version": "2.0.0",
    "maintainer": "Stephen Berg <saberg2@wisc.edu>",
    "url": "https://github.com/stephenberg/automultinomial",
    "exports": [],
    "topics": ["autologistic", "automultinomial", "inference", "logistic-regression", "multinomial", "multinomial-regression", "r-package", "spatial-analysis", "spatial-data", "spatial-data-analysis", "spatial-statistics"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 8881,
    "package_name": "avidaR",
    "title": "A Computational Biologist’s Toolkit To Get Data From 'avidaDB'",
    "description": "Easy-to-use tools for performing complex queries on 'avidaDB', a\n  semantic database that stores genomic and transcriptomic data of\n  self-replicating computer programs (known as digital organisms) that mutate\n  and evolve within a user-defined computational environment.",
    "version": "1.2.1",
    "maintainer": "Raúl Ortega <raul.ortega@ebd.csic.es>",
    "url": "https://gitlab.com/fortunalab/avidaR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8904,
    "package_name": "aws.wrfsmn",
    "title": "Data Processing of SMN Hi-Res Weather Forecast from 'AWS'",
    "description": "Exploration of Weather Research & Forecasting ('WRF') Model data\n    of Servicio Meteorologico Nacional (SMN) from Amazon Web Services\n    (<https://registry.opendata.aws/smn-ar-wrf-dataset/>) cloud. The package\n    provides the possibility of data downloading, processing and correction\n    methods. It also has map management and series exploration of available\n    meteorological variables of 'WRF' forecast.",
    "version": "0.1.0",
    "maintainer": "Gonzalo Diaz <gonzalomartindiaz22@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8910,
    "package_name": "azuremapsr",
    "title": "Interface to the 'Azure Maps' API",
    "description": "Provides a wrapper for the Microsoft 'Azure Maps' REST APIs <https://learn.microsoft.com/en-us/rest/api/maps/route?view=rest-maps-2025-01-01>,\n    enabling users to access mapping and geospatial services directly from R.\n    This package simplifies authenticating, building, and sending requests for\n    services like route directions. It handles conversions between R objects\n    (such as 'sf' objects) and the GeoJSON+JSON format required by the API,\n     making it easier to integrate 'Azure Maps' into R-based data analysis workflows.",
    "version": "0.0.2",
    "maintainer": "Juan P. Fonseca-Zamora <ts18jpf@leeds.ac.uk>",
    "url": "https://github.com/juanfonsecaLS1/azuremapsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8979,
    "package_name": "bangladesh",
    "title": "Provides Ready to Use Shapefiles for Geographical Map of\nBangladesh",
    "description": "Usually, it is difficult to plot choropleth maps for Bangladesh in 'R'.\n    The 'bangladesh' package provides ready-to-use shapefiles for different administrative\n    regions of Bangladesh (e.g., Division, District, Upazila, and Union).\n    This package helps users to draw thematic maps of administrative regions\n    of Bangladesh easily as it comes with the 'sf' objects for the boundaries.\n    It also provides functions allowing users to efficiently get specific area\n    maps and center coordinates for regions. Users can also search for\n    a specific area and calculate the centroids of those areas.",
    "version": "1.0.0",
    "maintainer": "Musaddiqur Rahman Ovi <m.ovirahman@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 8991,
    "package_name": "barrks",
    "title": "Calculate Bark Beetle Phenology Using Different Models",
    "description": "Calculate the bark beetle phenology based on raster data or\n    point-related data. There are multiple models implemented for two bark\n    beetle species. The models can be customized and their submodels (onset of\n    infestation, beetle development, diapause initiation, mortality) can be\n    combined. The following models are available in the package:\n    PHENIPS-Clim (first-time release in this package),\n    PHENIPS (Baier et al. 2007) <doi:10.1016/j.foreco.2007.05.020>,\n    RITY (Ogris et al. 2019) <doi:10.1016/j.ecolmodel.2019.108775>,\n    CHAPY (Ogris et al. 2020) <doi:10.1016/j.ecolmodel.2020.109137>,\n    BSO (Jakoby et al. 2019) <doi:10.1111/gcb.14766>,\n    Lange et al. (2008) <doi:10.1007/978-3-540-85081-6_32>,\n    Jönsson et al. (2011) <doi:10.1007/s10584-011-0038-4>.\n    The package may be expanded by models for other bark beetle species in the\n    future.",
    "version": "1.1.2",
    "maintainer": "Jakob Jentschke <jakob.jentschke@forst.bwl.de>",
    "url": "https://jjentschke.github.io/barrks/,\nhttps://github.com/jjentschke/barrks/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9000,
    "package_name": "base.rms",
    "title": "Convert Regression Between Base Function and 'rms' Package",
    "description": "\n  We perform linear, logistic, and cox regression using the base functions lm(), \n    glm(), and coxph() in the R software and the 'survival' package. Likewise, we \n    can use ols(), lrm() and cph() from the 'rms' package for the same \n    functionality. Each of these two sets of commands has a different focus.\n  In many cases, we need to use both sets of commands in the same situation, \n    e.g. we need to filter the full subset model using AIC, and we need to build \n    a visualization graph for the final model. 'base.rms' package can help you to switch \n    between the two sets of commands easily.",
    "version": "1.0",
    "maintainer": "Jing Zhang <zj391120@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9010,
    "package_name": "basemaps",
    "title": "Accessing Spatial Basemaps in R",
    "description": "A lightweight package to access spatial basemaps from open sources such as 'OpenStreetMap', 'Carto', 'Mapbox' and others in R.",
    "version": "0.0.8",
    "maintainer": "Jakob Schwalb-Willmann <dev@schwalb-willmann.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9017,
    "package_name": "basf",
    "title": "Plot Simple Features with 'base' Sensibilities",
    "description": "Resurrects the standard plot for shapes established by the\n 'base' and 'graphics' packages. This is suited to workflows that require\n plotting using the established and traditional idioms of plotting spatially\n coincident data where it belongs. This package depends on 'sf' and only replaces \n the plot method. ",
    "version": "0.2.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/mdsumner/basf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9019,
    "package_name": "basicdrm",
    "title": "Fit Hill Dose Response Models",
    "description": "Evaluate, fit, and analyze Hill dose response models (Goutelle et \n    al., 2008 <doi:10.1111/j.1472-8206.2008.00633.x>), also sometimes referred\n    to as four-parameter log-logistic models.  Includes tools to invert Hill \n    models,  select models based on the Akaike information criterion\n    (Akaike, 1974 <doi:10.1109/TAC.1974.1100705>) or Bayesian information \n    criterion (Schwarz, 1978 <https://www.jstor.org/stable/2958889>), and \n    construct bootstrapped confidence intervals both\n    on the Hill model parameters and values derived from the Hill model\n    parameters.",
    "version": "0.3.2",
    "maintainer": "Nathaniel Twarog <nathaniel.twarog@stjude.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9046,
    "package_name": "bayesCureRateModel",
    "title": "Bayesian Cure Rate Modeling for Time-to-Event Data",
    "description": "A fully Bayesian approach in order to estimate a general family of cure rate models under the presence of covariates, see Papastamoulis and Milienos (2024) <doi:10.1007/s11749-024-00942-w> and Papastamoulis and Milienos (2024b) <doi:10.48550/arXiv.2409.10221>. The promotion time can be modelled (a) parametrically using typical distributional assumptions for time to event data (including the Weibull, Exponential, Gompertz, log-Logistic distributions), or (b) semiparametrically using finite mixtures of distributions. In both cases, user-defined families of distributions are allowed under some specific requirements. Posterior inference is carried out by constructing a Metropolis-coupled Markov chain Monte Carlo (MCMC) sampler, which combines Gibbs sampling for the latent cure indicators and Metropolis-Hastings steps with Langevin diffusion dynamics for parameter updates. The main MCMC algorithm is embedded within a parallel tempering scheme by considering heated versions of the target posterior distribution.",
    "version": "1.5",
    "maintainer": "Panagiotis Papastamoulis <papapast@yahoo.gr>",
    "url": "https://github.com/mqbssppe/Bayesian_cure_rate_model",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9049,
    "package_name": "bayesEO",
    "title": "Bayesian Smoothing of Remote Sensing Image Classification",
    "description": "A  Bayesian smoothing method for post-processing of remote \n    sensing image classification which refines the\n    labelling in a classified image in order to enhance its classification accuracy.\n    Combines pixel-based classification methods with a spatial post-processing\n    method to remove outliers and misclassified pixels.",
    "version": "0.2.2",
    "maintainer": "Gilberto Camara <gilberto.camara.inpe@gmail.com>",
    "url": "https://github.com/e-sensing/bayesEO/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9093,
    "package_name": "bayesreg",
    "title": "Bayesian Regression Models with Global-Local Shrinkage Priors",
    "description": "Fits linear or generalized linear regression models using Bayesian global-local shrinkage prior hierarchies as described in Polson and Scott (2010) <doi:10.1093/acprof:oso/9780199694587.003.0017>. Provides an efficient implementation of ridge, lasso, horseshoe and horseshoe+ regression with logistic, Gaussian, Laplace, Student-t, Poisson or geometric distributed targets using the algorithms summarized in Makalic and Schmidt (2016) <doi:10.48550/arXiv.1611.06649>.",
    "version": "1.3",
    "maintainer": "Daniel F. Schmidt <daniel.schmidt@monash.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9113,
    "package_name": "bbox",
    "title": "Doze Bboxes Doe",
    "description": "Doze Bboxes Doe.",
    "version": "0.0.1.9100",
    "maintainer": "",
    "url": "https://github.com/ropensci-archive/bbox",
    "exports": [],
    "topics": ["bbox", "bounding-boxes", "geojson", "geospatial", "r", "r-package", "rstats", "wkt"],
    "score": "NA",
    "stars": 9
  },
  {
    "id": 9123,
    "package_name": "bcRiverProfileR",
    "title": "Extract elevation values for a river.",
    "description": "Extract elevation values for a river.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/bcgov/bc-fwa-river-profiles",
    "exports": [],
    "topics": ["elevation", "flnr", "geospatial", "hydrology", "r"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 9128,
    "package_name": "bcdata",
    "title": "Search and Retrieve Data from the BC Data Catalogue",
    "description": "Search, query, and download tabular and\n    'geospatial' data from the British Columbia Data Catalogue\n    (<https://catalogue.data.gov.bc.ca/>).  Search catalogue data records\n    based on keywords, data licence, sector, data format, and B.C.\n    government organization. View metadata directly in R, download many\n    data formats, and query 'geospatial' data available via the B.C.\n    government Web Feature Service ('WFS') using 'dplyr' syntax.",
    "version": "0.5.1",
    "maintainer": "Andy Teucher <andy.teucher@gmail.com>",
    "url": "https://bcgov.github.io/bcdata/,\nhttps://catalogue.data.gov.bc.ca/,\nhttps://github.com/bcgov/bcdata/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9131,
    "package_name": "bcmaps",
    "title": "Map Layers and Spatial Utilities for British Columbia",
    "description": "Various layers of B.C., including administrative boundaries,\n    natural resource management boundaries, census boundaries etc. All\n    layers are available in BC Albers\n    (<https://spatialreference.org/ref/epsg/3005/>) equal-area projection,\n    which is the B.C. government standard. The layers are sourced from the\n    British Columbia and Canadian government under open licenses,\n    including B.C. Data Catalogue (<https://data.gov.bc.ca>), the\n    Government of Canada Open Data Portal\n    (<https://open.canada.ca/en/using-open-data>), and Statistics Canada\n    (<https://www.statcan.gc.ca/en/reference/licence>).",
    "version": "2.2.1",
    "maintainer": "Andy Teucher <andy.teucher@gmail.com>",
    "url": "https://github.com/bcgov/bcmaps, https://bcgov.github.io/bcmaps/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9141,
    "package_name": "bdc",
    "title": "Biodiversity Data Cleaning",
    "description": "It brings together several aspects of biodiversity\n    data-cleaning in one place. 'bdc' is organized in thematic modules\n    related to different biodiversity dimensions, including 1) Merge\n    datasets: standardization and integration of different datasets; 2)\n    Pre-filter: flagging and removal of invalid or non-interpretable\n    information, followed by data amendments; 3) Taxonomy: cleaning,\n    parsing, and harmonization of scientific names from several taxonomic\n    groups against taxonomic databases locally stored through the\n    application of exact and partial matching algorithms; 4) Space:\n    flagging of erroneous, suspect, and low-precision geographic\n    coordinates; and 5) Time: flagging and, whenever possible, correction\n    of inconsistent collection date. In addition, it contains\n    features to visualize, document, and report data quality – which is\n    essential for making data quality assessment transparent and\n    reproducible. The reference for the methodology is Bruno et al. (2022)\n    <doi:10.1111/2041-210X.13868>.",
    "version": "1.1.5",
    "maintainer": "Bruno Ribeiro <ribeiro.brr@gmail.com>",
    "url": "https://brunobrr.github.io/bdc/ (website)\nhttps://github.com/brunobrr/bdc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9157,
    "package_name": "bea.R",
    "title": "Bureau of Economic Analysis API",
    "description": "Provides an R interface for the Bureau of Economic Analysis (BEA) \n\t\tAPI (see <http://www.bea.gov/API/bea_web_service_api_user_guide.htm> for \n\t\tmore information) that serves two core purposes - \n    1. To Extract/Transform/Load data [beaGet()] from the BEA API as R-friendly \n\t\tformats in the user's work space [transformation done by default in beaGet() \n\t\tcan be modified using optional parameters; see, too, bea2List(), bea2Tab()].\n\t\t2. To enable the search of descriptive meta data [beaSearch()].\n\t\tOther features of the library exist mainly as intermediate methods \n\t\tor are in early stages of development.\n\t\tImportant Note - You must have an API key to use this library.  \n\t\tRegister for a key at <http://www.bea.gov/API/signup/index.cfm> .",
    "version": "1.0.6",
    "maintainer": "Andrea Batch <Andrea.Julca@bea.gov>",
    "url": "https://github.com/us-bea/bea.R",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9164,
    "package_name": "bean",
    "title": "Data Thinning of Species Occurrences in Environmental Space",
    "description": "Provides a suite of tools to mitigate sampling bias in species occurrence records by thinning data in the environmental space (E-space). This process could help increase accuracy and precision in species distribution modeling (SDM, or ecological niche modeling, ENM). The package offers a data-driven protocol to determine thinning parameters. Thinning methods (stochastic and deterministic) help reduce oversampled conditions and outlier observations. The name 'bean' reflects the core principle of the method: ensuring that each “pod” (a grid cell in E-space) contains only a specified number of “beans” (occurrence points).",
    "version": "0.1.2",
    "maintainer": "Paanwaris Paansri <paanwaris@vt.edu>",
    "url": "https://github.com/paanwaris/bean",
    "exports": [],
    "topics": ["ecological-niche-modelling", "spatial-analysis"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 9174,
    "package_name": "beeca",
    "title": "Binary Endpoint Estimation with Covariate Adjustment",
    "description": "Performs estimation of marginal treatment effects for binary \n  outcomes when using logistic regression working models with covariate \n  adjustment (see discussions in Magirr et al (2024) <https://osf.io/9mp58/>). \n  Implements the variance estimators of Ge et al (2011) <doi:10.1177/009286151104500409> \n  and Ye et al (2023) <doi:10.1080/24754269.2023.2205802>. ",
    "version": "0.2.0",
    "maintainer": "Alex Przybylski <alexander.przybylski@novartis.com>",
    "url": "https://openpharma.github.io/beeca/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9199,
    "package_name": "bespatial",
    "title": "Boltzmann Entropy for Spatial Data",
    "description": "Calculates several entropy metrics for spatial data \n  inspired by Boltzmann's entropy formula.\n  It includes metrics introduced by Cushman for landscape mosaics \n  (Cushman (2015) <doi:10.1007/s10980-015-0305-2>), \n  and landscape gradients and point patterns\n  (Cushman (2021) <doi:10.3390/e23121616>); by Zhao and Zhang for \n  landscape mosaics (Zhao and Zhang (2019) <doi:10.1007/s10980-019-00876-x>);\n  and by Gao et al. for landscape gradients\n  (Gao et al. (2018) <doi:10.1111/tgis.12315>; Gao and Li (2019) <doi:10.1007/s10980-019-00854-3>).",
    "version": "0.1.3",
    "maintainer": "Jakub Nowosad <nowosad.jakub@gmail.com>",
    "url": "https://jakubnowosad.com/bespatial/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9200,
    "package_name": "bestNormalize",
    "title": "Normalizing Transformation Functions",
    "description": "Estimate a suite of normalizing transformations, including \n    a new adaptation of a technique based on ranks which can guarantee \n    normally distributed transformed data if there are no ties: ordered \n    quantile normalization (ORQ). ORQ normalization combines a rank-mapping\n    approach with a shifted logit approximation that allows\n    the transformation to work on data outside the original domain. It is \n    also able to handle new data within the original domain via linear \n    interpolation. The package is built to estimate the best normalizing \n    transformation for a vector consistently and accurately. It implements \n    the Box-Cox transformation, the Yeo-Johnson transformation, three types \n    of Lambert WxF transformations, and the ordered quantile normalization \n    transformation. It estimates the normalization efficacy of other\n    commonly used transformations, and it allows users to specify \n    custom transformations or normalization statistics. Finally, functionality\n    can be integrated into a machine learning workflow via recipes. ",
    "version": "1.9.2",
    "maintainer": "Ryan A Peterson <ryan-peterson@uiowa.edu>",
    "url": "https://petersonr.github.io/bestNormalize/,\nhttps://github.com/petersonR/bestNormalize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9232,
    "package_name": "bfsMaps",
    "title": "Plot Maps from Switzerland by Swiss Federal Statistical Office",
    "description": "At the Swiss Federal Statistical Office (SFSO), spatial maps of Switzerland are available free of charge as 'Cartographic bases for small-scale thematic mapping'. This package contains convenience functions to import ESRI (Environmental Systems Research Institute) shape files using the package 'sf' and to plot them easily and quickly without having to worry too much about the technical details.\n      It contains utilities to combine multiple areas to one single polygon and to find neighbours for single regions. For any point on a map, a special locator can be used to determine to which municipality, district or canton it belongs.",
    "version": "1.99.4",
    "maintainer": "Andri Signorell <andri@signorell.net>",
    "url": "https://github.com/AndriSignorell/bfsMaps/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9233,
    "package_name": "bfsl",
    "title": "Best-Fit Straight Line",
    "description": "How to fit a straight line through a set of points with errors in\n  both coordinates? The 'bfsl' package implements the York regression \n  (York, 2004 <doi:10.1119/1.1632486>). It provides unbiased estimates of the \n  intercept, slope and standard errors for the best-fit straight line to \n  independent points with (possibly correlated) normally distributed errors in \n  both x and y. Other commonly used errors-in-variables methods, such as \n  orthogonal distance regression, geometric mean regression or Deming regression\n  are special cases of the 'bfsl' solution.",
    "version": "0.2.0",
    "maintainer": "Patrick Sturm <sturm@tofwerk.com>",
    "url": "https://github.com/pasturm/bfsl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9238,
    "package_name": "bgmfiles",
    "title": "Example BGM Files for the Atlantis Ecosystem Model",
    "description": "A collection of box-geometry model (BGM) files for the Atlantis \n    ecosystem model. Atlantis is a deterministic, biogeochemical, \n    whole-of-ecosystem model (see <http://atlantis.cmar.csiro.au/> for more information).",
    "version": "0.1.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/AustralianAntarcticDivision/bgmfiles/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9241,
    "package_name": "bgsmtr",
    "title": "Bayesian Group Sparse Multi-Task Regression",
    "description": "Implementation of Bayesian multi-task regression models and was developed within the context of imaging genetics. The package can currently fit two models. The Bayesian group sparse multi-task regression model of Greenlaw et al. (2017)<doi:10.1093/bioinformatics/btx215> can be fit with implementation using Gibbs sampling. An extension of this model developed by Song, Ge et al. to accommodate both spatial correlation as well as correlation across brain hemispheres can also be fit using either mean-field variational Bayes or Gibbs sampling. The model can also be used more generally for multivariate (non-imaging) phenotypes with spatial correlation.",
    "version": "0.7",
    "maintainer": "Yin Song <yinsong@uvic.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9252,
    "package_name": "bibliometrix",
    "title": "Comprehensive Science Mapping Analysis",
    "description": "Tool for quantitative research in scientometrics and bibliometrics.\n    It implements the comprehensive workflow for science mapping analysis proposed in Aria M. and \n    Cuccurullo C. (2017) <doi:10.1016/j.joi.2017.08.007>.\n    'bibliometrix' provides various routines for importing bibliographic data from 'SCOPUS',\n    'Clarivate Analytics Web of Science' (<https://www.webofknowledge.com/>), 'Digital Science Dimensions' \n\t(<https://www.dimensions.ai/>), 'OpenAlex' (<https://openalex.org/>), 'Cochrane Library' (<https://www.cochranelibrary.com/>),  'Lens' (<https://lens.org>), \n\tand 'PubMed' (<https://pubmed.ncbi.nlm.nih.gov/>) databases, performing bibliometric analysis \n    and building networks for co-citation, coupling, scientific collaboration and co-word analysis.",
    "version": "5.2.1",
    "maintainer": "Massimo Aria <aria@unina.it>",
    "url": "https://www.bibliometrix.org,\nhttps://github.com/massimoaria/bibliometrix,\nhttps://www.k-synth.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9297,
    "package_name": "bigstatsr",
    "title": "Statistical Tools for Filebacked Big Matrices",
    "description": "Easy-to-use, efficient, flexible and scalable statistical tools.\n  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.\n  It provides for instance matrix operations, Principal Component Analysis,\n  sparse linear supervised models, utility functions and more\n  <doi:10.1093/bioinformatics/bty185>.",
    "version": "1.6.2",
    "maintainer": "Florian Privé <florian.prive.21@gmail.com>",
    "url": "https://privefl.github.io/bigstatsr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9306,
    "package_name": "bild",
    "title": "A Package for BInary Longitudinal Data",
    "description": "Performs logistic regression for binary longitudinal\n  data, allowing for serial dependence among observations from a given\n  individual and a random intercept term. Estimation is via maximization\n  of the exact likelihood of a suitably defined model. Missing values and \n  unbalanced data are allowed, with some restrictions. \n  M. Helena Goncalves et al.(2007) <DOI: 10.18637/jss.v046.i09>.",
    "version": "1.2-1",
    "maintainer": "M. Helena Goncalves <mhgoncal@ualg.pt>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9327,
    "package_name": "bingmapr",
    "title": "Get Maps from Bing Maps Static Map API",
    "description": "Get static maps using aerial, bird's eye and other imagery",
    "version": "0.1.0.9000",
    "maintainer": "",
    "url": "https://github.com/elipousson/bingmapr",
    "exports": [],
    "topics": ["bing-maps", "bing-maps-api", "r", "r-package", "r-spatial"],
    "score": "NA",
    "stars": 11
  },
  {
    "id": 9358,
    "package_name": "bioclim",
    "title": "Bioclimatic Analysis and Classification",
    "description": "Using numeric or raster data, this package contains functions to \n    calculate: complete water balance, bioclimatic balance, bioclimatic \n    intensities, reports for individual locations, multi-layered rasters for\n    spatial analysis.",
    "version": "0.4.0",
    "maintainer": "Roberto Serrano-Notivoli <roberto.serrano@unizar.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9372,
    "package_name": "biogeom",
    "title": "Biological Geometries",
    "description": "Is used to simulate and fit biological geometries. 'biogeom' incorporates several novel universal parametric equations that can generate the profiles of bird eggs, flowers, linear and lanceolate leaves, seeds, starfish, and tree-rings (Gielis (2003) <doi:10.3732/ajb.90.3.333>; Shi et al. (2020) <doi:10.3390/sym12040645>), three growth-rate curves representing the ontogenetic growth trajectories of animals and plants against time, and the axially symmetrical and integral forms of all these functions (Shi et al. (2017) <doi:10.1016/j.ecolmodel.2017.01.012>; Shi et al. (2021) <doi:10.3390/sym13081524>). The optimization method proposed by Nelder and Mead (1965) <doi:10.1093/comjnl/7.4.308> was used to estimate model parameters. 'biogeom' includes several real data sets of the boundary coordinates of natural shapes, including avian eggs, fruit, lanceolate and ovate leaves, tree rings, seeds, and sea stars,and can be potentially applied to other natural shapes. 'biogeom' can quantify the conspecific or interspecific similarity of natural outlines, and provides information with important ecological and evolutionary implications for the growth and form of living organisms. Please see Shi et al. (2022) <doi:10.1111/nyas.14862> for details.",
    "version": "1.5.0",
    "maintainer": "Peijian Shi <pjshi@njfu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9396,
    "package_name": "biostat3",
    "title": "Utility Functions, Datasets and Extended Examples for Survival\nAnalysis",
    "description": "Utility functions, datasets and extended examples for survival analysis. This extends a range of other packages, some simple wrappers for time-to-event analyses, datasets, and extensive examples in HTML with R scripts. The package also supports the course Biostatistics III entitled \"Survival analysis for epidemiologists in R\".",
    "version": "0.2.3",
    "maintainer": "Mark Clements <mark.clements@ki.se>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9401,
    "package_name": "biotools",
    "title": "Tools for Biometry and Applied Statistics in Agricultural\nScience",
    "description": "Tools designed to perform and evaluate cluster analysis (including Tocher's algorithm), \n\tdiscriminant analysis and path analysis (standard and under collinearity), as well as some \n\tuseful miscellaneous tools for dealing with sample size and optimum plot size calculations. \n\tA test for seed sample heterogeneity is now available. Mantel's permutation test can be found in this package. \n\tA new approach for calculating its power is implemented. biotools also contains tests for genetic covariance components.\n\tHeuristic approaches for performing non-parametric spatial predictions of generic response variables and \n\tspatial gene diversity are implemented.",
    "version": "4.3",
    "maintainer": "Anderson Rodrigo da Silva <anderson.agro@hotmail.com>",
    "url": "https://arsilva87.github.io/biotools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9413,
    "package_name": "birdsEye",
    "title": "Tools for geographic analysis",
    "description": "Tools for geographic analysis",
    "version": "0.0.0.9006",
    "maintainer": "Adam B. Smith <adam.smith@mobot.org>",
    "url": "https://github.com/adamlilith/birdsEye",
    "exports": [],
    "topics": ["gis", "interpolation", "projection-mapping", "projections", "spatial", "spatial-analysis", "spatial-data-analysis", "spatial-polygons"],
    "score": "NA",
    "stars": 1
  },
  {
    "id": 9417,
    "package_name": "birtr",
    "title": "The R Package for \"The Basics of Item Response Theory Using R\"",
    "description": "R functions for \"The Basics of Item Response Theory Using R\" by Frank B. Baker and Seock-Ho Kim (Springer, 2017, ISBN-13: 978-3-319-54204-1) including iccplot(), icccal(), icc(), iccfit(), groupinv(), tcc(), ability(), tif(), and rasch().  For example, iccplot() plots an item characteristic curve under the two-parameter logistic model.",
    "version": "1.0.0",
    "maintainer": "Seock-Ho Kim <shkim@uga.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9418,
    "package_name": "biscale",
    "title": "Tools and Palettes for Bivariate Thematic Mapping",
    "description": "Provides a 'ggplot2' centric approach to bivariate mapping. This is a \n    technique that maps two quantities simultaneously rather than the single value \n    that most thematic maps display. The package provides a suite of tools \n    for calculating breaks using multiple different approaches, a selection of \n    palettes appropriate for bivariate mapping and scale functions for 'ggplot2' \n    calls that adds those palettes to maps. Tools for creating bivariate legends \n    are also included.",
    "version": "1.1.0",
    "maintainer": "Christopher Prener <chris.prener@gmail.com>",
    "url": "https://chris-prener.github.io/biscale/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9420,
    "package_name": "bispdep",
    "title": "Statistical Tools for Bivariate Spatial Dependence Analysis",
    "description": "A collection of functions to test spatial autocorrelation between variables, including Moran I, Geary C and Getis G together with scatter plots, functions for mapping and identifying clusters and outliers, functions associated with the moments of the previous statistics that will allow testing whether there is bivariate spatial autocorrelation, and a function that allows identifying (visualizing neighbours) on the map, the neighbors of any region once the scheme of the spatial weights matrix has been established.",
    "version": "1.0-2",
    "maintainer": "Carlos Melo <cmelo@udistrital.edu.co>",
    "url": "https://github.com/carlosm77/bispdep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9434,
    "package_name": "bivrp",
    "title": "Bivariate Residual Plots with Simulation Polygons",
    "description": "Generates bivariate residual plots with simulation polygons for any diagnostics and bivariate model from which functions to extract the desired diagnostics, simulate new data and refit the models are available.",
    "version": "1.2-2",
    "maintainer": "Rafael de Andrade Moral <rafael.deandrademoral@mu.ie>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9456,
    "package_name": "blink",
    "title": "Record Linkage for Empirically Motivated Priors",
    "description": "An implementation of the model in Steorts (2015) <DOI:10.1214/15-BA965SI>, which performs Bayesian entity resolution for categorical and text data, for any distance function defined by the user. In addition, the precision and recall are in the package to allow one to compare to any other comparable method such as logistic regression, Bayesian additive regression trees (BART), or random forests. The experiments are reproducible and illustrated using a simple vignette. LICENSE: GPL-3 + file license. ",
    "version": "1.1.0",
    "maintainer": "Rebecca Steorts <beka@stat.duke.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9463,
    "package_name": "blockCV",
    "title": "Spatial and Environmental Blocking for K-Fold and LOO\nCross-Validation",
    "description": "Creating spatially or environmentally separated folds for cross-validation to provide a robust error estimation in spatially structured environments; Investigating and visualising the effective range of spatial autocorrelation in continuous raster covariates and point samples to find an initial realistic distance band to separate training and testing datasets spatially described in Valavi, R. et al. (2019) <doi:10.1111/2041-210X.13107>.",
    "version": "3.2-0",
    "maintainer": "Roozbeh Valavi <valavi.r@gmail.com>",
    "url": "https://github.com/rvalavi/blockCV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9485,
    "package_name": "blosc",
    "title": "Compress and Decompress Data Using the 'BLOSC' Library",
    "description": "Arrays of structured data types can require large volumes of disk\n    space to store. 'Blosc' is a library that provides a fast and efficient way\n    to compress such data. It is often applied in storage of n-dimensional\n    arrays, such as in the case of the geo-spatial 'zarr' file format. This\n    package can be used to compress and decompress data using 'Blosc'.",
    "version": "0.1.2",
    "maintainer": "Pepijn de Vries <pepijn.devries@outlook.com>",
    "url": "https://pepijn-devries.github.io/blosc/,\nhttps://github.com/pepijn-devries/blosc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9487,
    "package_name": "blrm",
    "title": "Dose Escalation Design in Phase I Oncology Trial Using Bayesian\nLogistic Regression Modeling",
    "description": "Design dose escalation using Bayesian logistic regression modeling in Phase I oncology trial.",
    "version": "1.0-2",
    "maintainer": "Furong Sun <furongs@vt.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9543,
    "package_name": "booami",
    "title": "Component-Wise Gradient Boosting after Multiple Imputation",
    "description": "Component-wise gradient boosting for analysis of multiply\n    imputed datasets. Implements the algorithm Boosting after Multiple\n    Imputation (MIBoost), which enforces uniform variable selection across\n    imputations and provides utilities for pooling. Includes a cross-validation\n    workflow that first splits the data into training and validation sets and\n    then performs imputation on the training data, applying the learned\n    imputation models to the validation data to avoid information leakage.\n    Supports Gaussian and logistic loss. Methods relate to gradient boosting\n    and multiple imputation as in Buehlmann and Hothorn (2007) <doi:10.1214/07-STS242>,\n    Friedman (2001) <doi:10.1214/aos/1013203451>, and van Buuren (2018, ISBN:9781138588318)\n    and Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>; see also Kuchen (2025)\n    <doi:10.48550/arXiv.2507.21807>.",
    "version": "0.1.1",
    "maintainer": "Robert Kuchen <rokuchen@uni-mainz.de>",
    "url": "https://arxiv.org/abs/2507.21807,\nhttps://github.com/RobertKuchen/booami",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9584,
    "package_name": "boundingbox",
    "title": "Create a Bounding Box in an Image",
    "description": "Generate ground truth cases for object localization algorithms. \n    Cycle through a list of images, select points around which to generate bounding \n    boxes and assign classifiers. Output the coordinates, and images annotated with \n    boxes and labels. For an example study that uses bounding boxes for image \n    localization and classification see Ibrahim, Badr, Abdallah, and Eissa (2012)\n    \"Bounding Box Object Localization Based on Image Superpixelization\"\n    <doi:10.1016/j.procs.2012.09.119>.",
    "version": "1.0.1",
    "maintainer": "David Stomski <stomperusa@verizon.net>",
    "url": "<https://github.com/stomperusa/boundingbox>",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9592,
    "package_name": "boxcoxmix",
    "title": "Box-Cox-Type Transformations for Linear and Logistic Models with\nRandom Effects",
    "description": "Box-Cox-type transformations for linear and logistic models with random effects using non-parametric profile maximum likelihood estimation, as introduced in Almohaimeed (2018) <http://etheses.dur.ac.uk/12831/> and Almohaimeed and Einbeck (2022) <doi:10.1177/1471082X20966919>. The main functions are 'optim.boxcox()' for linear models with random effects and 'boxcoxtype()' for logistic models with random effects.",
    "version": "0.46",
    "maintainer": "Iago Giné-Vázquez <iago.gin-vaz@protonmail.com>",
    "url": "https://gitlab.com/iagogv/boxcoxmix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9655,
    "package_name": "bridgedist",
    "title": "An Implementation of the Bridge Distribution with Logit-Link as\nin Wang and Louis (2003)",
    "description": "An implementation of the bridge distribution with logit-link in\n    R. In Wang and Louis (2003) <DOI:10.1093/biomet/90.4.765>, such a univariate\n    bridge distribution was derived as the distribution of the random intercept that\n    'bridged' a marginal logistic regression and a conditional logistic regression.\n    The conditional and marginal regression coefficients are a scalar multiple\n    of each other. Such is not the case if the random intercept distribution was\n    Gaussian.",
    "version": "0.1.3",
    "maintainer": "Bruce Swihart <bruce.swihart@gmail.com>",
    "url": "https://github.com/swihart/bridgedist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9686,
    "package_name": "bruneimap",
    "title": "Maps and Spatial Data of Brunei",
    "description": "Provides spatial data for mapping Brunei, including boundaries for districts, mukims, and kampongs, as well as locations of key infrastructure such as masjids, hospitals, clinics, and schools. The package supports researchers, analysts, and developers working with Brunei’s geographic and demographic data, offering a quick and accessible foundation for creating maps and conducting spatial studies.",
    "version": "0.3.1",
    "maintainer": "Haziq Jamil <haziq.jamil@gmail.com>",
    "url": "https://github.com/Bruneiverse/bruneimap,\nhttps://bruneiverse.github.io/bruneimap/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9709,
    "package_name": "bsreg",
    "title": "Bayesian Spatial Regression Models",
    "description": "Fit Bayesian models with a focus on the spatial econometric models.",
    "version": "0.0.2",
    "maintainer": "Nikolas Kuschnig <nikolas.kuschnig@wu.ac.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9720,
    "package_name": "btb",
    "title": "Beyond the Border - Kernel Density Estimation for Urban\nGeography",
    "description": "The kernelSmoothing() function allows you to square and smooth geolocated data. It calculates a classical kernel smoothing (conservative) or a geographically weighted median. There are four major call modes of the function. \n        The first call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth) for a classical kernel smoothing and automatic grid.\n        The second call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles) for a geographically weighted median and automatic grid.\n        The third call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, centroids) for a classical kernel smoothing and user grid.\n        The fourth call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles, centroids) for a geographically weighted median and user grid.\n        Geographically weighted summary statistics : a framework for localised exploratory data analysis, C.Brunsdon & al., in Computers, Environment and Urban Systems C.Brunsdon & al. (2002) <doi:10.1016/S0198-9715(01)00009-6>, \n        Statistical Analysis of Spatial and Spatio-Temporal Point Patterns, Third Edition, Diggle, pp. 83-86, (2003) <doi:10.1080/13658816.2014.937718>.",
    "version": "0.2.1",
    "maintainer": "Solène Colin <solene.colin@insee.fr>",
    "url": "https://github.com/InseeFr/btb, https://inseefr.github.io/btb/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9774,
    "package_name": "c2c",
    "title": "Compare Two Classifications or Clustering Solutions of Varying\nStructure",
    "description": "Compare two classifications or clustering solutions that may or may\n    not have the same number of classes, and that might have hard or soft\n    (fuzzy, probabilistic) membership. Calculate various metrics to assess how\n    the clusters compare to each other. The calculations are simple, but provide\n    a handy tool for users unfamiliar with matrix multiplication. This package\n    is not geared towards traditional accuracy assessment for classification/\n    mapping applications - the motivating use case is for comparing a\n    probabilistic clustering solution to a set of reference or existing class\n    labels that could have any number of classes (that is, without having to\n    degrade the probabilistic clustering to hard classes).",
    "version": "0.1.0",
    "maintainer": "Mitchell Lyons <mitchell.lyons@gmail.com>",
    "url": "https://github.com/mitchest/c2c/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9776,
    "package_name": "c3",
    "title": "'C3.js' Chart Library",
    "description": "Create interactive charts with the 'C3.js' <http://c3js.org/> charting library. All plot \n    types in 'C3.js' are available and include line, bar, scatter, and mixed geometry plots. Plot \n    annotations, labels and axis are highly adjustable. Interactive web based charts can be embedded \n    in R Markdown documents or Shiny web applications. ",
    "version": "0.3.0",
    "maintainer": "Matt Johnson <mrjoh3@gmail.com>",
    "url": "https://github.com/mrjoh3/c3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9796,
    "package_name": "cabootcrs",
    "title": "Bootstrap Confidence Regions for Simple and Multiple\nCorrespondence Analysis",
    "description": "Performs simple correspondence analysis on a two-way contingency table, \n    or multiple correspondence analysis (homogeneity analysis) \n    on data with p categorical variables,\n    and produces bootstrap-based elliptical confidence regions around the \n    projected coordinates for the category points. \n    Includes routines to plot the results in a variety of styles. \n    Also reports the standard numerical output for correspondence analysis.",
    "version": "2.1.0",
    "maintainer": "Trevor Ringrose <t.j.ringrose@cranfield.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9805,
    "package_name": "calba",
    "title": "Efficient Neighborhood Basal Area Metrics for Trees",
    "description": "Fast 'C++'-backed tools for computing conspecific and total neighborhood basal area in mapped forest plots. Includes unweighted and distance-weighted neighborhoods, multiple radii, decay kernels, and basic edge correction. Outputs are model-ready covariates for forest competition, growth, and survival models, following neighborhood modeling workflows commonly used in spatial ecology (e.g., Hülsmann et al. 2024 <doi:10.1038/s41586-024-07118-4>).",
    "version": "0.1.2",
    "maintainer": "Masatoshi Katabuchi <mattocci27@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9808,
    "package_name": "calcite",
    "title": "Bindings to the Calcite Design System 'JavaScript' Component",
    "description": "Provides access to the 'Calcite Design System' 'javascript'",
    "version": "0.1.2.9000",
    "maintainer": "",
    "url": "https://github.com/R-ArcGIS/calcite",
    "exports": [],
    "topics": ["arcgis", "calcite-design-system", "r-shiny", "r-spatial", "rstats"],
    "score": "NA",
    "stars": 13
  },
  {
    "id": 9813,
    "package_name": "calibmsm",
    "title": "Calibration Plots for the Transition Probabilities from\nMultistate Models",
    "description": "Assess the calibration of an existing (i.e. previously developed) multistate\n  model through calibration plots. \n  Calibration is assessed using one of three methods. 1) Calibration methods for \n  binary logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 2) Calibration methods for \n  multinomial logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 3) Pseudo-values estimated using \n  the Aalen-Johansen estimator of observed risk. All methods are applied in conjunction\n  with landmarking when required. These calibration plots evaluate the calibration \n  (in a validation cohort of interest) of the transition probabilities estimated from an \n  existing multistate model. While package development has focused on multistate \n  models, calibration plots can be produced for any model which utilises information \n  post baseline to update predictions (e.g. dynamic models); competing risks models; \n  or standard single outcome survival models, where predictions can be made at \n  any landmark time. Please see Pate et al. (2024) <doi:10.1002/sim.10094>\n  and Pate et al. (2024) <https://alexpate30.github.io/calibmsm/articles/Overview.html>.",
    "version": "1.1.3",
    "maintainer": "Alexander Pate <alexander.pate@manchester.ac.uk>",
    "url": "https://github.com/alexpate30/calibmsm,\nhttps://alexpate30.github.io/calibmsm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9836,
    "package_name": "camtrapR",
    "title": "Camera Trap Data Management and Analysis Framework",
    "description": "Management and analysis of camera trap wildlife data through an integrated workflow. Provides functions for image/video organization and metadata extraction, species/individual identification. Creates detection histories for occupancy and spatial capture-recapture analyses, with support for multi-season studies. Includes tools for fitting community occupancy models in JAGS and NIMBLE, and an interactive dashboard for survey data visualization and analysis. Features visualization of species distributions and activity patterns, plus export capabilities for GIS and reports. Emphasizes automation and reproducibility while maintaining flexibility for different study designs.",
    "version": "3.0.0",
    "maintainer": "Juergen Niedballa <camtrapr@gmail.com>",
    "url": "https://github.com/jniedballa/camtrapR,\nhttps://jniedballa.github.io/camtrapR/,\nhttps://groups.google.com/forum/#!forum/camtrapr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9839,
    "package_name": "canadianmaps",
    "title": "Effortlessly Create Stunning Canadian Maps",
    "description": "Simple and seamless access to a variety of 'StatCan' shapefiles for mapping Canadian provinces, regions, forward sortation areas, census divisions, and subdivisions using the popular 'ggplot2' package.",
    "version": "2.0.0",
    "maintainer": "Joelle Cayen <joelle.cayen@phac-aspc.gc.ca>",
    "url": "https://github.com/joellecayen/canadianmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9842,
    "package_name": "cancensus",
    "title": "Access, Retrieve, and Work with Canadian Census Data and\nGeography",
    "description": "Integrated, convenient, and uniform access to Canadian\n    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready \n    tidy data frames and spatial data in multiple formats, as well as convenience functions\n    for working with Census variables, variable hierarchies, and region selection. API\n    keys are freely available with free registration at <https://censusmapper.ca/api>.\n    Census data and boundary geometries are reproduced and distributed on an \"as\n    is\" basis with the permission of Statistics Canada (Statistics Canada 1996; 2001; 2006;\n    2011; 2016; 2021).",
    "version": "0.5.10",
    "maintainer": "Dmitry Shkolnik <shkolnikd@gmail.com>",
    "url": "https://github.com/mountainMath/cancensus,\nhttps://mountainmath.github.io/cancensus/,\nhttps://censusmapper.ca/api",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9885,
    "package_name": "caret",
    "title": "Classification and Regression Training",
    "description": "Misc functions for training and plotting classification and\n    regression models.",
    "version": "7.0-1",
    "maintainer": "Max Kuhn <mxkuhn@gmail.com>",
    "url": "https://github.com/topepo/caret/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9896,
    "package_name": "cartogony",
    "title": "What the Package Does (Title Case)",
    "description": "More about what it does (maybe more than one line)",
    "version": "0.1.0",
    "maintainer": "The package maintainer <yourself@somewhere.net>",
    "url": "https://github.com/mdsumner/cartogony",
    "exports": [],
    "topics": ["cartography", "gis", "maps", "rstats", "spatial-data"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 9897,
    "package_name": "cartograflow",
    "title": "Filtering Matrix for Flow Mapping",
    "description": "Functions to prepare and filter an origin-destination matrix for thematic flow mapping purposes.   \n             This comes after Bahoken, Francoise (2016), Mapping flow matrix a contribution, PhD in Geography - Territorial sciences. See Bahoken (2017) <doi:10.4000/netcom.2565>.",
    "version": "1.0.5",
    "maintainer": "Sylvain Blondeau <blondeau.sylvain@yahoo.fr>",
    "url": "https://github.com/fbahoken/cartogRaflow",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9898,
    "package_name": "cartogram",
    "title": "Create Cartograms with R",
    "description": "Construct continuous and non-contiguous area cartograms.",
    "version": "0.3.0",
    "maintainer": "Sebastian Jeworutzki <sebastian.jeworutzki@ruhr-uni-bochum.de>",
    "url": "https://github.com/sjewo/cartogram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9900,
    "package_name": "cartographer",
    "title": "Turn Place Names into Map Data",
    "description": "A tool for easily matching spatial data when you have a list of\n    place/region names. You might have a data frame that came from a\n    spreadsheet tracking some data by suburb or state. This package can\n    convert it into a spatial data frame ready for plotting. The actual map\n    data is provided by other packages (or your own code).",
    "version": "0.2.1",
    "maintainer": "Carl Suster <Carl.Suster@health.nsw.gov.au>",
    "url": "https://github.com/cidm-ph/cartographer,\nhttps://cidm-ph.github.io/cartographer/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9901,
    "package_name": "cartographr",
    "title": "Crafting Print-Ready Maps and Layered Visualizations",
    "description": "Simplifying the creation of print-ready maps, this package offers a user-friendly interface derived from 'ggplot2' for handling OpenStreetMap data. It streamlines the map-making process, allowing users to focus on the story their maps tell. Transforming raw geospatial data into informative visualizations is made easy with simple features 'sf' geometries. Whether for urban planning, environmental studies, or impactful public presentations, this tool facilitates straightforward and effective map creation. Enhance the dissemination of spatial information with high-quality, narrative-driven visualizations!",
    "version": "0.2.4",
    "maintainer": "David Willinger <david.willinger@gmail.com>",
    "url": "https://da-wi.github.io/cartographr/,\nhttps://github.com/da-wi/cartographr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 9921,
    "package_name": "catR",
    "title": "Generation of IRT Response Patterns under Computerized Adaptive\nTesting",
    "description": "Provides routines for the generation of response patterns under unidimensional dichotomous and polytomous computerized adaptive testing (CAT) framework. It holds many standard functions to estimate ability, select the first item(s) to administer and optimally select the next item, as well as several stopping rules. Options to control for item exposure and content balancing are also available (Magis and Barrada (2017) <doi:10.18637/jss.v076.c01>).",
    "version": "3.17",
    "maintainer": "Cheng Hua <chuabest@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10030,
    "package_name": "cdparcoord",
    "title": "Top Frequency-Based Parallel Coordinates",
    "description": "Parallel coordinate plotting with resolutions for large data sets\n and missing values.",
    "version": "1.0.1",
    "maintainer": "Norm Matloff <normmatloff@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10039,
    "package_name": "celestial",
    "title": "Collection of Common Astronomical Conversion Routines and\nFunctions",
    "description": "Contains a number of common astronomy utility functions for cosmology and angular coordinates.",
    "version": "1.5.8",
    "maintainer": "Aaron Robotham <aaron.robotham@uwa.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10070,
    "package_name": "centerline",
    "title": "Extract Centerline from Closed Polygons",
    "description": "Generates skeletons of closed 2D polygons using Voronoi diagrams. \n            It provides methods for 'sf', 'terra', and 'geos' objects to \n            compute polygon centerlines based on the generated skeletons.\n            Voronoi, G. (1908) <doi:10.1515/crll.1908.134.198>.",
    "version": "0.2.5",
    "maintainer": "Anatoly Tsyplenkov <atsyplenkov@fastmail.com>",
    "url": "https://centerline.anatolii.nz,\nhttps://github.com/atsyplenkov/centerline",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10072,
    "package_name": "centr",
    "title": "Weighted and Unweighted Spatial Centers",
    "description": "Generate mean and median weighted or unweighted spatial centers. \n    Functions are analogous to their identically named counterparts within \n    'ArcGIS Pro'. Median center methodology based off of Kuhn and Kuenne \n    (1962) <doi:10.1111/j.1467-9787.1962.tb00902.x>.",
    "version": "0.2.4",
    "maintainer": "Ryan Zomorrodi <rzomor2@uic.edu>",
    "url": "https://ryanzomorrodi.github.io/centr/,\nhttps://github.com/ryanzomorrodi/centr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10080,
    "package_name": "ceramic",
    "title": "Download Online Imagery Tiles",
    "description": "Download imagery tiles to a standard cache and load the data into raster objects. \n Facilities for 'AWS' terrain <https://registry.opendata.aws/terrain-tiles/> terrain and 'Mapbox' \n <https://www.mapbox.com/> servers are provided. ",
    "version": "0.9.5",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://hypertidy.github.io/ceramic/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10097,
    "package_name": "cffdrs",
    "title": "Canadian Forest Fire Danger Rating System",
    "description": "This project provides a group of new functions to calculate\n    the outputs of the two main components of the Canadian Forest Fire\n    Danger Rating System (CFFDRS) Van Wagner and Pickett (1985)\n    <https://ostrnrcan-dostrncan.canada.ca/entities/publication/29706108-2891-4e5d-a59a-a77c96bc507c>) at various time\n    scales: the Fire Weather Index (FWI) System Wan Wagner (1985)\n    <https://ostrnrcan-dostrncan.canada.ca/entities/publication/d96e56aa-e836-4394-ba29-3afe91c3aa6c> and the Fire Behaviour\n    Prediction (FBP) System Forestry Canada Fire Danger Group (1992)\n    <https://cfs.nrcan.gc.ca/pubwarehouse/pdfs/10068.pdf>. Some functions\n    have two versions, table and raster based.",
    "version": "1.9.2",
    "maintainer": "Brett Moore <Brett.Moore@nrcan-rncan.gc.ca>",
    "url": "https://github.com/cffdrs/cffdrs_r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10108,
    "package_name": "cgal4h",
    "title": "'CGAL' Version 4 C++ Header Files",
    "description": "'CGAL' is a C++ library that aims to provide easy access to efficient and\n  reliable algorithms in computational geometry. Since its version 4, 'CGAL' can be used\n  as standalone header-only library and is available under a double GPL-3|LGPL license.\n  <https://www.cgal.org/>.",
    "version": "0.1.0",
    "maintainer": "Ahmadou Dicko <mail@ahmadoudicko.com>",
    "url": "https://gitlab.com/dickoa/cgal4h",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10133,
    "package_name": "charisma",
    "title": "Reproducible Color Characterization of Digital Images for\nBiological Studies",
    "description": "Provides a standardized and reproducible framework for characterizing\n    and classifying discrete color classes from digital images of biological organisms.\n    The package automatically determines the presence or absence of 10 human-visible\n    color categories (black, blue, brown, green, grey, orange, purple, red, white, yellow)\n    using a biologically-inspired Color Look-Up Table (CLUT) that partitions HSV color space.\n    Supports both fully automated and semi-automated (interactive) workflows with complete\n    provenance tracking for reproducibility. Pre-processes images using the 'recolorize'\n    package (Weller et al. 2024 <doi:10.1111/ele.14378>) for spatial-color binning, and\n    integrates with 'pavo' (Maia et al. 2019 <doi:10.1111/2041-210X.13174>) for color\n    pattern geometry statistics. Designed for high-throughput analysis and seamless\n    integration with downstream evolutionary analyses.",
    "version": "1.0.0",
    "maintainer": "Shawn Schwartz <shawn.t.schwartz@gmail.com>",
    "url": "https://github.com/shawntz/charisma,\nhttps://shawnschwartz.com/charisma/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10155,
    "package_name": "cheddar",
    "title": "Analysis and Visualisation of Ecological Communities",
    "description": "Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.",
    "version": "0.1-639",
    "maintainer": "Lawrence Hudson <quicklizard@googlemail.com>",
    "url": "https://github.com/quicklizard99/cheddar/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10169,
    "package_name": "chessboard",
    "title": "Create Network Connections Based on Chess Moves",
    "description": "Provides functions to work with directed (asymmetric) and \n    undirected (symmetric) spatial networks. It makes the creation of \n    connectivity matrices easier, i.e. a binary matrix of dimension n x n, where \n    n is the number of nodes (sampling units) indicating the presence (1) or  \n    the absence (0) of an edge (link) between pairs of nodes. Different network\n    objects can be produced by 'chessboard': node list, neighbor list, edge \n    list, connectivity matrix. It can also produce objects that will be used \n    later in Moran's Eigenvector Maps (Dray et al. (2006) <doi:10.1016/j.ecolmodel.2006.02.015>)\n    and Asymetric Eigenvector Maps (Blanchet et al. (2008) <doi:10.1016/j.ecolmodel.2008.04.001>), \n    methods available in the package 'adespatial' (Dray et al. (2023) \n    <https://CRAN.R-project.org/package=adespatial>). This work is part of the \n    FRB-CESAB working group Bridge \n    <https://www.fondationbiodiversite.fr/en/the-frb-in-action/programs-and-projects/le-cesab/bridge/>.",
    "version": "0.1",
    "maintainer": "Nicolas Casajus <nicolas.casajus@fondationbiodiversite.fr>",
    "url": "https://github.com/frbcesab/chessboard",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10181,
    "package_name": "chillR",
    "title": "Statistical Methods for Phenology Analysis in Temperate Fruit\nTrees",
    "description": "The phenology of plants (i.e. the timing of their annual life\n    phases) depends on climatic cues. For temperate trees and many other plants,\n    spring phases, such as leaf emergence and flowering, have been found to result\n    from the effects of both cool (chilling) conditions and heat. Fruit tree\n    scientists (pomologists) have developed some metrics to quantify chilling\n    and heat (e.g. see Luedeling (2012) <doi:10.1016/j.scienta.2012.07.011>).\n    'chillR' contains functions for processing temperature records into\n    chilling (Chilling Hours, Utah Chill Units and Chill Portions) and heat units\n    (Growing Degree Hours). Regarding chilling metrics, Chill Portions are often\n    considered the most promising, but they are difficult to calculate. This package\n    makes it easy. 'chillR' also contains procedures for conducting a PLS analysis\n    relating phenological dates (e.g. bloom dates) to either mean temperatures or\n    mean chill and heat accumulation rates, based on long-term weather and phenology\n    records (Luedeling and Gassner (2012) <doi:10.1016/j.agrformet.2011.10.020>).\n    As of version 0.65, it also includes functions for generating weather\n    scenarios with a weather generator, for conducting climate change analyses\n    for temperature-based climatic metrics and for plotting results from such\n    analyses. Since version 0.70, 'chillR' contains a function for interpolating\n    hourly temperature records.",
    "version": "0.77",
    "maintainer": "Eike Luedeling <eike@eikeluedeling.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10204,
    "package_name": "choroplethr",
    "title": "Create Color-Coded Choropleth Maps in R",
    "description": "Easily create color-coded (choropleth) maps in R. No knowledge of\n  cartography or shapefiles needed; go directly from your geographically\n  identified data to a highly customizable map with a single line of code!\n  Supported geographies: U.S. states, counties, census tracts, and zip codes, \n  world countries and sub-country regions (e.g., provinces, prefectures, etc.).",
    "version": "5.0.1",
    "maintainer": "Zhaochen He <zhaochen.he@cnu.edu>",
    "url": "<https://github.com/eastnile/choroplethr>",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10239,
    "package_name": "ciftiTools",
    "title": "Tools for Reading, Writing, Viewing and Manipulating CIFTI Files",
    "description": "CIFTI files contain brain imaging data in \"grayordinates,\" which \n    represent the gray matter as cortical surface vertices (left and right) and\n    subcortical voxels (cerebellum, basal ganglia, and other deep gray matter). \n    'ciftiTools' provides a unified environment for reading, writing, \n    visualizing and manipulating CIFTI-format data. It supports the \"dscalar,\" \n    \"dlabel,\" and \"dtseries\" intents. Grayordinate data is read in as a \"xifti\" \n    object, which is structured for convenient access to the data and metadata,\n    and includes support for surface geometry files to enable\n    spatially-dependent functionality such as static or interactive \n    visualizations and smoothing.",
    "version": "0.18.0",
    "maintainer": "Amanda Mejia <mandy.mejia@gmail.com>",
    "url": "https://github.com/mandymejia/ciftiTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10250,
    "package_name": "circhelp",
    "title": "Circular Analyses Helper Functions",
    "description": "Light-weight functions for computing descriptive statistics in different circular spaces (e.g., 2pi, 180, or 360 degrees), to handle angle-dependent biases, pad circular data, and more. Specifically aimed for psychologists and neuroscientists analyzing circular data. Basic methods are based on Jammalamadaka and SenGupta (2001) <doi:10.1142/4031>, removal of cardinal biases is based on the approach introduced in van Bergen, Ma, Pratte, & Jehee (2015) <doi:10.1038/nn.4150> and Chetverikov and Jehee (2023) <doi:10.1038/s41467-023-43251-w>.",
    "version": "1.1",
    "maintainer": "Andrey Chetverikov <andrey.chetverikov@uib.no>",
    "url": "https://achetverikov.github.io/circhelp/index.html,\nhttps://github.com/achetverikov/circhelp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10264,
    "package_name": "cisp",
    "title": "A Correlation Indicator Based on Spatial Patterns",
    "description": "Use the spatial association marginal contributions derived from spatial stratified heterogeneity to capture the degree of correlation between spatial patterns.",
    "version": "0.1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/cisp/, https://github.com/stscl/cisp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10299,
    "package_name": "clc",
    "title": "CORINE Land Cover Data and Styles",
    "description": "Streamline the management, analysis, and visualization of\n    CORINE Land Cover data. Addresses challenges associated with its\n    classification system and related styles, such as color mappings and\n    descriptive labels.",
    "version": "1.0.0",
    "maintainer": "Jose Samos <jsamos@ugr.es>",
    "url": "https://josesamos.github.io/clc/, https://github.com/josesamos/clc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10317,
    "package_name": "clespr",
    "title": "Composite Likelihood Estimation for Spatial Data",
    "description": "Composite likelihood approach is implemented to estimating statistical models for spatial ordinal and proportional data based on Feng et al. (2014) <doi:10.1002/env.2306>. Parameter estimates are identified by maximizing composite log-likelihood functions using the limited memory BFGS optimization algorithm with bounding constraints, while standard errors are obtained by estimating the Godambe information matrix.",
    "version": "1.1.2",
    "maintainer": "Ting Fung (Ralph) Ma <tingfung.ma@wisc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10333,
    "package_name": "climate",
    "title": "Interface to Download Meteorological (and Hydrological) Datasets",
    "description": "Automatize downloading of meteorological and hydrological data from publicly available repositories:\n    OGIMET (<http://ogimet.com/index.phtml.en>), \n    University of Wyoming - atmospheric vertical profiling data (<http://weather.uwyo.edu/upperair/>),\n    Polish Institute of Meteorology and Water Management - National Research Institute (<https://danepubliczne.imgw.pl>),\n    and National Oceanic & Atmospheric Administration (NOAA).\n    This package also allows for searching geographical coordinates for each observation and calculate distances to the nearest stations.",
    "version": "1.2.5",
    "maintainer": "Bartosz Czernecki <nwp@amu.edu.pl>",
    "url": "https://github.com/bczernecki/climate,\nhttps://bczernecki.github.io/climate/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10335,
    "package_name": "climateStability",
    "title": "Estimating Climate Stability from Climate Model Data",
    "description": "Climate stability measures are not formalized in the literature and\n  tools for generating stability metrics from existing data are nascent.\n  This package provides tools for calculating climate stability from raster data\n  encapsulating climate change as a series of time slices. The methods follow\n  Owens and Guralnick <doi:10.17161/bi.v14i0.9786> Biodiversity Informatics.",
    "version": "0.1.4",
    "maintainer": "Hannah Owens <hannah.owens@gmail.com>",
    "url": "https://github.com/hannahlowens/climateStability",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10341,
    "package_name": "climodr",
    "title": "Climate Modeling with Point Data from Climate Stations",
    "description": "An automated and streamlined workflow for predictive climate \n             mapping using climate station data. Works within an environment \n             the user provides a destined path to - otherwise it's tempdir().\n             Quick and relatively easy creation of resilient and reproducible \n             climate models, predictions and climate maps, shortening the\n             usually long and complicated work of predictive modelling. \n             For more information, please find the provided URL.\n             Many methods in this package are new, but the main method is based\n             on a workflow from \n             Meyer (2019) <doi:10.1016/j.ecolmodel.2019.108815> \n             and \n             Meyer (2022) <doi:10.1038/s41467-022-29838-9> , however, it was generalized and adjusted in the context of this package.",
    "version": "1.0.0",
    "maintainer": "Alexander Klug <kluga@students.uni-marburg.de>",
    "url": "https://envima.github.io/climodr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10355,
    "package_name": "clinspacy",
    "title": "Clinical Natural Language Processing using 'spaCy', 'scispaCy',\nand 'medspaCy'",
    "description": "Performs biomedical named entity recognition,\n    Unified Medical Language System (UMLS) concept mapping, and negation\n    detection using the Python 'spaCy', 'scispaCy', and 'medspaCy' packages, and \n    transforms extracted data into a wide format for inclusion in machine\n    learning models. The development of the 'scispaCy' package is described by\n    Neumann (2019) <doi:10.18653/v1/W19-5034>. The 'medspacy' package uses\n    'ConText', an algorithm for determining the context of clinical statements\n    described by Harkema (2009) <doi:10.1016/j.jbi.2009.05.002>. Clinspacy\n    also supports entity embeddings from 'scispaCy' and UMLS 'cui2vec' concept\n    embeddings developed by Beam (2018) <arXiv:1804.01486>.",
    "version": "1.0.2",
    "maintainer": "Karandeep Singh <kdpsingh@umich.edu>",
    "url": "https://github.com/ML4LHS/clinspacy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10370,
    "package_name": "clogitL1",
    "title": "Fitting Exact Conditional Logistic Regression with Lasso and\nElastic Net Penalties",
    "description": "Tools for the fitting and cross validation of exact conditional logistic regression models with lasso and elastic net penalties. Uses cyclic coordinate descent and warm starts to compute the entire path efficiently.",
    "version": "1.5",
    "maintainer": "Stephen Reid <sreid1652@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10374,
    "package_name": "clordr",
    "title": "Composite Likelihood Inference and Diagnostics for Replicated\nSpatial Ordinal Data",
    "description": "Composite likelihood parameter estimate and asymptotic covariance matrix are calculated for the spatial ordinal data with replications, where spatial ordinal response with covariate and both spatial exponential covariance within subject and independent and identically distributed measurement error.  Parameter estimation can be performed by either solving the gradient function or maximizing composite log-likelihood. Parametric bootstrapping is used to estimate the Godambe information matrix and hence the asymptotic standard error and covariance matrix with parallel processing option. Moreover, the proposed surrogate residual, which extends the results of Liu and Zhang (2017) <doi: 10.1080/01621459.2017.1292915>, can act as a useful tool for model diagnostics.",
    "version": "1.7.0",
    "maintainer": "Ting Fung (Ralph) Ma <tingfung.ma@wisc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10401,
    "package_name": "clustTMB",
    "title": "Spatio-Temporal Finite Mixture Model using 'TMB'",
    "description": "Fits a spatio-temporal finite mixture model using 'TMB'.\n    Covariate, spatial and temporal random effects can be incorporated\n    into the gating formula using multinomial logistic regression, the\n    expert formula using a generalized linear mixed model framework, or\n    both.",
    "version": "0.1.0",
    "maintainer": "Andrea M. Havron <andrea.havron@noaa.gov>",
    "url": "https://github.com/Andrea-Havron/clustTMB,\nhttps://andrea-havron.github.io/clustTMB/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10416,
    "package_name": "clusterWebApp",
    "title": "Universal Clustering Analysis Platform",
    "description": "An interactive platform for clustering analysis and teaching based on the 'shiny' web application framework.\n    Supports multiple popular clustering algorithms including k-means, hierarchical clustering,\n    DBSCAN (Density-Based Spatial Clustering of Applications with Noise), PAM (Partitioning Around Medoids),\n    GMM (Gaussian Mixture Model), and spectral clustering. Users can upload datasets or use built-in ones,\n    visualize clustering results using dimensionality reduction methods such as Principal Component Analysis (PCA)\n    and t-distributed Stochastic Neighbor Embedding (t-SNE), evaluate clustering quality via silhouette plots,\n    and explore method-specific visualizations and guides. For details on implemented methods, see:\n    Reynolds (2009, ISBN:9781598296975) for GMM;\n    Luxburg (2007) <doi:10.1007/s11222-007-9033-z> for spectral clustering.",
    "version": "0.1.3",
    "maintainer": "Yijin Zhou <yijin_zhou1116@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10435,
    "package_name": "cmAnalysis",
    "title": "Process and Visualise Concept Mapping Data",
    "description": "Concept maps are versatile tools used across disciplines to enhance understanding,\n  teaching, brainstorming, and information organization. This package provides functions for\n  processing and visualizing concept mapping data, involving the sequential use of cluster analysis \n  (for sorting participants and statements), multidimensional scaling (for positioning statements \n  in a conceptual space), and visualization techniques, including point cluster maps and \n  dendrograms. The methodology and its validity are discussed in Kampen, J.K., Hageman, J.A.,\n  Breuer, M., & Tobi, H. (2025). \"The validity of concept mapping: let's call a spade a spade.\" \n  Qual Quant. <doi:10.1007/s11135-025-02351-z>.",
    "version": "1.0.1",
    "maintainer": "Jos Hageman <jos.hageman@wur.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10436,
    "package_name": "cmR",
    "title": "Analysis of Cardiac Magnetic Resonance Images",
    "description": "Computes maximum response from Cardiac Magnetic Resonance Images using spatial and voxel wise spline based Bayesian model. This is an implementation of the methods described in Schmid (2011) <doi:10.1109/TMI.2011.2109733> \"Voxel-Based Adaptive Spatio-Temporal Modelling of Perfusion Cardiovascular MRI\". IEEE TMI 30(7) p. 1305 - 1313.",
    "version": "1.1",
    "maintainer": "Volker Schmid <volker.schmid@lmu.de>",
    "url": "https://bioimaginggroup.github.io/cmr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10474,
    "package_name": "cnd",
    "title": "Create and Register Conditions",
    "description": "An interface for creating new condition generators objects.  \n    Generators are special functions that can be saved in registries and linked\n    to other functions.  Utilities for documenting your generators, and new\n    conditions is provided for package development.",
    "version": "0.1.1",
    "maintainer": "Jordan Mark Barbone <jmbarbone@gmail.com>",
    "url": "https://jmbarbone.github.io/cnd/, https://github.com/jmbarbone/cnd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10478,
    "package_name": "coFAST",
    "title": "Spatially-Aware Cell Clustering Algorithm with Cluster\nSignificant Assessment",
    "description": "A spatially-aware cell clustering algorithm is provided with cluster significance assessment. It comprises four key modules: spatially-aware cell-gene co-embedding, cell clustering, signature gene identification, and cluster significant assessment. More details can be referred to Peng Xie, et al. (2025) <doi:10.1016/j.cell.2025.05.035>.",
    "version": "0.2.0",
    "maintainer": "Wei Liu <liuweideng@gmail.com>",
    "url": "https://github.com/feiyoung/coFAST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10496,
    "package_name": "cocons",
    "title": "Covariate-Based Covariance Functions for Nonstationary Spatial\nModeling",
    "description": "Estimation, prediction, and simulation of nonstationary Gaussian process with modular covariate-based covariance functions. \n  Sources of nonstationarity, such as spatial mean, variance, geometric anisotropy, smoothness, and nugget, can be considered based on spatial characteristics. \n  An induced compact-supported nonstationary covariance function is provided, enabling fast and memory-efficient computations when handling densely sampled domains.",
    "version": "0.1.5",
    "maintainer": "Federico Blasi <federicoblasi@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10519,
    "package_name": "codep",
    "title": "Multiscale Codependence Analysis",
    "description": "Computation of Multiscale Codependence Analysis and spatial eigenvector maps.",
    "version": "1.2-4",
    "maintainer": "Guillaume Guénard <guillaume.guenard@umontreal.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10528,
    "package_name": "codyn",
    "title": "Community Dynamics Metrics",
    "description": "Univariate and multivariate temporal and spatial diversity indices, \n    rank abundance curves, and community stability measures. The functions \n    implement measures that are either explicitly temporal and include the \n    option to calculate them over multiple replicates, or spatial and include \n    the option to calculate them over multiple time points. Functions fall into \n    five categories: static diversity indices, temporal diversity indices, \n    spatial diversity indices, rank abundance curves, and community stability \n    measures. The diversity indices are temporal and spatial analogs to \n    traditional diversity indices. Specifically, the package includes functions \n    to calculate community richness, evenness and diversity at a given point in \n    space and time. In addition, it contains functions to calculate species \n    turnover, mean rank shifts, and lags in community similarity between two \n    time points. Details of the methods are available in\n    Hallett et al. (2016) <doi:10.1111/2041-210X.12569> and Avolio \n    et al. (2019) <doi:10.1002/ecs2.2881>.",
    "version": "2.0.5",
    "maintainer": "Matthew B. Jones <jones@nceas.ucsb.edu>",
    "url": "https://github.com/NCEAS/codyn/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10544,
    "package_name": "cogmapr",
    "title": "Cognitive Mapping Tools Based on Coding of Textual Sources",
    "description": "Functions for building cognitive maps based on qualitative data. Inputs are textual sources (articles, transcription of qualitative interviews of agents,...). These sources have been coded using relations and are linked to (i) a table describing the variables (or concepts) used for the coding and (ii) a table describing the sources (typology of agents, ...). Main outputs are Individual Cognitive Maps (ICM), Social Cognitive Maps (all sources or group of sources) and a list of quotes linked to relations. This package is linked to the work done during the PhD of Frederic M. Vanwindekens (CRA-W / UCL) hold the 13 of May 2014 at University of Louvain in collaboration with the Walloon Agricultural Research Centre (project MIMOSA, MOERMAN fund).",
    "version": "0.9.3",
    "maintainer": "Frédéric M. Vanwindekens <f.vanwindekens@cra.wallonie.be>",
    "url": "https://frdvnw.gitlab.io/cogmapr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10572,
    "package_name": "colocalization",
    "title": "Normalized Spatial Intensity Correlation",
    "description": "Calculate the colocalization index, NSInC, in two different ways as described in the paper (Liu et al., 2019. Manuscript submitted for publication.) for multiple-species spatial data which contain the precise locations and membership of each spatial point. The two main functions are nsinc.d() and nsinc.z(). They provide the Pearson’s correlation coefficients of signal proportions in different memberships within a concerned proximity of every signal (or every base signal if single direction colocalization is considered) across all (base) signals using two different ways of normalization. The proximity sizes could be an individual value or a range of values, where the default ranges of values are different for the two functions.",
    "version": "1.0.2",
    "maintainer": "Hui Zhang <hzhang@northwestern.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10578,
    "package_name": "colorRamp2",
    "title": "Generate Color Mapping Functions",
    "description": "A color mapping is generated according to the break values and corresponding colors.\n    Other colors are generated by interpolating in a certain color space. The functions were part\n    of the 'circlize' package <https://CRAN.R-project.org/package=circlize>.",
    "version": "0.1.0",
    "maintainer": "Zuguang Gu <z.gu@dkfz.de>",
    "url": "https://github.com/jokergoo/colorRamp2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10580,
    "package_name": "colorSpec",
    "title": "Color Calculations with Emphasis on Spectral Data",
    "description": "Calculate with spectral properties of light sources, materials, cameras, eyes, and scanners.\n    Build complex systems from simpler parts using a spectral product algebra. For light sources,\n    compute CCT, CRI, SSI, and IES TM-30 reports.  For object colors, compute optimal colors and Logvinenko coordinates.\n    Work with the standard CIE illuminants and color matching functions, and read spectra from \n    text files, including CGATS files.  Estimate a spectrum from its response. A user guide and 9 vignettes are included.",
    "version": "1.8-0",
    "maintainer": "Glenn Davis <gdavis@gluonics.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10584,
    "package_name": "colorfast",
    "title": "Fast Conversion of R Colors to Color Component Values and Native\nPacked Integer Format",
    "description": "Color values in R are often represented as strings of hexadecimal\n    colors or named colors.  This package offers fast conversion of \n    these color representations to either an array of red/green/blue/alpha values\n    or to the packed integer format used in native raster objects.  Functions\n    for conversion are also exported at the 'C' level for use in other packages.\n    This fast conversion\n    of colors is implemented using an order-preserving minimal perfect hash\n    derived from Majewski et al (1996) \"A Family of Perfect Hashing Methods\" \n    <doi:10.1093/comjnl/39.6.547>.",
    "version": "1.0.1",
    "maintainer": "Mike Cheng <mikefc@coolbutuseless.com>",
    "url": "https://github.com/coolbutuseless/colorfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10588,
    "package_name": "colorist",
    "title": "Coloring Wildlife Distributions in Space-Time",
    "description": "Color and visualize wildlife distributions in\n    space-time using raster data. In addition to enabling display of\n    sequential change in distributions through the use of small multiples,\n    'colorist' provides functions for extracting several features of\n    interest from a sequence of distributions and for visualizing those\n    features using HCL (hue-chroma-luminance) color palettes. Resulting\n    maps allow for \"fair\" visual comparison of intensity values (e.g.,\n    occurrence, abundance, or density) across space and time and can be\n    used to address questions about where, when, and how consistently a\n    species, group, or individual is likely to be found.",
    "version": "0.1.3",
    "maintainer": "Matthew Strimas-Mackey <mes335@cornell.edu>",
    "url": "https://github.com/mstrimas/colorist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10592,
    "package_name": "colorplane",
    "title": "Basic S4 Classes and Methods for Mapping Between Numeric Values\nand Colors",
    "description": "A simple set of classes and methods for mapping between scalar intensity values and colors. There is also support for layering maps on top of one another using alpha composition. ",
    "version": "0.5.0",
    "maintainer": "Bradley R Buchsbaum <brad.buchsbaum@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10642,
    "package_name": "compareAreas",
    "title": "A Shiny Gadget to compare areas across different polygons",
    "description": "What's larger -- 2000 square feet or 1800 square meters? And how large is that really? Get a handle on spatial areas.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/daranzolin/compareAreas",
    "exports": [],
    "topics": ["gis", "rstats", "rstudio-addin", "shiny"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 10674,
    "package_name": "conStruct",
    "title": "Models Spatially Continuous and Discrete Population Genetic\nStructure",
    "description": "A method for modeling genetic data as a combination of discrete\n    layers, within each of which relatedness may decay continuously with geographic\n    distance. This package contains code for running analyses (which are implemented\n    in the modeling language 'rstan') and visualizing and interpreting output. See the\n    paper for more details on the model and its utility.",
    "version": "1.0.6",
    "maintainer": "Gideon Bradburd <bradburd@umich.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10680,
    "package_name": "concaveman",
    "title": "A Very Fast 2D Concave Hull Algorithm",
    "description": "The concaveman function ports the 'concaveman' (<https://github.com/mapbox/concaveman>) library from 'mapbox'. It computes the concave polygon(s) for one or several set of points.",
    "version": "1.2.0",
    "maintainer": "Joël Gombin <joel.gombin@gmail.com>",
    "url": "https://joelgombin.github.io/concaveman/,\nhttps://github.com/joelgombin/concaveman/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10685,
    "package_name": "cond",
    "title": "Approximate Conditional Inference for Logistic and Loglinear\nModels",
    "description": "Implements higher order likelihood-based inference for logistic and loglinear models.",
    "version": "1.2-4",
    "maintainer": "Alessandra R. Brazzale <alessandra.brazzale@unipd.it>",
    "url": "https://www.r-project.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10751,
    "package_name": "conserveR",
    "title": "Identifying Conservation Prioritization Methods Based on Data\nAvailability",
    "description": "Helping biologists to choose the most suitable approach to link their research to conservation. After answering few questions on the data available, geographic and taxonomic scope, 'conserveR' ranks existing methods for conservation prioritization and systematic conservation planning by suitability. The methods data base of 'conserveR' contains 133 methods for conservation prioritization based on a systematic review of > 12,000 scientific publications from the fields of spatial conservation prioritization, systematic conservation planning, biogeography and ecology.",
    "version": "1.0.4",
    "maintainer": "Alexander Zizka <alexander.zizka@idiv.de>",
    "url": "https://github.com/azizka/conserveR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10759,
    "package_name": "constrainedKriging",
    "title": "Constrained, Covariance-Matching Constrained and Universal Point\nor Block Kriging",
    "description": "Provides functions for efficient computation of non-linear spatial predictions with local change of support (Hofer, C. and Papritz, A. (2011) \"constrainedKriging: An R-package for customary, constrained and covariance-matching constrained point or block kriging\" <doi:10.1016/j.cageo.2011.02.009>).  This package supplies functions for two-dimensional spatial interpolation by constrained (Cressie, N. (1993) \"Aggregation in geostatistical problems\" <doi:10.1007/978-94-011-1739-5_3>), covariance-matching constrained (Aldworth, J. and Cressie, N. (2003) \"Prediction of nonlinear spatial functionals\" <doi:10.1016/S0378-3758(02)00321-X>) and universal (external drift) Kriging for points or blocks of any shape from data with a non-stationary mean function and an isotropic weakly stationary covariance function.  The linear spatial interpolation methods, constrained and covariance-matching constrained Kriging, provide approximately unbiased prediction for non-linear target values under change of support.  This package extends the range of tools for spatial predictions available in R and provides an alternative to conditional simulation for non-linear spatial prediction problems with local change of support.",
    "version": "0.2-11",
    "maintainer": "Andreas Papritz <papritz@retired.ethz.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10768,
    "package_name": "contentid",
    "title": "An Interface for Content-Based Identifiers",
    "description": "An interface for creating, registering, and resolving content-based\n             identifiers for data management. Content-based identifiers rely on\n             the 'cryptographic' hashes to refer to the files they identify, thus,\n             anyone possessing the file can compute the identifier using a \n             well-known standard algorithm, such as 'SHA256'.  By registering\n             a URL at which the content is accessible to a public archive (such as \n             Hash Archive) or depositing data in a scientific repository such 'Zenodo',\n             'DataONE' or 'SoftwareHeritage', the content identifier can serve \n             many functions typically associated with A Digital Object Identifier\n             ('DOI').  Unlike location-based identifiers like 'DOIs', content-based\n             identifiers permit the same content to be registered in many locations.",
    "version": "0.0.19",
    "maintainer": "Carl Boettiger <cboettig@gmail.com>",
    "url": "https://github.com/cboettig/contentid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10798,
    "package_name": "convoSPAT",
    "title": "Convolution-Based Nonstationary Spatial Modeling",
    "description": "Fits convolution-based nonstationary\n    Gaussian process models to point-referenced spatial data. The nonstationary\n    covariance function allows the user to specify the underlying correlation\n    structure and which spatial dependence parameters should be allowed to\n    vary over space: the anisotropy, nugget variance, and process variance.\n    The parameters are estimated via maximum likelihood, using a local\n    likelihood approach. Also provided are functions to fit stationary spatial\n    models for comparison, calculate the Kriging predictor and standard errors,\n    and create various plots to visualize nonstationarity.",
    "version": "1.2.7",
    "maintainer": "Mark D. Risser <markdrisser@gmail.com>",
    "url": "http://github.com/markdrisser/convoSPAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10808,
    "package_name": "cope",
    "title": "Coverage Probability Excursion (CoPE) Sets",
    "description": "Provides functions to  compute and plot Coverage\n    Probability Excursion (CoPE) sets\n    for real valued functions on a 2-dimensional domain. CoPE sets are obtained\n    from repeated noisy observations of the function on the entire domain.\n    They are designed to bound the excursion\n    set of the target function at a given level from above and below with\n    a predefined probability. The target\n    function can be a parameter in spatially-indexed linear regression.\n    Support by NIH grant R01 CA157528 is gratefully acknowledged. ",
    "version": "0.2.3",
    "maintainer": "Max Sommerfeld <max.sommerfeld@mathematik.uni-goettingen.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10883,
    "package_name": "cosso",
    "title": "Fit Regularized Nonparametric Regression Models Using COSSO\nPenalty",
    "description": "The COSSO regularization method automatically\n        estimates and selects important function components by a\n        soft-thresholding penalty in the context of smoothing spline\n        ANOVA models. Implemented models include mean regression,\n        quantile regression, logistic regression and the Cox regression\n        models.",
    "version": "2.1-2",
    "maintainer": "Isaac Ray <null@stat.tamu.edu>",
    "url": "https://arxiv.org/abs/math/0702659",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10938,
    "package_name": "covidmx",
    "title": "Descarga y analiza datos de COVID-19 en México",
    "description": "Herramientas para el análisis de datos de COVID-19 en México. Descarga y analiza \n  los datos para COVID-19 de la Direccion General de Epidemiología de México (DGE) \n  <https://www.gob.mx/salud/documentos/datos-abiertos-152127>,\n  la Red de Infecciones Respiratorias Agudas Graves (Red IRAG)\n  <https://www.gits.igg.unam.mx/red-irag-dashboard/reviewHome> y la Iniciativa Global \n  para compartir todos los datos de influenza (GISAID)\n  <https://gisaid.org/>. \n  English: Downloads and analyzes data  of COVID-19 from the  Mexican General \n  Directorate of Epidemiology (DGE), the Network of \n  Severe Acute Respiratory  Infections (IRAG network),and the Global \n  Initiative on Sharing All Influenza Data GISAID.",
    "version": "0.7.7",
    "maintainer": "Rodrigo Zepeda-Tello <rzepeda17@gmail.com>",
    "url": "https://github.com/RodrigoZepeda/covidmx,\nhttps://rodrigozepeda.github.io/covidmx/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10963,
    "package_name": "cpfa",
    "title": "Classification with Parallel Factor Analysis",
    "description": "Classification using Richard A. Harshman's Parallel Factor Analysis-1 (Parafac) model or Parallel Factor Analysis-2 (Parafac2) model fit to a three-way or four-way data array. See Harshman and Lundy (1994): <doi:10.1016/0167-9473(94)90132-5>. Uses component weights from one mode of a Parafac or Parafac2 model as features to tune parameters for one or more classification methods via a k-fold cross-validation procedure. Allows for constraints on different tensor modes. Supports penalized logistic regression, support vector machine, random forest, feed-forward neural network, regularized discriminant analysis, and gradient boosting machine. Supports binary and multiclass classification. Predicts class labels or class probabilities and calculates multiple classification performance measures. Implements parallel computing via the 'parallel', 'doParallel', and 'doRNG' packages.",
    "version": "1.2-4",
    "maintainer": "Matthew A. Asisgress <mattgress@protonmail.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10983,
    "package_name": "cpr",
    "title": "Control Polygon Reduction",
    "description": "Implementation of the Control Polygon Reduction and Control Net\n    Reduction methods for finding parsimonious B-spline regression models.",
    "version": "0.4.1",
    "maintainer": "Peter DeWitt <dewittpe@gmail.com>",
    "url": "https://github.com/dewittpe/cpr/, http://www.peteredewitt.com/cpr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 10989,
    "package_name": "cpsvote",
    "title": "A Toolbox for Using the CPS’s Voting and Registration Supplement",
    "description": "Provides automated methods for downloading, recoding, and merging \n    selected years of the Current Population Survey's Voting and Registration \n    Supplement, a large N national survey about registration, voting, and \n    non-voting in United States federal elections. Provides documentation for \n    appropriate use of sample weights to generate statistical estimates, \n    drawing from Hur & Achen (2013) <doi:10.1093/poq/nft042> and McDonald (2018) \n    <http://www.electproject.org/home/voter-turnout/voter-turnout-data>.",
    "version": "0.1.0",
    "maintainer": "Jay Lee <jaylee@reed.edu>",
    "url": "https://github.com/Reed-EVIC/cpsvote",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11006,
    "package_name": "crawdad",
    "title": "CRAWDAD: Cell Relationship Analysis Workflow Done Across Distances",
    "description": "Here we present CRAWDAD, a workflow for statistically evaluating the spatial colocalization or separation of neighboring cell types and distinguishes between different cell-type colocalization patterns that vary across spatial scales. The workflow is demonstrated on simulated and real tissue data and is shown to be capable of detecting known cell type colocalizations as well as identifying novel spatial relationships. CRAWDAD is expected to facilitate the identification and characterization of cell colocalization relationships in complex tissues to advance our understanding of the relationship between cell-type organization and tissue function.",
    "version": "1.0.1",
    "maintainer": "",
    "url": "https://github.com/JEFworks-Lab/CRAWDAD",
    "exports": [],
    "topics": ["proteomics", "spatial-analysis", "spatial-omics", "transcriptomics"],
    "score": "NA",
    "stars": 39
  },
  {
    "id": 11027,
    "package_name": "crimedatasets",
    "title": "A Comprehensive Collection of Crime-Related Datasets",
    "description": "A comprehensive collection of datasets exclusively focused on crimes, criminal activities, and related topics. \n    This package serves as a valuable resource for researchers, analysts, and students interested in crime analysis, \n    criminology, social and economic studies related to criminal behavior. Datasets span global and local contexts, \n    with a mix of tabular and spatial data.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "url": "https://github.com/lightbluetitan/crimedatasets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11043,
    "package_name": "crm12Comb",
    "title": "Phase I/II CRM Based Drug Combination Design",
    "description": "Implements the adaptive designs for integrated phase I/II trials of drug combinations via continual reassessment method (CRM) to evaluate toxicity and efficacy simultaneously for each enrolled patient cohort based on Bayesian inference. It supports patients assignment guidance in a single trial using current enrolled data, as well as conducting extensive simulation studies to evaluate operating characteristics before the trial starts. It includes various link functions such as empiric, one-parameter logistic, two-parameter logistic, and hyperbolic tangent, as well as considering multiple prior distributions of the parameters like normal distribution, gamma distribution and exponential distribution to accommodate diverse clinical scenarios. Method using Bayesian framework with empiric link function is described in: Wages and Conaway (2014) <doi:10.1002/sim.6097>.",
    "version": "0.1.11",
    "maintainer": "Junying Wang <junying.wang@stonybrook.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11054,
    "package_name": "cropDemand",
    "title": "Spatial Crop Water Demand for Brazil",
    "description": "Estimation of crop water demand can be processed via this package. As example, the data  from 'TerraClimate' dataset (<https://www.climatologylab.org/terraclimate.html>) calibrated with automatic weather stations of National Meteorological Institute of Brazil is available in a coarse spatial resolution to do the crop water demand. However, the user have also the option to download the variables directly from 'TerraClimate' repository with the download.terraclimate function  and access the original 'TerraClimate' products. If the user believes that is necessary calibrate the variables, there is another function to do it. Lastly, the estimation of the crop water demand present in this package can be run for all the Brazilian territory with 'TerraClimate' dataset. ",
    "version": "1.0.3",
    "maintainer": "Roberto Filgueiras <betofilgueiras@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11082,
    "package_name": "crsmeta",
    "title": "Extract Coordinate System Metadata",
    "description": "Obtain coordinate system metadata from various data formats. There \n are functions to extract a 'CRS' (coordinate reference system, \n <https://en.wikipedia.org/wiki/Spatial_reference_system>) in 'EPSG' (European \n Petroleum Survey Group, <http://www.epsg.org/>), 'PROJ4' <https://proj.org/>, \n or 'WKT2' (Well-Known Text 2, \n <http://docs.opengeospatial.org/is/12-063r5/12-063r5.html>) forms. This is \n purely for getting simple metadata from in-memory formats, please use other \n tools for out of memory data sources. ",
    "version": "0.3.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/crsmeta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11085,
    "package_name": "crsuggest",
    "title": "Obtain Suggested Coordinate Reference System Information for\nSpatial Data",
    "description": "Uses data from the 'EPSG' Registry to look up suitable coordinate reference \n    system transformations for spatial datasets in R.  Returns a data frame with 'CRS' codes\n    that can be used for 'CRS' transformation and mapping projects.  Please see \n    the 'EPSG' Dataset Terms of Use at <https://epsg.org/terms-of-use.html> for more information.",
    "version": "0.4",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11102,
    "package_name": "csa",
    "title": "A Cross-Scale Analysis Tool for Model-Observation Visualization\nand Integration",
    "description": "Integration of Earth system data from various sources is a challenging task. Except for their qualitative heterogeneity, different data records exist for describing similar Earth system process at different spatio-temporal scales. Data inter-comparison and validation are usually performed at a single spatial or temporal scale, which could hamper the identification of potential discrepancies in other scales. 'csa' package offers a simple, yet efficient, graphical method for synthesizing and comparing observed and modelled data across a range of spatio-temporal scales. Instead of focusing at specific scales, such as annual means or original grid resolution, we examine how their statistical properties change across spatio-temporal continuum.  ",
    "version": "0.7.1",
    "maintainer": "Yannis Markonis <imarkonis@gmail.com>",
    "url": "https://github.com/imarkonis/csa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11110,
    "package_name": "cshapes",
    "title": "The CShapes 2.0 Dataset and Utilities",
    "description": "Package for CShapes 2.0, a GIS dataset of country borders (1886-today). Includes functions for data extraction and the computation of distance matrices and -lists.",
    "version": "2.0",
    "maintainer": "Luc Girardin <luc.girardin@ethz.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11119,
    "package_name": "csquares",
    "title": "Concise Spatial Query and Representation System (c-Squares)",
    "description": "Encode and decode c-squares, from and to simple feature (sf)\n    or spatiotemporal arrays (stars) objects. Use c-squares codes to quickly\n    join or query spatial data.",
    "version": "0.1.0",
    "maintainer": "Pepijn de Vries <pepijn.devries@outlook.com>",
    "url": "https://pepijn-devries.github.io/csquares/,\nhttps://github.com/pepijn-devries/csquares/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11140,
    "package_name": "ctl",
    "title": "Correlated Trait Locus Mapping",
    "description": "Identification and network inference of genetic loci associated\n  with correlation changes in quantitative traits (called correlated trait loci, CTLs).\n  Arends et al. (2016) <doi:10.21105/joss.00087>.",
    "version": "1.0.0-10",
    "maintainer": "Danny Arends <Danny.Arends@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11142,
    "package_name": "ctmcmove",
    "title": "Modeling Animal Movement with Continuous-Time Discrete-Space\nMarkov Chains",
    "description": "Software to facilitates taking movement data in xyt format and pairing it with raster covariates within a continuous time Markov chain (CTMC) framework.  As described in Hanks et al. (2015) <DOI:10.1214/14-AOAS803> , this allows flexible modeling of movement in response to covariates (or covariate gradients) with model fitting possible within a Poisson GLM framework. ",
    "version": "1.2.10",
    "maintainer": "Ephraim Hanks <hanks@psu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11164,
    "package_name": "cubeview",
    "title": "View 3D Raster Cubes Interactively",
    "description": "Creates a 3D data cube view of a RasterStack/Brick, typically a \n    collection/array of RasterLayers (along z-axis) with the same geographical \n    extent (x and y dimensions) and resolution, provided by package 'raster'. \n    Slices through each dimension (x/y/z), freely adjustable in location, \n    are mapped to the visible sides of the cube. The cube can be freely rotated. \n    Zooming and panning can be used to focus on different areas of the cube.",
    "version": "0.4.1",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11176,
    "package_name": "curephEM",
    "title": "NPMLE for Logistic-Cox Cure-Rate Model",
    "description": "Expectation-Maximization (EM) algorithm for point estimation and variance estimation to\n    the nonparametric maximum likelihood estimator (NPMLE) for \n    logistic-Cox cure-rate model with left truncation and right-\n    censoring. See Hou, Chambers and Xu (2017) <doi:10.1007/s10985-017-9415-2>. ",
    "version": "0.3.2",
    "maintainer": "Jue Hou <hou00123@umn.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11180,
    "package_name": "currencyapi",
    "title": "Client for the 'currencyapi.com' Currency Conversion API",
    "description": "An R client for the 'currencyapi.com' currency conversion API. The API requires registration of an API key. Basic features are free, some require a paid subscription. You can find the full API documentation at <https://currencyapi.com/docs> .",
    "version": "0.1.0",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://currencyapi.com, https://currencyapi.com/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11182,
    "package_name": "currr",
    "title": "Apply Mapping Functions in Frequent Saving",
    "description": "Implementations of the family of map() functions with frequent saving of the intermediate results. The contained functions let you start the evaluation of the iterations where you stopped  (reading the already evaluated ones from cache), and work with the currently evaluated iterations while remaining ones are running in a background job. Parallel computing is also easier with the workers parameter.",
    "version": "0.1.2",
    "maintainer": "Marcell Granat <granat.marcell@uni-neumann.hu>",
    "url": "https://github.com/MarcellGranat/currr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11191,
    "package_name": "cusp",
    "title": "Cusp-Catastrophe Model Fitting Using Maximum Likelihood",
    "description": "Cobb's maximum likelihood method for cusp-catastrophe modeling\n        (Grasman, van der Maas, and Wagenmakers (2009) <doi:10.18637/jss.v032.i08>;\n        Cobb (1981), Behavioral Science, 26(1), 75-78). Includes a cusp() function for model \n        fitting, and several utility functions for plotting, and for comparing the\n        model to linear regression and logistic curve models.",
    "version": "2.3.8",
    "maintainer": "Raoul P. P. P. Grasman <rgrasman@uva.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11199,
    "package_name": "cutoff",
    "title": "Seek the Significant Cutoff Value",
    "description": "Seek the significant cutoff value for a continuous variable, which will \n    be transformed into a classification, for linear regression, \n    logistic regression, logrank analysis and cox regression. First of all, \n    all combinations will be gotten by combn() function. Then n.per argument, \n    abbreviated of total number percentage, will be used to remove the combination \n    of smaller data group. In logistic, Cox regression and logrank analysis, \n    we will also use p.per argument, patient percentage, to filter the lower \n    proportion of patients in each group. Finally, p value in regression \n    results will be used to get the significant combinations and output \n    relevant parameters. In this package, there is no limit to the number of \n    cutoff points, which can be 1, 2, 3 or more. Still, we provide 2 methods, \n    typical Bonferroni and Duglas G (1994) <doi: 10.1093/jnci/86.11.829>, to \n    adjust the p value, Missing values will be deleted by na.omit() function \n    before analysis.",
    "version": "1.3",
    "maintainer": "Jing Zhang <zj391120@163.com>",
    "url": "https://github.com/yikeshu0611/cutoff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11228,
    "package_name": "cyclotomic",
    "title": "The Field of Cyclotomic Numbers",
    "description": "The cyclotomic numbers are complex numbers that can be\n    thought of as the rational numbers extended with the roots of unity. They\n    are represented exactly, enabling exact computations. They contain the\n    Gaussian rationals (complex numbers with rational real and imaginary\n    parts) as well as the square roots of all rational numbers. They also\n    contain the sine and cosine of all rational multiples of pi. The\n    algorithms implemented in this package are taken from the 'Haskell'\n    package 'cyclotomic', whose algorithms are adapted from code by Martin\n    Schoenert and Thomas Breuer in the 'GAP' project\n    (<https://www.gap-system.org/>). Cyclotomic numbers have applications in\n    number theory, algebraic geometry, algebraic number theory, coding \n    theory, and in the theory of graphs and combinatorics. They have \n    connections to the theory of modular functions and modular curves.",
    "version": "1.3.0",
    "maintainer": "Stéphane Laurent <laurent_step@outlook.fr>",
    "url": "https://github.com/stla/cyclotomic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11258,
    "package_name": "dGAselID",
    "title": "Genetic Algorithm with Incomplete Dominance for Feature\nSelection",
    "description": "Feature selection from high dimensional data using a diploid\n    genetic algorithm with Incomplete Dominance for genotype to phenotype mapping\n    and Random Assortment of chromosomes approach to recombination.",
    "version": "1.2",
    "maintainer": "Nicolae Teodor Melita <nt_melita@yahoo.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11263,
    "package_name": "dPCP",
    "title": "Automated Analysis of Multiplex Digital PCR Data",
    "description": "The automated clustering and quantification of the digital PCR\n            data is based on the combination of 'DBSCAN' (Hahsler et al. (2019)\n            <doi:10.18637/jss.v091.i01>) and 'c-means' (Bezdek et al. (1981) \n            <doi:10.1007/978-1-4757-0450-1>) algorithms.\n            The analysis is independent of multiplexing geometry, dPCR system, \n            and input amount.\n            The details about input data and parameters are available in the\n            vignette. ",
    "version": "2.0.1",
    "maintainer": "Alfonso De Falco <alfonsodefalco90@gmail.com>",
    "url": "https://github.com/alfodefalco/dPCP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11290,
    "package_name": "dagirlite",
    "title": "Spatial Vector Data for Danmarks Administrative Geografiske\nInddeling DAGI",
    "description": "Compressed spatial vector data originally from <https://dawadocs.dataforsyningen.dk/> saved as Simple \n    Features, SF, objects with data on population, age and gender from Statistics Denmark <https://www.dst.dk/da/>.",
    "version": "0.1.0",
    "maintainer": "Lars Boerty <lars.borty@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11299,
    "package_name": "damAOI",
    "title": "Create an 'Area of Interest' Around a Constructed Dam for\nComparative Impact Evaluations",
    "description": "Define a spatial 'Area of Interest' (AOI) around a constructed dam using hydrology data.\n  Dams have environmental and social impacts, both positive and negative.\n  Current analyses of dams have no consistent way to specify at what spatial extent we should evaluate these impacts.\n  'damAOI' implements methods to adjust reservoir polygons to match satellite-observed surface water areas, plot upstream and downstream rivers using elevation data and accumulated river flow, and draw buffers clipped by river basins around reservoirs and relevant rivers. \n  This helps to consistently determine the areas which could be impacted by dam construction, facilitating comparative analysis and informed infrastructure investments.",
    "version": "0.1",
    "maintainer": "Chris Littleboy <chris.littleboy@stir.ac.uk>",
    "url": "https://github.com/chrislittleboy/damaoi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11306,
    "package_name": "daqapo",
    "title": "Data Quality Assessment for Process-Oriented Data",
    "description": "Provides a variety of methods to identify data quality issues in process-oriented data, which are useful to verify data quality in a process mining context. Builds on the class for activity logs implemented in the package 'bupaR'. Methods to identify data quality issues either consider each activity log entry independently (e.g. missing values, activity duration outliers,...), or focus on the relation amongst several activity log entries (e.g. batch registrations, violations of the expected activity order,...).",
    "version": "0.3.2",
    "maintainer": "Niels Martin <niels.martin@uhasselt.be>",
    "url": "https://github.com/bupaverse/daqapo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11316,
    "package_name": "dartR.spatial",
    "title": "Applying Landscape Genomic Methods on 'SNP' and 'Silicodart'\nData",
    "description": "Provides landscape genomic functions to analyse 'SNP' (single nuclear\n    polymorphism) data, such as least cost path analysis and isolation by distance. \n    Therefore each sample needs to have coordinate data attached (lat/lon) to be \n    able to run most of the functions. 'dartR.spatial' is a package that belongs\n    to the 'dartRverse' suit of packages and depends on 'dartR.base' and 'dartR.data'.",
    "version": "1.0.3",
    "maintainer": "Bernd Gruber <bernd.gruber@canberra.edu.au>",
    "url": "https://green-striped-gecko.github.io/dartR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11403,
    "package_name": "dbcsp",
    "title": "Distance-Based Common Spatial Patterns",
    "description": "A way to apply Distance-Based Common Spatial Patterns\n    (DB-CSP) techniques in different fields, both classical Common Spatial\n    Patterns (CSP) as well as DB-CSP. The method is composed of two\n    phases: applying the DB-CSP algorithm and performing a classification.\n    The main idea behind the CSP is to use a linear transform to project\n    data into low-dimensional subspace with a projection matrix, in such a\n    way that each row consists of weights for signals. This transformation\n    maximizes the variance of two-class signal matrices.The dbcsp object\n    is created to compute the projection vectors. For exploratory and\n    descriptive purpose, plot and boxplot functions can be used. Functions\n    train, predict and selectQ are implemented for the classification\n    step.",
    "version": "0.0.2.2",
    "maintainer": "Itsaso Rodríguez-Moreno <itsaso.rodriguez@ehu.eus>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11409,
    "package_name": "dblr",
    "title": "Discrete Boosting Logistic Regression",
    "description": "Trains logistic regression model by discretizing continuous variables via gradient boosting approach. The proposed method tries to achieve a tradeoff between interpretation and prediction accuracy for logistic regression by discretizing the continuous variables. The variable binning is accomplished in a supervised fashion. The model trained by this package is still a single \n  logistic regression model, but not a sequence of logistic regression models. The fitted model\n  object returned from the model training consists of two tables. One table is used to give the\n  boundaries of bins for each continuous variable as well as the corresponding coefficients,\n  and the other one is used for discrete variables. This package can also be used for binning\n  continuous variables for other statistical analysis. ",
    "version": "0.1.0",
    "maintainer": "Nailong Zhang <setseed2016@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11410,
    "package_name": "dbmss",
    "title": "Distance-Based Measures of Spatial Structures",
    "description": "Simple computation of spatial statistic functions of distance to characterize the spatial structures of mapped objects, following Marcon, Traissac, Puech, and Lang (2015) <doi:10.18637/jss.v067.c03>.\n  Includes classical functions (Ripley's K and others) and more recent ones used by spatial economists (Duranton and Overman's Kd, Marcon and Puech's M). \n  Relies on 'spatstat' for some core calculation.",
    "version": "2.11-0",
    "maintainer": "Eric Marcon <eric.marcon@agroparistech.fr>",
    "url": "https://ericmarcon.github.io/dbmss/,\nhttps://github.com/EricMarcon/dbmss/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11417,
    "package_name": "dbscan",
    "title": "Density-Based Spatial Clustering of Applications with Noise\n(DBSCAN) and Related Algorithms",
    "description": "A fast reimplementation of several density-based algorithms\n    of the DBSCAN family. Includes the clustering algorithms DBSCAN\n    (density-based spatial clustering of applications with noise) and\n    HDBSCAN (hierarchical DBSCAN), the ordering algorithm OPTICS (ordering\n    points to identify the clustering structure), shared nearest neighbor\n    clustering, and the outlier detection algorithms LOF (local outlier\n    factor) and GLOSH (global-local outlier score from hierarchies). The\n    implementations use the kd-tree data structure (from library ANN) for\n    faster k-nearest neighbor search. An R interface to fast kNN and\n    fixed-radius NN search is also provided.  Hahsler, Piekenbrock and\n    Doran (2019) <doi:10.18637/jss.v091.i01>.",
    "version": "1.2.4",
    "maintainer": "Michael Hahsler <mhahsler@lyle.smu.edu>",
    "url": "https://github.com/mhahsler/dbscan",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11465,
    "package_name": "dePlzMap",
    "title": "Create a choropleth map based on the PLZ regions of Germany",
    "description": "This package provides a function that can plot a map of Germany",
    "version": "1.0.0",
    "maintainer": "",
    "url": "https://github.com/stefan-m-lenz/dePlzMap",
    "exports": [],
    "topics": ["census-data", "choropleth", "choropleth-map", "data-visualization", "geospatial", "germany", "heatmap", "maps", "postleitzahlen", "r-package"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 11480,
    "package_name": "decido",
    "title": "Bindings for 'Mapbox' Ear Cutting Triangulation Library",
    "description": "Provides constrained triangulation of polygons. Ear cutting (or \n ear clipping) applies constrained triangulation by successively 'cutting'\n triangles from a polygon defined by path/s. Holes are supported by introducing\n a bridge segment between polygon paths. This package wraps the 'header-only' \n library 'earcut.hpp' <https://github.com/mapbox/earcut.hpp> which includes\n a reference to the method used by Held, M. (2001) <doi:10.1007/s00453-001-0028-4>. ",
    "version": "0.4.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://hypertidy.github.io/decido/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11519,
    "package_name": "deepspat",
    "title": "Deep Compositional Spatial Models",
    "description": "Deep compositional spatial models are standard spatial covariance\n             models coupled with an injective warping function of the spatial \n             domain. The warping function is constructed through a composition \n             of multiple elemental injective functions in a deep-learning \n             framework. The package implements two cases for the univariate setting; first,\n\t     when these warping functions are known up to some weights that\n\t     need to be estimated, and, second, when the weights in each layer are random.\n\t     In the multivariate setting only the former case is available.\n\t     Estimation and inference is done using `tensorflow`, which makes use of \n             graphics processing units. \n             For more details see Zammit-Mangion et al. (2022) <doi:10.1080/01621459.2021.1887741>,\n             Vu et al. (2022) <doi:10.5705/ss.202020.0156>,\n             Vu et al. (2023) <doi:10.1016/j.spasta.2023.100742>, and\n             Shao et al. (2025) <doi:10.48550/arXiv.2505.12548>.",
    "version": "0.3.1",
    "maintainer": "Quan Vu <quanvustats@gmail.com>",
    "url": "https://github.com/andrewzm/deepspat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11530,
    "package_name": "deform",
    "title": "Spatial Deformation and Dimension Expansion Gaussian Processes",
    "description": "Methods for fitting nonstationary Gaussian process models by spatial deformation, as introduced by Sampson and Guttorp (1992) <doi:10.1080/01621459.1992.10475181>, and by dimension expansion, as introduced by Bornn et al. (2012) <doi:10.1080/01621459.2011.646919>. Low-rank thin-plate regression splines, as developed in Wood, S.N. (2003) <doi:10.1111/1467-9868.00374>, are used to either transform co-ordinates or create new latent dimensions.",
    "version": "1.0.1",
    "maintainer": "Ben Youngman <b.youngman@exeter.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11539,
    "package_name": "deldir",
    "title": "Delaunay Triangulation and Dirichlet (Voronoi) Tessellation",
    "description": "Calculates the Delaunay triangulation and the Dirichlet\n\tor Voronoi tessellation (with respect to the entire plane) of\n\ta planar point set. Plots triangulations and tessellations in\n\tvarious ways.  Clips tessellations to sub-windows. Calculates\n\tperimeters of tessellations.  Summarises information about\n\tthe tiles of the tessellation.\tCalculates the centroidal\n\tVoronoi (Dirichlet) tessellation using Lloyd's algorithm.",
    "version": "2.0-4",
    "maintainer": "Rolf Turner <rolfturner@posteo.net>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11545,
    "package_name": "deltaPlotR",
    "title": "Identification of Dichotomous Differential Item Functioning\n(DIF) using Angoff's Delta Plot Method",
    "description": "The deltaPlotR package implements Angoff's Delta Plot method to detect dichotomous DIF. Several detection thresholds are included, either from multivariate normality assumption or by prior determination. Item purification is supported (Magis and Facon (2014) <doi:10.18637/jss.v059.c01>).",
    "version": "1.6",
    "maintainer": "David Magis <david.magis@ulg.ac.be>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11566,
    "package_name": "dendrometry",
    "title": "Forest Estimations and Dendrometric Computations",
    "description": "Computation of dendrometric and structural parameters from forest inventory data. The objective is to provide a user-friendly R package for researchers, ecologists, foresters, statisticians, loggers and other persons who deal with forest inventory data. The package includes advanced distribution fitting capabilities with multiple estimation methods (Maximum Likelihood, Maximum Product Spacing with ties correction methods following Cheng & Amin (1983), and Method of Moments) for probability distributions commonly used in forestry. Visualization tools with confidence bands using delta method and parametric bootstrap are provided for three-parameter Weibull distribution fitting to diameter data. Useful conversion of angle value from degree to radian, conversion from angle to slope (in percentage) and their reciprocals as well as principal angle determination are also included. Position and dispersion parameters usually found in forest studies are implemented. The package contains Fibonacci series, its extensions and the Golden Number computation. Useful references are Arcadius Y. J. Akossou, Soufianou Arzouma, Eloi Y. Attakpa, Noël H. Fonton and Kouami Kokou (2013) <doi:10.3390/d5010099>, W. Bonou, R. Glele Kakaï, A.E. Assogbadjo, H.N. Fonton, B. Sinsin (2009) <doi:10.1016/j.foreco.2009.05.032>, R. C. H. Cheng and N. A. K. Amin (1983) <doi:10.1111/j.2517-6161.1983.tb01268.x>, and R. C. H. Cheng and M. A. Stephens (1989) <doi:10.1093/biomet/76.2.385>.",
    "version": "0.0.4",
    "maintainer": "Narcisse Yehouenou <narcisstar211@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11576,
    "package_name": "densityarea",
    "title": "Polygons of Bivariate Density Distributions",
    "description": "With bivariate data, it is possible to calculate\n    2-dimensional kernel density estimates that return polygons at given\n    levels of probability. 'densityarea' returns these polygons for\n    analysis, including for calculating their area.",
    "version": "0.1.1",
    "maintainer": "Josef Fruehwald <jofrhwld@gmail.com>",
    "url": "https://github.com/JoFrhwld/densityarea,\nhttps://jofrhwld.github.io/densityarea/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11583,
    "package_name": "dentomedical",
    "title": "Publication-Ready Descriptive, Bivariate, Regression, and\nDiagnostic Accuracy Tools for Medical and Dental Data",
    "description": "The 'dentomedical' package provides a comprehensive suite of tools for\n medical and dental research. It includes automated descriptive statistics,\n bivariate analysis with intelligent test selection, logistic regression,\n and diagnostic accuracy assessment. All functions generate structured,\n publication-ready tables using 'flextable', ensuring reproducibility and\n clarity suitable for manuscripts, reports, and clinical research workflows.",
    "version": "0.1.3",
    "maintainer": "Umar Hussain <drumarhussain@gmail.com>",
    "url": "https://github.com/umarhussain-git/dentomedical",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11595,
    "package_name": "depth.plot",
    "title": "Multivariate Analogy of Quantiles",
    "description": "Could be used to obtain spatial depths, spatial ranks and outliers of multivariate random variables. Could also be used to visualize DD-plots (a multivariate generalization of QQ-plots).",
    "version": "0.1",
    "maintainer": "Somedip Karmakar <somedip@yahoo.co.in>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11613,
    "package_name": "descsuppRplots",
    "title": "Generate Plots for All Variables in Descriptive Tables",
    "description": "Visualizes variables from descriptive tables produced by\n    'descsuppR::buildDescrTbl()' using 'ggstatsplot'. It automatically\n    maps each variable to a suitable 'ggstatsplot' plotting function\n    based on the applied or suggested statistical test. Users can override\n    the automatic mapping via a named list of plot specifications. The\n    package supports grouped and ungrouped tables, and forwards additional\n    arguments to the underlying 'ggstatsplot' functions, providing quick,\n    reproducible, and customizable default visualizations for descriptive\n    summaries.",
    "version": "1.0",
    "maintainer": "Fabian Kück <fabian.kueck@med.uni-goettingen.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11668,
    "package_name": "dfr",
    "title": "Dual Feature Reduction for SGL",
    "description": "Implementation of the Dual Feature Reduction (DFR) approach for the Sparse Group Lasso (SGL) and the Adaptive Sparse Group Lasso (aSGL) (Feser and Evangelou (2024) <doi:10.48550/arXiv.2405.17094>). The DFR approach is a feature reduction approach that applies strong screening to reduce the feature space before optimisation, leading to speed-up improvements for fitting SGL (Simon et al. (2013) <doi:10.1080/10618600.2012.681250>) and aSGL (Mendez-Civieta et al. (2020) <doi:10.1007/s11634-020-00413-8> and Poignard (2020) <doi:10.1007/s10463-018-0692-7>) models. DFR is implemented using the Adaptive Three Operator Splitting (ATOS) (Pedregosa and Gidel (2018) <doi:10.48550/arXiv.1804.02339>) algorithm, with linear and logistic SGL models supported, both of which can be fit using k-fold cross-validation. Dense and sparse input matrices are supported.",
    "version": "0.1.6",
    "maintainer": "Fabio Feser <ff120@ic.ac.uk>",
    "url": "https://github.com/ff1201/dfr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11705,
    "package_name": "diegr",
    "title": "Dynamic and Interactive EEG Graphics",
    "description": "Allows to visualize high-density electroencephalography (HD-EEG) data through interactive plots and animations, enabling exploratory and communicative analysis of temporal-spatial brain signals. Funder: Masaryk University (Grant No. MUNI/A/1457/2023).",
    "version": "0.1.0",
    "maintainer": "Zdeňka Geršlová <gerslovaz@math.muni.cz>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11709,
    "package_name": "difNLR",
    "title": "DIF and DDF Detection by Non-Linear Regression Models",
    "description": "Detection of differential item functioning (DIF) among dichotomously scored items and differential distractor functioning (DDF) among unscored items with non-linear regression  procedures based on generalized logistic regression models (Hladka & Martinkova, 2020, <doi:10.32614/RJ-2020-014>).",
    "version": "1.5.2-2",
    "maintainer": "Adela Hladka <hladka@cs.cas.cz>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11710,
    "package_name": "difR",
    "title": "Collection of Methods to Detect Dichotomous, Polytomous, and\nContinuous Differential Item Functioning (DIF)",
    "description": "Methods to detect differential item functioning (DIF) in dichotomous, polytomous, \n    and continuous items, using both classical and modern approaches. These include\n    Mantel-Haenszel procedures, logistic regression (including ordinal models), and\n    regularization-based methods such as LASSO. Uniform and non-uniform DIF effects\n    can be detected, and some methods support multiple focal groups. The package\n    also provides tools for anchor purification, rest score matching, effect size\n    estimation, and DIF simulation. See Magis, Beland, Tuerlinckx, and De Boeck\n    (2010, Behavior Research Methods, 42, 847–862, <doi:10.3758/BRM.42.3.847>) for\n    a general overview.",
    "version": "6.1.0",
    "maintainer": "Sebastien Beland <sebastien.beland@umontreal.ca>",
    "url": "https://github.com/343Babou/difR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11753,
    "package_name": "dipw",
    "title": "Debiased Inverse Propensity Score Weighting",
    "description": "Estimation of the average treatment effect when controlling for\n    high-dimensional confounders using debiased inverse propensity score\n    weighting (DIPW). DIPW relies on the propensity score following a sparse\n    logistic regression model, but the regression curves are not required to be\n    estimable. Despite this, our package also allows the users to estimate \n    the regression curves and take the estimated curves as input to our\n    methods. Details of the methodology can be found in Yuhao Wang and\n    Rajen D. Shah (2020) \"Debiased Inverse Propensity Score Weighting for\n    Estimation of Average Treatment Effects with High-Dimensional Confounders\"\n    <arXiv:2011.08661>. The package relies on the optimisation\n    software 'MOSEK' <https://www.mosek.com/> which must be installed separately;\n    see the documentation for 'Rmosek'. ",
    "version": "0.1.0",
    "maintainer": "Yuhao Wang <yuhaow.thu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11763,
    "package_name": "disaggregation",
    "title": "Disaggregation Modelling",
    "description": "Fits disaggregation regression models using 'TMB' ('Template Model\n    Builder'). When the response data are aggregated to polygon level but\n    the predictor variables are at a higher resolution, these models can be\n    useful. Regression models with spatial random fields. The package is \n    described in detail in Nandi et al. (2023) <doi:10.18637/jss.v106.i11>.",
    "version": "0.4.1",
    "maintainer": "Tim Lucas <timcdlucas@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11795,
    "package_name": "dispeRse",
    "title": "Simulation of Demic Diffusion with Environmental Constraints",
    "description": "Simulates demic diffusion building on models previously developed\n\tfor the expansion of Neolithic and other food-producing economies during\n\tthe Holocene (Fort et al. (2012) <doi:10.7183/0002-7316.77.2.203>, Souza et al.\n\t(2021) <doi:10.1098/rsif.2021.0499>). Growth and emigration are modelled as\n\tdensity-dependent processes using logistic growth and an asymptotic threshold\n\tmodel. Environmental and terrain layers, which can change over time, affect\n\tcarrying capacity, growth and mobility. Multiple centres of origin with\n\ttheir respective starting times can be specified.",
    "version": "1.1",
    "maintainer": "Jonas Gregorio de Souza <jonas.gregorio@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11803,
    "package_name": "dissever",
    "title": "Spatial Downscaling using the Dissever Algorithm",
    "description": "Spatial downscaling of coarse grid mapping to fine grid\n    mapping using predictive covariates and a model fitted using the 'caret'\n    package. The original dissever algorithm was published by Malone et al. \n    (2012) <doi:10.1016/j.cageo.2011.08.021>, and extended by Roudier et al.\n    (2017) <doi:10.1016/j.compag.2017.08.021>.",
    "version": "0.2-3",
    "maintainer": "Pierre Roudier <roudierp@landcareresearch.co.nz>",
    "url": "https://github.com/pierreroudier/dissever",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11808,
    "package_name": "distanceto",
    "title": "Calculate Distance to Features",
    "description": "Calculates distances from point locations to features.\n    The usual approach for eg. resource selection function analyses is to\n    generate a complete distance to features surface then sample it with your \n    observed and random points. Since these raster based approaches can be\n    pretty costly with large areas, and often lead to memory issues in R, \n    the distanceto package opts to compute these distances using\n    efficient, vector based approaches. As a helper, there's a decidedly \n    low-res raster based approach for visually inspecting your region's \n    distance surface. But the workhorse is distance_to.",
    "version": "0.0.3",
    "maintainer": "Alec L. Robitaille <robit.alec@gmail.com>",
    "url": "https://github.com/robitalec/distance-to,\nhttps://robitalec.github.io/distance-to/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11811,
    "package_name": "distcrete",
    "title": "Discrete Distribution Approximations",
    "description": "Creates discretised versions of continuous \n      distribution functions by mapping continuous values \n      to an underlying discrete grid, based on a (uniform) \n      frequency of discretisation, a valid discretisation \n      point, and an integration range. For a review of \n      discretisation methods, see \n      Chakraborty (2015) <doi:10.1186/s40488-015-0028-6>.",
    "version": "1.0.3",
    "maintainer": "Steph Locke <steph@itsalocke.com>",
    "url": "https://github.com/reconhub/distcrete",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11817,
    "package_name": "distillery",
    "title": "Method Functions for Confidence Intervals and to Distill\nInformation from an Object",
    "description": "Some very simple method functions for confidence interval calculation, bootstrap resampling aimed at atmospheric science applications, and to distill pertinent information from a potentially complex object; primarily used in common with packages extRemes and SpatialVx.  To reference this package and for a tutorial on the bootstrap functions, please see Gilleland (2020) <doi: 10.1175/JTECH-D-20-0069.1> and Gilleland (2020) <doi: 10.1175/JTECH-D-20-0070.1>.",
    "version": "1.2-2",
    "maintainer": "Eric Gilleland <eric.gilleland@colostate.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11838,
    "package_name": "distrom",
    "title": "Distributed Multinomial Regression",
    "description": "Fast distributed/parallel estimation for multinomial logistic regression via Poisson factorization and the 'gamlr' package.  For details see: Taddy (2015, AoAS), Distributed Multinomial Regression, <doi:10.48550/arXiv.1311.6139>.",
    "version": "1.0.2",
    "maintainer": "Nelson Rayl <nelsonrayl14@gmail.com>",
    "url": "https://github.com/TaddyLab/distrom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11847,
    "package_name": "diveR",
    "title": "Easily Install and Load Interactive Data Visualization Tools",
    "description": "A suite of 'loon' related packages providing data analytic tools for \n    Direct Interactive Visual Exploration in R ('diveR').\n    These tools work with and complement those of the 'tidyverse' suite, \n    extending the grammar of 'ggplot2' to become a grammar of interactive\n    graphics.\n    The suite provides many visual tools designed for moderately (100s of variables)\n    high dimensional data analysis, through 'zenplots' and novel tools in 'loon', and\n    extends the 'ggplot2' grammar to provide parallel coordinates, Andrews plots, and arbitrary \n    glyphs through 'ggmulti'.\n    The  'diveR' package gathers together and installs all these related packages\n    in a single step. ",
    "version": "0.1.2",
    "maintainer": "R. Wayne Oldford <rwoldford@uwaterloo.ca>",
    "url": "https://github.com/great-northern-diver/diver/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11856,
    "package_name": "divraster",
    "title": "Diversity Metrics Calculations for Rasterized Data",
    "description": "Alpha and beta diversity for taxonomic (TD), functional (FD),\n    and phylogenetic (PD) dimensions based on rasters. Spatial and\n    temporal beta diversity can be partitioned into replacement and\n    richness difference components. It also calculates standardized effect\n    size for FD and PD alpha diversity and the average individual traits\n    across multilayer rasters. The layers of the raster represent species,\n    while the cells represent communities. Methods details can be found at\n    Cardoso et al. 2022 <https://CRAN.R-project.org/package=BAT> and\n    Heming et al. 2023 <https://CRAN.R-project.org/package=SESraster>.",
    "version": "1.2.1",
    "maintainer": "Flávio M. M. Mota <flaviomoc@gmail.com>",
    "url": "https://github.com/flaviomoc/divraster,\nhttps://flaviomoc.github.io/divraster/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11857,
    "package_name": "divseg",
    "title": "Calculate Diversity and Segregation Indices",
    "description": "Implements common measures of diversity and spatial segregation. This package has tools to compute the majority of measures are reviewed in Massey and Denton (1988) <doi:10.2307/2579183>. Multiple common measures of within-geography diversity are implemented as well. All functions operate on data frames with a 'tidyselect' based workflow.",
    "version": "0.1.0",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/christopherkenny/divseg/,\nhttps://christophertkenny.com/divseg/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11858,
    "package_name": "divvy",
    "title": "Spatial Subsampling of Biodiversity Occurrence Data",
    "description": "Divide taxonomic occurrence data into geographic regions of fair\n    comparison, with three customisable methods to standardise area and extent.\n    Calculate common biodiversity and range-size metrics on subsampled data.\n    Background theory and practical considerations for the methods are described\n    in Antell and others (2024) <doi:10.1017/pab.2023.36>.",
    "version": "1.0.1",
    "maintainer": "Gawain Antell <gawainantell@gmail.com>",
    "url": "https://gawainantell.github.io/divvy/,\nhttps://github.com/GawainAntell/divvy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11859,
    "package_name": "dixon",
    "title": "Nearest Neighbour Contingency Table Analysis",
    "description": "Function to test spatial segregation and association based in contingency table analysis of nearest neighbour counts following Dixon (2002) <doi:10.1080/11956860.2002.11682700>. Some 'Fortran' code has been included to the original dixon2002() function of the 'ecespa' package to improve speed.",
    "version": "0.0-10",
    "maintainer": "Marcelino de la Cruz Rot <marcelino.delacruz@urjc.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11926,
    "package_name": "dominanceanalysis",
    "title": "Dominance Analysis",
    "description": "Dominance analysis is a method that allows to compare the\n             relative importance of predictors in multiple regression models:\n             ordinary least squares, generalized linear models, \n             hierarchical linear models, beta regression and dynamic linear models. \n             The main principles and methods of \n             dominance analysis are described in\n             Budescu, D. V. (1993) <doi:10.1037/0033-2909.114.3.542> and  \n             Azen, R., & Budescu, D. V. (2003) <doi:10.1037/1082-989X.8.2.129>\n             for ordinary least squares regression. Subsequently, the extensions \n             for multivariate regression, logistic regression and\n             hierarchical linear models were described in \n             Azen, R., & Budescu, D. V. (2006) <doi:10.3102/10769986031002157>,\n             Azen, R., & Traxel, N. (2009) <doi:10.3102/1076998609332754> and\n             Luo, W., & Azen, R. (2013) <doi:10.3102/1076998612458319>,\n             respectively.",
    "version": "2.1.1",
    "maintainer": "Claudio Bustos Navarrete <clbustos@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 11949,
    "package_name": "dots",
    "title": "Dot Density Maps",
    "description": "Generate point data for representing people within spatial data. This\n  collects a suite of tools for creating simple dot density maps. Several functions \n  from different spatial packages are standardized to take the same arguments so\n  that they can be easily substituted for each other.",
    "version": "0.0.3",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/christopherkenny/dots,\nhttp://christophertkenny.com/dots/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12000,
    "package_name": "drda",
    "title": "Dose-Response Data Analysis",
    "description": "Fit logistic functions to observed dose-response continuous\n    data and evaluate goodness-of-fit measures. See Malyutina A., Tang J.,\n    and Pessia A. (2023) <doi:10.18637/jss.v106.i04>.",
    "version": "2.0.5",
    "maintainer": "Alberto Pessia <dev@albertopessia.com>",
    "url": "https://github.com/albertopessia/drda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12007,
    "package_name": "drglm",
    "title": "Fitting Linear and Generalized Linear Models in \"Divide and\nRecombine\" Approach to Large Data Sets",
    "description": "To overcome the memory limitations for fitting linear (LM) and Generalized Linear Models (GLMs) to large data sets, this package implements the Divide and Recombine (D&R) strategy. It basically divides the entire large data set into suitable subsets manageable in size and then fits model to each subset. Finally, results from each subset are aggregated to obtain the final estimate. This package also supports fitting GLMs to data sets that cannot fit into memory and provides methods for fitting GLMs under linear regression, binomial regression, Poisson regression, and multinomial logistic regression settings. Respective models are fitted using different D&R strategies as described by: Xi, Lin, and Chen (2009) <doi:10.1109/TKDE.2008.186>, Xi, Lin and Chen (2006) <doi:10.1109/TKDE.2006.196>, Zuo and Li (2018) <doi:10.4236/ojs.2018.81003>, Karim, M.R., Islam, M.A. (2019) <doi:10.1007/978-981-13-9776-9>.",
    "version": "1.1",
    "maintainer": "Md. Mahadi Hassan Nayem <mhnayem.cu.stat@outlook.com>",
    "url": "https://nayemmh.github.io/drglm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12009,
    "package_name": "drhutools",
    "title": "Political Science Academic Research Gears",
    "description": "Using these tools to simplify the research process of political science and other social sciences. The current version can create folder system for academic project in political science, calculate psychological trait scores, visualize experimental and spatial data, and set up color-blind palette, functions used in academic research of political psychology or political science in general.",
    "version": "1.0.1",
    "maintainer": "Yue Hu <yuehu@tsinghua.edu.cn>",
    "url": "https://www.drhuyue.site/software/drhutools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12024,
    "package_name": "drugDemand",
    "title": "Drug Demand Forecasting",
    "description": "Performs drug demand forecasting by modeling drug dispensing data while taking into account predicted enrollment and treatment discontinuation dates. The gap time between randomization and the first drug dispensing visit is modeled using interval-censored exponential, Weibull, log-logistic, or log-normal distributions (Anderson-Bergman (2017) <doi:10.18637/jss.v081.i12>). The number of skipped visits is modeled using Poisson, zero-inflated Poisson, or negative binomial distributions (Zeileis, Kleiber & Jackman (2008) <doi:10.18637/jss.v027.i08>). The gap time between two consecutive drug dispensing visits given the number of skipped visits is modeled using linear regression based on least squares or least absolute deviations (Birkes & Dodge (1993, ISBN:0-471-56881-3)). The number of dispensed doses is modeled using linear or linear mixed-effects models (McCulloch & Searle (2001, ISBN:0-471-19364-X)).",
    "version": "0.1.3",
    "maintainer": "Kaifeng Lu <kaifenglu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12031,
    "package_name": "ds4psy",
    "title": "Data Science for Psychologists",
    "description": "All datasets and functions required for the examples and exercises of the book \"Data Science for Psychologists\" (by Hansjoerg Neth, Konstanz University, 2025, <doi:10.5281/zenodo.7229812>), freely available at <https://bookdown.org/hneth/ds4psy/>. The book and corresponding courses introduce principles and methods of data science to students of psychology and other biological or social sciences. The 'ds4psy' package primarily provides datasets, but also functions for data generation and manipulation (e.g., of text and time data) and graphics that are used in the book and its exercises. All functions included in 'ds4psy' are designed to be explicit and instructive, rather than efficient or elegant. ",
    "version": "1.2.0",
    "maintainer": "Hansjoerg Neth <h.neth@uni.kn>",
    "url": "https://bookdown.org/hneth/ds4psy/,\nhttps://github.com/hneth/ds4psy/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12046,
    "package_name": "dsm",
    "title": "Density Surface Modelling of Distance Sampling Data",
    "description": "Density surface modelling of line transect data. A Generalized\n    Additive Model-based approach is used to calculate spatially-explicit estimates\n    of animal abundance from distance sampling (also presence/absence and strip\n    transect) data. Several utility functions are provided for model checking,\n    plotting and variance estimation.",
    "version": "2.3.4",
    "maintainer": "Laura Marshall <lhm@st-andrews.ac.uk>",
    "url": "https://github.com/DistanceDevelopment/dsm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12070,
    "package_name": "dtreg",
    "title": "Interact with Data Type Registries and Create Machine-Readable\nData",
    "description": "You can load a schema from a DTR (data type registry) as an R\n    object. Use this schema to write your data in JSON-LD (JavaScript\n    Object Notation for Linked Data) format to make it machine readable.",
    "version": "1.1.2",
    "maintainer": "Markus Stocker <markus.stocker@tib.eu>",
    "url": "https://gitlab.com/TIBHannover/lki/knowledge-loom/dtreg-r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12082,
    "package_name": "duckdbfs",
    "title": "High Performance Remote File System, Database and 'Geospatial'\nAccess Using 'duckdb'",
    "description": "Provides friendly wrappers for creating 'duckdb'-backed connections\n  to tabular datasets ('csv', parquet, etc) on local or remote file systems.\n  This mimics the behaviour of \"open_dataset\" in the 'arrow' package, \n  but in addition to 'S3' file system also generalizes to any list of 'http' URLs.",
    "version": "0.1.2",
    "maintainer": "Carl Boettiger <cboettig@gmail.com>",
    "url": "https://github.com/cboettig/duckdbfs,\nhttps://cboettig.github.io/duckdbfs/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12085,
    "package_name": "duckspatial",
    "title": "R Interface to 'DuckDB' Database with Spatial Extension",
    "description": "Fast & memory-efficient functions to analyze and manipulate large \n             spatial data data sets. It leverages the fast analytical \n             capabilities of 'DuckDB' and its spatial extension (see <https://duckdb.org/docs/stable/core_extensions/spatial/overview>) \n             while maintaining compatibility with R’s spatial data ecosystem to \n             work with spatial vector data.",
    "version": "0.9.0",
    "maintainer": "Adrián Cidre González <adrian.cidre@gmail.com>",
    "url": "https://cidree.github.io/duckspatial/,\nhttps://github.com/Cidree/duckspatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12123,
    "package_name": "dynamicSDM",
    "title": "Species Distribution and Abundance Modelling at High\nSpatio-Temporal Resolution",
    "description": "A collection of novel tools for generating species distribution and abundance models (SDM) that are dynamic through both space and time. These highly flexible functions incorporate spatial and temporal aspects across key SDM stages; including when cleaning and filtering species occurrence data, generating pseudo-absence records, assessing and correcting sampling biases and autocorrelation, extracting explanatory variables and projecting distribution patterns. Throughout, functions utilise Google Earth Engine and Google Drive to minimise the computing power and storage demands associated with species distribution modelling at high spatio-temporal resolution.",
    "version": "1.3.4",
    "maintainer": "Rachel Dobson <eerdo@leeds.ac.uk>",
    "url": "https://github.com/r-a-dobson/dynamicSDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12126,
    "package_name": "dynatop",
    "title": "An Implementation of Dynamic TOPMODEL Hydrological Model in R",
    "description": "An R implementation and enhancement of the Dynamic TOPMODEL semi-distributed hydrological model originally proposed by Beven and Freer (2001) <doi:10.1002/hyp.252>. The 'dynatop' package implements code for simulating models which can be created using the 'dynatopGIS' package.",
    "version": "0.2.4",
    "maintainer": "Paul Smith <paul@waternumbers.co.uk>",
    "url": "https://waternumbers.github.io/dynatop/,\nhttps://github.com/waternumbers/dynatop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12127,
    "package_name": "dynatopGIS",
    "title": "Algorithms for Helping Build Dynamic TOPMODEL Implementations\nfrom Spatial Data",
    "description": "A set of algorithms based on Quinn et al. (1991) <doi:10.1002/hyp.3360050106> for processing river network and digital elevation data to build implementations of Dynamic TOPMODEL, a semi-distributed hydrological model proposed in Beven and Freer (2001) <doi:10.1002/hyp.252>. The 'dynatop' package implements simulation code for Dynamic TOPMODEL based on the output of 'dynatopGIS'.",
    "version": "0.2.5",
    "maintainer": "Paul Smith <paul@waternumbers.co.uk>",
    "url": "https://waternumbers.github.io/dynatopGIS/,\nhttps://github.com/waternumbers/dynatopGIS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12149,
    "package_name": "eCAR",
    "title": "Eigenvalue CAR Models",
    "description": "Fits Leroux model in spectral domain to estimate causal spatial effect as detailed in \n             Guan, Y; Page, G.L.; Reich, B.J.; Ventrucci, M.; Yang, S; (2020) <arXiv:2012.11767>.  \n             Both the parametric and semi-parametric models are available.  The semi-parametric model \n             relies on 'INLA'.  The 'INLA' package can be obtained from <https://www.r-inla.org/>.",
    "version": "0.1.2",
    "maintainer": "Garritt L. Page <page@stat.byu.edu>",
    "url": "https://github.com/gpage2990/eCAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12157,
    "package_name": "eFCM",
    "title": "Exponential Factor Copula Model",
    "description": "Implements the exponential Factor Copula Model (eFCM) of Castro-Camilo, D. and Huser, R. (2020) for spatial extremes, with tools for dependence estimation, tail inference, and visualization. The package supports likelihood-based inference, Gaussian process modeling via Matérn covariance functions, and bootstrap uncertainty quantification. See Castro-Camilo and Huser (2020) <doi:10.1080/01621459.2019.1647842>.",
    "version": "1.0",
    "maintainer": "Mengran Li <m.li.3@research.gla.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12166,
    "package_name": "eRm",
    "title": "Extended Rasch Modeling",
    "description": "Fits Rasch models (RM), linear logistic test models (LLTM), rating scale model (RSM), linear rating scale models (LRSM), partial credit models (PCM), and linear partial credit models (LPCM).  Missing values are allowed in the data matrix.  Additional features are the ML estimation of the person parameters, Andersen's LR-test, item-specific Wald test, Martin-Loef-Test, nonparametric Monte-Carlo Tests, itemfit and personfit statistics including infit and outfit measures, ICC and other plots, automated stepwise item elimination, simulation module for various binary data matrices.",
    "version": "1.0-10",
    "maintainer": "Patrick Mair <mair@fas.harvard.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12167,
    "package_name": "eSDM",
    "title": "Ensemble Tool for Predictions from Species Distribution Models",
    "description": "A tool which allows users to create and evaluate ensembles \n    of species distribution model (SDM) predictions. \n    Functionality is offered through R functions or a GUI (R Shiny app). \n    This tool can assist users in identifying spatial uncertainties and \n    making informed conservation and management decisions. The package is \n    further described in Woodman et al (2019) <doi:10.1111/2041-210X.13283>.",
    "version": "0.4.4",
    "maintainer": "Sam Woodman <sam.woodman@noaa.gov>",
    "url": "https://github.com/swfsc/eSDM/, https://swfsc.github.io/eSDM/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12170,
    "package_name": "eadrm",
    "title": "Fitting Dose-Response Models Using an Evolutionary Algorithm",
    "description": "Fits dose-response models using an evolutionary\n    algorithm to estimate the model parameters. The procedure currently\n    can fit 3-parameter, 4-parameter, and 5-parameter log-logistic models\n    as well as exponential models. Functions are also provided to plot,\n    make predictions, and calculate confidence intervals for the resulting\n    models. For details see \"Nonlinear Dose-response Modeling of\n    High-Throughput Screening Data Using an Evolutionary Algorithm\",\n    Ma, J., Bair, E., Motsinger-Reif, A.; Dose-Response\n    18(2):1559325820926734 (2020) <doi:10.1177/1559325820926734>.",
    "version": "0.1.4",
    "maintainer": "Eric Bair <eric.bair@sciome.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12185,
    "package_name": "easyORtables",
    "title": "Easy Odds Ratio Tables",
    "description": "Creates text, 'LaTeX', Markdown, or Bootstrap-styled HTML-formatted odds ratio tables with confidence intervals for multiple logistic regression models.",
    "version": "0.0.1",
    "maintainer": "Neil Mehta <neilmhta@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12190,
    "package_name": "easySVG",
    "title": "An Easy SVG Basic Elements Generator",
    "description": "This SVG elements generator can easily generate \n    SVG elements such as rect, line, circle, ellipse, polygon, \n    polyline, text and group. Also, it can combine and \n    output SVG elements into a SVG file.",
    "version": "0.1.0",
    "maintainer": "Yuting Dai <forlynna@sjtu.edu.cn>",
    "url": "https://github.com/ytdai/easySVG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12201,
    "package_name": "easyclimate",
    "title": "Easy Access to High-Resolution Daily Climate Data for Europe",
    "description": "Get high-resolution (1 km) daily climate data (precipitation,\n    minimum and maximum temperatures) for points and polygons within\n    Europe.",
    "version": "0.2.2",
    "maintainer": "Verónica Cruz-Alonso <veronica.cral@gmail.com>",
    "url": "https://github.com/VeruGHub/easyclimate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12203,
    "package_name": "easylabel",
    "title": "Interactive Scatter Plot and Volcano Plot Labels",
    "description": "Interactive labelling of scatter plots, volcano plots and \n    Manhattan plots using a 'shiny' and 'plotly' interface. Users can hover \n    over points to see where specific points are located and click points \n    on/off to easily label them. Labels can be dragged around the plot to place \n    them optimally. Plots can be exported directly to PDF for publication. For \n    plots with large numbers of points, points can optionally be rasterized as a \n    bitmap, while all other elements (axes, text, labels & lines) are preserved \n    as vector objects. This can dramatically reduce file size for plots with \n    millions of points such as Manhattan plots, and is ideal for publication.",
    "version": "0.3.3",
    "maintainer": "Myles Lewis <myles.lewis@qmul.ac.uk>",
    "url": "https://github.com/myles-lewis/easylabel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12227,
    "package_name": "ebirdst",
    "title": "Access and Analyze eBird Status and Trends Data Products",
    "description": "Tools for accessing and analyzing eBird Status and\n    Trends Data Products\n    (<https://science.ebird.org/en/status-and-trends>). eBird\n    (<https://ebird.org/home>) is a global database of bird observations\n    collected by member of the public. eBird Status and Trends uses these\n    data to model global bird distributions, abundances, and population trends \n    at a high spatial and temporal resolution.",
    "version": "3.2023.1",
    "maintainer": "Matthew Strimas-Mackey <mes335@cornell.edu>",
    "url": "https://ebird.github.io/ebirdst/, https://github.com/ebird/ebirdst",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12239,
    "package_name": "ecespa",
    "title": "Functions for Spatial Point Pattern Analysis",
    "description": "Some wrappers, functions and data sets for for spatial point pattern analysis (mainly based on 'spatstat'), used in the book \"Introduccion al Analisis Espacial de Datos en Ecologia y Ciencias Ambientales: Metodos y Aplicaciones\" and in the papers by De la Cruz et al. (2008) <doi:10.1111/j.0906-7590.2008.05299.x> and Olano et al. (2009) <doi:10.1051/forest:2008074>.",
    "version": "1.1-18",
    "maintainer": "Marcelino de la Cruz Rot <marcelino.delacruz@urjc.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12242,
    "package_name": "echelon",
    "title": "The Echelon Analysis and the Detection of Spatial Clusters using\nEchelon Scan Method",
    "description": "Functions for the echelon analysis proposed by Myers et al. (1997) <doi:10.1023/A:1018518327329>, and the detection of spatial clusters using echelon scan method proposed by Kurihara (2003) <doi:10.20551/jscswabun.15.2_171>.",
    "version": "0.4.0",
    "maintainer": "Fumio Ishioka <fishioka@okayama-u.ac.jp>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12257,
    "package_name": "ecochange",
    "title": "Integrating Ecosystem Remote Sensing Products to Derive EBV\nIndicators",
    "description": "Essential Biodiversity Variables (EBV) are state variables with dimensions on time, space, and biological organization that document biodiversity change. Freely available ecosystem remote sensing products (ERSP) are downloaded and integrated with data for national or regional domains to derive indicators for EBV in the class ecosystem structure (Pereira et al., 2013) <doi:10.1126/science.1229931>, including horizontal ecosystem extents, fragmentation, and information-theory indices. To process ERSP, users must provide a polygon or geographic administrative data map. Downloadable ERSP include Global Surface Water (Peckel et al., 2016) <doi:10.1038/nature20584>, Forest Change (Hansen et al., 2013) <doi:10.1126/science.1244693>, and Continuous Tree Cover data (Sexton et al., 2013) <doi:10.1080/17538947.2013.786146>. ",
    "version": "2.9.3.3",
    "maintainer": "Wilson Lara Henao <wilarhen@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12260,
    "package_name": "ecodist",
    "title": "Dissimilarity-Based Functions for Ecological Analysis",
    "description": "Dissimilarity-based analysis functions including ordination and Mantel test functions, intended for use with spatial and community ecological data. The original package description is in Goslee and Urban (2007) <doi:10.18637/jss.v022.i07>, with further statistical detail in Goslee (2010) <doi:10.1007/s11258-009-9641-0>.",
    "version": "2.1.3",
    "maintainer": "Sarah Goslee <Sarah.Goslee@usda.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12284,
    "package_name": "ecospat",
    "title": "Spatial Ecology Miscellaneous Methods",
    "description": "Collection of R functions and data sets for the support of spatial ecology analyses with a focus on pre, core and post modelling analyses of species distribution, niche quantification and community assembly. Written by current and former members and collaborators of the ecospat group of Antoine Guisan, Department of Ecology and Evolution (DEE) and Institute of Earth Surface Dynamics (IDYST), University of Lausanne, Switzerland. Read Di Cola et al. (2016) <doi:10.1111/ecog.02671> for details.",
    "version": "4.1.2",
    "maintainer": "Olivier Broennimann <olivier.broennimann@unil.ch>",
    "url": "https://www.unil.ch/ecospat/home/menuguid/ecospat-resources/tools.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12287,
    "package_name": "ecostatscale",
    "title": "Statistical Scaling Functions for Ecological Systems",
    "description": "Implementation of the scaling functions presented in \"General statistical scaling laws for stability in ecological systems\" by Clark et al in Ecology Letters <DOI:10.1111/ele.13760>. Includes functions for extrapolating variability, resistance, and resilience across spatial and ecological scales, as well as a basic simulation function for producing time series, and a regression routine for generating unbiased parameter estimates. See the main text of the paper for more details.",
    "version": "1.1",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12293,
    "package_name": "ecotrends",
    "title": "Temporal Trends in Ecological Niche Models",
    "description": "Computes temporal trends in environmental suitability obtained from ecological niche models, based on a set of species presence point coordinates and predictor variables.",
    "version": "1.2",
    "maintainer": "A. Marcia Barbosa <ana.marcia.barbosa@gmail.com>",
    "url": "https://github.com/AMBarbosa/ecotrends",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12299,
    "package_name": "ed50",
    "title": "Estimate ED50 and Its Confidence Interval",
    "description": "Functions of five estimation method for ED50 (50 percent effective dose) are provided, and they are respectively\n    Dixon-Mood method (1948) <doi:10.2307/2280071>, Choi's original turning point method (1990) <doi:10.2307/2531453> and it's modified version given by\n    us, as well as logistic regression and isotonic regression. Besides, the package also supports\n    comparison between two estimation results.",
    "version": "0.1.1",
    "maintainer": "Yongbo Gan <yongbogan@whu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12300,
    "package_name": "ed50simulation",
    "title": "Estimate ED50 and Its Confidence Interval",
    "description": "Functions of five estimation method for ED50 (50 percent effective dose) are provided, and they are respectively\n    Dixon-Mood method (1948) <doi:10.2307/2280071>, Choi's original turning point method (1990) <doi:10.2307/2531453> and it's modified version given by\n    us, as well as logistic regression and isotonic regression. Besides, the package also supports\n    comparison between two estimation results.",
    "version": "0.1.1",
    "maintainer": "Fengru Wang <wangfr@whu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12314,
    "package_name": "edgeCorr",
    "title": "Spatial Edge Correction",
    "description": "Facilitates basic spatial edge correction to point pattern data.",
    "version": "1.0",
    "maintainer": "Glenna Nightingale <glenna.evans@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12382,
    "package_name": "eixport",
    "title": "Export Emissions to Atmospheric Models",
    "description": "Emissions are the mass of pollutants released into the atmosphere. Air quality models need emissions data, with spatial and temporal distribution, to represent air pollutant concentrations. This package, eixport, creates inputs for the air quality models 'WRF-Chem' Grell et al (2005) <doi:10.1016/j.atmosenv.2005.04.027>, 'MUNICH' Kim et al (2018) <doi:10.5194/gmd-11-611-2018> , 'BRAMS-SPM' Freitas et al (2005) <doi:10.1016/j.atmosenv.2005.07.017> and 'RLINE' Snyder et al (2013) <doi:10.1016/j.atmosenv.2013.05.074>. See the 'eixport' website (<https://atmoschem.github.io/eixport/>) for more information, documentations and examples. More details in Ibarra-Espinosa et al (2018) <doi:10.21105/joss.00607>.",
    "version": "0.6.2",
    "maintainer": "Sergio Ibarra-Espinosa <zergioibarra@gmail.com>",
    "url": "https://atmoschem.github.io/eixport/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12383,
    "package_name": "eks",
    "title": "Tidy and Geospatial Kernel Smoothing",
    "description": "Extensions of the kernel smoothing functions from the 'ks' package for compatibility with the tidyverse and geospatial ecosystems <doi:10.1007/s00180-024-01543-9>.",
    "version": "1.1.2",
    "maintainer": "Tarn Duong <tarn.duong@gmail.com>",
    "url": "https://www.mvstat.net/mvksa/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12413,
    "package_name": "elo",
    "title": "Ranking Teams by Elo Rating and Comparable Methods",
    "description": "A flexible framework for calculating Elo ratings and resulting\n    rankings of any two-team-per-matchup system (chess, sports leagues, 'Go',\n    etc.). This implementation is capable of evaluating a variety of matchups,\n    Elo rating updates, and win probabilities, all based on the basic Elo\n    rating system. It also includes methods to benchmark performance,\n    including logistic regression and Markov chain models.",
    "version": "3.0.2",
    "maintainer": "Ethan Heinzen <heinzen.ethan@mayo.edu>",
    "url": "https://github.com/eheinzen/elo,\nhttps://cran.r-project.org/package=elo,\nhttps://eheinzen.github.io/elo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12414,
    "package_name": "elrm",
    "title": "Exact Logistic Regression via MCMC",
    "description": "Implements a Markov Chain Monte Carlo algorithm to approximate \n\texact conditional inference for logistic regression models. Exact \n\tconditional inference is based on the distribution of the sufficient \n\tstatistics for the parameters of interest given the sufficient statistics \n\tfor the remaining nuisance parameters. Using model formula notation, users \n\tspecify a logistic model and model terms of interest for exact inference.\n\tSee Zamar et al. (2007) <doi:10.18637/jss.v021.i03> for more details. ",
    "version": "1.2.6",
    "maintainer": "David Zamar <zamar.david@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12415,
    "package_name": "elsa",
    "title": "Entropy-Based Local Indicator of Spatial Association",
    "description": "A framework that provides the methods for quantifying entropy-based local indicator of spatial association (ELSA) that can be used for both continuous and categorical data. In addition, this package offers other methods to measure local indicators of spatial associations (LISA). Furthermore, global spatial structure can be measured using a variogram-like diagram, called entrogram. For more information, please check that paper: Naimi, B., Hamm, N. A., Groen, T. A., Skidmore, A. K., Toxopeus, A. G., & Alibakhshi, S. (2019) <doi:10.1016/j.spasta.2018.10.001>.",
    "version": "1.1-28",
    "maintainer": "Babak Naimi <naimi.b@gmail.com>",
    "url": "http://r-gis.net",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12420,
    "package_name": "emailvalidation",
    "title": "Client for the 'emailalvalidation.io' E-Mail Validation API",
    "description": "An R client for the 'emailvalidation.io' e-mail verification API. The API requires registration of an API key. Basic features are free, some require a paid subscription. You can find the full API documentation at <https://emailvalidation.io/docs> .",
    "version": "0.1.0",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://emailvalidation.io, https://emailvalidation.io/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12426,
    "package_name": "emdbook",
    "title": "Support Functions and Data for \"Ecological Models and Data\"",
    "description": "Auxiliary functions and data sets for \"Ecological Models and Data\", a book presenting maximum likelihood estimation and related topics for ecologists (ISBN 978-0-691-12522-0).",
    "version": "1.3.14",
    "maintainer": "Ben Bolker <bolker@mcmaster.ca>",
    "url": "https://math.mcmaster.ca/bolker/emdbook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12427,
    "package_name": "emdi",
    "title": "Estimating and Mapping Disaggregated Indicators",
    "description": "Functions that support estimating, assessing and mapping regional\n    disaggregated indicators. So far, estimation methods comprise direct estimation,\n    the model-based unit-level approach Empirical Best Prediction (see \"Small area\n    estimation of poverty indicators\" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), \n    the area-level model (see \"Estimates of income for small places: An \n    application of James-Stein procedures to Census Data\" by Fay and Herriot (1979) \n    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance \n    estimation methods, log and arcsin transformation, spatial, robust and measurement \n    error models), as well as their precision estimates. The assessment of the used model\n    is supported by a summary and diagnostic plots. For a suitable presentation of\n    estimates, map plots can be easily created. Furthermore, results can easily be\n    exported to excel. For a detailed description of the package and the methods used\n    see \"The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators\" \n    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette \n    \"A Framework for Producing Small Area Estimates Based on Area-Level Models in R\".",
    "version": "2.2.3",
    "maintainer": "Soeren Pannier <soeren.pannier@fu-berlin.de>",
    "url": "https://github.com/SoerenPannier/emdi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12450,
    "package_name": "emstreeR",
    "title": "Tools for Fast Computing and Visualizing Euclidean Minimum\nSpanning Trees",
    "description": "Fast and easy computation of Euclidean Minimum Spanning Trees (EMST) from data,\n    relying on the R API for 'mlpack' - the C++ Machine Learning Library (Curtin et. al., 2013).\n    'emstreeR' uses the Dual-Tree Boruvka (March, Ram, Gray, 2010, <doi:10.1145/1835804.1835882>), \n    which is theoretically and empirically the fastest algorithm for computing an EMST. This package also provides \n    functions and an S3 method for readily visualizing Minimum Spanning Trees (MST) using either the \n    style of the 'base', 'scatterplot3d', or 'ggplot2' libraries; and functions to export the MST output to shapefiles.",
    "version": "3.1.3",
    "maintainer": "Allan Quadros <allanvcq@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12475,
    "package_name": "enmSdmX",
    "title": "Species Distribution Modeling and Ecological Niche Modeling",
    "description": "Implements species distribution modeling and ecological niche\n\tmodeling, including: bias correction, spatial cross-validation, model\n\tevaluation, raster interpolation, biotic \"velocity\" (speed and\n\tdirection of movement of a \"mass\" represented by a raster), interpolating\n\tacross a time series of rasters, and use of spatially imprecise records.\n\tThe heart of the package is a set of \"training\" functions which\n\tautomatically optimize model complexity based number of available\n\toccurrences. These algorithms include MaxEnt, MaxNet, boosted regression\n\ttrees/gradient boosting machines, generalized additive models,\n\tgeneralized linear models, natural splines, and random forests. To enhance\n\tinteroperability with other modeling packages, no new classes are created.\n\tThe package works with 'PROJ6' geodetic objects and coordinate reference\n\tsystems.",
    "version": "1.2.12",
    "maintainer": "Adam B. Smith <adam.smith@mobot.org>",
    "url": "https://github.com/adamlilith/enmSdmX",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12500,
    "package_name": "envirem",
    "title": "Generation of ENVIREM Variables",
    "description": "Generation of bioclimatic rasters that are complementary to the typical 19 bioclim variables.  ",
    "version": "3.1",
    "maintainer": "Pascal Title <pascal.title@stonybrook.edu>",
    "url": "https://github.com/ptitle/envirem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12594,
    "package_name": "eq5d",
    "title": "Methods for Analysing 'EQ-5D' Data and Calculating 'EQ-5D' Index\nScores",
    "description": "EQ-5D is a popular health related quality of life instrument used \n    in the clinical and economic evaluation of health care. Developed by the \n    EuroQol group <https://euroqol.org/>, the instrument consists of two \n    components: health state description and evaluation. For the description \n    component a subject self-rates their health in terms of five dimensions; \n    mobility, self-care, usual activities, pain/discomfort, and \n    anxiety/depression using either a three-level (EQ-5D-3L,\n    <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-3l/>) or a five-level\n    (EQ-5D-5L, <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-5l/>) \n    scale. Frequently the scores on these five dimensions are converted to a \n    single utility index using country specific value sets, which can be used\n    in the clinical and economic evaluation of health care as well as in \n    population health surveys. The eq5d package provides methods to calculate \n    index scores from a subject's dimension scores. 32 TTO and 11 VAS EQ-5D-3L\n    value sets including those for countries in Szende et al (2007) \n    <doi:10.1007/1-4020-5511-0> and Szende et al (2014) \n    <doi:10.1007/978-94-007-7596-1>, 48 EQ-5D-5L EQ-VT value sets, the \n    EQ-5D-5L crosswalk value sets developed by van Hout et al. (2012) \n    <doi:10.1016/j.jval.2012.02.008>, the crosswalk value sets for Bermuda, Jordan and \n    Russia and the van Hout (2021) reverse crosswalk value sets. 11 EQ-5D-Y3L \n    value sets are also included as are the NICE 'DSU' age-sex based EQ-5D-3L \n    to EQ-5D-5L and EQ-5D-5L to EQ-5D-3L mappings. Methods are also included \n    for the analysis of EQ-5D profiles, including those from the book \"Methods \n    for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) \n    <doi:10.1007/978-3-030-47622-9>. Additionally a shiny web tool is included \n    to enable the calculation, visualisation and automated statistical analysis \n    of EQ-5D data via a web browser using EQ-5D dimension scores stored in CSV \n    or Excel files. ",
    "version": "0.16.1",
    "maintainer": "Fraser Morton <fraser.morton@glasgow.ac.uk>",
    "url": "https://github.com/fragla/eq5d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12595,
    "package_name": "eq5dsuite",
    "title": "Handling and Analysing EQ-5d Data",
    "description": "The EQ-5D is a widely-used standarized instrument for measuring Health Related Quality Of Life (HRQOL), \n    developed by the EuroQol group <https://euroqol.org/>. It assesses five dimensions; mobility, self-care, \n    usual activities, pain/discomfort, and anxiety/depression, using either a three-level (EQ-5D-3L) or five-level (EQ-5D-5L) scale.\n    Scores from these dimensions are commonly converted into a single utility index using country-specific value sets, \n    which are critical in clinical and economic evaluations of healthcare and in population health surveys. \n    The eq5dsuite package enables users to calculate utility index values for the EQ-5D instruments, \n    including crosswalk utilities using the original crosswalk developed by van Hout et al. (2012) <doi:10.1016/j.jval.2012.02.008> \n    (mapping EQ-5D-5L responses to EQ-5D-3L index values), or the recently developed reverse crosswalk \n    by van Hout et al. (2021) <doi:10.1016/j.jval.2021.03.009> (mapping EQ-5D-3L responses\n    to EQ-5D-5L index values). Users are allowed to add and/or remove user-defined value sets. \n    Additionally, the package provides tools to analyze EQ-5D data according to the recommended \n    guidelines outlined in \"Methods for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) <doi:10.1007/978-3-030-47622-9>.",
    "version": "1.0.1",
    "maintainer": "Kim Rand <krand@mathsinhealth.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12668,
    "package_name": "estimateW",
    "title": "Estimation of Spatial Weight Matrices",
    "description": "Bayesian estimation of spatial weight matrices in spatial\n    econometric panel models. Allows for estimation of spatial\n    autoregressive (SAR), spatial error (SEM), spatial Durbin (SDM),\n    spatial error Durbin (SDEM) and spatially lagged explanatory variable\n    (SLX) type specifications featuring an unknown spatial weight matrix.\n    Methodological details are given in Krisztin and Piribauer (2022)\n    <doi:10.1080/17421772.2022.2095426>.",
    "version": "0.1.0",
    "maintainer": "Tamas Krisztin <krisztin@iiasa.ac.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12689,
    "package_name": "eudata",
    "title": "Access Data from 'GISCO'",
    "description": "Access data related to the European union from 'GISCO'\n  <https://ec.europa.eu/eurostat/web/gisco>, the Geographic Information\n  System of the European Commission, via its rest API at\n  <https://gisco-services.ec.europa.eu>.\n  This package tries to make it easier to get these data into R.",
    "version": "0.1.3",
    "maintainer": "Vilmos Prokaj <prokaj.vilmos@gmail.com>",
    "url": "https://github.com/prokaj/eudata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12690,
    "package_name": "eudract",
    "title": "Creates Safety Results Summary in XML to Upload to EudraCT, or\nClinicalTrials.gov",
    "description": "The remit of the European Clinical Trials Data Base (EudraCT <https://eudract.ema.europa.eu/> ), or ClinicalTrials.gov <https://clinicaltrials.gov/>, is to provide open access to summaries of all registered clinical trial results; thus aiming to prevent non-reporting of negative results and provide open-access to results to inform future research. The amount of information required and the format of the results, however, imposes a large extra workload at the end of studies on clinical trial units. In particular, the adverse-event-reporting component requires entering: each unique combination of treatment group and safety event; for every such event above, a further 4 pieces of information (body system, number of occurrences, number of subjects, number exposed) for non-serious events, plus an extra three pieces of data for serious adverse events (numbers of causally related events, deaths, causally related deaths). This package prepares the required statistics needed by EudraCT and formats them into the precise requirements to directly upload an XML file into the web portal, with no further data entry by hand.",
    "version": "1.1.0",
    "maintainer": "Simon Bond <simon.bond7@nhs.net>",
    "url": "https://shug0131.github.io/eudraCT/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12791,
    "package_name": "expectreg",
    "title": "Expectile and Quantile Regression",
    "description": "Expectile and quantile regression of models with nonlinear effects\n  e.g. spatial, random, ridge using least asymmetric weighed squares / absolutes\n  as well as boosting; also supplies expectiles for common distributions.",
    "version": "0.54",
    "maintainer": "Fabian Otto-Sobotka <fabian.otto-sobotka@uni-oldenburg.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12829,
    "package_name": "extraterrestrial",
    "title": "Astrobiology Equations Estimating Extraterrestrial Life",
    "description": "Finding life outside the planet Earth several is the ultimate goal of an astrobiologist. Using known astronomical measurements and assumptions the probability of extraterrestrial life existence could be estimated. Equations such as the Drake equation (1961) as stated in the paper of Molina (2019) <arXiv:1912.01783>, Seager (2013) <https://www.space.com/22648-drake-equation-alien-life-seager.html> and Foucher et al, (2017) <doi:10.3390/life7040040> are included in the 'extraterrestrial' package.",
    "version": "0.1.0",
    "maintainer": "Chester C. Deocaris <ccdeocaris@pup.edu.ph>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12853,
    "package_name": "ezTrack",
    "title": "Exploring Animal Movement Data",
    "description": "Streamlines common steps for working with animal tracking data, \n    from raw telemetry points to summaries, interactive maps, and home range \n    estimates. Designed to be beginner-friendly, it enables rapid exploration \n    of spatial and movement data with minimal wrangling, providing a unified \n    workflow for importing, summarizing, and visualizing, and analyzing animal \n    movement datasets.",
    "version": "0.1.0",
    "maintainer": "Taylor Craft <taylor.craft.mail@gmail.com>",
    "url": "https://github.com/taylorbcraft/ezTrack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12923,
    "package_name": "factorplot",
    "title": "Presenting Pairwise Comparisons",
    "description": "The tools herein calculate, print, summarize and plot pairwise differences that result from generalized linear models, general linear hypothesis tests and multinomial logistic regression models. For more information, see Armstrong (2013) <doi:10.32614/RJ-2013-021>.",
    "version": "1.3",
    "maintainer": "Dave Armstrong <davearmstrong.ps@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12980,
    "package_name": "fastLogisticRegressionWrap",
    "title": "Fast Logistic Regression Wrapper",
    "description": "Provides very fast logistic regression with coefficient inferences plus other useful methods such as a forward stepwise model generator (see the benchmarks by visiting the github page at the URL below). The inputs are flexible enough to accomodate GPU computations. The coefficient estimation employs the fastLR() method in the 'RcppNumerical' package by Yixuan Qiu et al. This package allows their work to be more useful to a wider community that consumes inference.",
    "version": "1.2.0",
    "maintainer": "Adam Kapelner <kapelner@qc.cuny.edu>",
    "url": "https://github.com/kapelner/fastLogisticRegressionWrap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 12996,
    "package_name": "fasta",
    "title": "Fast Adaptive Shrinkage/Thresholding Algorithm",
    "description": "A collection of acceleration schemes for proximal gradient methods for estimating penalized regression parameters described in\n    Goldstein, Studer, and Baraniuk (2016) <arXiv:1411.3406>. Schemes such as Fast Iterative Shrinkage and Thresholding Algorithm (FISTA) by Beck and Teboulle (2009) <doi:10.1137/080716542> \n    and the adaptive stepsize rule introduced in Wright, Nowak, and Figueiredo (2009) <doi:10.1109/TSP.2009.2016892> are included. You provide the objective function and proximal mappings, and it takes care of the issues like stepsize selection, acceleration, and stopping conditions for you.",
    "version": "0.1.0",
    "maintainer": "Eric C. Chi <ecchi1105@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13002,
    "package_name": "fastbioclim",
    "title": "Scalable and Efficient Derivation of Bioclimatic Variables",
    "description": "Provides a high-performance framework for deriving bioclimatic and custom summary variables from \n    large-scale climate raster data. The package features a dual-backend architecture that intelligently switches \n    between fast in-memory processing for smaller datasets (via the 'terra' package) and a memory-safe tiled approach \n    for massive datasets that do not fit in RAM (via 'exactextractr' and 'Rfast'). The main functions, \n    derive_bioclim() and derive_statistics(), offer a unified interface with advanced options for \n    custom time periods and static indices, making it suitable for a wide range of ecological and \n    environmental modeling applications. A software note is in preparation. In the meantime, you can visit \n    the package website <https://gepinillab.github.io/fastbioclim/> to find tutorials in English and Spanish.",
    "version": "0.3.0",
    "maintainer": "Gonzalo E. Pinilla-Buitrago <gepinillab@gmail.com>",
    "url": "https://gepinillab.github.io/fastbioclim/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13011,
    "package_name": "fastfocal",
    "title": "Fast Multiscale Raster Extraction and Moving Window Analysis\nwith FFT",
    "description": "Provides fast moving-window (\"focal\") and buffer-based extraction \n    for raster data using the 'terra' package. Automatically selects between \n    a 'C++' backend (via 'terra') and a Fast Fourier Transform (FFT) backend \n    depending on problem size. The FFT backend supports sum and mean, while \n    other statistics (e.g., median, min, max, standard deviation) are handled \n    by the 'terra' backend. Supports multiple kernel types (e.g., circle, \n    rectangle, gaussian), with NA handling consistent with 'terra' via \n    'na.rm' and 'na.policy'. Operates on 'SpatRaster' objects and returns \n    results with the same geometry.",
    "version": "0.1.3",
    "maintainer": "Ho Yi Wan <hoyiwan@gmail.com>",
    "url": "https://hoyiwan.github.io/fastfocal/,\nhttps://github.com/hoyiwan/fastfocal,\nhttps://doi.org/10.5281/zenodo.17074691",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13017,
    "package_name": "fastlogitME",
    "title": "Basic Marginal Effects for Logit Models",
    "description": "Calculates marginal effects based on logistic model objects such as 'glm' or 'speedglm' at the average (default) or at given values using finite differences. It also returns confidence intervals for said marginal effects and the p-values, which can easily be used as input in stargazer. The function only returns the essentials and is therefore much faster but not as detailed as other functions available to calculate marginal effects. As a result, it is highly suitable for large datasets for which other packages may require too much time or calculating power.",
    "version": "0.1.0",
    "maintainer": "Mathieu Steijn <m.p.a.steijn@uu.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13042,
    "package_name": "faunabr",
    "title": "Explore Catálogo Taxônomico da Fauna do Brasil Database",
    "description": "A collection of functions designed to retrieve, filter and spatialize data from the Catálogo Taxônomico da Fauna do Brasil. For more information about the dataset, please visit <http://fauna.jbrj.gov.br/fauna/listaBrasil/>.",
    "version": "1.0.0",
    "maintainer": "Weverton Trindade <wevertonf1993@gmail.com>",
    "url": "https://wevertonbio.github.io/faunabr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13060,
    "package_name": "fca",
    "title": "Floating Catchment Area (FCA) Methods to Calculate Spatial\nAccessibility",
    "description": "Perform various floating catchment area methods to calculate a\n    spatial accessibility index (SPAI) for demand point data. The distance\n    matrix used for weighting is normalized in a preprocessing step using\n    common functions (gaussian, gravity, exponential or logistic).",
    "version": "0.1.0",
    "maintainer": "Etienne Grueebler <package@etienne.app>",
    "url": "https://egrueebler.github.io/fca/,\nhttps://github.com/egrueebler/fca/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13080,
    "package_name": "fdaPDE",
    "title": "Physics-Informed Spatial and Functional Data Analysis",
    "description": "An implementation of regression models with partial differential regularizations, making use of the Finite Element Method. The models efficiently handle data distributed over irregularly shaped domains and can comply with various conditions at the boundaries of the domain. A priori information about the spatial structure of the phenomenon under study can be incorporated in the model via the differential regularization. See Sangalli, L. M. (2021) <doi:10.1111/insr.12444> \"Spatial Regression With Partial Differential Equation Regularisation\" for an overview. The release 1.1-9 requires R (>= 4.2.0) to be installed on windows machines.",
    "version": "1.1-21",
    "maintainer": "Eleonora Arnone <eleonora.arnone@polimi.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13101,
    "package_name": "fdth",
    "title": "Frequency Distribution Tables, Histograms and Polygons",
    "description": "Perform frequency distribution tables, associated histograms\n             and polygons from vector, data.frame and matrix objects for\n             numerical and categorical variables.",
    "version": "1.3-0",
    "maintainer": "J. C. Faria <joseclaudio.faria@gmail.com>",
    "url": "https://github.com/jcfaria/fdth",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13115,
    "package_name": "federalregister",
    "title": "Client Package for the U.S. Federal Register API",
    "description": "Access data from the Federal Register API <https://www.federalregister.gov/developers/api/v1>.",
    "version": "0.2.0",
    "maintainer": "Thomas J. Leeper <thosjleeper@gmail.com>",
    "url": "https://github.com/rOpenGov/federalregister",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13125,
    "package_name": "feltr",
    "title": "Access the Felt API",
    "description": "Upload, download, and edit internet maps with the Felt API \n    (<https://developers.felt.com/rest-api/getting-started>). \n    Allows users to create new maps, edit existing maps, and extract data.\n    Provides tools for working with layers, which represent geographic data, and elements,\n    which are interactive annotations. Spatial data accessed from the API is \n    transformed to work with 'sf'.",
    "version": "0.1.0",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/christopherkenny/feltr,\nhttps://christophertkenny.com/feltr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13135,
    "package_name": "fetchr",
    "title": "fetchr: Calculate Fetch Distances for Geospatial Data",
    "description": "Provides functions for fast and scalable fetch distance calculations for landwater raster or vector data.",
    "version": "1.1.1.00",
    "maintainer": "",
    "url": "https://github.com/anguswg-ucsb/fetchr",
    "exports": [],
    "topics": ["fetch", "geospatial", "r", "raster"],
    "score": "NA",
    "stars": 6
  },
  {
    "id": 13137,
    "package_name": "ff",
    "title": "Memory-Efficient Storage of Large Data on Disk and Fast Access\nFunctions",
    "description": "The ff package provides data structures that are stored on\n\tdisk but behave (almost) as if they were in RAM by transparently \n\tmapping only a section (pagesize) in main memory - the effective \n\tvirtual memory consumption per ff object. ff supports R's standard \n\tatomic data types 'double', 'logical', 'raw' and 'integer' and \n\tnon-standard atomic types boolean (1 bit), quad (2 bit unsigned), \n\tnibble (4 bit unsigned), byte (1 byte signed with NAs), ubyte (1 byte \n\tunsigned), short (2 byte signed with NAs), ushort (2 byte unsigned), \n\tsingle (4 byte float with NAs). For example 'quad' allows efficient \n\tstorage of genomic data as an 'A','T','G','C' factor. The unsigned \n\ttypes support 'circular' arithmetic. There is also support for \n\tclose-to-atomic types 'factor', 'ordered', 'POSIXct', 'Date' and \n\tcustom close-to-atomic types. \n\tff not only has native C-support for vectors, matrices and arrays \n\twith flexible dimorder (major column-order, major row-order and \n\tgeneralizations for arrays). There is also a ffdf class not unlike \n\tdata.frames and import/export filters for csv files.\n\tff objects store raw data in binary flat files in native encoding,\n\tand complement this with metadata stored in R as physical and virtual\n\tattributes. ff objects have well-defined hybrid copying semantics, \n\twhich gives rise to certain performance improvements through \n\tvirtualization. ff objects can be stored and reopened across R \n\tsessions. ff files can be shared by multiple ff R objects \n\t(using different data en/de-coding schemes) in the same process \n\tor from multiple R processes to exploit parallelism. A wide choice of \n\tfinalizer options allows to work with 'permanent' files as well as \n\tcreating/removing 'temporary' ff files completely transparent to the \n\tuser. On certain OS/Filesystem combinations, creating the ff files\n\tworks without notable delay thanks to using sparse file allocation.\n\tSeveral access optimization techniques such as Hybrid Index \n\tPreprocessing and Virtualization are implemented to achieve good \n\tperformance even with large datasets, for example virtual matrix \n\ttranspose without touching a single byte on disk. Further, to reduce \n\tdisk I/O, 'logicals' and non-standard data types get stored native and \n\tcompact on binary flat files i.e. logicals take up exactly 2 bits to \n\trepresent TRUE, FALSE and NA. \n\tBeyond basic access functions, the ff package also provides \n\tcompatibility functions that facilitate writing code for ff and ram \n\tobjects and support for batch processing on ff objects (e.g. as.ram, \n\tas.ff, ffapply). ff interfaces closely with functionality from package \n\t'bit': chunked looping, fast bit operations and coercions between \n\tdifferent objects that can store subscript information ('bit', \n\t'bitwhich', ff 'boolean', ri range index, hi hybrid index). This allows\n\tto work interactively with selections of large datasets and quickly \n\tmodify selection criteria. \n\tFurther high-performance enhancements can be made available upon request. ",
    "version": "4.5.2",
    "maintainer": "Jens Oehlschlägel <Jens.Oehlschlaegel@truecluster.com>",
    "url": "https://github.com/truecluster/ff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13138,
    "package_name": "ffaframework",
    "title": "Flood Frequency Analysis Framework",
    "description": "Tools to support systematic and reproducible workflows for both\n\tstationary and nonstationary flood frequency analysis, with applications\n\textending to other hydroclimate extremes, such as precipitation frequency\n\tanalysis. This package implements the FFA framework proposed by Vidrio-\n\tSahagún et al. (2024) <doi:10.1016/j.envsoft.2024.105940>, originally\n\tdeveloped in 'MATLAB', now adapted for the 'R' environment. This work was\n\tfunded by the Flood Hazard Identification and Mapping Program of Environment\n\tand Climate Change Canada, as well as the Canada Research Chair (Tier 1)\n\tawarded to Dr. Pietroniro.",
    "version": "0.1.2",
    "maintainer": "Riley Wheadon <rileywheadon@gmail.com>",
    "url": "https://rileywheadon.github.io/ffa-framework/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13140,
    "package_name": "ffm",
    "title": "Download Official Spatial Data from Germany",
    "description": "Provides quick and easy access to official spatial data from\n    Germany’s Federal Agency for Cartography and Geodesy (BKG) <https://gdz.bkg.bund.de/>.\n    Interfaces various web feature services (WFS) and download servers.\n    Allows retrieval, caching and filtering with a wide range of open\n    geodata products, including administrative or non-administrative boundaries,\n    land cover, elevation models, geographic names, and points of interest\n    covering Germany. Can be particularly useful for linking regional statistics\n    to their spatial representations and streamlining workflows that involve\n    spatial data of Germany.",
    "version": "0.1.1",
    "maintainer": "Jonas Lieth <jonas.lieth@gesis.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13159,
    "package_name": "fhircrackr",
    "title": "Handling HL7 FHIR® Resources in R",
    "description": "Useful tools for conveniently downloading FHIR resources in xml format \n    and converting them to R data.frames. The package uses FHIR-search to download bundles \n    from a FHIR server, provides functions to save and read xml-files containing such bundles \n    and allows flattening the bundles to data.frames using XPath expressions. FHIR® is the registered trademark \n    of HL7 and is used with the permission of HL7. Use of the FHIR trademark does not constitute endorsement of this product by HL7.",
    "version": "2.3.0",
    "maintainer": "Julia Palm <julia.palm@med.uni-jena.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13164,
    "package_name": "fido",
    "title": "Bayesian Multinomial Logistic Normal Regression",
    "description": "Provides methods for fitting and inspection of Bayesian Multinomial Logistic Normal Models using MAP estimation and Laplace Approximation as developed in Silverman et. Al. (2022) <https://www.jmlr.org/papers/v23/19-882.html>. Key functionality is implemented in C++ for scalability. 'fido' replaces the previous package 'stray'.",
    "version": "1.1.2",
    "maintainer": "Justin Silverman\n<JustinSilverman@psu.edu>",
    "url": "https://jsilve24.github.io/fido/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13165,
    "package_name": "fields",
    "title": "Tools for Spatial Data",
    "description": "For curve, surface and function fitting with an emphasis\n on splines, spatial data, geostatistics, and spatial statistics. The major\n methods\n include  Gaussian spatial process prediction (known as Kriging), cubic and thin plate splines, and compactly supported\n covariance functions for large data sets. The spline and spatial process\n methods are\n supported by functions that can determine the smoothing parameter\n (nugget and sill variance) and other covariance function parameters by cross\n validation and also by  maximum likelihood. For spatial process prediction\n there is an easy to use function that also estimates the correlation\n scale (range parameter).  A major feature is that any covariance function\n implemented in R and following a simple format can be used for\n spatial prediction. As included are fast approximations for prediction\n and conditional simulation for larger data sets.\n There are also many useful functions for plotting\n and working with spatial data as images. This package also contains\n an implementation of sparse matrix methods for large spatial data\n sets based the  R sparse matrix package spam. Use\n help(fields) to get started and for an overview. All package graphics functions\n focus on  extending base R graphics and are easy to interpret and modify.\n The fields source\n code is deliberately commented and provides useful explanations of\n numerical details as a companion to the manual pages. The commented\n source code can be viewed by expanding the source code version of this package\n and looking in the R subdirectory. The reference for fields can be generated\n by the citation function in R and has DOI <doi:10.5065/D6W957CT>. Development\n of this package was supported in part by the National Science Foundation  Grant\n 1417857,  the National Center for Atmospheric Research, and Colorado School of Mines.\n See the Fields URL\n for a vignette on using this package and some background on spatial statistics.",
    "version": "17.1",
    "maintainer": "Douglas Nychka <douglasnychka@gmail.com>",
    "url": "https://github.com/dnychka/fieldsRPackage",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13211,
    "package_name": "finnishgrid",
    "title": "'Fingrid Open Data API' R Client",
    "description": "R API client package for 'Fingrid Open Data' \n    <https://data.fingrid.fi/> on the electricity market and the power system. \n    get_data() function holds the main application logic to retrieve \n    time-series data. API calls require free user account registration.\n    Data is made available by Fingrid Oyj and distributed under\n    Creative Commons 4.0 <https://creativecommons.org/licenses/by/4.0/>.",
    "version": "0.2.0",
    "maintainer": "Markus Virtanen <markus.m.virtanen@gmail.com>",
    "url": "https://github.com/virmar/finnishgrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13231,
    "package_name": "fishboot",
    "title": "Bootstrap-Based Methods for the Study of Fish Stocks and Aquatic\nPopulations",
    "description": "A suite of bootstrap-based models and tools for analyzing fish \n  stocks and aquatic populations. Designed for ecologists and fisheries \n  scientists, it supports data from length-frequency distributions, \n  tag-and-recapture studies, and hard structure readings (e.g., otoliths). \n  See Schwamborn et al., 2019 <doi:10.1016/j.ecolmodel.2018.12.001> \n  for background. The package includes functions for bootstrapped fitting of \n  growth curves and plotting. ",
    "version": "1.0.2",
    "maintainer": "Ralf Schwamborn <ralf.schwamborn@ufpe.br>",
    "url": "https://github.com/rschwamborn/fishboot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13234,
    "package_name": "fishgrowth",
    "title": "Fit Growth Curves to Fish Data",
    "description": "Fit growth models to otoliths and/or tagging data, using the 'RTMB'\n  package and maximum likelihood. The otoliths (or similar measurements of age)\n  provide direct observed coordinates of age and length. The tagging data\n  provide information about the observed length at release and length at\n  recapture at a later time, where the age at release is unknown and estimated\n  as a vector of parameters. The growth models provided by this package can be\n  fitted to otoliths only, tagging data only, or a combination of the two.\n  Growth variability can be modelled as constant or increasing with length.",
    "version": "1.0.4",
    "maintainer": "Arni Magnusson <thisisarni@gmail.com>",
    "url": "https://github.com/arni-magnusson/fishgrowth",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13263,
    "package_name": "fixerapi",
    "title": "An R Client for the \"Fixer.io\" Currency API",
    "description": "An R client for the \"fixer.io\" currency conversion and exchange \n  rate API. The API requires registration and some features are only available \n  on paid accounts. The full API documentation is available at \n  <https://fixer.io/documentation>.",
    "version": "0.1.6",
    "maintainer": "Evan Odell <evanodell91@gmail.com>",
    "url": "https://docs.evanodell.com/fixerapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13329,
    "package_name": "flocker",
    "title": "Flexible Occupancy Estimation with Stan",
    "description": "Fit occupancy models in 'Stan' via 'brms'. The full variety\n    of 'brms' formula-based effects structures are available to use in\n    multiple classes of occupancy model, including single-season\n    models, models with data augmentation for never-observed species,\n    dynamic (multiseason) models with explicit colonization and extinction\n    processes, and dynamic models with autologistic occupancy dynamics.\n    Formulas can be specified for all relevant distributional terms,\n    including detection and one or more of occupancy, colonization,\n    extinction, and autologistic depending on the model type. Several\n    important forms of model post-processing are provided.  References:\n    Bürkner (2017) <doi:10.18637/jss.v080.i01>; Carpenter et al. (2017)\n    <doi:10.18637/jss.v076.i01>; Socolar & Mills (2023)\n    <doi:10.1101/2023.10.26.564080>.",
    "version": "1.0-0",
    "maintainer": "Jacob B. Socolar <jacob.socolar@gmail.com>",
    "url": "https://github.com/jsocolar/flocker,\nhttps://jsocolar.github.io/flocker/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13332,
    "package_name": "florabr",
    "title": "Explore Flora e Funga do Brasil Database",
    "description": "A collection of functions designed to retrieve, filter and spatialize data from the Flora e Funga do Brasil dataset. For more information about the dataset, please visit <https://floradobrasil.jbrj.gov.br/consulta/>.",
    "version": "1.3.1",
    "maintainer": "Weverton Trindade <wevertonf1993@gmail.com>",
    "url": "https://wevertonbio.github.io/florabr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13364,
    "package_name": "flowcluster",
    "title": "Cluster Origin-Destination Flow Data",
    "description": "Provides functionality for clustering\n    origin-destination (OD) pairs, representing desire lines (or flows).\n    This includes creating distance matrices between OD pairs and passing\n    distance matrices to a clustering algorithm. See the academic paper \n    Tao and Thill (2016) <doi:10.1111/gean.12100>\n    for more details on spatial clustering of flows.\n    See the paper on delineating demand-responsive operating areas\n    by Mahfouz et al. (2025) <doi:10.1016/j.urbmob.2025.100135>\n    for an example of how this package can be used to cluster flows for\n    applied transportation research.",
    "version": "0.2.1",
    "maintainer": "Hussein Mahfouz <husseinmahfouz93@gmail.com>",
    "url": "https://hussein-mahfouz.github.io/flowcluster/,\nhttps://github.com/hussein-mahfouz/flowcluster",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13382,
    "package_name": "fmds",
    "title": "Multidimensional Scaling Development Kit",
    "description": "Multidimensional scaling (MDS) functions for various tasks that are beyond the beta stage and way past the alpha stage.\n             Currently, options are available for weights, restrictions, classical scaling or principal coordinate analysis, transformations (linear, power, Box-Cox, spline, ordinal), outlier mitigation (rdop), out-of-sample estimation (predict), negative dissimilarities, fast and faster executions with low memory footprints, penalized restrictions, cross-validation-based penalty selection, supplementary variable estimation (explain), additive constant estimation, mixed measurement level distance calculation, restricted classical scaling, etc. More will come in the future.\n             References. Busing (2024) \"A Simple Population Size Estimator for Local Minima Applied to Multidimensional Scaling\". Manuscript submitted for publication.\n             Busing (2025) \"Node Localization by Multidimensional Scaling with Iterative Majorization\". Manuscript submitted for publication.\n             Busing (2025) \"Faster Multidimensional Scaling\". Manuscript in preparation.\n             Barroso and Busing (2025) \"e-RDOP, Relative Density-Based Outlier Probabilities, Extended to Proximity Mapping\". Manuscript submitted for publication.",
    "version": "0.1.5",
    "maintainer": "Frank M.T.A. Busing <busing@fsw.leidenuniv.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13385,
    "package_name": "fmesher",
    "title": "Triangle Meshes and Related Geometry Tools",
    "description": "Generate planar and spherical triangle meshes,\n    compute finite element calculations for 1-, 2-, and 3-dimensional flat\n    and curved manifolds with associated basis function spaces, methods for\n    lines and polygons, and transparent handling of coordinate reference\n    systems and coordinate transformation, including 'sf' and 'sp' geometries.\n    The core 'fmesher' library code was originally part of the 'INLA' package,\n    and implements parts of \"Triangulations and Applications\" by\n    Hjelle and Daehlen (2006) <doi:10.1007/3-540-33261-8>.",
    "version": "0.6.1",
    "maintainer": "Finn Lindgren <finn.lindgren@gmail.com>",
    "url": "https://inlabru-org.github.io/fmesher/,\nhttps://github.com/inlabru-org/fmesher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13444,
    "package_name": "forestSAS",
    "title": "Forest Spatial Structure Analysis Systems",
    "description": "Recent years have seen significant interest in neighborhood-based structural parameters that effectively represent the spatial characteristics of tree populations and forest communities, and possess strong applicability for guiding forestry practices. This package provides valuable information that enhances our understanding and analysis of the fine-scale spatial structure of tree populations and forest stands. Reference: Yan L, Tan W, Chai Z, et al (2019) <doi:10.13323/j.cnki.j.fafu(nat.sci.).2019.03.007>.",
    "version": "2.0.4",
    "maintainer": "Zongzheng Chai <chaizz@126.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13529,
    "package_name": "freecurrencyapi",
    "title": "Client for the 'freecurrencyapi.com' Currency Conversion API",
    "description": "An R client for the 'freecurrencyapi.com' currency conversion API. The API requires registration of an API key. You can find the full API documentation at <https://freecurrencyapi.com/docs> .",
    "version": "0.1.0",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://freecurrencyapi.com, https://freecurrencyapi.com/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13541,
    "package_name": "freqparcoord",
    "title": "Novel Methods for Parallel Coordinates",
    "description": "New approaches to parallel coordinates plots for\n   multivariate data visualization, including applications to clustering,\n   outlier hunting and regression diagnostics.  Includes general functions\n   for multivariate nonparametric density and regression estimation, \n   using parallel computation.  ",
    "version": "1.0.1",
    "maintainer": "Norm Matloff <normmatloff@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13577,
    "package_name": "fsr",
    "title": "Handling Fuzzy Spatial Data",
    "description": "Support for fuzzy spatial objects, their operations, and fuzzy spatial inference models based on Spatial Plateau Algebra. \n    It employs fuzzy set theory and fuzzy logic as foundation to deal with spatial fuzziness. \n    It mainly implements underlying concepts defined in the following research papers: \n    (i) \"Spatial Plateau Algebra: An Executable Type System for Fuzzy Spatial Data Types\" <doi:10.1109/FUZZ-IEEE.2018.8491565>; \n    (ii) \"A Systematic Approach to Creating Fuzzy Region Objects from Real Spatial Data Sets\" <doi:10.1109/FUZZ-IEEE.2019.8858878>; \n    (iii) \"Spatial Data Types for Heterogeneously Structured Fuzzy Spatial Collections and Compositions\" <doi:10.1109/FUZZ48607.2020.9177620>;\n    (iv) \"Fuzzy Inference on Fuzzy Spatial Objects (FIFUS) for Spatial Decision Support Systems\" <doi:10.1109/FUZZ-IEEE.2017.8015707>;\n    (v) \"Evaluating Region Inference Methods by Using Fuzzy Spatial Inference Models\" <doi:10.1109/FUZZ-IEEE55066.2022.9882658>.",
    "version": "2.0.1",
    "maintainer": "Anderson Carniel <accarniel@gmail.com>",
    "url": "https://accarniel.github.io/fsr/, https://github.com/accarniel/fsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13589,
    "package_name": "fude",
    "title": "Utilities for Fude Polygon",
    "description": "Provides utilities to facilitate handling of Fude Polygon data \n    downloadable from the Ministry of Agriculture, Forestry and Fisheries \n    website <https://open.fude.maff.go.jp>.",
    "version": "0.3.7",
    "maintainer": "Takeshi Nishimura <takenishi@gmail.com>",
    "url": "https://github.com/takeshinishimura/fude,\nhttps://takeshinishimura.github.io/fude/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13619,
    "package_name": "funkycells",
    "title": "Functional Data Analysis for Multiplexed Cell Images",
    "description": "Compare variables of interest between (potentially large\n    numbers of) spatial interactions and meta-variables. Spatial variables\n    are summarized using K, or other, functions, and projected for use in\n    a modified random forest model. The model allows comparison of\n    functional and non-functional variables to each other and to noise,\n    giving statistical significance to the results. Included are\n    preparation, modeling, and interpreting tools along with example\n    datasets, as described in VanderDoes et al., (2023)\n    <doi:10.1101/2023.07.18.549619>.",
    "version": "1.1.1",
    "maintainer": "Jeremy VanderDoes <jeremy.vanderdoes@gmail.com>",
    "url": "https://github.com/jrvanderdoes/funkycells,\nhttps://jrvanderdoes.github.io/funkycells/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13629,
    "package_name": "funspace",
    "title": "Creating and Representing Functional Trait Spaces",
    "description": "Estimation of functional spaces based on traits of organisms.\n    The package includes functions to impute missing trait values (with or\n    without considering phylogenetic information), and to create,\n    represent and analyse two dimensional functional spaces based on\n    principal components analysis, other ordination methods, or raw\n    traits. It also allows for mapping a third variable onto the\n    functional space.  See 'Carmona et al. (2021)' \n    <doi:10.1038/s41586-021-03871-y>, 'Puglielli et al.  (2021)'\n    <doi:10.1111/nph.16952>, 'Carmona et al. (2021)'\n    <doi:10.1126/sciadv.abf2675>, 'Carmona et al. (2019)'\n    <doi:10.1002/ecy.2876> for more information.",
    "version": "0.2.2",
    "maintainer": "Carlos P. Carmona <perezcarmonacarlos@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13635,
    "package_name": "furrr",
    "title": "Apply Mapping Functions in Parallel using Futures",
    "description": "Implementations of the family of map() functions from 'purrr'\n    that can be resolved using any 'future'-supported backend, e.g.\n    parallel on the local machine or distributed on a compute cluster.",
    "version": "0.3.1",
    "maintainer": "Davis Vaughan <davis@rstudio.com>",
    "url": "https://github.com/DavisVaughan/furrr,\nhttps://furrr.futureverse.org/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13664,
    "package_name": "fxl",
    "title": "'fxl' Single Case Design Charting Package",
    "description": "The 'fxl' Charting package is used to prepare and design single case design figures that are typically prepared in spreadsheet software. With 'fxl', there is no need to leave the R environment to prepare these works and many of the more unique conventions in single case experimental designs can be performed without the need for physically constructing features of plots (e.g., drawing annotations across plots). Support is provided for various different plotting arrangements (e.g., multiple baseline), annotations (e.g., brackets, arrows), and output formats (e.g., svg, rasters).",
    "version": "1.7.2",
    "maintainer": "Shawn Gilroy <sgilroy1@lsu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13689,
    "package_name": "gProfileR",
    "title": "Interface to the 'g:Profiler' Toolkit",
    "description": "This package has been deprecated and will not be updated. \n    New users should use the package 'gprofiler2' (<https://CRAN.R-project.org/package=gprofiler2>)\n    for up-to-date data and improved functionality.\n    Functional enrichment analysis, gene identifier conversion and\n    mapping homologous genes across related organisms via the 'g:Profiler' toolkit\n    (<https://biit.cs.ut.ee/gprofiler/>).",
    "version": "0.7.0",
    "maintainer": "Ivan Kuzmin <ivan.kuzmin@ut.ee>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13779,
    "package_name": "gateway",
    "title": "Tools for Working with St. Louis Spatial Data",
    "description": "Contains various tools for accessing and modifying spatial data for the",
    "version": "0.3.0.9000",
    "maintainer": "",
    "url": "https://github.com/slu-openGIS/gateway",
    "exports": [],
    "topics": ["datascience", "gis", "missouri", "opendata", "package", "r", "rstats", "saint-louis", "st-louis", "statistics"],
    "score": "NA",
    "stars": 8
  },
  {
    "id": 13796,
    "package_name": "gbm.auto",
    "title": "Automated Boosted Regression Tree Modelling and Mapping Suite",
    "description": "Automates delta log-normal boosted regression tree abundance\n    prediction. Loops through parameters provided (LR (learning rate), TC\n    (tree complexity), BF (bag fraction)), chooses best, simplifies, &\n    generates line, dot & bar plots, & outputs these & predictions & a\n    report, makes predicted abundance maps, and Unrepresentativeness\n    surfaces.  Package core built around 'gbm' (gradient boosting machine)\n    functions in 'dismo' (Hijmans, Phillips, Leathwick & Jane Elith, 2020\n    & ongoing), itself built around 'gbm' (Greenwell, Boehmke, Cunningham\n    & Metcalfe, 2020 & ongoing, originally by Ridgeway). Indebted to\n    Elith/Leathwick/Hastie 2008 'Working Guide'\n    <doi:10.1111/j.1365-2656.2008.01390.x>; workflow follows Appendix S3.\n    See <https://www.simondedman.com/> for published guides and papers\n    using this package.",
    "version": "2024.10.01",
    "maintainer": "Simon Dedman <simondedman@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13807,
    "package_name": "gcdnet",
    "title": "The (Adaptive) LASSO and Elastic Net Penalized Least Squares,\nLogistic Regression, Hybrid Huberized Support Vector Machines,\nSquared Hinge Loss Support Vector Machines and Expectile\nRegression using a Fast Generalized Coordinate Descent\nAlgorithm",
    "description": "Implements a generalized coordinate descent (GCD) algorithm\n    for computing the solution paths of the hybrid Huberized support vector\n    machine (HHSVM) and its generalizations. Supported models include the\n    (adaptive) LASSO and elastic net penalized least squares, logistic\n    regression, HHSVM, squared hinge loss SVM and expectile regression.",
    "version": "1.0.6",
    "maintainer": "Yi Yang <yi.yang6@mcgill.ca>",
    "url": "https://github.com/emeryyi/gcdnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13821,
    "package_name": "gdalUtilities",
    "title": "Wrappers for 'GDAL' Utilities Executables",
    "description": "R's 'sf' package ships with self-contained 'GDAL'\n    executables, including a bare bones interface to several\n    'GDAL'-related utility programs collectively known as the 'GDAL\n    utilities'. For each of those utilities, this package provides an\n    R wrapper whose formal arguments closely mirror those of the\n    'GDAL' command line interface. The utilities operate on data\n    stored in files and typically write their output to other\n    files. Therefore, to process data stored in any of R's more common\n    spatial formats (i.e. those supported by the 'sf' and 'terra'\n    packages), first write them to disk, then process them with the\n    package's wrapper functions before reading the outputted results\n    back into R. GDAL function arguments introduced in GDAL version\n    3.5.2 or earlier are supported.",
    "version": "1.2.5",
    "maintainer": "Joshua O'Brien <joshmobrien@gmail.com>",
    "url": "https://github.com/JoshOBrien/gdalUtilities/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13827,
    "package_name": "gdiff",
    "title": "Graphical Difference Testing",
    "description": "Functions for performing graphical difference testing.     \n             Differences are generated between raster images.\n             Comparisons can be performed between different package\n             versions and between different R versions.",
    "version": "0.2-5",
    "maintainer": "Paul Murrell <paul@stat.auckland.ac.nz>",
    "url": "https://github.com/pmur002/,\nhttps://stattech.wordpress.fos.auckland.ac.nz/2020/01/06/2020-01-visual-testing-for-graphics-in-r/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13829,
    "package_name": "gdistance",
    "title": "Distances and Routes on Geographical Grids",
    "description": "Provides classes and functions to calculate various \n             distance measures and routes in heterogeneous geographic \n             spaces represented as grids. The package implements measures\n             to model dispersal histories first presented by van Etten and\n             Hijmans (2010) <doi:10.1371/journal.pone.0012060>. Least-cost\n             distances as well as more complex distances based on (constrained)\n             random walks can be calculated. The distances implemented in \n             the package are used in geographical genetics, accessibility \n             indicators, and may also have applications in other fields of\n             geospatial analysis.",
    "version": "1.6.5",
    "maintainer": "Andrew Marx <ajm.rpackages@gmail.com>",
    "url": "https://AgrDataSci.github.io/gdistance/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13836,
    "package_name": "gdverse",
    "title": "Analysis of Spatial Stratified Heterogeneity",
    "description": "Detecting spatial associations via spatial stratified heterogeneity, accounting for spatial dependencies, interpretability, complex interactions, and robust stratification. In addition, it supports the spatial stratified heterogeneity family described in Lv et al. (2025)<doi:10.1111/tgis.70032>.",
    "version": "1.5.1",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/gdverse/, https://github.com/stscl/gdverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13839,
    "package_name": "gear",
    "title": "Geostatistical Analysis in R",
    "description": "Implements common geostatistical methods in a clean, straightforward, efficient manner. The methods are discussed in Schabenberger and Gotway (2004, <ISBN:9781584883227>) and Waller and Gotway (2004, <ISBN:9780471387718>).",
    "version": "0.3.4",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13844,
    "package_name": "geeLite",
    "title": "Building and Managing Local Databases from 'Google Earth Engine'",
    "description": "Simplifies the creation, management, and updating of local databases using data extracted from 'Google Earth Engine' ('GEE'). It integrates with 'GEE' to store, aggregate, and process spatio-temporal data, leveraging 'SQLite' for efficient, serverless storage. The 'geeLite' package provides utilities for data transformation and supports real-time monitoring and analysis of geospatial features, making it suitable for researchers and practitioners in geospatial science. For details, see Kurbucz and Andrée (2025) \"Building and Managing Local Databases from Google Earth Engine with the geeLite R Package\" <https://hdl.handle.net/10986/43165>.",
    "version": "1.0.6",
    "maintainer": "Marcell T. Kurbucz <m.kurbucz@ucl.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13857,
    "package_name": "gellipsoid",
    "title": "Generalized Ellipsoids",
    "description": "Represents generalized geometric ellipsoids with the \"(U,D)\" representation. It allows degenerate\n\tand/or unbounded ellipsoids, together with methods for linear and duality transformations, and for plotting.\n\tThus ellipsoids are naturally extended to include lines, hyperplanes, points, cylinders, etc.\n\tThis permits exploration of a variety to statistical issues that can be visualized using ellipsoids\n\tas discussed by Friendly, Fox & Monette (2013), Elliptical Insights: Understanding Statistical Methods \n\tThrough Elliptical Geometry <doi:10.1214/12-STS402>.",
    "version": "0.7.3",
    "maintainer": "Michael Friendly <friendly@yorku.ca>",
    "url": "https://github.com/friendly/gellipsoid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13905,
    "package_name": "generalhoslem",
    "title": "Goodness of Fit Tests for Logistic Regression Models",
    "description": "Functions to assess the goodness of fit of binary, multinomial and ordinal logistic models. Included are the Hosmer-Lemeshow tests (binary, multinomial and ordinal) and the Lipsitz and Pulkstenis-Robinson tests (ordinal).",
    "version": "1.3.4",
    "maintainer": "Matthew Jay <matthew.jay.15@ucl.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13922,
    "package_name": "genlogis",
    "title": "Generalized Logistic Distribution",
    "description": "Provides basic distribution functions for a generalized logistic distribution proposed by Rathie and Swamee (2006) <https://www.rroij.com/open-access/on-new-generalized-logistic-distributions-and-applicationsbarreto-fhs-mota-jma-and-rathie-pn-.pdf>. It also has an interactive 'RStudio' plot for better guessing dynamically of initial values for ease of included optimization and simulating.",
    "version": "1.0.2",
    "maintainer": "Eduardo Hellas <ehellas@gmail.com>",
    "url": "https://pinduzera.github.io/genlogis/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13931,
    "package_name": "genomic.autocorr",
    "title": "Models Dealing with Spatial Dependency in Genomic Data",
    "description": "Local structure in genomic data often induces dependence between observations taken at different genomic locations.  Ignoring this dependence leads to underestimation of the standard error of parameter estimates.  This package uses block bootstrapping to estimate asymptotically correct standard errors of parameters from any standard generalised linear model that may be fit by the glm() function.",
    "version": "1.0-1",
    "maintainer": "Chris Wallace <cew54@cam.ac.uk>",
    "url": "https://github.com/chr1swallace/genomic.autocorr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13935,
    "package_name": "genpwr",
    "title": "Power Calculations Under Genetic Model Misspecification",
    "description": "Power and sample size calculations for genetic association studies allowing \n    for misspecification of the model of genetic susceptibility.\n    \"Hum Hered. 2019;84(6):256-271.<doi:10.1159/000508558>. Epub 2020 Jul 28.\"\n    Power and/or sample size can be calculated for logistic (case/control study design) \n    and linear (continuous phenotype) regression models, using additive, dominant, \n    recessive or degree of freedom coding of the genetic covariate while assuming \n    a true dominant, recessive or additive genetic effect. In addition, power and \n    sample size calculations can be performed for gene by environment interactions.  \n    These methods are extensions of Gauderman (2002) \n    <doi:10.1093/aje/155.5.478> and Gauderman (2002) <doi:10.1002/sim.973>\n    and are described in: \n    Moore CM, Jacobson S, Fingerlin TE. Power and Sample Size Calculations \n    for Genetic Association Studies in the Presence of Genetic Model Misspecification. \n    American Society of Human Genetics. \n    October 2018, San Diego. ",
    "version": "1.0.4",
    "maintainer": "Camille Moore <moorec@njhealth.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13945,
    "package_name": "geoGAM",
    "title": "Select Sparse Geoadditive Models for Spatial Prediction",
    "description": "A model building procedure to build parsimonious geoadditive model from a large number of covariates. Continuous, binary and ordered categorical responses are supported. The model building is based on component wise gradient boosting with linear effects, smoothing splines and a smooth spatial surface to model spatial autocorrelation. The resulting covariate set after gradient boosting is further reduced through backward elimination and aggregation of factor levels. The package provides a model based bootstrap method to simulate prediction intervals for point predictions. A test data set of a soil mapping case study in Berne (Switzerland) is provided. Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A. (2017) <doi:10.5194/soil-3-191-2017>. ",
    "version": "0.1-4",
    "maintainer": "Madlene Nussbaum <m.nussbaum@uu.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13946,
    "package_name": "geoR",
    "title": "Analysis of Geostatistical Data",
    "description": "Geostatistical analysis including variogram-based, likelihood-based and Bayesian methods. Software companion for Diggle and Ribeiro (2007) <doi:10.1007/978-0-387-48536-2>. ",
    "version": "1.9-6",
    "maintainer": "Paulo Justiniano Ribeiro Jr <paulojus@ufpr.br>",
    "url": "http://www.leg.ufpr.br/geoR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13947,
    "package_name": "geoSAE",
    "title": "Geoadditive Small Area Model",
    "description": "This function is an extension of the Small Area Estimation (SAE) model. Geoadditive Small Area Model is a combination of the geoadditive model with the Small Area Estimation (SAE) model, by adding geospatial information to the SAE model. This package refers to J.N.K Rao and Isabel Molina (2015, ISBN: 978-1-118-73578-7), Bocci, C., & Petrucci, A. (2016)<doi:10.1002/9781118814963.ch13>, and Ardiansyah, M., Djuraidah, A., & Kurnia, A. (2018)<doi:10.21082/jpptp.v2n2.2018.p101-110>.",
    "version": "0.1.0",
    "maintainer": "Ketut Karang Pradnyadika <221709776@stis.ac.id>",
    "url": "https://github.com/ketutdika/geoSAE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13948,
    "package_name": "geoTS",
    "title": "Methods for Handling and Analyzing Time Series of Satellite\nImages",
    "description": "Provides functions and methods for: splitting large raster objects\n             into smaller chunks, transferring images from a binary format into raster \n             layers, transferring raster layers into an 'RData' file, calculating the \n             maximum gap (amount of consecutive missing values) of a numeric vector, \n             and fitting harmonic regression models to periodic time series. The homoscedastic\n             harmonic regression model is based on G. Roerink, M. Menenti and W. Verhoef (2000) <doi:10.1080/014311600209814>.",
    "version": "0.1.10",
    "maintainer": "Inder Tecuapetla-Gómez\n<itecuapetla@conabio.gob.mx>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13949,
    "package_name": "geoarrow",
    "title": "Extension Types for Spatial Data for Use with 'Arrow'",
    "description": "Provides extension types and conversions to between R-native\n  object types and 'Arrow' columnar types. This includes integration among\n  the 'arrow', 'nanoarrow', 'sf', and 'wk' packages such that spatial\n  metadata is preserved wherever possible. Extension type implementations\n  ensure first-class geometry data type support in the 'arrow' and 'nanoarrow'\n  packages.",
    "version": "0.4.1",
    "maintainer": "Dewey Dunnington <dewey@dunnington.ca>",
    "url": "https://geoarrow.org/geoarrow-r/,\nhttps://github.com/geoarrow/geoarrow-r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13950,
    "package_name": "geobr",
    "title": "Download Official Spatial Data Sets of Brazil",
    "description": "Easy access to official spatial data sets of Brazil as 'sf' objects \n             in R. The package includes a wide range of geospatial data available\n             at various geographic scales and for various years with harmonized\n             attributes, projection and fixed topology.",
    "version": "1.9.1",
    "maintainer": "Rafael H. M. Pereira <rafa.pereira.br@gmail.com>",
    "url": "https://ipeagit.github.io/geobr/, https://github.com/ipeaGIT/geobr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13951,
    "package_name": "geobuffer",
    "title": "Geodesic buffer around points (long, lat) using metric radius",
    "description": "Allows the possibility of creating geodesic buffers when the radius is given in metric units.",
    "version": "0.0.0.9000",
    "maintainer": "Valentin Stefan <valentin.stefan@ufz.de>",
    "url": "https://github.com/valentinitnelav/geobuffer",
    "exports": [],
    "topics": ["buffer", "distortions", "geodesic", "geodesic-buffering", "geodesic-buffers", "geodesic-distances", "geodesy", "gis", "r", "radius"],
    "score": "NA",
    "stars": 16
  },
  {
    "id": 13954,
    "package_name": "geocausal",
    "title": "Causal Inference with Spatio-Temporal Data",
    "description": "Spatio-temporal causal inference based on point process data. \n    You provide the raw data of locations and timings of treatment and \n    outcome events, specify counterfactual scenarios, and the package \n    estimates causal effects over specified spatial and temporal windows.\n    See Papadogeorgou, et  al. (2022) <doi:10.1111/rssb.12548> and\n    Mukaigawara, et al. (2024) <doi:10.31219/osf.io/5kc6f>.",
    "version": "0.3.4",
    "maintainer": "Mitsuru Mukaigawara <mitsuru_mukaigawara@g.harvard.edu>",
    "url": "https://github.com/mmukaigawara/geocausal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13956,
    "package_name": "geocodebr",
    "title": "Geolocalização De Endereços Brasileiros (Geocoding Brazilian\nAddresses)",
    "description": "Método simples e eficiente de geolocalizar dados no Brasil. O \n    pacote é baseado em conjuntos de dados espaciais abertos de endereços \n    brasileiros, utilizando como fonte principal o Cadastro Nacional de Endereços \n    para Fins Estatísticos (CNEFE). O CNEFE é publicado pelo Instituto Brasileiro \n    de Geografia e Estatística (IBGE), órgão oficial de estatísticas e geografia \n    do Brasil. (A simple and efficient method for geolocating data in Brazil. The \n    package is based on open spatial datasets of Brazilian addresses, primarily \n    using the Cadastro Nacional de Endereços para Fins Estatísticos (CNEFE), \n    published by the Instituto Brasileiro de Geografia e Estatística (IBGE), \n    Brazil's official statistics and geography agency.)",
    "version": "0.5.0",
    "maintainer": "Rafael H. M. Pereira <rafa.pereira.br@gmail.com>",
    "url": "https://github.com/ipeaGIT/geocodebr,\nhttps://ipeagit.github.io/geocodebr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13957,
    "package_name": "geocomplexity",
    "title": "Mitigating Spatial Bias Through Geographical Complexity",
    "description": "The geographical complexity of individual variables can be characterized by the differences in local attribute variables, while the common geographical complexity of multiple variables can be represented by fluctuations in the similarity of vectors composed of multiple variables. In spatial regression tasks, the goodness of fit can be improved by incorporating a geographical complexity representation vector during modeling, using a geographical complexity-weighted spatial weight matrix, or employing local geographical complexity kernel density. Similarly, in spatial sampling tasks, samples can be selected more effectively by using a method that weights based on geographical complexity. By optimizing performance in spatial regression and spatial sampling tasks, the spatial bias of the model can be effectively reduced.",
    "version": "0.2.1",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://ausgis.github.io/geocomplexity/,\nhttps://github.com/ausgis/geocomplexity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13958,
    "package_name": "geodaData",
    "title": "Spatial Analysis Datasets for Teaching",
    "description": "Stores small spatial datasets used to teach basic spatial analysis\n    concepts. Datasets are based off of the 'GeoDa' software workbook and data\n    site <https://geodacenter.github.io/data-and-lab/> developed by Luc Anselin\n    and team at the University of Chicago. Datasets are stored as 'sf' objects.",
    "version": "0.1.0",
    "maintainer": "Angela Li <ali6@uchicago.edu>",
    "url": "https://github.com/spatialanalysis/geodaData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13960,
    "package_name": "geodetector",
    "title": "Stratified Heterogeneity Measure, Dominant Driving Force\nDetection, Interaction Relationship Investigation",
    "description": "Spatial stratified heterogeneity (SSH), referring to the within strata are more similar than the between strata, a model with global parameters would be confounded if input data is SSH. Note that the \"spatial\" here can be either geospatial or the space in mathematical meaning. Geographical detector is a novel tool to investigate SSH: (1) measure and find SSH of a variable Y; (2) test the power of determinant X of a dependent variable Y according to the consistency between their spatial distributions; and (3) investigate the interaction between two explanatory variables X1 and X2 to a dependent variable Y (Wang et al 2014 <doi:10.1080/13658810802443457>, Wang, Zhang, and Fu 2016 <doi:10.1016/j.ecolind.2016.02.052>). ",
    "version": "1.0-5",
    "maintainer": "Chengdong Xu <xucd@Lreis.ac.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13965,
    "package_name": "geodl",
    "title": "Geospatial Semantic Segmentation with Torch and Terra",
    "description": "Provides tools for semantic segmentation of geospatial data using convolutional neural \n  network-based deep learning. Utility functions allow for creating masks, image chips, data frames listing image \n  chips in a directory, and DataSets for use within DataLoaders. Additional functions are provided to serve as checks \n  during the data preparation and training process. A UNet architecture can be defined with 4 blocks in the encoder, a \n  bottleneck block, and 4 blocks in the decoder. The UNet can accept a variable number of input channels, and the user \n  can define the number of feature maps produced in each encoder and decoder block and the bottleneck. Users can also \n  choose to (1) replace all rectified linear unit (ReLU) activation functions with leaky ReLU or swish, (2) implement attention gates along the \n  skip connections, (3) implement squeeze and excitation modules within the encoder blocks, (4) add residual connections \n  within all blocks, (5) replace the bottleneck with a modified atrous spatial pyramid pooling (ASPP) module, and/or \n  (6) implement deep supervision using predictions generated at each stage in the decoder. A unified focal loss framework is implemented after\n  Yeung et al. (2022) <doi:10.1016/j.compmedimag.2021.102026>. We have also implemented \n  assessment metrics using the 'luz' package including F1-score, recall, and precision. Trained models can be used to predict to spatial \n  data without the need to generate chips from larger spatial extents. Functions are available for performing accuracy assessment. The package \n  relies on 'torch' for implementing deep learning, which does not require the installation of a 'Python' environment. Raster geospatial \n  data are handled with 'terra'. Models can be trained using a Compute Unified Device Architecture (CUDA)-enabled graphics processing unit (GPU); \n  however, multi-GPU training is not supported by 'torch' in 'R'. ",
    "version": "0.3.1",
    "maintainer": "Aaron Maxwell <Aaron.Maxwell@mail.wvu.edu>",
    "url": "https://github.com/maxwell-geospatial/geodl,\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0315127,\nhttps://wvview.org/gslr/index.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13972,
    "package_name": "geogrid",
    "title": "Turn Geospatial Polygons into Regular or Hexagonal Grids",
    "description": "Turn irregular polygons (such as geographical regions) into regular or hexagonal grids.\n    This package enables the generation of regular (square) and hexagonal grids through the package \n    'sp' and then assigns the content of the existing polygons to the new grid using \n    the Hungarian algorithm, Kuhn (1955) (<doi:10.1007/978-3-540-68279-0_2>). \n    This prevents the need for manual generation of hexagonal grids or regular grids \n    that are supposed to reflect existing geography.",
    "version": "0.1.2",
    "maintainer": "Ryan Hafen <rhafen@gmail.com>",
    "url": "https://github.com/jbaileyh/geogrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13974,
    "package_name": "geohashTools",
    "title": "Tools for Working with Geohashes",
    "description": "Tools for working with Gustavo Niemeyer's geohash coordinate system, including API for interacting with other common R GIS libraries.",
    "version": "0.3.3",
    "maintainer": "Michael Chirico <MichaelChirico4@gmail.com>",
    "url": "https://github.com/MichaelChirico/geohashTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13975,
    "package_name": "geoheatmap",
    "title": "Create Geospatial Cartogram Heatmaps",
    "description": "The functionality provided by this package is an expansion of the code \n    of the 'statebins' package, created by B. Rudis (2022), <doi:10.32614/CRAN.package.statebins>. It allows for the creation of square choropleths \n    for the entire world, provided an appropriate specified grid is supplied. ",
    "version": "0.1.0",
    "maintainer": "Sanne J.W. Willems <s.j.w.willems@fsw.leidenuniv.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13980,
    "package_name": "geomander",
    "title": "Geographic Tools for Studying Gerrymandering",
    "description": "A compilation of tools to complete common tasks for studying gerrymandering. \n    This focuses on the geographic tool side of common problems, such as linking \n    different levels of spatial units or estimating how to break up units. Functions \n    exist for creating redistricting-focused data for the US.",
    "version": "2.5.2",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://christophertkenny.com/geomander/,\nhttps://github.com/christopherkenny/geomander",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13981,
    "package_name": "geomapdata",
    "title": "Data for Topographic and Geologic Mapping",
    "description": "Data sets included here are for use with package GEOmap. These include world map, USA map, Coso map, Japan Map.",
    "version": "2.0-2",
    "maintainer": "Jonathan M. Lees <jonathan.lees@unc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13984,
    "package_name": "geomerge",
    "title": "Geospatial Data Integration",
    "description": "Geospatial data integration framework that merges raster, spatial polygon, and (dynamic) spatial points data into a spatial (panel) data frame at any geographical resolution.",
    "version": "0.3.4",
    "maintainer": "Karsten Donnay <kdonnay@gmx.net>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13985,
    "package_name": "geometa",
    "title": "Tools for Reading and Writing ISO/OGC Geographic Metadata",
    "description": "Provides facilities to read, write and validate geographic metadata \n defined with ISO TC211 / OGC ISO geographic information metadata standards, and \n encoded using the ISO 19139 and ISO 19115-3 (XML) standard technical specifications. \n This includes ISO 19110 (Feature cataloguing), 19115 (dataset metadata), 19119 (service metadata) \n and 19136 (GML). Other interoperable schemas from the OGC are progressively supported \n as well, such as the Sensor Web Enablement (SWE) Common Data Model, the OGC GML \n Coverage Implementation Schema (GMLCOV), or the OGC GML Referenceable Grid (GMLRGRID).",
    "version": "0.9.3",
    "maintainer": "Emmanuel Blondel <emmanuel.blondel1@gmail.com>",
    "url": "https://github.com/eblondel/geometa/wiki",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13986,
    "package_name": "geometries",
    "title": "Convert Between R Objects and Geometric Structures",
    "description": "Geometry shapes in 'R' are typically represented by matrices (points, lines), with more complex \n  shapes being lists of matrices (polygons). 'Geometries' will convert various 'R' objects into these shapes. \n  Conversion functions are available at both the 'R' level, and through 'Rcpp'.",
    "version": "0.2.5",
    "maintainer": "David Cooley <david.cooley.au@gmail.com>",
    "url": "https://dcooley.github.io/geometries/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13990,
    "package_name": "geomod",
    "title": "A Computer Program for Geotechnical Investigations",
    "description": "The 'geomod' does spatial prediction of the Geotechnical soil properties. \n    It predicts the spatial distribution of Geotechnical properties of soil e.g. shear strength, \n    permeability, plasticity index, Standard Penetration Test (SPT) counts, etc. The output of the prediction takes the form of a \n    map or a series of maps. It uses the interpolation technique where a single or statistically “best” \n    estimate of spatial occurrence soil property is determined. The interpolation is based on both the \n    sampled data and a variogram model for the spatial correlation of the sampled data. \n    The single estimate is produced by a Kriging technique.",
    "version": "0.1.0",
    "maintainer": "Festus Ngeno <festus.k.ngeno@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13995,
    "package_name": "geonapi",
    "title": "'GeoNetwork' API R Interface",
    "description": "Provides an R interface to the 'GeoNetwork' API (<https://geonetwork-opensource.org/#api>) allowing to upload and publish metadata in a 'GeoNetwork' web-application and expose it to OGC CSW.",
    "version": "0.8-1",
    "maintainer": "Emmanuel Blondel <emmanuel.blondel1@gmail.com>",
    "url": "https://github.com/eblondel/geonapi/wiki,\nhttps://geonetwork-opensource.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13996,
    "package_name": "geonetwork",
    "title": "Geographic Networks",
    "description": "Provides classes and methods for handling networks or \n  graphs whose nodes are geographical (i.e. locations in the globe).\n  The functionality includes the creation of objects of class geonetwork\n  as a graph with node coordinates, the computation of network measures,\n  the support of spatial operations (projection to different Coordinate\n  Reference Systems, handling of bounding boxes, etc.) and the plotting of\n  the geonetwork object combined with supplementary cartography for spatial \n  representation.",
    "version": "0.6.0",
    "maintainer": "Facundo Muñoz <facundo.munoz@cirad.fr>",
    "url": "https://astre.gitlab.cirad.fr/geonetwork,\nhttps://gitlab.cirad.fr/astre/geonetwork",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 13998,
    "package_name": "geonuts",
    "title": "Identification and Visualisation of European NUTS Regions from\nGeolocations",
    "description": "Provides functions to identify European NUTS (Nomenclature of Territorial Units for Statistics) regions for geographic coordinates (latitude/longitude) using Eurostat geospatial boundaries. Includes map-based visualisation of the matched regions for validation and exploration. Designed for regional data analysis, reproducible workflows, and integration with common geospatial R packages.",
    "version": "1.0.0",
    "maintainer": "Attila I. Katona <katona.attila@gtk.uni-pannon.hu>",
    "url": "https://github.com/aikatona/geonuts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14001,
    "package_name": "geopsych",
    "title": "Methods of Applied Psychology and Psychometrics in Geographical\nAnalysis",
    "description": "Integrating applied psychological and psychometric methods into geographical analysis. With the emergence of geo-referenced questionnaires, spatially explicit psychological and psychometric methods can offer a geographically contextualised approach that reflects latent traits and processes at a more local scale, leading to more tailored research and decision-making processes. The implemented methods include Geographically Weighted Cronbach's alpha and its bandwidth selection. See Zhang & Li (2025) <doi:10.1111/gean.70021>.",
    "version": "0.1.0",
    "maintainer": "Sui Zhang <sui.zhang@manchester.ac.uk>",
    "url": "https://github.com/ZhangSui921/geopsych",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14003,
    "package_name": "georob",
    "title": "Robust Geostatistical Analysis of Spatial Data",
    "description": "Provides functions for efficiently fitting linear models with spatially correlated errors by robust (Kuensch et al. (2011) <doi:10.3929/ethz-a-009900710>) and Gaussian (Harville (1977) <doi:10.1080/01621459.1977.10480998>) (Restricted) Maximum Likelihood and for computing robust and customary point and block external-drift Kriging predictions (Cressie (1993) <doi:10.1002/9781119115151>), along with utility functions for variogram modelling in ad hoc geostatistical analyses, model building, model evaluation by cross-validation, (conditional) simulation of Gaussian processes (Davies and Bryant (2013) <doi:10.18637/jss.v055.i09>), unbiased back-transformation of Kriging predictions of log-transformed data (Cressie (2006) <doi:10.1007/s11004-005-9022-8>).",
    "version": "0.3-23",
    "maintainer": "Andreas Papritz <papritz@retired.ethz.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14004,
    "package_name": "geos",
    "title": "Open Source Geometry Engine ('GEOS') R API",
    "description": "Provides an R API to the Open Source Geometry Engine\n  ('GEOS') library (<https://libgeos.org/>) and a vector format \n  with which to efficiently store 'GEOS' geometries. High-performance functions \n  to extract information from, calculate relationships between, and\n  transform geometries are provided. Finally, facilities to import \n  and export geometry vectors to other spatial formats are provided.",
    "version": "0.2.5",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "url": "https://paleolimbot.github.io/geos/,\nhttps://github.com/paleolimbot/geos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14007,
    "package_name": "geosimilarity",
    "title": "Geographically Optimal Similarity",
    "description": "Understanding spatial association is essential for spatial \n             statistical inference, including factor exploration and spatial prediction. \n             Geographically optimal similarity (GOS) model is an effective method \n             for spatial prediction, as described in Yongze Song (2022) \n             <doi:10.1007/s11004-022-10036-8>. GOS was developed based on \n             the geographical similarity principle, as described in Axing Zhu (2018) \n             <doi:10.1080/19475683.2018.1534890>. GOS has advantages in \n             more accurate spatial prediction using fewer samples and \n             critically reduced prediction uncertainty. ",
    "version": "3.8",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://github.com/ausgis/geosimilarity,\nhttps://ausgis.github.io/geosimilarity/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14009,
    "package_name": "geospatialsuite",
    "title": "Comprehensive Geospatiotemporal Analysis and Multimodal\nIntegration Toolkit",
    "description": "A comprehensive toolkit for geospatiotemporal analysis\n    featuring 60+ vegetation indices, advanced raster visualization,\n    universal spatial mapping, water quality analysis, CDL crop analysis,\n    spatial interpolation, temporal analysis, and terrain analysis.\n    Designed for agricultural research, environmental monitoring, remote\n    sensing applications, and publication-quality mapping with support for\n    any geographic region and robust error handling. Methods include\n    vegetation indices calculations (Rouse et al. 1974), NDVI and enhanced\n    vegetation indices (Huete et al. 1997)\n    <doi:10.1016/S0034-4257(97)00104-1>, (Akanbi et al. 2024) \n    <doi:10.1007/s41651-023-00164-y>, spatial interpolation techniques\n    (Cressie 1993, ISBN:9780471002556), water quality indices (McFeeters\n    1996) <doi:10.1080/01431169608948714>, and crop data layer analysis\n    (USDA NASS 2024)\n    <https://www.nass.usda.gov/Research_and_Science/Cropland/>.  Funding:\n    This material is based upon financial support by the National Science\n    Foundation, EEC Division of Engineering Education and Centers, NSF\n    Engineering Research Center for Advancing Sustainable and Distributed\n    Fertilizer production (CASFER), NSF 20-553 Gen-4 Engineering Research\n    Centers award 2133576.",
    "version": "0.1.1",
    "maintainer": "Olatunde D. Akanbi <olatunde.akanbi@case.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14011,
    "package_name": "geospt",
    "title": "Geostatistical Analysis and Design of Optimal Spatial Sampling\nNetworks",
    "description": "Estimation of the variogram through trimmed mean, radial basis \n        functions (optimization, prediction and cross-validation), summary\n        statistics from cross-validation, pocket plot, and design of\n        optimal sampling networks through sequential and simultaneous\n        points methods.",
    "version": "1.0-6",
    "maintainer": "Ali Santacruz <amsantac@unal.edu.co>",
    "url": "https://github.com/amsantac/geospt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14012,
    "package_name": "geosptdb",
    "title": "Spatio-Temporal Radial Basis Functions with Distance-Based\nMethods (Optimization, Prediction and Cross Validation)",
    "description": "Spatio-temporal radial basis functions (optimization, prediction and cross-validation), summary statistics from cross-validation, Adjusting distance-based linear regression model and generation of the principal coordinates of a new individual from Gower's distance.",
    "version": "1.0-2",
    "maintainer": "Carlos Melo <cmelo@udistrital.edu.co>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14015,
    "package_name": "geostatsp",
    "title": "Geostatistical Modelling with Likelihood and Bayes",
    "description": "Geostatistical modelling facilities using 'SpatRaster' and 'SpatVector'\n    objects are provided. Non-Gaussian models are fit using 'INLA', and Gaussian\n    geostatistical models use Maximum Likelihood Estimation.  For details see Brown (2015) <doi:10.18637/jss.v063.i12>. The 'RandomFields' package is available at <https://www.wim.uni-mannheim.de/schlather/publications/software>.",
    "version": "2.0.8",
    "maintainer": "Patrick Brown <patrick.brown@utoronto.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14018,
    "package_name": "geotoolsR",
    "title": "Tools to Improve the Use of Geostatistic",
    "description": "The basic idea of this package is provides some tools to help the researcher to work with geostatistics. Initially, we present a collection of functions that allow the researchers to deal with spatial data using bootstrap procedure. There are five methods available and two ways to display them: bootstrap confidence interval - provides a two-sided bootstrap confidence interval; bootstrap plot - a graphic with the original variogram and each of the B bootstrap variograms.",
    "version": "1.2.1",
    "maintainer": "Diogo Francisco Rossoni <dfrossoni@uem.br>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14019,
    "package_name": "geotopbricks",
    "title": "An R Plug-in for the Distributed Hydrological Model GEOtop",
    "description": "It analyzes raster maps and other information as input/output\n    files from the Hydrological Distributed Model GEOtop. It contains functions\n    and methods to import maps and other keywords from geotop.inpts file. Some\n    examples with simulation cases of GEOtop 2.x/3.x are presented in the package.\n    Any information about the GEOtop Distributed Hydrological Model can be found in the provided documentation.",
    "version": "1.5.9.1",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "url": "https://github.com/ecor/geotopbricks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14032,
    "package_name": "gesisdata",
    "title": "Reproducible Data Retrieval from the GESIS Data Archive",
    "description": "Reproducible, programmatic retrieval of datasets from the\n    GESIS Data Archive.  The GESIS Data Archive <https://search.gesis.org>  \n    makes available thousands of invaluable datasets, but researchers using\n    these datasets are caught in a bind.  The archive's terms and conditions\n    bar dissemination of downloaded datasets to third parties, but to ensure \n    that one's work can be reproduced, assessed, and built upon by others, one\n    must provide access to the raw data one has employed.  The 'gesisdata'\n    package cuts this knot by providing registered users with programmatic,\n    reproducible access to GESIS datasets from within 'R'.",
    "version": "0.1.2",
    "maintainer": "Frederick Solt <frederick-solt@uiowa.edu>",
    "url": "https://github.com/fsolt/gesisdata, https://fsolt.org/gesisdata/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14040,
    "package_name": "getLattes",
    "title": "Import and Process Data from the 'Lattes' Curriculum Platform",
    "description": "Tool for import and process data from 'Lattes' curriculum platform (<http://lattes.cnpq.br/>). The Brazilian government keeps an extensive base of curricula for academics from all over the country, with over 5 million registrations. The academic life of the Brazilian researcher, or related to Brazilian universities, is documented in 'Lattes'. Some information that can be obtained: professional formation, research area, publications, academics advisories, projects, etc. 'getLattes' package allows work with 'Lattes' data exported to XML format.",
    "version": "1.0.0",
    "maintainer": "Roney Fraga Souza <roneyfraga@gmail.com>",
    "url": "https://github.com/roneyfraga/getLattes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14069,
    "package_name": "ggBubbles",
    "title": "Mini Bubble Plots for Comparison of Discrete Data with 'ggplot2'",
    "description": "When comparing discrete data mini bubble plots allow displaying \n   more information than traditional bubble plots via colour, shape or labels. \n   Exact overlapping coordinates will be transformed so they surround the\n   original point circularly without overlapping. This is implemented as a \n   position_surround() function for 'ggplot2'.",
    "version": "0.1.4",
    "maintainer": "Thomas Schwarzl <schwarzl@embl.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14080,
    "package_name": "ggOceanMaps",
    "title": "Plot Data on Oceanographic Maps using 'ggplot2'",
    "description": "Allows plotting data on bathymetric maps using 'ggplot2'. Plotting\n  oceanographic spatial data is made as simple as feasible, but also flexible\n  for custom modifications. Data that contain geographic information from \n  anywhere around the globe can be plotted on maps generated by the basemap()\n  or qmap() functions using 'ggplot2' layers separated by the '+' operator. The \n  package uses spatial shape- ('sf') and raster ('stars') files, geospatial \n  packages for R to manipulate, and the 'ggplot2' package to plot these \n  files. The package ships with low-resolution spatial data files and \n  higher resolution files for detailed maps are stored in the \n  'ggOceanMapsLargeData' repository on GitHub and downloaded automatically \n  when needed. ",
    "version": "2.2.0",
    "maintainer": "Mikko Vihtakari <mikko.vihtakari@hi.no>",
    "url": "https://mikkovihtakari.github.io/ggOceanMaps/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14180,
    "package_name": "ggincerta",
    "title": "Extend 'ggplot2' with Layers and Scales for Spatial Uncertainty\nVisualization",
    "description": "Provide specialized 'ggplot2' layers and scales for spatial\n    uncertainty visualization, including bivariate choropleth maps, pixel maps,\n    glyph maps, and exceedance probability maps.",
    "version": "0.1.0",
    "maintainer": "Xueqi Ma <maggiexma07@gmail.com>",
    "url": "https://github.com/maggiexma/ggincerta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14189,
    "package_name": "gglasso",
    "title": "Group Lasso Penalized Learning Using a Unified BMD Algorithm",
    "description": "A unified algorithm, blockwise-majorization-descent (BMD), for efficiently computing the solution paths of the group-lasso penalized least squares, logistic regression, Huberized SVM and squared SVM. The package is an implementation of Yang, Y. and Zou, H. (2015) <doi:10.1007/s11222-014-9498-5>.",
    "version": "1.6",
    "maintainer": "Yi Yang <yi.yang6@mcgill.ca>",
    "url": "https://github.com/archer-yang-lab/gglasso",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14200,
    "package_name": "ggmapcn",
    "title": "Customizable China and Global Map Visualizations",
    "description": "A 'ggplot2' extension centered on map visualization of China\n    and the globe. Provides customizable projections, boundary styles,\n    coordinate grids, scale bars, and buffer zones for thematic maps,\n    suitable for spatial data analysis and cartographic visualization.",
    "version": "0.3.0",
    "maintainer": "Liang Ren <rl23@mails.tsinghua.edu.cn>",
    "url": "https://rimagination.github.io/ggmapcn/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14245,
    "package_name": "ggpolypath",
    "title": "Polygons with Holes for the Grammar of Graphics",
    "description": "Tools for working with polygons with holes in 'ggplot2', with a\n    new 'geom' for drawing a 'polypath' applying the 'evenodd' or 'winding'\n    rules.",
    "version": "0.4.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://mdsumner.github.io/ggpolypath/,\nhttp://rpubs.com/kohske/3522/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14247,
    "package_name": "ggpp",
    "title": "Grammar Extensions to 'ggplot2'",
    "description": "Extensions to 'ggplot2' respecting the grammar of graphics \n    paradigm. Geometries: geom_table(), geom_plot() and geom_grob() add insets to \n    plots using native data coordinates, while geom_table_npc(), geom_plot_npc()\n    and geom_grob_npc() do the same using \"npc\" coordinates through new \n    aesthetics \"npcx\" and \"npcy\". Statistics: select observations based on 2D \n    density. Positions: radial nudging away from a center point and nudging away\n    from a line or curve; combined stacking and nudging; combined dodging and\n    nudging.",
    "version": "0.5.9",
    "maintainer": "Pedro J. Aphalo <pedro.aphalo@helsinki.fi>",
    "url": "https://docs.r4photobiology.info/ggpp/,\nhttps://github.com/aphalo/ggpp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14260,
    "package_name": "ggrastr",
    "title": "Rasterize Layers for 'ggplot2'",
    "description": "Rasterize only specific layers of a 'ggplot2' plot while simultaneously keeping all labels and text in vector format. This allows users to keep plots within the reasonable size limit without loosing vector properties of the scale-sensitive information. ",
    "version": "1.0.2",
    "maintainer": "Evan Biederstedt <evan.biederstedt@gmail.com>",
    "url": "https://github.com/VPetukhov/ggrastr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14261,
    "package_name": "ggrcs",
    "title": "Draw Histograms and Restricted Cubic Splines (RCS)",
    "description": "You can use this function to easily draw a combined histogram and restricted cubic spline. \n    The function draws the graph through 'ggplot2'. RCS fitting requires the use of the rcs() function of the 'rms' package. \n    Can fit cox regression, logistic regression. This method was described by Per Kragh (2003) <doi:10.1002/sim.1497>.",
    "version": "0.4.3",
    "maintainer": "Qiang LIU <dege857@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14263,
    "package_name": "ggredist",
    "title": "Scales, Geometries, and Extensions of 'ggplot2' for Election\nMapping",
    "description": "Provides 'ggplot2' extensions for political map making. Implements\n    new geometries for groups of simple feature geometries. Adds palettes and scales\n    for red to blue color mapping and for discrete maps. Implements tools for easy\n    label generation and placement, automatic map coloring, and themes.",
    "version": "0.0.4",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/alarm-redist/ggredist,\nhttps://alarm-redist.org/ggredist/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14278,
    "package_name": "ggsem",
    "title": "Interactive Structural Equation Modeling (SEM) and Multi-Group\nPath Diagrams",
    "description": "Provides an interactive workflow for visualizing structural equation modeling (SEM), multi-group path diagrams, and network diagrams in R. Users can directly manipulate nodes and edges to create publication-quality figures while maintaining statistical model integrity. Supports integration with 'lavaan', 'OpenMx', 'tidySEM', and 'blavaan' etc. Features include parameter-based aesthetic mapping, generative AI assistance, and complete reproducibility by exporting metadata for script-based workflows. ",
    "version": "0.9.7",
    "maintainer": "Seung Hyun Min <seung.min@mail.mcgill.ca>",
    "url": "https://smin95.github.io/ggsem/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14291,
    "package_name": "ggspatial",
    "title": "Spatial Data Framework for ggplot2",
    "description": "Spatial data plus the power of the ggplot2 framework means easier mapping when input \n  data are already in the form of spatial objects.",
    "version": "1.1.10",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "url": "https://paleolimbot.github.io/ggspatial/,\nhttps://github.com/paleolimbot/ggspatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14296,
    "package_name": "ggstar",
    "title": "Multiple Geometric Shape Point Layer for 'ggplot2'",
    "description": "To create the multiple polygonal point layer for easily discernible shapes, \n             we developed the package, it is like the 'geom_point' of 'ggplot2'.\n             It can be used to draw the scatter plot.",
    "version": "1.0.6",
    "maintainer": "Shuangbin Xu <xshuangbin@163.com>",
    "url": "https://github.com/xiangpin/ggstar/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14314,
    "package_name": "ggtikz",
    "title": "Post-Process 'ggplot2' Plots with 'TikZ' Code Using Plot\nCoordinates",
    "description": "Annotation of 'ggplot2' plots with arbitrary 'TikZ' code, using absolute data or relative plot coordinates.",
    "version": "0.1.5",
    "maintainer": "Oliver Thomas <ost.dev@posteo.net>",
    "url": "https://github.com/osthomas/ggtikz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14349,
    "package_name": "gibble",
    "title": "Geometry Decomposition",
    "description": "Build a map of path-based geometry, this is a simple description of the number\n of parts in an object and their basic structure. Translation and restructuring operations for \n planar shapes and other hierarchical types require a data model with a record of the underlying\n relationships between elements. The gibble() function creates a geometry map, a simple record of \n the underlying structure in path-based hierarchical types. There are methods for the planar shape \n types in the 'sf' and 'sp' packages and for types in the 'trip' and 'silicate' packages. ",
    "version": "0.4.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/mdsumner/gibble",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14354,
    "package_name": "gifti",
    "title": "Reads in 'Neuroimaging' 'GIFTI' Files with Geometry Information",
    "description": "Functions to read in the geometry format under the \n    'Neuroimaging' 'Informatics' Technology Initiative ('NIfTI'), called \n    'GIFTI' <https://www.nitrc.org/projects/gifti/>. \n    These files contain surfaces of brain imaging data.",
    "version": "0.8.0",
    "maintainer": "John Muschelli <muschellij2@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14358,
    "package_name": "gim",
    "title": "Generalized Integration Model",
    "description": "Implements the generalized integration model, which integrates individual-level data and summary statistics under a generalized linear model framework. It supports continuous and binary outcomes to be modeled by the linear and logistic regression models. For binary outcome, data can be sampled in prospective cohort studies or case-control studies. Described in Zhang et al. (2020)<doi:10.1093/biomet/asaa014>. ",
    "version": "0.33.1",
    "maintainer": "Han Zhang <zhangh.ustc@gmail.com>",
    "url": "https://github.com/zhangh12/gim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14360,
    "package_name": "gimms",
    "title": "Download and Process GIMMS NDVI3g Data",
    "description": "This is a set of functions to retrieve information about GIMMS\n    NDVI3g files currently available online; download (and re-arrange, in the \n    case of NDVI3g.v0) the half-monthly data sets; import downloaded files from \n    ENVI binary (NDVI3g.v0) or NetCDF format (NDVI3g.v1) directly into R based \n    on the widespread 'raster' package; conduct quality control; and generate \n    monthly composites (e.g., maximum values) from the half-monthly input data. \n    As a special gimmick, a method is included to conveniently apply the \n    Mann-Kendall trend test upon 'Raster*' images, optionally featuring \n    trend-free pre-whitening to account for lag-1 autocorrelation.",
    "version": "1.2.4",
    "maintainer": "Florian Detsch <fdetsch@web.de>",
    "url": "https://github.com/environmentalinformatics-marburg/gimms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14369,
    "package_name": "gistr",
    "title": "Work with 'GitHub' 'Gists'",
    "description": "Work with 'GitHub' 'gists' from 'R' (e.g., \n    <https://en.wikipedia.org/wiki/GitHub#Gist>, \n    <https://docs.github.com/en/github/writing-on-github/creating-gists/>). A 'gist'\n    is simply one or more files with code/text/images/etc. This package allows\n    the user to create new 'gists', update 'gists' with new files, rename files,\n    delete files, get and delete 'gists', star and 'un-star' 'gists', fork 'gists',\n    open a 'gist' in your default browser, get embed code for a 'gist', list\n    'gist' 'commits', and get rate limit information when 'authenticated'. Some\n    requests require authentication and some do not. 'Gists' website: \n    <https://gist.github.com/>.",
    "version": "0.9.0",
    "maintainer": "Scott Chamberlain <myrmecocystus@gmail.com>",
    "url": "https://github.com/ropensci/gistr (devel),\nhttps://docs.ropensci.org/gistr (website)",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14408,
    "package_name": "glm.predict",
    "title": "Predicted Values and Discrete Changes for Regression Models",
    "description": "Functions to calculate predicted values and the difference between\n    the two cases with confidence interval for lm() [linear model], glm() [generalized linear model], glm.nb() [negative binomial model],\n\tpolr() [ordinal logistic model], vglm() [generalized ordinal logistic model],\tmultinom() [multinomial model], tobit() [tobit model],\n\tsvyglm() [survey-weighted generalised linear models] and lmer() [linear multilevel models] using Monte Carlo simulations or bootstrap. Reference: Bennet A. Zelner (2009) <doi:10.1002/smj.783>.",
    "version": "4.3-2",
    "maintainer": "Benjamin E. Schlegel <kontakt@benjaminschlegel.ch>",
    "url": "https://github.com/benjaminschlegel/glm.predict/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14418,
    "package_name": "glmlep",
    "title": "Fit GLM with LEP-Based Penalized Maximum Likelihood",
    "description": "Efficient algorithms for fitting regularization paths for\n        linear or logistic regression models penalized by LEP.",
    "version": "0.2",
    "maintainer": "Canhong Wen <wencanhong@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14428,
    "package_name": "glmmfields",
    "title": "Generalized Linear Mixed Models with Robust Random Fields",
    "description": "Implements Bayesian spatial and spatiotemporal",
    "version": "0.1.8",
    "maintainer": "",
    "url": "https://github.com/seananderson/glmmfields",
    "exports": [],
    "topics": ["ecology", "extremes", "r", "spatial-analysis", "spatiotemporal"],
    "score": "NA",
    "stars": 53
  },
  {
    "id": 14430,
    "package_name": "glmmrOptim",
    "title": "Approximate Optimal Experimental Designs Using Generalised\nLinear Mixed Models",
    "description": "Optimal design analysis algorithms for any study design that can be represented or\n  modelled as a generalised linear mixed model including cluster randomised trials,\n  cohort studies, spatial and temporal epidemiological studies, and split-plot designs.\n  See <https://github.com/samuel-watson/glmmrBase/blob/master/README.md> for a\n  detailed manual on model specification. A detailed discussion of the methods in this\n  package can be found in Watson, Hemming, and Girling (2023) <doi:10.1177/09622802231202379>.",
    "version": "0.3.6",
    "maintainer": "Sam Watson <S.I.Watson@bham.ac.uk>",
    "url": "https://github.com/samuel-watson/glmmrOptim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14441,
    "package_name": "glmtlp",
    "title": "Generalized Linear Models with Truncated Lasso Penalty",
    "description": "Extremely efficient procedures for fitting regularization path with l0, l1, and truncated lasso penalty for linear regression and logistic regression models. This version is a completely new version compared with our previous version, which was mainly based on R. New core algorithms are developed and are now written in C++ and highly optimized. ",
    "version": "2.0.2",
    "maintainer": "Yu Yang <yuyang.stat@gmail.com>",
    "url": "https://yuyangyy.com/glmtlp/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14460,
    "package_name": "glogis",
    "title": "Fitting and Testing Generalized Logistic Distributions",
    "description": "Tools for the generalized logistic distribution (Type I,\n             also known as skew-logistic distribution), encompassing\n\t     basic distribution functions (p, q, d, r, score), maximum\n\t     likelihood estimation, and structural change methods.",
    "version": "1.0-2",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14468,
    "package_name": "glsm",
    "title": "Saturated Model Log-Likelihood for Multinomial Outcomes",
    "description": "When the response variable Y takes one of R > 1 values, the function 'glsm()' computes the maximum likelihood estimates (MLEs) of the parameters under four models: null, complete, saturated, and logistic. It also calculates the log-likelihood values for each model. This method assumes independent, non-identically distributed variables. For grouped data with a multinomial outcome, where observations are divided into J populations, the function 'glsm()' provides estimation for any number K of explanatory variables.",
    "version": "0.0.0.6",
    "maintainer": "Jorge Villalba <jvillalba@utb.edu.co>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14496,
    "package_name": "gmt",
    "title": "Interface Between GMT Map-Making Software and R",
    "description": "Interface between the GMT map-making software and R, enabling the\n  user to manipulate geographic data within R and call GMT commands to draw and\n  annotate maps in postscript format. The gmt package is about interactive data\n  analysis, rapidly visualizing subsets and summaries of geographic data, while\n  performing statistical analysis in the R console.",
    "version": "2.0.3",
    "maintainer": "Arni Magnusson <thisisarni@gmail.com>",
    "url": "https://www.generic-mapping-tools.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14526,
    "package_name": "gofcat",
    "title": "Goodness-of-Fit Measures for Categorical Response Models",
    "description": "A post-estimation method for categorical response models (CRM). \n    Inputs from objects of class serp(), clm(), polr(), multinom(), mlogit(), \n    vglm() and glm() are currently supported. Available tests include the \n    Hosmer-Lemeshow tests for the binary, multinomial and ordinal logistic \n    regression; the Lipsitz and the Pulkstenis-Robinson tests for the ordinal \n    models. The proportional odds, adjacent-category, and constrained continuation-ratio \n    models are particularly supported at ordinal level. Tests for the proportional \n    odds assumptions in ordinal models are also possible with the Brant and the \n    Likelihood-Ratio tests. Moreover, several summary measures of predictive strength \n    (Pseudo R-squared), and some useful error metrics, including, the brier \n    score, misclassification rate and logloss are also available for the \n    binary, multinomial and ordinal models. Ugba, E. R. and Gertheiss, J. (2018) \n    <http://www.statmod.org/workshops_archive_proceedings_2018.html>.",
    "version": "0.1.2",
    "maintainer": "Ejike R. Ugba <ejike.ugba@outlook.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14580,
    "package_name": "gpboost",
    "title": "Combining Tree-Boosting with Gaussian Process and Mixed Effects\nModels",
    "description": "An R package that allows for combining tree-boosting with Gaussian process and mixed effects models. It also allows for independently doing tree-boosting as well as inference and prediction for Gaussian process and mixed effects models. See <https://github.com/fabsig/GPBoost> for more information on the software and Sigrist (2022, JMLR) <https://www.jmlr.org/papers/v23/20-322.html> and Sigrist (2023, TPAMI) <doi:10.1109/TPAMI.2022.3168152> for more information on the methodology.",
    "version": "1.6.5",
    "maintainer": "Fabio Sigrist <fabiosigrist@gmail.com>",
    "url": "https://github.com/fabsig/GPBoost",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14633,
    "package_name": "graph4lg",
    "title": "Build Graphs for Landscape Genetics Analysis",
    "description": "Build graphs for landscape genetics analysis. This set of \n\tfunctions can be used to import and convert spatial and genetic data \n\tinitially in different formats, import landscape graphs created with \n\t'GRAPHAB' software (Foltete et al., 2012) <doi:10.1016/j.envsoft.2012.07.002>, \n\tmake diagnosis plots of isolation by distance relationships in order to \n\tchoose how to build genetic graphs, create graphs with a large range of \n\tpruning methods, weight their links with several genetic distances, plot \n\tand analyse graphs,\tcompare them with other graphs. It uses functions from \n\tother packages such as 'adegenet' \n\t(Jombart, 2008) <doi:10.1093/bioinformatics/btn129> and 'igraph' (Csardi\n\tet Nepusz, 2006) <https://igraph.org/>. It also implements methods \n\tcommonly used in landscape genetics to create graphs, described by Dyer et \n\tNason (2004) <doi:10.1111/j.1365-294X.2004.02177.x> and Greenbaum et \n\tFefferman (2017) <doi:10.1111/mec.14059>, and to analyse distance data \n\t(van Strien et al., 2015) <doi:10.1038/hdy.2014.62>.",
    "version": "1.8.0",
    "maintainer": "Paul Savary <psavary@protonmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14661,
    "package_name": "grec",
    "title": "Gradient-Based Recognition of Spatial Patterns in Environmental\nData",
    "description": "Provides algorithms for detection of spatial patterns from oceanographic data using image processing methods based on Gradient Recognition.",
    "version": "1.6.3",
    "maintainer": "Wencheng Lau-Medrano <luis.laum@gmail.com>",
    "url": "https://github.com/LuisLauM/grec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14682,
    "package_name": "gridGeometry",
    "title": "Polygon Geometry in 'grid'",
    "description": "Functions for performing polygon geometry with 'grid' grobs.\n             This allows complex shapes to be defined by combining simpler\n             shapes.  ",
    "version": "0.4-0",
    "maintainer": "Paul Murrell <paul@stat.auckland.ac.nz>",
    "url": "https://github.com/pmur002/gridgeometry,\nhttps://stattech.wordpress.fos.auckland.ac.nz/2019/03/04/2019-01-a-geometry-engine-interface-for-grid/,\nhttps://stattech.blogs.auckland.ac.nz/2022/06/01/2022-02-constructive-geometry-for-complex-grobs/,\nhttps://stattech.wordpress.fos.auckland.ac.nz/2022/12/14/2022-03-offsetting-lines-and-polygons-in-grid/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14687,
    "package_name": "gridbr",
    "title": "easy access to the Brazilian statistical grid with R",
    "description": "Make Brazilian statistical grid and access 2010 population",
    "version": "0.1.3",
    "maintainer": "Luis Cunha <luisfelipebc@outlook.com>",
    "url": "https://github.com/luisfelipebr/gridbr",
    "exports": [],
    "topics": ["geoinformation", "geospatial", "grid"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 14689,
    "package_name": "gridpattern",
    "title": "'grid' Pattern Grobs",
    "description": "Provides 'grid' grobs that fill in a user-defined area with various patterns.  Includes enhanced versions of the geometric and image-based patterns originally contained in the 'ggpattern' package as well as original 'pch', 'polygon_tiling', 'regular_polygon', 'rose', 'text', 'wave', and 'weave' patterns plus support for custom user-defined patterns.",
    "version": "1.3.1",
    "maintainer": "Trevor L. Davis <trevor.l.davis@gmail.com>",
    "url": "https://trevorldavis.com/R/gridpattern/,\nhttps://github.com/trevorld/gridpattern",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14721,
    "package_name": "growthcurver",
    "title": "Simple Metrics to Summarize Growth Curves",
    "description": "Fits the logistic equation to\n    microbial growth curve data (e.g., repeated absorbance measurements\n    taken from a plate reader over time). From this fit, a variety of\n    metrics are provided, including the maximum growth rate,\n    the doubling time, the carrying capacity, the area under the logistic\n    curve, and the time to the inflection point. Method described in \n    Sprouffske and Wagner (2016) <doi:10.1186/s12859-016-1016-7>.",
    "version": "0.3.1",
    "maintainer": "Kathleen Sprouffske <sprouffske@gmail.com>",
    "url": "https://github.com/sprouffske/growthcurver",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14728,
    "package_name": "grpnet",
    "title": "Group Elastic Net Regularized GLMs and GAMs",
    "description": "Efficient algorithms for fitting generalized linear and additive models with group elastic net penalties as described in Helwig (2025) <doi:10.1080/10618600.2024.2362232>. Implements group LASSO, group MCP, and group SCAD with an optional group ridge penalty. Computes the regularization path for linear regression (gaussian), multivariate regression (multigaussian), smoothed support vector machines (svm1), squared support vector machines (svm2), logistic regression (binomial), proportional odds logistic regression (ordinal), multinomial logistic regression (multinomial), log-linear count regression (poisson and negative.binomial), and log-linear continuous regression (gamma and inverse gaussian). Supports default and formula methods for model specification, k-fold cross-validation for tuning the regularization parameters, and nonparametric regression via tensor product reproducing kernel (smoothing spline) basis function expansion. ",
    "version": "1.1",
    "maintainer": "Nathaniel E. Helwig <helwig@umn.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14730,
    "package_name": "grpsel",
    "title": "Group Subset Selection",
    "description": "Provides tools for sparse regression modelling with grouped predictors using the group \n    subset selection penalty. Uses coordinate descent and local search algorithms to rapidly deliver \n    near optimal estimates. The group subset penalty can be combined with a group lasso or ridge \n    penalty for added shrinkage. Linear and logistic regression are supported, as are overlapping \n    groups.",
    "version": "1.3.2",
    "maintainer": "Ryan Thompson <ryan.thompson-1@uts.edu.au>",
    "url": "https://github.com/ryan-thompson/grpsel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14763,
    "package_name": "gstsm",
    "title": "Generalized Spatial-Time Sequence Miner",
    "description": "Implementations of the algorithms present article \n    Generalized Spatial-Time Sequence Miner, original title\n    (Castro, Antonio; Borges, Heraldo ; Pacitti, Esther ; Porto, Fabio\n    ; Coutinho, Rafaelli ; Ogasawara, Eduardo . Generalização de Mineração de\n    Sequências Restritas no Espaço e no Tempo. In: XXXVI SBBD -\n    Simpósio Brasileiro de Banco de Dados, 2021 <doi:10.5753/sbbd.2021.17891>).",
    "version": "1.0.0",
    "maintainer": "Antonio Castro <gstsm@eic.cefet-rj.br>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14775,
    "package_name": "gtfs2emis",
    "title": "Estimating Public Transport Emissions from General Transit Feed\nSpecification (GTFS) Data",
    "description": "A bottom up model to estimate the emission levels of public transport systems based on General Transit Feed Specification (GTFS) data. The package requires two main inputs: i) Public transport data in the GTFS standard format; and ii) Some basic information on fleet characteristics such as fleet age, technology, fuel and Euro stage. As it stands, the package estimates several pollutants at high spatial and temporal resolutions. Pollution levels can be calculated for specific transport routes, trips, time of the day or for the transport system as a whole. The output with emission estimates can be extracted in different formats, supporting analysis on how emission levels vary across space, time and by fleet characteristics. A full description of the methods used in the 'gtfs2emis' model is presented in Vieira, J. P. B.; Pereira, R. H. M.; Andrade, P. R. (2022) <doi:10.31219/osf.io/8m2cy>. ",
    "version": "0.1.1",
    "maintainer": "Joao Bazzo <joao.bazzo@gmail.com>",
    "url": "https://ipeagit.github.io/gtfs2emis/ ,\nhttps://github.com/ipeaGIT/gtfs2emis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14784,
    "package_name": "gtregression",
    "title": "Tools for Creating Publication-Ready Regression Tables",
    "description": "\n  Simplifies regression modeling in R by integrating multiple modeling and summarization\n  tools into a cohesive, user-friendly interface. Designed to be accessible for researchers,\n  particularly those in Low- and Middle-Income Countries (LMIC). Built upon widely accepted \n  statistical methods, including logistic regression (Hosmer et al. 2013, ISBN:9781118548429), \n  log-binomial regression (Spiegelman and Hertzmark 2005 <doi:10.1093/aje/kwi188>), \n  Poisson and robust Poisson regression (Zou 2004 <doi:10.1093/aje/kwh090>), \n  negative binomial regression (Hilbe 2011, ISBN:9780521179515), and linear regression \n  (Kutner et al. 2005, ISBN:9780071122214). Leverages multiple dependencies to ensure \n  high-quality output and generate reproducible, publication-ready tables in alignment with\n  best practices in epidemiology and applied statistics.",
    "version": "1.0.0",
    "maintainer": "Rubeshkumar Polani <rubesh@thinkdenominator.com>",
    "url": "https://thinkdenominator.github.io/gtregression/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14789,
    "package_name": "guaguas",
    "title": "Nombres Inscritos en Chile (1920 - 2021)",
    "description": "Datos de nombres inscritos en Chile\n    entre 1920 y 2021, de acuerdo al Servicio de Registro Civil.\n    English: Chilean baby names registered from 1920 to 2021\n    by the Civil Registry Service.",
    "version": "0.3.0",
    "maintainer": "Riva Quiroga <riva.quiroga@uc.cl>",
    "url": "https://github.com/rivaquiroga/guaguas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14790,
    "package_name": "guardianapi",
    "title": "Access 'The Guardian' Newspaper Open Data API",
    "description": "Access to 'The Guardian' newspaper's open API\n  <https://open-platform.theguardian.com/>, containing all articles published \n  in 'The Guardian' from 1999 to the present, including article text, metadata,\n  tags and contributor information. An API key and registration is required.",
    "version": "0.1.1",
    "maintainer": "Evan Odell <evanodell91@gmail.com>",
    "url": "https://docs.evanodell.com/guardianapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14800,
    "package_name": "gunit",
    "title": "Converts Conductance Units",
    "description": "For plant physiologists, converts conductance (e.g. stomatal conductance) to different units: m/s, mol/m^2/s, and umol/m^2/s/Pa.",
    "version": "1.0.2",
    "maintainer": "Chris Muir <cdmuir@hawaii.edu>",
    "url": "https://github.com/cdmuir/gunit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14818,
    "package_name": "gwpcormapper",
    "title": "Geographically Weighted Partial Correlation Mapper",
    "description": "An interactive mapping tool for geographically weighted correlation and partial correlation. Geographically weighted partial correlation coefficients are calculated following (Percival and Tsutsumida, 2017)<doi:10.1553/giscience2017_01_s36> and are described in greater detail in (Tsutsumida et al., 2019)<doi:10.5194/ica-abs-1-372-2019> and (Percival et al., 2021)<arXiv:2101.03491>.",
    "version": "0.1.3",
    "maintainer": "Joseph Emile Honour Percival <ipercival@gmail.com>",
    "url": "https://github.com/gwpcor/gwpcormapper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14820,
    "package_name": "gwrr",
    "title": "Fits Geographically Weighted Regression Models with Diagnostic\nTools",
    "description": "Fits geographically weighted regression (GWR) models and has tools to diagnose and remediate collinearity in the GWR models. Also fits geographically weighted ridge regression (GWRR) and geographically weighted lasso (GWL) models. See Wheeler (2009) <doi:10.1068/a40256> and Wheeler (2007) <doi:10.1068/a38325> for more details.",
    "version": "0.2-2",
    "maintainer": "David Wheeler <dcwheels@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14828,
    "package_name": "h3",
    "title": "R Bindings for H3",
    "description": "Provides R bindings for H3 <https://h3geo.org/>,",
    "version": "3.7.2",
    "maintainer": "Stefan Kuethe <crazycapivara@gmail.com>",
    "url": "https://github.com/crazycapivara/h3-r",
    "exports": [],
    "topics": ["geocoding", "geospatial", "h3", "hexagon", "r", "r-bindings", "spatial-indexing"],
    "score": "NA",
    "stars": 78
  },
  {
    "id": 14829,
    "package_name": "h3js",
    "title": "R bindings to H3 via h3-js",
    "description": "R bindings to H3 Core Library via h3-js Javascript bindings.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/saurfang/h3js",
    "exports": [],
    "topics": ["geospatial", "h3", "spatial-indexing"],
    "score": "NA",
    "stars": 6
  },
  {
    "id": 14830,
    "package_name": "h3jsr",
    "title": "Access Uber's H3 Library",
    "description": "Provides access to Uber's H3 library for geospatial indexing via its JavaScript transpile 'h3-js' <https://github.com/uber/h3-js> and 'V8' <https://github.com/jeroen/v8>.",
    "version": "1.3.1",
    "maintainer": "Lauren O'Brien <obrlsoilau@gmail.com>",
    "url": "https://obrl-soil.github.io/h3jsr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14831,
    "package_name": "h3lib",
    "title": "Exposes the 'Uber' 'H3' Library to R Packages",
    "description": "'H3' is a hexagonal hierarchical spatial index developed by 'Uber' <https://h3geo.org/>.\n  This package exposes the source code of 'H3' (written in 'C') to routines that are callable through 'R'.",
    "version": "0.1.4",
    "maintainer": "David Cooley <dcooley@symbolix.com.au>",
    "url": "https://github.com/symbolixau/h3lib",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14832,
    "package_name": "h3o",
    "title": "H3 Geospatial Indexing System",
    "description": "A dependency free interface to the H3 geospatial indexing system utilizing the Rust library 'h3o' <https://github.com/HydroniumLabs/h3o> via the 'extendr' library <https://github.com/extendr/extendr>.",
    "version": "0.3.0",
    "maintainer": "Kenneth Vernon <kenneth.b.vernon@gmail.com>",
    "url": "https://github.com/extendr/h3o, https://extendr.rs/h3o/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14833,
    "package_name": "h3r",
    "title": "Hexagonal Hierarchical Geospatial Indexing System",
    "description": "Provides access to Uber's 'H3' geospatial indexing system via 'h3lib' \n  <https://CRAN.R-project.org/package=h3lib>. 'h3r' is designed to mimic the 'H3' \n  Application Programming Interface (API) <https://h3geo.org/docs/api/indexing/>, \n  so that any function in the API is also available in 'h3r'.",
    "version": "0.1.2",
    "maintainer": "David Cooley <dcooley@symbolix.com.au>",
    "url": "https://symbolixau.github.io/h3r/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14840,
    "package_name": "hSDM",
    "title": "Hierarchical Bayesian Species Distribution Models",
    "description": "User-friendly and fast set of functions for estimating parameters of hierarchical Bayesian species distribution models (Latimer and others 2006 <doi:10.1890/04-0609>). Such models allow interpreting the observations (occurrence and abundance of a species) as a result of several hierarchical processes including ecological processes (habitat suitability, spatial dependence and anthropogenic disturbance) and observation processes (species detectability). Hierarchical species distribution models are essential for accurately characterizing the environmental response of species, predicting their probability of occurrence, and assessing uncertainty in the model results.",
    "version": "1.4.4",
    "maintainer": "Ghislain Vieilledent <ghislain.vieilledent@cirad.fr>",
    "url": "https://ecology.ghislainv.fr/hSDM/,\nhttps://github.com/ghislainv/hSDM/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14845,
    "package_name": "hagis",
    "title": "Analysis of Plant Pathogen Pathotype Complexities, Distributions\nand Diversity",
    "description": "Analysis of plant pathogen pathotype survey data.  Functions\n    provided calculate distribution of susceptibilities, distribution of\n    complexities with statistics, pathotype frequency distribution, as\n    well as diversity indices for pathotypes.  This package is meant to be\n    a direct replacement for Herrmann, Löwer and Schachtel's (1999)\n    <doi:10.1046/j.1365-3059.1999.00325.x> Habgood-Gilmour Spreadsheet,\n    'HaGiS', previously used for pathotype analysis.",
    "version": "4.0.0",
    "maintainer": "Adam H. Sparks <adamhsparks@gmail.com>",
    "url": "https://github.com/openplantpathology/hagis,\nhttps://openplantpathology.github.io/hagis/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14853,
    "package_name": "ham",
    "title": "Healthcare Analysis Methods",
    "description": "Conducts analyses for healthcare program evaluations or intervention \n    studies. Calculates regression analyses for standard ordinary least squares \n    (OLS or linear) or logistic models. Performs regression models used for \n    causal modeling such as differences-in-differences (DID) and interrupted \n    time series (ITS) models. Provides limited interpretations of model \n    results and a ranking of variable importance in models. Performs \n    propensity score models, top-coding of model outcome variables, and \n    can return new data with the newly formed variables. Also performs Cronbach's \n    alpha for various scale items (e.g., survey questions). See Github URL for \n    examples in the README file. For more details on the statistical methods, see \n    Allen & Yen (1979, ISBN:0-8185-0283-5), \n    Angrist & Pischke (2009, ISBN:9780691120355), \n    Harrell (2016, ISBN:978-3-319-19424-0), \n    Kline (1999, ISBN:9780415211581),  \n    Linden (2015) <doi:10.1177/1536867X1501500208>,\n    Merlo (2006) <doi:10.1136/jech.2004.029454>\n    Muthen & Satorra (1995) <doi:10.2307/271070>, and\n    Rabe-Hesketh & Skrondal (2008, ISBN:978-1-59718-040-5).",
    "version": "1.1.0",
    "maintainer": "Stephen Zuniga <rms.shiny@gmail.com>",
    "url": "https://github.com/szuniga07/ham",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14865,
    "package_name": "haplo.ccs",
    "title": "Estimate Haplotype Relative Risks in Case-Control Data",
    "description": "Haplotype and covariate relative risks in case-control data are estimated by weighted logistic regression. Diplotype probabilities, which are estimated by EM computation with progressive insertion of loci, are utilized as weights. French et al. (2006) <doi:10.1002/gepi.20161>.",
    "version": "1.3.3",
    "maintainer": "Benjamin French <b.french@vumc.org>",
    "url": "https://github.com/vubiostat/haplo.ccs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14869,
    "package_name": "happign",
    "title": "R Interface to 'IGN' Web Services",
    "description": "Automatic open data acquisition from resources of IGN\n    ('Institut National de Information Geographique et forestiere')\n    (<https://www.ign.fr/>). Available datasets include various types of\n    raster and vector data, such as digital elevation models, state\n    borders, spatial databases, cadastral parcels, and more. 'happign' also \n    provide access to API Carto (<https://apicarto.ign.fr/api/doc/>).",
    "version": "0.3.7",
    "maintainer": "Paul Carteron <carteronpaul@gmail.com>",
    "url": "https://github.com/paul-carteron,\nhttps://paul-carteron.github.io/happign/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14890,
    "package_name": "hazer",
    "title": "Identifying Foggy and Cloudy Images by Quantifying Haziness",
    "description": "Provides a set of functions to estimate haziness of an image based on RGB bands. It returns a haze factor, varying from 0 to 1, a metric for fogginess and cloudiness. The package also presents additional functions to estimate brightness, darkness and contrast rasters of the RGB image. This package can be used for several applications such as inference of weather quality data and performing environmental studies from interpreting digital images.",
    "version": "1.1.1",
    "maintainer": "Bijan Seyednasrollah <bijan.s.nasr@gmail.com>",
    "url": "https://github.com/bnasr/hazer/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14903,
    "package_name": "hchinamap",
    "title": "Mapping China and Its Provinces",
    "description": "By binding R functions and the 'Highmaps' <https://www.highcharts.com.cn/products/highmaps> chart library, 'hchinamap' package provides a simple way to map China and its provinces. The map of China drawn by this package contains complete Chinese territory, especially the Nine-dotted line, South Tibet, Hong Kong, Macao and Taiwan.",
    "version": "0.1.0",
    "maintainer": "Zhenxing Cheng <czxjnu@163.com>",
    "url": "https://github.com/czxa/hchinamap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14943,
    "package_name": "healthatlas",
    "title": "Explore and Import 'Metopio' Health Atlas Data and Spatial\nLayers",
    "description": "Allows for painless use of the 'Metopio' health atlas APIs\n    <https://metopio.com/health-atlas> to explore and import data.\n    'Metopio' health atlases store open public health data. See what topics\n    (or indicators) are available among specific populations, periods, and\n    geographic layers. Download relevant data along with geographic \n    boundaries or point datasets. Spatial datasets are returned as 'sf' \n    objects.",
    "version": "0.2.2",
    "maintainer": "Ryan Zomorrodi <rzomor2@uic.edu>",
    "url": "https://ryanzomorrodi.github.io/healthatlas/,\nhttps://github.com/ryanzomorrodi/healthatlas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14951,
    "package_name": "healthyAddress",
    "title": "Convert Addresses to Standard Inputs",
    "description": "Efficient tools for parsing and standardizing Australian \n    addresses from textual data. It utilizes optimized algorithms to accurately identify and \n    extract components of addresses, such as street names, types, and postcodes, especially  \n    for large batched data in contexts where sending addresses to internet services may be \n    slow or inappropriate. The core functionality is built on fast string processing techniques \n    to handle variations in address formats and abbreviations commonly found in Australian \n    address data. Designed for data scientists, urban planners, and logistics analysts, the \n    package facilitates the cleaning and normalization of address information, supporting \n    better data integration and analysis in urban studies, geography, and related fields.",
    "version": "0.5.1",
    "maintainer": "Hugh Parsonage <hugh.parsonage@gmail.com>",
    "url": "https://github.com/HughParsonage/healthyAddress",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 14999,
    "package_name": "heterogen",
    "title": "Spatial Functions for Heterogeneity and Climate Variability",
    "description": "A comprehensive suite of spatial \n  functions created to analyze and assess data heterogeneity and climate variability \n  in spatial datasets. This package is specifically designed to address the challenges associated\n  with characterizing and understanding complex spatial patterns in environmental and climate-related data.",
    "version": "1.2.33",
    "maintainer": "P.Joser Atauchi <patauchi@gmail.com>",
    "url": "https://github.com/patauchi/heterogen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15011,
    "package_name": "hexDensity",
    "title": "Fast Kernel Density Estimation with Hexagonal Grid",
    "description": "Kernel density estimation with hexagonal grid for bivariate data.\n      Hexagonal grid has many beneficial properties like equidistant neighbours\n      and less edge bias, making it better for spatial analyses than the more\n      commonly used rectangular grid.\n      Carr, D. B. et al. (1987) <doi:10.2307/2289444>.\n      Diggle, P. J. (2010) <doi:10.1201/9781420072884>.\n      Hill, B. (2017) <https://blog.bruce-hill.com/meandering-triangles>.\n      Jones, M. C. (1993) <doi:10.1007/BF00147776>.",
    "version": "1.4.10",
    "maintainer": "Quoc Hoang Nguyen <nguyen.q@wehi.edu.au>",
    "url": "https://github.com/ChenLaboratory/hexDensity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15015,
    "package_name": "hexfont",
    "title": "'GNU Unifont' Hex Fonts",
    "description": "Contains most of the hex font files from the 'GNU Unifont Project' <https://unifoundry.com/unifont/> compressed by 'xz'.  'GNU Unifont' is a duospaced bitmap font that attempts to cover all the official Unicode glyphs plus several of the artificial scripts in the '(Under-)ConScript Unicode Registry' <https://www.kreativekorp.com/ucsur/>.  Provides a convenience function for loading in several of them at the same time as a 'bittermelon' bitmap font object for easy rendering of the glyphs in an 'R' terminal or graphics device.",
    "version": "1.0.0",
    "maintainer": "Trevor L. Davis <trevor.l.davis@gmail.com>",
    "url": "https://github.com/trevorld/hexfont,\nhttps://trevorldavis.com/R/hexfont/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15021,
    "package_name": "hglm",
    "title": "Hierarchical Generalized Linear Models",
    "description": "Implemented here are procedures for fitting hierarchical generalized linear models (HGLM). It can be used for linear mixed models and generalized linear mixed models with random effects for a variety of links and a variety of distributions for both the outcomes and the random effects. Fixed effects can also be fitted in the dispersion part of the mean model. As statistical models, HGLMs were initially developed by Lee and Nelder (1996) <https://www.jstor.org/stable/2346105?seq=1>. We provide an implementation (Ronnegard, Alam and Shen 2010) <https://journal.r-project.org/archive/2010-2/RJournal_2010-2_Roennegaard~et~al.pdf> following Lee, Nelder and Pawitan (2006) <ISBN: 9781420011340> with algorithms extended for spatial modeling (Alam, Ronnegard and Shen 2015) <https://journal.r-project.org/archive/2015/RJ-2015-017/RJ-2015-017.pdf>. ",
    "version": "2.2-1",
    "maintainer": "Xia Shen <xia.shen@ki.se>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15024,
    "package_name": "hgnc",
    "title": "Import Human Gene Nomenclature",
    "description": "A set of routines to quickly download and import the\n    HUGO Gene Nomenclature Committee (HGNC) data set on mapping of\n    gene symbols to gene entries in other genomic databases or resources.",
    "version": "0.3.0",
    "maintainer": "Ramiro Magno <rmagno@pattern.institute>",
    "url": "https://github.com/patterninstitute/hgnc,\nhttps://www.pattern.institute/hgnc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15026,
    "package_name": "hgwrr",
    "title": "Hierarchical and Geographically Weighted Regression",
    "description": "This model divides coefficients into three types,\n        i.e., local fixed effects, global fixed effects, and random effects (Hu et al., 2022)<doi:10.1177/23998083211063885>.\n        If data have spatial hierarchical structures (especially are overlapping on some locations),\n        it is worth trying this model to reach better fitness.",
    "version": "0.6-2",
    "maintainer": "Yigong Hu <yigong.hu@bristol.ac.uk>",
    "url": "https://github.com/HPDell/hgwrr/, https://hpdell.github.io/hgwrr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15067,
    "package_name": "hillshader",
    "title": "Create Hillshade Relief Maps Using Ray-Tracing",
    "description": "A set of tools to create georeferenced hillshade relief \n    raster maps using ray-tracing and other advanced hill-shading \n    techniques. It includes a wrapper function to create a georeferenced,\n    ray-traced hillshade map from a digital elevation model, and other\n    functions that can be used in a rayshader pipeline. ",
    "version": "0.1.2",
    "maintainer": "Pierre Roudier <pierre.roudier@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15092,
    "package_name": "hkevp",
    "title": "Spatial Extreme Value Analysis with the Hierarchical Model of\nReich and Shaby (2012)",
    "description": "Several procedures for the hierarchical kernel extreme value process of Reich and Shaby (2012) <DOI:10.1214/12-AOAS591>, including simulation, estimation and spatial extrapolation. The spatial latent variable model <DOI:10.1214/11-STS376> is also included.",
    "version": "1.1.6",
    "maintainer": "Leo Belzile <belzilel@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15115,
    "package_name": "holcmapr",
    "title": "Compare Mapping Methodologies for Home Owners' Loan Corporation (HOLC)",
    "description": "Provides a Shiny application for implementing and comparing methods of",
    "version": "1.0.1",
    "maintainer": "",
    "url": "https://github.com/mitre/holcmapr",
    "exports": [],
    "topics": ["equity", "geospatial", "health", "holc", "redlining"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 15116,
    "package_name": "holi",
    "title": "Higher Order Likelihood Inference Web Applications",
    "description": "Higher order likelihood inference is a promising approach for\n    analyzing small sample size data. The 'holi' package provides web applications\n    for higher order likelihood inference. It currently supports linear, logistic,\n    and Poisson generalized linear models through the rstar_glm() function, based\n    on Pierce and Bellio (2017) <doi:10.1111/insr.12232> and 'likelihoodAsy'.\n    The package offers two main features: LA_rstar(), which launches an interactive\n    'shiny' application allowing users to fit models with rstar_glm() through their\n    web browser, and sim_rstar_glm_pgsql(), which streamlines the process of\n    launching a web-based 'shiny' simulation application that saves results to a\n    user-created 'PostgreSQL' database.",
    "version": "0.1.1",
    "maintainer": "Mackson Ncube <macksonncube.stats@gmail.com>",
    "url": "https://github.com/mightymetrika/holi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15134,
    "package_name": "horseshoenlm",
    "title": "Nonlinear Regression using Horseshoe Prior",
    "description": "Provides the posterior estimates of the regression coefficients when horseshoe prior is specified. \n             The regression models considered here are logistic model for binary response and \n             log normal accelerated failure time model for right censored survival response. \n             The linear model analysis is also available for completeness. \n             All models provide deviance information criterion and widely applicable information criterion. \n             See <doi:10.1111/rssc.12377> Maity et. al. (2019) <doi:10.1111/biom.13132> Maity et. al. (2020).  ",
    "version": "0.0.6",
    "maintainer": "Arnab Kumar Maity <Arnab.Maity@pfizer.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15135,
    "package_name": "hosm",
    "title": "High Order Spatial Matrix",
    "description": "Automatically displays the order and spatial weighting matrix of the distance between locations. This concept was derived from the research of Mubarak, Aslanargun, and Siklar (2021) <doi:10.52403/ijrr.20211150> and Mubarak, Aslanargun, and Siklar (2022) <doi:10.17654/0972361722052>. Distance data between locations can be imported from 'Ms. Excel', 'maps' package or created in 'R' programming directly. This package also provides 5 simulations of distances between locations derived from fictitious data, the 'maps' package, and from research by Mubarak, Aslanargun, and Siklar (2022) <doi:10.29244/ijsa.v6i1p90-100>.",
    "version": "0.1.0",
    "maintainer": "Fadhlul Mubarak <mubarakfadhlul@gmail.com>",
    "url": "https://github.com/mubarakfadhlul/hosm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15165,
    "package_name": "hspm",
    "title": "Heterogeneous Spatial Models",
    "description": "Spatial heterogeneity can be specified in various ways. 'hspm' is an ambitious project that aims at implementing various methodologies to control for heterogeneity in spatial models. The current version of 'hspm' deals with spatial and (non-spatial) regimes models. In particular, the package allows to estimate a general spatial regimes model with additional endogenous variables, specified in terms of a spatial lag of the dependent variable, the spatially lagged regressors, and, potentially, a spatially autocorrelated error term. Spatial regime models are estimated by instrumental variables and generalized methods of moments (see Arraiz et al., (2010) <doi:10.1111/j.1467-9787.2009.00618.x>, Bivand and Piras, (2015) <doi:10.18637/jss.v063.i18>, Drukker et al., (2013) <doi:10.1080/07474938.2013.741020>, Kelejian and Prucha, (2010) <doi:10.1016/j.jeconom.2009.10.025>).",
    "version": "1.1",
    "maintainer": "Gianfranco Piras <gpiras@mac.com>",
    "url": "https://github.com/gpiras/hspm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15227,
    "package_name": "hydReng",
    "title": "Hydraulic Engineering Tools",
    "description": "The 'hydReng' package provides a set of functions for hydraulic engineering tasks and natural hazard assessments. It includes basic hydraulics (wetted area, wetted perimeter, flow, flow velocity, flow depth, and maximum flow) for open channels with arbitrary geometry under uniform flow conditions. For structures such as circular pipes, weirs, and gates, the package includes calculations for pressure flow, backwater depth, and overflow over a weir crest. Additionally, it provides formulas for calculating bedload transport. The formulas used can be found in standard literature on hydraulics, such as Bollrich (2019, ISBN:978-3-410-29169-5) or Hager (2011, ISBN:978-3-642-77430-0).",
    "version": "1.0.0",
    "maintainer": "Galatioto Niccolo <niccolo.galatioto@gmail.com>",
    "url": "https://github.com/NiccoloGalatioto/hydReng",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15236,
    "package_name": "hydroTSM",
    "title": "Time Series Management and Analysis for Hydrological Modelling",
    "description": "S3 functions for management, analysis, interpolation and plotting of time series used in hydrology and related environmental sciences. In particular, this package is highly oriented to hydrological modelling tasks. The focus of this package has been put in providing a collection of tools useful for the daily work of hydrologists (although an effort was made to optimise each function as much as possible, functionality has had priority over speed). Bugs / comments / questions / collaboration of any kind are very welcomed, and in particular, datasets that can be included in this package for academic purposes.",
    "version": "0.7-0.1",
    "maintainer": "Mauricio Zambrano-Bigiarini <mzb.devel@gmail.com>",
    "url": "https://github.com/hzambran/hydroTSM,\nhttps://cran.r-project.org/package=hydroTSM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15245,
    "package_name": "hyfo",
    "title": "Hydrology and Climate Forecasting",
    "description": "Focuses on data processing and visualization in hydrology and\n    climate forecasting. Main function includes data extraction, data downscaling,\n    data resampling, gap filler of precipitation, bias correction of forecasting\n    data, flexible time series plot, and spatial map generation. It is a good pre-\n    processing and post-processing tool for hydrological and hydraulic modellers.",
    "version": "1.4.6",
    "maintainer": "Yuanchao Xu <xuyuanchao37@gmail.com>",
    "url": "https://yuanchao-xu.github.io/hyfo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15259,
    "package_name": "hypervolume",
    "title": "High Dimensional Geometry, Set Operations, Projection, and\nInference Using Kernel Density Estimation, Support Vector\nMachines, and Convex Hulls",
    "description": "Estimates the shape and volume of high-dimensional datasets and performs set operations: intersection / overlap, union, unique components, inclusion test, and hole detection. Uses stochastic geometry approach to high-dimensional kernel density estimation, support vector machine delineation, and convex hull generation. Applications include modeling trait and niche hypervolumes and species distribution modeling.",
    "version": "3.1.6",
    "maintainer": "Benjamin Blonder <benjamin.blonder@berkeley.edu>",
    "url": "https://github.com/bblonder/hypervolume",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15322,
    "package_name": "iRfcb",
    "title": "Tools for Managing Imaging FlowCytobot (IFCB) Data",
    "description": "A comprehensive suite of tools for managing, processing, and\n    analyzing data from the IFCB. I R FlowCytobot ('iRfcb') supports\n    quality control, geospatial analysis, and preparation of IFCB data for\n    publication in databases like <https://www.gbif.org>,\n    <https://www.obis.org>, <https://emodnet.ec.europa.eu/en>,\n    <https://shark.smhi.se/en/>, and <https://www.ecotaxa.org>. The package\n    integrates with the MATLAB 'ifcb-analysis' tool, which is described in\n    Sosik and Olson (2007) <doi:10.4319/lom.2007.5.204>, and provides\n    features for working with raw, manually classified, and machine\n    learning–classified image datasets. Key functionalities include image\n    extraction, particle size distribution analysis, taxonomic data\n    handling, and biomass concentration calculations, essential for\n    plankton research.",
    "version": "0.7.0",
    "maintainer": "Anders Torstensson <anders.torstensson@smhi.se>",
    "url": "https://europeanifcbgroup.github.io/iRfcb/,\nhttps://github.com/EuropeanIFCBGroup/iRfcb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15335,
    "package_name": "iSTAY",
    "title": "Information-Based Stability and Synchrony Measures",
    "description": "Provides functions to to compute a continuum of information-based measures \n for quantifying the temporal stability of populations, communities, and ecosystems, \n as well as their associated synchrony, based on species (or species assemblage)\n biomass or other key variables. When biodiversity data are available, the package\n also enables the assessment of the corresponding diversity–stability relationships.\n All measures are applicable in both temporal and spatial contexts. The theoretical\n and methodological background is detailed in Chao et al. (2025) \n <doi:10.1101/2025.08.20.671203>.",
    "version": "1.0.0",
    "maintainer": "Anne Chao <chao@stat.nthu.edu.tw>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15400,
    "package_name": "icmm",
    "title": "Empirical Bayes Variable Selection via ICM/M Algorithm",
    "description": "Empirical Bayes variable selection via ICM/M algorithm for normal, binary logistic, and Cox's regression. The basic problem is to fit high-dimensional regression which sparse coefficients. This package allows incorporating the Ising prior to capture structure of predictors in the modeling process. More information can be found in the papers listed in the URL below.",
    "version": "1.2",
    "maintainer": "Vitara Pungpapong <vitara@cbs.chula.ac.th>",
    "url": "https://www.researchgate.net/publication/279279744_Selecting_massive_variables_using_an_iterated_conditional_modesmedians_algorithm,\nhttps://doi.org/10.1089/cmb.2019.0319",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15402,
    "package_name": "icosa",
    "title": "Global Triangular and Penta-Hexagonal Grids Based on Tessellated\nIcosahedra",
    "description": "Implementation of icosahedral grids in three dimensions. The spherical-triangular tessellation can be set to create grids with custom resolutions. Both the primary triangular and their inverted penta-hexagonal grids can be calculated. Additional functions are provided that allow plotting of the grids and associated data, the interaction of the grids with other raster and vector objects, and treating the grids as a graphs.",
    "version": "0.12.0",
    "maintainer": "Adam T. Kocsis <adam.t.kocsis@gmail.com>",
    "url": "https://icosa-grid.github.io/R-icosa/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15406,
    "package_name": "idar",
    "title": "Individual Diversity-Area Relationships",
    "description": "Computes and tests individual (species, phylogenetic and functional) diversity-area relationships, i.e., how species-, phylogenetic- and functional-diversity varies with spatial scale around the individuals of some species in a community. See applications of these methods in Wiegand et al. (2007) <doi:10.1073/pnas.0705621104> or Chacon-Labella et al. (2016) <doi:10.1007/s00442-016-3547-z>.",
    "version": "1.6",
    "maintainer": "Marcelino de la Cruz <marcelino.delacruz@urjc.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15426,
    "package_name": "idopNetwork",
    "title": "A Network Tool to Dissect Spatial Community Ecology",
    "description": "Most existing approaches for network reconstruction can only infer an overall network \n\tand, also, fail to capture a complete set of network properties. To address these issues, \n\ta new model has been developed, which converts static data into their 'dynamic' form. \n\t'idopNetwork' is an 'R' interface to this model, it can inferring informative, dynamic, \n\tomnidirectional and personalized networks. For more information on functional \n\tclustering part, see Kim et al. (2008) <doi:10.1534/genetics.108.093690>, \n\tWang et al. (2011) <doi:10.1093/bib/bbr032>. For more information on our model, \n\tsee Chen et al. (2019) <doi:10.1038/s41540-019-0116-1>, and Cao et al. (2022) \n\t<doi:10.1080/19490976.2022.2106103>.",
    "version": "0.1.2",
    "maintainer": "Ang Dong <fantasys05227@gmail.com>",
    "url": "https://github.com/cxzdsa2332/idopNetwork",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15455,
    "package_name": "igr",
    "title": "Irish Grid Reference Utilities",
    "description": "Convert between Irish grid references and Irish Grid coordinates. Irish grid \n    references can also be converted to or from an 'sf' object in any coordinate reference \n    system. Precisions from 1 m to 100 km including 2 km (tetrads) are supported, as are \n    datasets with mixed precision. Conversion to 'sf' polygons is precision-aware.",
    "version": "1.0.1",
    "maintainer": "John Kennedy <john@digitalnature.ie>",
    "url": "https://github.com/digitalnature-ie/igr,\nhttps://digitalnature-ie.github.io/igr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15483,
    "package_name": "imageRy",
    "title": "Modify and Share Images",
    "description": "Tools for manipulating, visualizing, and exporting raster images in R.\n Designed as an educational resource for students learning the basics of remote sensing,\n the package provides user-friendly functions to apply color ramps, export RGB composites,\n and create multi-frame visualizations. Built on top of the 'terra' and 'ggplot2' packages.\n See <https://github.com/ducciorocchini/imageRy> for more details and examples.",
    "version": "0.3.0",
    "maintainer": "Ludovico Chieffallo <ludovico.chieffallo2@unibo.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15486,
    "package_name": "imager",
    "title": "Image Processing Library Based on 'CImg'",
    "description": "Fast image processing for images in up to 4 dimensions (two spatial\n    dimensions, one time/depth dimension, one colour dimension). Provides most\n    traditional image processing tools (filtering, morphology, transformations,\n    etc.) as well as various functions for easily analysing image data using R. The\n    package wraps 'CImg', <https://cimg.eu>, a simple, modern C++ library for image\n    processing.",
    "version": "1.0.8",
    "maintainer": "Aaron Robotham <aaron.robotham@uwa.edu.au>",
    "url": "https://asgr.github.io/imager/, https://github.com/asgr/imager/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15495,
    "package_name": "imcExperiment",
    "title": "Mass Cytometry S4 Class Structure Pipeline for Images",
    "description": "Containerizes cytometry data and allows for S4 class structure to extend slots related to cell morphology, spatial coordinates, phenotype network information, and unique cellular labeling.",
    "version": "0.99.0",
    "maintainer": "Anthony Colombo <anthonycolombo60@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15540,
    "package_name": "imt",
    "title": "Impact Measurement Toolkit",
    "description": "A toolkit for causal inference in experimental and observational \n    studies. Implements various simple Bayesian models including linear, \n    negative binomial, and logistic regression for impact estimation. \n    Provides functionality for randomization and checking baseline equivalence \n    in experimental designs. The package aims to simplify the process of \n    impact measurement for researchers and analysts across different fields. \n    Examples and detailed usage instructions are available at \n    <https://book.martinez.fyi>.",
    "version": "1.0.0",
    "maintainer": "Ignacio Martinez <martinezig@google.com>",
    "url": "https://github.com/google/imt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15564,
    "package_name": "indiedown",
    "title": "Individual R Markdown Templates",
    "description": "Simplifies the generation of customized R Markdown PDF templates.\n    A template may include an individual logo, typography, geometry or color\n    scheme. The package provides a skeleton with detailed instructions for\n    customizations. The skeleton can be modified by changing defaults in the\n    'YAML' header, by adding additional 'LaTeX' commands or by applying dynamic\n    adjustments in R. Individual corporate design elements, such as a title page, can be added as R functions that produce 'LaTeX' code.",
    "version": "0.1.1",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "url": "https://cynkra.github.io/indiedown/,\nhttps://github.com/cynkra/indiedown",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15570,
    "package_name": "inecolr",
    "title": "Modeling and Plotting for Ecologist",
    "description": "It provides multiple functions that are useful for ecological research and teaching statistics to ecologists. It is based on data analysis courses offered at the Instituto de Ecología AC (INECOL). For references and published evidence see, Manrique-Ascencio, et al (2024) <doi:10.1111/gcb.17282>, Manrique-Ascencio et al (2024) <doi:10.1111/plb.13683>, Ruiz-Guerra et al(2017) <doi:10.17129/botsci.812>, Juarez-Fragoso et al (2024) <doi:10.1007/s10980-024-01809-z>, Papaqui-Bello et al (2024) <doi:10.13102/sociobiology.v71i2.10503>.",
    "version": "0.1.0",
    "maintainer": "Roger Guevara <roger.guevara@inecol.mx>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15594,
    "package_name": "infocausality",
    "title": "Information-Theoretic Measure of Causality",
    "description": "Methods for quantifying temporal and spatial causality through information flow, and decomposing it into unique, redundant, and synergistic components, following the framework described in Martinez-Sanchez et al. (2024) <doi:10.1038/s41467-024-53373-4>.",
    "version": "1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/infocausality/,\nhttps://github.com/stscl/infocausality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15605,
    "package_name": "inlabru",
    "title": "Bayesian Latent Gaussian Modelling using INLA and Extensions",
    "description": "Facilitates spatial and general latent Gaussian modeling using\n  integrated nested Laplace approximation via the INLA package (<https://www.r-inla.org>).\n  Additionally, extends the GAM-like model class to more general nonlinear predictor\n  expressions, and implements a log Gaussian Cox process likelihood for \n  modeling univariate and spatial point processes based on ecological survey data.\n  Model components are specified with general inputs and mapping methods to the\n  latent variables, and the predictors are specified via general R expressions,\n  with separate expressions for each observation likelihood model in\n  multi-likelihood models. A prediction method based on fast Monte Carlo sampling\n  allows posterior prediction of general expressions of the latent variables.\n  Ecology-focused introduction in Bachl, Lindgren, Borchers, and Illian (2019)\n  <doi:10.1111/2041-210X.13168>.",
    "version": "2.13.0",
    "maintainer": "Finn Lindgren <finn.lindgren@gmail.com>",
    "url": "http://www.inlabru.org, https://inlabru-org.github.io/inlabru/,\nhttps://github.com/inlabru-org/inlabru",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15620,
    "package_name": "insetplot",
    "title": "Inset Plots for Spatial Data Visualization",
    "description": "Tools for easily and flexibly creating 'ggplot2' maps with inset maps. One crucial feature of maps is that they have fixed coordinate ratios, i.e., they cannot be distorted, which makes it difficult to manually place inset maps. This package provides functions to automatically position inset maps based on user-defined parameters, making it extremely easy to create maps with inset maps with minimal code.",
    "version": "1.3.0",
    "maintainer": "Chao Kong <kongchao1998@gmail.com>",
    "url": "https://fncokg.github.io/insetplot/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15636,
    "package_name": "intSDM",
    "title": "Reproducible Integrated Species Distribution Models Across\nNorway using 'INLA'",
    "description": "Integration of disparate datasets is needed in order to make efficient use of all available data and thereby address the issues currently threatening biodiversity.\n   Data integration is a powerful modeling framework which allows us to combine these datasets together into a single model, yet retain the strengths of each individual dataset.\n   We therefore introduce the package, 'intSDM': an R package designed to help ecologists develop a reproducible workflow of integrated species distribution models, using data both provided from the user as well as data obtained freely online.\n   An introduction to data integration methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O’Hara (2020) <doi:10.1016/j.tree.2019.08.006>.",
    "version": "2.1.2",
    "maintainer": "Philip Mostert <philip.s.mostert@ntnu.no>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15637,
    "package_name": "intamap",
    "title": "Procedures for Automated Interpolation",
    "description": "Geostatistical interpolation has traditionally been done by manually fitting a variogram and then interpolating. Here, we introduce classes and methods that can do this interpolation automatically. Pebesma et al (2010) gives an overview of the methods behind and possible usage <doi:10.1016/j.cageo.2010.03.019>.",
    "version": "1.5-11",
    "maintainer": "Jon Olav Skoien <jon.skoien@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15646,
    "package_name": "intensitynet",
    "title": "Intensity Analysis of Spatial Point Patterns on Complex Networks",
    "description": "Tools to analyze point patterns in space occurring over planar network structures derived from graph-related intensity measures for undirected, directed, and mixed networks. \n    This package is based on the following research: Eckardt and Mateu (2018) <doi:10.1080/10618600.2017.1391695>. Eckardt and Mateu (2021) <doi:10.1007/s11749-020-00720-4>.",
    "version": "1.4.0",
    "maintainer": "Pol Llagostera <pol.llagostera@udl.cat>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15655,
    "package_name": "interca",
    "title": "Multiple Correspondence Analysis Based on Interpretive\nCoordinates",
    "description": "Various functions and a Shiny app to enrich the results of Multiple Correspondence Analysis with interpretive axes and planes (see Moschidis, Markos, and Thanopoulos, 2022; <doi:10.1108/ACI-07-2022-0191>). ",
    "version": "0.1.2",
    "maintainer": "Stratos Moschidis <smos@statistics.gr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15666,
    "package_name": "interp",
    "title": "Interpolation Methods",
    "description": "Bivariate data interpolation on regular and irregular\n  grids, either linear or using splines are the main part of this\n  package.  It is intended to provide FOSS replacement functions for\n  the ACM licensed akima::interp and tripack::tri.mesh functions.\n  Linear interpolation is implemented in \n  interp::interp(..., method=\"linear\"), this corresponds to the call \n  akima::interp(..., linear=TRUE) which is the default setting and \n  covers most of akima::interp use cases in depending packages.  \n  A re-implementation of Akimas irregular grid spline\n  interpolation (akima::interp(..., linear=FALSE)) is now also\n  available via interp::interp(..., method=\"akima\").\n  Estimators for partial derivatives are now also available in \n  interp::locpoly(), these are a prerequisite for the spline interpolation.  \n  The basic part is a GPLed triangulation algorithm (sweep hull \n  algorithm by David Sinclair) providing the starting point for the\n  irregular grid interpolator. As side effect this algorithm is also\n  used to provide replacements for almost all functions of the tripack\n  package which also suffers from the same ACM license restrictions.  \n  All functions are designed to be backward compatible with their \n  akima / tripack counterparts.",
    "version": "1.1-6",
    "maintainer": "Albrecht Gebhardt <albrecht.gebhardt@aau.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15682,
    "package_name": "intkrige",
    "title": "A Numerical Implementation of Interval-Valued Kriging",
    "description": "An interval-valued extension of ordinary and simple kriging.\n    Optimization of the function is based on a generalized interval distance.\n    This creates a non-differentiable cost function that requires a\n    differentiable approximation to the absolute value function. This\n    differentiable approximation is optimized using a Newton-Raphson algorithm\n    with a penalty function to impose the constraints. Analyses in the package\n    are driven by the 'intsp' and 'intgrd' \n    classes, \n    which are interval-valued extensions of\n    'SpatialPointsDataFrame' and 'SpatialPixelsDataFrame' respectively. \n    The package includes several wrappers to functions in the \n    'gstat' and 'sp' packages.",
    "version": "1.0.2",
    "maintainer": "Brennan Bean <brennan.bean@usu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15684,
    "package_name": "intmed",
    "title": "Mediation Analysis using Interventional Effects",
    "description": "Implementing the interventional effects for mediation analysis for up to 3 mediators.\n    The methods used are based on VanderWeele, Vansteelandt and Robins (2014) <doi:10.1097/ede.0000000000000034>, \n    Vansteelandt and Daniel (2017) <doi:10.1097/ede.0000000000000596> and Chan and Leung (2020; unpublished manuscript, available on request from the author of this package).\n    Linear regression, logistic regression and Poisson regression are used for continuous, binary \n    and count mediator/outcome variables respectively.",
    "version": "0.1.2",
    "maintainer": "Gary Chan <c.chan4@uq.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15709,
    "package_name": "iopsych",
    "title": "Methods for Industrial/Organizational Psychology",
    "description": "Collection of functions for IO Psychologists.",
    "version": "0.90.1",
    "maintainer": "Allen Goebl <goebl005@umn.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15714,
    "package_name": "ip2location",
    "title": "Lookup for IP Address Information",
    "description": "Enables the user to find the country, region, district, city, coordinates, zip code, time zone, ISP, domain name, connection type, area code, weather, Mobile Country Code, Mobile Network Code, mobile brand name, elevation, usage type, address type, IAB category and Autonomous system information that any IP address or hostname originates from. Supported IPv4 and IPv6.\n        Please visit <https://www.ip2location.com> to learn more. You may also want to visit <https://lite.ip2location.com> for free database download.\n        This package requires 'IP2Location Python' module. At the terminal, please run 'pip install IP2Location' to install the module.",
    "version": "8.1.3",
    "maintainer": "Kai Wen Ooi <support@ip2location.com>",
    "url": "https://github.com/ip2location/ip2location-r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15718,
    "package_name": "ip2whois",
    "title": "Lookup 'WHOIS' Information for a Particular Domain",
    "description": "Easily implement the checking of 'WHOIS' information for a particular domain. 'IP2WHOIS' supports the query for 1113 Top-level Domains(TLDs) and 634 Country Code Top-level Domains(ccTLDs).\n    To get started with a free API key, you may sign up at here <https://www.ip2whois.com/register>.",
    "version": "1.0.0",
    "maintainer": "IP2WHOIS <support@ip2whois.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15723,
    "package_name": "ipbase",
    "title": "Client for the 'ipbase.com' IP Geolocation API",
    "description": "An R client for the 'ipbase.com' IP Geolocation API. The API requires registration of an API key. Basic features are free, some require a paid subscription. You can find the full API documentation at <https://ipbase.com/docs> .",
    "version": "0.1.1",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://ipbase.com, https://ipbase.com/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15727,
    "package_name": "ipdw",
    "title": "Spatial Interpolation by Inverse Path Distance Weighting",
    "description": "Functions are provided to interpolate geo-referenced point data via\n    Inverse Path Distance Weighting. Useful for coastal marine applications where\n    barriers in the landscape preclude interpolation with Euclidean distances.",
    "version": "2.0-0",
    "maintainer": "Jemma Stachelek <jemma.stachelek@gmail.com>",
    "url": "https://github.com/jsta/ipdw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15736,
    "package_name": "iplookupapi",
    "title": "Client for the 'iplookupapi.com' IP Lookup API",
    "description": "An R client for the 'iplookupapi.com' IP Lookup API. The API requires registration of an API key. Basic features are free, some require a paid subscription. You can find the full API documentation at <https://iplookupapi.com/docs> .",
    "version": "0.1.0",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://iplookupapi.com, https://iplookupapi.com/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15744,
    "package_name": "ipsecr",
    "title": "Spatially Explicit Capture-Recapture by Inverse Prediction",
    "description": "Estimates the density of a spatially distributed animal population \n  sampled with an array of passive detectors, such as traps. Models incorporating \n  distance-dependent detection are fitted by simulation and inverse prediction \n  as proposed by Efford (2004) <doi:10.1111/j.0030-1299.2004.13043.x>.",
    "version": "1.4.4",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "url": "https://github.com/MurrayEfford/ipsecr/,\nhttps://www.otago.ac.nz/density/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15748,
    "package_name": "ipwCoxCSV",
    "title": "Inverse Probability Weighted Cox Model with Corrected Sandwich\nVariance",
    "description": "An implementation of corrected sandwich variance (CSV) estimation method for making inference of marginal hazard ratios (HR) in inverse probability weighted (IPW) Cox model without and with clustered data, proposed by Shu, Young, Toh, and Wang (2019) in their paper under revision for Biometrics. Both conventional inverse probability weights and stabilized weights are implemented. Logistic regression model is assumed for propensity score model.",
    "version": "1.0",
    "maintainer": "Di Shu <shudi1991@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15749,
    "package_name": "ipwErrorY",
    "title": "Inverse Probability Weighted Estimation of Average Treatment\nEffect with Misclassified Binary Outcome",
    "description": "An implementation of the correction methods proposed by Shu and Yi (2017) <doi:10.1177/0962280217743777> for the inverse probability weighted (IPW) estimation of average treatment effect (ATE) with misclassified binary outcomes. Logistic regression model is assumed for treatment model for all implemented correction methods, and is assumed for the outcome model for the implemented doubly robust correction method. Misclassification probability given a true value of the outcome is assumed to be the same for all individuals.",
    "version": "2.1",
    "maintainer": "Di Shu <shudi1991@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15756,
    "package_name": "irg",
    "title": "Instantaneous Rate of Green Up",
    "description": "Fits a double logistic function to NDVI time series and calculates \n             instantaneous rate of green (IRG) according to methods described\n             in Bischoff et al. (2012) <doi:10.1086/667590>. ",
    "version": "0.1.6",
    "maintainer": "Alec L. Robitaille <robit.alec@gmail.com>",
    "url": "https://github.com/robitalec/irg, https://robitalec.github.io/irg/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15758,
    "package_name": "irls",
    "title": "Generalised Linear Models via Iteratively Reweighted Least\nSquares",
    "description": "Generalised linear models via the iteratively reweighted least squares algorithm. The functions perform logistic, Poisson and Gamma regression (ISBN:9780412317606), either for a single model or many regression models in a column-wise fashion. ",
    "version": "1.0",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15767,
    "package_name": "irtQ",
    "title": "Unidimensional Item Response Theory Modeling",
    "description": "Fit unidimensional item response theory (IRT) models to test\n    data, which includes both dichotomous and polytomous items, calibrate \n    pretest item parameters, estimate examinees' abilities, and examine \n    the IRT model-data fit on item-level in different ways as well as provide \n    useful functions related to IRT analyses such as IRT model-data fit \n    evaluation and differential item functioning analysis. \n    The bring.flexmirt() and write.flexmirt() functions were written by modifying \n    the read.flexmirt() function (Pritikin & Falk (2022) <doi:10.1177/0146621620929431>).\n    The bring.bilog() and bring.parscale() functions were written by modifying the read.bilog() \n    and read.parscale() functions, respectively (Weeks (2010) <doi:10.18637/jss.v035.i12>).\n    The bisection() function was written by modifying the bisection() function \n    (Howard (2017, ISBN:9780367657918)). The code of the inverse test characteristic curve \n    scoring in the est_score() function was written by modifying the irt.eq.tse() function \n    (González (2014) <doi:10.18637/jss.v059.i07>). In est_score() function, the code of weighted \n    likelihood estimation method was written by referring to the Pi(), Ji(), and Ii() functions\n    of the catR package (Magis & Barrada (2017) <doi:10.18637/jss.v076.c01>).",
    "version": "1.0.0",
    "maintainer": "Hwanggyu Lim <hglim83@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15783,
    "package_name": "ismtchile",
    "title": "Calculating Socio Material Territorial Index",
    "description": "Paquete creado con el fin de facilitar el cálculo y distribución del índice Socio Material Territorial (ISMT), elaborado por el Observatorio de Ciudades UC. La metodología completa está disponible en \"ISMT\" (<https://ideocuc-ocuc.hub.arcgis.com/datasets/6ed956450cfc4293b7d90df3ce3474e4/about>) [Observatorio de Ciudades UC (2019)]. || Package created to facilitate the calculation and distribution of the Socio-Material Territorial Index by Observatorio de Ciudades UC. The full methodology is available at \"ISMT\" (<https://ideocuc-ocuc.hub.arcgis.com/datasets/6ed956450cfc4293b7d90df3ce3474e4/about>) [Observatorio de Ciudades UC (2019)].",
    "version": "2.1.5",
    "maintainer": "Martín Rosas Araya <mrosas1690@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15788,
    "package_name": "isoWater",
    "title": "Discovery, Retrieval, and Analysis of Water Isotope Data",
    "description": "The wiDB...() functions provide an interface to the public API \n    of the wiDB <https://github.com/SPATIAL-Lab/isoWater/blob/master/Protocol.md>: \n    build, check and submit queries, and receive and \n    unpack responses. Data analysis functions support Bayesian \n    inference of the source and source isotope composition of water \n    samples that may have experienced evaporation. Algorithms \n    adapted from Bowen et al. (2018, <doi:10.1007/s00442-018-4192-5>).",
    "version": "1.2.1",
    "maintainer": "Gabe Bowen <gabe.bowen@utah.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15794,
    "package_name": "isocat",
    "title": "Isotope Origin Clustering and Assignment Tools",
    "description": "This resource provides tools to create, compare, and post-process \n    spatial isotope assignment models of animal origin. It generates \n    probability-of-origin maps for individuals based on user-provided tissue and \n    environment isotope values (e.g., as generated by IsoMAP, Bowen et al. [2013] \n    <doi:10.1111/2041-210X.12147>) using the framework established in Bowen et al.\n    (2010) <doi:10.1146/annurev-earth-040809-152429>). The package 'isocat' can then \n    quantitatively compare and cluster these maps to group individuals by \n    similar origin. It also includes techniques for applying four approaches \n    (cumulative sum, odds ratio, quantile only, and quantile simulation) with \n    which users can summarize geographic origins and probable distance traveled \n    by individuals. Campbell et al. [2020] establishes several of the functions\n    included in this package <doi:10.1515/ami-2020-0004>.",
    "version": "0.3.0",
    "maintainer": "Caitlin Campbell <caitjcampbell@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15803,
    "package_name": "isonoi",
    "title": "Generate 'Voronoi-esque' Polygons from Travel Isochrones",
    "description": "The goal is to provide example data and functions to demonstrate the concept of 'iso voronoi' polygons.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/isonoi/isonoi",
    "exports": [],
    "topics": ["economics", "geospatial", "route-network", "transportation", "transportation-planning", "voronoi", "voronoi-diagram"],
    "score": "NA",
    "stars": 12
  },
  {
    "id": 15811,
    "package_name": "ispdata",
    "title": "Access Data from the Public Security Institute of the State of\nRio De Janeiro",
    "description": "Allows access to data from the Rio de Janeiro Public Security Institute (ISP), such as criminal statistics, data on gun seizures and femicide. The package also contains the spatial data of Pacifying Police Units (UPPs) and Integrated Public Safety Regions, Areas and Circumscriptions. ",
    "version": "1.1.2",
    "maintainer": "Igor Laltuf <igorlaltuf@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15817,
    "package_name": "itcSegment",
    "title": "Individual Tree Crowns Segmentation",
    "description": "Three methods for Individual Tree Crowns (ITCs) delineation on remote sensing data: one is based on LiDAR data in x,y,z format and one on imagery data in raster format.",
    "version": "1.0",
    "maintainer": "Michele Dalponte <michele.dalponte@fmach.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15829,
    "package_name": "itmsa",
    "title": "Information-Theoretic Measures for Spatial Association",
    "description": "Leveraging information-theoretic measures like mutual information and v-measure to quantify spatial associations between patterns (Nowosad and Stepinski (2018) <doi:10.1080/13658816.2018.1511794>; Bai, H. et al. (2023) <doi:10.1080/24694452.2023.2223700>).",
    "version": "0.1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/itmsa/, https://github.com/stscl/itmsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15837,
    "package_name": "itsdm",
    "title": "Isolation Forest-Based Presence-Only Species Distribution\nModeling",
    "description": "Collection of R functions to do purely presence-only species\n    distribution modeling with isolation forest (iForest) and its\n    variations such as Extended isolation forest and SCiForest. See the\n    details of these methods in references: Liu, F.T., Ting, K.M. and\n    Zhou, Z.H. (2008) <doi:10.1109/ICDM.2008.17>, Hariri, S., Kind, M.C.\n    and Brunner, R.J. (2019) <doi:10.1109/TKDE.2019.2947676>, Liu, F.T.,\n    Ting, K.M. and Zhou, Z.H. (2010) <doi:10.1007/978-3-642-15883-4_18>,\n    Guha, S., Mishra, N., Roy, G. and Schrijvers, O. (2016)\n    <https://proceedings.mlr.press/v48/guha16.html>, Cortes, D. (2021)\n    <doi:10.48550/arXiv.2110.13402>. \n    Additionally, Shapley values are used to explain\n    model inputs and outputs. See details in references: Shapley, L.S.\n    (1953) <doi:10.1515/9781400881970-018>, Lundberg, S.M. and Lee, S.I.\n    (2017) <https://dm-gatech.github.io/CS8803-Fall2018-DML-Papers/shapley.pdf>, Molnar,\n    C.  (2020) <ISBN:978-0-244-76852-2>, Štrumbelj, E. and Kononenko, I.\n    (2014) <doi:10.1007/s10115-013-0679-x>. itsdm also provides functions\n    to diagnose variable response, analyze variable importance, draw\n    spatial dependence of variables and examine variable contribution. As\n    utilities, the package includes a few functions to download\n    bioclimatic variables including 'WorldClim' version 2.0 (see Fick,\n    S.E. and Hijmans, R.J. (2017) <doi:10.1002/joc.5086>) and\n    'CMCC-BioClimInd' (see Noce, S., Caporaso, L. and Santini, M. (2020)\n    <doi:10.1038/s41597-020-00726-5>.",
    "version": "0.2.2",
    "maintainer": "Lei Song <lsong@clarku.edu>",
    "url": "https://github.com/LLeiSong/itsdm,\nhttps://lleisong.github.io/itsdm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 15977,
    "package_name": "jsonlite",
    "title": "A Simple and Robust JSON Parser and Generator for R",
    "description": "A reasonably fast JSON parser and generator, optimized for statistical \n    data and the web. Offers simple, flexible tools for working with JSON in R, and\n    is particularly powerful for building pipelines and interacting with a web API. \n    The implementation is based on the mapping described in the vignette (Ooms, 2014).\n    In addition to converting JSON data from/to R objects, 'jsonlite' contains \n    functions to stream, validate, and prettify JSON data. The unit tests included \n    with the package verify that all edge cases are encoded and decoded consistently \n    for use with dynamic data in systems and applications.",
    "version": "2.0.0",
    "maintainer": "Jeroen Ooms <jeroenooms@gmail.com>",
    "url": "https://jeroen.r-universe.dev/jsonlite\nhttps://arxiv.org/abs/1403.2805",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16008,
    "package_name": "kangar00",
    "title": "Kernel Approaches for Nonlinear Genetic Association Regression",
    "description": "Methods to extract information on pathways, genes and various single-nucleotid polymorphisms (SNPs) from online databases. It provides functions for data preparation and evaluation of genetic influence on a binary outcome using the logistic kernel machine test (LKMT). Three different kernel functions are offered to analyze genotype information in this variance component test: A linear kernel, a size-adjusted kernel and a network-based kernel).",
    "version": "1.4.2",
    "maintainer": "Juliane Manitz <r@manitz.org>",
    "url": "https://kangar00.manitz.org/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16047,
    "package_name": "kequate",
    "title": "The Kernel Method of Test Equating",
    "description": "Implements the kernel method of test equating as defined in von Davier, A. A., Holland, P. W. and Thayer, D. T. (2004) <doi:10.1007/b97446> and Andersson, B. and Wiberg, M. (2017) <doi:10.1007/s11336-016-9528-7> using the CB, EG, SG, NEAT CE/PSE and NEC designs, supporting Gaussian, logistic and uniform kernels and unsmoothed and pre-smoothed input data.",
    "version": "1.6.4",
    "maintainer": "Björn Andersson <bjoern.h.andersson@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16107,
    "package_name": "kissmig",
    "title": "a Keep It Simple Species Migration Model",
    "description": "Simulating species migration and range dynamics under stable or changing environmental conditions based on a simple, raster-based, deterministic or stochastic migration model. KISSMig runs on binary or quantitative suitability maps, which are pre-calculated with niche-based habitat suitability models (also called ecological niche models (ENMs) or species distribution models (SDMs)). Nobis & Normand (2014), <doi:10.1111/ecog.00930>.",
    "version": "2.0-1",
    "maintainer": "Michael P. Nobis <michael.nobis@wsl.ch>",
    "url": "https://purl.oclc.org/wsl/kissmig",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16113,
    "package_name": "kko",
    "title": "Kernel Knockoffs Selection for Nonparametric Additive Models",
    "description": "A variable selection procedure, dubbed KKO, for nonparametric additive model with finite-sample false discovery rate control guarantee. The method integrates three key components: knockoffs, subsampling for stability, and random feature mapping for nonparametric function approximation. For more information, see the accompanying paper: Dai, X., Lyu, X., & Li, L. (2021). “Kernel Knockoffs Selection for Nonparametric Additive Models”. arXiv preprint <arXiv:2105.11659>.",
    "version": "1.0.1",
    "maintainer": "Xiang Lyu <xianglyu@berkeley.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16122,
    "package_name": "klustR",
    "title": "D3 Dynamic Cluster Visualizations",
    "description": "Used to create dynamic, interactive 'D3.js' \n  based parallel coordinates and principal component plots in 'R'.\n  The plots make visualizing k-means or other clusters simple and informative.",
    "version": "0.1.0",
    "maintainer": "McKay Davis <mckaymdavis@gmail.com>",
    "url": "https://mckaymdavis.github.io/klustR/,\nhttps://github.com/McKayMDavis/klustR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16134,
    "package_name": "knfi",
    "title": "Analysis of Korean National Forest Inventory Database",
    "description": "Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.",
    "version": "1.0.1.9",
    "maintainer": "Sinyoung Park <youngsin0306@kookmin.ac.kr>",
    "url": "https://github.com/SYOUNG9836/knfi,\nhttps://syoung9836.github.io/knfi/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16156,
    "package_name": "kokudosuuchi",
    "title": "Utilities for 'Kokudo Suuchi'",
    "description": "Provides utilities for 'Kokudo Suuchi', the GIS data service of the Japanese government.\n    See <https://nlftp.mlit.go.jp/index.html> for more information.",
    "version": "1.0.0",
    "maintainer": "Hiroaki Yutani <yutani.ini@gmail.com>",
    "url": "https://yutannihilation.github.io/kokudosuuchi/,\nhttps://github.com/yutannihilation/kokudosuuchi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16168,
    "package_name": "krige",
    "title": "Geospatial Kriging with Metropolis Sampling",
    "description": "Estimates kriging models for geographical point-referenced data. Method is described in Gill (2020) <doi:10.1177/1532440020930197>.",
    "version": "0.6.2",
    "maintainer": "Jason S. Byers <jaybyers55@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16190,
    "package_name": "kvkapiR",
    "title": "Interface to the Dutch Chamber of Commerce (KvK) API",
    "description": "Access business registration data from the Dutch Chamber of\n    Commerce (Kamer van Koophandel, KvK) through their official API\n    <https://developers.kvk.nl/>. Search for companies by name, location,\n    or registration number. Retrieve detailed business profiles,\n    establishment information, and company name histories. Built on\n    'httr2' for robust API interaction with automatic pagination, error\n    handling, and usage tracking.",
    "version": "0.1.2",
    "maintainer": "Coen Eisma <coeneisma@gmail.com>",
    "url": "https://coeneisma.github.io/kvkapiR/,\nhttps://github.com/coeneisma/kvkapiR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16193,
    "package_name": "kzs",
    "title": "Kolmogorov-Zurbenko Spatial Smoothing and Applications",
    "description": "A spatial smoothing algorithm based on convolutions of finite rectangular kernels that provides sharp resolution in the presence of high levels of noise.",
    "version": "1.4.1",
    "maintainer": "Derek Cyr <cyr.derek@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16194,
    "package_name": "l0ara",
    "title": "Sparse Generalized Linear Model with L0 Approximation for\nFeature Selection",
    "description": "An efficient procedure for feature selection for generalized linear models with L0 penalty, including linear, logistic, Poisson, gamma, inverse Gaussian regression. Adaptive ridge algorithms are used to fit the models.",
    "version": "0.1.6",
    "maintainer": "Wenchuan Guo <wguo007@ucr.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16200,
    "package_name": "laGP",
    "title": "Local Approximate Gaussian Process Regression",
    "description": "Performs approximate GP regression for large computer experiments and spatial datasets.  The approximation is based on finding small local designs for prediction (independently) at particular inputs. OpenMP and SNOW parallelization are supported for prediction over a vast out-of-sample testing set; GPU acceleration is also supported for an important subroutine.  OpenMP and GPU features may require special compilation.  An interface to lower-level (full) GP inference and prediction is provided. Wrapper routines for blackbox optimization under mixed equality and inequality constraints via an augmented Lagrangian scheme, and for large scale computer model calibration, are also provided.  For details and tutorial, see Gramacy (2016 <doi:10.18637/jss.v072.i01>.",
    "version": "1.5-9",
    "maintainer": "Robert B. Gramacy  <rbg@vt.edu>",
    "url": "https://bobby.gramacy.com/r_packages/laGP/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16211,
    "package_name": "labelr",
    "title": "Label Data Frames, Variables, and Values",
    "description": "Create and use data frame labels for data frame objects (frame labels), their columns (name labels), and individual values of a column (value labels). Value labels include one-to-one and many-to-one labels for nominal and ordinal variables, as well as numerical range-based value labels for continuous variables. Convert value-labeled variables so each value is replaced by its corresponding value label. Add values-converted-to-labels columns to a value-labeled data frame while preserving parent columns. Filter and subset a value-labeled data frame using labels, while returning results in terms of values. Overlay labels in place of values in common R commands to increase interpretability. Generate tables of value frequencies, with categories expressed as raw values or as labels. Access data frames that show value-to-label mappings for easy reference.",
    "version": "0.1.9",
    "maintainer": "Robert Hartman <rohartman@gmail.com>",
    "url": "https://github.com/rhartmano/labelr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16215,
    "package_name": "labstats",
    "title": "Data Sets for the Book \"Experimental Design for Laboratory\nBiologists\"",
    "description": "Contains data sets to accompany the book: Lazic SE\n    (2016). \"Experimental Design for Laboratory Biologists: Maximising Information\n    and Improving Reproducibility\". Cambridge University Press.",
    "version": "1.0.1",
    "maintainer": "Stanley E. Lazic <stan.lazic@cantab.net>",
    "url": "https://github.com/stanlazic/labstats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16219,
    "package_name": "lacunaritycovariance",
    "title": "Gliding Box Lacunarity and Other Metrics for 2D Random Closed\nSets",
    "description": "Functions for estimating the gliding box lacunarity (GBL),\n    covariance, and pair-correlation of a random closed set (RACS) in 2D\n    from a binary coverage map (e.g. presence-absence land cover maps).\n    Contains a number of newly-developed covariance-based estimators of\n    GBL (Hingee et al., 2019) <doi:10.1007/s13253-019-00351-9> and\n    balanced estimators, proposed by Picka (2000)\n    <http://www.jstor.org/stable/1428408>, for covariance, centred\n    covariance, and pair-correlation.  Also contains methods for\n    estimating contagion-like properties of RACS and simulating 2D Boolean\n    models.  Binary coverage maps are usually represented as raster images\n    with pixel values of TRUE, FALSE or NA, with NA representing\n    unobserved pixels.  A demo for extracting such a binary map from a\n    geospatial data format is provided.  Binary maps may also be\n    represented using polygonal sets as the foreground, however for most\n    computations such maps are converted into raster images.  The package\n    is based on research conducted during the author's PhD studies.",
    "version": "1.1-9",
    "maintainer": "Kassel Liam Hingee <kassel.hingee@gmail.com>",
    "url": "https://github.com/kasselhingee/lacunaritycovariance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16224,
    "package_name": "lagsarlmtree",
    "title": "Spatial Lag Model Trees",
    "description": "Model-based linear model trees adjusting for spatial correlation using a\n             simultaneous autoregressive spatial lag, Wagner and Zeileis (2019)\n\t     <doi:10.1111/geer.12146>.",
    "version": "1.0-1",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16242,
    "package_name": "landsat",
    "title": "Radiometric and Topographic Correction of Satellite Imagery",
    "description": "Processing of Landsat or other multispectral satellite imagery. Includes relative normalization, image-based radiometric correction, and topographic correction options. The original package description was published as Goslee (2011) <doi:10.18637/jss.v043.i04>, and details of the topographic corrections in Goslee (2012) <doi:10.14358/PERS.78.9.973>.",
    "version": "1.1.2",
    "maintainer": "Sarah Goslee <sarah.goslee@usda.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16243,
    "package_name": "landscapeR",
    "title": "Categorical Landscape Simulation Facility",
    "description": "Simulates categorical maps on actual geographical realms, starting from either empty landscapes or landscapes provided by the user (e.g. land use maps). Allows to tweak or create landscapes while retaining a high degree of control on its features, without the hassle of specifying each location attribute. In this it differs from other tools which generate null or neutral landscapes in a theoretical space. The basic algorithm currently implemented uses a simple agent style/cellular automata growth model, with no rules (apart from areas of exclusion) and von Neumann neighbourhood (four cells, aka Rook case). Outputs are raster dataset exportable to any common GIS format.",
    "version": "1.3.1",
    "maintainer": "Dario Masante <dario.masante@gmail.com>",
    "url": "https://github.com/dariomasante/landscapeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16288,
    "package_name": "lawn",
    "title": "Client for 'Turfjs' for 'Geospatial' Analysis",
    "description": "Client for 'Turfjs' (<https://turfjs.org>) for",
    "version": "0.6.0",
    "maintainer": "",
    "url": "https://github.com/ropensci-archive/lawn",
    "exports": [],
    "topics": ["geojson", "geospatial", "r", "r-package", "rstats", "turf", "turfjs"],
    "score": "NA",
    "stars": 55
  },
  {
    "id": 16302,
    "package_name": "lbfgsb3c",
    "title": "Limited Memory BFGS Minimizer with Bounds on Parameters with\noptim() 'C' Interface",
    "description": "Interfacing to Nocedal et al. L-BFGS-B.3.0\n        (See <http://users.iems.northwestern.edu/~nocedal/lbfgsb.html>)\n        limited memory BFGS minimizer with bounds on parameters.\n        This is a fork of 'lbfgsb3'.\n\tThis registers a 'R' compatible 'C' interface to L-BFGS-B.3.0 that uses the same\n\tfunction types and optimization as the optim() function (see writing 'R' extensions\n        and source for details).  This package also adds more stopping criteria as well\n        as allowing the adjustment of more tolerances.",
    "version": "2024-3.5",
    "maintainer": "Matthew L Fidler <matthew.fidler@gmail.com>",
    "url": "https://nlmixr2.github.io/lbfgsb3c/,\nhttps://github.com/nlmixr2/lbfgsb3c",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16304,
    "package_name": "lbmech",
    "title": "A Package to Study the Mechanics of Landscape and Behavior",
    "description": "A geospatial package to study the adaptive mechanics of landscape and behavior, including at present: (1) distance, movement, and influence; (2) dispersion and inequality; and (3) agricultural productivity.",
    "version": "0.5.3",
    "maintainer": "Andres G. Mejia Ramon <Andres.Mejia@UAB.cat>",
    "url": "https://github.com/andresgmejiar/lbmech",
    "exports": [],
    "topics": ["energetics", "gis", "least-cost"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 16305,
    "package_name": "lboxcox",
    "title": "Implementation of Logistic Box-Cox Regression",
    "description": "Implements a logistic box-cox model. This model is fully described in Xing, L. et al. (2021) <doi:10.1002/cjs.11587>.",
    "version": "1.2",
    "maintainer": "Li Xing <sfulxing@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16318,
    "package_name": "lczexplore",
    "title": "lczexplore",
    "description": "This lczexplore package automatize the comparison of sets of local climate zone classifications. It was developed thanks to the project PAENDORA2 (Pour la gestion du confort estival : Donnees, Outils et Recherche-Action) (2022 -2025), funded by ADEME.",
    "version": "1.0.0.0001",
    "maintainer": "",
    "url": "https://github.com/orbisgis/lczexplore",
    "exports": [],
    "topics": ["climate-change", "environment", "geoclimate", "r-spatial"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 16327,
    "package_name": "ldmppr",
    "title": "Estimate and Simulate from Location Dependent Marked Point\nProcesses",
    "description": "A suite of tools for estimating, assessing model fit, simulating from, and visualizing location dependent marked point processes characterized by regularity in the pattern.\n    You provide a reference marked point process, a set of raster images containing location specific covariates, and select the estimation algorithm and type of mark model.\n    'ldmppr' estimates the process and mark models and allows you to check the appropriateness of the model using a variety of diagnostic tools.\n    Once a satisfactory model fit is obtained, you can simulate from the model and visualize the results.\n    Documentation for the package 'ldmppr' is available in the form of a vignette.",
    "version": "1.1.0",
    "maintainer": "Lane Drew <lanetdrew@gmail.com>",
    "url": "https://github.com/lanedrew/ldmppr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16330,
    "package_name": "leaderCluster",
    "title": "Leader Clustering Algorithm",
    "description": "The leader clustering algorithm provides\n a means for clustering a set of data points. Unlike many other clustering\n algorithms it does not require the user to specify the number of clusters,\n but instead requires the approximate radius of a cluster as its primary\n tuning parameter. The package provides a fast implementation of this\n algorithm in n-dimensions using Lp-distances (with special cases for p=1,2,\n and infinity) as well as for spatial data using the Haversine\n formula, which takes latitude/longitude pairs as inputs and clusters\n based on great circle distances.",
    "version": "1.5",
    "maintainer": "Taylor B. Arnold <tarnold2@richmond.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16332,
    "package_name": "leafSTAR",
    "title": "Silhouette to Area Ratio of Tilted Surfaces",
    "description": "Implementation of trigonometric functions to calculate the exposure of flat, tilted surfaces, such as leaves and slopes, to direct solar radiation. It implements the equations in A.G. Escribano-Rocafort, A. Ventre-Lespiaucq, C. Granado-Yela, et al. (2014) <doi:10.1111/2041-210X.12141> in a few user-friendly R functions. All functions handle data obtained with 'Ahmes' 1.0 for Android, as well as more traditional data sources (compass, protractor, inclinometer). The main function (star()) calculates the potential exposure of flat, tilted surfaces to direct solar radiation (silhouette to area ratio, STAR). It is equivalent to the ratio of the leaf projected area to total leaf area, but instead of using area data it uses spatial position angles, such as pitch, roll and course, and information on the geographical coordinates, hour, and date. The package includes additional functions to recalculate STAR with custom settings of location and time, to calculate the tilt angle of a surface, and the minimum angle between two non-orthogonal planes.",
    "version": "1.0",
    "maintainer": "Agustina Ventre Lespiaucq <aguslespiaucq@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16338,
    "package_name": "leaflet.esri",
    "title": "'ESRI' Bindings for the 'leaflet' Package",
    "description": "An add-on package to the 'leaflet' package, which provides bindings for 'ESRI' services. This package allows a user to add 'ESRI' provided services such as 'MapService', 'ImageMapService', 'TiledMapService' etc. to a 'leaflet' map.",
    "version": "1.0.0",
    "maintainer": "",
    "url": "https://github.com/trafficonese/leaflet.esri",
    "exports": [],
    "topics": ["data-visualization", "esri", "esri-leaflet", "geospatial", "leaflet", "rstats"],
    "score": "NA",
    "stars": 36
  },
  {
    "id": 16343,
    "package_name": "leafletZH",
    "title": "Chinese Leaflet Map Relate Operation",
    "description": "Provides 'sf' data for Chinese provinces and cities,\n  methods for plotting shape maps of Chinese provinces and cities,\n  Convert Coordinates Between Different Systems,\n  and a layer for 'leaflet' with Gaode tiles.\n  It is designed to facilitate geographical data visualization in China.",
    "version": "0.1.1",
    "maintainer": "Damonsoul <chenmaowei96@gmail.com>",
    "url": "https://damonsoul.github.io/leafletZH/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16347,
    "package_name": "leaftime",
    "title": "'Leaflet-timeline' Plugin for Leaflet",
    "description": "Use the 'leaflet-timeline' plugin with a leaflet widget to add an\n    interactive slider with play, pause, and step buttons to explore temporal\n    geographic spatial data changes.",
    "version": "0.2.0",
    "maintainer": "Kent Russell <kent.russell@timelyportfolio.com>",
    "url": "https://github.com/timelyportfolio/leaftime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16370,
    "package_name": "legislatoR",
    "title": "Interface to the Comparative Legislators Database",
    "description": "Facilitates access to the Comparative Legislators Database (CLD). The CLD includes political, sociodemographic, career, online presence, public attention, and visual information for over 67,000 contemporary and historical politicians from 16 countries.",
    "version": "1.1.0",
    "maintainer": "Sascha Goebel <sascha.goebel@soz.uni-frankfurt.de>",
    "url": "https://github.com/saschagobel/legislatoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16372,
    "package_name": "legocolors",
    "title": "Official Lego Color Palettes",
    "description": "Provides a dataset containing several color naming conventions established by multiple sources, along with associated color metadata.\n    The package also provides related helper functions for mapping among the different Lego color naming conventions and between Lego colors, hex colors, and 'R' color names, \n    making it easy to convert any color palette to one based on existing Lego colors while keeping as close to the original color palette as possible.\n    The functions use nearest color matching based on Euclidean distance in RGB space. \n    Naming conventions for color mapping include those from 'BrickLink' (<https://www.bricklink.com>), 'The Lego Group' (<https://www.lego.com>), 'LDraw' (<https://www.ldraw.org/>), and 'Peeron' (<http://www.peeron.com/>).",
    "version": "0.4.0",
    "maintainer": "Matthew Leonawicz <rpkgs@pm.me>",
    "url": "https://github.com/leonawicz/legocolors",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16414,
    "package_name": "lgcp",
    "title": "Log-Gaussian Cox Process",
    "description": "Spatial and spatio-temporal modelling of point patterns using the\n    log-Gaussian Cox process. Bayesian inference for spatial, spatiotemporal,\n    multivariate and aggregated point processes using Markov chain Monte Carlo. See Benjamin M. Taylor, Tilman M. Davies, Barry S. Rowlingson, Peter J. Diggle (2015) <doi:10.18637/jss.v063.i07>.",
    "version": "2.0-1",
    "maintainer": "Benjamin M. Taylor <benjamin.taylor.software@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16419,
    "package_name": "lgrdata",
    "title": "Example Datasets for a Learning Guide to R",
    "description": "A largish collection of example datasets, including several classics. Many of\n    these datasets are well suited for regression, classification, and visualization.",
    "version": "0.1.1",
    "maintainer": "Remko Duursma <remkoduursma@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16427,
    "package_name": "libgeos",
    "title": "Open Source Geometry Engine ('GEOS') C API",
    "description": "Provides the Open Source Geometry Engine ('GEOS') as a\n  C API that can be used to write high-performance C and C++\n  geometry operations using R as an interface. Headers are provided\n  to make linking to and using these functions from C++ code as\n  easy and as safe as possible. This package contains an internal\n  copy of the 'GEOS' library to guarantee the best possible\n  consistency on multiple platforms.",
    "version": "3.11.1-3",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "url": "https://paleolimbot.github.io/libgeos/,\nhttps://github.com/paleolimbot/libgeos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16435,
    "package_name": "lidR",
    "title": "Airborne LiDAR Data Manipulation and Visualization for Forestry\nApplications",
    "description": "Airborne LiDAR (Light Detection and Ranging) interface for data\n    manipulation and visualization. Read/write 'las' and 'laz' files, computation\n    of metrics in area based approach, point filtering, artificial point reduction,\n    classification from geographic data, normalization, individual tree segmentation\n    and other manipulations.",
    "version": "4.2.3",
    "maintainer": "Jean-Romain Roussel <info@r-lidar.com>",
    "url": "https://github.com/r-lidar/lidR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16436,
    "package_name": "lidaRtRee",
    "title": "Forest Analysis with Airborne Laser Scanning (LiDAR) Data",
    "description": "Provides functions for forest objects detection, structure metrics \n    computation, model calibration and mapping with airborne laser scanning:\n    co-registration of field plots (Monnet and Mermin (2014) \n    <doi:10.3390/f5092307>); tree detection (method 1 in Eysn et al. (2015) \n    <doi:10.3390/f6051721>) and segmentation; forest parameters estimation with \n    the area-based approach: model calibration with ground reference, and maps \n    export (Aussenac et al. (2023) <doi:10.12688/openreseurope.15373.2>); \n    extraction of both physical (gaps, edges, trees) and statistical \n    features useful for e.g. habitat suitability modeling (Glad et al. (2020) \n    <doi:10.1002/rse2.117>) and forest maturity mapping (Fuhr et al. (2022) \n    <doi:10.1002/rse2.274>).",
    "version": "4.0.8",
    "maintainer": "Jean-Matthieu Monnet <jean-matthieu.monnet@inrae.fr>",
    "url": "https://lidar.pages.mia.inra.fr/lidaRtRee/,\nhttps://forgemia.inra.fr/lidar/lidaRtRee",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16451,
    "package_name": "lightsf",
    "title": "A Curated Collection of Georeferenced and Spatial Datasets",
    "description": "Provides a diverse collection of georeferenced and spatial datasets\n    from different domains including urban studies, housing markets, environmental\n    monitoring, transportation, and socio-economic indicators.\n    The package consolidates datasets from multiple open sources such as Kaggle,\n    chopin, spData, adespatial, and bivariateLeaflet.\n    It is designed for researchers, analysts, and educators interested in spatial\n    analysis, geostatistics, and geographic data visualization. \n    The datasets include point patterns, polygons, socio-economic data frames, and\n    network-like structures, allowing flexible exploration of geospatial phenomena.",
    "version": "0.1.0",
    "maintainer": "Ingrid Romero Pinilla <ingridpinilla11@gmail.com>",
    "url": "https://github.com/roming20/lightsf,\nhttps://roming20.github.io/lightsf/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16481,
    "package_name": "linemap",
    "title": "Line Maps",
    "description": "Create maps made of lines. The package contains one function:\n    linemap(). linemap() displays a map made of lines using a\n    raster or gridded data.",
    "version": "0.3.0",
    "maintainer": "Timothée Giraud <timothee.giraud@cnrs.fr>",
    "url": "https://github.com/riatelab/linemap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16494,
    "package_name": "linkeR",
    "title": "Link Interactive Plots and Tables in 'shiny' Applications",
    "description": "Build powerful, linked-view dashboards in 'shiny' applications. With a \n    declarative, one-line setup, you can create bidirectional links between \n    interactive components. When a user interacts with one element (e.g., clicking \n    a map marker), all linked components (such as 'DT' tables or other charts) \n    instantly update. Supports 'leaflet' maps, 'DT' tables, 'plotly' charts, and spatial data \n    via 'sf' objects out-of-the-box, with an extensible API for custom components.",
    "version": "0.1.3",
    "maintainer": "Jake Wagoner <jakew@sci.utah.edu>",
    "url": "https://epiforesite.github.io/linkeR/,\nhttps://github.com/EpiForeSITE/linkeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16536,
    "package_name": "ljr",
    "title": "Logistic Joinpoint Regression",
    "description": "Fits and tests logistic joinpoint models.",
    "version": "1.4-0",
    "maintainer": "Ryan Gill <ryan.gill@louisville.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16540,
    "package_name": "llogistic",
    "title": "The L-Logistic Distribution",
    "description": "Density, distribution function, quantile function and random generation for the L-Logistic distribution with parameters m and phi. The parameter m is the median of the distribution.",
    "version": "1.0.3",
    "maintainer": "Rosineide Fernando da Paz <rfpaz2@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16548,
    "package_name": "lmap",
    "title": "Logistic Mapping",
    "description": "Set of tools for mapping of categorical response variables based on principal component analysis (pca) and multidimensional unfolding (mdu).",
    "version": "0.2.4",
    "maintainer": "Mark de Rooij <rooijm@fsw.leidenuniv.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16569,
    "package_name": "lmomPi",
    "title": "(Precipitation) Frequency Analysis and Variability with\nL-Moments from 'lmom'",
    "description": "It is an extension of 'lmom' R package: 'pel...()','cdf...()',qua...()' function\n    families are lumped and called from one function per each family respectively in order to\n    create robust automatic tools to fit data  with different probability\n    distributions and then to estimate probability values and return periods.  The implemented functions are able to manage time series with constant and/or missing values without stopping\n    the execution with error messages. The package also contains tools to  calculate several  indices based on variability (e.g. 'SPI' , Standardized\n    Precipitation Index, see <https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi> and <http://spei.csic.es/>) for multiple time series or spatially gridded values. ",
    "version": "0.6.7",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16580,
    "package_name": "lnmCluster",
    "title": "Perform Logistic Normal Multinomial Clustering for Microbiome\nCompositional Data",
    "description": "An implementation of logistic normal multinomial (LNM) clustering. It is an extension of LNM mixture model proposed by Fang and Subedi (2020) <arXiv:2011.06682>, and is designed for clustering compositional data. The package includes 3 extended models: LNM Factor Analyzer (LNM-FA), LNM Bicluster Mixture Model (LNM-BMM) and Penalized LNM Factor Analyzer (LNM-FA). There are several advantages of LNM models: 1. LNM provides more flexible covariance structure; 2. Factor analyzer can reduce the number of parameters to estimate; 3. Bicluster can simultaneously cluster subjects and taxa, and provides significant biological insights; 4. Penalty term allows sparse estimation in the covariance matrix. Details for model assumptions and interpretation can be found in papers: Tu and Subedi (2021) <arXiv:2101.01871> and Tu and Subedi (2022) <doi:10.1002/sam.11555>.  ",
    "version": "0.3.1",
    "maintainer": "Wangshu Tu <wangshu.tu@carleton.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16598,
    "package_name": "localsp",
    "title": "Local Indicator of Stratified Power",
    "description": "Implements a local indicator of stratified power to analyze local spatial stratified association and demonstrate how spatial stratified association changes spatially and in local regions, as outlined in Hu et al. (2024) <doi:10.1080/13658816.2024.2437811>.",
    "version": "0.1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://ausgis.github.io/localsp/,\nhttps://github.com/ausgis/localsp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16627,
    "package_name": "logiBin",
    "title": "Binning Variables to Use in Logistic Regression",
    "description": "Fast binning of multiple variables using parallel processing. A summary of all the variables binned is generated which provides the information value, entropy, an indicator of whether the variable follows a monotonic trend or not, etc. It supports rebinning of variables to force a monotonic trend as well as manual binning based on pre specified cuts. The cut points of the bins are based on conditional inference trees as implemented in the partykit package. The conditional inference framework is described by Hothorn T, Hornik K, Zeileis A (2006) <doi:10.1198/106186006X133933>.",
    "version": "0.3",
    "maintainer": "Sneha Tody <sn.tody1@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16634,
    "package_name": "logistic4p",
    "title": "Logistic Regression with Misclassification in Dependent\nVariables",
    "description": "Error in a binary dependent variable, also known as misclassification, has not drawn much attention in psychology. Ignoring misclassification in logistic regression can result in misleading parameter estimates and statistical inference. This package conducts logistic regression analysis with misspecification in outcome variables. ",
    "version": "1.6",
    "maintainer": "Zhiyong Zhang <johnnyzhz@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16635,
    "package_name": "logisticPCA",
    "title": "Binary Dimensionality Reduction",
    "description": "Dimensionality reduction techniques for binary data including\n    logistic PCA.",
    "version": "0.2",
    "maintainer": "Andrew J. Landgraf <andland@gmail.com>",
    "url": "https://github.com/andland/logisticPCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16636,
    "package_name": "logisticRR",
    "title": "Adjusted Relative Risk from Logistic Regression",
    "description": "Adjusted odds ratio conditional on potential confounders can be directly obtained from logistic regression. However, those adjusted odds ratios have been widely incorrectly interpreted as a relative risk. As relative risk is often of interest in public health, we provide a simple code to return adjusted relative risks from logistic regression model under potential confounders. ",
    "version": "0.3.0",
    "maintainer": "Youjin Lee <youjin.lee@pennmedicine.upenn.edu>",
    "url": "https://github.com/youjin1207/logisticRR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16637,
    "package_name": "logitFD",
    "title": "Functional Principal Components Logistic Regression",
    "description": "Functions for fitting a functional principal components logit regression model\n\tin four different situations: ordinary and filtered functional principal components\n\tof functional predictors, included in the model according to their variability\n\texplanation power, and according to their prediction ability by stepwise methods. The\n\tproposed methods were developed in Escabias et al (2004) \n\t<doi:10.1080/10485250310001624738> and Escabias et al (2005)\n\t<doi:10.1016/j.csda.2005.03.011>.",
    "version": "1.0",
    "maintainer": "Manuel Escabias <escabias@ugr.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16653,
    "package_name": "lolog",
    "title": "Latent Order Logistic Graph Models",
    "description": "Estimation of Latent Order Logistic (LOLOG) Models for Networks.\n    LOLOGs are a flexible and fully general class of statistical graph models. \n    This package provides functions for performing MOM, GMM and variational \n    inference. Visual diagnostics and goodness of fit metrics are provided. \n    See Fellows (2018) <doi:10.48550/arXiv.1804.04583> for a detailed description of the methods.",
    "version": "1.3.2",
    "maintainer": "Ian E. Fellows <ian@fellstat.com>",
    "url": "https://github.com/statnet/lolog",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16682,
    "package_name": "loopevd",
    "title": "Loop Functions for Extreme Value Distributions",
    "description": "Performs extreme value analysis at multiple locations using functions from the 'evd' package. Supports both point-based and gridded input data using the 'terra' package, enabling flexible looping across spatial datasets for batch processing of generalised extreme value, Gumbel fits.",
    "version": "1.0.2",
    "maintainer": "Julian O'Grady <julian.ogrady@csiro.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16685,
    "package_name": "lordif",
    "title": "Logistic Ordinal Regression Differential Item Functioning using\nIRT",
    "description": "Performs analysis of Differential Item Functioning (DIF) for\n        dichotomous and polytomous items using an iterative hybrid of\n        ordinal logistic regression and item response theory (IRT) according to \n        Choi, Gibbons, and Crane (2011) <doi:10.18637/jss.v039.i08>.",
    "version": "0.4.2",
    "maintainer": "Seung W. Choi <schoi@austin.utexas.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16712,
    "package_name": "lqr",
    "title": "Robust Linear Quantile Regression",
    "description": "It fits a robust linear quantile regression model using a new family of zero-quantile distributions for the error term. Missing values and censored observations can be handled as well. This family of distribution includes skewed versions of the Normal, Student's t, Laplace, Slash and Contaminated Normal distribution. It also performs logistic quantile regression for bounded responses as shown in Galarza et.al.(2020) <doi:10.1007/s13571-020-00231-0>. It provides estimates and full inference. It also provides envelopes plots for assessing the fit and confidences bands when several quantiles are provided simultaneously.",
    "version": "5.2",
    "maintainer": "Christian E. Galarza <cgalarza88@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16738,
    "package_name": "ltm",
    "title": "Latent Trait Models under IRT",
    "description": "Analysis of multivariate dichotomous and polytomous data using latent trait models under the Item Response Theory approach. It includes the Rasch, the Two-Parameter Logistic, the Birnbaum's Three-Parameter, the Graded Response, and the Generalized Partial Credit Models.",
    "version": "1.2-0",
    "maintainer": "Dimitris Rizopoulos <d.rizopoulos@erasmusmc.nl>",
    "url": "https://github.com/drizopoulos/ltm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16742,
    "package_name": "ltsk",
    "title": "Local Time Space Kriging",
    "description": "Implements local spatial and local spatiotemporal Kriging based on local spatial and local spatiotemporal variograms, respectively. The method is documented in Kumar et al (2013) <https://www.nature.com/articles/jes201352)>.",
    "version": "1.1.2",
    "maintainer": "Dong Liang <dliang@umces.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16752,
    "package_name": "lulcc",
    "title": "Land Use Change Modelling in R",
    "description": "Classes and methods for spatially explicit land use change\n    modelling in R.",
    "version": "1.0.4",
    "maintainer": "Simon Moulds <sim.moulds@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16796,
    "package_name": "mStats",
    "title": "Epidemiological Data Analysis",
    "description": "This is a tool for epidemiologist, medical data analyst, \n    medical or public health professionals. It contains three domains of functions:\n    1) data management, 2) statistical analysis and 3) calculating \n    epidemiological measures.",
    "version": "3.4.0",
    "maintainer": "Myo Minn Oo <dr.myominnoo@gmail.com>",
    "url": "https://myominnoo.github.io/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16803,
    "package_name": "mabacR",
    "title": "Assisting Decision Makers",
    "description": "Easy implementation of the MABAC multi-criteria decision method, that was introduced by Pamučar and Ćirović in the work entitled: \"The selection of transport and handling resources in logistics centers using Multi-Attributive Border Approximation area Comparison (MABAC)\" - <doi:10.1016/j.eswa.2014.11.057> - which aimed to choose implements for logistics centers. This package receives data, preferably in a spreadsheet, reads it and applies the mathematical algorithms inherent to the MABAC method to generate a ranking with the optimal solution according to the established criteria, weights and type of criteria. The data will be normalized, weighted by the weights, the border area will be determined, the distances to this border area will be calculated and finally a ranking with the optimal option will be generated.",
    "version": "0.1.0",
    "maintainer": "Adam Slabadack <arslabadack@gmail.com>",
    "url": "https://github.com/slabaverse/mabacR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16805,
    "package_name": "macleish",
    "title": "Retrieve Data from MacLeish Field Station",
    "description": "Download data from the Ada and Archibald MacLeish Field \n    Station in Whately, MA. The Ada \n    and Archibald MacLeish Field Station is a 260-acre patchwork of \n    forest and farmland located in West Whately, MA that provides opportunities \n    for faculty and students to pursue environmental research, outdoor \n    education, and low-impact recreation \n    (see <https://www.smith.edu/discover-smith/smith-action/sustainable-smith/macleish-field-station> for more information). \n    This package contains \n    weather data over several years, and spatial data on various man-made and \n    natural structures.",
    "version": "0.3.10",
    "maintainer": "Benjamin S. Baumer <ben.baumer@gmail.com>",
    "url": "https://github.com/beanumber/macleish,\nhttp://beanumber.github.io/macleish/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16809,
    "package_name": "macroBiome",
    "title": "A Tool for Mapping the Distribution of the Biomes and Bioclimate",
    "description": "Procedures for simulating biomes by equilibrium vegetation \n  models, with a special focus on paleoenvironmental applications.\n  Three widely used equilibrium biome models are currently implemented in \n  the package: the Holdridge Life Zone (HLZ) system (Holdridge 1947, \n  <doi:10.1126/science.105.2727.367>), the Köppen-Geiger classification \n  (KGC) system (Köppen 1936, \n  <https://koeppen-geiger.vu-wien.ac.at/pdf/Koppen_1936.pdf>) and the \n  BIOME model (Prentice et al. 1992, <doi:10.2307/2845499>). Three \n  climatic forest-steppe models are also implemented.\n  An approach for estimating monthly time series of relative sunshine \n  duration from temperature and precipitation data (Yin 1999, \n  <doi:10.1007/s007040050111>) is also adapted, allowing \n  process-based biome models to be combined with high-resolution \n  paleoclimate simulation datasets (e.g., CHELSA-TraCE21k v1.0 dataset: \n  <https://chelsa-climate.org/chelsa-trace21k/>).",
    "version": "0.4.0",
    "maintainer": "Zoltán Szelepcsényi <szelepcsenyi.zoltan@gmail.com>",
    "url": "https://github.com/szelepcsenyi/macroBiome",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16812,
    "package_name": "mactivate",
    "title": "Multiplicative Activation",
    "description": "Provides methods and classes for adding m-activation (\"multiplicative activation\") layers to MLR or multivariate logistic regression models.  M-activation layers created in this library detect and add input interaction (polynomial) effects into a predictive model.  M-activation can detect high-order interactions -- a traditionally non-trivial challenge.  Details concerning application, methodology, and relevant survey literature can be found in this library's vignette, \"About.\"",
    "version": "0.6.6",
    "maintainer": "Dave Zes <zesdave@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16827,
    "package_name": "magclass",
    "title": "Data Class and Tools for Handling Spatial-Temporal Data",
    "description": "Data class for increased interoperability working with\n    spatial-temporal data together with corresponding functions and\n    methods (conversions, basic calculations and basic data manipulation).\n    The class distinguishes between spatial, temporal and other dimensions\n    to facilitate the development and interoperability of tools build for\n    it. Additional features are name-based addressing of data and internal\n    consistency checks (e.g. checking for the right data order in\n    calculations).",
    "version": "6.13.2",
    "maintainer": "Jan Philipp Dietrich <dietrich@pik-potsdam.de>",
    "url": "https://github.com/pik-piam/magclass,\nhttps://doi.org/10.5281/zenodo.1158580",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16881,
    "package_name": "manureshed",
    "title": "Spatiotemporal Nutrient Balance Analysis Across Agricultural and\nMunicipal Systems",
    "description": "A comprehensive framework for analyzing agricultural nutrient \n    balances across multiple spatial scales (county, 'HUC8', 'HUC2') with \n    integration of wastewater treatment plant ('WWTP') effluent loads for both \n    nitrogen and phosphorus. Supports classification of spatial units as \n    nutrient sources, sinks, or balanced areas based on agricultural surplus \n    and deficit calculations. Includes visualization tools, spatial transition \n    probability analysis, and nutrient flow network mapping. Built-in datasets \n    include agricultural nutrient balance data from the Nutrient Use Geographic \n    Information System ('NuGIS'; The Fertilizer Institute and Plant Nutrition \n    Canada, 1987-2016) <https://nugis.tfi.org/tabular_data/> and U.S. Environmental \n    Protection Agency ('EPA') wastewater discharge data from the 'ECHO' Discharge \n    Monitoring Report ('DMR') Loading Tool (2007-2016) \n    <https://echo.epa.gov/trends/loading-tool/water-pollution-search>. Data \n    are downloaded on demand from the Open Science Framework ('OSF') repository to\n    minimize package size while maintaining full functionality. The integrated \n    'manureshed' framework methodology is described in Akanbi et al. (2025) \n    <doi:10.1016/j.resconrec.2025.108697>. Designed for \n    nutrient management planning, environmental analysis, and circular \n    economy research at watershed/administrative to national scales.  \n    This material is based upon financial support by the National Science Foundation, \n    EEC Division of Engineering Education and Centers, \n    NSF Engineering Research Center for Advancing Sustainable and Distributed \n    Fertilizer Production (CASFER), NSF 20-553 Gen-4 Engineering Research Centers \n    award 2133576. We thank Dr. Robert D. Sabo (U.S. Environmental Protection Agency) \n    for his valuable contributions to the conceptual development and review of this work.",
    "version": "0.1.0",
    "maintainer": "Olatunde D. Akanbi <olatunde.akanbi@case.edu>",
    "url": "https://osf.io/g39xa/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16897,
    "package_name": "mapchina",
    "title": "China Administrative Divisions Geospatial Shapefile Data",
    "description": "Geospatial shapefile data of China administrative divisions to the county/district-level.",
    "version": "0.1.0",
    "maintainer": "Mingchu Xu <mxu.china@gmail.com>",
    "url": "https://github.com/xmc811/mapchina",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16898,
    "package_name": "mapdata",
    "title": "Extra Map Databases",
    "description": "Supplement to maps package, providing some larger and/or\n\thigher-resolution databases. NOTE: this is a legacy package. The world map is out-dated.",
    "version": "2.3.1",
    "maintainer": "Alex Deckmyn <alex.deckmyn@meteo.be>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16902,
    "package_name": "mapgl",
    "title": "Interactive Maps with 'Mapbox GL JS' and 'MapLibre GL JS'",
    "description": "Provides an interface to the 'Mapbox GL JS' (<https://docs.mapbox.com/mapbox-gl-js/guides>)\n    and the 'MapLibre GL JS' (<https://maplibre.org/maplibre-gl-js/docs/>) interactive mapping libraries to help users\n    create custom interactive maps in R.  Users can create interactive globe visualizations; layer 'sf' objects to create\n    filled maps, circle maps, 'heatmaps', and three-dimensional graphics; and customize map styles and views.  The package\n    also includes utilities to use 'Mapbox' and 'MapLibre' maps in 'Shiny' web applications.",
    "version": "0.4.3",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "url": "https://walker-data.com/mapgl/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16903,
    "package_name": "mapi",
    "title": "Mapping Averaged Pairwise Information",
    "description": "Mapping Averaged Pairwise Information (MAPI) is an\n    exploratory method providing graphical representations summarizing the\n    spatial variation of pairwise metrics (eg. distance, similarity\n    coefficient, ...) computed between georeferenced samples.",
    "version": "1.1.4",
    "maintainer": "Sylvain Piry <sylvain.piry@inrae.fr>",
    "url": "https://www1.montpellier.inrae.fr/CBGP/software/MAPI/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16904,
    "package_name": "mapic",
    "title": "Map Infrastructure per city",
    "description": "Create simple maps of infrastructure per city of any country using maps and ggplot2 libraries.",
    "version": "2.5.4",
    "maintainer": "",
    "url": "https://github.com/teotenn/mapic",
    "exports": [],
    "topics": ["geospatial", "maps", "r-api", "r-package", "r-programming", "rstats"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 16905,
    "package_name": "mapindia",
    "title": "Plot Map of the Indian Subcontinent",
    "description": "Get map data frames for the Indian subcontinent with different region\n    levels (e.g., district, state). The package also offers convenience functions\n    for plotting choropleths, visualizing spatial data, and handling state/district\n    codes.",
    "version": "1.0.1",
    "maintainer": "Shubham Dutta <shubhamdutta26@gmail.com>",
    "url": "https://github.com/shubhamdutta26/mapindia,\nhttps://www.shubhamdutta.com/mapindia/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16906,
    "package_name": "mapindiatools",
    "title": "Mapping Data for 'mapindia' Package",
    "description": "Provides a container for data used by the 'mapindia' package. \n    The data used by 'mapindia' has been extracted into this package so that the \n    file size of the 'mapindia' package can be reduced considerably. The data in\n    this package will be updated when latest data is available.",
    "version": "1.0.1",
    "maintainer": "Shubham Dutta <shubhamdutta26@gmail.com>",
    "url": "https://github.com/shubhamdutta26/mapindiatools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16907,
    "package_name": "mapiso",
    "title": "Create Contour Polygons from Regular Grids",
    "description": "Regularly spaced grids containing continuous data are transformed\n    to contour polygons. A grid can be defined by a data.frame (x, y, value),\n    an 'sf' object or a raster from 'terra'.",
    "version": "0.3.0",
    "maintainer": "Timothée Giraud <timothee.giraud@cnrs.fr>",
    "url": "https://github.com/riatelab/mapiso",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16912,
    "package_name": "mapmisc",
    "title": "Utilities for Producing Maps",
    "description": "Provides a minimal, light-weight set of tools for producing nice looking maps in R, with support for map projections.  See Brown (2016) <doi:10.32614/RJ-2016-005>.",
    "version": "2.1.0",
    "maintainer": "Patrick Brown <patrick.brown@utoronto.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16915,
    "package_name": "mappestRisk",
    "title": "Create Maps Forecasting Risk of Pest Occurrence",
    "description": "There are three different modules: (1) model fitting and selection \n    using a set of the most commonly used equations describing developmental \n    responses to temperature helped by already existing R packages ('rTPC') \n    and nonlinear regression model functions from 'nls.multstart' \n    (Padfield et al. 2021, <doi:10.1111/2041-210X.13585>), with visualization \n    of model predictions to guide ecological criteria for model selection; \n    (2) calculation of suitability thermal limits, which consist on a \n    temperature interval delimiting the optimal performance zone or suitability; \n    and (3) climatic data extraction and visualization inspired on previous \n    research (Taylor et al. 2019, <doi:10.1111/1365-2664.13455>), with either \n    exportable rasters, static map images or html, interactive maps.",
    "version": "0.1.2",
    "maintainer": "Darío San-Segundo Molina <dario.ssm2@gmail.com>",
    "url": "https://github.com/EcologyR/mappestRisk,\nhttps://ecologyr.github.io/mappestRisk/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16919,
    "package_name": "mapproj",
    "title": "Map Projections",
    "description": "Converts latitude/longitude into projected coordinates.",
    "version": "1.2.12",
    "maintainer": "Alex Deckmyn <alex.deckmyn@meteo.be>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16920,
    "package_name": "maps",
    "title": "Draw Geographical Maps",
    "description": "Display of maps.  Projection code and larger maps are in\n             separate packages ('mapproj' and 'mapdata').",
    "version": "3.4.3",
    "maintainer": "Alex Deckmyn <alex.deckmyn@meteo.be>",
    "url": "https://github.com/adeckmyn/maps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16923,
    "package_name": "mapsRinteractive",
    "title": "Local Adaptation and Evaluation of Raster Maps",
    "description": "Local adaptation and evaluation of maps of continuous attributes in raster format by use of point location data.",
    "version": "2.0.1",
    "maintainer": "Kristin Persson <kristin.persson@slu.se>",
    "url": "https://CRAN.R-project.org/package=mapsRinteractive",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16963,
    "package_name": "markstat",
    "title": "Mark Correlation Functions for Spatial Point Patterns",
    "description": "Provides a range of functions for computing both global and local mark correlation functions for spatial point patterns in either Euclidean spaces or on linear networks, with points carrying either real-valued or function-valued marks. For a review of mark correlation functions, see Eckardt and Moradi (2024) <doi:10.1007/s13253-024-00605-1>. ",
    "version": "0.1.5",
    "maintainer": "Mehdi Moradi <m2.moradi@yahoo.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16965,
    "package_name": "marmap",
    "title": "Import, Plot and Analyze Bathymetric and Topographic Data",
    "description": "Import bathymetric and hypsometric data from the NOAA (National Oceanic and Atmospheric Administration, <https://www.ncei.noaa.gov/products/etopo-global-relief-model>), GEBCO (General Bathymetric Chart of the Oceans, <https://www.gebco.net>) and other sources, plot xyz data to prepare publication-ready figures, analyze xyz data to extract transects, get depth / altitude based on geographical coordinates, or calculate z-constrained least-cost paths.",
    "version": "1.0.12",
    "maintainer": "Benoit Simon-Bouhet <besibo@gmail.com>",
    "url": "https://github.com/ericpante/marmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16989,
    "package_name": "matRiks",
    "title": "Generates Raven-Like Matrices According to Rules",
    "description": "Generates Raven like matrices according to different rules and the response list associated to the matrix. \n     The package can generate matrices composed of 4 or 9 cells, along with a response list of 11 elements (the correct response + 10 incorrect responses). The matrices can be generated according to both logical rules (i.e., the relationships between the elements in the matrix are manipulated to create the matrix) and visual-spatial rules (i.e., the visual or spatial characteristics of the elements are manipulated to generate the matrix).\n    The graphical elements of this package are based on the 'DescTools' package.\n    This package has been developed within the PRIN2020 Project (Prot. 20209WKCLL) titled \"Computerized, Adaptive and Personalized Assessment of Executive Functions and Fluid Intelligence\" and founded by the Italian Ministry of Education and Research.",
    "version": "0.1.5",
    "maintainer": "Andrea Brancaccio <andreabrancaccio01@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 16994,
    "package_name": "matchedcc",
    "title": "'Stata'-Like Matched Case-Control Analysis",
    "description": "Calculate multiple statistics with confidence intervals for matched\n    case-control data including risk difference, risk ratio, relative\n    difference, and the odds ratio. Results are equivalent to those from\n    'Stata', and you can choose how to format your input data. Methods used are\n    those described on page 56 the 'Stata' documentation for \"Epitab - Tables\n    for Epidemologists\" <https://www.stata.com/manuals/repitab.pdf>.",
    "version": "0.1.1",
    "maintainer": "Simon R Parker <simon.parker.24@ucl.ac.uk>",
    "url": "https://github.com/simpar1471/matchedcc/,\nhttps://simpar1471.github.io/matchedcc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17000,
    "package_name": "mateable",
    "title": "Assess Mating Potential in Space and Time",
    "description": "Simulate, manage, visualize, and analyze spatially and temporally \n    explicit datasets of mating potential. Implements methods to calculate \n    synchrony, proximity, and compatibility.Synchrony calculations are based on \n    methods described in Augspurger (1983) <doi:10.2307/2387650>, \n    Kempenaers (1993) <doi:10.2307/3676415>, Ison et al. (2014) \n    <doi:10.3732/ajb.1300065>, and variations on these, as described.",
    "version": "0.3.3",
    "maintainer": "Stuart Wagenius <stuart.wagenius@gmail.com>",
    "url": "https://github.com/stuartWagenius/mateable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17058,
    "package_name": "mbg",
    "title": "Model-Based Geostatistics",
    "description": "\n    Modern model-based geostatistics for point-referenced data. This package provides a\n    simple interface to run spatial machine learning models and geostatistical models\n    that estimate a continuous (raster) surface from point-referenced outcomes and,\n    optionally, a set of raster covariates. The package also includes functions to\n    summarize raster outcomes by (polygon) region while preserving uncertainty.",
    "version": "1.1.0",
    "maintainer": "Nathaniel Henry <nat@henryspatialanalysis.com>",
    "url": "https://henryspatialanalysis.github.io/mbg/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17081,
    "package_name": "mccca",
    "title": "Visualizing Class Specific Heterogeneous Tendencies in\nCategorical Data",
    "description": "Performing multiple-class cluster correspondence analysis(MCCCA). The main functions are create.MCCCAdata() to create a list to be applied to MCCCA, MCCCA() to apply MCCCA, and plot.mccca() for visualizing MCCCA result. Methods used in the \n  package refers to Mariko Takagishi and Michel van de Velden (2022)<doi:10.1080/10618600.2022.2035737>.",
    "version": "1.1.0.1",
    "maintainer": "Mariko Takagishi <m.takagishi0728@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17092,
    "package_name": "mcglm",
    "title": "Multivariate Covariance Generalized Linear Models",
    "description": "Fitting multivariate covariance generalized linear\n     models (McGLMs) to data.  McGLM is a general framework for non-normal\n     multivariate data analysis, designed to handle multivariate response\n     variables, along with a wide range of temporal and spatial correlation\n     structures defined in terms of a covariance link function combined\n     with a matrix linear predictor involving known matrices.\n     The models take non-normality into account in the conventional way\n     by means of a variance function, and the mean structure is modelled\n     by means of a link function and a linear predictor.\n     The models are fitted using an efficient Newton scoring algorithm\n     based on quasi-likelihood and Pearson estimating functions, using\n     only second-moment assumptions. This provides a unified approach to\n     a wide variety of different types of response variables and covariance\n     structures, including multivariate extensions of repeated measures,\n     time series, longitudinal, spatial and spatio-temporal structures.\n     The package offers a user-friendly interface for fitting McGLMs\n     similar to the glm() R function. \n     See Bonat (2018) <doi:10.18637/jss.v084.i04>, for more information \n     and examples.",
    "version": "0.9.0",
    "maintainer": "Wagner Hugo Bonat <wbonat@ufpr.br>",
    "url": "https://github.com/bonatwagner/mcglm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17100,
    "package_name": "mcmapper",
    "title": "Mapping First Moment and C-Statistic to the Parameters of\nDistributions for Risk",
    "description": "Provides a series of numerical methods for extracting parameters of distributions for risks based on knowing the expected value and c-statistics (e.g., from a published report on the performance of a risk prediction model). This package implements the methodology described in Sadatsafavi et al (2024) <doi:10.48550/arXiv.2409.09178>. The core of the package is mcmap(), which takes a pair of (mean, c-statistic) and the distribution type requested. This function provides a generic interface to more customized functions (mcmap_beta(), mcmap_logitnorm(), mcmap_probitnorm()) for specific distributions. ",
    "version": "0.0.11",
    "maintainer": "Mohsen Sadatsafavi <mohsen.sadatsafavi@ubc.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17116,
    "package_name": "mcptools",
    "title": "Model Context Protocol Servers and Clients",
    "description": "Implements the Model Context Protocol (MCP). Users can start\n    'R'-based servers, serving functions as tools for large language\n    models to call before responding to the user in MCP-compatible apps\n    like 'Claude Desktop' and 'Claude Code', with options to run those\n    tools inside of interactive 'R' sessions. On the other end, when 'R'\n    is the client via the 'ellmer' package, users can register tools from\n    third-party MCP servers to integrate additional context into chats.",
    "version": "0.2.0",
    "maintainer": "Simon Couch <simon.couch@posit.co>",
    "url": "https://github.com/posit-dev/mcptools,\nhttps://posit-dev.github.io/mcptools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17132,
    "package_name": "mda.biber",
    "title": "Functions for Multi-Dimensional Analysis",
    "description": "Multi-Dimensional Analysis (MDA) is an adaptation of factor\n  analysis developed by Douglas Biber (1992) <doi:10.1007/BF00136979>. Its most\n  common use is to describe language as it varies by genre, register, and use.\n  This package contains functions for carrying out the calculations needed to\n  describe and plot MDA results: dimension scores, dimension means, and factor\n  loadings.",
    "version": "1.0.1",
    "maintainer": "David Brown <dwb2@andrew.cmu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17135,
    "package_name": "mddmaps",
    "title": "Download World Mammal Maps",
    "description": "Lightweight maps of mammals of the world. These maps are a \n    comprehensive collection of maps aligned with the Mammal Diversity Database\n    taxonomy of the American Society of Mammalogists. They are generated at low\n    resolution for easy access, consultation and manipulation in shapefile\n    format. The package connects to a binary backup hosted in the Digital Ocean\n    cloud service and allows individual or batch download of any mammal species\n    in the mdd taxonomy by providing the scientific species name. ",
    "version": "1.3.0",
    "maintainer": "Angel Robles <a.l.robles.fernandez@gmail.com>",
    "url": "<https://github.com/alrobles/mddmaps>,\n<https://alrobles.github.io/mddmaps/>\n<https://zenodo.org/records/10974868>,\nhttps://alrobles.github.io/mddmaps/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17169,
    "package_name": "medfateland",
    "title": "Mediterranean Landscape Simulation",
    "description": "Simulate forest hydrology, forest function and dynamics over landscapes [De Caceres et al. (2015) <doi:10.1016/j.agrformet.2015.06.012>]. Parallelization is allowed in several simulation functions and simulations may be conducted including spatial processes such as lateral water transfer and seed dispersal.",
    "version": "2.8.1",
    "maintainer": "Miquel De Cáceres <miquelcaceres@gmail.com>",
    "url": "https://emf-creaf.github.io/medfateland/,\nhttps://github.com/emf-creaf/medfateland",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17198,
    "package_name": "memgene",
    "title": "Spatial Pattern Detection in Genetic Distance Data Using Moran's\nEigenvector Maps",
    "description": "Can detect relatively weak spatial genetic patterns by using Moran's Eigenvector Maps (MEM) to extract only the spatial component of genetic variation.  Has applications in landscape genetics where the movement and dispersal of organisms are studied using neutral genetic variation.",
    "version": "1.0.3",
    "maintainer": "Paul Galpern <pgalpern@ucalgary.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17245,
    "package_name": "metaRange",
    "title": "Framework to Build Mechanistic and Metabolic Constrained Species\nDistribution Models",
    "description": "Build spatially and temporally explicit\n    process-based species distribution models, that can include an arbitrary\n    number of environmental factors, species and processes including metabolic\n    constraints and species interactions. The focus of the package is simulating\n    populations of one or multiple species in a grid-based landscape and studying\n    the meta-population dynamics and emergent patterns that arise from the\n    interaction of species under complex environmental conditions. It\n    provides functions for common ecological processes such as\n    negative exponential, kernel-based dispersal (see\n    Nathan et al. (2012) <doi:10.1093/acprof:oso/9780199608898.003.0015>),\n    calculation of the environmental suitability based on cardinal values (\n    Yin et al. (1995) <doi:10.1016/0168-1923(95)02236-Q>, simplified by\n    Yan and Hunt (1999) <doi:10.1006/anbo.1999.0955> see eq: 4), reproduction in\n    form of an Ricker model (see Ricker (1954) <doi:10.1139/f54-039> and\n    Cabral and Schurr (2010) <doi:10.1111/j.1466-8238.2009.00492.x>),\n    as well as metabolic scaling based on the metabolic theory of ecology\n    (see Brown et al. (2004) <doi:10.1890/03-9000> and\n    Brown, Sibly and Kodric-Brown (2012)\n    <doi:10.1002/9781119968535.ch>).",
    "version": "1.1.4",
    "maintainer": "Stefan Fallert <srfallert@gmail.com>",
    "url": "https://metaRange.github.io/metaRange/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17319,
    "package_name": "meteo",
    "title": "RFSI & STRK Interpolation for Meteo and Environmental Variables",
    "description": "Random Forest Spatial Interpolation (RFSI, Sekulić et al. (2020) <doi:10.3390/rs12101687>) and spatio-temporal geostatistical (spatio-temporal regression Kriging (STRK)) interpolation for meteorological (Kilibarda et al. (2014) <doi:10.1002/2013JD020803>, Sekulić et al. (2020) <doi:10.1007/s00704-019-03077-3>) and other environmental variables. Contains global spatio-temporal models calculated using publicly available data.",
    "version": "2.0-3",
    "maintainer": "Aleksandar Sekulić <asekulic@grf.bg.ac.rs>",
    "url": "https://www.r-pkg.org/pkg/meteo,\nhttps://r-forge.r-project.org/projects/meteo/,\nhttps://github.com/AleksandarSekulic/Rmeteo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17321,
    "package_name": "meteoForecast",
    "title": "Numerical Weather Predictions",
    "description": "Access to several Numerical Weather Prediction services both in raster format and as a time series for a location. Currently it works with GFS <https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast>, MeteoGalicia <https://www.meteogalicia.gal/web/modelos/threddsIndex.action>, NAM <https://www.ncei.noaa.gov/products/weather-climate-models/north-american-mesoscale>, and RAP <https://www.ncei.noaa.gov/products/weather-climate-models/rapid-refresh-update>.",
    "version": "0.57",
    "maintainer": "Oscar Perpinan Lamigueiro <oscar.perpinan@upm.es>",
    "url": "https://codeberg.org/oscarperpinan/meteoForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17355,
    "package_name": "mexicolors",
    "title": "Mexican Politics-Inspired Color Palette Generator",
    "description": "A color palette generator inspired by Mexican politics, with \n    colors ranging from red on the left to gray in the middle and green on the \n    right. Palette options range from only a few colors to several colors, but with\n    discrete and continuous options to offer greatest flexibility to the user. \n    This package allows for a range of applications, from mapping brief discrete scales \n    (e.g., four colors for Morena, PRI, and PAN) to continuous interpolated arrays \n    including dozens of shades graded from red to green.",
    "version": "0.2.0",
    "maintainer": "Alejandro Platas-López <alejandroplatasl@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17365,
    "package_name": "mgc",
    "title": "Multiscale Graph Correlation",
    "description": "Multiscale Graph Correlation (MGC) is a framework developed by Vogelstein et al. (2019) <DOI:10.7554/eLife.41690> that extends global correlation procedures to be multiscale; consequently, MGC tests typically require far fewer samples than existing methods for a wide variety of dependence structures and dimensionalities, while maintaining computational efficiency. Moreover, MGC provides a simple and elegant multiscale characterization of the potentially complex latent geometry underlying the relationship.",
    "version": "2.0.2",
    "maintainer": "Eric Bridgeford <ericwb95@gmail.com>",
    "url": "https://github.com/neurodata/r-mgc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17367,
    "package_name": "mgcv",
    "title": "Mixed GAM Computation Vehicle with Automatic Smoothness\nEstimation",
    "description": "Generalized additive (mixed) models, some of their extensions and \n             other generalized ridge regression with multiple smoothing \n             parameter estimation by (Restricted) Marginal Likelihood, \n             Cross Validation and similar, or using iterated nested Laplace\n\t     approximation for fully Bayesian inference. See Wood (2025)\n\t     <doi:10.1146/annurev-statistics-112723-034249> for an overview.\n\t     Includes a gam() function, a wide variety of smoothers, 'JAGS'\n\t     support and distributions beyond the exponential family. ",
    "version": "1.9-4",
    "maintainer": "Simon Wood <simon.wood@r-project.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17374,
    "package_name": "mgpStreamingSDK",
    "title": "Interact with the Maxar MGP Streaming API",
    "description": "This grants the functionality of the Maxar Geospatial Platform (MGP) Streaming API. It can search for images using the WFS method. It can Download images using WMS WMTS. It can also Download a full resolution image.",
    "version": "0.2.0",
    "maintainer": "Nathan Carr <nathan.carr@maxar.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17379,
    "package_name": "mgwrsar",
    "title": "GWR, Mixed GWR and Multiscale GWR with Spatial Autocorrelation",
    "description": "Functions for computing (Mixed and Multiscale) Geographically Weighted Regression with spatial autocorrelation, Geniaux and Martinetti (2017) <doi:10.1016/j.regsciurbeco.2017.04.001>.",
    "version": "1.1",
    "maintainer": "Ghislain Geniaux <ghislain.geniaux@inrae.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17419,
    "package_name": "miceafter",
    "title": "Data and Statistical Analyses after Multiple Imputation",
    "description": "\n   Statistical Analyses and Pooling after Multiple Imputation. A large variety \n   of repeated statistical analysis can be performed and finally pooled. Statistical analysis \n   that are available are, among others, Levene's test, Odds and Risk Ratios, One sample \n   proportions, difference between proportions and linear and logistic regression models. \n   Functions can also be used in combination with the Pipe operator. \n   More and more statistical analyses and pooling functions will be added over time.\n   Heymans (2007) <doi:10.1186/1471-2288-7-33>.\n   Eekhout (2017) <doi:10.1186/s12874-017-0404-7>.\n\t Wiel (2009) <doi:10.1093/biostatistics/kxp011>.\n\t Marshall (2009) <doi:10.1186/1471-2288-9-57>.\n\t Sidi (2021) <doi:10.1080/00031305.2021.1898468>.\n\t Lott (2018) <doi:10.1080/00031305.2018.1473796>.\n\t Grund (2021) <doi:10.31234/osf.io/d459g>.",
    "version": "0.5.0",
    "maintainer": "Martijn Heymans <mw.heymans@amsterdamumc.nl>",
    "url": "https://mwheymans.github.io/miceafter/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17441,
    "package_name": "micromap",
    "title": "Linked Micromap Plots",
    "description": "This group of functions simplifies the creation of linked micromap plots. Please\n  see <https://www.jstatsoft.org/v63/i02/> for additional details.",
    "version": "1.9.10",
    "maintainer": "Marcus W. Beck <mbeck@tbep.org>",
    "url": "<https://github.com/fawda123/micromap>",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17461,
    "package_name": "midfieldr",
    "title": "Tools and Methods for Working with MIDFIELD Data in 'R'",
    "description": "Provides tools and demonstrates methods for working with individual \n  undergraduate student-level records (registrar's data) in 'R'. Tools include \n  filters for program codes, data sufficiency, and timely completion. Methods \n  include gathering blocs of records, computing quantitative metrics such as \n  graduation rate, and creating charts to visualize comparisons. 'midfieldr' \n  interacts with practice data provided in 'midfielddata', an R data package \n  available at <https://midfieldr.github.io/midfielddata/>. \n  'midfieldr' also interacts with the full MIDFIELD database for users who have \n  access. This work is supported by the US National Science Foundation through \n  grant numbers 1545667 and 2142087.",
    "version": "1.0.2",
    "maintainer": "Richard Layton <graphdoctor@gmail.com>",
    "url": "https://midfieldr.github.io/midfieldr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17462,
    "package_name": "midi",
    "title": "Microstructure Information from Diffusion Imaging",
    "description": "An implementation of a taxonomy of models of restricted diffusion\n    in biological tissues parametrized by the tissue geometry (axis, diameter,\n    density, etc.). This is primarily used in the context of diffusion magnetic\n    resonance (MR) imaging to model the MR signal attenuation in the presence of\n    diffusion gradients. The goal is to provide tools to simulate the MR signal\n    attenuation predicted by these models under different experimental\n    conditions. The package feeds a companion 'shiny' app available at\n    <https://midi-pastrami.apps.math.cnrs.fr> that serves as a graphical\n    interface to the models and tools provided by the package. Models currently\n    available are the ones in Neuman (1974) <doi:10.1063/1.1680931>, Van\n    Gelderen et al. (1994) <doi:10.1006/jmrb.1994.1038>, Stanisz et al. (1997)\n    <doi:10.1002/mrm.1910370115>, Soderman & Jonsson (1995)\n    <doi:10.1006/jmra.1995.0014> and Callaghan (1995)\n    <doi:10.1006/jmra.1995.1055>.",
    "version": "0.1.0",
    "maintainer": "Aymeric Stamm <aymeric.stamm@cnrs.fr>",
    "url": "https://github.com/lmjl-alea/midi,\nhttps://lmjl-alea.github.io/midi/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17504,
    "package_name": "miniLNM",
    "title": "Miniature Logistic-Normal Multinomial Models",
    "description": "Logistic-normal Multinomial (LNM) models are common in problems with multivariate count data. This package gives a simple implementation with a 30 line 'Stan' script. This lightweight implementation makes it an easy starting point for other projects, in particular for downstream tasks that require analysis of \"compositional\" data. It can be applied whenever a multinomial probability parameter is thought to depend linearly on inputs in a transformed, log ratio space. Additional utilities make it easy to inspect, create predictions, and draw samples using the fitted models. More about the LNM can be found in Xia et al. (2013) \"A Logistic Normal Multinomial Regression Model for Microbiome Compositional Data Analysis\" <doi:10.1111/biom.12079> and Sankaran and Holmes (2023) \"Generative Models: An Interdisciplinary Perspective\" <doi:10.1146/annurev-statistics-033121-110134>.",
    "version": "0.1.0",
    "maintainer": "Kris Sankaran <ksankaran@wisc.edu>",
    "url": "https://github.com/krisrs1128/miniLNM/,\nhttps://krisrs1128.github.io/miniLNM/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17519,
    "package_name": "minorparties",
    "title": "Quantitatively Analyze Minor Political Parties",
    "description": "Tools for calculating I-Scores, a simple way to measure how successful minor political parties are at influencing the major parties in their environment. I-Scores are designed to be a more comprehensive measurement of minor party success than vote share and legislative seats won, the current standard measurements, which do not reflect the strategies that most minor parties employ. The procedure leverages the Manifesto Project's NLP model to identify the issue areas that sentences discuss, see Burst et al. (2024) <doi:10.25522/manifesto.manifestoberta.56topics.context.2024.1.1>, and the Wordfish algorithm to estimate the relative positions that platforms take on those issue areas, see Slapin and Proksch (2008) <doi:10.1111/j.1540-5907.2008.00338.x>.",
    "version": "1.0.0",
    "maintainer": "Theodore Gercken <tgercken@hamilton.edu>",
    "url": "https://gerckentheodore.github.io/minorparties/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17537,
    "package_name": "misaem",
    "title": "Linear Regression and Logistic Regression with Missing\nCovariates",
    "description": "Estimate parameters of linear regression and logistic regression with missing covariates with missing data, perform model selection and prediction, using EM-type algorithms. Jiang W., Josse J., Lavielle M., TraumaBase Group (2020) <doi:10.1016/j.csda.2019.106907>.",
    "version": "1.1.0",
    "maintainer": "Julie Josse <julie.josse@inria.fr>",
    "url": "https://github.com/julierennes/misaem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17539,
    "package_name": "miscF",
    "title": "Miscellaneous Functions",
    "description": "Various functions for random number generation, density \n             estimation, classification, curve fitting, and spatial \n             data analysis.",
    "version": "0.1-5",
    "maintainer": "Dai Feng <daifeng.stat@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17570,
    "package_name": "misuvi",
    "title": "Access the Michigan Substance Use Vulnerability Index (MI-SUVI)",
    "description": "Easily import the MI-SUVI data sets. The user can import data sets with full metrics, percentiles, Z-scores, or rankings.\n    Data is available at both the County and Zip Code Tabulation Area (ZCTA) levels. This package also includes a function to import \n    shape files for easy mapping and a function to access the full technical documentation. All data is sourced from the Michigan Department of Health and Human Services.",
    "version": "0.1.1",
    "maintainer": "Brenden Smith <brendensmithmi@gmail.com>",
    "url": "https://github.com/brendensm/misuvi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17590,
    "package_name": "mixcat",
    "title": "Mixed Effects Cumulative Link and Logistic Regression Models",
    "description": "Mixed effects cumulative and baseline logit link models for the analysis of ordinal or nominal responses, with non-parametric distribution for the random effects.",
    "version": "1.0-4",
    "maintainer": "Georgios Papageorgiou <gpapageo@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17612,
    "package_name": "mixtools",
    "title": "Tools for Analyzing Finite Mixture Models",
    "description": "Analyzes finite mixture models for various parametric and semiparametric settings.  This includes mixtures of parametric distributions (normal, multivariate normal, multinomial, gamma), various Reliability Mixture Models (RMMs), mixtures-of-regressions settings (linear regression, logistic regression, Poisson regression, linear regression with changepoints, predictor-dependent mixing proportions, random effects regressions, hierarchical mixtures-of-experts), and tools for selecting the number of components (bootstrapping the likelihood ratio test statistic, mixturegrams, and model selection criteria).  Bayesian estimation of mixtures-of-linear-regressions models is available as well as a novel data depth method for obtaining credible bands.  This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772 and the Chan Zuckerberg Initiative: Essential Open Source Software for Science (Grant No. 2020-255193).",
    "version": "2.0.0.1",
    "maintainer": "Derek Young <derek.young@uky.edu>",
    "url": "https://github.com/dsy109/mixtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17620,
    "package_name": "mkde",
    "title": "2D and 3D Movement-Based Kernel Density Estimates (MKDEs)",
    "description": "Provides functions to compute and visualize movement-based kernel density estimates (MKDEs) for animal utilization distributions in 2 or 3 spatial dimensions.",
    "version": "0.4",
    "maintainer": "Robert Sinkovits <sinkovit@sdsc.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17680,
    "package_name": "mlr3spatial",
    "title": "Support for Spatial Objects Within the 'mlr3' Ecosystem",
    "description": "Extends the 'mlr3' ML framework with methods for spatial\n    objects. Data storage and prediction are supported for packages\n    'terra', 'raster' and 'stars'.",
    "version": "0.6.1",
    "maintainer": "Marc Becker <marcbecker@posteo.de>",
    "url": "https://mlr3spatial.mlr-org.com,\nhttps://github.com/mlr-org/mlr3spatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17681,
    "package_name": "mlr3spatiotempcv",
    "title": "Spatiotemporal Resampling Methods for 'mlr3'",
    "description": "Extends the mlr3 machine learning framework with\n    spatio-temporal resampling methods to account for the presence of\n    spatiotemporal autocorrelation (STAC) in predictor variables. STAC may\n    cause highly biased performance estimates in cross-validation if\n    ignored. A JSS article is available at <doi:10.18637/jss.v111.i07>.",
    "version": "2.3.4",
    "maintainer": "Patrick Schratz <patrick.schratz@gmail.com>",
    "url": "https://mlr3spatiotempcv.mlr-org.com/,\nhttps://github.com/mlr-org/mlr3spatiotempcv,\nhttps://mlr3book.mlr-org.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17709,
    "package_name": "mmapcharr",
    "title": "Memory-Map Character Files",
    "description": "Uses memory-mapping to enable the random access of elements of\n  a text file of characters separated by characters as if it were a simple\n  R(cpp) matrix.",
    "version": "0.3.1",
    "maintainer": "Florian Privé <florian.prive.21@gmail.com>",
    "url": "https://github.com/privefl/mmapcharr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17710,
    "package_name": "mmaqshiny",
    "title": "Explore Air-Quality Mobile-Monitoring Data",
    "description": "Mobile-monitoring or \"sensors on a mobile platform\", is an increasingly \n    popular approach to measure high-resolution pollution data at the street level. \n    Coupled with location data, spatial visualisation of air-quality parameters \n    helps detect localized areas of high air-pollution, also called hotspots. \n    In this approach, portable sensors are mounted on a vehicle and driven on \n    predetermined routes to collect high frequency data (1 Hz). \n    'mmaqshiny' is for analysing, visualising and spatial mapping of \n    high-resolution air-quality data collected by specific devices installed on \n    a moving platform. 1 Hz data of PM2.5 (mass concentrations of particulate  \n    matter with size less than 2.5 microns), Black carbon mass concentrations \n    (BC), ultra-fine particle number concentrations, carbon dioxide along with \n    GPS coordinates and relative humidity (RH) data collected by popular \n    portable instruments (TSI DustTrak-8530, Aethlabs microAeth-AE51, TSI CPC3007, \n    LICOR Li-830, Garmin GPSMAP 64s, Omega USB RH probe respectively). It \n    incorporates device specific cleaning and correction algorithms. RH correction \n    is applied to DustTrak PM2.5 following the Chakrabarti et al., (2004) \n    <doi:10.1016/j.atmosenv.2004.03.007>. Provision is given to add linear \n    regression coefficients for correcting the PM2.5 data (if required). BC data\n    will be cleaned for the vibration generated noise, by adopting the statistical \n    procedure as explained in Apte et al., (2011) <doi:10.1016/j.atmosenv.2011.05.028>, \n    followed by a loading correction as suggested by Ban-Weiss et al., (2009)  \n    <doi:10.1021/es8021039>. For the number concentration data, provision is \n    given for dilution correction factor (if a diluter is used with CPC3007; \n    default value is 1). The package joins the raw, cleaned and corrected data \n    from the above said instruments and outputs as a downloadable csv file. ",
    "version": "1.0.0",
    "maintainer": "Adithi R. Upadhya <adithi@ilklabs.com>",
    "url": "https://github.com/meenakshi-kushwaha/mmaqshiny",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17712,
    "package_name": "mmc",
    "title": "Multivariate Measurement Error Correction",
    "description": "Provides routines for multivariate measurement error correction. Includes procedures for linear, logistic and Cox regression models. Bootstrapped standard errors and confidence intervals can be obtained for corrected estimates.",
    "version": "0.0.3",
    "maintainer": "Jaejoon Song <jjsong2@mdanderson.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17746,
    "package_name": "mob",
    "title": "Monotonic Optimal Binning",
    "description": "Generate the monotonic binning and\n    perform the woe (weight of evidence) transformation for the logistic regression\n    used in the consumer credit scorecard development. The woe transformation is a piecewise\n    transformation that is linear to the log odds. For a numeric variable, all of its monotonic \n    functional transformations will converge to the same woe transformation. ",
    "version": "0.4.2",
    "maintainer": "WenSui Liu <liuwensui@gmail.com>",
    "url": "https://github.com/statcompute/mob",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17750,
    "package_name": "mobsim",
    "title": "Spatial Simulation and Scale-Dependent Analysis of Biodiversity\nChanges",
    "description": "Simulation, analysis and sampling of spatial\n    biodiversity data (May, Gerstner, McGlinn, Xiao & Chase 2017)\n    <doi:10.1111/2041-210x.12986>.\n    In the simulation tools user define the numbers of\n    species and individuals, the species abundance distribution and species\n    aggregation. Functions for analysis include species rarefaction \n    and accumulation curves, species-area relationships and the distance\n    decay of similarity. ",
    "version": "0.3.2",
    "maintainer": "Felix May <felix.may@fu-berlin.de>",
    "url": "https://github.com/MoBiodiv/mobsim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17798,
    "package_name": "modest",
    "title": "Model-Based Dose-Escalation Trials",
    "description": "User-friendly Shiny apps for designing and evaluating phase I cancer clinical trials, with the aim to estimate the maximum tolerated dose (MTD) of a novel drug, using a Bayesian decision procedure based on logistic regression.",
    "version": "0.3-1",
    "maintainer": "Philip Pallmann <pallmannp@cardiff.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17804,
    "package_name": "modisfast",
    "title": "Fast and Efficient Access to MODIS Earth Observation Data",
    "description": "Programmatic interface to several NASA Earth Observation 'OPeNDAP' servers (Open-source Project for a Network Data Access Protocol) (<https://www.opendap.org/>). Allows for easy downloads of MODIS subsets, as well as other Earth Observation datacubes, in a time-saving and efficient way : by sampling it at the very downloading phase (spatially, temporally and dimensionally).",
    "version": "1.0.2",
    "maintainer": "Paul Taconet <paul.taconet@gmail.com>",
    "url": "https://github.com/ptaconet/modisfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17862,
    "package_name": "morphomap",
    "title": "Morphometric Maps, Bone Landmarking and Cross Sectional Geometry",
    "description": "Extract cross sections from long bone meshes at specified intervals along the diaphysis. Calculate two and three-dimensional morphometric maps, cross-sectional geometric parameters, and semilandmarks on the periosteal and endosteal contours of each cross section. ",
    "version": "1.5",
    "maintainer": "Antonio Profico <antonio.profico@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17881,
    "package_name": "motif",
    "title": "Local Pattern Analysis",
    "description": "Describes spatial patterns of categorical raster data for \n    any defined regular and irregular areas. \n    Patterns are described quantitatively using built-in signatures \n    based on co-occurrence matrices but also allows for \n    any user-defined functions. \n    It enables spatial analysis such as search, change detection,\n    and clustering to be performed on spatial patterns (Nowosad (2021) <doi:10.1007/s10980-020-01135-0>).",
    "version": "0.6.5",
    "maintainer": "Jakub Nowosad <nowosad.jakub@gmail.com>",
    "url": "https://jakubnowosad.com/motif/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17892,
    "package_name": "mousetRajectory",
    "title": "Mouse Trajectory Analyses for Behavioural Scientists",
    "description": "Helping psychologists and other behavioural scientists\n    to analyze mouse movement (and other 2-D trajectory) data. Bundles\n    together several functions that compute spatial measures (e.g., maximum\n    absolute deviation, area under the curve, sample entropy) or provide a\n    shorthand for procedures that are frequently used (e.g., time \n    normalization, linear interpolation, extracting initiation and movement \n    times). For more information on these dependent measures, see Wirth et al. \n    (2020) <doi:10.3758/s13428-020-01409-0>.",
    "version": "0.2.1",
    "maintainer": "Roland Pfister <mail@roland-pfister.net>",
    "url": "https://github.com/mc-schaaf/mousetRajectory,\nhttps://mc-schaaf.github.io/mousetRajectory/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17939,
    "package_name": "mrbsizeR",
    "title": "Scale Space Multiresolution Analysis of Random Signals",
    "description": "A method for the multiresolution analysis of spatial fields and images to capture scale-dependent features.\n    mrbsizeR is based on scale space smoothing and uses differences of smooths at neighbouring scales for finding features on different scales.\n    To infer which of the captured features are credible, Bayesian analysis is used.\n    The scale space multiresolution analysis has three steps: (1) Bayesian signal reconstruction.\n    (2) Using differences of smooths, scale-dependent features of the reconstructed signal can be found.\n    (3) Posterior credibility analysis of the differences of smooths created.\n    The method has first been proposed by Holmstrom, Pasanen, Furrer, Sain (2011) <DOI:10.1016/j.csda.2011.04.011> and extended in Flury, Gerber, Schmid and Furrer (2021) <DOI:10.1016/j.spasta.2020.100483>.",
    "version": "1.3",
    "maintainer": "Roman Flury <roman.flury@math.uzh.ch>",
    "url": "https://github.com/romanflury/mrbsizeR,\nhttps://romanflury.github.io/mrbsizeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17973,
    "package_name": "mscstexta4r",
    "title": "R Client for the Microsoft Cognitive Services Text Analytics\nREST API",
    "description": "R Client for the Microsoft Cognitive Services Text Analytics\n    REST API, including Sentiment Analysis, Topic Detection, Language Detection,\n    and Key Phrase Extraction. An account MUST be registered at the Microsoft\n    Cognitive Services website <https://www.microsoft.com/cognitive-services/>\n    in order to obtain a (free) API key. Without an API key, this package will\n    not work properly.",
    "version": "0.1.2",
    "maintainer": "Phil Ferriere <pferriere@hotmail.com>",
    "url": "https://github.com/philferriere/mscstexta4r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17974,
    "package_name": "mscstts",
    "title": "R Client for the Microsoft Cognitive Services 'Text-to-Speech'\nREST API",
    "description": "R Client for the Microsoft Cognitive Services \n  'Text-to-Speech' REST API, including voice synthesis. A valid account \n  must be registered at the Microsoft Cognitive Services website \n  <https://azure.microsoft.com/en-us/products/ai-services/> in order to \n  obtain a (free) API key. Without an API key, this package will not \n  work properly.",
    "version": "0.6.4",
    "maintainer": "John Muschelli <muschellij2@gmail.com>",
    "url": "https://github.com/jhudsl/mscstts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17975,
    "package_name": "mscsweblm4r",
    "title": "R Client for the Microsoft Cognitive Services Web Language Model\nREST API",
    "description": "R Client for the Microsoft Cognitive Services Web Language Model\n    REST API, including Break Into Words, Calculate Conditional\n    Probability, Calculate Joint Probability, Generate Next Words, and List\n    Available Models. A valid account MUST be registered at the Microsoft\n    Cognitive Services website <https://www.microsoft.com/cognitive-services/>\n    in order to obtain a (free) API key. Without an API key, this package will\n    not work properly.",
    "version": "0.1.2",
    "maintainer": "Phil Ferriere <pferriere@hotmail.com>",
    "url": "https://github.com/philferriere/mscsweblm4r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17985,
    "package_name": "msig",
    "title": "An R Package for Exploring Molecular Signatures Database",
    "description": "The Molecular Signatures Database ('MSigDB') is one of the most widely \n    used and comprehensive databases of gene sets for performing gene set \n    enrichment analysis <doi:10.1016/j.cels.2015.12.004>. The 'msig' package provides \n    you with powerful, easy-to-use and flexible query functions for the 'MsigDB' \n    database.\n        There are 2 query modes in the 'msig' package: online query and local query. \n    Both queries contain 2 steps: gene set name and gene.\n        The online search is divided into 2 modes: registered search and \n    non-registered browse. For registered search, email that you registered should \n    be provided.\n        Local queries can be made from local database, which can be updated by msig_update() function.",
    "version": "1.0",
    "maintainer": "Jing Zhang <zj391120@163.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 17999,
    "package_name": "mstDIF",
    "title": "A Collection of DIF Tests for Multistage Tests",
    "description": "A collection of statistical tests for the detection of differential\n    item functioning (DIF) in multistage tests. Methods entail logistic regression,\n    an adaptation of the simultaneous item bias test (SIBTEST), and various score-based tests.\n    The presented tests provide itemwise test for DIF along categorical, ordinal or metric covariates. Methods for uniform and non-uniform \n    DIF effects are available depending on which method is used.",
    "version": "0.1.8",
    "maintainer": "Rudolf Debelak <rudolf.debelak@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18000,
    "package_name": "mstR",
    "title": "Procedures to Generate Patterns under Multistage Testing",
    "description": "Generation of response patterns under dichotomous and polytomous computerized multistage testing (MST) framework. It holds various item response theory (IRT) and score-based methods to select the next module and estimate ability levels (Magis, Yan and von Davier (2017, ISBN:978-3-319-69218-0)). ",
    "version": "1.2",
    "maintainer": "David Magis <david.magis@uliege.be>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18019,
    "package_name": "muRL",
    "title": "Mailmerge using R, LaTeX, and the Web",
    "description": "Provides mailmerge methods for reading spreadsheets of addresses and other relevant information to create standardized but customizable letters.  Provides a method for mapping US ZIP codes, including those of letter recipients.  Provides a method for parsing and processing html code from online job postings of the American Political Science Association.",
    "version": "0.1-13",
    "maintainer": "Ryan T. Moore <rtm@american.edu>",
    "url": "https://www.ryantmoore.org/software.murl.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18055,
    "package_name": "multiModTest",
    "title": "Information Assessment for Individual Modalities in Multimodal\nRegression Models",
    "description": "Provides methods for quantifying the information gain contributed by individual \n\tmodalities in multimodal regression models. Information gain is measured using Expected \n\tRelative Entropy (ERE) or pseudo-R² metrics, with corresponding p-values and confidence \n\tintervals. Currently supports linear and logistic regression models with plans for \n\textension to additional Generalized Linear Models and Cox proportional hazard model.",
    "version": "1.0",
    "maintainer": "Wanting Jin <jinwanting5@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18058,
    "package_name": "multiScaleR",
    "title": "Methods for Optimizing Scales of Effect",
    "description": "A tool for optimizing scales of effect when modeling ecological processes in space. Specifically, the scale parameter of a distance-weighted kernel distribution is identified for all environmental layers included in the model. Includes functions to assist in model selection, model evaluation, efficient transformation of raster surfaces using fast Fourier transformation, and projecting models. For more details see Peterman (2025) <doi:10.21203/rs.3.rs-7246115/v1>.",
    "version": "0.4.5",
    "maintainer": "Bill Peterman <Peterman.73@osu.edu>",
    "url": "https://github.com/wpeterman/multiScaleR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18082,
    "package_name": "multilandr",
    "title": "Landscape Analysis at Multiple Spatial Scales",
    "description": "Provides a tidy workflow for landscape-scale analysis. 'multilandr' offers tools to generate landscapes at multiple spatial scales and compute landscape metrics, primarily using the 'landscapemetrics' package. It also features utility functions for plotting and analyzing multi-scale landscapes, exploring correlations between metrics, filtering landscapes based on specific conditions, generating landscape gradients for a given metric, and preparing datasets for further statistical analysis. Documentation about 'multilandr' is provided in an introductory vignette included in this package and in the paper by Huais (2024) <doi:10.1007/s10980-024-01930-z>; see citation(\"multilandr\") for details.",
    "version": "1.0.0",
    "maintainer": "Pablo Yair Huais <pablo.huais@unc.edu.ar>",
    "url": "https://github.com/phuais/multilandr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18093,
    "package_name": "multimark",
    "title": "Capture-Mark-Recapture Analysis using Multiple Non-Invasive\nMarks",
    "description": "Traditional and spatial capture-mark-recapture analysis with\n    multiple non-invasive marks. The models implemented in 'multimark' combine\n    encounter history data arising from two different non-invasive \"marks\",\n    such as images of left-sided and right-sided pelage patterns of bilaterally\n    asymmetrical species, to estimate abundance and related demographic\n    parameters while accounting for imperfect detection. Bayesian models are\n    specified using simple formulae and fitted using Markov chain Monte Carlo.\n    Addressing deficiencies in currently available software, 'multimark' also\n    provides a user-friendly interface for performing Bayesian multimodel\n    inference using non-spatial or spatial capture-recapture data consisting of a single\n    conventional mark or multiple non-invasive marks. See McClintock (2015) <doi:10.1002/ece3.1676> and Maronde et al. (2020) <doi:10.1002/ece3.6990>.",
    "version": "2.1.7",
    "maintainer": "Brett T. McClintock <brett.mcclintock@noaa.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18100,
    "package_name": "multiness",
    "title": "MULTIplex NEtworks with Shared Structure",
    "description": "Model fitting and simulation for Gaussian and logistic inner \n    product MultiNeSS models for multiplex networks. The package implements \n    a convex fitting algorithm with fully adaptive parameter tuning, \n    including options for edge cross-validation. For more details see \n    MacDonald et al. (2020).  ",
    "version": "1.0.2",
    "maintainer": "Peter W. MacDonald <pwmacdon@umich.edu>",
    "url": "https://github.com/peterwmacd/multiness/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18111,
    "package_name": "multiplestressR",
    "title": "Additive and Multiplicative Null Models for Multiple Stressor\nData",
    "description": "An implementation of the additive (Gurevitch et al., 2000 <doi:10.1086/303337>) \n    and multiplicative (Lajeunesse, 2011 <doi:10.1890/11-0423.1>) factorial null models for \n    multiple stressor data (Burgess et al., 2021 <doi:10.1101/2021.07.21.453207>). Effect sizes \n    are able to be calculated for either null model, and subsequently classified into one of \n    four different interaction classifications (e.g., antagonistic or synergistic interactions). \n    Analyses can be conducted on data for single experiments through to large meta-analytical datasets. \n    Minimal input (or statistical knowledge) is required, with any output easily understood. \n    Summary figures are also able to be easily generated.",
    "version": "0.1.1",
    "maintainer": "Benjamin Burgess <benjamin.joshua.burgess@gmail.com>",
    "url": "https://benjburgess.github.io/multiplestressR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18115,
    "package_name": "multiridge",
    "title": "Fast Cross-Validation for Multi-Penalty Ridge Regression",
    "description": "Multi-penalty linear, logistic and cox ridge regression, including estimation of the penalty parameters by efficient (repeated) cross-validation and marginal likelihood maximization. Multiple high-dimensional data types that require penalization are allowed, as well as unpenalized variables. Paired and preferential data types can be specified. See Van de Wiel et al. (2021), <arXiv:2005.09301>. ",
    "version": "1.11",
    "maintainer": "Mark A. van de Wiel <mark.vdwiel@amsterdamumc.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18121,
    "package_name": "multispatialCCM",
    "title": "Multispatial Convergent Cross Mapping",
    "description": "The multispatial convergent cross mapping algorithm can be used as a test for causal associations between pairs of processes represented by time series. This is a combination of convergent cross mapping (CCM), described in Sugihara et al., 2012, Science, 338, 496-500, and dew-drop regression, described in Hsieh et al., 2008, American Naturalist, 171, 71–80. The algorithm allows CCM to be implemented on data that are not from a single long time series. Instead, data can come from many short time series, which are stitched together using bootstrapping.",
    "version": "1.3",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18140,
    "package_name": "munsell",
    "title": "Utilities for Using Munsell Colours",
    "description": "Provides easy access to, and manipulation of, the Munsell \n    colours. Provides a mapping between Munsell's \n    original notation (e.g. \"5R 5/10\") and hexadecimal strings suitable \n    for use directly in R graphics. Also provides utilities \n    to explore slices through the Munsell colour tree, to transform \n    Munsell colours and display colour palettes.",
    "version": "0.5.1",
    "maintainer": "Charlotte Wickham <cwickham@gmail.com>",
    "url": "https://cran.r-project.org/package=munsell,\nhttps://github.com/cwickham/munsell/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18166,
    "package_name": "mvPot",
    "title": "Multivariate Peaks-over-Threshold Modelling for Spatial Extreme\nEvents",
    "description": "Tools for high-dimensional peaks-over-threshold inference and simulation of Brown-Resnick and extremal Student spatial extremal processes. These include optimization routines based on censored likelihood and gradient scoring, and exact simulation algorithms for max-stable and multivariate Pareto distributions based on rejection sampling. Fast multivariate Gaussian and Student distribution functions using separation-of-variable algorithm with quasi Monte Carlo integration are also provided. Key references include de Fondeville and Davison (2018) <doi:10.1093/biomet/asy026>, Thibaud and Opitz (2015) <doi:10.1093/biomet/asv045>, Wadsworth and Tawn (2014) <doi:10.1093/biomet/ast042> and Genz and Bretz (2009) <doi:10.1007/978-3-642-01689-9>.",
    "version": "0.1.7",
    "maintainer": "Leo Belzile <belzilel@gmail.com>",
    "url": "https://github.com/r-fndv/mvPot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18204,
    "package_name": "mvs",
    "title": "Methods for High-Dimensional Multi-View Learning",
    "description": "Methods for high-dimensional multi-view learning based on the multi-view stacking (MVS) framework.\n    For technical details on the MVS and stacked penalized logistic regression (StaPLR) methods see Van Loon, Fokkema, Szabo, & De Rooij (2020) <doi:10.1016/j.inffus.2020.03.007> and Van Loon et al. (2022) <doi:10.3389/fnins.2022.830630>. ",
    "version": "2.1.0",
    "maintainer": "Wouter van Loon <w.s.van.loon@fsw.leidenuniv.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18217,
    "package_name": "mxfda",
    "title": "A Functional Data Analysis Package for Spatial Single Cell Data",
    "description": "Methods and tools for deriving spatial summary functions from single-cell imaging\n  data and performing functional data analyses. Functions can be applied to other single-cell\n  technologies such as spatial transcriptomics. Functional regression and functional principal component analysis methods\n  are in the 'refund' package <https://cran.r-project.org/package=refund> while calculation of the\n  spatial summary functions are from the 'spatstat' package <https://spatstat.org/>.",
    "version": "0.2.2-1",
    "maintainer": "Alex Soupir <alex.soupir@moffitt.org>",
    "url": "https://github.com/julia-wrobel/mxfda/,\nhttp://juliawrobel.com/mxfda/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18240,
    "package_name": "nRegression",
    "title": "Simulation-Based Calculations of Sample Size for Linear and\nLogistic Regression",
    "description": "Provides a function designed to estimate the minimal sample size required to attain a specific statistical power in the context of linear regression and logistic regression models through simulations.",
    "version": "0.5.1",
    "maintainer": "Srivastav Budugutta <sb4788@columbia.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18242,
    "package_name": "naaccr",
    "title": "Read Cancer Records in the NAACCR Format",
    "description": "Functions for reading cancer record files which follow a format\n    defined by the North American Association of Central Cancer Registries\n    (NAACCR).",
    "version": "3.1.1",
    "maintainer": "Nathan Werth <nwerth@pa.gov>",
    "url": "https://github.com/WerthPADOH/naaccr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18273,
    "package_name": "narray",
    "title": "Subset- And Name-Aware Array Utility Functions",
    "description": "Stacking arrays according to dimension names, subset-aware\n    splitting and mapping of functions, intersecting along arbitrary\n    dimensions, converting to and from data.frames, and many other helper\n    functions.",
    "version": "0.5.2",
    "maintainer": "Michael Schubert <mschu.dev@gmail.com>",
    "url": "https://github.com/mschubert/narray",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18280,
    "package_name": "naspaclust",
    "title": "Nature-Inspired Spatial Clustering",
    "description": "Implement and enhance the performance of spatial fuzzy clustering using Fuzzy Geographically Weighted Clustering with various optimization algorithms, mainly from Xin She Yang (2014) <ISBN:9780124167438> with book entitled Nature-Inspired Optimization Algorithms. The optimization algorithm is useful to tackle the disadvantages of clustering inconsistency when using the traditional approach. The distance measurements option is also provided in order to increase the quality of clustering results. The Fuzzy Geographically Weighted Clustering with nature inspired optimisation algorithm was firstly developed by Arie Wahyu Wijayanto and Ayu Purwarianti (2014) <doi:10.1109/CITSM.2014.7042178> using Artificial Bee Colony algorithm.",
    "version": "0.2.2",
    "maintainer": "Bahrul Ilmi Nasution <bahrulnst@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18281,
    "package_name": "nat",
    "title": "NeuroAnatomy Toolbox for Analysis of 3D Image Data",
    "description": "NeuroAnatomy Toolbox (nat) enables analysis and visualisation of 3D\n    biological image data, especially traced neurons. Reads and writes 3D images\n    in NRRD and 'Amira' AmiraMesh formats and reads surfaces in 'Amira' hxsurf\n    format. Traced neurons can be imported from and written to SWC and 'Amira'\n    LineSet and SkeletonGraph formats. These data can then be visualised in 3D\n    via 'rgl', manipulated including applying calculated registrations, e.g.\n    using the 'CMTK' registration suite, and analysed. There is also a simple\n    representation for neurons that have been subjected to 3D skeletonisation\n    but not formally traced; this allows morphological comparison between\n    neurons including searches and clustering (via the 'nat.nblast' extension\n    package).",
    "version": "1.8.25",
    "maintainer": "Gregory Jefferis <jefferis@gmail.com>",
    "url": "https://github.com/natverse/nat, https://natverse.org/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18311,
    "package_name": "ncdf4",
    "title": "Interface to Unidata netCDF (Version 4 or Earlier) Format Data\nFiles",
    "description": "Provides a high-level R interface to data files written using Unidata's netCDF library (version 4 or earlier), which are binary data files that are portable across platforms and include metadata information in addition to the data sets.  Using this package, netCDF files (either version 4 or \"classic\" version 3) can be opened and data sets read in easily.  It is also easy to create new netCDF dimensions, variables, and files, in either version 3 or 4 format, and manipulate existing netCDF files.  This package replaces the former ncdf package, which only worked with netcdf version 3 files.  For various reasons the names of the functions have had to be changed from the names in the ncdf package.  The old ncdf package is still available at the URL given below, if you need to have backward compatibility.  It should be possible to have both the ncdf and ncdf4 packages installed simultaneously without a problem.  However, the ncdf package does not provide an interface for netcdf version 4 files.",
    "version": "1.24",
    "maintainer": "David Pierce <dpierce@ucsd.edu>",
    "url": "https://cirrus.ucsd.edu/~pierce/ncdf/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18314,
    "package_name": "ncdfgeom",
    "title": "'NetCDF' Geometry and Time Series",
    "description": "Tools to create time series and geometry 'NetCDF' files.",
    "version": "1.1.6",
    "maintainer": "David Blodgett <dblodgett@usgs.gov>",
    "url": "https://code.usgs.gov/water/ncdfgeom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18315,
    "package_name": "ncf",
    "title": "Spatial Covariance Functions",
    "description": "Spatial (cross-)covariance and related geostatistical tools: the\n        nonparametric (cross-)covariance function , the spline correlogram, the\n        nonparametric phase coherence function, local indicators of spatial \n        association (LISA), (Mantel) correlogram, (Partial) Mantel test.",
    "version": "1.3-2",
    "maintainer": "Ottar N. Bjornstad <onb1@psu.edu>",
    "url": "https://ento.psu.edu/directory/onb1",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18319,
    "package_name": "ncpen",
    "title": "Unified Algorithm for Non-convex Penalized Estimation for\nGeneralized Linear Models",
    "description": "An efficient unified nonconvex penalized estimation algorithm for\n    Gaussian (linear), binomial Logit (logistic), Poisson, multinomial Logit,\n    and Cox proportional hazard regression models.\n    The unified algorithm is implemented based on the convex concave procedure and\n    the algorithm can be applied to most of the existing nonconvex penalties.\n    The algorithm also supports convex penalty:\n    least absolute shrinkage and selection operator (LASSO).\n    Supported nonconvex penalties include\n    smoothly clipped absolute deviation (SCAD),\n    minimax concave penalty (MCP), truncated LASSO penalty (TLP),\n    clipped LASSO (CLASSO), sparse ridge (SRIDGE),\n    modified bridge (MBRIDGE) and modified log (MLOG).\n    For high-dimensional data (data set with many variables),\n    the algorithm selects relevant variables producing a parsimonious regression model.\n    Kim, D., Lee, S. and Kwon, S. (2018) <arXiv:1811.05061>,\n    Lee, S., Kwon, S. and Kim, Y. (2016) <doi:10.1016/j.csda.2015.08.019>,\n    Kwon, S., Lee, S. and Kim, Y. (2015) <doi:10.1016/j.csda.2015.07.001>.\n    (This research is funded by Julian Virtue Professorship from Center for Applied Research at Pepperdine\n    Graziadio Business School and the National Research Foundation of Korea.)",
    "version": "1.0.0",
    "maintainer": "Dongshin Kim <dongshin.kim@live.com>",
    "url": "https://github.com/zeemkr/ncpen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18360,
    "package_name": "neptune",
    "title": "MLOps Metadata Store - Experiment Tracking and Model Registry\nfor Production Teams",
    "description": "An interface to Neptune. A metadata store for MLOps, built for teams that run a lot of experiments.\n    It gives you a single place to log, store, display, organize, compare, and query all your model-building metadata.\n    Neptune is used for:\n    • Experiment tracking: Log, display, organize, and compare ML experiments in a single place.\n    • Model registry: Version, store, manage, and query trained models, and model building metadata.\n    • Monitoring ML runs live: Record and monitor model training, evaluation, or production runs live\n    For more information see <https://neptune.ai/>.",
    "version": "0.2.3",
    "maintainer": "Rafal Jankowski <rafal.jankowski@neptune.ai>",
    "url": "https://github.com/neptune-ai/neptune-r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18365,
    "package_name": "nestfs",
    "title": "Cross-Validated (Nested) Forward Selection",
    "description": "Implementation of forward selection based on cross-validated\n             linear and logistic regression.",
    "version": "1.0.3",
    "maintainer": "Marco Colombo <mar.colombo13@gmail.com>",
    "url": "https://github.com/mcol/nestfs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18413,
    "package_name": "networkR",
    "title": "Network Analysis and Visualization",
    "description": "Collection of functions for fast manipulation, handling, and analysis of large-scale\n    networks based on family and social data. Functions are utility functions used to manipulate data\n    in three \"formats\": sparse adjacency matrices, pedigree trio family data, and pedigree family data.\n    When possible, the functions should be able to handle millions of data points quickly for use in combination\n    with data from large public national registers and databases.\n    Kenneth Lange (2003, ISBN:978-8181281135).",
    "version": "0.1.5",
    "maintainer": "Claus Thorn Ekstrøm <ekstrom@sund.ku.dk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18421,
    "package_name": "neuroSCC",
    "title": "Bridging Simultaneous Confidence Corridors and PET Neuroimaging",
    "description": "Tools for the structured processing of PET neuroimaging data \n    in preparation for the estimation of Simultaneous Confidence Corridors (SCCs) \n    for one-group, two-group, or single-patient vs group comparisons. \n    The package facilitates PET image loading, data restructuring, integration \n    into a Functional Data Analysis framework, contour extraction, identification \n    of significant results, and performance evaluation. It bridges established \n    packages (e.g., 'oro.nifti') with novel statistical methodologies (e.g., \n    'ImageSCC') and enables reproducible analysis pipelines, including \n    comparison with Statistical Parametric Mapping ('SPM').",
    "version": "1.0.0",
    "maintainer": "Juan A. Arias Lopez <juanantonio.arias.lopez@usc.es>",
    "url": "https://iguanamarina.github.io/neuroSCC/,\nhttps://github.com/iguanamarina/PhD-2023-SCC-vs-SPM-Group-vs-Group,\nhttps://github.com/iguanamarina/PhD-2024-SCC-vs-SPM-SinglePatient-vs-Group",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18427,
    "package_name": "neuroim2",
    "title": "Data Structures for Brain Imaging Data",
    "description": "A collection of data structures and methods for handling volumetric\n    brain imaging data, with a focus on functional magnetic resonance imaging (fMRI). Provides efficient\n    representations for three-dimensional and four-dimensional neuroimaging data through sparse and dense array\n    implementations, memory-mapped file access for large datasets, and\n    spatial transformation capabilities. Implements methods for image resampling,\n    spatial filtering, region of interest analysis, and connected component labeling. General introduction \n    to fMRI analysis can be found in Poldrack et al. (2024, \"Handbook of functional MRI data analysis\",\n    <ISBN:9781108795760>). ",
    "version": "0.8.1",
    "maintainer": "Bradley R Buchsbaum <brad.buchsbaum@gmail.com>",
    "url": "https://github.com/bbuchsbaum/neuroim2,\nhttps://bbuchsbaum.github.io/neuroim2/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18460,
    "package_name": "ngspatial",
    "title": "Fitting the Centered Autologistic and Sparse Spatial Generalized\nLinear Mixed Models for Areal Data",
    "description": "Provides tools for analyzing spatial data, especially non-\n    Gaussian areal data. The current version supports the sparse restricted\n    spatial regression model of Hughes and Haran (2013) <DOI:10.1111/j.1467-9868.2012.01041.x>,\n\tthe centered autologistic model of Caragea and Kaiser (2009) <DOI:10.1198/jabes.2009.07032>,\n\tand the Bayesian spatial filtering model of Hughes (2017) <arXiv:1706.04651>.",
    "version": "1.2-2",
    "maintainer": "John Hughes <drjphughesjr@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18479,
    "package_name": "nifti.pbcor",
    "title": "Parcel-Based Correlation Between NIfTI Images",
    "description": "Estimate the correlation between two NIfTI images across random parcellations of the images (Fortea et al., under review). This approach overcomes the problems of both voxel-based correlations (neighbor voxels may be spatially dependent) and atlas-based correlations (the correlation may depend on the atlas used).",
    "version": "1.0",
    "maintainer": "Joaquim Radua <quimradua@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18490,
    "package_name": "nimbleSCR",
    "title": "Spatial Capture-Recapture (SCR) Methods Using 'nimble'",
    "description": "Provides utility functions, distributions, and fitting methods for Bayesian Spatial Capture-Recapture (SCR) and Open Population Spatial Capture-Recapture (OPSCR) modelling using the nimble package (de Valpine et al. 2017 <doi:10.1080/10618600.2016.1172487 >). Development of the package was motivated primarily by the need for flexible and efficient analysis of large-scale SCR data (Bischof et al. 2020 <doi:10.1073/pnas.2011383117 >). Computational methods and techniques implemented in nimbleSCR include those discussed in Turek et al. 2021 <doi:10.1002/ecs2.3385>; among others. For a recent application of nimbleSCR, see Milleret et al. (2021) <doi:10.1098/rsbl.2021.0128>.",
    "version": "0.2.1",
    "maintainer": "Daniel Turek <danielturek@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18492,
    "package_name": "nimblewomble",
    "title": "Bayesian Wombling using 'nimble'",
    "description": "A software package to perform Wombling, or boundary analysis, using the 'nimble' Bayesian hierarchical modeling environment. Wombling is used widely to track regions of rapid change within the spatial reference domain. Specific functions in the package implement Gaussian process models for point-referenced spatial data followed by predictive inference on rates of change over curves using line integrals. We demonstrate model based Bayesian inference using posterior distributions featuring simple analytic forms while offering uncertainty quantification over curves. For more details on wombling please see, Banerjee and Gelfand (2006) <doi:10.1198/016214506000000041> and Halder, Banerjee and Dey (2024) <doi:10.1080/01621459.2023.2177166>.",
    "version": "0.1.0",
    "maintainer": "Aritra Halder <aritra.halder@drexel.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18500,
    "package_name": "nlMS",
    "title": "Non-Linear Model Selection",
    "description": "Package to select best model  among several linear and nonlinear models. The main function uses the gnls() function from the 'nlme' package to fit the data to nine regression models, named: \"linear\", \"quadratic\", \"cubic\", \"logistic\", \"exponential\", \"power\", \"monod\", \"haldane\", \"logit\".",
    "version": "1.1",
    "maintainer": "Carme Font <carme.font.moragon@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18505,
    "package_name": "nlgm",
    "title": "Non Linear Growth Models",
    "description": "Six growth models are fitted using non-linear least squares. These are the Richards, the 3, 4 and 5 parameter logistic, the Gompetz and the Weibull growth models. Reference: Reddy T., Shkedy Z., van Rensburg C. J., Mwambi H., Debba P., Zuma K. and Manda, S. (2021). \"Short-term real-time prediction of total number of reported COVID-19 cases and deaths in South Africa: a data driven approach\". BMC medical research methodology, 21(1), 1-11. <doi:10.1186/s12874-020-01165-x>.",
    "version": "1.0",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18508,
    "package_name": "nlme",
    "title": "Linear and Nonlinear Mixed Effects Models",
    "description": "Fit and compare Gaussian linear and nonlinear mixed-effects models.",
    "version": "3.1-168",
    "maintainer": "R Core Team <R-core@R-project.org>",
    "url": "https://svn.r-project.org/R-packages/trunk/nlme/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18548,
    "package_name": "nmfbin",
    "title": "Non-Negative Matrix Factorization for Binary Data",
    "description": "Factorize binary matrices into rank-k components using the logistic function in the updating process. See e.g. Tomé et al (2015) <doi:10.1007/s11045-013-0240-9> .",
    "version": "0.2.1",
    "maintainer": "Michal Ovadek <michal.ovadek@gmail.com>",
    "url": "https://michalovadek.github.io/nmfbin/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18560,
    "package_name": "nna",
    "title": "Nearest-Neighbor Analysis",
    "description": "Calculates spatial pattern analysis using a T-square sample procedure.\n  This method is based on two measures \"x\" and \"y\".\n  \"x\" - Distance from the random point to the nearest individual.\n  \"y\" - Distance from individual to its nearest neighbor.\n  This is a methodology commonly used in phytosociology or marine benthos ecology to analyze the species' distribution (random, uniform or clumped patterns).\n  Ludwig & Reynolds (1988, ISBN:0471832359).",
    "version": "0.0.2.1",
    "maintainer": "Cristiano Pereira <cristianomp@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18566,
    "package_name": "nngeo",
    "title": "k-Nearest Neighbor Join for Spatial Data",
    "description": "K-nearest neighbor search for projected and non-projected 'sf' spatial layers. Nearest neighbor search uses (1) C code from 'GeographicLib' for lon-lat point layers, (2) function knn() from package 'nabor' for projected point layers, or (3) function st_distance() from package 'sf' for line or polygon layers. The package also includes several other utility functions for spatial analysis.",
    "version": "0.4.8",
    "maintainer": "Michael Dorman <dorman@post.bgu.ac.il>",
    "url": "https://michaeldorman.github.io/nngeo/,\nhttps://github.com/michaeldorman/nngeo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18594,
    "package_name": "nomisdata",
    "title": "Access 'Nomis' UK Labour Market Data and Statistics",
    "description": "Interface to the 'Nomis' database (<https://www.nomisweb.co.uk>), a comprehensive resource of United Kingdom labour market statistics provided by the Office for National Statistics (ONS). Facilitates programmatic access to census data, labour force surveys, benefit statistics, and socioeconomic indicators through a modern HTTP client with intelligent caching, automatic query pagination, and tidy data principles. Includes spatial data integration, interactive helpers, and visualization utilities. Independent implementation unaffiliated with ONS or Durham University.",
    "version": "0.1.1",
    "maintainer": "Cheryl Isabella Lim <cheryl.academic@gmail.com>",
    "url": "https://github.com/cherylisabella/nomisdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18677,
    "package_name": "nplr",
    "title": "N-Parameter Logistic Regression",
    "description": "Performing drug response analyses and IC50 estimations using n-Parameter logistic regression. Can also be applied to proliferation analyses.",
    "version": "0.1-8",
    "maintainer": "Tymoteusz Kwiecinski <tymoteuszkwiecinski@gmail.com>",
    "url": "https://github.com/mini-pw/nplr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18681,
    "package_name": "npmr",
    "title": "Nuclear Penalized Multinomial Regression",
    "description": "Fit multinomial logistic regression with a penalty on the nuclear\n    norm of the estimated regression coefficient matrix, using proximal\n    gradient descent.",
    "version": "1.3.1",
    "maintainer": "Scott Powers <saberpowers@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18685,
    "package_name": "npphen",
    "title": "Vegetation Phenological Cycle and Anomaly Detection using Remote\nSensing Data",
    "description": "Calculates phenological cycle and anomalies using a non-parametric\n    approach applied to time series of vegetation indices derived from remote sensing data \n    or field measurements. The package implements basic and high-level functions for \n    manipulating vector data (numerical series) and raster data (satellite derived products).\n    Processing of very large raster files is supported. For more information, please check \n    the following paper:\n    Chávez et al. (2023) <doi:10.3390/rs15010073>.",
    "version": "2.0.1",
    "maintainer": "José A. Lastra <jose.lastra@pucv.cl>",
    "url": "https://github.com/labGRS/npphen, https://labgrs.github.io/npphen/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18702,
    "package_name": "nsRFA",
    "title": "Non-Supervised Regional Frequency Analysis",
    "description": "A collection of statistical tools for objective (non-supervised) applications \n             of the Regional Frequency Analysis methods in hydrology. \n             The package refers to the index-value method and, more precisely, helps the\n             hydrologist to: (1) regionalize the index-value; (2) form homogeneous regions \n             with similar growth curves; (3) fit distribution functions to the \n             empirical regional growth curves.\n             Most of the methods are those described in the Flood Estimation Handbook \n            (Centre for Ecology & Hydrology, 1999, ISBN:9781906698003).\n             Homogeneity tests from Hosking and Wallis (1993) <doi:10.1029/92WR01980> \n             and Viglione et al. (2007) <doi:10.1029/2006WR005095> are available.",
    "version": "0.7-17",
    "maintainer": "Alberto Viglione <alberto.viglione@polito.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18746,
    "package_name": "nycgeo",
    "title": "Spatial Data Files for NYC",
    "description": "Spatial data files for various geographic and administrative",
    "version": "0.1.0.9000",
    "maintainer": "Matt Herman <mfherman@gmail.com>",
    "url": "https://github.com/mfherman/nycgeo",
    "exports": [],
    "topics": ["american-community-survey", "census", "gis", "nyc", "r", "sf", "spatial-data"],
    "score": "NA",
    "stars": 27
  },
  {
    "id": 18768,
    "package_name": "objectSignals",
    "title": "Observer Pattern for S4",
    "description": "A mutable Signal object can report changes to its state,\n    clients could register functions so that they are called whenever\n    the signal is emitted. The signal could be emitted, disconnected,\n    blocked, unblocked, and buffered.",
    "version": "0.10.3",
    "maintainer": "Michael Lawrence <michafla@gene.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18772,
    "package_name": "obsSens",
    "title": "Sensitivity Analysis for Observational Studies",
    "description": "Observational studies are limited in that there could be an unmeasured variable related to both the response variable and the primary predictor.  If this unmeasured variable were included in the analysis it would change the relationship (possibly changing the conclusions).  Sensitivity analysis is a way to see how much of a relationship needs to exist with the unmeasured variable before the conclusions change.  This package provides tools for doing a sensitivity analysis for regression (linear, logistic, and cox) style models.",
    "version": "1.4",
    "maintainer": "Greg Snow <538280@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18784,
    "package_name": "oceanic",
    "title": "Location Identify Tool",
    "description": "Determine the sea area where the fishing boat operates. \n             The latitude and longitude of geographic coordinates are used to match oceanic areas and economic sea areas. \n\t    \t     You can plot the distribution map with dotplot() function.\n\t\t         Please refer to Flanders Marine Institute (2020) <doi:10.14284/403>.",
    "version": "0.1.8",
    "maintainer": "shiao chih hao <chihhao@ofdc.org.tw>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18786,
    "package_name": "oceanmap",
    "title": "A Plotting Toolbox for 2D Oceanographic Data",
    "description": "Plotting toolbox for 2D oceanographic data (satellite data, sea surface temperature, chlorophyll, ocean fronts & bathymetry). Recognized classes and formats include netcdf, Raster, '.nc' and '.gz' files.",
    "version": "0.1.7",
    "maintainer": "Robert K. Bauer <marine.biologging@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18801,
    "package_name": "odbr",
    "title": "Download Data from Brazil's Origin Destination Surveys",
    "description": "Download data from Brazil's Origin Destination Surveys. The package covers both data from household travel surveys, dictionaries of variables, and the spatial geometries of surveys conducted in different years and across various urban areas in Brazil. For some cities, the package will include enhanced versions of the data sets with variables \"harmonized\" across different years.",
    "version": "0.1.1",
    "maintainer": "Haydee Svab <hsvab@hsvab.eng.br>",
    "url": "https://hsvab.github.io/odbr/, https://github.com/hsvab/odbr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18837,
    "package_name": "ohsome",
    "title": "An 'ohsome API' Client",
    "description": "A client that grants access to the power of the 'ohsome API'\n    from R. It lets you analyze the rich data source of the \n    'OpenStreetMap (OSM)' history. You can retrieve the geometry of 'OSM' \n    data at specific points in time, and you can get aggregated statistics \n    on the evolution of 'OSM' elements and specify your own temporal, \n    spatial and/or thematic filters.",
    "version": "0.2.2",
    "maintainer": "Oliver Fritz <oliver.fritz@heigit.org>",
    "url": "https://github.com/GIScience/ohsome-r,https://docs.ohsome.org/ohsome-api/stable/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18848,
    "package_name": "ollg",
    "title": "Computes some Measures of OLL-G Family of Distributions",
    "description": "Computes the pdf, cdf, quantile function, hazard function and generating random numbers for Odd log-logistic family (OLL-G). This family have been developed by different authors in the recent years. See Alizadeh (2019) <doi:10.31801/cfsuasmas.542988> for example.",
    "version": "1.0.0",
    "maintainer": "Danial Mazarei <danial.mazarei@gmail.com>",
    "url": "https://github.com/dmazarei/ollg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18849,
    "package_name": "ollggamma",
    "title": "Odd Log-Logistic Generalized Gamma Probability Distribution",
    "description": "Density, distribution function, quantile function and random generation for the Odd Log-Logistic Generalized Gamma proposed in Prataviera, F. et al (2017) <doi:10.1080/00949655.2016.1238088>.",
    "version": "1.0.2",
    "maintainer": "Matheus H. J. Saldanha <mhjsaldanha@gmail.com>",
    "url": "https://mjsaldanha.com/posts/ollggamma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18889,
    "package_name": "onion",
    "title": "Octonions and Quaternions",
    "description": "\n  Quaternions and Octonions are four- and eight- dimensional\n  extensions of the complex numbers.  They are normed division\n  algebras over the real numbers and find applications in spatial\n  rotations (quaternions), and string theory and relativity\n  (octonions).  The quaternions are noncommutative and the octonions\n  nonassociative.  See the package vignette for more details.",
    "version": "1.5-3",
    "maintainer": "Robin K. S. Hankin <hankin.robin@gmail.com>",
    "url": "https://github.com/RobinHankin/onion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18891,
    "package_name": "onlineCOV",
    "title": "Online Change Point Detection in High-Dimensional Covariance\nStructure",
    "description": "Implement a new stopping rule to detect anomaly in the covariance structure of high-dimensional online data. The detection procedure can be applied to Gaussian or non-Gaussian data with a large number of components. Moreover, it allows both spatial and temporal dependence in data. The dependence can be estimated by a data-driven procedure. The level of threshold in the stopping rule can be determined at a pre-selected average run length. More detail can be seen in Li, L. and Li, J. (2020) \"Online Change-Point Detection in High-Dimensional Covariance Structure with Application to Dynamic Networks.\" <arXiv:1911.07762>.",
    "version": "1.3",
    "maintainer": "Jun Li <jli49@kent.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18895,
    "package_name": "onlineretail",
    "title": "Online Retail Dataset",
    "description": "Transactions occurring for a UK-based and registered, non-store online \n    retail between 01/12/2010 and 09/12/2011 (Chen et. al., 2012, <doi:10.1145/1835804.1835882>). \n    This dataset is included in this package with the donor's permission, Dr. Daqing Chen.",
    "version": "0.1.2",
    "maintainer": "Allan Quadros <allanvcq@gmail.com>",
    "url": "https://github.com/allanvc/onlineretail/,\nhttps://doi.org/10.1057/dbm.2012.17,\nhttps://www.researchgate.net/profile/Daqing-Chen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18897,
    "package_name": "onmaRg",
    "title": "Import Public Health Ontario's Ontario Marginalization Index",
    "description": "The Ontario Marginalization Index is a socioeconomic model that is built on Statistics Canada census data.\n    The model consists of four dimensions: In 2021, these dimensions were updated to \"Material Resources\" (previously called \"Material Deprivation\"), \"Households and Dwellings\" (previously called \"Residential Instability\"), \"Age and Labour Force\" (previously called \"Dependency\"), and \"Racialized and Newcomer Populations\" (previously called \"Ethnic Concentration\").\n    This update reflects a movement away from deficit-based language. 2021 data will load with these new dimension names, wheras 2011 and 2016 data will load with the historical dimension names.\n    Each of these dimensions are imported for a variety of geographic levels (DA, CD, etc.) for the 2021, 2011 and 2016 administrations of the census.\n    These data sets contribute to community analysis of equity with respect to Ontario's Anti-Racism Act.\n    The Ontario Marginalization Index data is retrieved from the Public Health Ontario website: <https://www.publichealthontario.ca/en/data-and-analysis/health-equity/ontario-marginalization-index>.\n    The shapefile data is retrieved from the Statistics Canada website: <https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-eng.cfm>.",
    "version": "1.0.3",
    "maintainer": "William Conley <william@cconley.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18899,
    "package_name": "onpoint",
    "title": "Helper Functions for Point Pattern Analysis",
    "description": "\n  Growing collection of helper functions for point pattern analysis. Most functions\n  are designed to work with the 'spatstat' (<http://spatstat.org>) package. The focus of \n  most functions are either null models or summary functions for spatial point patterns. \n  For a detailed description of all null models and summary functions, see \n  Wiegand and Moloney (2014, ISBN:9781420082548).",
    "version": "1.1",
    "maintainer": "Maximilian H.K. Hesselbarth <mhk.hesselbarth@gmail.com>",
    "url": "https://r-spatialecology.github.io/onpoint/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18921,
    "package_name": "openCR",
    "title": "Open Population Capture-Recapture",
    "description": "Non-spatial and spatial open-population capture-recapture analysis.",
    "version": "2.2.7",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "url": "https://www.otago.ac.nz/density/,\nhttps://github.com/MurrayEfford/openCR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18924,
    "package_name": "openEO.R.UDF",
    "title": "User-defined functions (UDF) in R on Earth observation data in cloud back-ends",
    "description": "Reads Earth Observation (EO) data to a stars object, applies users' custom function on it,",
    "version": "0.1",
    "maintainer": "Pramit Ghosh <pramitghosh@uni-muenster.de>",
    "url": "https://github.com/pramitghosh/openEO.R.UDF",
    "exports": [],
    "topics": ["cloud-computing", "eo-data", "r-spatial", "rest-api", "user-defined-functions"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 18930,
    "package_name": "openSTARS",
    "title": "An Open Source Implementation of the 'ArcGIS' Toolbox 'STARS'",
    "description": "An open source implementation of the 'STARS' toolbox",
    "version": "1.2.3",
    "maintainer": "",
    "url": "https://github.com/MiKatt/openSTARS",
    "exports": [],
    "topics": ["gis", "grass", "ssn", "stream-network"],
    "score": "NA",
    "stars": 46
  },
  {
    "id": 18947,
    "package_name": "openeo",
    "title": "Client Interface for 'openEO' Servers",
    "description": "Access data and processing functionalities of 'openEO' compliant back-ends in R.",
    "version": "1.4.1",
    "maintainer": "Florian Lahn <florian.lahn@eftas.com>",
    "url": "https://open-eo.github.io/openeo-r-client/,\nhttps://github.com/Open-EO/openeo-r-client",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18971,
    "package_name": "optRF",
    "title": "Optimising Random Forest Stability by Determining the Optimal\nNumber of Trees",
    "description": "Calculating the stability of random forest with certain numbers of trees. The non-linear relationship between stability and numbers of trees is described using a logistic regression model and used to estimate the optimal number of trees.",
    "version": "1.2.1",
    "maintainer": "Thomas Martin Lange <thomas.lange@uni-goettingen.de>",
    "url": "https://github.com/tmlange/optRF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 18981,
    "package_name": "optical",
    "title": "Optimal Item Calibration",
    "description": "The restricted optimal design method is implemented to optimally \n allocate a set of items that require calibration to a group of examinees.\n The optimization process is based on the method described in detail by \n Ul Hassan and Miller in their works published in (2019) \n <doi:10.1177/0146621618824854> and (2021) <doi:10.1016/j.csda.2021.107177>.\n To use the method, preliminary item characteristics must be provided as input.\n These characteristics can either be expert guesses or based on previous\n calibration with a small number of examinees. The item characteristics\n should be described in the form of parameters for an Item Response\n Theory (IRT) model. These models can include the Rasch model, the\n 2-parameter logistic model, the 3-parameter logistic model, or a mixture\n of these models. The output consists of a set of rules for each item\n that determine which examinees should be assigned to each item. The\n efficiency or gain achieved through the optimal design is quantified by\n comparing it to a random allocation. This comparison allows for an\n assessment of how much improvement or advantage is gained by using the\n optimal design approach. This work was supported by the Swedish Research Council\n (Vetenskapsrådet) Grant 2019-02706.",
    "version": "1.7.1",
    "maintainer": "Mahmood Ul Hassan <scenic555@gmail.com>",
    "url": "https://scenic555.github.io/optical/,\nhttps://github.com/scenic555/optical",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19013,
    "package_name": "orbis",
    "title": "Spatial Data Analysis Tools",
    "description": "A collection of tools for gathering and processing spatial data",
    "version": "0.1.0.9000",
    "maintainer": "",
    "url": "https://github.com/danielvartan/orbis",
    "exports": [],
    "topics": ["api-clients", "brazil", "r-packages", "rstats", "sidra", "spatial-analysis", "spatial-data", "terra", "worldclim"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 19021,
    "package_name": "ordcrm",
    "title": "Likelihood-Based Continual Reassessment Method (CRM) Dose\nFinding Designs",
    "description": "Provides the setup and calculations needed\n        to run a likelihood-based continual reassessment method (CRM)\n        dose finding trial and performs simulations to assess design\n        performance under various scenarios. 3 dose finding designs\n        are included in this package: ordinal proportional odds model\n        (POM) CRM, ordinal continuation ratio (CR) model CRM, and the\n        binary 2-parameter logistic model CRM.\n        These functions allow customization of design characteristics\n        to vary sample size, cohort sizes, target dose-limiting\n        toxicity (DLT) rates, discrete or continuous dose levels,\n        combining ordinal grades 0 and 1 into one category, and\n        incorporate safety and/or stopping rules.\n        For POM and CR model designs, ordinal toxicity grades are\n        specified by common terminology criteria for adverse events\n        (CTCAE) version 4.0.\n        Function 'pseudodata' creates the necessary starting models\n        for these 3 designs, and function 'nextdose' estimates the\n        next dose to test in a cohort of patients for a target DLT\n        rate.\n        We also provide the function 'crmsimulations' to assess the\n        performance of these 3 dose finding designs under various\n        scenarios.",
    "version": "1.0.0",
    "maintainer": "Emily V. Dressler <EmilyVDressler@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19030,
    "package_name": "orders",
    "title": "Sampling from k-th Order Statistics of New Families of\nDistributions",
    "description": "Set of tools to generate samples of k-th order statistics and others quantities of interest from new families of distributions. \n    The main references for this package are: C. Kleiber and S. Kotz (2003) Statistical size distributions in economics and actuarial sciences; Gentle, J. (2009), Computational Statistics, Springer-Verlag; \n    Naradajah, S. and Rocha, R. (2016), <DOI:10.18637/jss.v069.i10> and Stasinopoulos, M. and Rigby, R. (2015), <DOI:10.1111/j.1467-9876.2005.00510.x>.\n    The families of distributions are: Benini distributions, Burr distributions, Dagum distributions, Feller-Pareto distributions, Generalized Pareto distributions, Inverse Pareto distributions, The Inverse Paralogistic distributions, Marshall-Olkin G distributions, exponentiated G distributions, beta G distributions, \n    gamma G distributions, Kumaraswamy G distributions, generalized beta G distributions, \n    beta extended G distributions, gamma G distributions, gamma uniform G distributions, beta exponential G distributions, Weibull G distributions, log gamma G I distributions, log gamma G II distributions, \n    exponentiated generalized G distributions, exponentiated Kumaraswamy G distributions, geometric exponential Poisson G distributions, truncated-exponential skew-symmetric G distributions, modified beta G distributions, \n    exponentiated exponential Poisson G distributions, Poisson-inverse gaussian distributions, Skew normal type 1 distributions, Skew student t distributions, Singh-Maddala distributions, Sinh-Arcsinh distributions, Sichel distributions, Zero inflated Poisson distributions. ",
    "version": "0.1.8",
    "maintainer": "Carlos Alberto Cardozo Delgado <cardozorpackages@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19040,
    "package_name": "ordinalTables",
    "title": "Fit Models to Two-Way Tables with Correlated Ordered Response\nCategories",
    "description": "Fit a variety of models to two-way tables with ordered categories.\n  Most of the models are appropriate to apply to tables of that have correlated ordered\n  response categories.  There is a particular interest in rater data and models for rescore\n  tables. Some utility functions (e.g., Cohen's kappa and weighted kappa) support\n  more general work on rater agreement.\n  Because the names of the models are very similar, the functions that implement them are\n  organized by last name of the primary author of the article or book that suggested the model,\n  with the name of the function beginning with that author's name and an underscore.  This\n  may make some models more difficult to locate if one doesn't have the original sources.  The\n  vignettes and tests can help to locate models of interest.  For more dertaiils see the following references:\n  Agresti, A. (1983) <doi:10.1016/0167-7152(83)90051-2> \"A Simple Diagonals-Parameter Symmetry And Quasi-Symmetry Model\",\n  Agrestim A. (1983) <doi:10.2307/2531022> \"Testing Marginal Homogeneity for Ordinal Categorical Variables\",\n  Agresti, A. (1988) <doi:10.2307/2531866> \"A Model For Agreement Between Ratings On An Ordinal Scale\",\n  Agresti, A. (1989) <doi:10.1016/0167-7152(89)90104-1> \"An Agreement Model With Kappa As Parameter\",\n  Agresti, A. (2010 ISBN:978-0470082898) \"Analysis Of Ordinal Categorical Data\",\n  Bhapkar, V. P. (1966) <doi:10.1080/01621459.1966.10502021> \"A Note On The Equivalence Of Two Test Criteria For Hypotheses In Categorical Data\",\n  Bhapkar, V. P. (1979) <doi:10.2307/2530344> \"On Tests Of Marginal Symmetry And Quasi-Symmetry In Two And Three-Dimensional Contingency Tables\",\n  Bowker, A. H. (1948) <doi:10.2307/2280710> \"A Test For Symmetry In Contingency Tables\",\n  Clayton, D. G. (1974) <doi:10.2307/2335638> \"Some Odds Ratio Statistics For The Analysis Of Ordered Categorical Data\",\n  Cliff, N. (1993) <doi:10.1037/0033-2909.114.3.494> \"Dominance Statistics: Ordinal Analyses To Answer Ordinal Questions\",\n  Cliff, N. (1996 ISBN:978-0805813333) \"Ordinal Methods For Behavioral Data Analysis\",\n  Goodman, L. A. (1979) <doi:10.1080/01621459.1979.10481650> \"Simple Models For The Analysis Of Association In Cross-Classifications Having Ordered Categories\",\n  Goodman, L. A. (1979) <doi:10.2307/2335159> \"Multiplicative Models For Square Contingency Tables With Ordered Categories\",\n  Ireland, C. T., Ku, H. H., & Kullback, S. (1969) <doi:10.2307/2286071> \"Symmetry And Marginal Homogeneity Of An r × r Contingency Table\",\n  Ishi-kuntz, M. (1994 ISBN:978-0803943766) \"Ordinal Log-linear Models\",\n  McCullah, P. (1977) <doi:10.2307/2345320> \"A Logistic Model For Paired Comparisons With Ordered Categorical Data\",\n  McCullagh, P. (1978) <doi:10.2307/2335224> A Class Of Parametric Models For The Analysis Of Square Contingency Tables With Ordered Categories\",\n  McCullagh, P. (1980) <doi:10.1111/j.2517-6161.1980.tb01109.x> \"Regression Models For Ordinal Data\",\n  Penn State: Eberly College of Science (undated) <https://online.stat.psu.edu/stat504/lesson/11> \"Stat 504: Analysis of Discrete Data, 11. Advanced Topics I\",\n  Schuster, C. (2001) <doi:10.3102/10769986026003331> \"Kappa As A Parameter Of A Symmetry Model For Rater Agreement\",\n  Shoukri, M. M. (2004 ISBN:978-1584883210). \"Measures Of Interobserver Agreement\",\n  Stuart, A. (1953) <doi:10.2307/2333101> \"The Estimation Of And Comparison Of Strengths Of Association In Contingency Tables\",\n  Stuart, A. (1955) <doi:10.2307/2333387> \"A Test For Homogeneity Of The Marginal Distributions In A Two-Way Classification\",\n  von Eye, A., & Mun, E. Y. (2005 ISBN:978-0805849677) \"Analyzing Rater Agreement: Manifest Variable Methods\".",
    "version": "1.0.0.3",
    "maintainer": "John R. Donoghue <jdonoghue0823@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19047,
    "package_name": "oregonfrogs",
    "title": "Oregon Spotted A Frog (Rana Pretiosa)",
    "description": "Oregon Frogs Rana Pretiosa dataset contains information about",
    "version": "0.1.0",
    "maintainer": "The package maintainer <fede.gazzelloni@gmail.com>",
    "url": "https://github.com/Fgazzelloni/oregonfrogs",
    "exports": [],
    "topics": ["classification-model", "frequency-analysis", "geolocation", "regression-analysis", "rstats", "rstats-package", "spatial-analysis"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 19064,
    "package_name": "orsifronts",
    "title": "Southern Ocean Frontal Distributions (Orsi)",
    "description": "A data set package with the \"Orsi\" and \"Park/Durand\" fronts as\n    'SpatialLinesDataFrame' objects. The Orsi et al. (1995) fronts are published at\n    the Southern Ocean Atlas Database Page, and the Park et al. (2019) fronts are published at the 'SEANOE' \n    Altimetry-derived Antarctic Circumpolar Current fronts page, please see package CITATION for details.",
    "version": "0.2.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://australianantarcticdivision.github.io/orsifronts/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19073,
    "package_name": "osDesign",
    "title": "Design, Planning and Analysis of Observational Studies",
    "description": "A suite of functions for the design of case-control and two-phase studies, and the analysis of data that arise from them. Functions in this packages provides Monte Carlo based evaluation of operating characteristics such as powers for estimators of the components of a logistic regression model. For additional detail see: Haneuse S, Saegusa T and Lumley T (2011)<doi:10.18637/jss.v043.i11>.",
    "version": "1.8",
    "maintainer": "Sebastien Haneuse <shaneuse@hsph.harvard.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19075,
    "package_name": "osc",
    "title": "Orthodromic Spatial Clustering",
    "description": "Allows distance based spatial clustering of georeferenced data by implementing the City Clustering Algorithm - CCA. Multiple versions allow clustering for a matrix, raster and single coordinates on a plain (Euclidean distance) or on a sphere (great-circle or orthodromic distance).",
    "version": "1.0.5",
    "maintainer": "Steffen Kriewald <kriewald@pik-potsdam.de>",
    "url": "https://www.pik-potsdam.de/~kriewald/osc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19079,
    "package_name": "osdc",
    "title": "Open Source Diabetes Classifier for Danish Registers",
    "description": "The algorithm first identifies a population of individuals from \n    Danish register data with any type of diabetes as individuals with two or\n    more inclusion events. Then, it splits this population into individuals with\n    either type 1 diabetes or type 2 diabetes by identifying individuals with\n    type 1 diabetes and classifying the remainder of the diabetes population as\n    having type 2 diabetes.",
    "version": "0.9.17",
    "maintainer": "Luke William Johnston <lwjohnst@gmail.com>",
    "url": "https://github.com/steno-aarhus/osdc,\nhttps://steno-aarhus.github.io/osdc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19086,
    "package_name": "osmenrich",
    "title": "Enrich sf Data with Geographic Features from OpenStreetMaps",
    "description": "Add columns to sf data using geographic features from",
    "version": "1.2.1",
    "maintainer": "",
    "url": "https://github.com/sodascience/osmenrich",
    "exports": [],
    "topics": ["geospatial", "geospatial-data", "odissei", "osm", "sf", "utrecht-university"],
    "score": "NA",
    "stars": 19
  },
  {
    "id": 19089,
    "package_name": "osmxml",
    "title": "Import, prepare and render 'OpenStreetMap' XML files",
    "description": "Tools to import .osm files, prepare them for analysis, and plot the data with a default rendering.",
    "version": "0.2.0.9000",
    "maintainer": "",
    "url": "https://github.com/stragu/osmxml",
    "exports": [],
    "topics": ["mapping", "open-data", "openstreetmap", "osm", "r-spatial", "rstats", "xml"],
    "score": "NA",
    "stars": 6
  },
  {
    "id": 19110,
    "package_name": "ouladFormat",
    "title": "Loads and Formats the Open University Learning Analytics Dataset\nfor Data Analysis",
    "description": "The Open University Learning Analytics Dataset (OULAD) is available from \n    Kuzilek et al. (2017) <doi:10.1038/sdata.2017.171>.  The 'ouladFormat' \n    package loads, cleans and formats the OULAD for data analysis (each row of the\n    returned data set is an individual student). The package’s main function,\n    combined_dataset(), allows the user to choose whether the returned\n    data set includes assessment, demographics, virtual learning environment (VLE),\n    or registration variables etc.",
    "version": "1.2.2",
    "maintainer": "Emma Howard <emhoward@tcd.ie>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19127,
    "package_name": "overlapptest",
    "title": "Test Overlapping of Polygons Against Random Rotation",
    "description": "Tests the observed overlapping polygon area in a collection of polygons against a null model of random rotation, as explained in De la Cruz et al. (2017) <doi:10.13140/RG.2.2.12825.72801>.",
    "version": "1.4",
    "maintainer": "Marcelino de la Cruz <marcelino.delacruz@urjc.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19129,
    "package_name": "overtureR",
    "title": "Load 'Overture' Datasets as 'dbplyr' and 'sf'-Ready Data Frames",
    "description": "An integrated R interface to the 'Overture' API \n  (<https://docs.overturemaps.org/>). Allows R users to return 'Overture' data as \n  'dbplyr' data frames or materialized 'sf' spatial data frames.",
    "version": "0.2.5",
    "maintainer": "Arthur Gailes <agailes1@gmail.com>",
    "url": "https://github.com/arthurgailes/overtureR,\nhttps://arthurgailes.github.io/overtureR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19141,
    "package_name": "ozmaps",
    "title": "Australia Maps",
    "description": "Maps of Australian coastline and administrative regions. Data \n can be drawn or accessed directly as simple features objects. Includes\n simple functions for country or state maps of Australia and in-built data\n sets of administrative regions from the Australian Bureau of Statistics \n <https://www.abs.gov.au/>. Layers include electoral divisions and local \n government areas, simplified from the original sources but with sufficient \n detail to allow mapping of a local municipality. ",
    "version": "0.4.5",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/mdsumner/ozmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19153,
    "package_name": "pMEM",
    "title": "Predictive Moran's Eigenvector Maps",
    "description": "Calculation of Predictive Moran's eigenvector maps (pMEM), as\n  defined by Guénard and Legendre (In Press) \"Spatially-explicit predictions\n  using spatial eigenvector maps\" <doi:10.5281/zenodo.13356457>. Methods in\n  Ecology and Evolution. This method enables scientists to predict the values of\n  spatially-structured environmental variables. Multiple types of pMEM are\n  defined, each one implemented on the basis of spatial weighting function\n  taking a range parameter, and sometimes also a shape parameter. The code's\n  modular nature enables programers to implement new pMEM by defining new\n  spatial weighting functions.",
    "version": "0.1-1",
    "maintainer": "Guillaume Guénard <guillaume.guenard@umontreal.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19165,
    "package_name": "paar",
    "title": "Precision Agriculture Data Analysis",
    "description": "Precision agriculture spatial data\n depuration and homogeneous zones (management zone) delineation.\n The package includes functions that performs protocols for data cleaning\n management zone delineation and zone comparison; protocols are described in \n Paccioretti et al., (2020) <doi:10.1016/j.compag.2020.105556>.",
    "version": "1.0.1",
    "maintainer": "Pablo Paccioretti <pablopaccioretti@agro.unc.edu.ar>",
    "url": "https://ppaccioretti.github.io/paar/,\nhttps://github.com/PPaccioretti/paar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19185,
    "package_name": "pacu",
    "title": "Precision Agriculture Computational Utilities",
    "description": "Support for a variety of commonly used precision agriculture operations. Includes functions to download and process raw satellite images from Sentinel-2 <https://documentation.dataspace.copernicus.eu/APIs/OData.html>. Includes functions that download vegetation index statistics for a given period of time, without the need to download the raw images <https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Statistical.html>. There are also functions to download and visualize weather data in a historical context. Lastly, the package also contains functions to process yield monitor data. These functions can build polygons around recorded data points, evaluate the overlap between polygons, clean yield data, and smooth yield maps.",
    "version": "0.1.74",
    "maintainer": "dos Santos Caio <clsantos@iastate.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19186,
    "package_name": "pacviz",
    "title": "Pac-Man Visualization Package",
    "description": "Provides a broad-view perspective on data via\n    linear mapping of data onto a radial coordinate system. The package\n    contains functions to visualize the residual values of linear\n    regression and Cartesian data in the defined radial scheme. See the\n    'pacviz' documentation page for more information:\n    <https://pacviz.sriley.dev/>.",
    "version": "1.0.4",
    "maintainer": "Sarah Riley <academic@sriley.dev>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19208,
    "package_name": "paisaje",
    "title": "Spatial and Environmental Data Tools for Landscape Ecology",
    "description": "Provides functions for landscape analysis and data retrieval. \n    The package allows users to download environmental variables from global \n    datasets (e.g., WorldClim, ESA WorldCover, Nighttime Lights), and to \n    compute spatial and landscape metrics using a hexagonal grid system \n    based on the H3 spatial index. It is useful for ecological modeling, \n    biodiversity studies, and spatial data processing in landscape ecology. \n    Fick and Hijmans (2017) <doi:10.1002/joc.5086>. \n    Zanaga et al. (2022) <doi:10.5281/zenodo.7254221>. \n    Uber Technologies Inc. (2022) \"H3: Hexagonal hierarchical spatial index\".",
    "version": "0.2.0",
    "maintainer": "Manuel Spínola <mspinola10@gmail.com>",
    "url": "https://manuelspinola.github.io/paisaje/,\nhttps://github.com/ManuelSpinola/paisaje",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19211,
    "package_name": "palaeoSig",
    "title": "Significance Tests for Palaeoenvironmental Reconstructions",
    "description": "Several tests of quantitative palaeoenvironmental reconstructions \n  from microfossil assemblages, including the null model tests of the \n  statistically significant of reconstructions developed by Telford and Birks\n  (2011) <doi:10.1016/j.quascirev.2011.03.002>, and tests of the effect of \n  spatial autocorrelation on transfer function model performance using methods \n  from Telford and Birks (2009) <doi:10.1016/j.quascirev.2008.12.020> and \n  Trachsel and Telford (2016) <doi:10.5194/cp-12-1215-2016>. Age-depth models with \n  generalized mixed-effect regression from Heegaard et al (2005)\n  <doi:10.1191/0959683605hl836rr> are also included.",
    "version": "2.1-4",
    "maintainer": "Richard Telford <Richard.Telford@uib.no>",
    "url": "https://richardjtelford.github.io/palaeoSig/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19225,
    "package_name": "paletteknife",
    "title": "Create Colour Scales and Legend from Continuous or Categorical\nVectors",
    "description": "Streamlines the steps for adding colour scales and associated legends \n         when working with base R graphics, especially for interactive use. Popular\n         palettes are included and pretty legends produced when mapping a large \n         variety of vector classes to a colour scale. An additional helper for \n         adding axes and grid lines complements the base::plot() work flow.",
    "version": "0.4.2",
    "maintainer": "John Hobbs <johnxhobbs@gmail.com>",
    "url": "https://github.com/johnxhobbs/paletteknife",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19233,
    "package_name": "palr",
    "title": "Colour Palettes for Data",
    "description": "Colour palettes for data, based on some well known public data\n    sets. Includes helper functions to map absolute values to known palettes, and \n    capture the work of image colour mapping as raster data sets. ",
    "version": "0.4.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/AustralianAntarcticDivision/palr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19257,
    "package_name": "pannotator",
    "title": "Visualisation and Annotation of 360 Degree Imagery",
    "description": "Provides a customisable R 'shiny' app for immersively\n    visualising, mapping and annotating panospheric (360 degree) imagery.\n    The flexible interface allows annotation of any geocoded images using\n    up to 4 user specified dropdown menus. The app uses 'leaflet' to\n    render maps that display the geo-locations of images and panellum\n    <https://pannellum.org/>, a lightweight panorama viewer for the web,\n    to render images in virtual 360 degree viewing mode. Key functions\n    include the ability to draw on & export parts of 360 images for\n    downstream applications. Users can also draw polygons and points on\n    map imagery related to the panoramic images and export them for\n    further analysis. Downstream applications include using annotations to\n    train Artificial Intelligence/Machine Learning (AI/ML) models and\n    geospatial modelling and analysis of camera based survey data.",
    "version": "1.0.0.4",
    "maintainer": "Nunzio Knerr <Nunzio.Knerr@csiro.au>",
    "url": "https://github.com/NunzioKnerr/pannotator_package_source",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19273,
    "package_name": "parallelPlot",
    "title": "`htmlwidget` for a Parallel Coordinates Plot",
    "description": "Create a parallel coordinates plot, using `htmlwidgets` package and `d3.js`.",
    "version": "0.4.0",
    "maintainer": "David Chazalviel <david.chazalviel@club-internet.fr>",
    "url": "https://gitlab.com/drti/parallelplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19293,
    "package_name": "parfm",
    "title": "Parametric Frailty Models",
    "description": "Fits Parametric Frailty Models by maximum marginal likelihood.\n             Possible baseline hazards:\n                 exponential, Weibull, inverse Weibull (Fréchet),\n                 Gompertz, lognormal, log-skew-normal, and loglogistic.\n             Possible Frailty distributions:\n                gamma, positive stable, inverse Gaussian and lognormal.",
    "version": "2.7.8",
    "maintainer": "Federico Rotolo <federico.rotolo@sanofi.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19294,
    "package_name": "pargasite",
    "title": "Pollution-Associated Risk Geospatial Analysis Site",
    "description": "Offers tools to estimate and visualize levels of major pollutants\n             (CO, NO2, SO2, Ozone, PM2.5 and PM10) across the conterminous\n             United States for user-defined time ranges. Provides functions to\n             retrieve pollutant data from the U.S. Environmental Protection\n             Agency’s 'Air Quality System' (AQS) API service\n             <https://aqs.epa.gov/aqsweb/documents/data_api.html> for\n             interactive visualization through a 'shiny' application, allowing\n             users to explore pollutant levels for a given location over time\n             relative to the National Ambient Air Quality Standards (NAAQS).",
    "version": "2.1.1",
    "maintainer": "Jaehyun Joo <jaehyunjoo@outlook.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19304,
    "package_name": "parseRPDR",
    "title": "Parse and Manipulate Research Patient Data Registry ('RPDR')\nText Queries",
    "description": "Functions to load Research Patient Data Registry ('RPDR') text queries from Partners Healthcare institutions into R.\n             The package also provides helper functions to manipulate data and execute common procedures\n             such as finding the closest radiological exams considering a given timepoint, or creating a DICOM header database\n             from the downloaded images. All functionalities are parallelized for fast and efficient analyses.",
    "version": "1.1.2",
    "maintainer": "Marton Kolossvary <mkolossvary@mgh.harvard.edu>",
    "url": "https://github.com/martonkolossvary/parseRPDR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19365,
    "package_name": "patternize",
    "title": "Quantification of Color Pattern Variation",
    "description": "Quantification of variation in organismal color patterns as\n    obtained from image data. Patternize defines homology between pattern positions\n    across images either through fixed landmarks or image registration. Pattern\n    identification is performed by categorizing the distribution of colors using RGB\n    thresholds or image segmentation.",
    "version": "0.0.5",
    "maintainer": "Steven Van Belleghem <vanbelleghemsteven@hotmail.com>",
    "url": "https://github.com/StevenVB12/patternize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19368,
    "package_name": "pavo",
    "title": "Perceptual Analysis, Visualization and Organization of Spectral\nColour Data",
    "description": "A cohesive framework for the spectral and spatial analysis of \n    colour described in Maia, Eliason, Bitton, Doucet & Shawkey (2013) \n    <doi:10.1111/2041-210X.12069> and Maia, Gruson, Endler & White (2019)\n    <doi:10.1111/2041-210X.13174>.",
    "version": "2.9.0",
    "maintainer": "Thomas White <thomas.white026@gmail.com>",
    "url": "http://pavo.colrverse.com, https://github.com/rmaia/pavo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19406,
    "package_name": "pcLasso",
    "title": "Principal Components Lasso",
    "description": "A method for fitting the entire regularization path \n    of the principal components lasso for linear and\n    logistic regression models. The algorithm uses cyclic coordinate descent\n    in a path-wise fashion. See URL below for more information on the algorithm.\n    See Tay, K., Friedman, J. ,Tibshirani, R., (2014) 'Principal component-guided sparse regression'\n    <arXiv:1810.04651>.",
    "version": "1.2",
    "maintainer": "Rob Tibshirani <tibs@stanford.edu>",
    "url": "https://arxiv.org/abs/1810.04651",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19421,
    "package_name": "pcds.ugraph",
    "title": "Underlying Graphs of Proximity Catch Digraphs and Their\nApplications",
    "description": "Contains the functions for construction and visualization of underlying and reflexivity graphs of \n            the three families of the proximity catch digraphs (PCDs), see (Ceyhan (2005) ISBN:978-3-639-19063-2),\n            and for computing the edge density of these PCD-based graphs which are then\n            used for testing the patterns of segregation and association against complete spatial randomness (CSR))\n            or uniformity in one and two dimensional cases. \n            The PCD families considered are Arc-Slice PCDs, Proportional-Edge (PE) PCDs (Ceyhan et al. (2006) <doi:10.1016/j.csda.2005.03.002>) \n            and Central Similarity PCDs (Ceyhan et al. (2007) <doi:10.1002/cjs.5550350106>). \n            See also (Ceyhan (2016) <doi:10.1016/j.stamet.2016.07.003>) for edge density of the underlying and \n            reflexivity graphs of PE-PCDs.\n            The package also has tools for visualization of PCD-based graphs for one, two, and three dimensional data. ",
    "version": "0.1.1",
    "maintainer": "Elvan Ceyhan <elvanceyhan@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19482,
    "package_name": "pedometrics",
    "title": "Miscellaneous Pedometric Tools",
    "description": "An R implementation of methods employed in the field of pedometrics, soil science\n    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil\n    using statistical and computational methods. The methods found here include the calibration of\n    linear regression models using covariate selection strategies, computation of summary validation\n    statistics for predictions, generation of summary plots, evaluation of the local quality of a\n    geostatistical model of uncertainty, and so on. Other functions simply extend the\n    functionalities of or facilitate the usage of functions from other packages that are commonly\n    used for the analysis of soil data. Formerly available versions of suggested packages no longer\n    available from CRAN can be obtained from the CRAN archive\n    <https://cran.r-project.org/src/contrib/Archive/>.",
    "version": "0.12.1",
    "maintainer": "Alessandro Samuel-Rosa <alessandrosamuelrosa@gmail.com>",
    "url": "https://github.com/Laboratorio-de-Pedometria/pedometrics-package",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19501,
    "package_name": "penalizedclr",
    "title": "Integrative Penalized Conditional Logistic Regression",
    "description": "Implements L1 and L2 penalized conditional logistic regression with penalty \n    factors allowing for integration of multiple data sources. Implements\n    stability selection for variable selection. ",
    "version": "2.0.0",
    "maintainer": "Vera Djordjilovi'c <vera.djordjilovic@unive.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19540,
    "package_name": "permute",
    "title": "Functions for Generating Restricted Permutations of Data",
    "description": "A set of restricted permutation designs for freely exchangeable, line transects (time series), and spatial grid designs plus permutation of blocks (groups of samples) is provided. 'permute' also allows split-plot designs, in which the whole-plots or split-plots or both can be freely-exchangeable or one of the restricted designs. The 'permute' package is modelled after the permutation schemes of 'Canoco 3.1' (and later) by Cajo ter Braak.",
    "version": "0.9-8",
    "maintainer": "Gavin L. Simpson <ucfagls@gmail.com>",
    "url": "https://github.com/gavinsimpson/permute",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19561,
    "package_name": "pestr",
    "title": "Interface to Download Data on Pests and Hosts from 'EPPO'",
    "description": "Set of tools to automatize extraction of data on pests from 'EPPO\n    Data Services' and 'EPPO Global Database' and to put them into tables with\n    human readable format. Those function use 'EPPO database API', thus you \n    first need to register on <https://data.eppo.int> (free of charge).\n    Additional helpers allow to download, check and connect to\n    'SQLite EPPO database'.",
    "version": "0.8.2",
    "maintainer": "Michal Jan Czyz <m.czyz.j@gmail.com>",
    "url": "https://github.com/mczyzj/pestr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19578,
    "package_name": "pgirmess",
    "title": "Spatial Analysis and Data Mining for Field Ecologists",
    "description": "Set of tools for reading, writing and transforming spatial and seasonal data, model selection and specific statistical tests for ecologists. It includes functions to interpolate regular positions of points between landmarks, to discretize polylines into regular point positions, link distant observations to points and convert a bounding box in a spatial object. It also provides miscellaneous functions for field ecologists such as spatial statistics and inference on diversity indexes, writing data.frame with Chinese characters.",
    "version": "2.0.3",
    "maintainer": "Patrick Giraudoux <patrick.giraudoux@univ-fcomte.fr>",
    "url": "https://github.com/pgiraudoux/pgirmess",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19611,
    "package_name": "phenex",
    "title": "Auxiliary Functions for Phenological Data Analysis",
    "description": "Provides some easy-to-use functions for \n\tspatial analyses of (plant-) phenological data \n\tsets and satellite observations of vegetation.",
    "version": "1.4-5",
    "maintainer": "Daniel Doktor <daniel.doktor@ufz.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19613,
    "package_name": "pheno",
    "title": "Auxiliary Functions for Phenological Data Analysis",
    "description": "Provides some easy-to-use functions for time series\n        analyses of (plant-) phenological data sets. These functions\n        mainly deal with the estimation of combined phenological time\n        series and are usually wrappers for functions that are already\n        implemented in other R packages adapted to the special\n        structure of phenological data and the needs of phenologists.\n        Some date conversion functions to handle Julian dates are also\n        provided.",
    "version": "1.7-0",
    "maintainer": "Maximilian Lange <maximilian.lange@ufz.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19619,
    "package_name": "phenomap",
    "title": "Projecting Satellite-Derived Phenology in Space",
    "description": "This takes in a series of multi-layer raster files and returns a phenology projection raster, following methodologies described in John (2016) <https://etda.libraries.psu.edu/catalog/13521clj5135>.",
    "version": "2.0.1",
    "maintainer": "Christian John <cjohn@ucsb.edu>",
    "url": "https://github.com/JepsonNomad/phenomap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19662,
    "package_name": "phylin",
    "title": "Spatial Interpolation of Genetic Data",
    "description": "The spatial interpolation of genetic distances between\n\t     samples is based on a modified kriging method that\n\t     accepts a genetic distance matrix and generates a map of\n\t     probability of lineage presence. This package also offers\n\t     tools to generate a map of  potential contact zones\n\t     between groups with user-defined thresholds in the tree\n\t     to account for old and recent divergence. Additionally,\n\t     it has functions for IDW interpolation using genetic data\n\t     and midpoints.",
    "version": "2.0.2",
    "maintainer": "Pedro Tarroso <ptarroso@cibio.up.pt>",
    "url": "https://www.r-project.org, https://github.com/ptarroso/phylin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19680,
    "package_name": "phylospatial",
    "title": "Spatial Phylogenetic Analysis",
    "description": "Analyze spatial phylogenetic diversity patterns. \n    Use your data on an evolutionary tree and geographic distributions of the \n    terminal taxa to compute diversity and endemism metrics, test significance \n    with null model randomization, analyze community turnover and biotic \n    regionalization, and perform spatial conservation prioritizations. All \n    functions support quantitative community data in addition to binary data.",
    "version": "1.2.1",
    "maintainer": "Matthew Kling <mattkling@berkeley.edu>",
    "url": "https://matthewkling.github.io/phylospatial/,\nhttps://github.com/matthewkling/phylospatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19698,
    "package_name": "picohdr",
    "title": "Read, Write and Manipulate High Dynamic Range Images",
    "description": "High Dynamic Range (HDR) images support a large range in luminosity\n    between the lightest and darkest regions of an image.  To capture this range,\n    data in HDR images is often stored as floating point numbers and in formats\n    that capture more data and channels than standard image types.  This package supports\n    reading and writing two types of HDR images; PFM (Portable Float Map) \n    and OpenEXR images. HDR images can be converted to lower\n    dynamic ranges (for viewing) using tone-mapping.  A number of\n    tone-mapping algorithms are included which are based on \n    Reinhard (2002) \"Photographic tone reproduction for digital images\" \n    <doi:10.1145/566654.566575>.",
    "version": "0.1.1",
    "maintainer": "Mike Cheng <mikefc@coolbutuseless.com>",
    "url": "https://github.com/coolbutuseless/picohdr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19706,
    "package_name": "pii",
    "title": "Search Data Frames for Personally Identifiable Information",
    "description": "Check a data frame for personal information, including names, location, disability status, and geo-coordinates. ",
    "version": "1.3.0",
    "maintainer": "Jacob Patterson-Stein <jacobpstein@gmail.com>",
    "url": "https://github.com/jacobpstein/pii",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19804,
    "package_name": "pldamixture",
    "title": "Post-Linkage Data Analysis Based on Mixture Modelling",
    "description": "Perform inference in the secondary analysis setting with linked data potentially containing mismatch errors. Only the linked data file may be accessible and information about the record linkage process may be limited or unavailable. Implements the 'General Framework for Regression with Mismatched Data' developed by Slawski et al. (2023) <doi:10.48550/arXiv.2306.00909>. The framework uses a mixture model for pairs of linked records whose two components reflect distributions conditional on match status, i.e., correct match or mismatch. Inference is based on composite likelihood and the Expectation-Maximization (EM) algorithm. The package currently supports Cox Proportional Hazards Regression (right-censored data only) and Generalized Linear Regression Models (Gaussian, Gamma, Poisson, and Logistic (binary models only)). Information about the underlying record linkage process can be incorporated into the method if available (e.g., assumed overall mismatch rate, safe matches, predictors of match status, or predicted probabilities of correct matches).",
    "version": "0.1.1",
    "maintainer": "Priyanjali Bukke <pbukke@gmu.edu>",
    "url": "https://github.com/bpriy/pldamixture",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19811,
    "package_name": "plfm",
    "title": "Probabilistic Latent Feature Analysis",
    "description": "Functions for estimating probabilistic latent feature models with a disjunctive, conjunctive or additive mapping rule on (aggregated) binary three-way data.",
    "version": "2.2.6",
    "maintainer": "Michel Meulders <michel.meulders@kuleuven.be>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19816,
    "package_name": "pliman",
    "title": "Tools for Plant Image Analysis",
    "description": "Tools for both single and batch image manipulation and\n    analysis (Olivoto, 2022 <doi:10.1111/2041-210X.13803>) and\n    phytopathometry (Olivoto et al., 2022 <doi:10.1007/S40858-021-00487-5>).\n    The tools can be used for the quantification of leaf area, object\n    counting, extraction of image indexes, shape measurement, object\n    landmark identification, and Elliptical Fourier Analysis of object\n    outlines (Claude (2008) <doi:10.1007/978-0-387-77789-4>). The package\n    also provides a comprehensive pipeline for generating shapefiles with\n    complex layouts and supports high-throughput phenotyping of RGB,\n    multispectral, and hyperspectral orthomosaics. This functionality\n    facilitates field phenotyping using UAV- or satellite-based imagery.",
    "version": "3.1.1",
    "maintainer": "Tiago Olivoto <tiagoolivoto@gmail.com>",
    "url": "https://nepem-ufsc.github.io/pliman/,\nhttps://github.com/nepem-ufsc/pliman",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19822,
    "package_name": "pln",
    "title": "Polytomous Logit-Normit (Graded Logistic) Model Estimation",
    "description": "Performs bivariate composite likelihood and full\n        information maximum likelihood estimation for polytomous\n        logit-normit (graded logistic) item response theory (IRT)\n        models.",
    "version": "0.2-3",
    "maintainer": "Carl F. Falk <cffalk@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19840,
    "package_name": "plotbb",
    "title": "Grammar of Graphics for 'base' Plot",
    "description": "Proof of concept for implementing grammar of graphics using base plot. The bbplot() function initializes a 'bbplot' object to store input data, aesthetic mapping, a list of layers and theme elements. The object will be rendered as a graphic using base plot command if it is printed.  ",
    "version": "0.0.6",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19841,
    "package_name": "plotcli",
    "title": "Command Line Interface Plotting",
    "description": "The 'plotcli' package provides terminal-based plotting in R.\n             It supports colored scatter plots, line plots, bar plots, boxplots, \n             histograms, density plots, and more. The 'ggplotcli()' function is a \n             universal converter that renders any 'ggplot2' plot in the terminal \n             using Unicode Braille characters or ASCII. Features include support for \n             15+ geom types, faceting (facet_wrap/facet_grid), automatic theme \n             detection, legends, optimized color mapping, and multiple canvas types.",
    "version": "0.2.0",
    "maintainer": "Claas Heuer <claasheuer@gmail.com>",
    "url": "https://github.com/cheuerde/plotcli",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19855,
    "package_name": "plotr",
    "title": "Plots Made Easy",
    "description": "A set of tools designed to provide quick and easy access to",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/danielvartan/plotr",
    "exports": [],
    "topics": ["data-visualization", "ggplot2", "r", "rstats", "spatial-analysis", "spatial-statistics"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 19869,
    "package_name": "plsgenomics",
    "title": "PLS Analyses for Genomics",
    "description": "Routines for PLS-based genomic analyses,\n        implementing PLS methods for classification with\n        microarray data and prediction of transcription factor\n        activities from combined ChIP-chip analysis. The >=1.2-1\n        versions include two new classification methods for microarray\n        data: GSIM and Ridge PLS. The >=1.3 versions includes a\n        new classification method combining variable selection and\n        compression in logistic regression context: logit-SPLS; and\n        an adaptive version of the sparse PLS.",
    "version": "1.5-3",
    "maintainer": "Ghislain Durif <gd.dev@libertymail.net>",
    "url": "https://github.com/gdurif/plsgenomics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19883,
    "package_name": "plusCode2",
    "title": "Coordinates to 'Plus Code' Conversion Tool",
    "description": "Generates 'Plus Code' of geometric objects or data frames that contain them, giving the possibility to specify the precision of the area. The main feature of the package comes from the open-source code developed by 'Google Inc.' present in the repository <https://github.com/google/open-location-code/blob/main/java/src/main/java/com/google/openlocationcode/OpenLocationCode.java>. For details about 'Plus Code', visit <https://maps.google.com/pluscodes/> or <https://github.com/google/open-location-code>.",
    "version": "0.1.0",
    "maintainer": "Armando d'Aniello <armando.daniello@istat.it>",
    "url": "https://github.com/Armando-d/plusCode2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19887,
    "package_name": "plyr",
    "title": "Tools for Splitting, Applying and Combining Data",
    "description": "A set of tools that solves a common set of problems: you need\n    to break a big problem down into manageable pieces, operate on each\n    piece and then put all the pieces back together.  For example, you\n    might want to fit a model to each spatial location or time point in\n    your study, summarise data by panels or collapse high-dimensional\n    arrays to simpler summary statistics. The development of 'plyr' has\n    been generously supported by 'Becton Dickinson'.",
    "version": "1.8.9",
    "maintainer": "Hadley Wickham <hadley@rstudio.com>",
    "url": "http://had.co.nz/plyr, https://github.com/hadley/plyr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19929,
    "package_name": "pogit",
    "title": "Bayesian Variable Selection for a Poisson-Logistic Model",
    "description": "Bayesian variable selection for regression models of under-reported\n    count data as well as for (overdispersed) Poisson, negative binomal and\n    binomial logit regression models using spike and slab priors.",
    "version": "1.3.0",
    "maintainer": "Michaela Dvorzak <m.dvorzak@gmx.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19935,
    "package_name": "pointdensityP",
    "title": "Point Density for Geospatial Data",
    "description": "The function pointdensity returns a density count and the temporal average for\n    every point in the original list. The dataframe returned includes four\n    columns: lat, lon, count, and date_avg. The \"lat\" column is the original\n    latitude data; the \"lon\" column is the original longitude data; the \"count\"\n    is the density count of the number of points within a radius of\n    radius*grid_size (the neighborhood); and the date_avg column includes the\n    average date of each point in the neighborhood.",
    "version": "0.3.5",
    "maintainer": "Paul Evangelista <paul.evangelista@westpoint.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19936,
    "package_name": "pointdexter",
    "title": "Labels Points Inside Polygons",
    "description": "Labels longitudinal and latitudinal coordinates located inside a polygon.",
    "version": "0.1.1",
    "maintainer": "Cristian E. Nuno <cenuno@syr.edu>",
    "url": "https://github.com/cenuno/pointdexter",
    "exports": [],
    "topics": ["points", "polygon", "polygons", "r", "spatial-analysis", "spatial-statistics"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 19964,
    "package_name": "polyCub",
    "title": "Cubature over Polygonal Domains",
    "description": "Numerical integration of continuously differentiable\n    functions f(x,y) over simple closed polygonal domains.\n    The following cubature methods are implemented:\n    product Gauss cubature (Sommariva and Vianello, 2007,\n    <doi:10.1007/s10543-007-0131-2>),\n    the simple two-dimensional midpoint rule\n    (wrapping 'spatstat.geom' functions), and\n    adaptive cubature for radially symmetric functions via line\n    integrate() along the polygon boundary (Meyer and Held, 2014,\n    <doi:10.1214/14-AOAS743>, Supplement B).\n    For simple integration along the axes, the 'cubature' package\n    is more appropriate.",
    "version": "0.9.2",
    "maintainer": "Sebastian Meyer <seb.meyer@fau.de>",
    "url": "https://github.com/bastistician/polyCub",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19971,
    "package_name": "polyclip",
    "title": "Polygon Clipping",
    "description": "R port of Angus Johnson's open source library 'Clipper'. Performs polygon clipping operations (intersection, union, set minus, set difference) for polygonal regions of arbitrary complexity, including holes. Computes offset polygons (spatial buffer zones, morphological dilations, Minkowski dilations) for polygonal regions and polygonal lines. Computes Minkowski Sum of general polygons. There is a function for removing self-intersections from polygon data.",
    "version": "1.10-7",
    "maintainer": "Adrian Baddeley <Adrian.Baddeley@curtin.edu.au>",
    "url": "https://www.angusj.com,\nhttps://sourceforge.net/projects/polyclipping,\nhttps://github.com/baddstats/polyclip",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19976,
    "package_name": "polylabelr",
    "title": "Find the Pole of Inaccessibility (Visual Center) of a Polygon",
    "description": "A wrapper around the C++ library 'polylabel' from 'Mapbox',\n    providing an efficient routine for finding the approximate pole of\n    inaccessibility of a polygon, which usually serves as an excellent candidate\n    for labeling of a polygon.",
    "version": "0.3.0",
    "maintainer": "Johan Larsson <johanlarsson@outlook.com>",
    "url": "https://github.com/jolars/polylabelr,\nhttps://jolars.github.io/polylabelr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19986,
    "package_name": "pomcheckr",
    "title": "Graphical Check for Proportional Odds Assumption",
    "description": "Implements the method described at the UCLA Statistical\n    Consulting site <https://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/>\n    for checking if the proportional odds assumption holds for a \n    cumulative logit model.",
    "version": "0.1.1",
    "maintainer": "Melissa Wong <melissa.wong.stats@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 19989,
    "package_name": "pomodoro",
    "title": "Predictive Power of Linear and Tree Modeling",
    "description": "Runs generalized and multinominal logistic (GLM and MLM) models, as well as random forest (RF), Bagging (BAG), and Boosting (BOOST). This package prints out to predictive outcomes easy for the selected data and data splits.",
    "version": "3.8.0",
    "maintainer": "Seyma Kalay <seymakalay@hotmail.com>",
    "url": "https://github.com/seymakalay/pomodoro,\nhttps://seymakalay.github.io/pomodoro/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20021,
    "package_name": "populR",
    "title": "Population Downscaling Using Areal Interpolation",
    "description": "Given a \n    set of source zone polygons such as\n    census tracts or city blocks alongside with population counts and a \n    target zone of incogruent yet superimposed polygon features (such as\n    individual buildings) populR transforms population counts from the \n    former to the latter using Areal Interpolation methods.",
    "version": "0.2.1",
    "maintainer": "Marios Batsaris <m.batsaris@aegean.gr>",
    "url": "https://github.com/mbatsaris/populR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20069,
    "package_name": "powerMediation",
    "title": "Power/Sample Size Calculation for Mediation Analysis",
    "description": "Functions to \n        calculate power and sample size for testing\n        (1) mediation effects; \n        (2) the slope in a simple linear regression; \n        (3) odds ratio in a simple logistic regression;\n        (4) mean change for longitudinal study with 2 time points;\n        (5) interaction effect in 2-way ANOVA; and\n        (6) the slope in a simple Poisson regression.",
    "version": "0.3.4",
    "maintainer": "Weiliang Qiu <weiliang.qiu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20086,
    "package_name": "ppcSpatial",
    "title": "Spatial Analysis of Pakistan Population Census",
    "description": "Spatial Analysis for exploration of Pakistan Population Census 2017 (<https://www.pbs.gov.pk/content/population-census>). It uses data from R package 'PakPC2017'.",
    "version": "0.3.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "url": "https://github.com/MYaseen208/ppcSpatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20087,
    "package_name": "ppcc",
    "title": "Probability Plot Correlation Coefficient Test",
    "description": "Calculates the Probability Plot Correlation Coefficient (PPCC) \n             between a continuous variable X and a specified distribution. The corresponding \n\t     composite hypothesis test that was first introduced by \n\t     Filliben (1975) <doi: 10.1080/00401706.1975.10489279> \n\t     can be performed to test whether the sample \n\t     X is element of either the Normal, log-Normal, Exponential,\n\t     Uniform, Cauchy, Logistic, Generalized Logistic, Gumbel (GEVI), Weibull,\n\t     Generalized Extreme Value, Pearson III (Gamma 2), Mielke's Kappa, Rayleigh\n\t     or Generalized Logistic Distribution. The PPCC test is performed with\n\t     a fast Monte-Carlo simulation.",
    "version": "1.3",
    "maintainer": "Thorsten Pohlert <thorsten.pohlert@gmx.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20101,
    "package_name": "ppmSuite",
    "title": "A Collection of Models that Employ Product Partition\nDistributions as a Prior on Partitions",
    "description": "Provides a suite of functions that fit models that use PPM type priors for partitions.\n                Models include hierarchical Gaussian and probit ordinal models with  a (covariate \n                dependent) PPM.  If a covariate dependent product partition model is selected, \n                then all the options detailed in Page, G.L.; Quintana, F.A. (2018) \n                <doi:10.1007/s11222-017-9777-z> are available.  If covariate values are missing, \n                then the approach detailed in Page, G.L.; Quintana, F.A.; Mueller, P (2020) \n                <doi:10.1080/10618600.2021.1999824> is employed.   Also included in the package is \n                a function that fits a Gaussian likelihood spatial product  partition model that is \n                detailed in Page, G.L.; Quintana, F.A. (2016)  <doi:10.1214/15-BA971>, and \n                multivariate PPM change point models that are detailed in Quinlan, J.J.; Page, G.L.; \n                Castro, L.M. (2023) <doi:10.1214/22-BA1344>. In addition, a function that fits a \n                univariate or bivariate functional data model that employs a PPM or a PPMx to \n                cluster curves based on B-spline coefficients is provided.",
    "version": "0.3.4",
    "maintainer": "Garritt L. Page <page@stat.byu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20116,
    "package_name": "prabclus",
    "title": "Functions for Clustering and Testing of Presence-Absence,\nAbundance and Multilocus Genetic Data",
    "description": "Distance-based parametric bootstrap tests for clustering with \n  spatial neighborhood information. Some distance measures, \n  Clustering of presence-absence, abundance and multilocus genetic data \n  for species delimitation, nearest neighbor \n  based noise detection. Genetic distances between communities.\n  Tests whether various distance-based regressions\n  are equal. Try package?prabclus for on overview. ",
    "version": "2.3-4",
    "maintainer": "Christian Hennig <christian.hennig@unibo.it>",
    "url": "https://www.unibo.it/sitoweb/christian.hennig/en/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20119,
    "package_name": "practicalSigni",
    "title": "Practical Significance Ranking of Regressors and Exact t Density",
    "description": "Consider a possibly nonlinear nonparametric regression\n   with p regressors. We provide evaluations by 13 methods to rank\n   regressors by their practical significance or importance using \n   various methods, including machine learning tools. Comprehensive\n   methods are as follows. \n   m6=Generalized partial correlation coefficient or\n   GPCC by Vinod (2021)<doi:10.1007/s10614-021-10190-x> and\n   Vinod (2022)<https://www.mdpi.com/1911-8074/15/1/32>.\n   m7= a generalization of psychologists' effect size incorporating \n   nonlinearity and many variables.\n   m8= local linear partial (dy/dxi) using the 'np' package for kernel \n   regressions.\n   m9= partial (dy/dxi) using the 'NNS' package.\n   m10= importance measure using the 'NNS' boost function.\n   m11= Shapley Value measure of importance (cooperative game theory).\n   m12 and m13= two versions of the random forest algorithm.\n   Taraldsen's exact density for sampling distribution of correlations added.",
    "version": "0.1.2",
    "maintainer": "Hrishikesh Vinod <vinod@fordham.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20152,
    "package_name": "predictsr",
    "title": "Access the 'PREDICTS' Biodiversity Database",
    "description": "Fetches the 'PREDICTS' database and relevant metadata from the Data\n    Portal at the Natural History Museum, London <https://data.nhm.ac.uk>. Data\n    were collated from over 400 existing spatial comparisons of local-scale\n    biodiversity exposed to different intensities and types of anthropogenic\n    pressures, from sites around the world. These data are described in Hudson\n    et al. (2013) <doi:10.1002/ece3.2579>.",
    "version": "0.2.0",
    "maintainer": "Connor Duffin <connor.p.duffin@gmail.com>",
    "url": "https://biodiversity-futures-lab.github.io/predictsr/,\nhttps://github.com/Biodiversity-Futures-Lab/predictsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20171,
    "package_name": "prereg",
    "title": "R Markdown Templates to Preregister Scientific Studies",
    "description": "Provides a collection of templates to author preregistration documents for scientific studies in PDF format.",
    "version": "0.6.0",
    "maintainer": "Frederik Aust <frederik.aust@uni-koeln.de>",
    "url": "https://github.com/crsh/prereg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20172,
    "package_name": "preregr",
    "title": "Specify (Pre)Registrations and Export Them Human- And\nMachine-Readably",
    "description": "Preregistrations, or more generally, registrations, enable\n    explicit timestamped and (often but not necessarily publicly) frozen\n    documentation of plans and expectations as well as decisions and\n    justifications. In research, preregistrations are commonly used to\n    clearly document plans and facilitate justifications of deviations from\n    those plans, as well as decreasing the effects of publication bias by\n    enabling identification of research that was conducted but not published.\n    Like reporting guidelines, (pre)registration forms often have specific\n    structures that facilitate systematic reporting of important items. The\n    'preregr' package facilitates specifying (pre)registrations in R and\n    exporting them to a human-readable format (using R Markdown partials or\n    exporting to an 'HTML' file) as well as human-readable embedded data\n    (using 'JSON'), as well as importing such exported (pre)registration\n    specifications from such embedded 'JSON'.",
    "version": "0.2.9",
    "maintainer": "Gjalt-Jorn Peters <preregr@opens.science>",
    "url": "https://preregr.opens.science",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20176,
    "package_name": "presentes",
    "title": "Registry of Victims of State Terrorism in Argentina",
    "description": "Compilation and digitalization of the official registry of victims of state terrorism in Argentina during the last\n             military coup. The original data comes from RUVTE-ILID (2019) <https://www.argentina.gob.ar/sitiosdememoria/ruvte/informe> and <http://basededatos.parquedelamemoria.org.ar/registros/>. The title, presentes, comes from present in spanish.",
    "version": "0.1.0",
    "maintainer": "Diego Kozlowski <diegokoz92@gmail.com>",
    "url": "https://diegokoz.github.io/presentes/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20217,
    "package_name": "priorCON",
    "title": "Graph Community Detection Methods into Systematic Conservation\nPlanning",
    "description": "An innovative tool-set that incorporates graph community detection\n             methods into systematic conservation planning. It is designed to\n             enhance spatial prioritization by focusing on the protection of\n             areas with high ecological connectivity. Unlike traditional\n             approaches that prioritize individual planning units, 'priorCON'\n             focuses on clusters of features that exhibit strong ecological\n             linkages. The 'priorCON' package is built upon the 'prioritizr'\n             package <doi:10.32614/CRAN.package.prioritizr>, using commercial\n             and open-source exact algorithm solvers that ensure optimal\n             solutions to prioritization problems.",
    "version": "0.1.7",
    "maintainer": "Christos Adam <econp266@econ.soc.uoc.gr>",
    "url": "https://github.com/cadam00/priorCON,\nhttps://cadam00.github.io/priorCON/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20219,
    "package_name": "prioritizr",
    "title": "Systematic Conservation Prioritization in R",
    "description": "\n    Systematic conservation prioritization using mixed integer linear\n    programming (MILP). It provides a flexible interface for building and\n    solving conservation planning problems. Once built, conservation planning\n    problems can be solved using a variety of commercial and open-source exact\n    algorithm solvers. By using exact algorithm solvers, solutions can be\n    generated that are guaranteed to be optimal (or within a pre-specified\n    optimality gap). Furthermore, conservation problems can be constructed to\n    optimize the spatial allocation of different management actions or zones,\n    meaning that conservation practitioners can identify solutions that benefit\n    multiple stakeholders. To solve large-scale or complex conservation\n    planning problems, users should install the Gurobi optimization software\n    (available from <https://www.gurobi.com/>) and the 'gurobi' R package (see\n    Gurobi Installation Guide vignette for details). Users can also install the\n    IBM CPLEX software (<https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer>) and\n    the 'cplexAPI' R package (available at <https://github.com/cran/cplexAPI>).\n    Additionally, the 'rcbc' R package (available at\n    <https://github.com/dirkschumacher/rcbc>) can be used to generate solutions\n    using the CBC optimization software (<https://github.com/coin-or/Cbc>). For\n    further details, see Hanson et al. (2025) <doi:10.1111/cobi.14376>.",
    "version": "8.1.0",
    "maintainer": "Richard Schuster <richard.schuster@glel.carleton.ca>",
    "url": "https://prioritizr.net, https://github.com/prioritizr/prioritizr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20252,
    "package_name": "procmaps",
    "title": "Portable Address Space Mapping",
    "description": "Portable '/proc/self/maps' as a data frame.\n    Determine which library or other region is mapped to a specific\n    address of a process. --\n    R packages can contain native code, compiled to shared libraries at build or\n    installation time.\n    When loaded, each shared library occupies a portion of the address space of\n    the main process.\n    When only a machine instruction pointer is available (e.g. from a backtrace\n    during error inspection or profiling), the address space map determines\n    which library this instruction pointer corresponds to.",
    "version": "0.0.5",
    "maintainer": "Kirill Müller <kirill@cynkra.com>",
    "url": "https://r-prof.github.io/procmaps/,\nhttps://github.com/r-prof/procmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20277,
    "package_name": "proj4",
    "title": "A simple interface to the PROJ.4 cartographic projections\nlibrary",
    "description": "A simple interface to lat/long projection and datum\n\t     transformation of the PROJ.4 cartographic projections library. It\n\t     allows transformation of geographic coordinates from one projection\n\t     and/or datum to another.",
    "version": "1.0-15",
    "maintainer": "Simon Urbanek <simon.urbanek@r-project.org>",
    "url": "https://www.rforge.net/proj4/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20304,
    "package_name": "proporz",
    "title": "Proportional Apportionment",
    "description": "Calculate seat apportionment for legislative bodies with \n    various methods. The algorithms include divisor or highest averages methods\n    (e.g. Jefferson, Webster or Adams), largest remainder methods and \n    biproportional apportionment.\n    Gaffke, N. & Pukelsheim, F. (2008) <doi:10.1016/j.mathsocsci.2008.01.004>\n    Oelbermann, K. F. (2016) <doi:10.1016/j.mathsocsci.2016.02.003>.",
    "version": "1.5.2",
    "maintainer": "Flavio Poletti <flavio.poletti@hotmail.ch>",
    "url": "https://polettif.github.io/proporz/,\nhttps://github.com/polettif/proporz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20334,
    "package_name": "proxirr",
    "title": "Alpha, Beta and Gamma Proximity to Irreplaceability",
    "description": "Functions to measure Alpha, Beta and Gamma Proximity to Irreplaceability.\n  The methods for Alpha and Beta irreplaceability were first described in:\n    Baisero D., Schuster R. & Plumptre A.J.\n    Redefining and Mapping Global Irreplaceability.\n    Conservation Biology 2021;1-11.\n    <doi:10.1111/cobi.13806>.",
    "version": "0.5",
    "maintainer": "Daniele Baisero <daniele.baisero@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20342,
    "package_name": "pruatlas",
    "title": "The Atlas and Utilities for PRU Maps",
    "description": "A set of utilities for creation of map as used in",
    "version": "0.0.3.4",
    "maintainer": "Enrico Spinielli <enrico.spinielli@eurocontrol.int>",
    "url": "https://github.com/euctrl-pru/pruatlas",
    "exports": [],
    "topics": ["aviation", "gis", "r", "spatial"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 20346,
    "package_name": "psHarmonize",
    "title": "Creates a Harmonized Dataset Based on a Set of Instructions",
    "description": "Functions which facilitate harmonization of data from multiple\n    different datasets. Data harmonization involves taking data sources with\n    differing values, creating coding instructions to create a harmonized\n    set of values, then making those data modifications. 'psHarmonize' will\n    assist with data modification once the harmonization instructions are\n    written. Coding instructions are written by the user to create a\n    \"harmonization sheet\". This sheet catalogs variable names, domains\n    (e.g. clinical, behavioral, outcomes), provides R code instructions for\n    mapping or conversion of data, specifies the variable name in the\n    harmonized data set, and tracks notes. The package will then harmonize\n    the source datasets according to the harmonization sheet to create a\n    harmonized dataset. Once harmonization is finished, the package also has\n    functions that will create descriptive statistics using 'RMarkdown'. Data\n    Harmonization guidelines have been described by Fortier I, Raina P,\n    Van den Heuvel ER, et al. (2017) <doi:10.1093/ije/dyw075>. Additional\n    details of our R package have been described by Stephen JJ, Carolan P,\n    Krefman AE, et al. (2024) <doi:10.1016/j.patter.2024.101003>.",
    "version": "0.3.6",
    "maintainer": "John Stephen <John.Stephen@northwestern.edu>",
    "url": "https://github.com/NUDACC/psHarmonize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20358,
    "package_name": "pseudobibeR",
    "title": "Aggregate Counts of Linguistic Features",
    "description": "Calculates the lexicogrammatical and functional features described\n  by Biber (1985) <doi:10.1515/ling.1985.23.2.337> and widely used for\n  text-type, register, and genre classification tasks.",
    "version": "1.2",
    "maintainer": "David Brown <dwb2@andrew.cmu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20363,
    "package_name": "psgp",
    "title": "Projected Spatial Gaussian Process Methods",
    "description": "Implements projected sparse Gaussian process Kriging ('Ingram et. al.', 2008, <doi:10.1007/s00477-007-0163-9>) as an additional method for the 'intamap' package. More details on implementation ('Barillec et. al.', 2010, <doi:10.1016/j.cageo.2010.05.008>).",
    "version": "0.3-25",
    "maintainer": "Ben Ingram <ingrambr.work@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20374,
    "package_name": "pspatreg",
    "title": "Spatial and Spatio-Temporal Semiparametric Regression Models\nwith Spatial Lags",
    "description": "Estimation and inference of spatial and spatio-temporal \n    semiparametric models including spatial or spatio-temporal non-parametric \n    trends, parametric and non-parametric covariates and, possibly, a spatial \n    lag for the dependent variable and temporal correlation in the noise.\n    The spatio-temporal trend can be decomposed in ANOVA way including main and \n    interaction functional terms. Use of SAP algorithm to estimate the spatial \n    or spatio-temporal trend and non-parametric covariates. The methodology of \n    these models can be found in next references\n    Basile, R. et al. (2014), <doi:10.1016/j.jedc.2014.06.011>;\n    Rodriguez-Alvarez, M.X. et al. (2015) <doi:10.1007/s11222-014-9464-2> and,\n    particularly referred to the focus of the package, Minguez, R., \n    Basile, R. and Durban, M. (2020) <doi:10.1007/s10260-019-00492-8>.",
    "version": "1.1.2",
    "maintainer": "Roman Minguez <roman.minguez@uclm.es>",
    "url": "https://github.com/rominsal/pspatreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20377,
    "package_name": "pspm",
    "title": "Probabilistic Spatial Partition Model",
    "description": "Estimation and simulation of probabilistic spatial partition models.",
    "version": "1.0",
    "maintainer": "Carl Muller-Crepon <c.a.muller-crepon@lse.ac.uk>",
    "url": "https://github.com/carl-mc/pspm",
    "exports": [],
    "topics": ["igraph", "partitioning", "partitions", "r-spatial", "rstats", "spatial", "spatial-analysis", "spatial-data-analysis"],
    "score": "NA",
    "stars": 1
  },
  {
    "id": 20394,
    "package_name": "psychotools",
    "title": "Psychometric Modeling Infrastructure",
    "description": "Infrastructure for psychometric modeling such as data classes (for\n  item response data and paired comparisons), basic model fitting functions (for\n  Bradley-Terry, Rasch, parametric logistic IRT, generalized partial credit,\n  rating scale, multinomial processing tree models), extractor functions for\n  different types of parameters (item, person, threshold, discrimination,\n  guessing, upper asymptotes), unified inference and visualizations, and various\n  datasets for illustration.  Intended as a common lightweight and efficient\n  toolbox for psychometric modeling and a common building block for fitting\n  psychometric mixture models in package \"psychomix\" and trees based on\n  psychometric models in package \"psychotree\".",
    "version": "0.7-5",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20405,
    "package_name": "ptinpoly",
    "title": "Point-in-Polyhedron Test (2D and 3D)",
    "description": "Function pip3d() tests whether a point in 3D space is\n  within, exactly on, or outside an enclosed surface defined by a triangular mesh.\n  Function pip2d() tests whether a point in 2D space is within, exactly on, or outside a polygon.\n  For a reference, see: Liu et al., A new point containment test algorithm based on preprocessing\n  and determining triangles, Computer-Aided Design 42(12):1143-1150.",
    "version": "2.8",
    "maintainer": "Jose M. Maisog <bravas02@gmail.com>",
    "url": "http://ptinpoly.pbworks.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20408,
    "package_name": "ptools",
    "title": "Tools for Poisson Data",
    "description": "Functions used for analyzing count data, mostly crime counts. Includes checking difference in two Poisson counts (e-test), checking the fit for a Poisson distribution, small sample tests for counts in bins, Weighted Displacement Difference test (Wheeler and Ratcliffe, 2018) <doi:10.1186/s40163-018-0085-5>, to evaluate crime changes over time in treated/control areas. Additionally includes functions for aggregating spatial data and spatial feature engineering.",
    "version": "2.0.0",
    "maintainer": "Andrew Wheeler <apwheele@gmail.com>",
    "url": "https://github.com/apwheele/ptools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20426,
    "package_name": "puff",
    "title": "Simulate and Visualize the Gaussian Puff Forward Atmospheric\nModel",
    "description": "Simulate and run the Gaussian puff forward atmospheric\n    model in sensor (specific sensor coordinates) or grid (across the\n    grid of a full oil and gas operations site) modes, following Jia, M., \n    Fish, R., Daniels, W., Sprinkle, B. and Hammerling, D. (2024) \n    <doi:10.26434/chemrxiv-2023-hc95q-v3>. Numerous visualization options, \n    including static and animated, 2D and 3D, and a site map generator \n    based on sensor and source coordinates.",
    "version": "0.1.0",
    "maintainer": "Philip Waggoner <philip.waggoner@mines.edu>",
    "url": "https://github.com/Hammerling-Research-Group/puff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20443,
    "package_name": "putior",
    "title": "\"Register In- and Outputs for Workflow Visualization\"",
    "description": "Provides tools for extracting and processing structured annotations from 'R' \n    and 'Python' source files to facilitate workflow visualization. The package scans \n    source files for special 'PUT' annotations that define nodes, connections, and \n    metadata within a data processing workflow. These annotations can then be used \n    to generate visual representations of data flows and processing steps across \n    polyglot software environments. Builds on concepts from literate programming \n    Knuth (1984) <doi:10.1093/comjnl/27.2.97> and utilizes directed acyclic graph (DAG) \n    theory for workflow representation Foraita, Spallek, and Zeeb (2014) \n    <doi:10.1007/978-0-387-09834-0_65>. Diagram generation powered by 'Mermaid' \n    Sveidqvist (2014) <https://mermaid.js.org/>.",
    "version": "0.1.0",
    "maintainer": "Philipp Thoss <ph.thoss@gmx.de>",
    "url": "https://pjt222.github.io/putior/, https://github.com/pjt222/putior",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20452,
    "package_name": "pvclass",
    "title": "P-Values for Classification",
    "description": "Computes nonparametric p-values for the potential class\n        memberships of new observations as well as cross-validated\n        p-values for the training data. The p-values are based on\n        permutation tests applied to an estimated Bayesian likelihood\n        ratio, using a plug-in statistic for the Gaussian model, 'k\n        nearest neighbors', 'weighted nearest neighbors' or\n        'penalized logistic regression'.\n        Additionally, it provides graphical displays and quantitative\n        analyses of the p-values.",
    "version": "1.4.1",
    "maintainer": "Niki Zumbrunnen <niki.zumbrunnen@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20463,
    "package_name": "pwr2ppl",
    "title": "Power Analyses for Common Designs (Power to the People)",
    "description": "Statistical power analysis for designs including t-tests, correlations, \n    multiple regression, ANOVA, mediation, and logistic regression. Functions accompany \n    Aberson (2019) <doi:10.4324/9781315171500>.",
    "version": "0.5.0",
    "maintainer": "Chris Aberson <chris.aberson@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20478,
    "package_name": "pycno",
    "title": "Pycnophylactic Interpolation",
    "description": "Given a SpatialPolygonsDataFrame and a set of populations for each polygon,\n compute a population density estimate based on Tobler's pycnophylactic interpolation\n algorithm. The result is a SpatialGridDataFrame. \n Methods are described in Tobler Waldo R. (1979) <doi:10.1080/01621459.1979.10481647>.",
    "version": "1.4.1",
    "maintainer": "Francesca Bitonti <francesca.bitonti@unict.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20487,
    "package_name": "qMRI",
    "title": "Methods for Quantitative Magnetic Resonance Imaging ('qMRI')",
    "description": "Implementation of methods for estimation of quantitative maps\n    from Multi-Parameter Mapping (MPM) acquisitions (Weiskopf et al. (2013)\n    <doi:10.3389/fnins.2013.00095>) and analysis of Inversion Recovery MRI data.\n    Usage of the package is described in\n    Polzehl and Tabelow (2023),\n    \"Magnetic Resonance Brain Imaging\", 2nd Edition, Chapter 6 and 7, Springer, Use R! Series.\n    <doi:10.1007/978-3-031-38949-8>.\n    J. Polzehl and K. Tabelow (2023), \"Magnetic Resonance Brain Imaging - Modeling and Data Analysis Using R: Code and Data.\"\n    <doi:10.20347/WIAS.DATA.6> provides extensive example code and data.",
    "version": "1.2.7.9",
    "maintainer": "Karsten Tabelow <karsten.tabelow@wias-berlin.de>",
    "url": "https://www.wias-berlin.de/research/ats/imaging/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20537,
    "package_name": "qkerntool",
    "title": "Q-Kernel-Based and Conditionally Negative Definite Kernel-Based\nMachine Learning Tools",
    "description": "Nonlinear machine learning tool for classification, clustering\n        and dimensionality reduction. It integrates 12 q-kernel functions and\n        15 conditional negative definite kernel functions and includes the \n        q-kernel and conditional negative definite kernel version of\n        density-based spatial clustering of applications with noise,\n        spectral clustering, generalized discriminant analysis, principal\n        component analysis, multidimensional scaling, locally linear embedding,\n        sammon's mapping and t-Distributed stochastic neighbor embedding.",
    "version": "1.19",
    "maintainer": "Yusen Zhang <yusenzhang@126.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20542,
    "package_name": "qmap",
    "title": "Statistical Transformations for Post-Processing Climate Model\nOutput",
    "description": "Empirical adjustment of the distribution of variables originating from (regional) climate model simulations using quantile mapping.",
    "version": "1.0-6",
    "maintainer": "Lukas Gudmundsson <lukas.gudmundsson@env.ethz.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20594,
    "package_name": "qtl2",
    "title": "Quantitative Trait Locus Mapping in Experimental Crosses",
    "description": "Provides a set of tools to perform quantitative\n    trait locus (QTL) analysis in experimental crosses. It is a\n    reimplementation of the 'R/qtl' package to better handle\n    high-dimensional data and complex cross designs.\n    Broman et al. (2019) <doi:10.1534/genetics.118.301595>.",
    "version": "0.38",
    "maintainer": "Karl W Broman <broman@wisc.edu>",
    "url": "https://kbroman.org/qtl2/, https://github.com/rqtl/qtl2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20595,
    "package_name": "qtl2convert",
    "title": "Convert Data among QTL Mapping Packages",
    "description": "Functions to convert data structures among the 'qtl2', 'qtl', and 'DOQTL' packages for mapping quantitative trait loci (QTL).",
    "version": "0.30",
    "maintainer": "Karl W Broman <broman@wisc.edu>",
    "url": "https://kbroman.org/qtl2/, https://github.com/rqtl/qtl2convert",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20596,
    "package_name": "qtl2fst",
    "title": "Database Storage of Genotype Probabilities for QTL Mapping",
    "description": "Uses the 'fst' package to store genotype probabilities on disk for the 'qtl2' package. These genotype probabilities are a central data object for mapping quantitative trait loci (QTL), but they can be quite large. The facilities in this package enable the genotype probabilities to be stored on disk, leading to reduced memory usage with only a modest increase in computation time.",
    "version": "0.30",
    "maintainer": "Karl W Broman <broman@wisc.edu>",
    "url": "https://github.com/rqtl/qtl2fst",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20598,
    "package_name": "qtl2pattern",
    "title": "Pattern Support for 'qtl2' Package",
    "description": "Routines in 'qtl2' to study allele patterns in quantitative trait loci (QTL)\n    mapping over a chromosome.\n    Useful in crosses with more than two alleles to identify how sets of alleles,\n    genetically different strands at the same locus, have different response levels.\n    Plots show profiles over a chromosome.\n    Can handle multiple traits together.\n    See <https://github.com/byandell/qtl2pattern>.",
    "version": "1.2.1",
    "maintainer": "Brian S Yandell <brian.yandell@wisc.edu>",
    "url": "https://github.com/byandell/qtl2pattern",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20601,
    "package_name": "qtlbook",
    "title": "Datasets for the R/qtl Book",
    "description": "Datasets for the book, A Guide to QTL Mapping with R/qtl.\n    Broman and Sen (2009) <doi:10.1007/978-0-387-92125-9>.",
    "version": "0.20",
    "maintainer": "Karl W Broman <broman@wisc.edu>",
    "url": "https://rqtl.org/book/, https://github.com/kbroman/qtlbook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20613,
    "package_name": "quadmesh",
    "title": "Quadrangle Mesh",
    "description": "Create surface forms from matrix or 'raster' data for flexible plotting and\n conversion to other mesh types. The functions 'quadmesh' or 'triangmesh'\n produce a continuous surface as a 'mesh3d' object as used by the 'rgl'\n package. This is used for plotting raster data in 3D (optionally with\n texture), and allows the application of a map projection without data loss and \n many processing applications that are restricted by inflexible regular grid rasters.\n There are discrete forms of these continuous surfaces available with\n 'dquadmesh' and 'dtriangmesh' functions.",
    "version": "0.5.5",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/quadmesh",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20618,
    "package_name": "quadtree",
    "title": "Region Quadtrees for Spatial Data",
    "description": "Provides functionality for working with raster-like quadtrees\n    (also called “region quadtrees”), which allow for variable-sized\n    cells. The package allows for flexibility in the quadtree creation\n    process.  Several functions defining how to split and aggregate cells\n    are provided, and custom functions can be written for both of these\n    processes. In addition, quadtrees can be created using other quadtrees\n    as “templates”, so that the new quadtree's structure is identical to\n    the template quadtree. The package also includes functionality for\n    modifying quadtrees, querying values, saving quadtrees to a file, and\n    calculating least-cost paths using the quadtree as a resistance\n    surface.",
    "version": "0.1.14",
    "maintainer": "Derek Friend <dafriend.R@gmail.com>",
    "url": "https://github.com/dfriend21/quadtree/,\nhttps://dfriend21.github.io/quadtree/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20661,
    "package_name": "quaxnat",
    "title": "Estimation of Natural Regeneration Potential",
    "description": "Functions for estimating the potential dispersal of tree species \n  using regeneration densities and dispersal distances to nearest seed trees. \n  A quantile regression is implemented to determine the dispersal potential.\n  Spatial prediction can be used to identify natural regeneration potential for forest restoration as described in Axer et al (2021) <doi:10.1016/j.foreco.2020.118802>.",
    "version": "1.0.1",
    "maintainer": "Maximilian Axer <maximilian.axer@nw-fva.de>",
    "url": "https://github.com/MaximilianAxer/quaxnat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20678,
    "package_name": "quickglobe",
    "title": "Create Interative 3D Globes",
    "description": "Create and style interactive, 3-D, chloropleth globes.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/daranzolin/quickglobe",
    "exports": [],
    "topics": ["gis", "globe", "htmlwidget", "htmlwidgets", "rstats"],
    "score": "NA",
    "stars": 23
  },
  {
    "id": 20680,
    "package_name": "quickpsy",
    "title": "Fits Psychometric Functions for Multiple Groups",
    "description": "Quickly fits and plots psychometric functions (normal, logistic,\n    Weibull or any or any function defined by the user) for multiple groups.",
    "version": "0.1.5.1",
    "maintainer": "Linares Daniel <danilinares@gmail.com>",
    "url": "http://dlinares.org/quickpsy.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20773,
    "package_name": "rFIA",
    "title": "Estimation of Forest Variables using the FIA Database",
    "description": "The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted and model-based estimators to improve population, change, and ratio estimates.",
    "version": "1.1.2",
    "maintainer": "Jeffrey Doser <jwdoser@ncsu.edu>",
    "url": "https://github.com/doserjef/rFIA,\nhttps://www.doserlab.com/files/rFIA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20785,
    "package_name": "rIntervalTree",
    "title": "An Interval Tree Tool for Real Numbers",
    "description": "This tool can be used to build binary interval trees using real number inputs. \n    The tree supports queries of intervals overlapping a single number or an interval (start, end). \n    Intervals with same bounds but different names are treated as distinct intervals. \n    Insertion of intervals is also allowed. Deletion of intervals is not implemented at this point.\n    See  Mark de Berg, Otfried Cheong, Marc van Kreveld, Mark Overmars (2008). Computational Geometry: Algorithms and Applications, for a reference.",
    "version": "0.1.0",
    "maintainer": "Shuye Pu <shuye2009@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20786,
    "package_name": "rIsing",
    "title": "High-Dimensional Ising Model Selection",
    "description": "Fits an Ising model to a binary dataset using L1 regularized\n    logistic regression and extended BIC. Also includes a fast lasso logistic\n    regression function for high-dimensional problems. Uses the 'libLBFGS'\n    optimization library by Naoaki Okazaki.",
    "version": "0.1.0",
    "maintainer": "Pratik Ramprasad <pratik.ramprasad@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20789,
    "package_name": "rKIN",
    "title": "(Kernel) Isotope Niche Estimation",
    "description": "Applies methods used to estimate animal homerange, but\n    instead of geospatial coordinates, we use isotopic coordinates. The estimation\n    methods include: 1) 2-dimensional bivariate normal kernel utilization density\n    estimator, 2) bivariate normal ellipse estimator, and 3) minimum convex polygon\n    estimator, all applied to stable isotope data. Additionally, functions to\n    determine niche area, polygon overlap between groups and levels (confidence\n    contours) and plotting capabilities.",
    "version": "1.0.4",
    "maintainer": "Shannon E Albeke <salbeke@uwyo.edu>",
    "url": "https://github.com/salbeke/rKIN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20824,
    "package_name": "rSDI",
    "title": "Spatial Dispersion Index (SDI) Family of Metrics for\nSpatial/Geographic Networks",
    "description": "Spatial Dispersion Index (SDI) is a generalized measurement index, or rather a family of indices to evaluate spatial dispersion of movements/flows in a network in a problem neutral way as described in: Gencer (2023) <doi:10.1007/s12061-023-09545-8>. This package computes and optionally visualizes this index with minimal hassle.",
    "version": "0.2.2",
    "maintainer": "Mehmet Gençer <mehmetgencer@yahoo.com>",
    "url": "https://github.com/ehengirmen/rSDI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20859,
    "package_name": "radar",
    "title": "Fundamental Formulas for Radar",
    "description": "Fundamental formulas for Radar, for attenuation, range, velocity,\n    effectiveness, power, scatter, doppler, geometry, radar equations, etc.\n    Based on Nick Guy's Python package PyRadarMet",
    "version": "1.0.0",
    "maintainer": "Jose' Gama <rxprtgama@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20865,
    "package_name": "radiant.model",
    "title": "Model Menu for Radiant: Business Analytics using R and Shiny",
    "description": "The Radiant Model menu includes interfaces for linear and logistic\n    regression, naive Bayes, neural networks, classification and regression trees,\n    model evaluation, collaborative filtering, decision analysis, and simulation.\n    The application extends the functionality in 'radiant.data'.",
    "version": "1.6.9",
    "maintainer": "Vincent Nijs <radiant@rady.ucsd.edu>",
    "url": "https://github.com/radiant-rstats/radiant.model/,\nhttps://radiant-rstats.github.io/radiant.model/,\nhttps://radiant-rstats.github.io/docs/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20866,
    "package_name": "radiant.multivariate",
    "title": "Multivariate Menu for Radiant: Business Analytics using R and\nShiny",
    "description": "The Radiant Multivariate menu includes interfaces for perceptual\n    mapping, factor analysis, cluster analysis, and conjoint analysis. The\n    application extends the functionality in 'radiant.data'.",
    "version": "1.6.8",
    "maintainer": "Vincent Nijs <radiant@rady.ucsd.edu>",
    "url": "https://github.com/radiant-rstats/radiant.multivariate/,\nhttps://radiant-rstats.github.io/radiant.multivariate/,\nhttps://radiant-rstats.github.io/docs/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20870,
    "package_name": "radsafer",
    "title": "Radiation Safety",
    "description": "Provides functions for radiation safety, also known as\n    \"radiation protection\" and \"radiological control\". The science of \n    radiation protection is called \"health physics\" and its engineering \n    functions are called \"radiological engineering\". Functions in this \n    package cover many of the computations needed by radiation safety \n    professionals. Examples include: obtaining updated calibration and\n    source check values for radiation monitors to account for radioactive \n    decay in a reference source, simulating instrument readings to better\n    understand measurement uncertainty, correcting instrument readings \n    for geometry and ambient atmospheric conditions. Many of these \n    functions are described in Johnson and Kirby (2011, ISBN-13:  \n    978-1609134198). Utilities are also included for developing inputs \n    and processing outputs with radiation transport codes, such as MCNP, \n    a general-purpose Monte Carlo N-Particle code that can be used for \n    neutron, photon, electron, or coupled neutron/photon/electron transport\n    (Werner et. al. (2018) <doi:10.2172/1419730>).",
    "version": "2.4.0",
    "maintainer": "Mark Hogue <mark.hogue.chp@gmail.com>",
    "url": "https://github.com/markhogue/radsafer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20885,
    "package_name": "rainfarmr",
    "title": "Stochastic Precipitation Downscaling with the RainFARM Method",
    "description": "An implementation of the RainFARM (Rainfall Filtered Autoregressive Model) stochastic precipitation downscaling method (Rebora et al. (2006) <doi:10.1175/JHM517.1>). Adapted for climate downscaling according to D'Onofrio et al. (2018) <doi:10.1175/JHM-D-13-096.1> and for complex topography as in Terzago et al. (2018) <doi:10.5194/nhess-18-2825-2018>. The RainFARM method is based on the extrapolation to small scales of the Fourier spectrum of a large-scale precipitation field, using a fixed logarithmic slope and random phases at small scales, followed by a nonlinear transformation of the resulting linearly correlated stochastic field. RainFARM allows to generate ensembles of spatially downscaled precipitation fields which conserve precipitation at large scales and whose statistical properties are consistent with the small-scale statistics of observed precipitation, based only on knowledge of the large-scale precipitation field.",
    "version": "0.1",
    "maintainer": "Jost von Hardenberg <j.vonhardenberg@isac.cnr.it>",
    "url": "https://github.com/jhardenberg/rainfarmr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20887,
    "package_name": "rakeR",
    "title": "Easy Spatial Microsimulation (Raking) in R",
    "description": "Functions for performing spatial microsimulation ('raking')\n    in R.",
    "version": "0.2.1",
    "maintainer": "Phil Mike Jones <philmikejones@gmail.com>",
    "url": "https://philmikejones.github.io/rakeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20894,
    "package_name": "rampage",
    "title": "Calibrated Color Ramps",
    "description": "Value-calibrated color ramps can be useful to emphasize patterns in data from complex distributions. Colors can be tied to specific values, and the association can be expanded into full color ramps that also include the relationship between colors and values. Such ramps can be used in a variety of cases when heatmap-type plots are necessary, including the visualization of vector and raster spatial data, such as topographies.",
    "version": "0.2.0",
    "maintainer": "Adam T. Kocsis <adam.t.kocsis@gmail.com>",
    "url": "https://adamtkocsis.com/rampage/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20895,
    "package_name": "ramps",
    "title": "Bayesian Geostatistical Modeling with RAMPS",
    "description": "Bayesian geostatistical modeling of Gaussian processes using a\n    reparameterized and marginalized posterior sampling (RAMPS) algorithm\n    designed to lower autocorrelation in MCMC samples.  Package performance is\n    tuned for large spatial datasets.",
    "version": "0.6.18",
    "maintainer": "Brian J Smith <brian-j-smith@uiowa.edu>",
    "url": "https://www.jstatsoft.org/v25/i10",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20903,
    "package_name": "randcorr",
    "title": "Generate a Random p x p Correlation Matrix",
    "description": "Implements the algorithm by Pourahmadi and Wang (2015) <doi:10.1016/j.spl.2015.06.015> for generating a random p x p correlation matrix. Briefly, the idea is to represent the correlation matrix using Cholesky factorization and p(p-1)/2 hyperspherical coordinates (i.e., angles), sample the angles from a particular distribution and then convert to the standard correlation matrix form. The angles are sampled from a distribution with pdf proportional to sin^k(theta) (0 < theta < pi, k >= 1) using the efficient sampling algorithm described in Enes Makalic and Daniel F. Schmidt (2018) <arXiv:1809.05212>.",
    "version": "1.0",
    "maintainer": "Daniel F. Schmidt <daniel.schmidt@monash.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20904,
    "package_name": "randgeo",
    "title": "Generate Random 'WKT' or 'GeoJSON'",
    "description": "Generate random positions (latitude/longitude), \n    Well-known text ('WKT') points or polygons, or 'GeoJSON' points or \n    polygons. ",
    "version": "0.3.0",
    "maintainer": "Scott Chamberlain <myrmecocystus@gmail.com>",
    "url": "https://github.com/ropensci/randgeo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20930,
    "package_name": "rangeBuilder",
    "title": "Occurrence Filtering, Geographic Standardization and Generation\nof Species Range Polygons",
    "description": "Provides tools for filtering occurrence records, generating alpha-hull-derived range polygons and mapping species distributions. ",
    "version": "2.2",
    "maintainer": "Pascal Title <ptitle@umich.edu>",
    "url": "https://github.com/ptitle/rangeBuilder",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20933,
    "package_name": "rangemodelR",
    "title": "Mid-Domain Effect and Species Richness",
    "description": "Used for generating randomized community matrices under\n             strict range cohesion. The package can handle data where species occurrence\n             are recorded across sites ordered along gradients such as elevation and latitude, as well as species occurrences recorded on spatial grids with known geographic coordinates.",
    "version": "1.0.6",
    "maintainer": "Aniruddha Marathe <aniruddha.pravin.marathe@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20961,
    "package_name": "raptools",
    "title": "Risk Assessment Plot and Reclassification Metrics",
    "description": "Assessing the comparative performance of two logistic regression models or results of such models or classification models. Discrimination metrics include Integrated Discrimination Improvement (IDI), Net Reclassification Improvement (NRI), and difference in Area Under the Curves (AUCs), Brier scores and Brier skill. Plots include Risk Assessment Plots, Decision curves and Calibration plots. Methods are described in Pickering and Endre (2012) <doi:10.1373/clinchem.2011.167965> and Pencina et al. (2008) <doi:10.1002/sim.2929>.  ",
    "version": "1.23.0",
    "maintainer": "Daniel Perez Vicencio <dvicencio947@gmail.com>",
    "url": "https://github.com/Researchverse/raptools,\nhttps://researchverse.github.io/raptools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20962,
    "package_name": "raptr",
    "title": "Representative and Adequate Prioritization Toolkit in R",
    "description": "Biodiversity is in crisis. The overarching aim of conservation\n    is to preserve biodiversity patterns and processes. To this end, protected\n    areas are established to buffer species and preserve biodiversity processes.\n    But resources are limited and so protected areas must be cost-effective.\n    This package contains tools to generate plans for protected areas\n    (prioritizations), using spatially explicit targets for biodiversity\n    patterns and processes. To obtain solutions in a feasible amount  of time,\n    this package uses the commercial 'Gurobi' software (obtained from\n    <https://www.gurobi.com/>). For more information on using\n    this package, see Hanson et al. (2018) <doi:10.1111/2041-210X.12862>.",
    "version": "1.0.1",
    "maintainer": "Jeffrey O Hanson <jeffrey.hanson@uqconnect.edu.au>",
    "url": "https://jeffrey-hanson.com/raptr/,\nhttps://github.com/jeffreyhanson/raptr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20971,
    "package_name": "rassta",
    "title": "Raster-Based Spatial Stratification Algorithms",
    "description": "Algorithms for the spatial stratification of landscapes, sampling and modeling of \n    spatially-varying phenomena. These algorithms offer a simple framework for the stratification \n    of geographic space based on raster layers representing landscape factors and/or factor scales. \n    The stratification process follows a hierarchical approach, which is based on first level units \n    (i.e., classification units) and second-level units (i.e., stratification units). Nonparametric \n    techniques allow to measure the correspondence between the geographic space and the landscape \n    configuration represented by the units. These correspondence metrics are useful to define \n    sampling schemes and to model the spatial variability of environmental phenomena. The \n    theoretical background of the algorithms and code examples are presented in Fuentes et al. (2022). \n    <doi:10.32614/RJ-2022-036>.",
    "version": "1.0.6",
    "maintainer": "Bryan A. Fuentes <bryandrep@gmail.com>",
    "url": "https://bafuentes.github.io/rassta/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20974,
    "package_name": "rasterImage",
    "title": "An Improved Wrapper of image()",
    "description": "This is a wrapper function for image(), which makes reasonable\n    raster plots with nice axis and other useful features.",
    "version": "0.4.0",
    "maintainer": "Martin Seilmayer <m.seilmayer@hzdr.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20975,
    "package_name": "rasterKernelEstimates",
    "title": "Kernel Based Estimates on in-Memory Raster Images",
    "description": "Performs kernel based estimates on in-memory raster images \n  from the raster package.  These kernel estimates include local means\n  variances, modes, and quantiles.  All results are in the form of \n  raster images, preserving original resolution and projection attributes.",
    "version": "1.0.2",
    "maintainer": "Jonathan Lisic <jlisic@gmail.com>",
    "url": "http://meanmean.me/blog/rasterKernel/rasterKernel.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20976,
    "package_name": "rasterList",
    "title": "A Raster Where Cells are Generic Objects",
    "description": "A S4 class has been created such that complex operations can be\n    executed on each cell of a raster map. The raster of objects contains a raster map with the addition of a list of generic objects: one\n    object for each raster cells. It allows to write few lines of R code for complex\n    map algebra. Two environmental applications about frequency analysis of raster\n    map of precipitation and creation of a raster map of soil water retention curves\n    have been presented.",
    "version": "0.5.21",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "url": "https://github.com/ecor/rasterList",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20977,
    "package_name": "rasterVis",
    "title": "Visualization Methods for Raster Data",
    "description": "Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.",
    "version": "0.51.7",
    "maintainer": "Oscar Perpinan Lamigueiro <oscar.perpinan@upm.es>",
    "url": "https://oscarperpinan.codeberg.page/rastervis/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20980,
    "package_name": "rasterize",
    "title": "Rasterize Graphical Output",
    "description": "Provides R functions to selectively rasterize components\n             of 'grid' output.  ",
    "version": "0.1",
    "maintainer": "Paul Murrell <paul@stat.auckland.ac.nz>",
    "url": "https://github.com/pmur002/rasterize,\nhttps://stattech.wordpress.fos.auckland.ac.nz/2018/05/25/2018-05-selective-raster-graphics/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 20999,
    "package_name": "ravetools",
    "title": "Signal and Image Processing Toolbox for Analyzing Intracranial\nElectroencephalography Data",
    "description": "Implemented fast and memory-efficient Notch-filter, \n    Welch-periodogram, discrete wavelet spectrogram for minutes of \n    high-resolution signals, fast 3D convolution, image registration,\n    3D mesh manipulation; providing fundamental toolbox for intracranial \n    Electroencephalography (iEEG) pipelines. \n    Documentation and examples about 'RAVE' project are provided at \n    <https://rave.wiki>, and the paper by John F. Magnotti, \n    Zhengjia Wang, Michael S. Beauchamp (2020) \n    <doi:10.1016/j.neuroimage.2020.117341>; see 'citation(\"ravetools\")' for \n    details.",
    "version": "0.2.4",
    "maintainer": "Zhengjia Wang <dipterix.wang@gmail.com>",
    "url": "https://rave.wiki, https://dipterix.org/ravetools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21005,
    "package_name": "raybevel",
    "title": "Generates Polygon Straight Skeletons and 3D Bevels",
    "description": "Generates polygon straight skeletons and 3D models.  \n    Provides functions to create and visualize interior polygon offsets, \n    3D beveled polygons, and 3D roof models.",
    "version": "0.2.2",
    "maintainer": "Tyler Morgan-Wall <tylermw@gmail.com>",
    "url": "https://www.raybevel.com,\nhttps://github.com/tylermorganwall/raybevel/,\nhttp://www.raybevel.com/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21008,
    "package_name": "rayrender",
    "title": "Build and Raytrace 3D Scenes",
    "description": "Render scenes using pathtracing. Build 3D scenes out of spheres, cubes, planes, disks, triangles, cones, curves, line segments, cylinders, ellipsoids, and 3D models in the 'Wavefront' OBJ file format or the PLY Polygon File Format. Supports several material types, textures, multicore rendering, and tone-mapping. Based on the \"Ray Tracing in One Weekend\" book series. Peter Shirley (2018) <https://raytracing.github.io>.",
    "version": "0.38.10",
    "maintainer": "Tyler Morgan-Wall <tylermw@gmail.com>",
    "url": "https://www.rayrender.net,\nhttps://github.com/tylermorganwall/rayrender,\nhttp://www.rayrender.net/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21057,
    "package_name": "rcdd",
    "title": "Computational Geometry",
    "description": "R interface to (some of) cddlib\n    (<https://github.com/cddlib/cddlib>).\n    Converts back and forth between two representations of a convex polytope:\n    as solution of a set of linear equalities and inequalities and as\n    convex hull of set of points and rays.\n    Also does linear programming and redundant generator elimination\n    (for example, convex hull in n dimensions).  All functions can use exact\n    infinite-precision rational arithmetic.",
    "version": "1.6",
    "maintainer": "Charles J. Geyer <geyer@umn.edu>",
    "url": "https://www.stat.umn.edu/geyer/rcdd/,\nhttps://github.com/cjgeyer/rcdd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21076,
    "package_name": "rcoins",
    "title": "Identify Naturally Continuous Lines in a Spatial Network",
    "description": "Provides functionality to group lines that form naturally\n    continuous lines in a spatial network. The algorithm implemented is based\n    on the Continuity in Street Networks (COINS) method from Tripathy et al.\n    (2021) <doi:10.1177/2399808320967680>, which identifies continuous\n    \"strokes\" in the network as the line strings that maximize the angles\n    between consecutive segments.",
    "version": "0.4.0",
    "maintainer": "Francesco Nattino <f.nattino@esciencecenter.nl>",
    "url": "https://cityriverspaces.github.io/rcoins/,\nhttps://doi.org/10.5281/zenodo.14501804,\nhttps://github.com/CityRiverSpaces/rcoins",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21078,
    "package_name": "rcolors",
    "title": "270 'NCL' Color Tables in R Language",
    "description": "'NCL' (NCAR Command Language) is one of the most popular spatial \n    data mapping tools in meteorology studies, due to its beautiful output \n    figures with plenty of color palettes designed by experts \n    <https://www.ncl.ucar.edu/index.shtml>. \n    Here we translate all 'NCL' color palettes into R hexadecimal RGB colors and \n    provide color selection function, which will help users make a beautiful figure.",
    "version": "0.1.0",
    "maintainer": "Dongdong Kong <kongdd.sysu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21084,
    "package_name": "rconvertu",
    "title": "From/to Classification Converter",
    "description": "Convert text into target classifications (e.g., ISO 3166-1) using a\n    JSON mapping with regular expressions. Provides helpers to return the full\n    mapping and associated metadata.",
    "version": "0.1.0",
    "maintainer": "Ilya Bolotov <ilya.bolotov@vse.cz>",
    "url": "https://github.com/econcz/rconvertu",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21090,
    "package_name": "rcrisp",
    "title": "Automate the Delineation of Urban River Spaces",
    "description": "Provides tools to automate the morphological delineation of\n    riverside urban areas based on a method introduced in Forgaci (2018)\n    <doi:10.7480/abe.2018.31>. Delineation entails the identification of\n    corridor boundaries, segmentation of the corridor, and delineation of\n    the river space using two-dimensional spatial information from street\n    network data and digital elevation data in a projected CRS. The\n    resulting delineation can be used to characterise spatial phenomena\n    that can be related to the river as a central element.",
    "version": "0.3.1",
    "maintainer": "Claudiu Forgaci <c.forgaci@tudelft.nl>",
    "url": "https://cityriverspaces.github.io/rcrisp/,\nhttps://doi.org/10.5281/zenodo.15793526",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21092,
    "package_name": "rcssci",
    "title": "Visualization of Restricted Cubic Splines",
    "description": "Restricted Cubic Splines were performed to explore the shape of association form of \"U, inverted U,\n    L\" shape and test linearity or non-linearity base on \"Cox,Logistic,linear,quasipoisson\" regression, and auto output Restricted Cubic Splines figures.\n    rcssci package could automatically draw RCS graphics with Y-axis \"OR,HR,RR,beta\".\n    The Restricted Cubic Splines method were based on \n    Suli Huang (2022) <doi:10.1016/j.ecoenv.2022.113183>,Amit Kaura (2019) <doi:10.1136/bmj.l6055>,\n    and Harrell Jr (2015, ISBN:978-3-319-19424-0 (Print) 978-3-319-19425-7 (Online)).",
    "version": "0.4.0",
    "maintainer": "Zhiqiang Nie <niezhiqiang@gdph.org.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21095,
    "package_name": "rd2d",
    "title": "Boundary Regression Discontinuity Designs",
    "description": "Provides estimation and inference procedures for boundary regression discontinuity (RD) designs\n    using local polynomial methods, based on either bivariate coordinates or distance-based approaches.\n    Methods are developed in Cattaneo, Titiunik, and Yu (2025) \n    <https://mdcattaneo.github.io/papers/Cattaneo-Titiunik-Yu_2025_BoundaryRD.pdf>.",
    "version": "0.0.3",
    "maintainer": "Ruiqi Rae Yu <rae.yu@princeton.edu>",
    "url": "https://rdpackages.github.io/rd2d/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21132,
    "package_name": "rdwd",
    "title": "Select and Download Climate Data from 'DWD' (German Weather\nService)",
    "description": "Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see \n             <https://www.dwd.de/EN/climate_environment/cdc/cdc_node_en.html> for more information).\n             Choose observational time series from meteorological stations with 'selectDWD()'.\n             Find raster data from radar and interpolation according to <https://brry.github.io/rdwd/raster-data.html>.\n             Download (multiple) data sets with progress bars and no re-downloads through 'dataDWD()'.\n             Read both tabular observational data and binary gridded datasets with 'readDWD()'.",
    "version": "1.9.8",
    "maintainer": "Berry Boessenkool <berry-b@gmx.de>",
    "url": "https://brry.github.io/rdwd/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21133,
    "package_name": "rdwplus",
    "title": "Inverse Distance Weighted Percent Land Use for Streams",
    "description": "Compute spatially explicit land-use metrics for stream survey sites in GRASS GIS and R as an open-source implementation of IDW-PLUS (Inverse Distance Weighted Percent Land Use for Streams). The package includes functions for preprocessing digital elevation and streams data, and one function to compute all the spatially explicit land use metrics described in Peterson et al. (2011) <doi:10.1111/j.1365-2427.2010.02507.x> and previously implemented by Peterson and Pearse (2017) <doi:10.1111/1752-1688.12558> in ArcGIS-Python as IDW-PLUS. ",
    "version": "1.0.1",
    "maintainer": "Alan Pearse <alan.pearse@unimelb.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21203,
    "package_name": "recexcavAAR",
    "title": "3D Reconstruction of Archaeological Excavations",
    "description": "A toolset for 3D reconstruction and analysis of excavations. It provides methods to reconstruct natural and artificial surfaces based on field measurements. This allows to spatially contextualize documented subunits and features. Intended to be part of a 3D visualization workflow.",
    "version": "0.3.0",
    "maintainer": "Clemens Schmid <clemens@nevrome.de>",
    "url": "https://github.com/ISAAKiel/recexcavAAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21205,
    "package_name": "rechaRge",
    "title": "HydroBudget – Groundwater Recharge Model",
    "description": "HydroBudget is a spatially distributed\n  groundwater recharge model that computes a superficial water\n  budget on grid cells with outputs aggregated into monthly time steps.\n  It was developed as an accessible and computationally affordable model\n  to simulate groundwater recharge over large areas (thousands of km2,\n  regional-scale watersheds) and for long time periods (decades), in cold\n  and humid climates. Model algorithms are based on the research of\n  Dubois, E. et al. (2021a) <doi:10.5683/SP3/EUDV3H> and \n  Dubois, E. et al. (2021b) <doi:10.5194/hess-25-6567-2021>.",
    "version": "1.0.0",
    "maintainer": "Yannick Marcon <yannick.marcon@epfl.ch>",
    "url": "https://github.com/gwrecharge/rechaRge/,\nhttps://gwrecharge.github.io/rechaRge-book/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21210,
    "package_name": "recmap",
    "title": "Compute the Rectangular Statistical Cartogram",
    "description": "Implements the RecMap MP2 construction heuristic\n  <doi:10.1109/INFVIS.2004.57>.\n  This algorithm draws maps according to a given statistical\n  value, e.g., election results, population, or epidemiological data.\n  The basic idea of the RecMap algorithm is that each map region,\n  e.g., different countries, is represented by a rectangle.\n  The area of each rectangle represents the statistical value provided\n  as input to maintain zero cartographic error.\n  Computationally intensive tasks are implemented in C++.\n  The included vignette documents recmap algorithm usage.",
    "version": "1.0.20",
    "maintainer": "Christian Panse <Christian.Panse@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21246,
    "package_name": "redistverse",
    "title": "Easily Install and Load Redistricting Software",
    "description": "Easy installation, loading, and control of packages for redistricting\n    data downloading, spatial data processing, simulation, analysis, and \n    visualization. This package makes it easy to install and load multiple \n    'redistverse' packages at once. The 'redistverse' is developed and maintained \n    by the Algorithm-Assisted Redistricting Methodology (ALARM) Project.\n    For more details see <https://alarm-redist.org>.",
    "version": "0.1.2",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/alarm-redist/redistverse,\nhttps://alarm-redist.org/redistverse/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21253,
    "package_name": "ref.ICAR",
    "title": "Objective Bayes Intrinsic Conditional Autoregressive Model for\nAreal Data",
    "description": "Implements an objective Bayes intrinsic conditional autoregressive \n    prior. This model provides an objective Bayesian approach for modeling spatially \n    correlated areal data using an intrinsic conditional autoregressive prior on a vector of \n    spatial random effects.",
    "version": "2.0.2",
    "maintainer": "Erica M. Porter <emporte@clemson.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21274,
    "package_name": "regMMD",
    "title": "Robust Regression and Estimation Through Maximum Mean\nDiscrepancy Minimization",
    "description": "The functions in this package compute robust estimators by minimizing a kernel-based distance known as MMD (Maximum Mean Discrepancy) between the sample and a statistical model. Recent works proved that these estimators enjoy a universal consistency property, and are extremely robust to outliers. Various optimization algorithms are implemented: stochastic gradient is available for most models, but the package also allows gradient descent in a few models for which an exact formula is available for the gradient. In terms of distribution fit, a large number of continuous and discrete distributions are available: Gaussian, exponential, uniform, gamma, Poisson, geometric, etc. In terms of regression, the models available are: linear, logistic, gamma, beta and Poisson.\n\tAlquier, P. and Gerber, M. (2024) <doi:10.1093/biomet/asad031>\n\tCherief-Abdellatif, B.-E. and Alquier, P. (2022) <doi:10.3150/21-BEJ1338>.",
    "version": "0.1.0",
    "maintainer": "Pierre Alquier <pierre.alquier.stat@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21283,
    "package_name": "regional",
    "title": "Intra- and Inter-Regional Similarity",
    "description": "Calculates intra-regional and inter-regional similarities based on user-provided\n    spatial vector objects (regions) and spatial raster objects (cells with values).\n    Implemented metrics include inhomogeneity, isolation \n    (Haralick and Shapiro (1985) <doi:10.1016/S0734-189X(85)90153-7>, \n    Jasiewicz et al. (2018) <doi:10.1016/j.cageo.2018.06.003>), \n    and distinction (Nowosad (2021) <doi:10.1080/13658816.2021.1893324>).",
    "version": "0.4.4",
    "maintainer": "Jakub Nowosad <nowosad.jakub@gmail.com>",
    "url": "https://jakubnowosad.com/regional/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21289,
    "package_name": "registry",
    "title": "Infrastructure for R Package Registries",
    "description": "Provides a generic infrastructure for creating and using registries.",
    "version": "0.5-1",
    "maintainer": "David Meyer <David.Meyer@R-project.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21290,
    "package_name": "reglogit",
    "title": "Simulation-Based Regularized Logistic Regression",
    "description": "Regularized (polychotomous) logistic regression \n  by Gibbs sampling. The package implements subtly different \n  MCMC schemes with varying efficiency depending on the data type \n  (binary v. binomial, say) and the desired estimator (regularized maximum\n  likelihood, or Bayesian maximum a posteriori/posterior mean, etc.) through a \n  unified interface. For details, see Gramacy & Polson (2012 <doi:10.1214/12-BA719>).",
    "version": "1.2-8",
    "maintainer": "Robert B. Gramacy <rbg@vt.edu>",
    "url": "https://bobby.gramacy.com/r_packages/reglogit/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21300,
    "package_name": "regress",
    "title": "Gaussian Linear Models with Linear Covariance Structure",
    "description": "Functions to fit Gaussian linear model by maximising the\n        residual log likelihood where the covariance structure can be\n        written as a linear combination of known matrices.  Can be used\n        for multivariate models and random effects models.  Easy\n        straight forward manner to specify random effects models,\n        including random interactions. Code now optimised to use\n        Sherman Morrison Woodbury identities for matrix inversion in\n        random effects models. We've added the ability to fit models\n        using any kernel as well as a function to return the mean and\n        covariance of random effects conditional on the data (best\n        linear unbiased predictors, BLUPs).\n        Clifford and McCullagh (2006)\n        <https://www.r-project.org/doc/Rnews/Rnews_2006-2.pdf>.",
    "version": "1.3-22",
    "maintainer": "Karl W Broman <broman@wisc.edu>",
    "url": "https://github.com/kbroman/regress",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21319,
    "package_name": "relatable",
    "title": "Functions for Mapping Key-Value Pairs, Many-to-Many,\nOne-to-Many, and Many-to-One Relations",
    "description": "Functions to safely map from a vector of keys to a vector of values, determine properties of a given relation, or ensure a relation conforms to a given type, such as many-to-many, one-to-many, injective, surjective, or bijective. Permits default return values for use similar to a vectorised switch statement, as well as safely handling large vectors, NAs, and duplicate mappings.",
    "version": "1.0.0",
    "maintainer": "Dominic Jarkey <dominic.jarkey@gmail.com>",
    "url": "https://github.com/domjarkey/relatable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21326,
    "package_name": "relgam",
    "title": "Reluctant Generalized Additive Models",
    "description": "A method for fitting the entire regularization path of the\n    reluctant generalized additive model (RGAM) for linear regression, logistic, \n    Poisson and Cox regression models. See Tay, J. K., and Tibshirani, R., (2019)\n    <arXiv:1912.01808> for details.",
    "version": "1.0",
    "maintainer": "Kenneth Tay <kjytay@stanford.edu>",
    "url": "https://arxiv.org/abs/1912.01808",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21327,
    "package_name": "reliaR",
    "title": "Comprehensive Tools for some Probability Distributions",
    "description": "Provides a comprehensive suite of utilities for univariate continuous probability distributions and reliability models. Includes functions to compute the probability density, cumulative distribution, quantile, reliability, and hazard functions, along with random variate generation. Also offers diagnostic and model assessment tools  such as Quantile-Quantile (Q-Q) and Probability-Probability (P-P) plots, the Kolmogorov-Smirnov goodness-of-fit test, and model selection criteria including the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). Currently implements the following distributions: Burr X, Chen, Exponential Extension, Exponentiated Logistic, Exponentiated Weibull, Exponential Power, Flexible Weibull, Generalized Exponential, Gompertz, Generalized Power Weibull, Gumbel, Inverse Generalized Exponential, Linear Failure Rate, Log-Gamma, Logistic-Exponential, Logistic-Rayleigh, Log-log, Marshall-Olkin Extended Exponential, Marshall-Olkin Extended Weibull, and Weibull Extension distributions. Serves as a valuable resource for teaching and research in probability theory, reliability analysis, and applied statistical modeling.\t",
    "version": "0.2",
    "maintainer": "Vijay Kumar <vkgkp@rediffmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21332,
    "package_name": "rema",
    "title": "Rare Event Meta Analysis",
    "description": "The rema package implements a permutation-based approach for binary \n\tmeta-analyses of 2x2 tables, founded on conditional logistic regression, \n\tthat provides more reliable statistical tests when heterogeneity is \n\tobserved in rare event data (Zabriskie et al. 2021 <doi:10.1002/sim.9142>). \n\tTo adjust for the effect of heterogeneity, this method conditions on the \n\tsufficient statistic of a proxy for the heterogeneity effect as opposed to\n\testimating the heterogeneity variance. While this results in the model not\n\tstrictly falling under the random-effects framework, it is akin to a \n\trandom-effects approach in that it assumes differences in variability due \n\tto treatment. Further, this method does not rely on large-sample \n\tapproximations or continuity corrections for rare event data. This method\n\tuses the permutational distribution of the test statistic instead of\n\tasymptotic approximations for inference. The number of observed events \n\tdrives the computation complexity for creating this permutational \n\tdistribution. Accordingly, for this method to be computationally feasible,\n\tit should only be applied to meta-analyses with a relatively low number of\n\tobserved events. To create this permutational distribution, a network \n\talgorithm, based on the work of Mehta et al. (1992) <doi:10.2307/1390598> \n\tand Corcoran et al. (2001) <doi:10.1111/j.0006-341x.2001.00941.x>, is \n\temployed using C++ and integrated into the package.",
    "version": "0.0.1",
    "maintainer": "Brinley N. Zabriskie <zabriskie@stat.byu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21334,
    "package_name": "remap",
    "title": "Regional Spatial Modeling with Continuous Borders",
    "description": "Automatically creates separate regression models for different spatial \n    regions. The prediction surface is smoothed using a regional border smoothing \n    method. If regional models are continuous, the resulting prediction surface is \n    continuous across the spatial dimensions, even at region borders. Methodology \n    is described in Wagstaff and Bean (2023) <doi:10.32614/RJ-2023-004>.",
    "version": "0.3.2",
    "maintainer": "Jadon Wagstaff <jadonw@gmail.com>",
    "url": "https://github.com/jadonwagstaff/remap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21343,
    "package_name": "remotePARTS",
    "title": "Spatiotemporal Autoregression Analyses for Large Data Sets",
    "description": "\n  These tools were created to test map-scale hypotheses about trends in large\n  remotely sensed data sets but any data with spatial and temporal variation\n  can be analyzed. Tests are conducted using the PARTS method for analyzing spatially\n  autocorrelated time series\n  (Ives et al., 2021: <doi:10.1016/j.rse.2021.112678>).\n  The method's unique approach can handle extremely large data sets that other\n  spatiotemporal models cannot, while still appropriately accounting for\n  spatial and temporal autocorrelation. This is done by partitioning the data\n  into smaller chunks, analyzing chunks separately and then combining the\n  separate analyses into a single, correlated test of the map-scale hypotheses.",
    "version": "1.0.4",
    "maintainer": "Clay Morrow <morrowcj@outlook.com>",
    "url": "https://github.com/morrowcj/remotePARTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21363,
    "package_name": "replicatedpp2w",
    "title": "Two-Way ANOVA-Like Method to Analyze Replicated Point Patterns",
    "description": "Test for effects of  both individual factors and their interaction on  replicated spatial patterns in a two factorial design, as explained in Ramon et al. (2016) <doi:10.1111/ecog.01848>.",
    "version": "0.1-6",
    "maintainer": "Marcelino de la Cruz <marcelino.delacruz@urjc.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21368,
    "package_name": "repolr",
    "title": "Repeated Measures Proportional Odds Logistic Regression",
    "description": "Fits linear models to repeated ordinal scores using GEE methodology.",
    "version": "3.4",
    "maintainer": "Nick Parsons <nick.parsons@warwick.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21372,
    "package_name": "reportReg",
    "title": "An Easy Way to Report Regression Analysis",
    "description": "Provides an easy way to report the results of regression analysis, including:\n    1. Proportional hazards regression from function 'coxph' of package 'survival';\n    2. Conditional logistic regression from function 'clogit' of package 'survival';\n    3. Ordered logistic regression from function 'polr' of package 'MASS';\n    4. Binary logistic regression from function 'glm' of package 'stats';\n    5. Linear regression from function 'lm' of package 'stats';\n    6. Risk regression model for survival analysis with competing risks from function 'FGR' of package 'riskRegression';\n    7. Multilevel model from function 'lme' of package 'nlme'.",
    "version": "0.3.0",
    "maintainer": "Zhicheng Du<dgdzc@hotmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21373,
    "package_name": "reportRmd",
    "title": "Tidy Presentation of Clinical Reporting",
    "description": "Streamlined statistical reporting in 'Rmarkdown' environments. \n    Facilitates the automated reporting of descriptive statistics, multiple \n    univariate models, multivariable models and tables combining these outputs. \n    Plotting functions include customisable survival curves, forest plots from \n    logistic and ordinal regression and bivariate comparison plots.",
    "version": "0.1.1",
    "maintainer": "Lisa Avery <lisa.avery@uhn.ca>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21384,
    "package_name": "reproducible",
    "title": "Enhance Reproducibility of R Code",
    "description": "A collection of high-level, machine- and OS-independent tools\n    for making reproducible and reusable content in R.\n    The two workhorse functions are 'Cache()' and 'prepInputs()'.\n    'Cache()' allows for nested caching, is robust to environments and objects\n    with environments (like functions), and deals with some classes of \n    file-backed R objects e.g., from 'terra' and 'raster' packages. \n    Both functions have been developed to be foundational components of data\n    retrieval and processing in continuous workflow situations. In both functions,\n    efforts are made to make the first and subsequent calls of functions have \n    the same result, but faster at subsequent times by way of checksums\n    and digesting. Several features are still under development, including\n    cloud storage of cached objects allowing for sharing between users. Several\n    advanced options are available, see '?reproducibleOptions()'.",
    "version": "3.0.0",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "url": "https://reproducible.predictiveecology.org,\nhttps://github.com/PredictiveEcology/reproducible",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21386,
    "package_name": "reproj",
    "title": "Coordinate System Transformations for Generic Map Data",
    "description": "Transform coordinates from a specified source to a specified \n target map projection. This uses the 'PROJ' library directly, by wrapping the \n 'PROJ' package which leverages 'libproj', otherwise the 'proj4' package. The 'reproj()' \n function is generic, methods may be added to remove the need for an explicit \n source definition. If 'proj4' is in use 'reproj()' handles the requirement for \n conversion of angular units where necessary. This is for use primarily to \n transform generic data formats and direct leverage of the underlying\n 'PROJ' library. (There are transformations that aren't possible with 'PROJ' and\n that are provided by the 'GDAL' library, a limitation which users of this \n package should be aware of.) The 'PROJ' library is available at \n <https://proj.org/>.  ",
    "version": "0.7.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/reproj,\nhttps://hypertidy.github.io/reproj/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21390,
    "package_name": "reptiledbr",
    "title": "Interface to the Reptile Database for Querying and Retrieving\nTaxonomic Data",
    "description": "Provides tools to search, access, and format taxonomic information \n    from the Reptile Database (<http://reptile-database.org>) directly within R. \n    Users can retrieve species-level data, distribution, etymology, synonyms, \n    common names, and other relevant information for reptiles. Designed for \n    taxonomists, ecologists, and biodiversity researchers.",
    "version": "0.0.1",
    "maintainer": "Paul Efren Santos Andrade <paulefrens@gmail.com>",
    "url": "https://github.com/PaulESantos/reptiledbr,\nhttps://paulesantos.github.io/reptiledbr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21398,
    "package_name": "rerddapXtracto",
    "title": "Extracts Environmental Data from 'ERDDAP™' Web Services",
    "description": "Contains three functions that access\n    environmental data from any 'ERDDAP™' data web service. The rxtracto() function extracts\n    data along a trajectory for a given \"radius\" around the point. The\n    rxtracto_3D() function extracts data in a box. The rxtractogon() function\n    extracts data in a polygon. All of those three function use the 'rerddap' package\n    to extract the data, and should work with any 'ERDDAP™' server.\n    There are also two functions, plotBBox() and plotTrack() that use the 'plotdap'\n    package to simplify the creation of maps of the data.",
    "version": "1.2.3",
    "maintainer": "Roy Mendelssohn <roy.mendelssohn@noaa.gov>",
    "url": "https://github.com/rmendels/rerddapXtracto",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21483,
    "package_name": "rflexscan",
    "title": "The Flexible Spatial Scan Statistic",
    "description": "Provides functions for detecting spatial clusters using the flexible\n    spatial scan statistic developed by Tango and Takahashi (2005) <doi:10.1186/1476-072X-4-11>.\n    This package implements a wrapper for the 'C' routine used in the 'FleXScan' 3.1.2 \n    <https://sites.google.com/site/flexscansoftware/home> developed by Takahashi,\n    Yokoyama, and Tango. For details, see Otani et al. (2021) <doi:10.18637/jss.v099.i13>.",
    "version": "1.2.0",
    "maintainer": "Takahiro Otani <t.otani@aichi-cc.jp>",
    "url": "https://tkhrotn.github.io/rflexscan/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21484,
    "package_name": "rflsgen",
    "title": "Neutral Landscape Generator with Targets on Landscape Indices",
    "description": "Interface to the 'flsgen' neutral landscape generator <https://github.com/dimitri-justeau/flsgen>. It allows to\n  - Generate fractal terrain;\n  - Generate landscape structures satisfying user targets over landscape indices;\n  - Generate landscape raster from landscape structures.",
    "version": "1.2.2",
    "maintainer": "Dimitri Justeau-Allaire <dimitri.justeau@gmail.com>",
    "url": "https://dimitri-justeau.github.io/rflsgen/,\nhttps://dimitri-justeau.github.io/rflsgen/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21504,
    "package_name": "rgeopat2",
    "title": "Additional Functions for 'GeoPAT' 2",
    "description": "Supports analysis of spatial data processed with the 'GeoPAT' 2\n    software <https://github.com/Nowosad/geopat2>. \n    Available features include creation of a grid based on the 'GeoPAT' 2\n    grid header file and reading a 'GeoPAT' 2 text outputs.",
    "version": "0.4.0",
    "maintainer": "Jakub Nowosad <nowosad.jakub@gmail.com>",
    "url": "https://github.com/Nowosad/rgeopat2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21520,
    "package_name": "rgrass",
    "title": "Interface Between 'GRASS' Geographical Information System and\n'R'",
    "description": "An interface between the 'GRASS' geographical information system ('GIS') and 'R', based on starting 'R' from within the 'GRASS' 'GIS' environment, or running a free-standing 'R' session in a temporary 'GRASS' location; the package provides facilities for using all 'GRASS' commands from the 'R' command line. The original interface package for 'GRASS 5' (2000-2010) is described in Bivand (2000) <doi:10.1016/S0098-3004(00)00057-1> and Bivand (2001) <https://www.r-project.org/conferences/DSC-2001/Proceedings/Bivand.pdf>. This was succeeded by 'spgrass6' for 'GRASS 6' (2006-2016) and 'rgrass7' for 'GRASS 7' (2015-present). The 'rgrass' package modernizes the interface for 'GRASS 8' while still permitting the use of 'GRASS 7'.",
    "version": "0.5-3",
    "maintainer": "Steven Pawley <dr.stevenpawley@gmail.com>",
    "url": "https://osgeo.github.io/rgrass/, https://grass.osgeo.org/,\nhttps://github.com/osgeo/rgrass,\nhttps://lists.osgeo.org/mailman/listinfo/grass-stats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21571,
    "package_name": "rim",
    "title": "Interface to 'Maxima', Enabling Symbolic Computation",
    "description": "An interface to the powerful and fairly complete computer algebra system 'Maxima'.\n    It can be used to start and control 'Maxima' from within R by entering 'Maxima' commands. \n    Results from 'Maxima' can be parsed and evaluated in R. \n    It facilitates outputting results from 'Maxima' in 'LaTeX' and 'MathML'. \n    2D and 3D plots can be displayed directly. \n    This package also registers a 'knitr'-engine enabling 'Maxima' code chunks \n    to be written in 'RMarkdown' documents.",
    "version": "0.8.1",
    "maintainer": "Eric Stemmler <stemmler.eric@gmail.com>",
    "url": "https://rcst.github.io/rim/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21636,
    "package_name": "rlandfire",
    "title": "Interface to 'LANDFIRE Product Service' API",
    "description": "Provides access to a suite of geospatial data layers for wildfire management, fuel modeling, ecology, natural resource management, climate, conservation, etc., via the 'LANDFIRE' (<https://www.landfire.gov/>) Product Service ('LFPS') API.",
    "version": "2.0.1",
    "maintainer": "Mark Buckner <mab677@cornell.edu>",
    "url": "https://github.com/bcknr/rlandfire",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21639,
    "package_name": "rlccs",
    "title": "R Client For Land Cover Classification System Web Service",
    "description": "Provides functions to access, search and manage classification systems.",
    "version": "0.1.0",
    "maintainer": "The package maintainer <yourself@somewhere.net>",
    "url": "https://github.com/brazil-data-cube/rlccs",
    "exports": [],
    "topics": ["earth-science", "geospatial", "gis", "land-cover", "land-use", "r"],
    "score": "NA",
    "stars": 6
  },
  {
    "id": 21642,
    "package_name": "rleafmap",
    "title": "Interactive Maps with R and Leaflet",
    "description": "Display spatial data with interactive maps powered by the open-\n    source JavaScript library 'Leaflet' (see <https://leafletjs.com/>). Maps can be\n    rendered in a web browser or displayed in the HTML viewer pane of 'RStudio'.\n    This package is designed to be easy to use and can create complex maps with\n    vector and raster data, web served map tiles and interface elements.",
    "version": "0.2.1",
    "maintainer": "Francois Keck <francois.keck@gmail.com>",
    "url": "http://www.francoiskeck.fr/rleafmap/,\nhttps://github.com/fkeck/rleafmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21649,
    "package_name": "rlist",
    "title": "A Toolbox for Non-Tabular Data Manipulation",
    "description": "Provides a set of functions for data manipulation with\n    list objects, including mapping, filtering, grouping, sorting,\n    updating, searching, and other useful functions. Most functions\n    are designed to be pipeline friendly so that data processing with\n    lists can be chained.",
    "version": "0.4.6.2",
    "maintainer": "Kun Ren <ken@renkun.me>",
    "url": "https://renkun-ken.github.io/rlist/,\nhttps://github.com/renkun-ken/rlist,\nhttps://renkun-ken.github.io/rlist-tutorial/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21659,
    "package_name": "rmacrostrat",
    "title": "Fetch Geologic Data from the 'Macrostrat' Platform",
    "description": "Work with the 'Macrostrat' (<https://macrostrat.org/>) Web Service \n    (v.2, <https://macrostrat.org/api/v2>) to fetch geological data relevant to\n    the spatial and temporal distribution of sedimentary, igneous, and\n    metamorphic rocks as well as data extracted from them. ",
    "version": "1.0.0",
    "maintainer": "Lewis A. Jones <LewisA.Jones@outlook.com>",
    "url": "https://rmacrostrat.palaeoverse.org, https://palaeoverse.org,\nhttps://macrostrat.org,\nhttps://github.com/UW-Macrostrat/macrostrat/issues",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21662,
    "package_name": "rmapshaper",
    "title": "Client for 'mapshaper' for 'Geospatial' Operations",
    "description": "Edit and simplify 'geojson', 'Spatial', and 'sf'\n    objects.  This is wrapper around the 'mapshaper' 'JavaScript' library\n    by Matthew Bloch <https://github.com/mbloch/mapshaper/> to perform\n    topologically-aware polygon simplification, as well as other\n    operations such as clipping, erasing, dissolving, and converting\n    'multi-part' to 'single-part' geometries.",
    "version": "0.6.0",
    "maintainer": "Andy Teucher <andy.teucher@gmail.com>",
    "url": "https://github.com/ateucher/rmapshaper,\nhttp://andyteucher.ca/rmapshaper/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21688,
    "package_name": "rmlnomogram",
    "title": "Construct Explainable Nomogram for a Machine Learning Model",
    "description": "Construct an explainable nomogram for a machine learning (ML) model to improve availability of an ML prediction model in addition to a computer application, particularly in a situation where a computer, a mobile phone, an internet connection, or the application accessibility are unreliable. This package enables a nomogram creation for any ML prediction models, which is conventionally limited to only a linear/logistic regression model. This nomogram may indicate the explainability value per feature, e.g., the Shapley additive explanation value, for each individual. However, this package only allows a nomogram creation for a model using categorical without or with single numerical predictors. Detailed methodologies and examples are documented in our vignette, available at <https://htmlpreview.github.io/?https://github.com/herdiantrisufriyana/rmlnomogram/blob/master/doc/ml_nomogram_exemplar.html>.",
    "version": "0.1.2",
    "maintainer": "Herdiantri Sufriyana <herdi@nycu.edu.tw>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21696,
    "package_name": "rmsb",
    "title": "Bayesian Regression Modeling Strategies",
    "description": "A Bayesian companion to the 'rms' package, 'rmsb' provides Bayesian model fitting, post-fit estimation, and graphics.  It implements Bayesian regression models whose fit objects can be processed by 'rms' functions such as 'contrast()', 'summary()', 'Predict()', 'nomogram()', and 'latex()'.  The fitting function currently implemented in the package is 'blrm()' for Bayesian logistic binary and ordinal regression with optional clustering, censoring, and departures from the proportional odds assumption using the partial proportional odds model of Peterson and Harrell (1990) <https://www.jstor.org/stable/2347760>.",
    "version": "1.1-2",
    "maintainer": "Frank Harrell <fh@fharrell.com>",
    "url": "https://hbiostat.org/R/rmsb/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21731,
    "package_name": "roads",
    "title": "Road Network Projection",
    "description": "Iterative least cost path and minimum spanning tree methods for projecting \n    forest road networks. The methods connect a set of target points to an existing \n    road network using 'igraph' <https://igraph.org> to identify least cost routes.\n    The cost of constructing a road segment between adjacent pixels is determined\n    by a user supplied weight raster and a weight function; options include the\n    average of adjacent weight raster values, and a function of the elevation \n    differences between adjacent cells that penalizes steep grades. These road\n    network projection methods are intended for integration into R workflows and \n    modelling frameworks used for forecasting forest change, and can be applied \n    over multiple time-steps without rebuilding a graph at each time-step.",
    "version": "1.2.0",
    "maintainer": "Sarah Endicott <sarah.endicott@ec.gc.ca>",
    "url": "https://github.com/LandSciTech/roads,\nhttps://landscitech.github.io/roads/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21828,
    "package_name": "ropendata",
    "title": "Query and Download 'Rapid7' 'Cybersecurity' Data Sets",
    "description": "'Rapid7' collects 'cybersecurity' data and makes it available via\n    their 'Open Data' <http://opendata.rapid7.com> portal which has an API. Tools are\n    provided to assist in querying for available data sets and downloading any\n    data set authorized to a free, registered account.",
    "version": "0.1.0",
    "maintainer": "Bob Rudis <bob@rud.is>",
    "url": "https://github.com/brudis-r7/ropendata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21831,
    "package_name": "ropercenter",
    "title": "Reproducible Data Retrieval from the Roper Center Data Archive",
    "description": "Reproducible, programmatic retrieval of datasets from the\n    Roper Center data archive.  The Roper Center for Public Opinion\n    Research <https://ropercenter.cornell.edu> maintains the largest \n    archive of public opinion data in existence, but researchers using\n    these datasets are caught in a bind.  The Center's terms and conditions\n    bar redistribution of downloaded datasets, but to ensure that one's \n    work can be reproduced, assessed, and built upon by others, one must\n    provide access to the raw data one employed.  The `ropercenter`\n    package cuts this knot by providing registered users with programmatic,\n    reproducible access to Roper Center datasets from within R.",
    "version": "0.3.2",
    "maintainer": "Frederick Solt <frederick-solt@uiowa.edu>",
    "url": "https://github.com/fsolt/ropercenter,\nhttps://fsolt.org/ropercenter/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21840,
    "package_name": "rosm",
    "title": "Plot Raster Map Tiles from Open Street Map and Other Sources",
    "description": "Download and plot Open Street Map <https://www.openstreetmap.org/>,\n    Bing Maps <https://www.bing.com/maps> and other tiled map sources. Use to create \n    basemaps quickly and add hillshade to vector-based maps.",
    "version": "0.3.0",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "url": "https://github.com/paleolimbot/rosm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21852,
    "package_name": "roughsf",
    "title": "Visualize Spatial Data using 'roughjs'",
    "description": "Draw maps using the 'javascript' library 'roughjs'. This allows to draw sketchy, hand-drawn-like maps.",
    "version": "1.0.0",
    "maintainer": "David Schoch <david@schochastics.net>",
    "url": "https://github.com/schochastics/roughsf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21863,
    "package_name": "roxylint",
    "title": "Lint 'roxygen2'-Generated Documentation",
    "description": "Provides formatting linting to 'roxygen2' tags. Linters report\n    'roxygen2' tags that do not conform to a standard style. These linters\n    can be a helpful check for building more consistent documentation and \n    to provide reminders about best practices or checks for typos. Default \n    linting suites are provided for common style guides such as the one \n    followed by the 'tidyverse', though custom linters can be registered by \n    other packages or be custom-tailored to a specific package.",
    "version": "0.1.0",
    "maintainer": "Doug Kelkhoff <doug.kelkhoff@gmail.com>",
    "url": "https://github.com/openpharma/roxylint,\nhttps://openpharma.github.io/roxylint/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21867,
    "package_name": "rpaleoclim",
    "title": "Download Paleoclimate Data from 'PaleoClim'",
    "description": "\n    'PaleoClim' <http://www.paleoclim.org> (Brown et al. 2019, \n  <doi:10.1038/sdata.2018.254>) is a set of free, high resolution paleoclimate \n  surfaces covering the whole globe. It includes data on surface temperature,\n  precipitation and the standard bioclimatic variables commonly used in \n  ecological modelling, derived from the 'HadCM3' general circulation model and \n  downscaled to a spatial resolution of up to 2.5 minutes. Simulations are\n  available for key time periods from the Late Holocene to mid-Pliocene. Data on\n  current and Last Glacial Maximum climate is derived from 'CHELSA'  (Karger et \n  al. 2017, <doi:10.1038/sdata.2017.122>) and reprocessed by 'PaleoClim' to \n  match their format; it is available at up to 30 seconds resolution. This \n  package provides a simple interface for downloading 'PaleoClim' data in R, \n  with support for caching and filtering retrieved data by period, resolution,\n  and geographic extent.",
    "version": "1.1.0",
    "maintainer": "Joe Roe <joe@joeroe.io>",
    "url": "https://rpaleoclim.joeroe.io, https://github.com/joeroe/rpaleoclim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21876,
    "package_name": "rpf",
    "title": "Response Probability Functions",
    "description": "Factor out logic\n    and math common to Item Factor Analysis fitting, diagnostics, and\n    analysis. It is envisioned as core support code suitable for more\n    specialized IRT packages to build upon. Complete access to optimized C\n    functions are made available with R_RegisterCCallable().\n    This software is described in Pritikin & Falk (2020) <doi:10.1177/0146621620929431>.",
    "version": "1.0.15",
    "maintainer": "Joshua Pritikin <jpritikin@pobox.com>",
    "url": "https://github.com/jpritikin/rpf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21892,
    "package_name": "rpostgis",
    "title": "R Interface to a 'PostGIS' Database",
    "description": "Provides an interface between R and 'PostGIS'-enabled\n    'PostgreSQL' databases to transparently transfer spatial\n    data. Both vector (points, lines, polygons) and raster data are\n    supported in read and write modes. Also provides convenience\n    functions to execute common procedures in 'PostgreSQL/PostGIS'.",
    "version": "1.6.0",
    "maintainer": "Adrian Cidre Gonzalez <adrian.cidre@gmail.com>",
    "url": "https://cidree.github.io/rpostgis/,\nhttps://github.com/Cidree/rpostgis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21917,
    "package_name": "rr2",
    "title": "R2s for Regression Models",
    "description": "Three methods to calculate R2 for models with correlated errors, \n    including Phylogenetic GLS, Phylogenetic Logistic Regression, Linear Mixed \n    Models (LMMs), and Generalized Linear Mixed Models (GLMMs). See details in \n    Ives 2018 <doi:10.1093/sysbio/syy060>.",
    "version": "1.1.1",
    "maintainer": "Anthony Ives <arives@wisc.edu>",
    "url": "https://github.com/arives/rr2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21931,
    "package_name": "rreg",
    "title": "Visualization for Norwegian Health Quality Registries",
    "description": "Assists for presentation and visualization of data from the Norwegian Health Quality Registries following the standardization based on the requirement specified by the National Service for Health Quality Registries. This requirement can be accessed from (<https://www.kvalitetsregistre.no/resultater-til-publisering-pa-nett>). Unfortunately the website is only available in Norwegian.",
    "version": "0.2.1",
    "maintainer": "Yusman Kamaleri <ybkamaleri@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 21947,
    "package_name": "rsMove",
    "title": "Guidelines for the use of Remote Sensing in Movement Ecology",
    "description": "Tools for the guided selection of satellite data and environmental predictors, the combination of remote sensing and animal movement data and the mapping of resource suitability. Based on the paper by Remelgado et al. (2015) <doi:10.1111/2041-210X.13199>.",
    "version": "0.2.8",
    "maintainer": "Ruben Remelgado <remelgado.ruben@gmail.com>",
    "url": "https://github.com/RRemelgado/rsMove",
    "exports": [],
    "topics": ["animal-behavior", "animal-behaviour", "ecology", "machine-learning", "movement-ecology", "r", "remote-sensing", "spatial-analysis"],
    "score": "NA",
    "stars": 32
  },
  {
    "id": 21951,
    "package_name": "rsamplr",
    "title": "Sampling Algorithms and Spatially Balanced Sampling",
    "description": "\n    Fast tools for unequal probability sampling in multi-dimensional spaces, implemented in Rust for high performance.\n    The package offers a wide range of methods, including Sampford (Sampford, 1967, <doi:10.1093/biomet/54.3-4.499>) and correlated Poisson sampling (Bondesson and Thorburn, 2008, <doi:10.1111/j.1467-9469.2008.00596.x>), pivotal sampling (Deville and Tillé, 1998, <doi:10.1093/biomet/91.4.893>), and balanced sampling such as the cube method (Deville and Tillé, 2004, <doi:10.1093/biomet/91.4.893>) to ensure auxiliary totals are respected.\n    Spatially balanced approaches, including the local pivotal method (Grafström et al., 2012, <doi:10.1111/j.1541-0420.2011.01699.x>), spatially correlated Poisson sampling (Grafström, 2012, <doi:10.1016/j.jspi.2011.07.003>), and locally correlated Poisson sampling (Prentius, 2024, <doi:10.1002/env.2832>), provide efficient designs when the target variable is linked to auxiliary information.",
    "version": "0.1.1",
    "maintainer": "Wilmer Prentius <wilmer.prentius@slu.se>",
    "url": "https://www.envisim.se/, https://github.com/envisim/rust-samplr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22054,
    "package_name": "rtop",
    "title": "Interpolation of Data with Variable Spatial Support",
    "description": "Data with irregular spatial support, such as runoff related data or data from administrative units, can with 'rtop' be interpolated to locations without observations with the top-kriging method. A description of the package is given by Skøien et al (2014) <doi:10.1016/j.cageo.2014.02.009>.",
    "version": "0.6-17",
    "maintainer": "Jon Olav Skøien <jon.skoien@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22084,
    "package_name": "runkeepR",
    "title": "Extract, analyse, and plot Runkeeper(TM) data",
    "description": "Extract, analyse, and plot Runkeeper(TM) data.",
    "version": "0.0.1",
    "maintainer": "Jonathan Carroll <rpkg@jcarroll.com.au>",
    "url": "https://github.com/jonocarroll/runkeepR",
    "exports": [],
    "topics": ["data-analysis", "data-mining", "gis", "gpx", "rstats", "runkeeper"],
    "score": "NA",
    "stars": 9
  },
  {
    "id": 22116,
    "package_name": "rwc",
    "title": "Random Walk Covariance Models",
    "description": "Code to facilitate simulation and inference when connectivity is defined by underlying random walks. Methods for spatially-correlated pairwise distance data are especially considered. This provides core code to conduct analyses similar to that in Hanks and Hooten (2013) <doi:10.1080/01621459.2012.724647>.",
    "version": "1.12",
    "maintainer": "Ephraim Hanks <hanks@psu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22120,
    "package_name": "rwisp",
    "title": "WISP Multiple Criteria Sorting Method",
    "description": "Implementation of the Integrated Simple Weighted Sum Product Method (WISP), a multiple criteria sorting method create by Dragisa Stanujkic (2021) <doi:10.1109/TEM.2021.3075783>.",
    "version": "1.0.5",
    "maintainer": "Bernardo Silva <bernardo.silva@furg.br>",
    "url": "https://github.com/dioubernardo/rwisp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22122,
    "package_name": "rwlts",
    "title": "Web Land Trajectory Service R Client",
    "description": "R client for access to data provided in the Brazil Data Cube Web Land Trajectory Service.",
    "version": "0.8.0",
    "maintainer": "",
    "url": "https://github.com/brazil-data-cube/rwlts",
    "exports": [],
    "topics": ["earth-observation", "earth-science", "geoinformatics", "geoscience", "geospatial", "land-cover", "r", "trajectory"],
    "score": "NA",
    "stars": 8
  },
  {
    "id": 22124,
    "package_name": "rworldmap",
    "title": "Mapping Global Data",
    "description": "Enables mapping of country level and gridded user datasets.",
    "version": "1.3-8",
    "maintainer": "Andy South <southandy@gmail.com>",
    "url": "https://github.com/AndySouth/rworldmap/,\nhttps://groups.google.com/forum/#!forum/rworldmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22141,
    "package_name": "s2net",
    "title": "The Generalized Semi-Supervised Elastic-Net",
    "description": "Implements the generalized semi-supervised elastic-net. This method extends the supervised elastic-net problem, and thus it is a practical solution to the problem of feature selection in semi-supervised contexts. Its mathematical formulation is presented from a general perspective, covering a wide range of models.  We focus on linear and logistic responses, but the implementation could be easily extended to other losses in generalized linear models. We develop a flexible and fast implementation, written in 'C++' using 'RcppArmadillo' and integrated into R via 'Rcpp' modules. See Culp, M. 2013 <doi:10.1080/10618600.2012.657139> for references on the Joint Trained Elastic-Net.",
    "version": "1.0.7",
    "maintainer": "Juan C. Laria <juank.laria@gmail.com>",
    "url": "https://github.com/jlaria/s2net",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22145,
    "package_name": "sAIC",
    "title": "Akaike Information Criterion for Sparse Estimation",
    "description": "Computes the Akaike information criterion for the generalized linear models (logistic regression, Poisson regression, and Gaussian graphical models) estimated by the lasso. ",
    "version": "1.0.1",
    "maintainer": "Shuichi Kawano <skawano@math.kyushu-u.ac.jp>",
    "url": "https://doi.org/10.1214/16-EJS1179,\nhttps://sites.google.com/site/shuichikawanoen/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22169,
    "package_name": "sad",
    "title": "Verify the Scale, Anisotropy and Direction of Weather Forecasts",
    "description": "Implementation of the wavelet-based spatial verification method of Buschow and Friederichs \"SAD: Verifying the Scale, Anisotropy and Direction of precipitation forecasts\" (2020, submitted to QJRMS). Forecasts and Observations are transformed by a decimated or redundant dual-tree complex wavelet transform to analyze the spatial scale, degree of anisotropy and preferred direction in each field. These structural attributes are compared by a series of scores. An experimental algorithm for the correction of these errors is included as well.",
    "version": "0.1.3",
    "maintainer": "Sebastian Buschow <s6sebusc@uni-bonn.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22173,
    "package_name": "sae.prop",
    "title": "Small Area Estimation using Fay-Herriot Models with Additive\nLogistic Transformation",
    "description": "Implements Additive Logistic Transformation (alr) for Small Area Estimation under Fay Herriot Model. Small Area Estimation is used to borrow strength from auxiliary variables to improve the effectiveness of a domain sample size. This package uses Empirical Best Linear Unbiased Prediction (EBLUP). The Additive Logistic Transformation (alr) are based on transformation by Aitchison J (1986). The covariance matrix for multivariate application is based on covariance matrix used by Esteban M, Lombardía M, López-Vizcaíno E, Morales D, and Pérez A <doi:10.1007/s11749-019-00688-w>. The non-sampled models are modified area-level models based on models proposed by Anisa R, Kurnia A, and Indahwati I <doi:10.9790/5728-10121519>, with univariate model using model-3, and multivariate model using model-1. The MSE are estimated using Parametric Bootstrap approach. For non-sampled cases, MSE are estimated using modified approach proposed by Haris F and Ubaidillah A <doi:10.4108/eai.2-8-2019.2290339>.",
    "version": "0.1.2",
    "maintainer": "M. Rijalus Sholihin <m.rijalussholihin@bps.go.id>",
    "url": "https://github.com/mrijalussholihin/sae.prop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22174,
    "package_name": "sae2",
    "title": "Small Area Estimation: Time-Series Models",
    "description": "Time series area-level models for small area estimation. \n      The package supplements the functionality of the sae package. Specifically, it includes\n      EBLUP fitting of the Rao-Yu model in the original form without a spatial component. \n      The package also offers a modified (\"dynamic\") version of the Rao-Yu model, replacing\n      the assumption of stationarity. Both univariate and multivariate applications are\n      supported. Of particular note is the allowance for covariance of the area-level sample \n      estimates over time, as encountered in rotating panel designs such as the U.S. National \n      Crime Victimization Survey or present in a time-series of 5-year estimates from the \n      American Community Survey. Key references to the methods include\n      J.N.K. Rao and I. Molina (2015, ISBN:9781118735787),\n      J.N.K. Rao and M. Yu (1994) <doi:10.2307/3315407>, and\n      R.E. Fay and R.A. Herriot (1979) <doi:10.1080/01621459.1979.10482505>.",
    "version": "1.2-2",
    "maintainer": "Robert Fay <bobfay@hotmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22184,
    "package_name": "saeHB.spatial",
    "title": "Small Area Estimation Hierarchical Bayes For Spatial Model",
    "description": "Provides several functions and datasets for area level of Small Area Estimation under Spatial Model using Hierarchical Bayesian (HB) Method. Model-based estimators include the HB estimators based on a Spatial Fay-Herriot model with univariate normal distribution for variable of interest.The 'rjags' package is employed to obtain parameter estimates. For the reference, see Rao and Molina (2015) <doi:10.1002/9781118735855>.",
    "version": "0.1.1",
    "maintainer": "Arina Mana Sikana <sikanaradrianan@gmail.com>",
    "url": "https://github.com/arinams/saeHB.spatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22194,
    "package_name": "saeczi",
    "title": "Small Area Estimation for Continuous Zero Inflated Data",
    "description": "Provides functionality to fit a zero-inflated estimator for small area estimation.\n    This estimator is a combines a linear mixed effects regression model and a logistic\n    mixed effects regression model via a two-stage modeling approach. The estimator's mean\n    squared error is estimated via a parametric bootstrap method. Chandra and others\n    (2012, <doi:10.1080/03610918.2011.598991>) introduce and describe this estimator and mean\n    squared error estimator. White and others (2024+, <doi:10.48550/arXiv.2402.03263>) describe the \n    applicability of this estimator to estimation of forest attributes and further assess the\n    estimator's properties. ",
    "version": "0.2.0",
    "maintainer": "Josh Yamamoto <joshuayamamoto5@gmail.com>",
    "url": "https://harvard-ufds.github.io/saeczi/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22220,
    "package_name": "samc",
    "title": "Spatial Absorbing Markov Chains",
    "description": "Implements functions for working with absorbing Markov chains. The\n    implementation is based on the framework described in \"Toward a unified\n    framework for connectivity that disentangles movement and mortality in space\n    and time\" by Fletcher et al. (2019) <doi:10.1111/ele.13333>, which applies\n    them to spatial ecology. This framework incorporates both resistance and \n    absorption with spatial absorbing Markov chains (SAMC) to provide several\n    short-term and long-term predictions for metrics related to connectivity in \n    landscapes. Despite the ecological context of the framework, this package\n    can be used in any application of absorbing Markov chains.",
    "version": "4.0.0",
    "maintainer": "Andrew Marx <ajm.rpackages@gmail.com>",
    "url": "https://andrewmarx.github.io/samc/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22222,
    "package_name": "sampbias",
    "title": "Evaluating Geographic Sampling Bias in Biological Collections",
    "description": "Evaluating the biasing impact of geographic features such as airports, cities, roads, rivers in datasets of coordinates based biological collection datasets, by Bayesian estimation of the parameters of a Poisson process. Enables also spatial visualization of sampling bias and includes a set of convenience functions for publication level plotting. Also available as 'shiny' app. The reference for the methodology is: Zizka et al. (2020) <doi:10.1111/ecog.05102>.",
    "version": "2.0.0",
    "maintainer": "Alexander Zizka <alexander.zizka@biologie.uni-marburg.de>",
    "url": "https://github.com/azizka/sampbias",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22233,
    "package_name": "samplesizelogisticcasecontrol",
    "title": "Sample Size and Power Calculations for Case-Control Studies",
    "description": "To determine sample size or power for case-control studies to be analyzed using logistic regression.",
    "version": "2.0.2",
    "maintainer": "William Wheeler <WheelerB@imsweb.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22267,
    "package_name": "sapo",
    "title": "Spatial Association of Different Types of Polygon",
    "description": "In ecology, spatial data is often represented using polygons. These\n  polygons can represent a variety of spatial entities, such as ecological\n  patches, animal home ranges, or gaps in the forest canopy.  Researchers often\n  need to determine if two spatial processes, represented by these polygons, are\n  independent of each other. For instance, they might want to test if the home\n  range of a particular animal species is influenced by the presence of a\n  certain type of vegetation.  To address this, Godoy et al. (2022)\n  (<doi:10.1016/j.spasta.2022.100695>) developed conditional Monte Carlo\n  tests. These tests are designed to assess spatial independence while taking\n  into account the shape and size of the polygons.",
    "version": "0.8.0",
    "maintainer": "Lucas da Cunha Godoy <lcgodoy@duck.com>",
    "url": "https://github.com/lcgodoy/sapo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22290,
    "package_name": "satellite",
    "title": "Handling and Manipulating Remote Sensing Data",
    "description": "Herein, we provide a broad variety of functions which are useful\n    for handling, manipulating, and visualizing satellite-based remote sensing \n    data. These operations range from mere data import and layer handling (eg \n    subsetting), over Raster* typical data wrangling (eg crop, extend), to more \n    sophisticated (pre-)processing tasks typically applied to satellite imagery \n    (eg atmospheric and topographic correction). This functionality is \n    complemented by a full access to the satellite layers' metadata at any \n    stage and the documentation of performed actions in a separate log file. \n    Currently available sensors include Landsat 4-5 (TM), 7 (ETM+), and 8 \n    (OLI/TIRS Combined), and additional compatibility is ensured for the Landsat \n    Global Land Survey data set. ",
    "version": "1.0.6",
    "maintainer": "Florian Detsch <fdetsch@web.de>",
    "url": "https://github.com/environmentalinformatics-marburg/satellite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22292,
    "package_name": "satres",
    "title": "Grouping Satellite Bands by Spectral and Spatial Resolution",
    "description": "Given raster files directly downloaded from various websites,\n    it generates a raster structure where it merges them if they are tiles\n    of the same scene and classifies them according to their spectral and\n    spatial resolution for easy access by name.",
    "version": "1.1.1",
    "maintainer": "Jose Samos <jsamos@ugr.es>",
    "url": "https://josesamos.github.io/satres/,\nhttps://github.com/josesamos/satres",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22300,
    "package_name": "sbde",
    "title": "Semiparametric Bayesian Density Estimation",
    "description": "Offers Bayesian semiparametric density estimation \n             and tail-index estimation for heavy tailed data, by\n             using a parametric, tail-respecting transformation\n             of the data to the unit interval and then modeling\n             the transformed data with a purely nonparametric\n             logistic Gaussian process density prior. Based on \n             Tokdar et al. (2022) <doi:10.1080/01621459.2022.2104727>.",
    "version": "1.0-2",
    "maintainer": "Surya Tokdar <surya.tokdar@duke.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22311,
    "package_name": "sc2sc",
    "title": "Spatial Transfer of Statistics among Spanish Census Sections",
    "description": "Transfers/imputes statistics among Spanish spatial polygons (census sections or postal code areas) from different moments in time (2001-2023) without need of spatial files, just linking statistics to the ID codes of the spatial units. \n    The data available in the census sections of a partition/division (cartography) into force in a moment of time is transferred to the census sections of another partition/division employing the geometric approach (also known as areal weighting or polygon overlay). \n    References: \n    Goerlich (2022) <doi:10.12842/WPIVIE_0322>.\n    Pavía and Cantarino (2017a, b) <doi:10.1111/gean.12112>, <doi:10.1016/j.apgeog.2017.06.021>.\n    Pérez and Pavía (2024a, b) <doi:10.4995/CARMA2024.2024.17796>, <doi:10.38191/iirr-jorr.24.057>.\n    Acknowledgements:\n    The authors wish to thank Consellería de Educación, Cultura, Universidades y Empleo, Generalitat Valenciana (grant CIACIO/2023/031), Consellería de Educación, Universidades y Empleo, Generalitat Valenciana (grant AICO/2021/257), Ministerio de Economía e Innovación (grant PID2021-128228NB-I00) and Fundación Mapfre for supporting this research.",
    "version": "0.0.1-18",
    "maintainer": "Jose M. Pavía <jose.m.pavia@uv.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22315,
    "package_name": "scBSP",
    "title": "A Fast Tool for Single-Cell Spatially Variable Genes\nIdentifications on Large-Scale Data",
    "description": "Identifying spatially variable genes is critical in linking molecular cell functions \n\twith tissue phenotypes. This package utilizes a granularity-based dimension-agnostic tool, \n\tsingle-cell big-small patch (scBSP), implementing sparse matrix operation and KD tree \n\tmethods for distance calculation, for the identification of spatially variable genes on \n\tlarge-scale data. The detailed description of this method is available at Wang, J. \n\tand Li, J. et al. 2023 (Wang, J. and Li, J. (2023), <doi:10.1038/s41467-023-43256-5>).",
    "version": "1.1.0",
    "maintainer": "Jinpu Li <castle.lee.f@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22316,
    "package_name": "scBio",
    "title": "Single Cell Genomics for Enhancing Cell Composition Inference\nfrom Bulk Genomics Data",
    "description": "Cellular population mapping (CPM) a deconvolution algorithm in which single-cell genomics is required in only one or a few samples, where in other samples of the same tissue, only bulk genomics is measured and the underlying fine resolution cellular heterogeneity is inferred.",
    "version": "0.1.6",
    "maintainer": "Amit Frishberg <amfrishberg@gmail.com>",
    "url": "https://github.com/amitfrish/scBio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22370,
    "package_name": "scSpatialSIM",
    "title": "A Point Pattern Simulator for Spatial Cellular Data",
    "description": "Single cell resolution data has been valuable in learning about tissue microenvironments and interactions between cells or spots. This package allows for the simulation of this level of data, be it single cell or ‘spots’, in both a univariate (single metric or cell type) and bivariate (2 or more metrics or cell types) ways. As more technologies come to marker, more methods will be developed to derive spatial metrics from the data which will require a way to benchmark methods against each other. Additionally, as the field currently stands, there is not a gold standard method to be compared against. We set out to develop an R package that will allow users to simulate point patterns that can be biologically informed from different tissue domains, holes, and varying degrees of clustering/colocalization. The data can be exported as spatial files and a summary file (like 'HALO'). <https://github.com/FridleyLab/scSpatialSIM/>.",
    "version": "0.1.3.4",
    "maintainer": "Fridley Lab <fridley.lab@moffitt.org>",
    "url": "https://github.com/FridleyLab/scSpatialSIM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22382,
    "package_name": "scaleAlign",
    "title": "Scale Alignment for Between-Items Multidimensional Rasch Family\nModels",
    "description": "Scale alignment is a new procedure for rescaling dimensions of \n    between-items multidimensional Rasch family models so that dimensions scores\n    can be compared directly (Feuerstahler & Wilson, 2019; under review) \n\t<doi:10.1111/jedm.12209>. This package includes functions for implementing \n    delta-dimensional alignment (DDA) and logistic regression alignment (LRA) \n    for dichotomous or polytomous data. This function also includes a wrapper \n\tfor models fit using the 'TAM' package.",
    "version": "1.0.0.0",
    "maintainer": "Leah Feuerstahler <lfeuerstahler@fordham.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22401,
    "package_name": "scattermore",
    "title": "Scatterplots with More Points",
    "description": "C-based conversion of large scatterplot data to rasters plus other \n             operations such as data blurring or data alpha blending. Speeds up \n             plotting of data with millions of points.",
    "version": "1.2",
    "maintainer": "Mirek Kratochvil <exa.exa@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22417,
    "package_name": "scdrake",
    "title": "A pipeline for droplet-based single-cell RNA-seq data secondary analysis implemented in the drake Make-like toolkit for R language",
    "description": "",
    "version": "1.7.1",
    "maintainer": "",
    "url": "https://github.com/bioinfocz/scdrake",
    "exports": [],
    "topics": ["bioconductor", "bioinformatics", "bioinformatics-analysis", "bioinformatics-pipeline", "drake", "r-language", "r-package", "single-cell-analysis", "single-cell-pipeline", "single-cell-rna-seq", "spatial-analysis", "spatial-transcriptomics", "visium-analysis"],
    "score": "NA",
    "stars": 15
  },
  {
    "id": 22428,
    "package_name": "schoRsch",
    "title": "Tools for Analyzing Factorial Experiments",
    "description": "Offers a helping hand to psychologists and other behavioral scientists who routinely deal with experimental data from factorial experiments. It includes several functions to format output from other R functions according to the style guidelines of the APA (American Psychological Association). This formatted output can be copied directly into manuscripts to facilitate data reporting. These features are backed up by a toolkit of several small helper functions, e.g., offering out-of-the-box outlier removal. The package lends its name to Georg \"Schorsch\" Schuessler, ingenious technician at the Department of Psychology III, University of Wuerzburg. For details on the implemented methods, see Roland Pfister and Markus Janczyk (2016) <doi: 10.20982/tqmp.12.2.p147>.",
    "version": "1.11",
    "maintainer": "Roland Pfister <mail@roland-pfister.net>",
    "url": "https://www.tqmp.org/RegularArticles/vol12-2/p147/index.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22469,
    "package_name": "scov",
    "title": "Structured Covariances Estimators for Pairwise and Spatial\nCovariates",
    "description": "Implements estimators for structured covariance matrices in the\n    presence of pairwise and spatial covariates.\n    Metodiev, Perrot-Dockès, Ouadah, Fosdick, Robin, Latouche & Raftery (2025)\n    <doi:10.48550/arXiv.2411.04520>.",
    "version": "0.1.2",
    "maintainer": "Martin Metodiev <m.metodiev@tutanota.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22517,
    "package_name": "sdcSpatial",
    "title": "Statistical Disclosure Control for Spatial Data",
    "description": "Privacy protected raster maps \n  can be created from spatial point data. Protection\n  methods include smoothing of dichotomous variables by de Jonge and de Wolf (2016) \n  <doi:10.1007/978-3-319-45381-1_9>, continuous variables by de Wolf and \n  de Jonge (2018) <doi:10.1007/978-3-319-99771-1_23>, suppressing \n  revealing values and a generalization of the quad tree method by \n  Suñé, Rovira, Ibáñez and Farré (2017) <doi:10.2901/EUROSTAT.C2017.001>.",
    "version": "0.6.1",
    "maintainer": "Edwin de Jonge <edwindjonge@gmail.com>",
    "url": "https://github.com/edwindj/sdcSpatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22528,
    "package_name": "sdsfun",
    "title": "Spatial Data Science Complementary Features",
    "description": "Wrapping and supplementing commonly used functions in the R ecosystem related to spatial data science, \n             while serving as a basis for other packages maintained by Wenbo Lv.",
    "version": "0.8.1",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/sdsfun/, https://github.com/stscl/sdsfun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22548,
    "package_name": "secr",
    "title": "Spatially Explicit Capture-Recapture",
    "description": "Functions to estimate the density and size of a spatially \n  distributed animal population sampled with an array of passive detectors, \n  such as traps, or by searching polygons or transects. Models incorporating \n  distance-dependent detection are fitted by maximizing the likelihood. \n  Tools are included for data manipulation and model selection.",
    "version": "5.3.0",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "url": "https://www.otago.ac.nz/density/,\nhttps://github.com/MurrayEfford/secr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22549,
    "package_name": "secrdesign",
    "title": "Sampling Design for Spatially Explicit Capture-Recapture",
    "description": "Tools for designing spatially explicit capture-recapture studies of animal populations. This is primarily a simulation manager for package 'secr'. Extensions in version 2.5.0 include costing and evaluation of detector spacing.",
    "version": "2.10.1",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "url": "https://www.otago.ac.nz/density/,\nhttps://github.com/MurrayEfford/secrdesign/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22554,
    "package_name": "secrlinear",
    "title": "Spatially Explicit Capture-Recapture for Linear Habitats",
    "description": "Tools for spatially explicit capture-recapture analysis of animal populations in linear habitats, extending package 'secr'.",
    "version": "1.2.5",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "url": "https://www.otago.ac.nz/density/,\nhttps://github.com/MurrayEfford/secrlinear/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22558,
    "package_name": "sedMaps",
    "title": "Visualise, manipulate and access sediment and disturbance data.",
    "description": "Visualise, manipulate and access sediment and disturbance data.",
    "version": "0.0.1",
    "maintainer": "",
    "url": "https://github.com/annakrystalli/sedMaps",
    "exports": [],
    "topics": ["data-access", "data-visualization", "gis", "marine-data", "r", "sedimentary", "shinyapps", "spatial"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 22580,
    "package_name": "segmetric",
    "title": "Metrics for Assessing Segmentation Accuracy for Geospatial Data",
    "description": "A system that computes metrics to assess the segmentation \n    accuracy of geospatial data. These metrics calculate the discrepancy \n    between segmented and reference objects, and indicate the segmentation \n    accuracy. For more details on choosing evaluation metrics, we \n    suggest seeing Costa et al. (2018) <doi:10.1016/j.rse.2017.11.024> and \n    Jozdani et al. (2020) <doi:10.1016/j.isprsjprs.2020.01.002>.",
    "version": "0.3.0",
    "maintainer": "Michelle Picoli <mipicoli@gmail.com>",
    "url": "https://michellepicoli.github.io/segmetric/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22596,
    "package_name": "selectiveInference",
    "title": "Tools for Post-Selection Inference",
    "description": "New tools for post-selection inference, for use with forward\n    stepwise regression, least angle regression, the lasso, and the many means\n    problem. The lasso function implements Gaussian, logistic and Cox survival\n    models.",
    "version": "1.2.5",
    "maintainer": "Rob Tibshirani <tibs@stanford.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22630,
    "package_name": "semnar",
    "title": "Constructing and Interacting with Databases of Presentations",
    "description": "Provides methods for constructing and maintaining a database of presentations in R. The presentations are either ones that the user gives or gave or presentations at a particular event or event series. The package also provides a plot method for the interactive mapping of the presentations using 'leaflet' by grouping them according to country, city, year and other presentation attributes. The markers on the map come with popups providing presentation details (title, institution, event, links to materials and events, and so on).",
    "version": "0.8.2",
    "maintainer": "Ioannis Kosmidis <ioannis.kosmidis@warwick.ac.uk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22731,
    "package_name": "sfarrow",
    "title": "Read/Write Simple Feature Objects ('sf') with 'Apache' 'Arrow'",
    "description": "Support for reading/writing simple feature ('sf') spatial objects from/to 'Parquet' files. 'Parquet' files are an open-source, column-oriented data storage format from Apache (<https://parquet.apache.org/>), now popular across programming languages. This implementation converts simple feature list geometries into well-known binary format for use by 'arrow', and coordinate reference system information is maintained in a standard metadata format.",
    "version": "0.4.1",
    "maintainer": "Chris Jochem <w.c.jochem@soton.ac.uk>",
    "url": "https://github.com/wcjochem/sfarrow,\nhttps://wcjochem.github.io/sfarrow/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22733,
    "package_name": "sfcentral",
    "title": "Spatial Centrality and Dispersion Statistics",
    "description": "Compute centrographic statistics (central points, standard \n    distance, standard deviation ellipse, standard deviation box) for \n    observations taken at point locations in 2D or 3D. The 'sfcentral' library \n    was inspired in 'aspace' package but conceived to be used in a spatial\n    'tidyverse' context.",
    "version": "0.1.3",
    "maintainer": "Gabriel V. Gaona <gabo@gavg712.com>",
    "url": "https://gavg712.gitlab.io/sfcentral/,\nhttps://gitlab.com/gavg712/sfcentral",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22734,
    "package_name": "sfclust",
    "title": "Bayesian Spatial Functional Clustering",
    "description": "Bayesian clustering of spatial regions with similar functional shapes using\n    spanning trees and latent Gaussian models. The method enforces spatial contiguity\n    within clusters and supports a wide range of latent Gaussian models, including\n    non-Gaussian likelihoods, via the R-INLA framework. The algorithm is based on Zhong,\n    R., Chacón-Montalván, E. A., and Moraga, P. (2024) <doi:10.48550/arXiv.2407.12633>,\n    extending the approach of Zhang, B., Sang, H., Luo, Z. T., and Huang, H. (2023)\n    <doi:10.1214/22-AOAS1643>. The package includes tools for model fitting, convergence\n    diagnostics, visualization, and summarization of clustering results.",
    "version": "1.0.1",
    "maintainer": "Erick A. Chacón-Montalván <erick.chaconmontalvan@kaust.edu.sa>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22740,
    "package_name": "sfdep",
    "title": "Spatial Dependence for Simple Features",
    "description": "An interface to 'spdep' to integrate with 'sf' objects and the 'tidyverse'.",
    "version": "0.2.4.9000",
    "maintainer": "",
    "url": "https://github.com/JosiahParry/sfdep",
    "exports": [],
    "topics": ["r-spatial", "rstats", "spatial"],
    "score": "NA",
    "stars": 139
  },
  {
    "id": 22743,
    "package_name": "sfhelper",
    "title": "Repair Functions for 'sf' Package Objects",
    "description": "A group of functions that support the 'sf' package, focused primarily on repairing polygons that break when re-projected.",
    "version": "0.2.2.0",
    "maintainer": "Mark Ravina <mark.ravina@austin.utexas.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22746,
    "package_name": "sfislands",
    "title": "Streamlines the Process of Fitting Areal Spatial Models",
    "description": "Helpers for addressing the issue of disconnected spatial units. \n    It allows for convenient adding and removal of neighbourhood connectivity between areal units prior to modelling, with the visual aid of maps.\n    Post-modelling, it reduces the human workload for extracting, tidying and mapping predictions from areal models.",
    "version": "1.1.2",
    "maintainer": "Kevin Horan <kevin.horan.2021@mumail.ie>",
    "url": "https://github.com/horankev/sfislands,\nhttps://horankev.github.io/sfislands/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22753,
    "package_name": "sftrack",
    "title": "Modern Classes for Tracking and Movement Data",
    "description": "Modern classes for tracking and movement data, building\n    on 'sf' spatial infrastructure, and early theoretical work from\n    Turchin (1998, ISBN: 9780878938476), and Calenge et al. (2009)\n    <doi:10.1016/j.ecoinf.2008.10.002>. Tracking data are series of\n    locations with at least 2-dimensional spatial coordinates (x,y), a\n    time index (t), and individual identification (id) of the object\n    being monitored; movement data are made of trajectories, i.e. the\n    line representation of the path, composed by steps (the\n    straight-line segments connecting successive locations). 'sftrack'\n    is designed to handle movement of both living organisms and\n    inanimate objects.",
    "version": "0.5.4",
    "maintainer": "Mathieu Basille <mathieu@basille.org>",
    "url": "https://mablab.org/sftrack/, https://github.com/mablab/sftrack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22754,
    "package_name": "sfweight",
    "title": "What the Package Does (One Line, Title Case)",
    "description": "What the package does (one paragraph).",
    "version": "0.0.0.9002",
    "maintainer": "",
    "url": "https://github.com/JosiahParry/sfweight",
    "exports": [],
    "topics": ["gis", "rspatial"],
    "score": "NA",
    "stars": 59
  },
  {
    "id": 22755,
    "package_name": "sfx",
    "title": "Extra functions for Simple Features manipulation",
    "description": "Filter, join, measure, and other functions to extend the 'sf'",
    "version": "0.0.1",
    "maintainer": "Luke Smith <lukedansmi@sbcglobal.net>",
    "url": "https://github.com/seasmith/sfx",
    "exports": [],
    "topics": ["r", "r-spatial", "spatial"],
    "score": "NA",
    "stars": 13
  },
  {
    "id": 22758,
    "package_name": "sgapi",
    "title": "Aid Querying 'nomis' and 'Office for National Statistics Open\nGeography' APIs",
    "description": "Facilitates extraction of geospatial data from the 'Office for National Statistics Open Geography' and 'nomis' Application Programming Interfaces (APIs). Simplifies process of querying 'nomis' datasets <https://www.nomisweb.co.uk/> and extracting desired datasets in dataframe format. Extracts area shapefiles at chosen resolution from 'Office for National Statistics Open Geography' <https://geoportal.statistics.gov.uk/>.",
    "version": "1.1.2",
    "maintainer": "Michael Stocks <sgapi.orhub@gmail.com>",
    "url": "https://defra-data-science-centre-of-excellence.github.io/sgapi/,\nhttps://github.com/Defra-Data-Science-Centre-of-Excellence/sgapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22763,
    "package_name": "sgeostat",
    "title": "An Object-Oriented Framework for Geostatistical Modeling in S+",
    "description": "An Object-oriented Framework for Geostatistical Modeling in S+ \n  containing functions for variogram estimation, variogram fitting and kriging\n  as well as some plot functions. Written entirely in S, therefore works only\n  for small data sets in acceptable computing time.",
    "version": "1.0-27",
    "maintainer": "Albrecht Gebhardt <albrecht.gebhardt@aau.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22775,
    "package_name": "sgs",
    "title": "Sparse-Group SLOPE: Adaptive Bi-Level Selection with FDR Control",
    "description": "Implementation of Sparse-group SLOPE (SGS) (Feser and Evangelou (2023) <doi:10.48550/arXiv.2305.09467>) models. Linear and logistic regression models are supported, both of which can be fit using k-fold cross-validation. Dense and sparse input matrices are supported. In addition, a general Adaptive Three Operator Splitting (ATOS) (Pedregosa and Gidel (2018) <doi:10.48550/arXiv.1804.02339>) implementation is provided. Group SLOPE (gSLOPE) (Brzyski et al. (2019) <doi:10.1080/01621459.2017.1411269>) and group-based OSCAR models (Feser and Evangelou (2024) <doi:10.48550/arXiv.2405.15357>) are also implemented. All models are available with strong screening rules (Feser and Evangelou (2024) <doi:10.48550/arXiv.2405.15357>) for computational speed-up.",
    "version": "0.3.9",
    "maintainer": "Fabio Feser <ff120@ic.ac.uk>",
    "url": "https://github.com/ff1201/sgs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22776,
    "package_name": "sgsR",
    "title": "Structurally Guided Sampling",
    "description": "Structurally guided sampling (SGS) approaches for airborne laser scanning (ALS; LIDAR). Primary functions provide means \n    to generate data-driven stratifications & methods for allocating samples. Intermediate functions for calculating and extracting important information \n    about input covariates and samples are also included. Processing outcomes are intended to help forest and environmental management\n    practitioners better optimize field sample placement as well as assess and augment existing sample networks in the context of data\n    distributions and conditions. ALS data is the primary intended use case, however any rasterized remote sensing data can be used, \n    enabling data-driven stratifications and sampling approaches.",
    "version": "1.5.0",
    "maintainer": "Tristan RH Goodbody <goodbody.t@gmail.com>",
    "url": "https://github.com/tgoodbody/sgsR,\nhttps://tgoodbody.github.io/sgsR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22788,
    "package_name": "shapefiles",
    "title": "Read and Write ESRI Shapefiles",
    "description": "Functions to read and write ESRI shapefiles.",
    "version": "0.7.2",
    "maintainer": "Ben Stabler <benstabler@yahoo.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22800,
    "package_name": "sharpshootR",
    "title": "A Soil Survey Toolkit",
    "description": "A collection of data processing, visualization, and export functions to support soil survey operations. Many of the functions build on the `SoilProfileCollection` S4 class provided by the aqp package, extending baseline visualization to more elaborate depictions in the context of spatial and taxonomic data. While this package is primarily developed by and for the USDA-NRCS, in support of the National Cooperative Soil Survey, the authors strive for generalization sufficient to support any soil survey operation. Many of the included functions are used by the SoilWeb suite of websites and movile applications. These functions are provided here, with additional documentation, to enable others to replicate high quality versions of these figures for their own purposes.",
    "version": "2.4",
    "maintainer": "Dylan Beaudette <dylan.beaudette@usda.gov>",
    "url": "https://github.com/ncss-tech/sharpshootR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22802,
    "package_name": "shattering",
    "title": "Estimate the Shattering Coefficient for a Particular Dataset",
    "description": "The Statistical Learning Theory (SLT) provides the theoretical background to ensure that a supervised algorithm generalizes the mapping f:X -> Y given f is selected from its search space bias F. This formal result depends on the Shattering coefficient function N(F,2n) to upper bound the empirical risk minimization principle, from which one can estimate the necessary training sample size to ensure the probabilistic learning convergence and, most importantly, the characterization of the capacity of F, including its under and overfitting abilities while addressing specific target problems. In this context, we propose a new approach to estimate the maximal number of hyperplanes required to shatter a given sample, i.e., to separate every pair of points from one another, based on the recent contributions by Har-Peled and Jones in the dataset partitioning scenario, and use such foundation to analytically compute the Shattering coefficient function for both binary and multi-class problems. As main contributions, one can use our approach to study the complexity of the search space bias F, estimate training sample sizes, and parametrize the number of hyperplanes a learning algorithm needs to address some supervised task, what is specially appealing to deep neural networks. Reference: de Mello, R.F. (2019) \"On the Shattering Coefficient of Supervised Learning Algorithms\" <arXiv:1911.05461>; de Mello, R.F., Ponti, M.A. (2018, ISBN: 978-3319949888) \"Machine Learning: A Practical Approach on the Statistical Learning Theory\".",
    "version": "1.0.7",
    "maintainer": "Rodrigo F. de Mello <mellorf@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22804,
    "package_name": "shelltrace",
    "title": "Bivalve Growth and Trace Element Accumulation Model",
    "description": "\n    Contains all the formulae of the growth and trace element uptake model described in the equally-named\n    Geoscientific Model Development paper (de Winter, 2017, <doi:10.5194/gmd-2017-137>). The model takes as input a file with X- and Y-coordinates of digitized\n    growth increments recognized on a longitudinal cross section through the bivalve shell, as well as a BMP file of an elemental map of the\n    cross section surface with chemically distinct phases separated by phase analysis. It proceeds by a step-by-step process described in\n    the paper, by which digitized growth increments are used to calculate changes in shell height, shell thickness, shell volume, shell mass\n    and shell growth rate through the bivalve's life time. Then, results of this growth modelling are combined with the trace element mapping\n    results to trace the incorporation of trace elements into the bivalve shell. Results of various modelling parameters can be exported in\n    the form of XLSX files.",
    "version": "3.5.1",
    "maintainer": "Niels J. de Winter <niels.de.winter@vub.be>",
    "url": "https://github.com/nielsjdewinter/ShellTrace,\nhttps://doi.org/10.5194/gmd-2017-137-supplement,\nhttp://nidewint.wixsite.com/nielsdewinter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22824,
    "package_name": "shiny.reglog",
    "title": "Optional Login and Registration Module System for ShinyApps",
    "description": "RegLog system provides a set of shiny modules to handle register\n   procedure for your users, alongside with login, edit credentials and\n   password reset functionality. \n   It provides support for popular SQL databases\n   and optionally googlesheet-based database for easy setup. For email sending\n   it provides support for 'emayili' and 'gmailr' backends. Architecture makes \n   customizing usability pretty straightforward.\n   The authentication system created \n   with shiny.reglog is designed to be optional: user don't need to be logged-in \n   to access your application, but when logged-in the user data can be used \n   to read from and write to relational databases.",
    "version": "0.5.2",
    "maintainer": "Michal Kosinski <kosinski.mich@gmail.com>",
    "url": "https://statismike.github.io/shiny.reglog/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 22962,
    "package_name": "shp2graph",
    "title": "Convert a 'SpatialLinesDataFrame' -Class Object to an\n'igraph'-Class Object",
    "description": "Functions for converting and processing network data from a\n        'SpatialLinesDataFrame' -Class object to an 'igraph'-Class object.",
    "version": "1-0",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23006,
    "package_name": "siland",
    "title": "Spatial Influence of Landscape",
    "description": "Method to estimate the spatial influence scales of landscape variables on a response variable. The method is based on Chandler and Hepinstall-Cymerman (2016) Estimating the spatial scales of landscape effects on abundance, Landscape ecology, 31: 1383-1394, <doi:10.1007/s10980-016-0380-z>.",
    "version": "3.0.2",
    "maintainer": "Martin Olivier <olivier.martin@inrae.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23011,
    "package_name": "sim2Dpredictr",
    "title": "Simulate Outcomes Using Spatially Dependent Design Matrices",
    "description": "Provides tools for simulating spatially dependent predictors (continuous or binary),\n    which are used to generate scalar outcomes in a (generalized) linear model framework. Continuous\n    predictors are generated using traditional multivariate normal distributions or Gauss Markov random\n    fields with several correlation function approaches (e.g., see Rue (2001) <doi:10.1111/1467-9868.00288>\n    and Furrer and Sain (2010) <doi:10.18637/jss.v036.i10>), while binary predictors are generated using\n    a Boolean model (see Cressie and Wikle (2011, ISBN: 978-0-471-69274-4)). Parameter vectors \n\texhibiting spatial clustering can also be easily specified by the user.  ",
    "version": "0.1.1",
    "maintainer": "Justin Leach <jleach@uab.edu>",
    "url": "https://github.com/jmleach-bst/sim2Dpredictr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23013,
    "package_name": "simCAT",
    "title": "Implements Computerized Adaptive Testing Simulations",
    "description": "Computerized Adaptive Testing simulations with dichotomous and polytomous items. Selects items with Maximum Fisher Information method or randomly, with or without constraints (content balancing and item exposure control). Evaluates the simulation results in terms of precision, item exposure, and test length. Inspired on Magis & Barrada (2017) <doi:10.18637/jss.v076.c01>.",
    "version": "1.0.1",
    "maintainer": "Alexandre Jaloto <alexandrejaloto@gmail.com>",
    "url": "https://github.com/alexandrejaloto/simCAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23021,
    "package_name": "simIC",
    "title": "Simulate and Analyze Interval- and Mixed-Censored Survival Data",
    "description": "Provides tools to simulate and analyze survival data with interval-, \n  left-, right-, and uncensored observations under common parametric distributions, \n  including \"Weibull\", \"Exponential\", \"Log-Normal\", \"Log-Logistic\", \"Gamma\", \n  \"Gompertz\", \"Normal\", \"Logistic\", and \"EMV\". The package supports both direct \n  maximum likelihood estimation and imputation-based methods, making it suitable \n  for methodological research, simulation benchmarking, and teaching. A web-based \n  companion app is also available for demonstration purposes.",
    "version": "0.1.0",
    "maintainer": "Jayanthi Arasan <jayanthi@upm.edu.my>",
    "url": "https://github.com/jayarasan/simIC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23048,
    "package_name": "simfinapi",
    "title": "Accessing 'SimFin' Data",
    "description": "Through simfinapi, you can intuitively access the 'SimFin'\n    Web-API (<https://www.simfin.com/>) to make 'SimFin' data easily\n    available in R. To obtain an 'SimFin' API key (and thus to use this\n    package), you need to register at <https://app.simfin.com/login>.",
    "version": "1.0.1",
    "maintainer": "Matthias Gomolka <matthias.gomolka@posteo.de>",
    "url": "https://github.com/matthiasgomolka/simfinapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23054,
    "package_name": "simitation",
    "title": "Simplified Simulations",
    "description": "Provides tools for generating and analyzing simulation studies. Users may easily specify all terms of a simulation study, often in a single line of code. Common univariate and bivariate methods, such as t tests, proportions tests, and chi squared tests, are integrated. Multivariate studies involving linear or logistic regression may also be specified with symbolic inputs. The simulation studies generate data for n observations in each of B experiments. Analyses of each experiment are integrated, and empirical results across the experiments are also provided.",
    "version": "0.0.7",
    "maintainer": "Srivastav Budugutta <sb4788@columbia.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23062,
    "package_name": "simodels",
    "title": "Flexible Framework for Developing Spatial Interaction Models",
    "description": "Develop spatial interaction models (SIMs).  SIMs predict the\n    amount of interaction, for example number of trips per day, between\n    geographic entities representing trip origins and destinations.\n    Contains functions for creating origin-destination datasets\n    from geographic input datasets and calculating movement between\n    origin-destination pairs with constrained, production-constrained,\n    and attraction-constrained models (Wilson 1979) <doi:10.1068/a030001>.",
    "version": "0.2.0",
    "maintainer": "Robin Lovelace <rob00x@gmail.com>",
    "url": "https://github.com/robinlovelace/simodels,\nhttps://robinlovelace.github.io/simodels/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23113,
    "package_name": "sinar",
    "title": "Conditional Least Squared (CLS) Method for the Model SINAR(1,1)",
    "description": "Implementation of the Conditional Least Square (CLS) estimates and\n    its covariance matrix for the first-order spatial integer-valued\n    autoregressive model (SINAR(1,1)) proposed by Ghodsi (2012)\n    <doi:10.1080/03610926.2011.560739>.",
    "version": "0.1.0",
    "maintainer": "Gilberto P. Sassi <sassi.pereira.gilberto@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23125,
    "package_name": "siplab",
    "title": "Spatial Individual-Plant Modelling",
    "description": "A platform for computing competition indices and experimenting\n    with spatially explicit individual-based vegetation models.",
    "version": "1.6",
    "maintainer": "Oscar Garcia <garcia@dasometrics.net>",
    "url": "https://github.com/ogarciav/siplab/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23134,
    "package_name": "sistec",
    "title": "Tools to Analyze 'Sistec' Datasets",
    "description": "The Brazilian system for diploma registration and validation on technical and superior\n    courses are managing by 'Sistec' platform, see <https://sistec.mec.gov.br/>. This package provides \n    tools for Brazilian institutions to update the student's registration and make data analysis \n    about their situation, retention and drop out.",
    "version": "0.2.0",
    "maintainer": "Samuel Macêdo <samuelmacedo@recife.ifpe.edu.br>",
    "url": "https://github.com/r-ifpe/sistec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23151,
    "package_name": "sizeMat",
    "title": "Estimate Size at Sexual Maturity",
    "description": "Estimate morphometric and gonadal size at sexual maturity for organisms, usually fish and invertebrates. It includes methods for classification based on relative growth (using principal components analysis, hierarchical clustering, discriminant analysis), logistic regression (Frequentist or Bayes), parameters estimation and some basic plots.",
    "version": "1.1.2",
    "maintainer": "Josymar Torrejon-Magallanes <ejosymart@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23174,
    "package_name": "skiftiTools",
    "title": "Tools and Operations for Reading, Writing, Viewing, and\nManipulating SKIFTI Files",
    "description": "SKIFTI files contain brain imaging data in coordinates across Tract Based Spatial Statistics (TBSS) skeleton, which \n    represent the brain white matter intensity values. \n    'skiftiTools' provides a unified environment for reading, writing, \n    visualizing and manipulating SKIFTI-format data. It supports the \"subsetting\", \n    \"concatenating\", and using data as data.frame for R statistical functions. The SKIFTI data is structured for convenient access to the data and metadata,\n    and includes support for visualizations. For more information see Merisaari et al. (2024) <doi:10.57736/87d2-0608>.",
    "version": "0.1.0",
    "maintainer": "Ilkka Suuronen <ilksuu@utu.fi>",
    "url": "https://github.com/haanme/skiftiTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23194,
    "package_name": "sld",
    "title": "Estimation and Use of the Quantile-Based Skew Logistic\nDistribution",
    "description": "The skew logistic distribution is a quantile-defined generalisation\n of the logistic distribution (van Staden and King 2015).  Provides random \n numbers, quantiles, probabilities, densities and density quantiles for the distribution.\n It provides Quantile-Quantile plots and method of L-Moments estimation \n (including asymptotic standard errors) for the distribution.",
    "version": "1.0.1",
    "maintainer": "Robert King <Robert.King.Newcastle@gmail.com>",
    "url": "https://github.com/newystats/SLD/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23199,
    "package_name": "slendr",
    "title": "A Simulation Framework for Spatiotemporal Population Genetics",
    "description": "A framework for simulating spatially explicit genomic data which\n    leverages real cartographic information for programmatic and visual encoding\n    of spatiotemporal population dynamics on real geographic landscapes. Population\n    genetic models are then automatically executed by the 'SLiM' software by Haller\n    et al. (2019) <doi:10.1093/molbev/msy228> behind the scenes, using a custom\n    built-in simulation 'SLiM' script. Additionally, fully abstract spatial models\n    not tied to a specific geographic location are supported, and users can also\n    simulate data from standard, non-spatial, random-mating models. These can be\n    simulated either with the 'SLiM' built-in back-end script, or using an efficient\n    coalescent population genetics simulator 'msprime' by Baumdicker et al. (2022)\n    <doi:10.1093/genetics/iyab229> with a custom-built 'Python' script bundled with the\n    R package. Simulated genomic data is saved in a tree-sequence format and can be\n    loaded, manipulated, and summarised using tree-sequence functionality via an R\n    interface to the 'Python' module 'tskit' by Kelleher et al. (2019)\n    <doi:10.1038/s41588-019-0483-y>. Complete model configuration, simulation and\n    analysis pipelines can be therefore constructed without a need to leave the R\n    environment, eliminating friction between disparate tools for population genetic\n    simulations and data analysis.",
    "version": "1.3.0",
    "maintainer": "Martin Petr <contact@bodkan.net>",
    "url": "https://github.com/bodkan/slendr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23208,
    "package_name": "slippymath",
    "title": "Slippy Map Tile Tools",
    "description": "Provides functions for performing common tasks when working with\n  slippy map tile service APIs e.g. Google maps, Open Street Map, Mapbox, Stamen,\n  among others. Functionality includes converting from latitude and longitude to\n  tile numbers, determining tile bounding boxes, and compositing tiles to a\n  georeferenced raster image.",
    "version": "0.3.1",
    "maintainer": "Miles McBain <miles.mcbain@gmail.com>",
    "url": "https://www.github.com/milesmcbain/slippymath",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23223,
    "package_name": "smacpod",
    "title": "Statistical Methods for the Analysis of Case-Control Point Data",
    "description": "Statistical methods for analyzing case-control point data.  Methods include the ratio of kernel densities, the difference in K Functions, the spatial scan statistic, and q nearest neighbors of cases.",
    "version": "2.6.4",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23232,
    "package_name": "smartmap",
    "title": "Smartly Create Maps from R Objects",
    "description": "Preview spatial data as 'leaflet' maps with minimal\n  effort. smartmap is optimized for interactive use and distinguishes itself \n  from similar packages because it does not need real spatial ('sp' or 'sf')\n  objects an input; instead, it tries to automatically coerce everything that \n  looks like spatial data to sf objects or leaflet maps. It - for example -  \n  supports direct mapping of: a vector containing a single coordinate pair,\n  a two column matrix, a data.frame with longitude and latitude columns, or\n  the path or URL to a (possibly compressed) 'shapefile'.",
    "version": "0.1.1",
    "maintainer": "Stefan Fleck <stefan.b.fleck@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23238,
    "package_name": "smbinning",
    "title": "Scoring Modeling and Optimal Binning",
    "description": "A set of functions to build a scoring model from beginning to end, leading the user\n\tto follow an efficient and organized development process, reducing significantly the time\n\tspent on data exploration, variable selection, feature engineering, binning and model selection \n\tamong other recurrent tasks. \n\tThe package also incorporates monotonic and customized binning, scaling capabilities that \n\ttransforms logistic coefficients into points for a better business understanding and \n\tcalculates and visualizes classic performance metrics of a classification model.",
    "version": "0.9",
    "maintainer": "Herman Jopia <hjopia@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23246,
    "package_name": "smerc",
    "title": "Statistical Methods for Regional Counts",
    "description": "Implements statistical methods for analyzing the counts of areal data, with a focus on the detection of spatial clusters and clustering.  The package has a heavy emphasis on spatial scan methods, which were first introduced by Kulldorff and Nagarwalla (1995) <doi:10.1002/sim.4780140809> and Kulldorff (1997) <doi:10.1080/03610929708831995>.",
    "version": "1.8.4",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23248,
    "package_name": "smfishHmrf",
    "title": "Hidden Markov Random Field for Spatial Transcriptomic Data",
    "description": "Discovery of spatial patterns with Hidden Markov Random Field. This package is designed for spatial transcriptomic data and single molecule fluorescent in situ hybridization (FISH) data such as sequential fluorescence in situ hybridization (seqFISH) and multiplexed error-robust fluorescence in situ hybridization (MERFISH). The methods implemented in this package are described in Zhu et al. (2018) <doi:10.1038/nbt.4260>.",
    "version": "0.1",
    "maintainer": "Qian Zhu <zqian@jimmy.harvard.edu>",
    "url": "https://bitbucket.org/qzhudfci/smfishhmrf-r/src/master/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23252,
    "package_name": "smile",
    "title": "Spatial Misalignment: Interpolation, Linkage, and Estimation",
    "description": "Provides functions to estimate, predict and interpolate areal\n        data. For estimation and prediction we assume areal data is an average\n        of an underlying continuous spatial process as in Moraga et\n        al. (2017) <doi:10.1016/j.spasta.2017.04.006>, Johnson et al. (2020)\n        <doi:10.1186/s12942-020-00200-w>, and Wilson and Wakefield (2020)\n        <doi:10.1093/biostatistics/kxy041>. The interpolation methodology is\n        (mostly) based on Goodchild and Lam (1980, ISSN:01652273).",
    "version": "1.1.0",
    "maintainer": "Lucas da Cunha Godoy <lcgodoy@duck.com>",
    "url": "https://lcgodoy.me/smile/, https://github.com/lcgodoy/smile/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23269,
    "package_name": "smoothie",
    "title": "Two-Dimensional Field Smoothing",
    "description": "Perform two-dimensional smoothing for spatial fields using FFT and the convolution theorem (see Gilleland 2013, <doi:10.5065/D61834G2>).",
    "version": "1.0-4",
    "maintainer": "Eric Gilleland <eric.gilleland@colostate.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23275,
    "package_name": "smosr",
    "title": "Acquire and Explore BEC-SMOS L4 Soil Moisture Data in R",
    "description": "Provides functions that automate accessing, downloading and exploring Soil Moisture\n    and Ocean Salinity (SMOS) Level 4 (L4) data developed by Barcelona Expert Center (BEC). \n    Particularly, it includes functions to search for, acquire, extract, and plot BEC-SMOS L4 soil \n    moisture data downscaled to ~1 km spatial resolution. Note that SMOS is one of Earth Explorer \n    Opportunity missions by the European Space Agency (ESA). More information about SMOS  \n    products can be found at <https://earth.esa.int/eogateway/missions/smos/data>.",
    "version": "1.0.1",
    "maintainer": "Tatiana A. Shestakova <tasha.work24@gmail.com>",
    "url": "https://github.com/tshestakova/smosr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23280,
    "package_name": "sms",
    "title": "Spatial Microsimulation",
    "description": "Produce small area population estimates by fitting census data to\n    survey data.",
    "version": "2.3.1",
    "maintainer": "Dimitris Kavroudakis <dimitris123@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23293,
    "package_name": "snapKrig",
    "title": "Fast Kriging and Geostatistics on Grids with Kronecker\nCovariance",
    "description": "Geostatistical modeling and kriging with\n    gridded data using spatially separable covariance functions (Kronecker\n    covariances). Kronecker products in these models provide shortcuts for\n    solving large matrix problems in likelihood and conditional mean,\n    making 'snapKrig' computationally efficient with large grids. The package\n    supplies its own S3 grid object class, and a host of methods including\n    plot, print, Ops, square bracket replace/assign, and more. Our computational\n    methods are described in Koch, Lele, Lewis (2020) <doi:10.7939/r3-g6qb-bq70>.",
    "version": "0.0.2",
    "maintainer": "Dean Koch <dkoch@ualberta.ca>",
    "url": "https://github.com/deankoch/snapKrig",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23303,
    "package_name": "snic",
    "title": "Superpixel Segmentation with the Simple Non-Iterative Clustering\nAlgorithm",
    "description": "Implements the Simple Non-Iterative Clustering algorithm for \n    superpixel segmentation of multi-band images, as introduced by Achanta \n    and Susstrunk (2017) <doi:10.1109/CVPR.2017.520>. Supports both standard \n    image arrays and geospatial raster objects, with a design that can be \n    extended to other spatial data frameworks. The algorithm groups adjacent \n    pixels into compact, coherent regions based on spectral similarity and \n    spatial proximity. A high-performance implementation supports images \n    with arbitrary spectral bands.",
    "version": "0.6.1",
    "maintainer": "Rolf Simoes <rolfsimoes@gmail.com>",
    "url": "https://github.com/rolfsimoes/snic,\nhttps://rolfsimoes.github.io/snic/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23334,
    "package_name": "socratadata",
    "title": "Explore Socrata Data with Ease",
    "description": "Provides an interface to search, read, query, and retrieve metadata for \n    datasets hosted on 'Socrata' open data portals. Supports all 'Socrata' data types, \n    including spatial data returned as 'sf' objects. ",
    "version": "0.1.1",
    "maintainer": "Ryan Zomorrodi <rzomor2@uic.edu>",
    "url": "https://ryanzomorrodi.github.io/socratadata/,\nhttps://github.com/ryanzomorrodi/socratadata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23336,
    "package_name": "sodavis",
    "title": "SODA: Main and Interaction Effects Selection for Logistic\nRegression, Quadratic Discriminant and General Index Models",
    "description": "Variable and interaction selection are essential to classification in high-dimensional setting. In this package, we provide the implementation of SODA procedure, which is a forward-backward algorithm that selects both main and interaction effects under logistic regression and quadratic discriminant analysis. We also provide an extension, S-SODA, for dealing with the variable selection problem for semi-parametric models with continuous responses.",
    "version": "1.2",
    "maintainer": "Yang Li <yangli.stat@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23360,
    "package_name": "som.nn",
    "title": "Topological k-NN Classifier Based on Self-Organising Maps",
    "description": "A topological version of k-NN: An abstract model is build\n             as 2-dimensional self-organising map. Samples of unknown\n             class are predicted by mapping them on the SOM and analysing\n             class membership of neurons in the neighbourhood.",
    "version": "1.4.4",
    "maintainer": "Andreas Dominik <andreas.dominik@mni.thm.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23379,
    "package_name": "sotu",
    "title": "United States Presidential State of the Union Addresses",
    "description": "The President of the United States is constitutionally obligated to provide\n  a report known as the 'State of the Union'. The report summarizes the current challenges\n  facing the country and the president's upcoming legislative agenda. While historically\n  the State of the Union was often a written document, in recent decades it has always\n  taken the form of an oral address to a joint session of the United States Congress.\n  This package provides the raw text from every such address with the intention of\n  being used for meaningful examples of text analysis in R. The corpus is well suited\n  to the task as it is historically important, includes material intended to be read\n  and material intended to be spoken, and it falls in the public domain. As the corpus\n  spans over two centuries it is also a good test of how well various methods hold up\n  to the idiosyncrasies of historical texts. Associated data about each address, such\n  as the year, president, party, and format, are also included.",
    "version": "1.0.4",
    "maintainer": "Taylor B. Arnold <tarnold2@richmond.edu>",
    "url": "https://github.com/statsmaths/sotu/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23388,
    "package_name": "sp",
    "title": "Classes and Methods for Spatial Data",
    "description": "Classes and methods for spatial\n  data; the classes document where the spatial location information\n  resides, for 2D or 3D data. Utility functions are provided, e.g. for\n  plotting data as maps, spatial selection, as well as methods for\n  retrieving coordinates, for subsetting, print, summary, etc. From this\n  version, 'rgdal', 'maptools', and 'rgeos' are no longer used at all,\n  see <https://r-spatial.org/r/2023/05/15/evolution4.html> for details.",
    "version": "2.2-0",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://github.com/edzer/sp/ https://edzer.github.io/sp/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23390,
    "package_name": "spANOVA",
    "title": "Analysis of Field Trials with Geostatistics & Spatial AR Models",
    "description": "Perform analysis of variance when the experimental units are spatially correlated. There are two methods to deal with spatial dependence: Spatial autoregressive models (see Rossoni, D. F., & Lima, R. R. (2019) <doi:10.28951/rbb.v37i2.388>) and geostatistics (see Pontes, J. M., & Oliveira, M. S. D. (2004) <doi:10.1590/S1413-70542004000100018>). For both methods, there are three multicomparison procedure available: Tukey, multivariate T, and Scott-Knott.",
    "version": "0.99.4",
    "maintainer": "Castro L. R. <lucasroberto.castro@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23391,
    "package_name": "spAbundance",
    "title": "Univariate and Multivariate Spatial Modeling of Species\nAbundance",
    "description": "Fits single-species (univariate) and multi-species (multivariate) non-spatial and spatial abundance models in a Bayesian framework using Markov Chain Monte Carlo (MCMC). Spatial models are fit using Nearest Neighbor Gaussian Processes (NNGPs). Details on NNGP models are given in Datta, Banerjee, Finley, and Gelfand (2016) <doi:10.1080/01621459.2015.1044091> and Finley, Datta, and Banerjee (2022) <doi:10.18637/jss.v103.i05>. Fits single-species and multi-species spatial and non-spatial versions of generalized linear mixed models (Gaussian, Poisson, Negative Binomial), N-mixture models (Royle 2004 <doi:10.1111/j.0006-341X.2004.00142.x>) and hierarchical distance sampling models (Royle, Dawson, Bates (2004) <doi:10.1890/03-3127>). Multi-species spatial models are fit using a spatial factor modeling approach with NNGPs for computational efficiency. ",
    "version": "0.2.1",
    "maintainer": "Jeffrey Doser <jwdoser@ncsu.edu>",
    "url": "https://www.doserlab.com/files/spabundance-web\nhttps://groups.google.com/g/spocc-spabund-users",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23393,
    "package_name": "spBFA",
    "title": "Spatial Bayesian Factor Analysis",
    "description": "Implements a spatial Bayesian non-parametric factor analysis model \n    with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC). \n    Spatial correlation is introduced in the columns of the factor loadings \n    matrix using a Bayesian non-parametric prior, the probit stick-breaking \n    process. Areal spatial data is modeled using a conditional autoregressive \n    (CAR) prior and point-referenced spatial data is treated using a Gaussian \n    process. The response variable can be modeled as Gaussian, probit, Tobit, or\n    Binomial (using Polya-Gamma augmentation). Temporal correlation is \n    introduced for the latent factors through a hierarchical structure and can \n    be specified as exponential or first-order autoregressive. Full details of \n    the package can be found in the accompanying vignette. Furthermore, the \n    details of the package can be found in \"Bayesian Non-Parametric Factor \n    Analysis for Longitudinal Spatial Surfaces\", by Berchuck et al (2019), \n    <doi:10.1214/20-BA1253> in Bayesian Analysis.",
    "version": "1.5.0",
    "maintainer": "Samuel I. Berchuck <sib2@duke.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23394,
    "package_name": "spBPS",
    "title": "Bayesian Predictive Stacking for Scalable Geospatial Transfer\nLearning",
    "description": "Provides functions for Bayesian Predictive Stacking within the Bayesian transfer learning framework for geospatial artificial systems, as introduced in \"Bayesian Transfer Learning for Artificially Intelligent Geospatial Systems: A Predictive Stacking Approach\" (Presicce and Banerjee, 2024) <doi:10.48550/arXiv.2410.09504>. This methodology enables efficient Bayesian geostatistical modeling, utilizing predictive stacking to improve inference across spatial datasets. The core functions leverage 'C++' for high-performance computation, making the framework well-suited for large-scale spatial data analysis in parallel and distributed computing environments. Designed for scalability, it allows seamless application in computationally demanding scenarios.",
    "version": "0.0-4",
    "maintainer": "Luca Presicce <l.presicce@campus.unimib.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23395,
    "package_name": "spBayes",
    "title": "Univariate and Multivariate Spatial-Temporal Modeling",
    "description": "Fits univariate and multivariate spatio-temporal\n        random effects models for point-referenced data using Markov chain Monte Carlo (MCMC). Details are given in Finley, Banerjee, and Gelfand (2015) <doi:10.18637/jss.v063.i13> and Finley and Banerjee <doi:10.1016/j.envsoft.2019.104608>.",
    "version": "0.4-8",
    "maintainer": "Andrew Finley <finleya@msu.edu>",
    "url": "https://www.finley-lab.com",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23396,
    "package_name": "spBayesSurv",
    "title": "Bayesian Modeling and Analysis of Spatially Correlated Survival\nData",
    "description": "Provides several Bayesian survival models for spatial/non-spatial survival data: proportional hazards (PH), accelerated failure time (AFT), proportional odds (PO), and accelerated hazards (AH), a super model that includes PH, AFT, PO and AH as special cases, Bayesian nonparametric nonproportional hazards (LDDPM), generalized accelerated failure time (GAFT), and spatially smoothed Polya tree density estimation. The spatial dependence is modeled via frailties under PH, AFT, PO, AH and GAFT, and via copulas under LDDPM and PH. Model choice is carried out via the logarithm of the pseudo marginal likelihood (LPML), the deviance information criterion (DIC), and the Watanabe-Akaike information criterion (WAIC). See Zhou, Hanson and Zhang (2020) <doi:10.18637/jss.v092.i09>. ",
    "version": "1.1.9",
    "maintainer": "Haiming Zhou <haiming2019@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23397,
    "package_name": "spCP",
    "title": "Spatially Varying Change Points",
    "description": "Implements a spatially varying change point model with \n    unique intercepts, slopes, variance intercepts and slopes, and \n    change points at each location. Inference is within the \n    Bayesian setting using Markov chain Monte Carlo (MCMC). The \n    response variable can be modeled as Gaussian (no nugget), \n    probit or Tobit link and the five spatially varying parameter\n    are modeled jointly using a multivariate conditional \n    autoregressive (MCAR) prior. The MCAR is a unique process that\n    allows for a dissimilarity metric to dictate the local spatial \n    dependencies. Full details of the package can be found in the accompanying vignette.\n    Furthermore, the details of the package can be found in the corresponding paper published in Spatial Statistics\n    by Berchuck et al (2019): \"A spatially varying change points model for monitoring glaucoma \n    progression using visual field data\", <doi:10.1016/j.spasta.2019.02.001>.",
    "version": "1.4.0",
    "maintainer": "Samuel I. Berchuck <sib2@duke.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23404,
    "package_name": "spGARCH",
    "title": "Spatial ARCH and GARCH Models (spGARCH)",
    "description": "A collection of functions to deal with spatial and spatiotemporal autoregressive conditional heteroscedasticity (spatial ARCH and GARCH models) by Otto, Schmid, Garthoff (2018, Spatial Statistics) <doi:10.1016/j.spasta.2018.07.005>: simulation of spatial ARCH-type processes (spARCH, log/exponential-spARCH, complex-spARCH); quasi-maximum-likelihood estimation of the parameters of spARCH models and spatial autoregressive models with spARCH disturbances, diagnostic checks, visualizations.",
    "version": "0.2.3",
    "maintainer": "Philipp Otto <philipp.otto89@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23406,
    "package_name": "spMC",
    "title": "Continuous-Lag Spatial Markov Chains",
    "description": "A set of functions is provided for 1) the stratum lengths analysis along a chosen direction, 2) fast estimation of continuous lag spatial Markov chains model parameters and probability computing (also for large data sets), 3) transition probability maps and transiograms drawing, 4) simulation methods for categorical random fields. More details on the methodology are discussed in Sartore (2013) <doi:10.32614/RJ-2013-022> and Sartore et al. (2016) <doi:10.1016/j.cageo.2016.06.001>.",
    "version": "0.3.15",
    "maintainer": "Luca Sartore <drwolf85@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23407,
    "package_name": "spMaps",
    "title": "Europe SpatialPolygonsDataFrame Builder",
    "description": "Build custom Europe SpatialPolygonsDataFrame, if you don't know what is\n    a SpatialPolygonsDataFrame see SpatialPolygons() in 'sp', by example for mapLayout() in 'antaresViz'. \n    Antares is a powerful software developed by RTE to simulate and study electric power systems \n    (more information about 'Antares' here: <https://antares-simulator.org/>).",
    "version": "0.5.0",
    "maintainer": "Tatiana Vargas <tatiana.vargas@rte-france.com>",
    "url": "https://github.com/rte-antares-rpackage/spMaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23408,
    "package_name": "spNNGP",
    "title": "Spatial Regression Models for Large Datasets using Nearest\nNeighbor Gaussian Processes",
    "description": "Fits univariate Bayesian spatial regression models for large datasets using Nearest Neighbor Gaussian Processes (NNGP) detailed in Finley, Datta, Banerjee (2022) <doi:10.18637/jss.v103.i05>, Finley, Datta, Cook, Morton, Andersen, and Banerjee (2019) <doi:10.1080/10618600.2018.1537924>, and Datta, Banerjee, Finley, and Gelfand (2016) <doi:10.1080/01621459.2015.1044091>.",
    "version": "1.0.1",
    "maintainer": "Andrew Finley <finleya@msu.edu>",
    "url": "https://www.finley-lab.com/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23410,
    "package_name": "spOccupancy",
    "title": "Single-Species, Multi-Species, and Integrated Spatial Occupancy\nModels",
    "description": "Fits single-species, multi-species, and integrated non-spatial and spatial occupancy models using Markov Chain Monte Carlo (MCMC). Models are fit using Polya-Gamma data augmentation detailed in Polson, Scott, and Windle (2013) <doi:10.1080/01621459.2013.829001>. Spatial models are fit using either Gaussian processes or Nearest Neighbor Gaussian Processes (NNGP) for large spatial datasets. Details on NNGP models are given in Datta, Banerjee, Finley, and Gelfand (2016) <doi:10.1080/01621459.2015.1044091> and Finley, Datta, and Banerjee (2022) <doi:10.18637/jss.v103.i05>. Provides functionality for data integration of multiple single-species occupancy data sets using a joint likelihood framework. Details on data integration are given in Miller, Pacifici, Sanderlin, and Reich (2019) <doi:10.1111/2041-210X.13110>. Details on single-species and multi-species models are found in MacKenzie, Nichols, Lachman, Droege, Royle, and Langtimm (2002) <doi:10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2> and Dorazio and Royle <doi:10.1198/016214505000000015>, respectively. ",
    "version": "0.8.0",
    "maintainer": "Jeffrey Doser <jwdoser@ncsu.edu>",
    "url": "https://www.doserlab.com/files/spoccupancy-web,\nhttps://groups.google.com/g/spocc-spabund-users,\nhttps://github.com/biodiverse/spOccupancy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23412,
    "package_name": "spStack",
    "title": "Bayesian Geostatistics Using Predictive Stacking",
    "description": "Fits Bayesian hierarchical spatial and spatial-temporal process\n    models for point-referenced Gaussian, Poisson, binomial, and binary data\n    using stacking of predictive densities. It involves sampling from\n    analytically available posterior distributions conditional upon candidate\n    values of the spatial process parameters and, subsequently assimilate\n    inference from these individual posterior distributions using Bayesian\n    predictive stacking. Our algorithm is highly parallelizable and hence, much\n    faster than traditional Markov chain Monte Carlo algorithms while delivering\n    competitive predictive performance. See Zhang, Tang, and Banerjee (2025)\n    <doi:10.1080/01621459.2025.2566449>, and, Pan, Zhang, Bradley, and Banerjee\n    (2025) <doi:10.48550/arXiv.2406.04655> for details.",
    "version": "1.1.2",
    "maintainer": "Soumyakanti Pan <span18@ucla.edu>",
    "url": "https://span-18.github.io/spStack-dev/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23413,
    "package_name": "spTDyn",
    "title": "Spatially Varying and Spatio-Temporal Dynamic Linear Models",
    "description": "Fits, spatially predicts, and temporally forecasts space-time data using Gaussian Process (GP): (1) spatially varying coefficient process models and (2) spatio-temporal dynamic linear models. Bakar et al., (2016). Bakar et al., (2015).",
    "version": "2.0.3",
    "maintainer": "K. Shuvo Bakar <shuvo.bakar@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23414,
    "package_name": "spThin",
    "title": "Functions for Spatial Thinning of Species Occurrence Records for\nUse in Ecological Models",
    "description": "A set of functions that can be used to spatially thin\n    species occurrence data. The resulting thinned data can be used in ecological\n    modeling, such as ecological niche modeling.",
    "version": "0.2.0",
    "maintainer": "Matthew E. Aiello-Lammens <matt.lammens@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23415,
    "package_name": "spTimer",
    "title": "Spatio-Temporal Bayesian Modelling",
    "description": "Fits, spatially predicts and temporally forecasts large amounts of space-time data using  [1] Bayesian Gaussian Process (GP) Models, [2] Bayesian Auto-Regressive (AR) Models, and [3] Bayesian Gaussian Predictive Processes (GPP) based AR Models for spatio-temporal big-n problems. Bakar and Sahu (2015) <doi:10.18637/jss.v063.i15>.",
    "version": "3.3.3",
    "maintainer": "K. Shuvo Bakar <shuvo.bakar@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23417,
    "package_name": "spaMM",
    "title": "Mixed-Effect Models, with or without Spatial Random Effects",
    "description": "Inference based on models with or without spatially-correlated random effects, multivariate responses, or non-Gaussian random effects (e.g., Beta). Variation in residual variance (heteroscedasticity) can itself be represented by a mixed-effect model. Both classical geostatistical models (Rousset and Ferdy 2014 <doi:10.1111/ecog.00566>), and Markov random field models on irregular grids (as considered in the 'INLA' package, <https://www.r-inla.org>), can be fitted, with distinct computational procedures exploiting the sparse matrix representations for the latter case and other autoregressive models. Laplace approximations are used for likelihood or restricted  likelihood. Penalized quasi-likelihood and other variants discussed in the h-likelihood literature (Lee and Nelder 2001 <doi:10.1093/biomet/88.4.987>) are also implemented. ",
    "version": "4.6.1",
    "maintainer": "François Rousset <francois.rousset@umontpellier.fr>",
    "url": "https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23424,
    "package_name": "spacetime",
    "title": "Classes and Methods for Spatio-Temporal Data",
    "description": "Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.",
    "version": "1.3-3",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://github.com/edzer/spacetime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23426,
    "package_name": "spagmix",
    "title": "Artificial Spatial and Spatio-Temporal Densities on Bounded\nWindows",
    "description": "Simple utilities to design and generate density functions on bounded regions in space and space-time, and simulate independent, identically distributed data therefrom. See Davies & Lawson (2019) <doi:10.1080/00949655.2019.1575066> for example.",
    "version": "0.4-2",
    "maintainer": "Tilman M. Davies <tilman.davies@otago.ac.nz>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23446,
    "package_name": "sparr",
    "title": "Spatial and Spatiotemporal Relative Risk",
    "description": "Provides functions to estimate kernel-smoothed spatial and spatio-temporal densities and relative risk functions, and perform subsequent inference. Methodological details can be found in the accompanying tutorial: Davies et al. (2018) <DOI:10.1002/sim.7577>.",
    "version": "2.3-16",
    "maintainer": "Tilman M. Davies <tilman.davies@otago.ac.nz>",
    "url": "https://tilmandavies.github.io/sparr/,\nhttps://github.com/tilmandavies/sparr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23448,
    "package_name": "sparrpowR",
    "title": "Power Analysis to Detect Spatial Relative Risk Clusters",
    "description": "Calculate the statistical power to detect clusters using kernel-based \n        spatial relative risk functions that are estimated using the 'sparr' package.\n        Details about the 'sparr' package methods can be found in the tutorial: Davies\n        et al. (2018) <doi:10.1002/sim.7577>. Details about kernel density estimation \n        can be found in J. F. Bithell (1990) <doi:10.1002/sim.4780090616>. More \n        information about relative risk functions using kernel density estimation can \n        be found in J. F. Bithell (1991) <doi:10.1002/sim.4780101112>.",
    "version": "0.2.9",
    "maintainer": "Ian D. Buller <ian.buller@alumni.emory.edu>",
    "url": "https://github.com/machiela-lab/sparrpowR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23477,
    "package_name": "sparsevb",
    "title": "Spike-and-Slab Variational Bayes for Linear and Logistic\nRegression",
    "description": "Implements variational Bayesian algorithms to perform scalable variable selection for sparse, high-dimensional linear and logistic regression models. Features include a novel prioritized updating scheme, which uses a preliminary estimator of the variational means during initialization to generate an updating order prioritizing large, more relevant, coefficients. Sparsity is induced via spike-and-slab priors with either Laplace or Gaussian slabs. By default, the heavier-tailed Laplace density is used. Formal derivations of the algorithms and asymptotic consistency results may be found in Kolyan Ray and Botond Szabo (JASA 2020) and Kolyan Ray, Botond Szabo, and Gabriel Clara (NeurIPS 2020).",
    "version": "0.1.1",
    "maintainer": "Gabriel Clara <gabriel.j.clara@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23483,
    "package_name": "spatPomp",
    "title": "Inference for Spatiotemporal Partially Observed Markov Processes",
    "description": "Inference on panel data using spatiotemporal partially-observed Markov process (SpatPOMP) models. The 'spatPomp' package extends 'pomp' to include algorithms taking advantage of the spatial structure in order to assist with handling high dimensional processes. See Asfaw et al. (2024) <doi:10.48550/arXiv.2101.01157> for further description of the package.",
    "version": "1.1.0",
    "maintainer": "Edward Ionides <ionides@umich.edu>",
    "url": "https://github.com/spatPomp-org/spatPomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23485,
    "package_name": "spatemR",
    "title": "Generalized Spatial Autoregresive Models for Mean and Variance",
    "description": "Modeling spatial dependencies in dependent variables, extending traditional spatial regression approaches. It allows for the joint modeling of both the mean and the variance of the dependent variable, incorporating semiparametric effects in both models. Based on generalized additive models (GAM), the package enables the inclusion of non-parametric terms while maintaining the classical theoretical framework of spatial regression. Additionally, it implements the Generalized Spatial Autoregression (GSAR) model, which extends classical methods like logistic Spatial Autoregresive Models (SAR), probit Spatial Autoregresive Models (SAR), and Poisson Spatial Autoregresive Models (SAR), offering greater flexibility in modeling spatial dependencies and significantly improving computational efficiency and the statistical properties of the estimators. Related work includes: a) J.D. Toloza-Delgado, Melo O.O., Cruz N.A. (2024). \"Joint spatial modeling of mean and non-homogeneous variance combining semiparametric SAR and GAMLSS models for hedonic prices\". <doi:10.1016/j.spasta.2024.100864>. b) Cruz, N. A., Toloza-Delgado, J. D., Melo, O. O. (2024). \"Generalized spatial autoregressive model\". <doi:10.48550/arXiv.2412.00945>. ",
    "version": "1.2.0",
    "maintainer": "Nelson Alirio Cruz Gutierrez <nelson-alirio.cruz@uib.es>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23486,
    "package_name": "spatgeom",
    "title": "Geometric Spatial Point Analysis",
    "description": "The implementation to perform the geometric spatial point analysis developed in Hernández & Solís (2022) <doi:10.1007/s00180-022-01244-1>. It estimates the geometric goodness-of-fit index for a set of variables against a response one based on the 'sf' package. The package has methods to print and plot the results.",
    "version": "0.3.0",
    "maintainer": "Maikol Solís <maikol.solis@ucr.ac.cr>",
    "url": "https://github.com/maikol-solis/spatgeom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23487,
    "package_name": "spatgraphs",
    "title": "Graph Edge Computations for Spatial Point Patterns",
    "description": "Graphs (or networks) and graph component\n        calculations for spatial locations in 1D, 2D, 3D etc.",
    "version": "3.4",
    "maintainer": "Tuomas Rajala <tuomas.rajala@iki.fi>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23488,
    "package_name": "spaths",
    "title": "Shortest Paths Between Points in Grids",
    "description": "Shortest paths between points in grids. Optional barriers and custom transition functions. Applications regarding planet Earth, as well as \n  generally spheres and planes. Optimized for computational performance, customizability, and user friendliness. Graph-theoretical implementation tailored \n  to gridded data. Currently focused on Dijkstra's (1959) <doi:10.1007/BF01386390> algorithm. Future updates broaden the scope to other least cost path\n  algorithms and to centrality measures.",
    "version": "1.2.0",
    "maintainer": "Christian Düben <cdueben.ml+cran@proton.me>",
    "url": "https://github.com/cdueben/spaths",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23489,
    "package_name": "spatial",
    "title": "Functions for Kriging and Point Pattern Analysis",
    "description": "Functions for kriging and point pattern analysis.",
    "version": "7.3-18",
    "maintainer": "Brian Ripley <Brian.Ripley@R-project.org>",
    "url": "http://www.stats.ox.ac.uk/pub/MASS4/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23490,
    "package_name": "spatialAtomizeR",
    "title": "Spatial Analysis with Misaligned Data Using Atom-Based\nRegression Models",
    "description": "Implements atom-based regression models (ABRM) for analyzing spatially \n    misaligned data. Provides functions for simulating misaligned spatial data, \n    preparing NIMBLE model inputs, running MCMC diagnostics, and comparing different \n    spatial analysis methods including dasymetric mapping. All main functions return\n    S3 objects with print(), summary(), and plot() methods for intuitive result exploration.\n    Methods are described in Nethery et al. (2023) <doi:10.1101/2023.01.10.23284410>.\n    Further methodological details and software implementation are described in Qian et al. (in review).",
    "version": "0.2.4",
    "maintainer": "Yunzhe Qian <qyzanemos@gmail.com>",
    "url": "https://github.com/bellayqian/spatialAtomizeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23491,
    "package_name": "spatialCatalogueViewer",
    "title": "A 'Shiny' Tool to Create Interactive Catalogues for Geospatial\nData",
    "description": "Seamlessly create interactive online catalogues for geospatial data. Items can be mapped as points or areas and retrieved using either a map or a dynamic table with search form and optional column filters. ",
    "version": "0.1.3",
    "maintainer": "Sebastien Plutniak <sebastien.plutniak@posteo.net>",
    "url": "https://github.com/sebastien-plutniak/spatialCatalogueViewer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23492,
    "package_name": "spatialCovariance",
    "title": "Computation of Spatial Covariance Matrices for Data on\nRectangles",
    "description": "Functions that compute the spatial covariance matrix for the matern and power classes of spatial models, for data that arise on rectangular units.  This code can also be used for the change of support problem and for spatial data that arise on irregularly shaped regions like counties or zipcodes by laying a fine grid of rectangles and aggregating the integrals in a form of Riemann integration.",
    "version": "0.6-9",
    "maintainer": "David Clifford <david.clifford+CRAN@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23500,
    "package_name": "spatialTIME",
    "title": "Spatial Analysis of Vectra Immunoflourescent Data",
    "description": "Visualization and analysis  of Vectra Immunoflourescent\n    data. Options for calculating both the univariate and bivariate Ripley's K\n    are included. Calculations are performed using a permutation-based \n    approach presented by Wilson et al.  <doi:10.1101/2021.04.27.21256104>. ",
    "version": "1.3.4-5",
    "maintainer": "Fridley Lab <fridley.lab@moffitt.org>",
    "url": "https://github.com/FridleyLab/spatialTIME",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23502,
    "package_name": "spatialprobit",
    "title": "Spatial Probit Models",
    "description": "A collection of methods for the Bayesian estimation of Spatial Probit, Spatial Ordered Probit and Spatial Tobit Models. Original implementations from the works of 'LeSage and Pace' (2009, ISBN: 1420064258) were ported and adjusted for R, as described in 'Wilhelm and de Matos' (2013) <doi:10.32614/RJ-2013-013>.  ",
    "version": "1.0.4",
    "maintainer": "Stefan Wilhelm <wilhelm@financial.com>",
    "url": "https://www.r-project.org",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23504,
    "package_name": "spatialreg.hp",
    "title": "Hierarchical Partitioning of R2 for Spatial Simultaneous\nAutoregressive Model",
    "description": "Conducts hierarchical partitioning to calculate individual contributions of spatial and  predictors (groups) towards total R2  for spatial simultaneous autoregressive model.",
    "version": "0.0-1",
    "maintainer": "Jiangshan Lai <lai@njfu.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23505,
    "package_name": "spatialrisk",
    "title": "Calculating Spatial Risk",
    "description": "Provides methods for spatial risk calculations, focusing on \n    efficient determination of the sum of observations within a circle of a \n    given radius. These methods are particularly relevant for applications such \n    as insurance, where recent European Commission regulations require the \n    calculation of the maximum insured value of fire risk policies for all \n    buildings that are partly or fully located within a 200 m radius. The \n    underlying problem is described by Church (1974) <doi:10.1007/BF01942293>.",
    "version": "0.7.3",
    "maintainer": "Martin Haringa <mtharinga@gmail.com>",
    "url": "https://github.com/mharinga/spatialrisk,\nhttps://mharinga.github.io/spatialrisk/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23508,
    "package_name": "spatialwarnings",
    "title": "Spatial Early Warning Signals of Ecosystem Degradation",
    "description": "Tools to compute and assess significance of early-warnings signals (EWS) of ecosystem degradation. EWS are spatial metrics derived from raster data -- e.g. spatial autocorrelation -- that increase before an ecosystem undergoes a non-linear transition (Genin et al. (2018) <doi:10.1111/2041-210X.13058>).",
    "version": "3.1.1",
    "maintainer": "Alexandre Genin <alexandre.genin@sete.cnrs.fr>",
    "url": "https://github.com/spatial-ews/spatialwarnings",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23512,
    "package_name": "spatstat.Knet",
    "title": "Extension to 'spatstat' for Large Datasets on a Linear Network",
    "description": "Extension to the 'spatstat' family of packages, for analysing\n\t     large datasets of spatial points on a network. The geometrically-\n\t     corrected K function is computed using a memory-efficient\n\t     tree-based algorithm described by Rakshit, Baddeley and Nair (2019).",
    "version": "3.1-2",
    "maintainer": "Adrian Baddeley <Adrian.Baddeley@curtin.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23513,
    "package_name": "spatstat.core",
    "title": "Core Functionality of the 'spatstat' Family",
    "description": "Functionality for data analysis and modelling of",
    "version": "2.4-4.010",
    "maintainer": "Adrian Baddeley <Adrian.Baddeley@curtin.edu.au>",
    "url": "https://github.com/spatstat/spatstat.core",
    "exports": [],
    "topics": ["model-checking", "point-pattern-analysis", "point-process", "r", "random-generation", "random-sampling", "spatial-analysis", "spatial-data", "spatstat", "statistical-analysis", "statistical-diagnostics", "statistical-inference", "statistical-models", "statistical-tests"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 23518,
    "package_name": "spatstat.linnet",
    "title": "Linear Networks Functionality of the 'spatstat' Family",
    "description": "Defines types of spatial data on a linear network\n\t     and provides functionality for geometrical operations,\n\t     data analysis and modelling of data on a linear network,\n\t     in the 'spatstat' family of packages.\n\t     Contains definitions and support for linear networks, including creation of networks, geometrical measurements, topological connectivity, geometrical operations such as inserting and deleting vertices, intersecting a network with another object, and interactive editing of networks.\n\t     Data types defined on a network include point patterns, pixel images, functions, and tessellations.\n\t     Exploratory methods include kernel estimation of intensity on a network, K-functions and pair correlation functions on a network, simulation envelopes, nearest neighbour distance and empty space distance, relative risk estimation with cross-validated bandwidth selection. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\n\tParametric models can be fitted to point pattern data using the function lppm() similar to glm(). Only Poisson models are implemented so far. Models may involve dependence on covariates and dependence on marks. Models are fitted by maximum likelihood.\n\tFitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.\n\tRandom point patterns on a network can be generated using a variety of models.",
    "version": "3.4-0",
    "maintainer": "Adrian Baddeley <Adrian.Baddeley@curtin.edu.au>",
    "url": "http://spatstat.org/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23523,
    "package_name": "spatstat.sphere",
    "title": "Point patterns on the Sphere",
    "description": "This package extends the spatstat package to handle point patterns",
    "version": "0.3-1",
    "maintainer": "",
    "url": "https://github.com/spatstat/spatstat.sphere",
    "exports": [],
    "topics": ["spatial-analysis", "spatial-data", "spatstat", "sphere"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 23526,
    "package_name": "spatsurv",
    "title": "Bayesian Spatial Survival Analysis with Parametric Proportional\nHazards Models",
    "description": "Bayesian inference for parametric proportional hazards spatial\n    survival models; flexible spatial survival models. See Benjamin M. Taylor, Barry S. Rowlingson (2017) <doi:10.18637/jss.v077.i04>.",
    "version": "2.0-1",
    "maintainer": "Benjamin M. Taylor <benjamin.taylor.software@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23528,
    "package_name": "spbabel",
    "title": "Convert Spatial Data Using Tidy Tables",
    "description": "Tools to convert from specific formats to more general forms of \n    spatial data. Using tables to store the actual entities present in spatial\n    data provides flexibility, and the functions here deliberately \n    minimize the level of interpretation applied, leaving that for specific \n    applications. Includes support for simple features,  round-trip for 'Spatial' classes and long-form \n    tables, analogous to 'ggplot2::fortify'. There is also a more 'normal form' representation\n    that decomposes simple features and their kin to tables of objects, parts, and unique coordinates. ",
    "version": "0.6.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://mdsumner.github.io/spbabel/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23529,
    "package_name": "spbal",
    "title": "Spatially Balanced Sampling Algorithms",
    "description": "Encapsulates a number of spatially balanced sampling algorithms,\n    namely, Balanced Acceptance Sampling (equal, unequal, seed point, panels), Halton frames \n    (for discretizing a continuous resource), Halton Iterative Partitioning (equal probability) \n    and Simple Random Sampling.\n    Robertson, B. L., Brown, J. A., McDonald, T. and Jaksons, P. (2013) <doi:10.1111/biom.12059>.\n    Robertson, B. L., McDonald, T., Price, C. J. and Brown, J. A. (2017) <doi:10.1016/j.spl.2017.05.004>.\n    Robertson, B. L., McDonald, T., Price, C. J. and Brown, J. A. (2018) <doi:10.1007/s10651-018-0406-6>.\n    Robertson, B. L., van Dam-Bates, P. and Gansell, O. (2021a) <doi:10.1007/s10651-020-00481-1>.\n    Robertson, B. L., Davies, P., Gansell, O., van Dam-Bates, P., McDonald, T. (2025) <doi:10.1111/anzs.12435>.",
    "version": "1.0.1",
    "maintainer": "Phil Davies <philip.davies@canterbury.ac.nz>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23534,
    "package_name": "spcosa",
    "title": "Spatial Coverage Sampling and Random Sampling from Compact\nGeographical Strata",
    "description": "Spatial coverage sampling and random sampling from compact\n        geographical strata created by k-means. See Walvoort et al. (2010) \n        <doi:10.1016/j.cageo.2010.04.005> for details. ",
    "version": "0.4-6",
    "maintainer": "Dennis Walvoort <dennis.Walvoort@wur.nl>",
    "url": "https://git.wur.nl/Walvo001/spcosa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23540,
    "package_name": "spdgp",
    "title": "Simulate Spatial Data Generation Processes",
    "description": "Provides functionality for simulating data generation processes across various spatial regression models, conceptually aligned with the 'dgp' module of the 'Python' library 'spreg' <https://pysal.org/spreg/api.html#dgp>.",
    "version": "0.1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://josiahparry.github.io/spdgp/,\nhttps://github.com/josiahparry/spdgp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23542,
    "package_name": "spdownscale",
    "title": "Spatial Downscaling Using Bias Correction Approach",
    "description": "Spatial downscaling of climate data (Global Circulation Models/Regional Climate Models) using quantile-quantile bias correction technique.",
    "version": "0.1.0",
    "maintainer": "Rasheed AM <a.rasheed@qut.edu.au>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23544,
    "package_name": "spdynmod",
    "title": "Spatio-Dynamic Wetland Plant Communities Model",
    "description": "A spatio-dynamic modelling package that focuses on three\n    characteristic wetland plant communities in a semiarid Mediterranean\n    wetland in response to hydrological pressures from the catchment. The\n    package includes the data on watershed hydrological pressure and the\n    initial raster maps of plant communities but also allows for random initial\n    distribution of plant communities. For more detailed info see: Martinez-Lopez et al. (2015) <doi:10.1016/j.ecolmodel.2014.11.024>.",
    "version": "1.1.6",
    "maintainer": "Javier Martinez-Lopez <javi.martinez.lopez@gmail.com>",
    "url": "https://github.com/javimarlop/spdynmod",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23559,
    "package_name": "spectacles",
    "title": "Storing, Manipulating and Analysis Spectroscopy and Associated\nData",
    "description": "Stores and eases the manipulation of spectra and associated data,\n    with dedicated classes for spatial and soil-related data.",
    "version": "0.5-5",
    "maintainer": "Pierre Roudier <roudierp@landcareresearch.co.nz>",
    "url": "https://github.com/pierreroudier/spectacles/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23567,
    "package_name": "spectralR",
    "title": "Obtain and Visualize Spectral Reflectance Data for Earth Surface\nPolygons",
    "description": "Tools for obtaining, processing, and visualizing spectral reflectance data for the user-defined land or water surface classes for visual exploring in which wavelength the classes differ. Input should be a shapefile with polygons of surface classes (it might be different habitat types, crops, vegetation, etc.). The Sentinel-2 L2A satellite mission optical bands pixel data are obtained through the Google Earth Engine service (<https://earthengine.google.com/>) and used as a source of spectral data.",
    "version": "0.1.4",
    "maintainer": "Oleh Prylutskyi <oleh.prylutskyi@gmail.com>",
    "url": "https://github.com/olehprylutskyi/spectralR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23572,
    "package_name": "speech",
    "title": "Legislative Speeches",
    "description": "Converts the floor speeches of Uruguayan legislators, extracted from the \n    parliamentary minutes, to tidy data.frame where each observation is the intervention of a single legislator.",
    "version": "0.1.5",
    "maintainer": "Nicolas Schmidt <nschmidt@cienciassociales.edu.uy>",
    "url": "https://github.com/Nicolas-Schmidt/speech",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23583,
    "package_name": "spemd",
    "title": "A Bi-Dimensional Implementation of the Empirical Mode\nDecomposition for Spatial Data",
    "description": "This implementation of the Empirical Mode Decomposition (EMD) works in 2 dimensions simultaneously, and \n    can be applied on spatial data. It can handle both gridded or un-gridded datasets.",
    "version": "0.1-1",
    "maintainer": "Pierre Roudier <pierre.roudier@gmail.com>",
    "url": "https://github.com/pierreroudier/spemd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23586,
    "package_name": "spex",
    "title": "Spatial Extent Tools",
    "description": "Functions to produce a fully fledged 'geo-spatial' object extent as a\n    'SpatialPolygonsDataFrame'. Also included are functions to generate polygons\n    from raster data using 'quadmesh' techniques, a round number buffered extent, and\n    general spatial-extent and 'raster-like' extent helpers missing from the originating\n    packages. Some latitude-based tools for polar maps are included. ",
    "version": "0.7.1",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://mdsumner.github.io/spex/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23589,
    "package_name": "spfilteR",
    "title": "Semiparametric Spatial Filtering with Eigenvectors in\n(Generalized) Linear Models",
    "description": "Tools to decompose (transformed) spatial connectivity matrices and perform supervised or unsupervised semiparametric spatial filtering in a regression framework. The package supports unsupervised spatial filtering in standard linear as well as some generalized linear regression models.",
    "version": "2.2.0",
    "maintainer": "Sebastian Juhl <sebastian.juhl@t-online.de>",
    "url": "https://github.com/sjuhl/spfilteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23597,
    "package_name": "sphet",
    "title": "Estimation of Spatial Autoregressive Models with and without\nHeteroskedastic Innovations",
    "description": "Functions for fitting Cliff-Ord-type spatial autoregressive models with and without heteroskedastic innovations using Generalized Method of Moments estimation are provided. Some support is available for fitting spatial HAC models, and for fitting with non-spatial endogeneous variables using instrumental variables.",
    "version": "2.1-1",
    "maintainer": "Gianfranco Piras <gpiras@mac.com>",
    "url": "https://github.com/gpiras/sphet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23601,
    "package_name": "spidR",
    "title": "Spider Knowledge Online",
    "description": "Allows the user to connect with the World Spider Catalogue (WSC; <https://wsc.nmbe.ch/>) and the World Spider Trait (WST; <https://spidertraits.sci.muni.cz/>) databases. Also performs several basic functions such as checking names validity, retrieving coordinate data from the Global Biodiversity Information Facility (GBIF; <https://www.gbif.org/>), and mapping.",
    "version": "1.0.2",
    "maintainer": "Pedro Cardoso <pedro.cardoso@helsinki.fi>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23611,
    "package_name": "spind",
    "title": "Spatial Methods and Indices",
    "description": "Functions for spatial methods based on generalized estimating equations (GEE) and",
    "version": "2.2.1",
    "maintainer": "Sam Levin <levisc8@gmail.com>",
    "url": "https://github.com/levisc8/spind",
    "exports": [],
    "topics": ["cran", "models", "r-spatial", "rstats", "spatial"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 23617,
    "package_name": "spiritR",
    "title": "Template for Clinical Trial Protocol",
    "description": "Contains an R Markdown template for a clinical trial \n    protocol adhering to the SPIRIT statement. The SPIRIT (Standard Protocol \n    Items for Interventional Trials) statement outlines recommendations for a \n    minimum set of elements to be addressed in a  clinical trial protocol. \n    Also contains functions to create a xml document from the template and \n    upload it to clinicaltrials.gov<https://www.clinicaltrials.gov/> for \n    trial registration.",
    "version": "0.1.1",
    "maintainer": "Aaron Conway <aaron.conway@utoronto.ca>",
    "url": "https://github.com/awconway/spiritR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23620,
    "package_name": "splancs",
    "title": "Spatial and Space-Time Point Pattern Analysis",
    "description": "The Splancs package was written as an enhancement to S-Plus for display and analysis of spatial point pattern data; it has been ported to R and is in \"maintenance mode\". ",
    "version": "2.01-45",
    "maintainer": "Roger Bivand <Roger.Bivand@nhh.no>",
    "url": "https://www.maths.lancs.ac.uk/~rowlings/Splancs/,\nhttps://rsbivand.github.io/splancs/,\nhttps://github.com/rsbivand/splancs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23623,
    "package_name": "spldv",
    "title": "Spatial Models for Limited Dependent Variables",
    "description": "The current version of this package estimates spatial autoregressive models for binary dependent variables using GMM estimators <doi:10.18637/jss.v107.i08>. It supports one-step (Pinkse and Slade, 1998) <doi:10.1016/S0304-4076(97)00097-3> and two-step GMM estimator along with the linearized GMM estimator proposed by Klier and McMillen (2008) <doi:10.1198/073500107000000188>. It also allows for either Probit or Logit model and compute the average marginal effects. All these models are presented in Sarrias and Piras (2023) <doi:10.1016/j.jocm.2023.100432>. ",
    "version": "0.1.3",
    "maintainer": "Mauricio Sarrias <msarrias86@gmail.com>",
    "url": "https://github.com/gpiras/spldv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23637,
    "package_name": "splm",
    "title": "Econometric Models for Spatial Panel Data",
    "description": "ML and GM estimation and diagnostic testing of econometric models for spatial panel data.",
    "version": "1.6-5",
    "maintainer": "Giovanni Millo <giovanni.millo@deams.units.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23646,
    "package_name": "spm",
    "title": "Spatial Predictive Modeling",
    "description": "Introduction to some novel accurate hybrid methods of geostatistical and machine learning methods for spatial predictive modelling. It contains two commonly used geostatistical methods, two machine learning methods, four hybrid methods and two averaging methods. For each method, two functions are provided. One function is for assessing the predictive errors and accuracy of the method based on cross-validation. The other one is for generating spatial predictions using the method. For details please see: Li, J., Potter, A., Huang, Z., Daniell, J. J. and Heap, A. (2010) <https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/71407>\n  Li, J., Heap, A. D., Potter, A., Huang, Z. and Daniell, J. (2011) <doi:10.1016/j.csr.2011.05.015>\n  Li, J., Heap, A. D., Potter, A. and Daniell, J. (2011) <doi:10.1016/j.envsoft.2011.07.004>\n  Li, J., Potter, A., Huang, Z. and Heap, A. (2012) <https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/74030>.",
    "version": "1.2.3",
    "maintainer": "Jin Li <jinli68@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23648,
    "package_name": "spmodel",
    "title": "Spatial Statistical Modeling and Prediction",
    "description": "Fit, summarize, and predict for a variety of spatial statistical models applied to point-referenced and areal (lattice) data. Parameters are estimated using various methods. Additional modeling features include anisotropy, non-spatial random effects, partition factors, big data approaches, and more. Model-fit statistics are used to summarize, visualize, and compare models. Predictions at unobserved locations are readily obtainable. For additional details, see Dumelle et al. (2023) <doi:10.1371/journal.pone.0282524>.",
    "version": "0.11.1",
    "maintainer": "Michael Dumelle <Dumelle.Michael@epa.gov>",
    "url": "https://usepa.github.io/spmodel/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23649,
    "package_name": "spmoran",
    "title": "Fast Spatial and Spatio-Temporal Regression using Moran\nEigenvectors",
    "description": "A collection of functions for estimating spatial and spatio-temporal regression models. Moran eigenvectors are used as spatial basis functions to efficiently approximate spatially dependent Gaussian processes (i.e., random effects eigenvector spatial filtering; see Murakami and Griffith 2015 <doi: 10.1007/s10109-015-0213-7>). The implemented models include linear regression with residual spatial dependence, spatially/spatio-temporally varying coefficient models (Murakami et al., 2017, 2024; <doi:10.1016/j.spasta.2016.12.001>,<doi:10.48550/arXiv.2410.07229>), spatially filtered unconditional quantile regression (Murakami and Seya, 2019 <doi:10.1002/env.2556>), Gaussian and non-Gaussian spatial mixed models through compositionally-warping (Murakami et al. 2021, <doi:10.1016/j.spasta.2021.100520>).",
    "version": "0.3.3",
    "maintainer": "Daisuke Murakami <dmuraka@ism.ac.jp>",
    "url": "https://github.com/dmuraka/spmoran",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23650,
    "package_name": "spnaf",
    "title": "Spatial Network Autocorrelation for Flow Data",
    "description": "Identify statistically significant flow clusters using the local spatial network autocorrelation statistic G_ij* \n    proposed by 'Berglund' and 'Karlström' (1999) <doi:10.1007/s101090050013>. \n    The metric, an extended statistic of 'Getis/Ord' G ('Getis' and 'Ord' 1992) <doi:10.1111/j.1538-4632.1992.tb00261.x>, \n    detects a group of flows having similar traits in terms of directionality. \n    You provide OD data and the associated polygon to get results \n    with several parameters, some of which are defined by spdep package.",
    "version": "1.1.0",
    "maintainer": "Youngbin Lee <youngbin@snu.ac.kr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23663,
    "package_name": "spotoroo",
    "title": "Spatiotemporal Clustering of Satellite Hot Spot Data",
    "description": "An algorithm to cluster satellite hot spot data spatially and temporally.",
    "version": "0.1.5",
    "maintainer": "Weihao Li <llreczx@gmail.com>",
    "url": "https://tengmcing.github.io/spotoroo/,\nhttps://github.com/TengMCing/spotoroo/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23664,
    "package_name": "spotr",
    "title": "Estimate Spatial Population Indices from Ecological Abundance\nData",
    "description": "Compute relative or absolute population trends across space and time using predictions from models fitted to ecological population abundance data, as described in \n             Knape (2025) <doi:10.1016/j.ecolind.2025.113435>. The package supports models fitted by 'mgcv' or 'brms', and draws from posterior predictive distributions. ",
    "version": "0.1.0",
    "maintainer": "Jonas Knape <jonas.knape@slu.se>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23666,
    "package_name": "sppt",
    "title": "Spatial Point Pattern Test",
    "description": "This package implements point pattern tests that measures the",
    "version": "0.2.3",
    "maintainer": "Wouter Steenbeek <wsteenbeek@nscr.nl>",
    "url": "https://github.com/wsteenbeek/sppt",
    "exports": [],
    "topics": ["criminology", "r-package", "spatial-analysis"],
    "score": "NA",
    "stars": 13
  },
  {
    "id": 23667,
    "package_name": "spqdep",
    "title": "Testing for Spatial Independence of Cross-Sectional Qualitative\nData",
    "description": "Testing for Spatial Dependence of Qualitative Data in Cross Section. The list of functions includes join-count tests, Q test, spatial scan test, similarity test and spatial runs test. The methodology of these models can be found in <doi:10.1007/s10109-009-0100-1> and <doi:10.1080/13658816.2011.586327>.",
    "version": "0.1.3.6",
    "maintainer": "Fernando Lopez <fernando.lopez@upct.es>",
    "url": "https://f8l5h9.github.io/spqdep/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23678,
    "package_name": "spselect",
    "title": "Selecting Spatial Scale of Covariates in Regression Models",
    "description": "Fits spatial scale (SS) forward stepwise regression, SS incremental forward stagewise regression, SS least angle regression (LARS), and SS lasso models.  All area-level covariates are considered at all available scales to enter a model, but the SS algorithms are constrained to select each area-level covariate at a single spatial scale.",
    "version": "0.0.1",
    "maintainer": "Lauren Grant <pacele@vcu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23679,
    "package_name": "spsur",
    "title": "Spatial Seemingly Unrelated Regression Models",
    "description": "A collection of functions to test and estimate Seemingly \n    Unrelated Regression (usually called SUR) models, with spatial structure, by maximum \n    likelihood and three-stage least squares. The package estimates the \n    most common spatial specifications, that is, SUR with Spatial Lag of \n    X regressors (called SUR-SLX), SUR with Spatial Lag Model (called SUR-SLM), \n    SUR with Spatial Error Model (called SUR-SEM), SUR with Spatial Durbin Model (called SUR-SDM), \n    SUR with Spatial Durbin Error Model (called SUR-SDEM), \n    SUR with Spatial Autoregressive terms and Spatial Autoregressive \n    Disturbances (called SUR-SARAR), SUR-SARAR with Spatial Lag of X \n    regressors (called SUR-GNM) and SUR with Spatially Independent Model (called SUR-SIM).\n    The methodology of these models can be found in next references \n    Minguez, R., Lopez, F.A., and Mur, J. (2022) <doi:10.18637/jss.v104.i11>\n    Mur, J., Lopez, F.A., and Herrera, M. (2010) <doi:10.1080/17421772.2010.516443> \n    Lopez, F.A., Mur, J., and Angulo, A. (2014) <doi:10.1007/s00168-014-0624-2>.",
    "version": "1.0.2.6",
    "maintainer": "Roman Minguez <roman.minguez@uclm.es>",
    "url": "https://CRAN.R-project.org/package=spsur",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23681,
    "package_name": "spsurvey",
    "title": "Spatial Sampling Design and Analysis",
    "description": "A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more. For additional details, see Dumelle et al. (2023) <doi:10.18637/jss.v105.i03>.",
    "version": "5.6.0",
    "maintainer": "Michael Dumelle <Dumelle.Michael@epa.gov>",
    "url": "https://usepa.github.io/spsurvey/,\nhttps://github.com/USEPA/spsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23682,
    "package_name": "sptotal",
    "title": "Predicting Totals and Weighted Sums from Spatial Data",
    "description": "Performs predictions of totals and weighted sums, or finite population block kriging, on spatial data using the methods in Ver Hoef (2008) <doi:10.1007/s10651-007-0035-y>. The primary outputs are an estimate of the total, mean, or weighted sum in the region, an estimated prediction variance, and a plot of the predicted and observed values. This is useful primarily to users with ecological data that are counts or densities measured on some sites in a finite area of interest. Spatial prediction for the total count or average density in the entire region can then be done using the functions in this package. ",
    "version": "1.0.1",
    "maintainer": "Matt Higham <mhigham@stlawu.edu>",
    "url": "https://highamm.github.io/sptotal/index.html",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23713,
    "package_name": "srppp",
    "title": "Read the Swiss Register of Plant Protection Products",
    "description": "Generate data objects from XML versions of the Swiss\n  Register of Plant Protection Products. An online version of the\n  register can be accessed at <https://www.psm.admin.ch/de/produkte>. There is no\n  guarantee of correspondence of the data read in using this package with that\n  online version, or with the original registration documents.  Also, the\n  Federal Food Safety and Veterinary Office, coordinating the authorisation of\n  plant protection products in Switzerland, does not answer requests regarding\n  this package. ",
    "version": "2.0.0",
    "maintainer": "Johannes Ranke <johannes.ranke@agroscope.admin.ch>",
    "url": "https://agroscope-ch.github.io/srppp/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23718,
    "package_name": "ssMRCD",
    "title": "Robust Estimators for Multi-Group and Spatial Data",
    "description": "Estimation of robust estimators for multi-group and spatial data including the casewise robust Spatially Smoothed Minimum Regularized Determinant (ssMRCD) estimator and its usage for local outlier detection as described in Puchhammer and Filzmoser (2023) <doi:10.1080/10618600.2023.2277875> as well as for sparse robust PCA for multi-source data described in Puchhammer, Wilms and Filzmoser (2024) <doi:10.48550/arXiv.2407.16299>. Moreover, a cellwise robust multi-group Gaussian mixture model (MG-GMM) is implemented as described in Puchhammer, Wilms and Filzmoser (2024) <doi:10.48550/arXiv.2504.02547>. Included are also complementary visualization and parameter tuning tools.",
    "version": "2.0.1",
    "maintainer": "Patricia Puchhammer <patricia.puchhammer@tuwien.ac.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23728,
    "package_name": "sscor",
    "title": "Robust Correlation Estimation and Testing Based on Spatial Signs",
    "description": "Provides the spatial sign correlation and the two-stage spatial sign correlation as well as a one-sample test for the correlation coefficient.",
    "version": "0.2.1",
    "maintainer": "Alexander Duerre <alexander.duerre@tu-dortmund.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23733,
    "package_name": "ssdtools",
    "title": "Species Sensitivity Distributions",
    "description": "Species sensitivity distributions are cumulative probability\n    distributions which are fitted to toxicity concentrations for\n    different species as described by Posthuma et al.(2001)\n    <isbn:9781566705783>. The ssdtools package uses Maximum Likelihood to\n    fit distributions such as the gamma, log-logistic, log-normal and\n    log-normal log-normal mixture. Multiple distributions can be averaged\n    using Akaike Information Criteria.  Confidence intervals on hazard\n    concentrations and proportions are produced by bootstrapping.",
    "version": "2.5.0",
    "maintainer": "Joe Thorley <joe@poissonconsulting.ca>",
    "url": "https://github.com/bcgov/ssdtools,\nhttps://bcgov.github.io/ssdtools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23734,
    "package_name": "ssebiEF",
    "title": "Calculation of SSEBI and Evaporative Fraction from Raster Data",
    "description": "Calculates a modified Simplified Surface Energy Balance Index (SSEBI) and the Evaporative Fraction (EF) using geospatial raster data such as albedo and surface-air temperature difference (TS–TA). The SSEBI is computed from albedo and TS–TA to estimate surface moisture and evaporative dynamics, providing a robust assessment of surface dryness while accounting for atmospheric variations. Based on Roerink, Su, and Menenti (2000) <doi:10.1016/S1464-1909(99)00128-8>.",
    "version": "1.0.1",
    "maintainer": "Gaelle Hamelin <gaelle.hamelin@institut-agro.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23736,
    "package_name": "ssfa",
    "title": "Spatial Stochastic Frontier Analysis",
    "description": "Spatial Stochastic Frontier Analysis (SSFA) is an original method for controlling the spatial heterogeneity in Stochastic Frontier Analysis (SFA) models, for cross-sectional data, by splitting the inefficiency term into three terms: the first one related to spatial peculiarities of the territory in which each single unit operates, the second one related to the specific production features and the third one representing the error term.",
    "version": "1.2.3",
    "maintainer": "Elisa Fusco <fusco_elisa@libero.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23740,
    "package_name": "sshicm",
    "title": "Information Consistency-Based Measures for Spatial Stratified\nHeterogeneity",
    "description": "Spatial stratified heterogeneity (SSH) denotes the coexistence of within-strata homogeneity and between-strata heterogeneity. Information consistency-based methods provide a rigorous approach to quantify SSH and evaluate its role in spatial processes, grounded in principles of geographical stratification and information theory (Bai, H. et al. (2023) <doi:10.1080/24694452.2023.2223700>; Wang, J. et al. (2024) <doi:10.1080/24694452.2023.2289982>).",
    "version": "0.1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "url": "https://stscl.github.io/sshicm/, https://github.com/stscl/sshicm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23766,
    "package_name": "stCEG",
    "title": "Fully Customizable Chain Event Graphs over Spatial Areas",
    "description": "Enables the creation of Chain Event Graphs over spatial areas, with an optional 'Shiny' user interface. Allows users to fully customise both the structure and underlying model of the Chain Event Graph, offering a high degree of flexibility for tailored analyses. For more details on Chain Event Graphs, see Freeman, G., & Smith, J. Q. (2011) <doi:10.1016/j.jmva.2011.03.008>, Collazo R. A., Görgen C. and Smith J. Q. (2018, ISBN:9781498729604) and Barclay, L. M., Hutton, J. L., & Smith, J. Q. (2014) <doi:10.1214/13-BA843>.",
    "version": "0.1.0",
    "maintainer": "Hollie Calley <hc629@exeter.ac.uk>",
    "url": "https://github.com/holliecalley/stCEG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23770,
    "package_name": "sta",
    "title": "Seasonal Trend Analysis for Time Series Imagery in R",
    "description": "Efficiently estimate shape parameters of periodic time series \n    imagery with which  a statistical seasonal trend analysis (STA) is subsequently performed. \n    STA output can be exported in conventional raster formats. \n    Methods to visualize STA output are also implemented as well as the calculation \n    of additional basic statistics. STA is based on (R. Eastman, F. Sangermano, \n    B. Ghimire, H. Zhu, H. Chen, N. Neeti, Y. Cai, E. Machado and S. Crema, 2009) <doi:10.1080/01431160902755338>.",
    "version": "0.1.7",
    "maintainer": "Inder Tecuapetla-Gomez <itecuapetla@conabio.gob.mx>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23775,
    "package_name": "stabilo",
    "title": "Stabilometric Signal Quantification",
    "description": "\n    Functions for stabilometric signal quantification.      \n    The input is a data frame containing the x, y coordinates of the center-of-pressure displacement.     \n    Jose Magalhaes de Oliveira (2017) <doi:10.3758/s13428-016-0706-4> \"Statokinesigram normalization method\";       \n    T E Prieto, J B Myklebust, R G Hoffmann, E G Lovett, B M Myklebust (1996) <doi:10.1109/10.532130> \"Measures of postural steadiness: Differences between healthy young and elderly adults\";      \n    L F Oliveira et al (1996) <doi:10.1088/0967-3334/17/4/008> \"Calculation of area of stabilometric signals using principal component analisys\".",
    "version": "0.1.1",
    "maintainer": "Jose Oliveira <josemagalhaesdeoliveira@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23794,
    "package_name": "stampr",
    "title": "Spatial Temporal Analysis of Moving Polygons",
    "description": "Perform spatial temporal analysis of moving polygons; a\n    longstanding analysis problem in Geographic Information Systems. Facilitates\n    directional analysis, distance analysis, and some other simple functionality for\n    examining spatial-temporal patterns of moving polygons.",
    "version": "0.3.1",
    "maintainer": "Jed Long <jed.long@uwo.ca>",
    "url": "https://github.com/jedalong/stampr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23809,
    "package_name": "starma",
    "title": "Modelling Space Time AutoRegressive Moving Average (STARMA)\nProcesses",
    "description": "Statistical functions to identify, estimate and diagnose a Space-Time AutoRegressive Moving Average (STARMA) model.",
    "version": "1.3",
    "maintainer": "Felix Cheysson <felix@cheysson.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23813,
    "package_name": "starsExtra",
    "title": "Miscellaneous Functions for Working with 'stars' Rasters",
    "description": "Miscellaneous functions for working with 'stars' objects, mainly single-band rasters. Currently includes functions for: (1) focal filtering, (2) detrending of Digital Elevation Models, (3) calculating flow length, (4) calculating the Convergence Index, (5) calculating topographic aspect and topographic slope.",
    "version": "0.2.8",
    "maintainer": "Michael Dorman <dorman@post.bgu.ac.il>",
    "url": "https://michaeldorman.github.io/starsExtra/,\nhttps://github.com/michaeldorman/starsExtra/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23820,
    "package_name": "starvars",
    "title": "Vector Logistic Smooth Transition Models Estimation and\nPrediction",
    "description": "Allows the user to estimate a vector logistic smooth transition autoregressive model via maximum log-likelihood or nonlinear least squares. It further permits to test for linearity in the multivariate framework against a vector logistic smooth transition autoregressive model with a single transition variable. The estimation method is discussed in Terasvirta and Yang (2014, <doi:10.1108/S0731-9053(2013)0000031008>). Also, realized covariances can be constructed from stock market prices or returns, as explained in Andersen et al. (2001, <doi:10.1016/S0304-405X(01)00055-1>).",
    "version": "1.1.10",
    "maintainer": "Andrea Bucci <andrea.bucci@unich.it>",
    "url": "https://github.com/andbucci/starvars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23835,
    "package_name": "statforbiology",
    "title": "Data Analyses in Agriculture and Biology",
    "description": "Contains several tools for nonlinear regression analyses and general data analysis in biology and agriculture. Contains also datasets for practicing and teaching purposes. Supports the blog: Onofri (2024) \"Fixing the bridge between biologists and statisticians\" <https://www.statforbiology.com> and the book: Onofri (2024) \"Experimental Methods in Agriculture\" <https://www.statforbiology.com/_statbookeng/>. The blog is a collection of short articles aimed at improving the efficiency of communication between biologists and statisticians, as pointed out in Kozak (2016) <doi:10.1590/0103-9016-2015-0399>, spreading a better awareness of the potential usefulness, beauty and limitations of biostatistic.",
    "version": "1.0.2",
    "maintainer": "Andrea Onofri <andrea.onofri@unipg.it>",
    "url": "https://github.com/OnofriAndreaPG/statforbiology",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23840,
    "package_name": "statgenMPP",
    "title": "QTL Mapping for Multi Parent Populations",
    "description": "For Multi Parent Populations (MPP) Identity By Descend (IBD) \n    probabilities are computed using Hidden Markov Models. These probabilities \n    are then used in a mixed model approach for QTL Mapping as described in \n    Li et al. (<doi:10.1007/s00122-021-03919-7>).",
    "version": "1.0.4",
    "maintainer": "Bart-Jan van Rossum <bart-jan.vanrossum@wur.nl>",
    "url": "https://biometris.github.io/statgenMPP/index.html,\nhttps://github.com/Biometris/statgenMPP/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23856,
    "package_name": "statpsych",
    "title": "Statistical Methods for Psychologists",
    "description": "Implements confidence interval and sample size methods that \n    are especially useful in psychological research. The methods can be \n    applied in 1-group, 2-group, paired-samples, and multiple-group designs\n    and to a variety of parameters including means, medians, proportions, \n    slopes, standardized mean differences, standardized linear contrasts \n    of means, plus several measures of correlation and association. \n    Confidence interval and sample size functions are given for single \n    parameters as well as differences, ratios, and linear contrasts of\n    parameters. The sample size functions can be used to approximate the \n    sample size needed to estimate a parameter or function of parameters \n    with desired confidence interval precision or to perform a variety of\n    hypothesis tests (directional two-sided, equivalence, superiority, \n    noninferiority) with desired power. For details see: Statistical Methods\n    for Psychologists, Volumes 1 – 4, <https://dgbonett.sites.ucsc.edu/>.   ",
    "version": "1.8.0",
    "maintainer": "Douglas G. Bonett <dgbonett@ucsc.edu>",
    "url": "https://github.com/dgbonett/statpsych/,\nhttps://dgbonett.github.io/statpsych/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23883,
    "package_name": "stepPlr",
    "title": "L2 Penalized Logistic Regression with Stepwise Variable\nSelection",
    "description": "L2 penalized logistic regression for both continuous and discrete predictors, with forward stagewise/forward stepwise variable selection procedure.",
    "version": "0.93",
    "maintainer": "Mee Young Park <meeyoung@google.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23895,
    "package_name": "steps",
    "title": "Spatially- and Temporally-Explicit Population Simulator",
    "description": "Software to simulate population change across space and time. Visintin et al. (2020) <doi:10.1111/2041-210X.13354>.",
    "version": "1.3.0",
    "maintainer": "Casey Visintin <casey.visintin@unimelb.edu.au>",
    "url": "https://github.com/steps-dev/steps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23902,
    "package_name": "stfit",
    "title": "Spatio-Temporal Functional Imputation Tool",
    "description": "A general spatiotemporal satellite image imputation method based on sparse functional data analytic techniques. The imputation method applies and extends the Functional Principal Analysis by Conditional Estimation (PACE). The underlying idea for the proposed procedure is to impute a missing pixel by borrowing information from temporally and spatially contiguous pixels based on the best linear unbiased prediction.  ",
    "version": "0.99.9",
    "maintainer": "Weicheng Zhu <mingsnu@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23903,
    "package_name": "stgam",
    "title": "Spatially and Temporally Varying Coefficient Models Using\nGeneralized Additive Models",
    "description": "A framework for specifying spatially, temporally and spatially-and-temporally varying coefficient models using Generalized Additive Models with smooths. The smooths are parameterised with location, time and predictor variables. The framework supports the investigation of the presence and nature of any space-time dependencies in the data by evaluating multiple model forms (specifications) using a Generalized Cross-Validation score. The workflow sequence is to: i) Prepare the data by lengthening it to have a single location and time variables for each observation. ii) Evaluate all possible spatial and/or temporal models in which each predictor is specified in different ways. iii) Evaluate each model and pick the best one. iv) Create the final model. v) Calculate the varying coefficient estimates to quantify how the relationships between the target and predictor variables vary over space, time or space-time. vi) Create maps, time series plots etc. For more details see: Comber et al (2023) <doi:10.4230/LIPIcs.GIScience.2023.22>, Comber et al (2024) <doi:10.1080/13658816.2023.2270285>  and Comber et al (2004) <doi:10.3390/ijgi13120459>.",
    "version": "1.1.0",
    "maintainer": "Lex Comber <a.comber@leeds.ac.uk>",
    "url": "https://github.com/lexcomber/stgam",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23914,
    "package_name": "stldata",
    "title": "City of St. Louis Data",
    "description": "Contains a number of data sets representing various phenomena in the City of St. Louis.",
    "version": "2.1.0.9000",
    "maintainer": "",
    "url": "https://github.com/slu-openGIS/stldata",
    "exports": [],
    "topics": ["datascience", "gis", "missouri", "opendata", "package", "r", "rstats", "saint-louis", "st-louis", "statistics", "teaching"],
    "score": "NA",
    "stars": 3
  },
  {
    "id": 23921,
    "package_name": "stocc",
    "title": "Fit a Spatial Occupancy Model via Gibbs Sampling",
    "description": "Fit a spatial-temporal occupancy models using\n    a probit formulation instead of a traditional logit\n    model.",
    "version": "1.31",
    "maintainer": "Devin S. Johnson <devin.johnson@noaa.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23922,
    "package_name": "stochLAB",
    "title": "Stochastic Collision Risk Model",
    "description": "Collision Risk Models for avian fauna (seabird and migratory birds) at\n    offshore wind farms. The base deterministic model is derived from \n    Band (2012) <https://tethys.pnnl.gov/publications/using-collision-risk-model-assess-bird-collision-risks-offshore-wind-farms>. \n    This was further expanded on by Masden (2015) <doi:10.7489/1659-1> and code \n    used here is heavily derived from this work with input from Dr A. Cook at the \n    British Trust for Ornithology. These collision risk models are useful for \n    marine ornithologists who are working in the offshore wind industry, particularly \n    in UK waters. However, many of the species included in the stochastic collision \n    risk models can also be found in the North Atlantic in the \n    United States and Canada, and could be applied there. ",
    "version": "1.1.2",
    "maintainer": "Grant Humphries <grwhumphries@blackbawks.net>",
    "url": "https://github.com/HiDef-Aerial-Surveying/stochLAB,\nhttps://hidef-aerial-surveying.github.io/stochLAB/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23923,
    "package_name": "stochQN",
    "title": "Stochastic Limited Memory Quasi-Newton Optimizers",
    "description": "Implementations of stochastic, limited-memory quasi-Newton optimizers,\n\tsimilar in spirit to the LBFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm,\n\tfor smooth stochastic optimization. Implements the following methods:\n\toLBFGS (online LBFGS) (Schraudolph, N.N., Yu, J. and Guenter, S., 2007 <http://proceedings.mlr.press/v2/schraudolph07a.html>),\n\tSQN (stochastic quasi-Newton) (Byrd, R.H., Hansen, S.L., Nocedal, J. and Singer, Y., 2016 <arXiv:1401.7020>),\n\tadaQN (adaptive quasi-Newton) (Keskar, N.S., Berahas, A.S., 2016, <arXiv:1511.01169>).\n\tProvides functions for easily creating R objects\n\twith partial_fit/predict methods from some given objective/gradient/predict functions.\n\tIncludes an example stochastic logistic regression using these optimizers.\n\tProvides header files and registered C routines for using it directly from C/C++.",
    "version": "0.1.2-1",
    "maintainer": "David Cortes <david.cortes.rivera@gmail.com>",
    "url": "https://github.com/david-cortes/stochQN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 23983,
    "package_name": "string2path",
    "title": "Rendering Font into 'data.frame'",
    "description": "Extract glyph information from font data, and translate the\n    outline curves to flattened paths or tessellated polygons. The converted\n    data is returned as a 'data.frame' in easy-to-plot format.",
    "version": "0.2.2",
    "maintainer": "Hiroaki Yutani <yutani.ini@gmail.com>",
    "url": "https://yutannihilation.github.io/string2path/,\nhttps://github.com/yutannihilation/string2path",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24018,
    "package_name": "subincomeR",
    "title": "Access to Global Sub-National Income Data",
    "description": "Provides access to granular sub-national income data from the\n    MCC-PIK Database Of Sub-national Economic Output (DOSE). The package\n    downloads and processes the data from its open repository on 'Zenodo'\n    (<https://zenodo.org/records/13773040>). Functions are provided to\n    fetch data at multiple geographic levels, match coordinates to\n    administrative regions, and access associated geometries.",
    "version": "0.4.0",
    "maintainer": "Pablo García Guzmán <garciagp@ebrd.com>",
    "url": "https://github.com/pablogguz/subincomeR,\nhttps://pablogguz.github.io/subincomeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24034,
    "package_name": "sugarbag",
    "title": "Create Tessellated Hexagon Maps",
    "description": "Create a hexagon tile map display from spatial polygons. Each \n    polygon is represented by a hexagon tile, placed as close to it's original\n    centroid as possible, with a focus on maintaining spatial relationship to\n    a focal point. Developed to aid visualisation and analysis of spatial \n    distributions across Australia, which can be challenging due to the \n    concentration of the population on the coast and wide open interior.",
    "version": "0.1.9",
    "maintainer": "Dianne Cook <dicook@monash.edu>",
    "url": "https://srkobakian.github.io/sugarbag/,\nhttps://github.com/srkobakian/sugarbag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24038,
    "package_name": "sulcimap",
    "title": "Mapping Cortical Folding Patterns",
    "description": "Visualizes sulcal morphometry data derived from 'BrainVisa' <https://brainvisa.info/> including width, depth, surface area, and length. The package enables mapping of statistical group results or subject-level values onto cortical surface maps, with options to focus on all sulci or only selected regions of interest. Users can display all four measures simultaneously or restrict plots to chosen measures, creating composite, publication-quality brain visualizations in R to support the analysis and interpretation of sulcal morphology.",
    "version": "1.0.6",
    "maintainer": "Mahan Shafie <mahan.shafie@unito.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24054,
    "package_name": "supercells",
    "title": "Superpixels of Spatial Data",
    "description": "Creates superpixels based on input spatial data. \n  This package works on spatial data with one variable (e.g., continuous raster), many variables (e.g., RGB rasters), and spatial patterns (e.g., areas in categorical rasters).\n  It is based on the SLIC algorithm (Achanta et al. (2012) <doi:10.1109/TPAMI.2012.120>), and readapts it to work with arbitrary dissimilarity measures. ",
    "version": "1.0.0",
    "maintainer": "Jakub Nowosad <nowosad.jakub@gmail.com>",
    "url": "https://jakubnowosad.com/supercells/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24116,
    "package_name": "surveyCV",
    "title": "Cross Validation Based on Survey Design",
    "description": "Functions to generate K-fold cross validation (CV) folds\n    and CV test error estimates that take into account\n    how a survey dataset's sampling design was constructed\n    (SRS, clustering, stratification, and/or unequal sampling weights).\n    You can input linear and logistic regression models, along with data and a \n    type of survey design in order to get an output that can help you determine\n    which model best fits the data using K-fold cross validation.\n    Our paper on \"K-Fold Cross-Validation for Complex Sample Surveys\"\n    by Wieczorek, Guerin, and McMahon (2022)\n    <doi:10.1002/sta4.454>\n    explains why differing how we take folds based on survey design is useful.",
    "version": "0.2.0",
    "maintainer": "Jerzy Wieczorek <jawieczo@colby.edu>",
    "url": "https://github.com/ColbyStatSvyRsch/surveyCV/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24134,
    "package_name": "survivalPLANN",
    "title": "Neural Networks to Predict Survival",
    "description": "Several functions and S3 methods to predict survival by using neural networks. We implemented Partial Logistic Artificial Neural Networks (PLANN) as proposed by Biganzoli et al. (1998)  <https://pubmed.ncbi.nlm.nih.gov/9618776>.",
    "version": "0.4",
    "maintainer": "Yohann Foucher <yohann.foucher@univ-poitiers.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24148,
    "package_name": "survregVB",
    "title": "Variational Bayesian Analysis of Survival Data",
    "description": "Implements Bayesian inference in accelerated failure time (AFT) models for \n    right-censored survival times assuming a log-logistic distribution. Details of the \n    variational Bayes algorithms, with and without shared frailty, are described in \n    Xian et al. (2024) <doi:10.1007/s11222-023-10365-6> and \n    Xian et al. (2024) <doi:10.48550/arXiv.2408.00177>, respectively.",
    "version": "0.0.2",
    "maintainer": "Alison Zhang <alisonxzhang@gmail.com>",
    "url": "https://github.com/chengqianxian/survregVB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24152,
    "package_name": "susieR",
    "title": "Sum of Single Effects Linear Regression",
    "description": "Implements methods for variable selection in linear\n    regression based on the \"Sum of Single Effects\" (SuSiE) model, as\n    described in Wang et al (2020) <DOI:10.1101/501114> and Zou et al\n    (2021) <DOI:10.1101/2021.11.03.467167>. These methods provide\n    simple summaries, called \"Credible Sets\", for accurately\n    quantifying uncertainty in which variables should be selected.\n    The methods are motivated by genetic fine-mapping applications,\n    and are particularly well-suited to settings where variables are\n    highly correlated and detectable effects are sparse. The fitting\n    algorithm, a Bayesian analogue of stepwise selection methods\n    called \"Iterative Bayesian Stepwise Selection\" (IBSS), is simple\n    and fast, allowing the SuSiE model be fit to large data sets\n    (thousands of samples and hundreds of thousands of variables).",
    "version": "0.14.2",
    "maintainer": "Peter Carbonetto <peter.carbonetto@gmail.com>",
    "url": "https://github.com/stephenslab/susieR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24176,
    "package_name": "svgtools",
    "title": "Manipulate SVG (Template) Files of Charts",
    "description": "The purpose of this package is to manipulate SVG files that are templates of charts the user wants to produce. \n    In vector graphics one copes with x-/y-coordinates of elements (e.g. lines, rectangles, text). Their scale is often dependent on the program that is used to produce the graphics. \n    In applied statistics one usually has numeric values on a fixed scale (e.g. percentage values between 0 and 100) to show in a chart. \n    Basically, 'svgtools' transforms the statistical values into coordinates and widths/heights of the vector graphics.\n    This is done by stackedBar() for bar charts, by linesSymbols() for charts with lines and/or symbols (dot markers) and scatterSymbols() for scatterplots.",
    "version": "1.1.3",
    "maintainer": "Christian Wimmer <christian.wimmer@iqs.gv.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24185,
    "package_name": "svyVarSel",
    "title": "Variable Selection for Complex Survey Data",
    "description": "Fit design-based linear and logistic elastic nets with complex survey data considering the sampling design when defining training and test sets using replicate weights. Methods implemented in this package are described in: A. Iparragirre, T. Lumley, I. Barrio, I. Arostegui (2024) <doi:10.1002/sta4.578>.",
    "version": "1.0.1",
    "maintainer": "Amaia Iparragirre <amaia.iparragirre@ehu.eus>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24211,
    "package_name": "swfscMisc",
    "title": "Miscellaneous Functions for Southwest Fisheries Science Center",
    "description": "Collection of conversion, analytical, geodesic, mapping, and\n    plotting functions. Used to support packages and code written by\n    researchers at the Southwest Fisheries Science Center of the National\n    Oceanic and Atmospheric Administration.",
    "version": "1.7",
    "maintainer": "Eric Archer <eric.ivan.archer@gmail.com>",
    "url": "https://github.com/EricArcher/swfscMisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24238,
    "package_name": "symphony",
    "title": "Efficient and Precise Single-Cell Reference Atlas Mapping",
    "description": "Implements the Symphony single-cell reference building and query mapping algorithms and additional functions described in Kang et al <https://www.nature.com/articles/s41467-021-25957-x>.",
    "version": "0.1.2",
    "maintainer": "Joyce Kang <joyce_kang@hms.harvard.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24245,
    "package_name": "synchrony",
    "title": "Methods for Computing Spatial, Temporal, and Spatiotemporal\nStatistics",
    "description": "Methods for computing spatial, temporal, and spatiotemporal\n    statistics as described in Gouhier and Guichard (2014) \n    <doi:10.1111/2041-210X.12188>. These methods include \n    empirical univariate, bivariate and multivariate\n    variograms; fitting variogram models; phase locking and synchrony analysis;\n    generating autocorrelated and cross-correlated matrices.",
    "version": "0.3.8",
    "maintainer": "Tarik C. Gouhier <tarik.gouhier@gmail.com>",
    "url": "http://github.com/tgouhier/synchrony",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24309,
    "package_name": "tabr",
    "title": "Music Notation Syntax, Manipulation, Analysis and Transcription\nin R",
    "description": "Provides a music notation syntax and a collection of music\n    programming functions for generating, manipulating, organizing, and analyzing\n    musical information in R. Music syntax can be entered directly in character\n    strings, for example to quickly transcribe short pieces of music. The\n    package contains functions for directly performing various mathematical,\n    logical and organizational operations and musical transformations on special\n    object classes that facilitate working with music data and notation. The\n    same music data can be organized in tidy data frames for a familiar and\n    powerful approach to the analysis of large amounts of structured music data.\n    Functions are available for mapping seamlessly between these formats and\n    their representations of musical information. The package also provides an\n    API to 'LilyPond' (<https://lilypond.org/>) for transcribing musical\n    representations in R into tablature (\"tabs\") and sheet music. 'LilyPond' is\n    open source music engraving software for generating high quality sheet music\n    based on markup syntax. The package generates 'LilyPond' files from R code\n    and can pass them to the 'LilyPond' command line interface to be rendered\n    into sheet music PDF files or inserted into R markdown documents. The\n    package offers nominal MIDI file output support in conjunction with\n    rendering sheet music. The package can read MIDI files and attempts to\n    structure the MIDI data to integrate as best as possible with the data\n    structures and functionality found throughout the package.",
    "version": "0.5.5",
    "maintainer": "Matthew Leonawicz <rpkgs@pm.me>",
    "url": "https://github.com/leonawicz/tabr,\nhttps://leonawicz.github.io/tabr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24310,
    "package_name": "tabs",
    "title": "Temporal Altitudinal Biogeographic Shifts",
    "description": "A standardized workflow to reconstruct spatial configurations of altitude-bounded biogeographic systems over time. For example, 'tabs' can model how island archipelagos expand or contract with changing sea levels or how alpine biomes shift in response to tree line movements. It provides functionality to account for various geophysical processes such as crustal deformation and other tectonic changes, allowing for a more accurate representation of biogeographic system dynamics. For more information see De Groeve et al. (2025) <doi:10.3897/arphapreprints.e151900>.",
    "version": "0.1.1",
    "maintainer": "Johannes De Groeve <j.degroeve@uva.nl>",
    "url": "https://uva_ibed_piac.gitlab.io/tabs/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24311,
    "package_name": "tabshiftr",
    "title": "Reshape Disorganised Messy Data",
    "description": "Helps the user to build and register schema descriptions of \n    disorganised (messy) tables. Disorganised tables are tables that are \n    not in a topologically coherent form, where packages such as 'tidyr' could \n    be used for reshaping. The schema description documents the arrangement of \n    input tables and is used to reshape them into a standardised (tidy) output \n    format.",
    "version": "0.4.1",
    "maintainer": "Steffen Ehrmann <steffen.ehrmann@posteo.de>",
    "url": "https://github.com/luckinet/tabshiftr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24317,
    "package_name": "tabularaster",
    "title": "Tidy Tools for 'Raster' Data",
    "description": "Facilities to work with vector and raster data in efficient \n repeatable and systematic work flow. Missing functionality in existing packages \n is included here to allow extraction from raster data with 'simple features' and \n 'Spatial' types and to make extraction consistent and straightforward. Extract cell \n numbers from raster data and  return the cells as a data frame \n rather than as lists of matrices or vectors. The functions here allow spatial data \n to be used without special handling for the format currently in use. ",
    "version": "0.7.2",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/tabularaster",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24318,
    "package_name": "tabularmaps",
    "title": "Create Tile-Grid Geographical Maps",
    "description": "The 'tabularmap' is one of the visualization methods for \n    efficiently displaying data consisting of multiple elements by tiling them.\n    When dealing with geospatial, it corrects for differences in visibility \n    between areas.",
    "version": "0.1.0",
    "maintainer": "Shinya Uryu <suika1127@gmail.com>",
    "url": "https://github.com/uribo/tabularmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24387,
    "package_name": "tcl",
    "title": "Testing in Conditional Likelihood Context",
    "description": "An implementation of hypothesis testing in an extended Rasch modeling framework,\n    including sample size planning procedures and power computations. Provides 4 statistical tests, \n    i.e., gradient test (GR), likelihood ratio test (LR), Rao score or Lagrange multiplier test (RS), \n    and Wald test, for testing a number of hypotheses referring to the Rasch model (RM), linear \n    logistic test model (LLTM), rating scale model (RSM), and partial credit model (PCM). Three \n    types of functions for power and sample size computations are provided. Firstly, functions to \n    compute the sample size given a user-specified (predetermined) deviation from the hypothesis \n    to be tested, the level alpha, and the power of the test. Secondly, functions to evaluate the \n    power of the tests given a user-specified (predetermined) deviation from the hypothesis to be \n    tested, the level alpha of the test, and the sample size. Thirdly, functions to evaluate the \n    so-called post hoc power of the tests. This is the power of the tests given the observed \n    deviation of the data from the hypothesis to be tested and a user-specified level alpha of the\n    test. Power and sample size computations are based on a Monte Carlo simulation approach. It is\n    computationally very efficient. The variance of the random error in computing power and sample\n    size arising from the simulation approach is analytically derived by using the delta method. \n    Additionally, functions to compute the power of the tests as a function of an effect measure \n    interpreted as explained variance are provided.\n    Draxler, C., & Alexandrowicz, R. W. (2015), <doi:10.1007/s11336-015-9472-y>.",
    "version": "1.0.1",
    "maintainer": "Clemens Draxler <clemens.draxler@umit-tirol.at>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24435,
    "package_name": "templateICAr",
    "title": "Estimate Brain Networks and Connectivity with ICA and Empirical\nPriors",
    "description": "Implements the template ICA (independent components analysis) model\n    proposed in Mejia et al. (2020) <doi:10.1080/01621459.2019.1679638> and the \n    spatial template ICA model proposed in proposed in Mejia et al. (2022)\n    <doi:10.1080/10618600.2022.2104289>. Both models estimate subject-level \n    brain as deviations from known population-level networks, which are \n    estimated using standard ICA algorithms. Both models employ an \n    expectation-maximization algorithm for estimation of the latent brain \n    networks and unknown model parameters. Includes direct support for 'CIFTI',\n    'GIFTI', and 'NIFTI' neuroimaging file formats.",
    "version": "0.10.0",
    "maintainer": "Amanda Mejia <mandy.mejia@gmail.com>",
    "url": "https://github.com/mandymejia/templateICAr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24441,
    "package_name": "tenm",
    "title": "Temporal Ecological Niche Models",
    "description": "Implements methods and functions to calibrate \n  time-specific niche models (multi-temporal calibration), letting users \n  execute a strict calibration and selection process of niche models based \n  on ellipsoids, as well as functions to project the potential distribution in \n  the present and in global change  scenarios.The 'tenm' package has functions\n  to recover information that may be lost or overlooked while applying a data \n  curation protocol. This curation involves preserving occurrences that may \n  appear spatially redundant (occurring in the same pixel) but originate from \n  different time periods. A novel aspect of this package is that it might \n  reconstruct the fundamental niche more accurately than mono-calibrated \n  approaches. The theoretical background of the package can be found in \n  Peterson et al. (2011)<doi:10.5860/CHOICE.49-6266>.",
    "version": "0.5.1",
    "maintainer": "Luis Osorio-Olvera <luismurao@gmail.com>",
    "url": "https://luismurao.github.io/tenm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24468,
    "package_name": "terrainmeshr",
    "title": "Triangulate and Simplify 3D Terrain Meshes",
    "description": "Provides triangulations of regular height fields, based on the methods described in \"Fast Polygonal Approximation of Terrains and Height Fields\" Michael Garland and Paul S. Heckbert (1995) <https://www.mgarland.org/files/papers/scape.pdf> using code from the 'hmm' library written by Michael Fogleman <https://github.com/fogleman/hmm>.",
    "version": "1.0.1",
    "maintainer": "Tyler Morgan-Wall <tylermw@gmail.com>",
    "url": "https://github.com/tylermorganwall/terrainmeshr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24493,
    "package_name": "tetrascatt",
    "title": "Acoustic Scattering for Complex Shapes by Using the DWBA",
    "description": "Uses the Distorted Wave Born Approximation (DWBA) to compute the\n  acoustic backward scattering, the geometry of the object is formed by a\n  volumetric mesh, composed of tetrahedrons. This computation is done efficiently\n  through an analytical 3D integration that allows for a solution which is\n  expressed in terms of elementary functions for each tetrahedron.\n  It is important to note that this method is only valid for objects whose\n  acoustic properties, such as density and sound speed, do not vary significantly\n  compared to the surrounding medium. (See Lavia, Cascallares and Gonzalez, J. D. (2023). \n  TetraScatt model: Born approximation for the estimation of acoustic dispersion of \n  fluid-like objects of arbitrary geometries. arXiv preprint <arXiv:2312.16721>).",
    "version": "0.1.1",
    "maintainer": "Juan Domingo Gonzalez <juanrst@hotmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24500,
    "package_name": "text2emotion",
    "title": "Emotion Analysis and Emoji Mapping for Text",
    "description": "Allows users to analyze text and classify emotions\n    such as happiness, sadness, anger, fear, and neutrality.\n    It combines text preprocessing, TF-IDF (Term Frequency-Inverse Document Frequency) \n    feature extraction, and Random Forest classification to predict emotions\n    and map them to corresponding emojis for enhanced sentiment visualization.",
    "version": "0.1.0",
    "maintainer": "Fangyi Wang <123090550@link.cuhk.edu.cn>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24555,
    "package_name": "tgp",
    "title": "Bayesian Treed Gaussian Process Models",
    "description": "Bayesian nonstationary, semiparametric nonlinear regression \n and design by treed Gaussian processes (GPs) with jumps to the limiting \n linear model (LLM).  Special cases also implemented include Bayesian \n linear models, CART, treed linear models, stationary separable and \n isotropic GPs, and GP single-index models.  Provides 1-d and 2-d plotting functions \n (with projection and slice capabilities) and tree drawing, designed for \n visualization of tgp-class output.  Sensitivity analysis and \n multi-resolution models are supported. Sequential experimental \n design and adaptive sampling functions are also provided, including ALM, \n ALC, and expected improvement.  The latter supports derivative-free\n optimization of noisy black-box functions.  For details and tutorials, \n see Gramacy (2007) <doi:10.18637/jss.v019.i09> and Gramacy & Taddy (2010) \n <doi:10.18637/jss.v033.i06>.  ",
    "version": "2.4-23",
    "maintainer": "Robert B. Gramacy  <rbg@vt.edu>",
    "url": "https://bobby.gramacy.com/r_packages/tgp/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24582,
    "package_name": "threewords",
    "title": "Represent Precise Coordinates in Three Words",
    "description": "A connector to the 'What3Words' (http://what3words.com/) service, which represents each 3m by 3m square on earth\n             with a unique trio of English-language words.",
    "version": "0.1.0",
    "maintainer": "Oliver Keyes <ironholds@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24587,
    "package_name": "thunder",
    "title": "Computation and Visualisation of Atmospheric Convective\nParameters",
    "description": "Allow to compute and visualise convective parameters commonly\n  used in the operational prediction of severe convective storms. Core algorithm\n  is based on a highly optimized 'C++' code linked into 'R' via 'Rcpp'. Highly\n  efficient engine allows to derive thermodynamic and kinematic parameters from\n  large numerical datasets such as reanalyses or operational Numerical Weather \n  Prediction models in a reasonable amount of time. Package has been developed\n  since 2017 by research meteorologists specializing in severe thunderstorms.\n  The most relevant methods used in the package based on the following publications\n  Stipanuk (1973) <https://apps.dtic.mil/sti/pdfs/AD0769739.pdf>,\n  McCann et al. (1994) <doi:10.1175/1520-0434(1994)009%3C0532:WNIFFM%3E2.0.CO;2>,\n  Bunkers et al. (2000) <doi:10.1175/1520-0434(2000)015%3C0061:PSMUAN%3E2.0.CO;2>,\n  Corfidi et al. (2003) <doi:10.1175/1520-0434(2003)018%3C0997:CPAMPF%3E2.0.CO;2>,\n  Showalter (1953) <doi:10.1175/1520-0477-34.6.250>,\n  Coffer et al. (2019) <doi:10.1175/WAF-D-19-0115.1>,\n  Gropp and Davenport (2019) <doi:10.1175/WAF-D-17-0150.1>,\n  Czernecki et al. (2019) <doi:10.1016/j.atmosres.2019.05.010>,\n  Taszarek et al. (2020) <doi:10.1175/JCLI-D-20-0346.1>,\n  Sherburn and Parker (2014) <doi:10.1175/WAF-D-13-00041.1>,\n  Romanic et al. (2022) <doi:10.1016/j.wace.2022.100474>.",
    "version": "1.1.5",
    "maintainer": "Bartosz Czernecki <nwp@amu.edu.pl>",
    "url": "https://bczernecki.github.io/thundeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24621,
    "package_name": "tidycensus",
    "title": "Load US Census Boundary and Attribute Data as 'tidyverse' and\n'sf'-Ready Data Frames",
    "description": "An integrated R interface to several United States Census Bureau \n    APIs (<https://www.census.gov/data/developers/data-sets.html>) and the US Census Bureau's \n    geographic boundary files. Allows R users to return Census and ACS data as \n    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for mapping \n    and spatial analysis. ",
    "version": "1.7.3",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "url": "https://walker-data.com/tidycensus/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24664,
    "package_name": "tidymodlr",
    "title": "An R6 Class to Perform Analysis on Long Tidy Data",
    "description": "Transforms long data into a matrix form to allow for ease of input into modelling packages for regression, principal components, imputation or machine learning. It does this by pivoting on user defined columns, generating a key-value table for variable names to ensure one-to-one mappings are preserved. It is particularly useful when the indicator names in the columns are long descriptive strings, for example \"Energy imports, net (% of energy use)\". High level analysis wrapper functions for correlation and principal components analysis are provided.",
    "version": "1.0.0",
    "maintainer": "David Hammond <anotherdavidhammond@gmail.com>",
    "url": "https://github.com/david-hammond/tidymodlr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24669,
    "package_name": "tidynorm",
    "title": "Tools for Tidy Vowel Normalization",
    "description": "An implementation of tidy speaker vowel normalization.\n    This includes generic functions for defining new normalization methods for\n    points, formant tracks, and Discrete Cosine Transform coefficients, as well\n    as convenience functions implementing established normalization methods.\n    References for the implemented methods are:\n    Johnson, Keith (2020) <doi:10.5334/labphon.196>\n    Lobanov, Boris (1971) <doi:10.1121/1.1912396>\n    Nearey, Terrance M. (1978) <https://sites.ualberta.ca/~tnearey/Nearey1978_compressed.pdf>\n    Syrdal, Ann K., and Gopal, H. S. (1986) <doi:10.1121/1.393381>\n    Watt, Dominic, and Fabricius, Anne (2002) <https://www.latl.leeds.ac.uk/article/evaluation-of-a-technique-for-improving-the-mapping-of-multiple-speakers-vowel-spaces-in-the-f1-f2-plane/>.",
    "version": "0.4.0",
    "maintainer": "Josef Fruehwald <JoFrhwld@gmail.com>",
    "url": "https://jofrhwld.github.io/tidynorm/,\nhttps://github.com/JoFrhwld/tidynorm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24691,
    "package_name": "tidysdm",
    "title": "Species Distribution Models with Tidymodels",
    "description": "Fit species distribution models (SDMs) using the 'tidymodels' framework, \n  which provides a standardised interface to define models and process their \n  outputs. 'tidysdm' expands 'tidymodels' by providing methods for spatial objects,\n  models and metrics specific to SDMs,\n  as well as a number of specialised functions to process occurrences\n  for contemporary and palaeo datasets. The full \n  functionalities of the package are described\n  in Leonardi et al. (2024) <doi:10.1111/2041-210X.14406>.",
    "version": "1.0.4",
    "maintainer": "Andrea Manica <am315@cam.ac.uk>",
    "url": "https://github.com/EvolEcolGroup/tidysdm,\nhttps://evolecolgroup.github.io/tidysdm/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24703,
    "package_name": "tidyterra",
    "title": "'tidyverse' Methods and 'ggplot2' Helpers for 'terra' Objects",
    "description": "Extension of the 'tidyverse' for 'SpatRaster' and",
    "version": "0.7.2.9000",
    "maintainer": "",
    "url": "https://github.com/dieghernan/tidyterra",
    "exports": [],
    "topics": ["cran", "cran-r", "ggplot-extension", "r", "r-package", "r-spatial", "rspatial", "rstats", "rstats-package", "terra"],
    "score": "NA",
    "stars": 211
  },
  {
    "id": 24723,
    "package_name": "tigers",
    "title": "Integration of Geography, Environment, and Remote Sensing",
    "description": "Handling and manipulation polygons, coordinates, and other geographical objects. The tools include: polygon areas, barycentric and trilinear coordinates (Hormann and Floater, 2006, <doi:10.1145/1183287.1183295>), convex hull for polygons (Graham and Yao, 1983, <doi:10.1016/0196-6774(83)90013-5>), polygon triangulation (Toussaint, 1991, <doi:10.1007/BF01905693>), great circle and geodesic distances, Hausdorff distance, and reduced major axis.",
    "version": "0.1-3",
    "maintainer": "Emmanuel Paradis <Emmanuel.Paradis@ird.fr>",
    "url": "https://github.com/emmanuelparadis/tigers",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24729,
    "package_name": "tigris",
    "title": "Load Census TIGER/Line Shapefiles",
    "description": "Download TIGER/Line shapefiles from the United States Census Bureau\n    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>)\n    and load into R as 'sf' objects.",
    "version": "2.2.1",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "url": "https://github.com/walkerke/tigris",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24774,
    "package_name": "tinyVAST",
    "title": "Multivariate Spatio-Temporal Models using Structural Equations",
    "description": "Fits a wide variety of multivariate spatio-temporal models\n    with simultaneous and lagged interactions among variables (including\n    vector autoregressive spatio-temporal ('VAST') dynamics)\n    for areal, continuous, or network spatial domains.  \n    It includes time-variable, space-variable, and space-time-variable \n    interactions using dynamic structural equation models ('DSEM') \n    as expressive interface, and the 'mgcv' package to specify splines \n    via the formula interface.  See Thorson et al. (2025)\n    <doi:10.1111/geb.70035> for more details.",
    "version": "1.4.0",
    "maintainer": "James T. Thorson <James.Thorson@noaa.gov>",
    "url": "https://vast-lib.github.io/tinyVAST/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24789,
    "package_name": "tinytiger",
    "title": "Lightweight Interface to TIGER/Line Shapefiles",
    "description": "Download geographic shapes from the United States Census Bureau \n    TIGER/Line Shapefiles <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>.\n    Functions support downloading and reading in geographic boundary data.\n    All downloads can be set up with a cache to avoid multiple downloads.\n    Data is available back to 2000 for most geographies.",
    "version": "0.0.11",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "url": "https://github.com/alarm-redist/tinytiger,\nhttps://alarm-redist.org/tinytiger/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24795,
    "package_name": "tipsae",
    "title": "Tools for Handling Indices and Proportions in Small Area\nEstimation",
    "description": "It allows for mapping proportions and indicators defined on the unit interval. It implements Beta-based small area methods comprising the classical Beta regression models, the Flexible Beta model and Zero and/or One Inflated extensions (Janicki 2020 <doi:10.1080/03610926.2019.1570266>). Such methods, developed within a Bayesian framework through Stan <https://mc-stan.org/>, come equipped with a set of diagnostics and complementary tools, visualizing and exporting functions. A Shiny application with a user-friendly interface can be launched to further simplify the process. For further details, refer to De Nicolò and Gardini (2024 <doi:10.18637/jss.v108.i01>).",
    "version": "1.0.3",
    "maintainer": "Silvia De Nicolò <silvia.denicolo@unibo.it>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24809,
    "package_name": "tlm",
    "title": "Effects under Linear, Logistic and Poisson Regression Models\nwith Transformed Variables",
    "description": "Computation of effects under linear, logistic and Poisson regression\n    models with transformed variables. Logarithm and power transformations are allowed.\n    Effects can be displayed both numerically and graphically in both the original\n    and the transformed space of the variables. The methods are described in Barrera-Gomez\n    and Basagana (2015) <doi:10.1097/EDE.0000000000000247>.",
    "version": "0.2.0",
    "maintainer": "Jose Barrera-Gomez <jose.barrera@isglobal.org>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24812,
    "package_name": "tlsR",
    "title": "Detection and Spatial Analysis of Tertiary Lymphoid Structures",
    "description": "Fast, reproducible detection and quantitative analysis of tertiary lymphoid structures (TLS) in multiplexed tissue imaging. Implements Independent Component Analysis Trace (ICAT) index, local Ripley's K scanning, automated K Nearest Neighbor (KNN)-based TLS detection, and T-cell clusters identification as described in Amiryousefi et al. (2025) <doi:10.1101/2025.09.21.677465>.",
    "version": "0.1.2",
    "maintainer": "Ali Amiryousefi <ali_amiryousefi@hms.harvard.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24823,
    "package_name": "tmap",
    "title": "Thematic Maps",
    "description": "Thematic maps are geographical maps in which spatial data\n    distributions are visualized. This package offers a flexible,\n    layer-based, and easy to use approach to create thematic maps, such as\n    choropleths and bubble maps.",
    "version": "4.2",
    "maintainer": "Martijn Tennekes <mtennekes@gmail.com>",
    "url": "https://github.com/r-tmap/tmap, https://r-tmap.github.io/tmap/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24826,
    "package_name": "tmap.mapgl",
    "title": "Extensions to 'tmap' with Two New Modes: 'mapbox' and 'maplibre'",
    "description": "The 'tmap' package provides two plotting modes for static and interactive thematic maps. This package extends 'tmap' with two additional modes based on 'Mapbox GL JS' and 'MapLibre GL JS'. These modes feature interactive vector tiles, globe views, and other modern web-mapping capabilities, while maintaining a consistent 'tmap' interface across all plotting modes.",
    "version": "0.1.0",
    "maintainer": "Martijn Tennekes <mtennekes@gmail.com>",
    "url": "https://github.com/r-tmap/tmap.mapgl,\nhttps://r-tmap.github.io/tmap.mapgl/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24828,
    "package_name": "tmaptools",
    "title": "Thematic Map Tools",
    "description": "Set of tools for reading and processing spatial data. The aim is to supply the workflow to create thematic maps. This package also facilitates 'tmap', the package for visualizing thematic maps.",
    "version": "3.3",
    "maintainer": "Martijn Tennekes <mtennekes@gmail.com>",
    "url": "https://github.com/r-tmap/tmaptools,\nhttps://r-tmap.github.io/tmaptools/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24829,
    "package_name": "tmapverse",
    "title": "Meta-Package for Thematic Mapping with 'tmap'",
    "description": "Attaches a set of packages commonly used for spatial plotting with 'tmap'. It includes 'tmap' and its extensions ('tmap.glyphs', 'tmap.networks', 'tmap.cartogram', 'tmap.mapgl'), as well as supporting spatial data packages ('sf', 'stars', 'terra') and 'cols4all' for exploring color palettes. The collection is designed for thematic mapping workflows and does not include the full set of packages from the R-spatial ecosystem.",
    "version": "0.1.0",
    "maintainer": "Martijn Tennekes <mtennekes@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24852,
    "package_name": "tod",
    "title": "Easy import of some French open data sets with emphasis on environmental issues",
    "description": "The name tod stands for \"telechargement open data\". Package facilitant l'accès",
    "version": "0.2.1",
    "maintainer": "Pascal Irz <pascal.irz@ofb.gouv.fr>",
    "url": "https://github.com/PascalIrz/tod",
    "exports": [],
    "topics": ["api", "datasets", "ecology", "environment", "gis", "open"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 24859,
    "package_name": "tolerance",
    "title": "Statistical Tolerance Intervals and Regions",
    "description": "Statistical tolerance limits provide the limits between which we can expect to find a specified proportion of a sampled population with a given level of confidence.  This package provides functions for estimating tolerance limits (intervals) for various univariate distributions (binomial, Cauchy, discrete Pareto, exponential, two-parameter exponential, extreme value, hypergeometric, Laplace, logistic, negative binomial, negative hypergeometric, normal, Pareto, Poisson-Lindley, Poisson, uniform, and Zipf-Mandelbrot), Bayesian normal tolerance limits, multivariate normal tolerance regions, nonparametric tolerance intervals, tolerance bands for regression settings (linear regression, nonlinear regression, nonparametric regression, and multivariate regression), and analysis of variance tolerance intervals.  Visualizations are also available for most of these settings.",
    "version": "3.0.0",
    "maintainer": "Derek S. Young <derek.young@uky.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24867,
    "package_name": "toolbox",
    "title": "List, String, and Meta Programming Utility Functions",
    "description": "Includes functions for mapping named lists to function arguments, random strings,\n  pasting and combining rows together across columns, etc.",
    "version": "0.1.1",
    "maintainer": "Timothy Conwell <timconwell@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24875,
    "package_name": "topdowntimeratio",
    "title": "Top-Down Time Ratio Segmentation for Coordinate Trajectories",
    "description": "Data collected on movement behavior is often in the form of time-\n    stamped latitude/longitude coordinates sampled from the underlying movement\n    behavior. These data can be compressed into a set of segments via the Top-\n    Down Time Ratio Segmentation method described in Meratnia and de By (2004)\n    <doi:10.1007/978-3-540-24741-8_44> which, with some loss of information, \n    can both reduce the size of the data as well as provide corrective smoothing\n    mechanisms to help reduce the impact of measurement error.  This is an\n    improvement on the well-known Douglas-Peucker algorithm for segmentation\n    that operates not on the basis of perpendicular distances. Top-Down Time\n    Ratio segmentation allows for disparate sampling time intervals by\n    calculating the distance between locations and segments with respect to\n    time. Provided a trajectory with timestamps, tdtr() returns a set of straight-\n    line segments that can represent the full trajectory. McCool, Lugtig,\n    and Schouten (2022) <doi:10.1007/s11116-022-10328-2> describe this method as\n    implemented here in more detail. ",
    "version": "0.1.0",
    "maintainer": "Danielle McCool <d.m.mccool@uu.nl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24886,
    "package_name": "toposhop",
    "title": "What the Package Does (one line, title case)",
    "description": "What the package does (one paragraph).",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/hypertidy/toposhop",
    "exports": [],
    "topics": ["gis", "rstats"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 24906,
    "package_name": "touch",
    "title": "Tools of Utilization and Cost in Healthcare",
    "description": "R implementation of the software tools developed in the H-CUP\n    (Healthcare Cost and Utilization Project) <https://hcup-us.ahrq.gov>\n    and AHRQ (Agency for Healthcare Research and Quality)\n    <https://www.ahrq.gov>.  It currently contains functions for mapping ICD-9\n    codes to the AHRQ comorbidity measures and translating ICD-9\n    (resp. ICD-10) codes to ICD-10 (resp. ICD-9) codes based on GEM (General\n    Equivalence Mappings) from CMS (Centers for Medicare and Medicaid\n    Services).",
    "version": "0.1-7",
    "maintainer": "Wenjie Wang <wang@wwenjie.org>",
    "url": "https://github.com/wenjie2wang/touch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24948,
    "package_name": "traineR",
    "title": "Predictive (Classification and Regression) Models Homologator",
    "description": "Methods to unify the different ways of creating predictive models and their different predictive formats for classification and regression. It includes  methods such as K-Nearest Neighbors Schliep, K. P. (2004) <doi:10.5282/ubm/epub.1769>, Decision Trees Leo Breiman, Jerome H. Friedman, Richard A. Olshen, Charles J. Stone (2017) <doi:10.1201/9781315139470>,  ADA Boosting Esteban Alfaro, Matias Gamez, Noelia García (2013) <doi:10.18637/jss.v054.i02>, Extreme Gradient Boosting Chen & Guestrin (2016) <doi:10.1145/2939672.2939785>,  Random Forest Breiman (2001) <doi:10.1023/A:1010933404324>, Neural Networks Venables, W. N., & Ripley, B. D. (2002) <ISBN:0-387-95457-0>, Support Vector Machines Bennett, K. P. & Campbell, C. (2000) <doi:10.1145/380995.380999>, Bayesian Methods Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995) <doi:10.1201/9780429258411>,  Linear Discriminant Analysis Venables, W. N., & Ripley, B. D. (2002) <ISBN:0-387-95457-0>, Quadratic Discriminant Analysis Venables, W. N., & Ripley, B. D. (2002) <ISBN:0-387-95457-0>,  Logistic Regression Dobson, A. J., & Barnett, A. G. (2018) <doi:10.1201/9781315182780> and Penalized Logistic Regression Friedman, J. H., Hastie, T., & Tibshirani, R. (2010) <doi:10.18637/jss.v033.i01>.",
    "version": "2.2.9",
    "maintainer": "Oldemar Rodriguez R. <oldemar.rodriguez@ucr.ac.cr>",
    "url": "https://promidat.website/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 24954,
    "package_name": "trajSpatial",
    "title": "What the Package Does (One Line, Title Case)",
    "description": "Spatial analysis of trajectory endpoint data.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/MRPHarris/trajSpatial",
    "exports": [],
    "topics": ["hysplit", "spatial-analysis", "trajectory", "trajectory-analysis"],
    "score": "NA",
    "stars": 2
  },
  {
    "id": 24959,
    "package_name": "trakR",
    "title": "Basic Animal Tracking Data Analysis Tools",
    "description": "Basic functions for processing animal tracking data.  These",
    "version": "0.0.12",
    "maintainer": "",
    "url": "https://github.com/abfleishman/trakR",
    "exports": [],
    "topics": ["animal-behavior", "animal-movement", "animal-tracking", "colony", "distance", "seabirds", "spatial-analysis", "tracking", "trakr", "trip-segmentation"],
    "score": "NA",
    "stars": 7
  },
  {
    "id": 24972,
    "package_name": "transfR",
    "title": "Transfer of Hydrograph from Gauged to Ungauged Catchments",
    "description": "A geomorphology-based hydrological modelling for transferring\n    streamflow measurements from gauged to ungauged catchments. Inverse\n    modelling enables to estimate net rainfall from streamflow measurements \n    following Boudhraâ et al. (2018) <doi:10.1080/02626667.2018.1425801>. \n    Resulting net rainfall is then estimated on the ungauged catchments \n    by spatial interpolation in order to finally simulate streamflow \n    following de Lavenne et al. (2016) <doi:10.1002/2016WR018716>.",
    "version": "1.1.4",
    "maintainer": "Alban de Lavenne <alban.delavenne@inrae.fr>",
    "url": "https://gitlab.irstea.fr/HYCAR-Hydro/transfr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25010,
    "package_name": "treeDbalance",
    "title": "Computation of 3D Tree Imbalance",
    "description": "The main goal of the R package 'treeDbalance' is to provide\n    functions for the computation of several measurements of 3D node\n    imbalance and their respective 3D tree imbalance indices, as well as to\n    introduce the new 'phylo3D' format for rooted 3D tree objects.\n    Moreover, it encompasses an example dataset of 3D models of 63 beans \n    in 'phylo3D' format. Please note that this R package was developed \n    alongside the project described in the manuscript 'Measuring 3D tree \n    imbalance of plant models using graph-theoretical approaches' by \n    M. Fischer, S. Kersting, and L. Kühn (2023) <arXiv:2307.14537>, which \n    provides precise mathematical definitions of the measurements.  \n    Furthermore, the package contains several helpful functions, for example, \n    some auxiliary functions for computing the ancestors, descendants, and \n    depths of the nodes, which ensures that the computations can be done in \n    linear time.  \n    Most functions of 'treeDbalance' require as input a rooted tree in the \n    'phylo3D' format, an extended 'phylo' format (as introduced in the R package\n    'ape' 1.9 in November 2006). Such a 'phylo3D' object must have at least \n    two new attributes next to those required by the 'phylo' format: \n    'node.coord', the coordinates of the nodes, as well as 'edge.weight', \n    the literal weight or volume of the edges.  \n    Optional attributes are 'edge.diam', the diameter of the edges, and\n    'edge.length', the length of the edges. For visualization purposes one\n    can also specify 'edge.type', which ranges from normal cylinder to bud\n    to leaf, as well as 'edge.color' to change the color of the edge depiction.  \n    This project was supported by the joint research project DIG-IT! \n    funded by the European Social Fund (ESF), reference:\n    ESF/14-BM-A55-0017/19, and the Ministry of Education, Science and\n    Culture of Mecklenburg-Western Pomerania, Germany, as well as by the\n    the project ArtIGROW, which is a part of the WIR!-Alliance 'ArtIFARM – \n    Artificial Intelligence in Farming' funded by the German Federal Ministry \n    of Education and Research (FKZ: 03WIR4805).",
    "version": "1.0.1",
    "maintainer": "Sophie Kersting <sophie_kersting@gmx.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25048,
    "package_name": "trialr",
    "title": "Clinical Trial Designs in 'rstan'",
    "description": "A collection of clinical trial designs and methods, implemented in \n    'rstan' and R, including: the Continual Reassessment Method by O'Quigley et \n    al. (1990) <doi:10.2307/2531628>; EffTox by Thall & Cook (2004) \n    <doi:10.1111/j.0006-341X.2004.00218.x>; the two-parameter logistic method of\n    Neuenschwander, Branson & Sponer (2008) <doi:10.1002/sim.3230>; and the \n    Augmented Binary method by Wason & Seaman (2013) <doi:10.1002/sim.5867>; and\n    more. We provide functions to aid model-fitting and analysis. \n    The 'rstan' implementations may also serve as a cookbook to anyone looking \n    to extend or embellish these models. We hope that this package encourages \n    the use of Bayesian methods in clinical trials. There is a preponderance of \n    early phase trial designs because this is where Bayesian methods are used \n    most. If there is a method you would like implemented, please get in touch.",
    "version": "0.1.6",
    "maintainer": "Kristian Brock <kristian.brock@gmail.com>",
    "url": "https://github.com/brockk/trialr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25063,
    "package_name": "trip",
    "title": "Tracking Data",
    "description": "Access and manipulate spatial tracking data, with straightforward \n coercion from and to other formats. Filter for speed and create time spent \n maps from tracking data. There are coercion methods to convert between 'trip'\n and 'ltraj' from 'adehabitatLT', and between 'trip' and 'psp' and 'ppp' from \n 'spatstat'. Trip objects can be created from raw or grouped data frames, and \n from types in the 'sp', sf', 'amt', 'trackeR', 'mousetrap', and other packages, \n Sumner, MD (2011) <https://figshare.utas.edu.au/articles/thesis/The_tag_location_problem/23209538>.",
    "version": "1.10.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/Trackage/trip",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25064,
    "package_name": "tripEstimation",
    "title": "Metropolis Sampler and Supporting Functions for Estimating\nAnimal Movement from Archival Tags and Satellite Fixes",
    "description": "Data handling and estimation functions for animal movement\n    estimation from archival or satellite tags. Helper functions are included\n    for making image summaries binned by time interval from Markov Chain Monte Carlo\n    simulations. ",
    "version": "0.0-46",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/Trackage/tripEstimation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25160,
    "package_name": "ttbary",
    "title": "Barycenter Methods for Spatial Point Patterns",
    "description": "Computes a point pattern in R^2 or on a graph that is representative of a collection of many data patterns. The result is an approximate barycenter (also known as Fréchet mean or prototype) based on a transport-transform metric. Possible choices include Optimal SubPattern Assignment (OSPA) and Spike Time metrics. Details can be found in Müller, Schuhmacher and Mateu (2020) <doi:10.1007/s11222-020-09932-y>.",
    "version": "0.3-2",
    "maintainer": "Dominic Schuhmacher <dominic.schuhmacher@mathematik.uni-goettingen.de>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25185,
    "package_name": "turboEM",
    "title": "A Suite of Convergence Acceleration Schemes for EM, MM and Other\nFixed-Point Algorithms",
    "description": "Algorithms for accelerating the convergence of slow,\n        monotone sequences from smooth, contraction mapping such as the\n        EM and MM algorithms. It can be used to accelerate any smooth,\n        linearly convergent acceleration scheme.  A tutorial style\n        introduction to this package is available in a vignette on the\n        CRAN download page or, when the package is loaded in an R\n        session, with vignette(\"turboEM\").",
    "version": "2025.1",
    "maintainer": "Ravi Varadhan <ravi.varadhan@jhu.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25195,
    "package_name": "tvem",
    "title": "Time-Varying Effect Models",
    "description": "Fits time-varying effect models (TVEM). These are a kind of application of varying-coefficient models in the context of longitudinal data, allowing the strength of linear, logistic, or Poisson regression relationships to change over time.  These models are described further in Tan, Shiyko, Li, Li & Dierker (2012) <doi:10.1037/a0025814>.  We thank Kaylee Litson, Patricia Berglund, Yajnaseni Chakraborti, and Hanjoo Kim for their valuable help with testing the package and the documentation. The development of this package was part of a research project supported by National Institutes of Health grants P50 DA039838 from the National Institute of Drug Abuse and 1R01 CA229542-01 from the National Cancer Institute and the NIH Office of Behavioral and Social Science Research. Content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions mentioned above. This software is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.",
    "version": "1.4.1",
    "maintainer": "John J. Dziak <dziakj1@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25217,
    "package_name": "twfy",
    "title": "Drive the API for TheyWorkForYou",
    "description": "An R wrapper around the API of TheyWorkForYou, a parliamentary \n    monitoring site that scrapes and repackages Hansard (the UK's parliamentary \n    record) and augments it with information from the Register of Members' \n    Interests, election results, and voting records to provide a unified \n    source of information about UK legislators and their activities. See \n    <http://www.theyworkforyou.com> for details.",
    "version": "0.1.0",
    "maintainer": "Will Lowe <wlowe@princeton.edu>",
    "url": "https://conjugateprior.github.io/twfy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25262,
    "package_name": "uci",
    "title": "Urban Centrality Index",
    "description": "Calculates the Urban Centrality Index (UCI) as in Pereira et al., \n             (2013) <doi:10.1111/gean.12002>. The UCI measures the \n             extent to which the spatial organization of a city or region varies \n             from extreme polycentric to extreme monocentric in a continuous \n             scale from 0 to 1. Values closer to 0 indicate more polycentric patterns\n             and values closer to 1 indicate a more monocentric urban form.",
    "version": "0.3.1",
    "maintainer": "Rafael H. M. Pereira <rafa.pereira.br@gmail.com>",
    "url": "https://github.com/ipeaGIT/uci, https://ipeagit.github.io/uci/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25263,
    "package_name": "ucie",
    "title": "Mapping 3D Data into CIELab Color Space",
    "description": "Returns a data frame with the names of the input data points and hex colors (or CIELab coordinates). Data can be mapped to colors for use in data visualization. It optimally maps data points into a polygon that represents the CIELab colour space. Since Euclidean distance approximates relative perceptual differences in CIELab color space, the result is a color encoding that aims to capture much of the structure of the original data. ",
    "version": "1.0.2",
    "maintainer": "Mikaela Koutrouli <mikaela.koutrouli@cpr.ku.dk>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25282,
    "package_name": "uklr",
    "title": "Client to United Kingdom Land Registry",
    "description": "Access data from Land Registry Open Data\n    <http://landregistry.data.gov.uk/> through 'SPARQL' queries. 'uklr'\n    supports the house price index, transaction and price paid data.",
    "version": "1.0.2",
    "maintainer": "Kostas Vasilopoulos <k.vasilopoulo@gmail.com>",
    "url": "https://kvasilopoulos.github.io/uklr/,\nhttps://github.com/kvasilopoulos/uklr/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25284,
    "package_name": "ulex",
    "title": "Unique Location Extractor",
    "description": "Extracts coordinates of an event location from text based on dictionaries of landmarks, roads, and areas. Only returns the location of an event of interest and ignores other location references; for example, if determining the location of a road traffic crash from the text \"crash near [location 1] heading towards [location 2]\", only the coordinates of \"location 1\" would be returned. Moreover, accounts for differences in spelling between how a user references a location and how a location is captured in location dictionaries.",
    "version": "0.1.0",
    "maintainer": "Robert Marty <rmarty@worldbank.org>",
    "url": "https://dime-worldbank.github.io/ulex/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25287,
    "package_name": "ultrapolaRplot",
    "title": "Plotting Ultrasound Tongue Traces",
    "description": "Plots traced ultrasound tongue imaging data according to a polar coordinate system. \n    There is currently support for plotting means and standard deviations of each category's trace;\n    Smoothing Splines Analysis of Variance (SSANOVA) could be implemented as well.  The origin of the \n    polar coordinates may be defined manually or automatically determined based on different \n    algorithms.\n    Currently 'ultrapolaRplot' supports ultrasound tongue imaging trace data from 'UltraTrace' \n    (<https://github.com/SwatPhonLab/UltraTrace>). 'UltraTrace' is capable of importing data from \n    Articulate Instruments AAA.\n    'read_textgrid.R' is required for opening TextGrids to determine category and alignment\n    information of ultrasound traces.",
    "version": "0.1.1",
    "maintainer": "Yana Outkin <youtkin1@swarthmore.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25303,
    "package_name": "unfold",
    "title": "Mapping Hidden Geometry into Future Sequences",
    "description": "A variational mapping approach that reveals and expands future temporal dynamics from folded high-dimensional geometric distance spaces, unfold turns a set of time series into a 4D block of pairwise distances between reframed windows, learns a variational mapper that maps those distances to the next reframed window, and produces horizon-wise predictive functions for each input series. In short: it unfolds the future path of each series from a folded geometric distance representation.",
    "version": "1.0.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "url": "https://rpubs.com/giancarlo_vercellino/unfold",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25337,
    "package_name": "unjoin",
    "title": "Separate a Data Frame by Normalization",
    "description": "Separate a data frame in two based on key columns. The function\n unjoin() provides an inside-out version of a nested data frame. This is used\n to identify duplication and normalize it (in the database sense) by linking\n two tables with the redundancy removed. This is a basic requirement for\n detecting topology within spatial structures that has motivated the need for\n this package as a building block for workflows within more applied projects.",
    "version": "0.1.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/unjoin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25338,
    "package_name": "unknownpleasur",
    "title": "Produce Regularly-Spaced Ridgelines at Arbitrary Angles",
    "description": "A set of function for producing ridgelines at arbitrary",
    "version": "0.1.0",
    "maintainer": "",
    "url": "https://github.com/mit-spatial-action/unknownpleasur",
    "exports": [],
    "topics": ["joy-division", "mapping", "r", "r-spatial", "raster", "sf", "spatial-analysis", "terra"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 25365,
    "package_name": "urbanplanr",
    "title": "Access and Process Common Data Sources Used in Planning Practice",
    "description": "High-level wrappers for American Community Survey,",
    "version": "0.1.0",
    "maintainer": "",
    "url": "https://github.com/ographiesresearch/urbanplanr",
    "exports": [],
    "topics": ["acs", "census-data", "lehd", "mapping", "sf", "spatial-analysis", "spatial-data", "tidycensus", "tidyverse", "urban-planning"],
    "score": "NA",
    "stars": 4
  },
  {
    "id": 25375,
    "package_name": "ursa",
    "title": "Non-Interactive Spatial Tools for Raster Processing and\nVisualization",
    "description": "S3 classes and methods for manipulation with georeferenced raster data: reading/writing, processing, multi-panel visualization.",
    "version": "3.11.5",
    "maintainer": "Nikita Platonov <platonov@sev-in.ru>",
    "url": "https://github.com/nplatonov/ursa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25438,
    "package_name": "validata",
    "title": "Validate Data Frames",
    "description": "Functions for validating the structure and properties of data frames. Answers essential questions about a data set after initial import or modification. What are the unique or missing values? What columns form a primary key? What are the properties of the numeric or categorical columns? What kind of overlap or mapping exists between 2 columns?",
    "version": "0.1.0",
    "maintainer": "Harrison Tietze <Harrison4192@gmail.com>",
    "url": "https://harrison4192.github.io/validata/,\nhttps://github.com/Harrison4192/validata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25449,
    "package_name": "valueEQ5D",
    "title": "Scoring EQ-5d Descriptive System",
    "description": "EQ-5D is a standard instrument (<https://euroqol.org/eq-5d-instruments/>) that measures the quality of life \n    often used in clinical and economic evaluations of health care technologies. Both adult versions of EQ-5D (EQ-5D-3L and EQ-5D-5L)\n    contain a descriptive system and visual analog scale. The descriptive system measures the patient's health in 5 dimensions: \n    the 5L versions has 5 levels and 3L version has 3 levels. The descriptive system scores are usually converted to index values \n    using country specific values sets (that incorporates the country preferences). This package allows the calculation of both descriptive system\n    scores to the index value scores. The value sets for EQ-5D-3L are from the references mentioned in the website <https://euroqol.org/eq-5d-instruments/eq-5d-3l-about/valuation/>\n    The value sets for EQ-5D-3L for a total of 31 countries are used for the valuation (see the user guide for a complete list of references).\n    The value sets for EQ-5D-5L are obtained from references mentioned in the <https://euroqol.org/eq-5d-instruments/eq-5d-5l-about/valuation-standard-value-sets/> and other sources.\n    The value sets for EQ-5D-5L for a total of 17 countries are used for the valuation (see the user guide for a complete list of references).\n    The package can also be used to map 5L scores to 3L index values for 10 countries: Denmark, France, Germany, Japan, Netherlands, Spain, Thailand, UK, USA, and Zimbabwe. \n    The value set and method for mapping are obtained from Van Hout et al (2012) <doi: 10.1016/j.jval.2012.02.008>. ",
    "version": "0.7.2",
    "maintainer": "Sheeja Manchira Krishnan <sheejamk@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25452,
    "package_name": "valuespotter",
    "title": "Landmark-Based GIS Distance Scoring Visualisation",
    "description": "With this Shiny app, you can easily find out where in Amsterdam the true valueable spots for housing are. This works by measuring the distance between each building and certain value marks, such as the closest Starbucks store or the closest access to the motorway.",
    "version": "0.1.02",
    "maintainer": "Nils Glück <info@nilsole.net>",
    "url": "https://github.com/NilsOle/valuespots",
    "exports": [],
    "topics": ["amsterdam", "gdal", "geospatial", "heatmap", "kadaster", "leaflet", "maps", "r", "raster", "real-estate", "shiny"],
    "score": "NA",
    "stars": 5
  },
  {
    "id": 25458,
    "package_name": "vapour",
    "title": "Access to the 'Geospatial Data Abstraction Library' ('GDAL')",
    "description": "Provides low-level access to 'GDAL' functionality.  \n  'GDAL' is the 'Geospatial Data Abstraction Library' a translator for raster and vector geospatial data formats \n  that presents a single raster abstract data model and single vector abstract data model to the calling application \n  for all supported formats <https://gdal.org/>. This package is focussed on providing exactly and only what GDAL does, to enable\n  developing further tools. ",
    "version": "0.15.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "url": "https://github.com/hypertidy/vapour,\nhttps://hypertidy.github.io/vapour/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25466,
    "package_name": "varbin",
    "title": "Optimal Binning of Continuous and Categorical Variables",
    "description": "Tool for easy and efficient discretization of continuous and categorical data. \n    The package calculates the most optimal binning of a given explanatory variable with respect to a \n    user-specified target variable. The purpose is to assign a unique Weight-of-Evidence value \n    to each of the calculated binpoints in order to recode the original variable. \n    The package allows users to impose certain restrictions on the functional form on the resulting \n    binning while maximizing the overall information value in the original data. \n    The package is well suited for logistic scoring models where input variables may be subject to \n    restrictions such as linearity by e.g. regulatory authorities. An excellent source describing in \n    detail the development of scorecards, and the role of Weight-of-Evidence coding in credit scoring \n    is (Siddiqi 2006, ISBN: 978–0-471–75451–0). The package utilizes the discrete nature of decision trees and \n    Isotonic Regression to accommodate the trade-off between flexible functional forms and maximum \n    information value.",
    "version": "0.2.1",
    "maintainer": "Daniel Safai <danielsafai@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25467,
    "package_name": "varbvs",
    "title": "Large-Scale Bayesian Variable Selection Using Variational\nMethods",
    "description": "Fast algorithms for fitting Bayesian variable selection\n    models and computing Bayes factors, in which the outcome (or\n    response variable) is modeled using a linear regression or a\n    logistic regression. The algorithms are based on the variational\n    approximations described in \"Scalable variational inference for\n    Bayesian variable selection in regression, and its accuracy in\n    genetic association studies\" (P. Carbonetto & M. Stephens, 2012,\n    <DOI:10.1214/12-BA703>). This software has been applied to large\n    data sets with over a million variables and thousands of samples.",
    "version": "2.6-10",
    "maintainer": "Peter Carbonetto <peter.carbonetto@gmail.com>",
    "url": "https://github.com/pcarbo/varbvs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25469,
    "package_name": "vardiag",
    "title": "Variogram Diagnostics",
    "description": "Interactive variogram diagnostics.",
    "version": "0.2-2",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "url": "https://github.com/edzer/vardiag/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25478,
    "package_name": "variosig",
    "title": "Testing Spatial Dependence Using Empirical Variogram",
    "description": "Applying Monte Carlo permutation to generate pointwise variogram envelope and checking for spatial dependence at different scales using permutation test. Empirical Brown's method and Fisher's method are used to compute overall p-value for hypothesis test.",
    "version": "0.3-1",
    "maintainer": "Craig Wang <craig.wang@math.uzh.ch>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25485,
    "package_name": "varycoef",
    "title": "Modeling Spatially Varying Coefficients",
    "description": "Implements a maximum likelihood estimation (MLE) method for\n    estimation and prediction of Gaussian process-based spatially varying\n    coefficient (SVC) models (Dambon et al. (2021a)\n    <doi:10.1016/j.spasta.2020.100470>).  Covariance tapering (Furrer et\n    al. (2006) <doi:10.1198/106186006X132178>) can be applied such that\n    the method scales to large data. Further, it implements a joint\n    variable selection of the fixed and random effects (Dambon et al.\n    (2021b) <doi:10.1080/13658816.2022.2097684>). The package and its \n    capabilities are described in (Dambon et al. (2021c)\n    <doi:10.48550/arXiv.2106.02364>).",
    "version": "0.3.6",
    "maintainer": "Jakob A. Dambon <jakob.dambon@math.ethz.ch>",
    "url": "https://github.com/jakobdambon/varycoef",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25489,
    "package_name": "vatcheckapi",
    "title": "Client for the 'vatcheckapi.com' VAT Validation API",
    "description": "An R client for the 'vatcheckapi.com' VAT number validation API. The API requires registration of an API key. Basic features are free, some require a paid subscription. You can find the full API documentation at <https://vatcheckapi.com/docs> .",
    "version": "0.1.0",
    "maintainer": "Dominik Kukacka <dominik@everapi.com>",
    "url": "https://vatcheckapi.com, https://vatcheckapi.com/docs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25492,
    "package_name": "vaxpmx",
    "title": "Vaccines Pharmacometrics",
    "description": "Estimate vaccine efficacy (VE) using immunogenicity data.\n    The inclusion of immunogenicity data in regression models can increase precision in VE. \n    The methods are described in the publications \"Elucidating vaccine efficacy using a correlate of protection, demographics, and logistic regression\" and \"Improving precision of vaccine efficacy evaluation using immune correlate data in time-to-event models\" by Julie Dudasova, Zdenek Valenta, and Jeffrey R. Sachs (2024).",
    "version": "0.0.6",
    "maintainer": "Julie Dudasova (MSD) <julie.dudasova@merck.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25499,
    "package_name": "vcd2df",
    "title": "Value Change Dump to Data Frame",
    "description": "Provides the 'vcd2df' function, which loads a IEEE 1364-1995/2001\n    VCD (.vcd) file, specified as a parameter of type string containing exactly\n    a file path, and returns an R dataframe containing values over time.  \n    A VCD file captures the register values at discrete timepoints from a \n    simulated trace of execution of a hardware design in Verilog or VHDL.\n    The returned dataframe contains a row for each register, by name, and a\n    column for each time point, specified VCD-style using octothorpe-prefixed \n    multiples of the timescale as strings. \n    The only non-trivial implementation details are that (1) VCD 'x' and 'z' \n    non-numerical values are encoded as negative value -1 (as otherwise all bit\n    values are positive) and (2) registers with repeated names in distinct \n    modules are ignored, rather than duplicated, as we anticipate these \n    registers to have the same values.\n    Read more in arXiv preprint: 'vcd2df' -- Leveraging Data Science Insights \n    for Hardware Security Research <doi:10.48550/arXiv.2505.06470>.",
    "version": "1.0.1",
    "maintainer": "Calvin Deutschbein <ckdeutschbein@willamette.edu>",
    "url": "https://github.com/vcd2df/r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25504,
    "package_name": "vcmeta",
    "title": "Varying Coefficient Meta-Analysis",
    "description": "Implements functions for varying coefficient meta-analysis methods. \n  These methods do not assume effect size homogeneity. Subgroup effect size \n  comparisons, general linear effect size contrasts, and linear models of \n  effect sizes based on varying coefficient methods can be used to describe \n  effect size heterogeneity. Varying coefficient meta-analysis methods do not \n  require the unrealistic assumptions of the traditional fixed-effect and \n  random-effects meta-analysis methods. For details see: \n  Statistical Methods for Psychologists, Volume 5, <https://dgbonett.sites.ucsc.edu/>.",
    "version": "1.5.0",
    "maintainer": "Douglas G. Bonett <dgbonett@ucsc.edu>",
    "url": "https://github.com/dgbonett/vcmeta/,\nhttps://dgbonett.github.io/vcmeta/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25514,
    "package_name": "vec2dtransf",
    "title": "2D Cartesian Coordinate Transformation",
    "description": "Applies affine and similarity transformations on vector spatial data (sp objects). Transformations can be defined from control points or directly from parameters. If redundant control points are provided Least Squares is applied allowing to obtain residuals and RMSE.",
    "version": "1.1.5",
    "maintainer": "German Carrillo <geotux_tuxman@linuxmail.org>",
    "url": "https://github.com/gacarrillor/vec2dtransf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25519,
    "package_name": "vectorsurvR",
    "title": "Data Access and Analytical Tools for 'VectorSurv' Users",
    "description": "Allows registered 'VectorSurv' <https://vectorsurv.org/> users access to data through the 'VectorSurv API' <https://api.vectorsurv.org/>. Additionally provides functions for analysis and visualization.",
    "version": "1.6.1",
    "maintainer": "Christina De Cesaris <cmdecesaris@ucdavis.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25525,
    "package_name": "vegan",
    "title": "Community Ecology Package",
    "description": "Ordination methods, diversity analysis and other\n  functions for community and vegetation ecologists.",
    "version": "2.7-2",
    "maintainer": "Jari Oksanen <jhoksane@gmail.com>",
    "url": "https://vegandevs.github.io/vegan/,\nhttps://github.com/vegandevs/vegan",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25562,
    "package_name": "via",
    "title": "Virtual Arrays",
    "description": "The base class 'VirtualArray' is defined, which acts as a wrapper around lists allowing users to fold arbitrary sequential data into n-dimensional, R-style virtual arrays. The derived 'XArray' class is defined to be used for homogeneous lists that contain a single class of objects. The 'RasterArray' and 'SfArray' classes enable the use of stacked spatial data instead of lists.",
    "version": "0.2.0",
    "maintainer": "Adam T. Kocsis <adam.t.kocsis@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25567,
    "package_name": "vicspatial",
    "title": "Access Victorian Spatial Data Through Web File Services (WFS)",
    "description": "Easily interfaces R to spatial datasets available through",
    "version": "0.3.1",
    "maintainer": "",
    "url": "https://github.com/JustinCally/vicspatial",
    "exports": [],
    "topics": ["gis", "r", "spatial-data", "wfs", "wfs-urls"],
    "score": "NA",
    "stars": 17
  },
  {
    "id": 25568,
    "package_name": "victor",
    "title": "Work With Mapbox Vector Tiles In R",
    "description": "Import data from the Mapbox Vector Tile API and convert",
    "version": "0.0.0.9000",
    "maintainer": "",
    "url": "https://github.com/adam-gruer/victor",
    "exports": [],
    "topics": ["gis", "mapbox-vector-tile", "mvt", "r", "simple-features", "vector-tiles", "visualization"],
    "score": "NA",
    "stars": 29
  },
  {
    "id": 25591,
    "package_name": "viridis",
    "title": "Colorblind-Friendly Color Maps for R",
    "description": "Color maps designed to improve graph readability for readers with \n    common forms of color blindness and/or color vision deficiency. The color \n    maps are also perceptually-uniform, both in regular form and also when \n    converted to black-and-white for printing. This package also contains \n    'ggplot2' bindings for discrete and continuous color and fill scales. A lean\n    version of the package called 'viridisLite' that does not include the \n    'ggplot2' bindings can be found at \n    <https://cran.r-project.org/package=viridisLite>.",
    "version": "0.6.5",
    "maintainer": "Simon Garnier <garnier@njit.edu>",
    "url": "https://sjmgarnier.github.io/viridis/,\nhttps://github.com/sjmgarnier/viridis/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25610,
    "package_name": "visor",
    "title": "Geospatial Tools for Visibility Analysis",
    "description": "Provides tools for visibility analysis in geospatial data. It\n    offers functionality to perform isovist calculations, using arbitrary\n    geometries as both viewpoints and occluders.",
    "version": "0.1.1",
    "maintainer": "Claudiu Forgaci <c.forgaci@tudelft.nl>",
    "url": "https://cityriverspaces.github.io/visor/,\nhttps://github.com/CityRiverSpaces/visor,\nhttps://doi.org/10.5281/zenodo.15133420",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25640,
    "package_name": "vmsae",
    "title": "Variational Multivariate Spatial Small Area Estimation",
    "description": "Variational Autoencoded Multivariate Spatial Fay-Herriot models are designed to efficiently estimate population parameters in small area estimation. This package implements the variational generalized multivariate spatial Fay-Herriot model (VGMSFH) using 'NumPyro' and 'PyTorch' backends, as demonstrated by Wang, Parker, and Holan (2025) <doi:10.48550/arXiv.2503.14710>. The 'vmsae' package provides utility functions to load weights of the pretrained variational autoencoders (VAEs) as well as tools to train custom VAEs tailored to users specific applications.",
    "version": "0.1.2",
    "maintainer": "Zhenhua Wang <zhenhua.wang@missouri.edu>",
    "url": "https://github.com/zhenhua-wang/vmsae",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25654,
    "package_name": "voluModel",
    "title": "Modeling Species Distributions in Three Dimensions",
    "description": "Facilitates modeling species' ecological niches and \n  geographic distributions based on occurrences and environments that \n  have a vertical as well as horizontal component, and projecting models \n  into three-dimensional geographic space. Working in three dimensions is \n  useful in an aquatic context when the organisms one wishes to model can \n  be found across a wide range of depths in the water column. The package\n  also contains functions to automatically generate marine training\n  model training regions using machine learning, and interpolate and smooth\n  patchily sampled environmental rasters using thin plate splines.\n  Davis Rabosky AR, Cox CL, Rabosky DL, Title PO, Holmes IA, Feldman A, McGuire JA (2016) <doi:10.1038/ncomms11484>.\n  Nychka D, Furrer R, Paige J, Sain S (2021) <doi:10.5065/D6W957CT>.\n  Pateiro-Lopez B, Rodriguez-Casal A (2022) <https://CRAN.R-project.org/package=alphahull>.",
    "version": "0.2.3",
    "maintainer": "Hannah L. Owens <hannah.owens@gmail.com>",
    "url": "https://hannahlowens.github.io/voluModel/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25725,
    "package_name": "wand",
    "title": "Retrieve 'Magic' Attributes from Files and Directories",
    "description": "'MIME' types are shorthand descriptors for\n      file contents and can be determined from \"magic\"\n      bytes in file headers, file contents or intuited\n      from file extensions. Tools are provided to\n      perform curated \"magic\" tests as well as mapping\n      'MIME' types from a database of over 1,500\n      extension mappings.",
    "version": "0.5.0",
    "maintainer": "Bob Rudis <bob@rud.is>",
    "url": "http://gitlab.com/hrbrmstr/wand",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25729,
    "package_name": "warehouseTools",
    "title": "Heuristics for Solving the Traveling Salesman Problem in\nWarehouse Layouts",
    "description": "Heuristic methods to solve the routing problems in a warehouse management. Package includes several heuristics such as the Midpoint, Return, S-Shape and Semi-Optimal Heuristics for designation of the picker’s route in order picking. The heuristics aim to provide the acceptable travel distances while considering warehouse layout constraints such as aisles and shelves. \n    It also includes implementation of the COPRAS (COmplex PRoportional ASsessment) method for supporting selection of locations to be visited by the picker in shared storage systems. The package is designed to facilitate more efficient warehouse routing and logistics operations.     \n    see:\n    Bartholdi, J. J.,  Hackman, S. T. (2019). \"WAREHOUSE & DISTRIBUTION SCIENCE. Release 0.98.1.\"\n    The Supply Chain & Logistics Institute. H. Milton Stewart School of Industrial and Systems Engineering. \n    Georgia Institute of Technology. \n    <https://www.warehouse-science.com/book/editions/wh-sci-0.98.1.pdf>.",
    "version": "0.1.4",
    "maintainer": "Andrzej Dudek <andrzej.dudek@ue.wroc.pl>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25771,
    "package_name": "wdiEF",
    "title": "Calculation of the Water Deficit Index (WDI) and the Evaporative\nFraction (EF) on Rasters",
    "description": "Provides functions to calculate the Water Deficit Index (WDI) and \n    the Evaporative Fraction (EF) using geospatial raster data such as fractional \n    vegetation cover (FVC) and surface-air temperature difference (TS-TA). \n    The package automates regression-based edge fitting and produces continuous \n    spatial maps of surface moisture and evaporative dynamics.",
    "version": "1.0.4",
    "maintainer": "Gaelle Hamelin <gaelle.hamelin@institut-agro.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25776,
    "package_name": "wdnr.gis",
    "title": "Pull Spatial Layers from 'WDNR ArcGIS REST API'",
    "description": "Functions for finding and pulling data from the\n  'Wisconsin Department of Natural Resources ArcGIS REST APIs'\n  <https://dnrmaps.wi.gov/arcgis/rest/services> and \n  <https://dnrmaps.wi.gov/arcgis2/rest/services>.",
    "version": "0.1.7",
    "maintainer": "Paul Frater <paul.frater@wisconsin.gov>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25796,
    "package_name": "webmap",
    "title": "Create Interactive Web Maps Using 'The National Map' Services",
    "description": "Creates interactive web maps using the 'JavaScript' 'Leaflet'\n    library with base layers of 'The National Map' ('TNM'). 'TNM' services\n    provide access to base geospatial information that describes the landscape\n    of the United States and its territories. This package is dependent on, and\n    intended to be used with, the 'leaflet' package.",
    "version": "1.1.1",
    "maintainer": "Jason C. Fisher <jfisher@usgs.gov>",
    "url": "https://rconnect.usgs.gov/INLPO/webmap-main/,\nhttps://code.usgs.gov/inl/webmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25826,
    "package_name": "wellknown",
    "title": "Convert Between 'WKT' and 'GeoJSON'",
    "description": "Convert 'WKT' to 'GeoJSON' and 'GeoJSON' to 'WKT'. Functions",
    "version": "0.7.4",
    "maintainer": "",
    "url": "https://github.com/ropensci-archive/wellknown",
    "exports": [],
    "topics": ["geojson", "geospatial", "r", "r-package", "rstats", "spatial", "wellknown", "wkb", "wkt"],
    "score": "NA",
    "stars": 17
  },
  {
    "id": 25843,
    "package_name": "whatthreewords",
    "title": "Work with the 'what3words' API for Easy Location Referencing",
    "description": "Use the 'what3words' API \n    <https://developer.what3words.com/public-api> to return three words which \n    uniquely identify every 3m x 3m square on Earth. It is also possible to \n    return coordinates from any valid three words location. Supports multiple \n    languages. ",
    "version": "0.1.3",
    "maintainer": "David Smith <david.alex.smith@gmail.com>",
    "url": "https://davidasmith.github.io/whatthreewords/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25873,
    "package_name": "wikiprofiler",
    "title": "'WikiPathway' Based Data Integration and Visualization",
    "description": "Queries online 'WikiPathway' graphics and allows mapping user data (e.g., expression values) on the graph. The package designs a grammar of graphic syntax that using pipe operator to add graphic layer.",
    "version": "0.1.6",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "url": "https://yulab-smu.top/contribution-knowledge-mining/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25878,
    "package_name": "wildlifeDI",
    "title": "Calculate Indices of Dynamic Interaction for Wildlife Tracking\nData",
    "description": "Dynamic interaction refers to spatial-temporal associations in the movements of two (or more) animals. This package provides tools for calculating a suite of indices used for quantifying dynamic interaction with wildlife telemetry data. For more information on each of the methods employed see the references within. The package (as of version >= 0.3) also has new tools for automating contact analysis in large tracking datasets. The package (as of version 1.0) uses the 'move2' class of objects for working with tracking dataset.",
    "version": "1.0.1",
    "maintainer": "Jed Long <jed.long@uwo.ca>",
    "url": "https://github.com/jedalong/wildlifeDI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25883,
    "package_name": "windAC",
    "title": "Area Correction Methods",
    "description": "Post-construction fatality monitoring studies at wind facilities are based on data from searches for bird and bat carcasses in plots beneath turbines. Bird and bat carcasses can fall outside of the search plot. Bird and bat carcasses from wind turbines often fall outside of the searched area. To compensate, area correction (AC) estimations are calculated to estimate the percentage of fatalities that fall within the searched area versus those that fall outside of it. This package provides two likelihood based methods and one physics based method (Hull and Muir (2010) <doi:10.1080/14486563.2010.9725253>, Huso and Dalthorp (2014) <doi:10.1002/jwmg.663>) to estimate the carcass fall distribution. There are also functions for calculating the proportion of area searched within one unit annuli, log logistic distribution functions, and truncated distribution functions.",
    "version": "1.2.10",
    "maintainer": "Daniel Riser-Espinoza <despinoza@west-inc.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25888,
    "package_name": "wingen",
    "title": "Continuous Mapping of Genetic Diversity",
    "description": "Generate continuous maps of genetic diversity using moving windows with options for rarefaction, interpolation, and masking as described in Bishop et al. (2023) <doi:10.1111/2041-210X.14090>.",
    "version": "2.2.0",
    "maintainer": "Anusha Bishop <anusha.bishop@berkeley.edu>",
    "url": "https://github.com/AnushaPB/wingen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25897,
    "package_name": "wk",
    "title": "Lightweight Well-Known Geometry Parsing",
    "description": "Provides a minimal R and C++ API for parsing\n  well-known binary and well-known text representation of\n  geometries to and from R-native formats.\n  Well-known binary is compact\n  and fast to parse; well-known text is human-readable\n  and is useful for writing tests. These formats are\n  useful in R only if the information they contain can be\n  accessed in R, for which high-performance functions\n  are provided here.",
    "version": "0.9.5",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "url": "https://paleolimbot.github.io/wk/,\nhttps://github.com/paleolimbot/wk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25898,
    "package_name": "wkb",
    "title": "Convert Between Spatial Objects and Well-Known Binary Geometry",
    "description": "Utility functions to convert between the 'Spatial' classes\n  specified by the package 'sp', and the well-known binary '(WKB)'\n  representation for geometry specified by the 'Open Geospatial Consortium'.\n  Supports 'Spatial' objects of class 'SpatialPoints',\n  'SpatialPointsDataFrame', 'SpatialLines', 'SpatialLinesDataFrame',\n  'SpatialPolygons', and 'SpatialPolygonsDataFrame'. Supports 'WKB' geometry\n  types 'Point', 'LineString', 'Polygon', 'MultiPoint', 'MultiLineString', and\n  'MultiPolygon'. Includes extensions to enable creation of maps with\n  'TIBCO Spotfire'.",
    "version": "0.4-0",
    "maintainer": "Ian Cook <ianmcook@gmail.com>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25909,
    "package_name": "womblR",
    "title": "Spatiotemporal Boundary Detection Model for Areal Unit Data",
    "description": "Implements a spatiotemporal boundary detection model with a dissimilarity\n    metric for areal data with inference in a Bayesian setting using Markov chain\n    Monte Carlo (MCMC). The response variable can be modeled as Gaussian (no nugget),\n    probit or Tobit link and spatial correlation is introduced at each time point\n    through a conditional autoregressive (CAR) prior. Temporal correlation is introduced\n    through a hierarchical structure and can be specified as exponential or first-order\n    autoregressive. Full details of the package can be found in the accompanying vignette.\n    Furthermore, the details of the package can be found in \"Diagnosing Glaucoma \n    Progression with Visual Field Data Using a Spatiotemporal Boundary Detection Method\", \n    by Berchuck et al (2019) <doi:10.1080/01621459.2018.1537911>.",
    "version": "1.0.6",
    "maintainer": "Samuel I. Berchuck <sib2@duke.edu>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25920,
    "package_name": "wordnet",
    "title": "WordNet Interface",
    "description": "An interface to WordNet using the Jawbone Java API to WordNet.\n  WordNet (<https://wordnet.princeton.edu/>) is a large lexical database of\n  English.  Nouns, verbs, adjectives and adverbs are grouped into sets of\n  cognitive synonyms (synsets), each expressing a distinct concept.  Synsets\n  are interlinked by means of conceptual-semantic and lexical relations.\n  Please note that WordNet(R) is a registered tradename.  Princeton\n  University makes WordNet available to research and commercial users\n  free of charge provided the terms of their license\n  (<https://wordnet.princeton.edu/license-and-commercial-use>) are followed,\n  and proper reference is made to the project using an appropriate\n  citation (<https://wordnet.princeton.edu/citing-wordnet>).\n  The WordNet database files need to be made available separately,\n  either via package 'wordnetDicts' from <https://datacube.wu.ac.at>,\n  installing system packages where available, or direct download from\n  <https://wordnetcode.princeton.edu/3.0/WNdb-3.0.tar.gz>.",
    "version": "0.1-17",
    "maintainer": "Kurt Hornik <Kurt.Hornik@R-project.org>",
    "url": "https://wordnet.princeton.edu/,\nhttps://sites.google.com/site/mfwallace/jawbone",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25932,
    "package_name": "workspace",
    "title": "Manage Collections of Datasets and Objects",
    "description": "Create, store, read and manage structured collections of\n    datasets and other objects using a 'workspace', then bundle it into a\n    compressed archive.  Using open and interoperable formats makes it\n    possible to exchange bundled data from 'R' to other languages such as\n    'Python' or 'Julia'.  Multiple formats are supported 'Parquet',\n    'JSON', 'yaml', spatial data and raster data are supported.",
    "version": "0.1.6",
    "maintainer": "Eli Daniels <eli.daniels@ardata.fr>",
    "url": "https://github.com/ardata-fr/workspace",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25942,
    "package_name": "wpeR",
    "title": "Streamlined Analysis of Wild Pedigree Data",
    "description": "Analyzing pedigree data of wild\n    populations. While primarily designed to process outputs from the\n    'COLONY' (Jones & Wang (2010) <doi:10.1111/j.1755-0998.2009.02787.x>)\n    pedigree reconstruction software, it can also accommodate\n    data from other sources. By linking reconstructed pedigrees with\n    genetic sample metadata, 'wpeR' produces spatial and temporal\n    visualizations as well as tabular summaries that support\n    interpretation of family structures and dynamics. The main goal of the\n    package is to provide a solution for the analysis of\n    complex wild pedigree data and to help the user to gain insights\n    into genetic relationships within wild animal populations.",
    "version": "0.1.0",
    "maintainer": "Gregor Simcic <grega0simcic@gmail.com>",
    "url": "https://gr3602.github.io/wpeR/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 25989,
    "package_name": "xLLiM",
    "title": "High Dimensional Locally-Linear Mapping",
    "description": "Provides a tool for non linear mapping (non linear regression) using a mixture of regression model and an inverse regression strategy. The methods include the GLLiM model (see Deleforge et al (2015) <DOI:10.1007/s11222-014-9461-5>) based on Gaussian mixtures and a robust version of GLLiM, named SLLiM (see Perthame et al (2016) <DOI:10.1016/j.jmva.2017.09.009>) based on a mixture of Generalized Student distributions. The methods also include BLLiM (see Devijver et al (2017) <arXiv:1701.07899>) which is an extension of GLLiM with a sparse block diagonal structure for large covariance matrices (particularly interesting for transcriptomic data).",
    "version": "2.3",
    "maintainer": "Emeline Perthame <emeline.perthame@pasteur.fr>",
    "url": "",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 26112,
    "package_name": "z22",
    "title": "Official Gridded Data from the German Census 2022",
    "description": "Provides fast and easy access to German census grid data\n    from the 2011 and 2022 censuses <https://www.zensus2022.de/>, including a\n    wide range of socio-economic indicators at multiple spatial resolutions\n    (100m, 1km, 10km). Enables efficient download, processing, and analysis\n    of large census datasets covering population, households, families,\n    dwellings, and buildings. Harmonized data structures allow direct\n    comparison with the 2011 census, supporting temporal and spatial analyses.\n    Facilitates conversion of data into common formats for spatial analysis and\n    mapping ('terra', 'sf', 'ggplot2').",
    "version": "1.1.0",
    "maintainer": "Jonas Lieth <jonas.lieth@gesis.org>",
    "url": "https://github.com/jslth/z22/, https://jslth.github.io/z22/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 26156,
    "package_name": "zonebuilder",
    "title": "Create and Explore Geographic Zoning Systems",
    "description": "Functions, documentation and example data to help divide\n    geographic space into discrete polygons (zones).\n    The package supports new zoning systems that are documented in the\n    accompanying paper,\n    \"ClockBoard: A zoning system for urban analysis\",\n    by Lovelace et al. (2022) <doi:10.5311/JOSIS.2022.24.172>.\n    The functions are motivated by research into the merits of different zoning systems\n    (Openshaw, 1977) <doi:10.1068/a090169>. A flexible ClockBoard zoning system is\n    provided, which breaks-up space by concentric rings\n    and radial lines emanating from a central point.\n    By default, the diameter of the rings grow according to the triangular number sequence\n    (Ross & Knott, 2019) <doi:10.1080/26375451.2019.1598687> with the first 4 doughnuts\n    (or annuli) measuring 1, 3, 6, and 10 km wide.\n    These annuli are subdivided into equal segments (12 by default), creating the\n    visual impression of a dartboard. Zones are labelled according to\n    distance to the centre and angular distance from North, creating a simple\n    geographic zoning and labelling system useful for visualising geographic\n    phenomena with a clearly demarcated central location such as cities.",
    "version": "0.1.0",
    "maintainer": "Robin Lovelace <rob00x@gmail.com>",
    "url": "https://github.com/zonebuilders/zonebuilder,\nhttps://zonebuilders.github.io/zonebuilder/",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  },
  {
    "id": 26161,
    "package_name": "zoom",
    "title": "A Spatial Data Visualization Tool",
    "description": "You can call zm(), when displaying any active plot to enter an\n    interactive session to zoom/navigate any plot. The development\n    version, as well as binary releases can be found at\n    <https://github.com/cbarbu/R-package-zoom>. ",
    "version": "2.0.6",
    "maintainer": "Corentin M Barbu <corentin.barbu@gmail.com>",
    "url": "https://github.com/cbarbu/R-package-zoom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0
  }
]
