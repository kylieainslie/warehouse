[
  {
    "id": 1273,
    "package_name": "stars",
    "title": "Spatiotemporal Arrays, Raster and Vector Data Cubes",
    "description": "Reading, manipulating, writing and plotting spatiotemporal\narrays (raster and vector data cubes) in 'R', using 'GDAL'\nbindings provided by 'sf', and 'NetCDF' bindings by 'ncmeta'\nand 'RNetCDF'.",
    "version": "0.7-0",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "author": "Edzer Pebesma [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8049-7069>),\nMichael Sumner [ctb] (ORCID: <https://orcid.org/0000-0002-2471-7511>),\nEtienne Racine [ctb],\nAdriano Fantini [ctb],\nDavid Blodgett [ctb],\nKrzysztof Dyba [ctb] (ORCID: <https://orcid.org/0000-0002-8614-3816>)",
    "url": "https://r-spatial.github.io/stars/,\nhttps://github.com/r-spatial/stars/",
    "bug_reports": "https://github.com/r-spatial/stars/issues/",
    "repository": "",
    "exports": [
      [
        "%in%"
      ],
      [
        "as.tbl_cube.stars"
      ],
      [
        "detect.driver"
      ],
      [
        "expand_dimensions"
      ],
      [
        "geom_stars"
      ],
      [
        "make_intervals"
      ],
      [
        "read_mdim"
      ],
      [
        "read_ncdf"
      ],
      [
        "read_stars"
      ],
      [
        "st_apply"
      ],
      [
        "st_as_stars"
      ],
      [
        "st_cells"
      ],
      [
        "st_contour"
      ],
      [
        "st_dim_to_attr"
      ],
      [
        "st_dimensions"
      ],
      [
        "st_dimensions<-"
      ],
      [
        "st_downsample"
      ],
      [
        "st_extract"
      ],
      [
        "st_flip"
      ],
      [
        "st_geotransform"
      ],
      [
        "st_geotransform<-"
      ],
      [
        "st_get_dimension_values"
      ],
      [
        "st_mosaic"
      ],
      [
        "st_raster_type"
      ],
      [
        "st_rasterize"
      ],
      [
        "st_redimension"
      ],
      [
        "st_res"
      ],
      [
        "st_rgb"
      ],
      [
        "st_rotate"
      ],
      [
        "st_set_bbox"
      ],
      [
        "st_set_dimensions"
      ],
      [
        "st_sfc2xy"
      ],
      [
        "st_tile"
      ],
      [
        "st_warp"
      ],
      [
        "st_xy2sfc"
      ],
      [
        "write_mdim"
      ],
      [
        "write_stars"
      ]
    ],
    "topics": [
      [
        "raster"
      ],
      [
        "satellite-images"
      ],
      [
        "spatial"
      ]
    ],
    "score": 18.3493,
    "stars": 593,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "stars Spatiotemporal Arrays, Raster and Vector Data Cubes Reading, manipulating, writing and plotting spatiotemporal\narrays (raster and vector data cubes) in 'R', using 'GDAL'\nbindings provided by 'sf', and 'NetCDF' bindings by 'ncmeta'\nand 'RNetCDF'. %in% as.tbl_cube.stars detect.driver expand_dimensions geom_stars make_intervals read_mdim read_ncdf read_stars st_apply st_as_stars st_cells st_contour st_dim_to_attr st_dimensions st_dimensions<- st_downsample st_extract st_flip st_geotransform st_geotransform<- st_get_dimension_values st_mosaic st_raster_type st_rasterize st_redimension st_res st_rgb st_rotate st_set_bbox st_set_dimensions st_sfc2xy st_tile st_warp st_xy2sfc write_mdim write_stars raster satellite-images spatial"
  },
  {
    "id": 1478,
    "package_name": "zoo",
    "title": "S3 Infrastructure for Regular and Irregular Time Series (Z's\nOrdered Observations)",
    "description": "An S3 class with methods for totally ordered indexed\nobservations. It is particularly aimed at irregular time series\nof numeric vectors/matrices and factors. zoo's key design goals\nare independence of a particular index/date/time class and\nconsistency with ts and base R by providing methods to extend\nstandard generics.",
    "version": "1.8-14",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "author": "Achim Zeileis [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-0918-3766>),\nGabor Grothendieck [aut],\nJeffrey A. Ryan [aut],\nJoshua M. Ulrich [ctb],\nFelix Andrews [ctb]",
    "url": "https://zoo.R-Forge.R-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "as.Date"
      ],
      [
        "as.Date.numeric"
      ],
      [
        "as.Date.ts"
      ],
      [
        "as.Date.yearmon"
      ],
      [
        "as.Date.yearqtr"
      ],
      [
        "as.yearmon"
      ],
      [
        "as.yearmon.default"
      ],
      [
        "as.yearqtr"
      ],
      [
        "as.yearqtr.default"
      ],
      [
        "as.zoo"
      ],
      [
        "as.zoo.default"
      ],
      [
        "as.zooreg"
      ],
      [
        "as.zooreg.default"
      ],
      [
        "autoplot.zoo"
      ],
      [
        "cbind.zoo"
      ],
      [
        "coredata"
      ],
      [
        "coredata.default"
      ],
      [
        "coredata<-"
      ],
      [
        "facet_free"
      ],
      [
        "format.yearqtr"
      ],
      [
        "fortify.zoo"
      ],
      [
        "frequency<-"
      ],
      [
        "ifelse.zoo"
      ],
      [
        "index"
      ],
      [
        "index<-"
      ],
      [
        "index2char"
      ],
      [
        "is.regular"
      ],
      [
        "is.zoo"
      ],
      [
        "make.par.list"
      ],
      [
        "MATCH"
      ],
      [
        "MATCH.default"
      ],
      [
        "MATCH.times"
      ],
      [
        "median.zoo"
      ],
      [
        "merge.zoo"
      ],
      [
        "na.aggregate"
      ],
      [
        "na.aggregate.default"
      ],
      [
        "na.approx"
      ],
      [
        "na.approx.default"
      ],
      [
        "na.fill"
      ],
      [
        "na.fill.default"
      ],
      [
        "na.fill0"
      ],
      [
        "na.locf"
      ],
      [
        "na.locf.default"
      ],
      [
        "na.locf0"
      ],
      [
        "na.spline"
      ],
      [
        "na.spline.default"
      ],
      [
        "na.StructTS"
      ],
      [
        "na.trim"
      ],
      [
        "na.trim.default"
      ],
      [
        "na.trim.ts"
      ],
      [
        "ORDER"
      ],
      [
        "ORDER.default"
      ],
      [
        "panel.lines.its"
      ],
      [
        "panel.lines.tis"
      ],
      [
        "panel.lines.ts"
      ],
      [
        "panel.lines.zoo"
      ],
      [
        "panel.plot.custom"
      ],
      [
        "panel.plot.default"
      ],
      [
        "panel.points.its"
      ],
      [
        "panel.points.tis"
      ],
      [
        "panel.points.ts"
      ],
      [
        "panel.points.zoo"
      ],
      [
        "panel.polygon.its"
      ],
      [
        "panel.polygon.tis"
      ],
      [
        "panel.polygon.ts"
      ],
      [
        "panel.polygon.zoo"
      ],
      [
        "panel.rect.its"
      ],
      [
        "panel.rect.tis"
      ],
      [
        "panel.rect.ts"
      ],
      [
        "panel.rect.zoo"
      ],
      [
        "panel.segments.its"
      ],
      [
        "panel.segments.tis"
      ],
      [
        "panel.segments.ts"
      ],
      [
        "panel.segments.zoo"
      ],
      [
        "panel.text.its"
      ],
      [
        "panel.text.tis"
      ],
      [
        "panel.text.ts"
      ],
      [
        "panel.text.zoo"
      ],
      [
        "plot.zoo"
      ],
      [
        "quantile.zoo"
      ],
      [
        "rbind.zoo"
      ],
      [
        "read.csv.zoo"
      ],
      [
        "read.csv2.zoo"
      ],
      [
        "read.delim.zoo"
      ],
      [
        "read.delim2.zoo"
      ],
      [
        "read.table.zoo"
      ],
      [
        "read.zoo"
      ],
      [
        "rev.zoo"
      ],
      [
        "rollapply"
      ],
      [
        "rollapplyr"
      ],
      [
        "rollmax"
      ],
      [
        "rollmax.default"
      ],
      [
        "rollmaxr"
      ],
      [
        "rollmean"
      ],
      [
        "rollmean.default"
      ],
      [
        "rollmeanr"
      ],
      [
        "rollmedian"
      ],
      [
        "rollmedian.default"
      ],
      [
        "rollmedianr"
      ],
      [
        "rollsum"
      ],
      [
        "rollsum.default"
      ],
      [
        "rollsumr"
      ],
      [
        "scale_type.yearmon"
      ],
      [
        "scale_type.yearqtr"
      ],
      [
        "scale_x_yearmon"
      ],
      [
        "scale_x_yearqtr"
      ],
      [
        "scale_y_yearmon"
      ],
      [
        "scale_y_yearqtr"
      ],
      [
        "Sys.yearmon"
      ],
      [
        "Sys.yearqtr"
      ],
      [
        "time<-"
      ],
      [
        "tinyplot.zoo"
      ],
      [
        "write.zoo"
      ],
      [
        "xblocks"
      ],
      [
        "xblocks.default"
      ],
      [
        "xtfrm.zoo"
      ],
      [
        "yearmon"
      ],
      [
        "yearmon_trans"
      ],
      [
        "yearqtr"
      ],
      [
        "yearqtr_trans"
      ],
      [
        "zoo"
      ],
      [
        "zooreg"
      ]
    ],
    "topics": [],
    "score": 16.5984,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "zoo S3 Infrastructure for Regular and Irregular Time Series (Z's\nOrdered Observations) An S3 class with methods for totally ordered indexed\nobservations. It is particularly aimed at irregular time series\nof numeric vectors/matrices and factors. zoo's key design goals\nare independence of a particular index/date/time class and\nconsistency with ts and base R by providing methods to extend\nstandard generics. as.Date as.Date.numeric as.Date.ts as.Date.yearmon as.Date.yearqtr as.yearmon as.yearmon.default as.yearqtr as.yearqtr.default as.zoo as.zoo.default as.zooreg as.zooreg.default autoplot.zoo cbind.zoo coredata coredata.default coredata<- facet_free format.yearqtr fortify.zoo frequency<- ifelse.zoo index index<- index2char is.regular is.zoo make.par.list MATCH MATCH.default MATCH.times median.zoo merge.zoo na.aggregate na.aggregate.default na.approx na.approx.default na.fill na.fill.default na.fill0 na.locf na.locf.default na.locf0 na.spline na.spline.default na.StructTS na.trim na.trim.default na.trim.ts ORDER ORDER.default panel.lines.its panel.lines.tis panel.lines.ts panel.lines.zoo panel.plot.custom panel.plot.default panel.points.its panel.points.tis panel.points.ts panel.points.zoo panel.polygon.its panel.polygon.tis panel.polygon.ts panel.polygon.zoo panel.rect.its panel.rect.tis panel.rect.ts panel.rect.zoo panel.segments.its panel.segments.tis panel.segments.ts panel.segments.zoo panel.text.its panel.text.tis panel.text.ts panel.text.zoo plot.zoo quantile.zoo rbind.zoo read.csv.zoo read.csv2.zoo read.delim.zoo read.delim2.zoo read.table.zoo read.zoo rev.zoo rollapply rollapplyr rollmax rollmax.default rollmaxr rollmean rollmean.default rollmeanr rollmedian rollmedian.default rollmedianr rollsum rollsum.default rollsumr scale_type.yearmon scale_type.yearqtr scale_x_yearmon scale_x_yearqtr scale_y_yearmon scale_y_yearqtr Sys.yearmon Sys.yearqtr time<- tinyplot.zoo write.zoo xblocks xblocks.default xtfrm.zoo yearmon yearmon_trans yearqtr yearqtr_trans zoo zooreg "
  },
  {
    "id": 667,
    "package_name": "gstat",
    "title": "Spatial and Spatio-Temporal Geostatistical Modelling, Prediction\nand Simulation",
    "description": "Variogram modelling; simple, ordinary and universal point\nor block (co)kriging; spatio-temporal kriging; sequential\nGaussian or indicator (co)simulation; variogram and variogram\nmap plotting utility functions; supports sf and stars.",
    "version": "2.1-5",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "author": "Edzer Pebesma [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8049-7069>), Benedikt Graeler\n[aut]",
    "url": "https://github.com/r-spatial/gstat/,\nhttps://r-spatial.github.io/gstat/",
    "bug_reports": "https://github.com/r-spatial/gstat/issues/",
    "repository": "",
    "exports": [
      [
        "[.gstat"
      ],
      [
        "as.vgm.variomodel"
      ],
      [
        "cross.name"
      ],
      [
        "estiStAni"
      ],
      [
        "extractPar"
      ],
      [
        "extractParNames"
      ],
      [
        "fit.lmc"
      ],
      [
        "fit.StVariogram"
      ],
      [
        "fit.variogram"
      ],
      [
        "fit.variogram.gls"
      ],
      [
        "fit.variogram.reml"
      ],
      [
        "get_gstat_progress"
      ],
      [
        "get.contr"
      ],
      [
        "gstat"
      ],
      [
        "gstat.cv"
      ],
      [
        "hscat"
      ],
      [
        "idw"
      ],
      [
        "idw0"
      ],
      [
        "krige"
      ],
      [
        "krige.cv"
      ],
      [
        "krige0"
      ],
      [
        "krigeSimCE"
      ],
      [
        "krigeST"
      ],
      [
        "krigeSTSimTB"
      ],
      [
        "krigeSTTg"
      ],
      [
        "krigeTg"
      ],
      [
        "map.to.lev"
      ],
      [
        "ossfim"
      ],
      [
        "panel.pointPairs"
      ],
      [
        "set_gstat_progress"
      ],
      [
        "show.vgms"
      ],
      [
        "spplot.vcov"
      ],
      [
        "variogram"
      ],
      [
        "variogramLine"
      ],
      [
        "variogramST"
      ],
      [
        "variogramSurface"
      ],
      [
        "vgm"
      ],
      [
        "vgm.panel.xyplot"
      ],
      [
        "vgmArea"
      ],
      [
        "vgmAreaST"
      ],
      [
        "vgmST"
      ],
      [
        "xyz2img"
      ]
    ],
    "topics": [
      [
        "openblas"
      ]
    ],
    "score": 15.8623,
    "stars": 205,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "gstat Spatial and Spatio-Temporal Geostatistical Modelling, Prediction\nand Simulation Variogram modelling; simple, ordinary and universal point\nor block (co)kriging; spatio-temporal kriging; sequential\nGaussian or indicator (co)simulation; variogram and variogram\nmap plotting utility functions; supports sf and stars. [.gstat as.vgm.variomodel cross.name estiStAni extractPar extractParNames fit.lmc fit.StVariogram fit.variogram fit.variogram.gls fit.variogram.reml get_gstat_progress get.contr gstat gstat.cv hscat idw idw0 krige krige.cv krige0 krigeSimCE krigeST krigeSTSimTB krigeSTTg krigeTg map.to.lev ossfim panel.pointPairs set_gstat_progress show.vgms spplot.vcov variogram variogramLine variogramST variogramSurface vgm vgm.panel.xyplot vgmArea vgmAreaST vgmST xyz2img openblas"
  },
  {
    "id": 1175,
    "package_name": "sandwich",
    "title": "Robust Covariance Matrix Estimators",
    "description": "Object-oriented software for model-robust covariance\nmatrix estimators. Starting out from the basic robust\nEicker-Huber-White sandwich covariance methods include:\nheteroscedasticity-consistent (HC) covariances for\ncross-section data; heteroscedasticity- and\nautocorrelation-consistent (HAC) covariances for time series\ndata (such as Andrews' kernel HAC, Newey-West, and WEAVE\nestimators); clustered covariances (one-way and multi-way);\npanel and panel-corrected covariances;\nouter-product-of-gradients covariances; and (clustered)\nbootstrap covariances. All methods are applicable to\n(generalized) linear model objects fitted by lm() and glm() but\ncan also be adapted to other classes through S3 methods.\nDetails can be found in Zeileis et al. (2020)\n<doi:10.18637/jss.v095.i01>, Zeileis (2004)\n<doi:10.18637/jss.v011.i10> and Zeileis (2006)\n<doi:10.18637/jss.v016.i09>.",
    "version": "3.1-2",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "author": "Achim Zeileis [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-0918-3766>),\nThomas Lumley [aut] (ORCID: <https://orcid.org/0000-0003-4255-5437>),\nNathaniel Graham [ctb] (ORCID: <https://orcid.org/0009-0002-1215-5256>),\nSusanne Koell [ctb]",
    "url": "https://sandwich.R-Forge.R-project.org/",
    "bug_reports": "https://sandwich.R-Forge.R-project.org/contact.html",
    "repository": "",
    "exports": [
      [
        ".vcovBSenv"
      ],
      [
        "bread"
      ],
      [
        "bwAndrews"
      ],
      [
        "bwNeweyWest"
      ],
      [
        "estfun"
      ],
      [
        "isoacf"
      ],
      [
        "kernHAC"
      ],
      [
        "kweights"
      ],
      [
        "lrvar"
      ],
      [
        "meat"
      ],
      [
        "meatCL"
      ],
      [
        "meatHAC"
      ],
      [
        "meatHC"
      ],
      [
        "meatPC"
      ],
      [
        "meatPL"
      ],
      [
        "NeweyWest"
      ],
      [
        "pava.blocks"
      ],
      [
        "sandwich"
      ],
      [
        "vcovBS"
      ],
      [
        "vcovBS.default"
      ],
      [
        "vcovBS.lm"
      ],
      [
        "vcovCL"
      ],
      [
        "vcovHAC"
      ],
      [
        "vcovHAC.default"
      ],
      [
        "vcovHC"
      ],
      [
        "vcovHC.default"
      ],
      [
        "vcovJK"
      ],
      [
        "vcovOPG"
      ],
      [
        "vcovPC"
      ],
      [
        "vcovPL"
      ],
      [
        "weave"
      ],
      [
        "weightsAndrews"
      ],
      [
        "weightsLumley"
      ]
    ],
    "topics": [],
    "score": 14.9911,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "sandwich Robust Covariance Matrix Estimators Object-oriented software for model-robust covariance\nmatrix estimators. Starting out from the basic robust\nEicker-Huber-White sandwich covariance methods include:\nheteroscedasticity-consistent (HC) covariances for\ncross-section data; heteroscedasticity- and\nautocorrelation-consistent (HAC) covariances for time series\ndata (such as Andrews' kernel HAC, Newey-West, and WEAVE\nestimators); clustered covariances (one-way and multi-way);\npanel and panel-corrected covariances;\nouter-product-of-gradients covariances; and (clustered)\nbootstrap covariances. All methods are applicable to\n(generalized) linear model objects fitted by lm() and glm() but\ncan also be adapted to other classes through S3 methods.\nDetails can be found in Zeileis et al. (2020)\n<doi:10.18637/jss.v095.i01>, Zeileis (2004)\n<doi:10.18637/jss.v011.i10> and Zeileis (2006)\n<doi:10.18637/jss.v016.i09>. .vcovBSenv bread bwAndrews bwNeweyWest estfun isoacf kernHAC kweights lrvar meat meatCL meatHAC meatHC meatPC meatPL NeweyWest pava.blocks sandwich vcovBS vcovBS.default vcovBS.lm vcovCL vcovHAC vcovHAC.default vcovHC vcovHC.default vcovJK vcovOPG vcovPC vcovPL weave weightsAndrews weightsLumley "
  },
  {
    "id": 1356,
    "package_name": "timetk",
    "title": "A Tool Kit for Working with Time Series",
    "description": "Easy visualization, wrangling, and feature engineering of\ntime series data for forecasting and machine learning\nprediction. Consolidates and extends time series functionality\nfrom packages including 'dplyr', 'stats', 'xts', 'forecast',\n'slider', 'padr', 'recipes', and 'rsample'.",
    "version": "2.9.1.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nDavis Vaughan [aut]",
    "url": "https://github.com/business-science/timetk,\nhttps://business-science.github.io/timetk/",
    "bug_reports": "https://github.com/business-science/timetk/issues",
    "repository": "",
    "exports": [
      [
        ":="
      ],
      [
        ".data"
      ],
      [
        "%-time%"
      ],
      [
        "%+time%"
      ],
      [
        "%||%"
      ],
      [
        "add_time"
      ],
      [
        "anomalize"
      ],
      [
        "as_label"
      ],
      [
        "as_name"
      ],
      [
        "auto_lambda"
      ],
      [
        "between_time"
      ],
      [
        "box_cox_inv_vec"
      ],
      [
        "box_cox_vec"
      ],
      [
        "condense_period"
      ],
      [
        "diff_inv_vec"
      ],
      [
        "diff_vec"
      ],
      [
        "enquo"
      ],
      [
        "enquos"
      ],
      [
        "expr"
      ],
      [
        "filter_by_time"
      ],
      [
        "filter_period"
      ],
      [
        "fourier_vec"
      ],
      [
        "future_frame"
      ],
      [
        "get_tk_time_scale_template"
      ],
      [
        "has_timetk_idx"
      ],
      [
        "is_date_class"
      ],
      [
        "lag_vec"
      ],
      [
        "lead_vec"
      ],
      [
        "log_interval_inv_vec"
      ],
      [
        "log_interval_vec"
      ],
      [
        "mutate_by_time"
      ],
      [
        "normalize_inv_vec"
      ],
      [
        "normalize_vec"
      ],
      [
        "pad_by_time"
      ],
      [
        "parse_date2"
      ],
      [
        "parse_datetime2"
      ],
      [
        "plot_acf_diagnostics"
      ],
      [
        "plot_anomalies"
      ],
      [
        "plot_anomalies_cleaned"
      ],
      [
        "plot_anomalies_decomp"
      ],
      [
        "plot_anomaly_diagnostics"
      ],
      [
        "plot_seasonal_diagnostics"
      ],
      [
        "plot_stl_diagnostics"
      ],
      [
        "plot_time_series"
      ],
      [
        "plot_time_series_boxplot"
      ],
      [
        "plot_time_series_cv_plan"
      ],
      [
        "plot_time_series_regression"
      ],
      [
        "set_tk_time_scale_template"
      ],
      [
        "slice_period"
      ],
      [
        "slidify"
      ],
      [
        "slidify_vec"
      ],
      [
        "smooth_vec"
      ],
      [
        "standardize_inv_vec"
      ],
      [
        "standardize_vec"
      ],
      [
        "step_box_cox"
      ],
      [
        "step_diff"
      ],
      [
        "step_fourier"
      ],
      [
        "step_holiday_signature"
      ],
      [
        "step_log_interval"
      ],
      [
        "step_slidify"
      ],
      [
        "step_slidify_augment"
      ],
      [
        "step_smooth"
      ],
      [
        "step_timeseries_signature"
      ],
      [
        "step_ts_clean"
      ],
      [
        "step_ts_impute"
      ],
      [
        "step_ts_pad"
      ],
      [
        "subtract_time"
      ],
      [
        "summarise_by_time"
      ],
      [
        "summarize_by_time"
      ],
      [
        "sym"
      ],
      [
        "syms"
      ],
      [
        "time_series_cv"
      ],
      [
        "time_series_split"
      ],
      [
        "tk_acf_diagnostics"
      ],
      [
        "tk_anomaly_diagnostics"
      ],
      [
        "tk_augment_differences"
      ],
      [
        "tk_augment_fourier"
      ],
      [
        "tk_augment_holiday_signature"
      ],
      [
        "tk_augment_lags"
      ],
      [
        "tk_augment_leads"
      ],
      [
        "tk_augment_slidify"
      ],
      [
        "tk_augment_timeseries_signature"
      ],
      [
        "tk_get_frequency"
      ],
      [
        "tk_get_holiday_signature"
      ],
      [
        "tk_get_holidays_by_year"
      ],
      [
        "tk_get_timeseries_signature"
      ],
      [
        "tk_get_timeseries_summary"
      ],
      [
        "tk_get_timeseries_unit_frequency"
      ],
      [
        "tk_get_timeseries_variables"
      ],
      [
        "tk_get_trend"
      ],
      [
        "tk_index"
      ],
      [
        "tk_make_future_timeseries"
      ],
      [
        "tk_make_holiday_sequence"
      ],
      [
        "tk_make_timeseries"
      ],
      [
        "tk_make_weekday_sequence"
      ],
      [
        "tk_make_weekend_sequence"
      ],
      [
        "tk_seasonal_diagnostics"
      ],
      [
        "tk_stl_diagnostics"
      ],
      [
        "tk_summary_diagnostics"
      ],
      [
        "tk_tbl"
      ],
      [
        "tk_time_scale_template"
      ],
      [
        "tk_time_series_cv_plan"
      ],
      [
        "tk_ts"
      ],
      [
        "tk_ts_"
      ],
      [
        "tk_ts_.data.frame"
      ],
      [
        "tk_ts_.default"
      ],
      [
        "tk_ts_dispatch_"
      ],
      [
        "tk_tsfeatures"
      ],
      [
        "tk_xts"
      ],
      [
        "tk_xts_"
      ],
      [
        "tk_zoo"
      ],
      [
        "tk_zoo_"
      ],
      [
        "tk_zooreg"
      ],
      [
        "tk_zooreg_"
      ],
      [
        "tk_zooreg_.data.frame"
      ],
      [
        "tk_zooreg_.default"
      ],
      [
        "tk_zooreg_dispatch_"
      ],
      [
        "ts_clean_vec"
      ],
      [
        "ts_impute_vec"
      ]
    ],
    "topics": [
      [
        "coercion"
      ],
      [
        "coercion-functions"
      ],
      [
        "data-mining"
      ],
      [
        "dplyr"
      ],
      [
        "forecast"
      ],
      [
        "forecasting"
      ],
      [
        "forecasting-models"
      ],
      [
        "machine-learning"
      ],
      [
        "series-decomposition"
      ],
      [
        "series-signature"
      ],
      [
        "tibble"
      ],
      [
        "tidy"
      ],
      [
        "tidyquant"
      ],
      [
        "tidyverse"
      ],
      [
        "time"
      ],
      [
        "time-series"
      ],
      [
        "timeseries"
      ]
    ],
    "score": 14.4312,
    "stars": 632,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "timetk A Tool Kit for Working with Time Series Easy visualization, wrangling, and feature engineering of\ntime series data for forecasting and machine learning\nprediction. Consolidates and extends time series functionality\nfrom packages including 'dplyr', 'stats', 'xts', 'forecast',\n'slider', 'padr', 'recipes', and 'rsample'. := .data %-time% %+time% %||% add_time anomalize as_label as_name auto_lambda between_time box_cox_inv_vec box_cox_vec condense_period diff_inv_vec diff_vec enquo enquos expr filter_by_time filter_period fourier_vec future_frame get_tk_time_scale_template has_timetk_idx is_date_class lag_vec lead_vec log_interval_inv_vec log_interval_vec mutate_by_time normalize_inv_vec normalize_vec pad_by_time parse_date2 parse_datetime2 plot_acf_diagnostics plot_anomalies plot_anomalies_cleaned plot_anomalies_decomp plot_anomaly_diagnostics plot_seasonal_diagnostics plot_stl_diagnostics plot_time_series plot_time_series_boxplot plot_time_series_cv_plan plot_time_series_regression set_tk_time_scale_template slice_period slidify slidify_vec smooth_vec standardize_inv_vec standardize_vec step_box_cox step_diff step_fourier step_holiday_signature step_log_interval step_slidify step_slidify_augment step_smooth step_timeseries_signature step_ts_clean step_ts_impute step_ts_pad subtract_time summarise_by_time summarize_by_time sym syms time_series_cv time_series_split tk_acf_diagnostics tk_anomaly_diagnostics tk_augment_differences tk_augment_fourier tk_augment_holiday_signature tk_augment_lags tk_augment_leads tk_augment_slidify tk_augment_timeseries_signature tk_get_frequency tk_get_holiday_signature tk_get_holidays_by_year tk_get_timeseries_signature tk_get_timeseries_summary tk_get_timeseries_unit_frequency tk_get_timeseries_variables tk_get_trend tk_index tk_make_future_timeseries tk_make_holiday_sequence tk_make_timeseries tk_make_weekday_sequence tk_make_weekend_sequence tk_seasonal_diagnostics tk_stl_diagnostics tk_summary_diagnostics tk_tbl tk_time_scale_template tk_time_series_cv_plan tk_ts tk_ts_ tk_ts_.data.frame tk_ts_.default tk_ts_dispatch_ tk_tsfeatures tk_xts tk_xts_ tk_zoo tk_zoo_ tk_zooreg tk_zooreg_ tk_zooreg_.data.frame tk_zooreg_.default tk_zooreg_dispatch_ ts_clean_vec ts_impute_vec coercion coercion-functions data-mining dplyr forecast forecasting forecasting-models machine-learning series-decomposition series-signature tibble tidy tidyquant tidyverse time time-series timeseries"
  },
  {
    "id": 1104,
    "package_name": "rgee",
    "title": "R Bindings for Calling the 'Earth Engine' API",
    "description": "Earth Engine <https://earthengine.google.com/> client\nlibrary for R. All of the 'Earth Engine' API classes, modules,\nand functions are made available. Additional functions\nimplemented include importing (exporting) of Earth Engine\nspatial objects, extraction of time series, interactive map\ndisplay, assets management interface, and metadata display. See\n<https://r-spatial.github.io/rgee/> for further details.",
    "version": "1.1.8.9000",
    "maintainer": "Matthieu Stigler <Matthieu.Stigler@gmail.com>",
    "author": "Cesar Aybar [aut] (ORCID: <https://orcid.org/0000-0003-2745-9535>),\nWu Qiusheng [ctb] (ORCID: <https://orcid.org/0000-0001-5437-4073>),\nLesly Bautista [ctb] (ORCID: <https://orcid.org/0000-0003-3523-8687>),\nRoy Yali [ctb] (ORCID: <https://orcid.org/0000-0003-4542-3755>),\nAntony Barja [ctb] (ORCID: <https://orcid.org/0000-0001-5921-2858>),\nKevin Ushey [ctb],\nJeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\nTim Appelhans [ctb],\nJJ Allaire [ctb],\nYuan Tang [ctb],\nSamapriya Roy [ctb],\nMariaElena Adauto [ctb] (ORCID:\n<https://orcid.org/0000-0002-2154-2429>),\nGabriel Carrasco [ctb] (ORCID: <https://orcid.org/0000-0002-6945-0419>),\nHenrik Bengtsson [ctb],\nJeffrey Hollister [rev] (Hollister reviewed the package for JOSS, see\nhttps://github.com/openjournals/joss-reviews/issues/2272/),\nGennadii Donchyts [rev] (Gena reviewed the package for JOSS, see\nhttps://github.com/openjournals/joss-reviews/issues/2272/),\nMatthieu Stigler [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-6802-4290>),\nMarius Appel [rev] (Appel reviewed the package for JOSS, see\nhttps://github.com/openjournals/joss-reviews/issues/2272/)",
    "url": "https://github.com/r-spatial/rgee/,\nhttps://r-spatial.github.io/rgee/,\nhttps://github.com/google/earthengine-api/",
    "bug_reports": "https://github.com/r-spatial/rgee/issues/",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "ee"
      ],
      [
        "ee_as_rast"
      ],
      [
        "ee_as_raster"
      ],
      [
        "ee_as_sf"
      ],
      [
        "ee_as_stars"
      ],
      [
        "ee_as_thumbnail"
      ],
      [
        "ee_Authenticate"
      ],
      [
        "ee_check"
      ],
      [
        "ee_check_credentials"
      ],
      [
        "ee_check_gcloud"
      ],
      [
        "ee_check_python"
      ],
      [
        "ee_check_python_packages"
      ],
      [
        "ee_check_task_status"
      ],
      [
        "ee_clean_container"
      ],
      [
        "ee_clean_pyenv"
      ],
      [
        "ee_clean_user_credentials"
      ],
      [
        "ee_drive_to_local"
      ],
      [
        "ee_extract"
      ],
      [
        "ee_gcs_to_local"
      ],
      [
        "ee_get_assethome"
      ],
      [
        "ee_get_date_ic"
      ],
      [
        "ee_get_date_img"
      ],
      [
        "ee_get_earthengine_path"
      ],
      [
        "ee_help"
      ],
      [
        "ee_image_info"
      ],
      [
        "ee_image_to_asset"
      ],
      [
        "ee_image_to_drive"
      ],
      [
        "ee_image_to_gcs"
      ],
      [
        "ee_imagecollection_to_local"
      ],
      [
        "ee_Initialize"
      ],
      [
        "ee_install"
      ],
      [
        "ee_install_set_pyenv"
      ],
      [
        "ee_install_upgrade"
      ],
      [
        "ee_manage_asset_access"
      ],
      [
        "ee_manage_asset_size"
      ],
      [
        "ee_manage_assetlist"
      ],
      [
        "ee_manage_cancel_all_running_task"
      ],
      [
        "ee_manage_copy"
      ],
      [
        "ee_manage_create"
      ],
      [
        "ee_manage_delete"
      ],
      [
        "ee_manage_delete_properties"
      ],
      [
        "ee_manage_move"
      ],
      [
        "ee_manage_quota"
      ],
      [
        "ee_manage_set_properties"
      ],
      [
        "ee_manage_task"
      ],
      [
        "ee_monitoring"
      ],
      [
        "ee_print"
      ],
      [
        "ee_table_to_asset"
      ],
      [
        "ee_table_to_drive"
      ],
      [
        "ee_table_to_gcs"
      ],
      [
        "ee_user_info"
      ],
      [
        "ee_users"
      ],
      [
        "ee_utils_cog_metadata"
      ],
      [
        "ee_utils_create_json"
      ],
      [
        "ee_utils_create_manifest_image"
      ],
      [
        "ee_utils_create_manifest_table"
      ],
      [
        "ee_utils_dataset_display"
      ],
      [
        "ee_utils_future_value"
      ],
      [
        "ee_utils_get_crs"
      ],
      [
        "ee_utils_py_to_r"
      ],
      [
        "ee_utils_pyfunc"
      ],
      [
        "ee_utils_sak_copy"
      ],
      [
        "ee_utils_sak_validate"
      ],
      [
        "ee_utils_shp_to_zip"
      ],
      [
        "ee_version"
      ],
      [
        "eedate_to_rdate"
      ],
      [
        "gcs_to_ee_image"
      ],
      [
        "gcs_to_ee_table"
      ],
      [
        "local_to_gcs"
      ],
      [
        "Map"
      ],
      [
        "R6Map"
      ],
      [
        "raster_as_ee"
      ],
      [
        "rdate_to_eedate"
      ],
      [
        "sf_as_ee"
      ],
      [
        "stars_as_ee"
      ]
    ],
    "topics": [
      [
        "earth-engine"
      ],
      [
        "earthengine"
      ],
      [
        "google-earth-engine"
      ],
      [
        "googleearthengine"
      ],
      [
        "spatial-analysis"
      ],
      [
        "spatial-data"
      ]
    ],
    "score": 14.2851,
    "stars": 750,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "rgee R Bindings for Calling the 'Earth Engine' API Earth Engine <https://earthengine.google.com/> client\nlibrary for R. All of the 'Earth Engine' API classes, modules,\nand functions are made available. Additional functions\nimplemented include importing (exporting) of Earth Engine\nspatial objects, extraction of time series, interactive map\ndisplay, assets management interface, and metadata display. See\n<https://r-spatial.github.io/rgee/> for further details. %>% ee ee_as_rast ee_as_raster ee_as_sf ee_as_stars ee_as_thumbnail ee_Authenticate ee_check ee_check_credentials ee_check_gcloud ee_check_python ee_check_python_packages ee_check_task_status ee_clean_container ee_clean_pyenv ee_clean_user_credentials ee_drive_to_local ee_extract ee_gcs_to_local ee_get_assethome ee_get_date_ic ee_get_date_img ee_get_earthengine_path ee_help ee_image_info ee_image_to_asset ee_image_to_drive ee_image_to_gcs ee_imagecollection_to_local ee_Initialize ee_install ee_install_set_pyenv ee_install_upgrade ee_manage_asset_access ee_manage_asset_size ee_manage_assetlist ee_manage_cancel_all_running_task ee_manage_copy ee_manage_create ee_manage_delete ee_manage_delete_properties ee_manage_move ee_manage_quota ee_manage_set_properties ee_manage_task ee_monitoring ee_print ee_table_to_asset ee_table_to_drive ee_table_to_gcs ee_user_info ee_users ee_utils_cog_metadata ee_utils_create_json ee_utils_create_manifest_image ee_utils_create_manifest_table ee_utils_dataset_display ee_utils_future_value ee_utils_get_crs ee_utils_py_to_r ee_utils_pyfunc ee_utils_sak_copy ee_utils_sak_validate ee_utils_shp_to_zip ee_version eedate_to_rdate gcs_to_ee_image gcs_to_ee_table local_to_gcs Map R6Map raster_as_ee rdate_to_eedate sf_as_ee stars_as_ee earth-engine earthengine google-earth-engine googleearthengine spatial-analysis spatial-data"
  },
  {
    "id": 504,
    "package_name": "dygraphs",
    "title": "Interface to 'Dygraphs' Interactive Time Series Charting Library",
    "description": "An R interface to the 'dygraphs' JavaScript charting\nlibrary (a copy of which is included in the package). Provides\nrich facilities for charting time-series data in R, including\nhighly configurable series- and axis-display and interactive\nfeatures like zoom/pan and series/point highlighting.",
    "version": "1.1.1.7",
    "maintainer": "Petr Shevtsov <petr.shevtsov@gmail.com>",
    "author": "Dan Vanderkam [aut, cph] (dygraphs library in htmlwidgets/lib,\nhttps://dygraphs.com/),\nPetr Shevtsov [cre, cph],\nJJ Allaire [aut],\nRStudio [cph],\nJonathan Owen [aut, cph],\nDaniel Gromer [aut, cph],\nBenoit Thieurmel [aut, cph],\nKent Laukhuf [ctb],\njQuery Foundation [cph] (jQuery library),\njQuery contributors [ctb, cph] (jQuery library; authors listed in\ninst/htmlwidgets/lib/jquery/AUTHORS.txt)",
    "url": "https://github.com/rstudio/dygraphs",
    "bug_reports": "https://github.com/rstudio/dygraphs/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "as.yearmon"
      ],
      [
        "as.yearqtr"
      ],
      [
        "dyAnnotation"
      ],
      [
        "dyAxis"
      ],
      [
        "dyBarChart"
      ],
      [
        "dyBarSeries"
      ],
      [
        "dyCallbacks"
      ],
      [
        "dyCandlestick"
      ],
      [
        "dyCandlestickGroup"
      ],
      [
        "dyCrosshair"
      ],
      [
        "dyCSS"
      ],
      [
        "dyDataHandler"
      ],
      [
        "dyDependency"
      ],
      [
        "dyErrorFill"
      ],
      [
        "dyEvent"
      ],
      [
        "dyFilledLine"
      ],
      [
        "dygraph"
      ],
      [
        "dygraphOutput"
      ],
      [
        "dyGroup"
      ],
      [
        "dyHighlight"
      ],
      [
        "dyLegend"
      ],
      [
        "dyLimit"
      ],
      [
        "dyMultiColumn"
      ],
      [
        "dyMultiColumnGroup"
      ],
      [
        "dyOptions"
      ],
      [
        "dyPlotter"
      ],
      [
        "dyPlugin"
      ],
      [
        "dyRangeSelector"
      ],
      [
        "dyRebase"
      ],
      [
        "dyRibbon"
      ],
      [
        "dyRoller"
      ],
      [
        "dySeries"
      ],
      [
        "dySeriesData"
      ],
      [
        "dyShading"
      ],
      [
        "dyShadow"
      ],
      [
        "dyStackedBarChart"
      ],
      [
        "dyStackedBarGroup"
      ],
      [
        "dyStackedLineGroup"
      ],
      [
        "dyStackedRibbonGroup"
      ],
      [
        "dyStemSeries"
      ],
      [
        "dyUnzoom"
      ],
      [
        "renderDygraph"
      ]
    ],
    "topics": [],
    "score": 14.1962,
    "stars": 367,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "dygraphs Interface to 'Dygraphs' Interactive Time Series Charting Library An R interface to the 'dygraphs' JavaScript charting\nlibrary (a copy of which is included in the package). Provides\nrich facilities for charting time-series data in R, including\nhighly configurable series- and axis-display and interactive\nfeatures like zoom/pan and series/point highlighting. %>% as.yearmon as.yearqtr dyAnnotation dyAxis dyBarChart dyBarSeries dyCallbacks dyCandlestick dyCandlestickGroup dyCrosshair dyCSS dyDataHandler dyDependency dyErrorFill dyEvent dyFilledLine dygraph dygraphOutput dyGroup dyHighlight dyLegend dyLimit dyMultiColumn dyMultiColumnGroup dyOptions dyPlotter dyPlugin dyRangeSelector dyRebase dyRibbon dyRoller dySeries dySeriesData dyShading dyShadow dyStackedBarChart dyStackedBarGroup dyStackedLineGroup dyStackedRibbonGroup dyStemSeries dyUnzoom renderDygraph "
  },
  {
    "id": 1348,
    "package_name": "tidyquant",
    "title": "Tidy Quantitative Financial Analysis",
    "description": "Bringing business and financial analysis to the\n'tidyverse'. The 'tidyquant' package provides a convenient\nwrapper to various 'xts', 'zoo', 'quantmod', 'TTR' and\n'PerformanceAnalytics' package functions and returns the\nobjects in the tidy 'tibble' format. The main advantage is\nbeing able to use quantitative functions with the 'tidyverse'\nfunctions including 'purrr', 'dplyr', 'tidyr', 'ggplot2',\n'lubridate', etc. See the 'tidyquant' website for more\ninformation, documentation and examples.",
    "version": "1.0.11.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nDavis Vaughan [aut]",
    "url": "https://business-science.github.io/tidyquant/,\nhttps://github.com/business-science/tidyquant",
    "bug_reports": "https://github.com/business-science/tidyquant/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "ABS"
      ],
      [
        "AS_DATE"
      ],
      [
        "AS_DATETIME"
      ],
      [
        "av_api_key"
      ],
      [
        "AVERAGE"
      ],
      [
        "AVERAGE_IFS"
      ],
      [
        "CEILING_DATE"
      ],
      [
        "CEILING_DAY"
      ],
      [
        "CEILING_MONTH"
      ],
      [
        "CEILING_QUARTER"
      ],
      [
        "CEILING_WEEK"
      ],
      [
        "CEILING_YEAR"
      ],
      [
        "CHANGE"
      ],
      [
        "CHANGE_FIRSTLAST"
      ],
      [
        "coord_x_date"
      ],
      [
        "coord_x_datetime"
      ],
      [
        "COR"
      ],
      [
        "COUNT"
      ],
      [
        "COUNT_DAYS"
      ],
      [
        "COUNT_IFS"
      ],
      [
        "COUNT_UNIQUE"
      ],
      [
        "COV"
      ],
      [
        "CREATE_IFS"
      ],
      [
        "CUMULATIVE_MAX"
      ],
      [
        "CUMULATIVE_MEAN"
      ],
      [
        "CUMULATIVE_MEDIAN"
      ],
      [
        "CUMULATIVE_MIN"
      ],
      [
        "CUMULATIVE_PRODUCT"
      ],
      [
        "CUMULATIVE_SUM"
      ],
      [
        "DATE"
      ],
      [
        "DATE_SEQUENCE"
      ],
      [
        "DATE_TO_DECIMAL"
      ],
      [
        "DATE_TO_NUMERIC"
      ],
      [
        "DATEVALUE"
      ],
      [
        "DAY"
      ],
      [
        "DMY"
      ],
      [
        "DMY_H"
      ],
      [
        "DMY_HM"
      ],
      [
        "DMY_HMS"
      ],
      [
        "DOM"
      ],
      [
        "DOW"
      ],
      [
        "EDATE"
      ],
      [
        "EOMONTH"
      ],
      [
        "EXP"
      ],
      [
        "FIRST"
      ],
      [
        "FLOOR_DATE"
      ],
      [
        "FLOOR_DAY"
      ],
      [
        "FLOOR_MONTH"
      ],
      [
        "FLOOR_QUARTER"
      ],
      [
        "FLOOR_WEEK"
      ],
      [
        "FLOOR_YEAR"
      ],
      [
        "FV"
      ],
      [
        "geom_barchart"
      ],
      [
        "geom_bbands"
      ],
      [
        "geom_bbands_"
      ],
      [
        "geom_candlestick"
      ],
      [
        "geom_ma"
      ],
      [
        "geom_ma_"
      ],
      [
        "HOLIDAY_SEQUENCE"
      ],
      [
        "HOLIDAY_TABLE"
      ],
      [
        "HOUR"
      ],
      [
        "IRR"
      ],
      [
        "LAG"
      ],
      [
        "LAST"
      ],
      [
        "LEAD"
      ],
      [
        "LOG"
      ],
      [
        "MAX"
      ],
      [
        "MAX_IFS"
      ],
      [
        "MDAY"
      ],
      [
        "MDY"
      ],
      [
        "MDY_H"
      ],
      [
        "MDY_HM"
      ],
      [
        "MDY_HMS"
      ],
      [
        "MEDIAN"
      ],
      [
        "MEDIAN_IFS"
      ],
      [
        "MIN"
      ],
      [
        "MIN_IFS"
      ],
      [
        "MINUTE"
      ],
      [
        "MONTH"
      ],
      [
        "MONTHDAY"
      ],
      [
        "NET_WORKDAYS"
      ],
      [
        "NOW"
      ],
      [
        "NPV"
      ],
      [
        "NTH"
      ],
      [
        "palette_dark"
      ],
      [
        "palette_green"
      ],
      [
        "palette_light"
      ],
      [
        "PCT_CHANGE"
      ],
      [
        "PCT_CHANGE_FIRSTLAST"
      ],
      [
        "pivot_table"
      ],
      [
        "PMT"
      ],
      [
        "PV"
      ],
      [
        "QDAY"
      ],
      [
        "quandl_api_key"
      ],
      [
        "quandl_search"
      ],
      [
        "QUARTER"
      ],
      [
        "QUARTERDAY"
      ],
      [
        "RATE"
      ],
      [
        "RETURN"
      ],
      [
        "ROUND_DATE"
      ],
      [
        "ROUND_DAY"
      ],
      [
        "ROUND_MONTH"
      ],
      [
        "ROUND_QUARTER"
      ],
      [
        "ROUND_WEEK"
      ],
      [
        "ROUND_YEAR"
      ],
      [
        "scale_color_tq"
      ],
      [
        "scale_colour_tq"
      ],
      [
        "scale_fill_tq"
      ],
      [
        "SECOND"
      ],
      [
        "SQRT"
      ],
      [
        "STDEV"
      ],
      [
        "SUM"
      ],
      [
        "SUM_IFS"
      ],
      [
        "theme_tq"
      ],
      [
        "theme_tq_dark"
      ],
      [
        "theme_tq_green"
      ],
      [
        "tidyquant_conflicts"
      ],
      [
        "tiingo_api_key"
      ],
      [
        "TODAY"
      ],
      [
        "tq_exchange"
      ],
      [
        "tq_exchange_options"
      ],
      [
        "tq_fund_holdings"
      ],
      [
        "tq_fund_source_options"
      ],
      [
        "tq_get"
      ],
      [
        "tq_get_options"
      ],
      [
        "tq_index"
      ],
      [
        "tq_index_options"
      ],
      [
        "tq_mutate"
      ],
      [
        "tq_mutate_"
      ],
      [
        "tq_mutate_fun_options"
      ],
      [
        "tq_mutate_xy"
      ],
      [
        "tq_mutate_xy_"
      ],
      [
        "tq_performance"
      ],
      [
        "tq_performance_"
      ],
      [
        "tq_performance_fun_options"
      ],
      [
        "tq_portfolio"
      ],
      [
        "tq_portfolio_"
      ],
      [
        "tq_repeat_df"
      ],
      [
        "tq_transform"
      ],
      [
        "tq_transform_xy"
      ],
      [
        "tq_transmute"
      ],
      [
        "tq_transmute_"
      ],
      [
        "tq_transmute_fun_options"
      ],
      [
        "tq_transmute_xy"
      ],
      [
        "tq_transmute_xy_"
      ],
      [
        "VAR"
      ],
      [
        "VLOOKUP"
      ],
      [
        "WDAY"
      ],
      [
        "WEEK"
      ],
      [
        "WEEKDAY"
      ],
      [
        "WEEKNUM"
      ],
      [
        "WEEKNUM_ISO"
      ],
      [
        "WORKDAY_SEQUENCE"
      ],
      [
        "YEAR"
      ],
      [
        "YEAR_ISO"
      ],
      [
        "YEARFRAC"
      ],
      [
        "YMD"
      ],
      [
        "YMD_H"
      ],
      [
        "YMD_HM"
      ],
      [
        "YMD_HMS"
      ]
    ],
    "topics": [
      [
        "dplyr"
      ],
      [
        "financial-analysis"
      ],
      [
        "financial-data"
      ],
      [
        "financial-statements"
      ],
      [
        "multiple-stocks"
      ],
      [
        "performance-analysis"
      ],
      [
        "performanceanalytics"
      ],
      [
        "quantmod"
      ],
      [
        "stock"
      ],
      [
        "stock-exchanges"
      ],
      [
        "stock-indexes"
      ],
      [
        "stock-lists"
      ],
      [
        "stock-performance"
      ],
      [
        "stock-prices"
      ],
      [
        "stock-symbol"
      ],
      [
        "tidyverse"
      ],
      [
        "time-series"
      ],
      [
        "timeseries"
      ],
      [
        "xts"
      ]
    ],
    "score": 13.2668,
    "stars": 897,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "tidyquant Tidy Quantitative Financial Analysis Bringing business and financial analysis to the\n'tidyverse'. The 'tidyquant' package provides a convenient\nwrapper to various 'xts', 'zoo', 'quantmod', 'TTR' and\n'PerformanceAnalytics' package functions and returns the\nobjects in the tidy 'tibble' format. The main advantage is\nbeing able to use quantitative functions with the 'tidyverse'\nfunctions including 'purrr', 'dplyr', 'tidyr', 'ggplot2',\n'lubridate', etc. See the 'tidyquant' website for more\ninformation, documentation and examples. %>% ABS AS_DATE AS_DATETIME av_api_key AVERAGE AVERAGE_IFS CEILING_DATE CEILING_DAY CEILING_MONTH CEILING_QUARTER CEILING_WEEK CEILING_YEAR CHANGE CHANGE_FIRSTLAST coord_x_date coord_x_datetime COR COUNT COUNT_DAYS COUNT_IFS COUNT_UNIQUE COV CREATE_IFS CUMULATIVE_MAX CUMULATIVE_MEAN CUMULATIVE_MEDIAN CUMULATIVE_MIN CUMULATIVE_PRODUCT CUMULATIVE_SUM DATE DATE_SEQUENCE DATE_TO_DECIMAL DATE_TO_NUMERIC DATEVALUE DAY DMY DMY_H DMY_HM DMY_HMS DOM DOW EDATE EOMONTH EXP FIRST FLOOR_DATE FLOOR_DAY FLOOR_MONTH FLOOR_QUARTER FLOOR_WEEK FLOOR_YEAR FV geom_barchart geom_bbands geom_bbands_ geom_candlestick geom_ma geom_ma_ HOLIDAY_SEQUENCE HOLIDAY_TABLE HOUR IRR LAG LAST LEAD LOG MAX MAX_IFS MDAY MDY MDY_H MDY_HM MDY_HMS MEDIAN MEDIAN_IFS MIN MIN_IFS MINUTE MONTH MONTHDAY NET_WORKDAYS NOW NPV NTH palette_dark palette_green palette_light PCT_CHANGE PCT_CHANGE_FIRSTLAST pivot_table PMT PV QDAY quandl_api_key quandl_search QUARTER QUARTERDAY RATE RETURN ROUND_DATE ROUND_DAY ROUND_MONTH ROUND_QUARTER ROUND_WEEK ROUND_YEAR scale_color_tq scale_colour_tq scale_fill_tq SECOND SQRT STDEV SUM SUM_IFS theme_tq theme_tq_dark theme_tq_green tidyquant_conflicts tiingo_api_key TODAY tq_exchange tq_exchange_options tq_fund_holdings tq_fund_source_options tq_get tq_get_options tq_index tq_index_options tq_mutate tq_mutate_ tq_mutate_fun_options tq_mutate_xy tq_mutate_xy_ tq_performance tq_performance_ tq_performance_fun_options tq_portfolio tq_portfolio_ tq_repeat_df tq_transform tq_transform_xy tq_transmute tq_transmute_ tq_transmute_fun_options tq_transmute_xy tq_transmute_xy_ VAR VLOOKUP WDAY WEEK WEEKDAY WEEKNUM WEEKNUM_ISO WORKDAY_SEQUENCE YEAR YEAR_ISO YEARFRAC YMD YMD_H YMD_HM YMD_HMS dplyr financial-analysis financial-data financial-statements multiple-stocks performance-analysis performanceanalytics quantmod stock stock-exchanges stock-indexes stock-lists stock-performance stock-prices stock-symbol tidyverse time-series timeseries xts"
  },
  {
    "id": 24,
    "package_name": "CoordinateCleaner",
    "title": "Automated Cleaning of Occurrence Records from Biological\nCollections",
    "description": "Automated flagging of common spatial and temporal errors\nin biological and paleontological collection data, for the use\nin conservation, ecology and paleontology. Includes automated\ntests to easily flag (and exclude) records assigned to country\nor province centroid, the open ocean, the headquarters of the\nGlobal Biodiversity Information Facility, urban areas or the\nlocation of biodiversity institutions (museums, zoos, botanical\ngardens, universities). Furthermore identifies per species\noutlier coordinates, zero coordinates, identical\nlatitude/longitude and invalid coordinates. Also implements an\nalgorithm to identify data sets with a significant proportion\nof rounded coordinates. Especially suited for large data sets.\nThe reference for the methodology is: Zizka et al. (2019)\n<doi:10.1111/2041-210X.13152>.",
    "version": "3.0.1",
    "maintainer": "Alexander Zizka <zizka.alexander@gmail.com>",
    "author": "Alexander Zizka [aut, cre],\nDaniele Silvestro [ctb],\nTobias Andermann [ctb],\nJosue Azevedo [ctb],\nCamila Duarte Ritter [ctb],\nDaniel Edler [ctb],\nHarith Farooq [ctb],\nAndrei Herdean [ctb],\nMaria Ariza [ctb],\nRuud Scharn [ctb],\nSten Svanteson [ctb],\nNiklas Wengstrom [ctb],\nVera Zizka [ctb],\nAlexandre Antonelli [ctb],\nBruno Vilela [ctb] (Bruno updated the package to remove dependencies on\nsp, raster, rgdal, maptools, and rgeos packages),\nIrene Steves [rev] (Irene reviewed the package for ropensci, see\n<https://github.com/ropensci/onboarding/issues/210>),\nFrancisco Rodriguez-Sanchez [rev] (Francisco reviewed the package for\nropensci, see <https://github.com/ropensci/onboarding/issues/210>)",
    "url": "https://ropensci.github.io/CoordinateCleaner/",
    "bug_reports": "https://github.com/ropensci/CoordinateCleaner/issues",
    "repository": "",
    "exports": [
      [
        "cc_aohi"
      ],
      [
        "cc_cap"
      ],
      [
        "cc_cen"
      ],
      [
        "cc_coun"
      ],
      [
        "cc_dupl"
      ],
      [
        "cc_equ"
      ],
      [
        "cc_gbif"
      ],
      [
        "cc_inst"
      ],
      [
        "cc_iucn"
      ],
      [
        "cc_outl"
      ],
      [
        "cc_sea"
      ],
      [
        "cc_urb"
      ],
      [
        "cc_val"
      ],
      [
        "cc_zero"
      ],
      [
        "cd_ddmm"
      ],
      [
        "cd_round"
      ],
      [
        "cf_age"
      ],
      [
        "cf_equal"
      ],
      [
        "cf_outl"
      ],
      [
        "cf_range"
      ],
      [
        "clean_coordinates"
      ],
      [
        "clean_dataset"
      ],
      [
        "clean_fossils"
      ],
      [
        "is.spatialvalid"
      ],
      [
        "write_pyrate"
      ]
    ],
    "topics": [],
    "score": 11.9125,
    "stars": 84,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "CoordinateCleaner Automated Cleaning of Occurrence Records from Biological\nCollections Automated flagging of common spatial and temporal errors\nin biological and paleontological collection data, for the use\nin conservation, ecology and paleontology. Includes automated\ntests to easily flag (and exclude) records assigned to country\nor province centroid, the open ocean, the headquarters of the\nGlobal Biodiversity Information Facility, urban areas or the\nlocation of biodiversity institutions (museums, zoos, botanical\ngardens, universities). Furthermore identifies per species\noutlier coordinates, zero coordinates, identical\nlatitude/longitude and invalid coordinates. Also implements an\nalgorithm to identify data sets with a significant proportion\nof rounded coordinates. Especially suited for large data sets.\nThe reference for the methodology is: Zizka et al. (2019)\n<doi:10.1111/2041-210X.13152>. cc_aohi cc_cap cc_cen cc_coun cc_dupl cc_equ cc_gbif cc_inst cc_iucn cc_outl cc_sea cc_urb cc_val cc_zero cd_ddmm cd_round cf_age cf_equal cf_outl cf_range clean_coordinates clean_dataset clean_fossils is.spatialvalid write_pyrate "
  },
  {
    "id": 1184,
    "package_name": "scoringutils",
    "title": "Utilities for Scoring and Assessing Predictions",
    "description": "Facilitate the evaluation of forecasts in a convenient\nframework based on data.table. It allows user to to check their\nforecasts and diagnose issues, to visualise forecasts and\nmissing data, to transform data before scoring, to handle\nmissing forecasts, to aggregate scores, and to visualise the\nresults of the evaluation. The package mostly focuses on the\nevaluation of probabilistic forecasts and allows evaluating\nseveral different forecast types and input formats. Find more\ninformation about the package in the Vignettes as well as in\nthe accompanying paper, <doi:10.48550/arXiv.2205.07090>.",
    "version": "2.1.2",
    "maintainer": "Nikos Bosse <nikosbosse@gmail.com>",
    "author": "Nikos Bosse [aut, cre] (ORCID: <https://orcid.org/0000-0002-7750-5280>),\nSam Abbott [aut] (ORCID: <https://orcid.org/0000-0001-8057-8037>),\nHugo Gruson [aut] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nJohannes Bracher [ctb] (ORCID: <https://orcid.org/0000-0002-3777-1410>),\nToshiaki Asakura [ctb] (ORCID: <https://orcid.org/0000-0001-8838-785X>),\nJames Mba Azam [ctb] (ORCID: <https://orcid.org/0000-0001-5782-7330>),\nSebastian Funk [aut],\nMichael Chirico [ctb] (ORCID: <https://orcid.org/0000-0003-0787-087X>)",
    "url": "https://doi.org/10.48550/arXiv.2205.07090,\nhttps://epiforecasts.io/scoringutils/,\nhttps://github.com/epiforecasts/scoringutils",
    "bug_reports": "https://github.com/epiforecasts/scoringutils/issues",
    "repository": "",
    "exports": [
      [
        "add_relative_skill"
      ],
      [
        "ae_median_quantile"
      ],
      [
        "ae_median_sample"
      ],
      [
        "as_forecast_binary"
      ],
      [
        "as_forecast_nominal"
      ],
      [
        "as_forecast_ordinal"
      ],
      [
        "as_forecast_point"
      ],
      [
        "as_forecast_quantile"
      ],
      [
        "as_forecast_sample"
      ],
      [
        "assert_forecast"
      ],
      [
        "bias_quantile"
      ],
      [
        "bias_sample"
      ],
      [
        "brier_score"
      ],
      [
        "crps_sample"
      ],
      [
        "dispersion_quantile"
      ],
      [
        "dispersion_sample"
      ],
      [
        "dss_sample"
      ],
      [
        "get_correlations"
      ],
      [
        "get_coverage"
      ],
      [
        "get_duplicate_forecasts"
      ],
      [
        "get_forecast_counts"
      ],
      [
        "get_forecast_unit"
      ],
      [
        "get_metrics"
      ],
      [
        "get_pairwise_comparisons"
      ],
      [
        "get_pit_histogram"
      ],
      [
        "interval_coverage"
      ],
      [
        "is_forecast"
      ],
      [
        "is_forecast_binary"
      ],
      [
        "is_forecast_nominal"
      ],
      [
        "is_forecast_ordinal"
      ],
      [
        "is_forecast_point"
      ],
      [
        "is_forecast_quantile"
      ],
      [
        "is_forecast_sample"
      ],
      [
        "log_shift"
      ],
      [
        "logs_binary"
      ],
      [
        "logs_categorical"
      ],
      [
        "logs_sample"
      ],
      [
        "mad_sample"
      ],
      [
        "new_forecast"
      ],
      [
        "overprediction_quantile"
      ],
      [
        "overprediction_sample"
      ],
      [
        "pit_histogram_sample"
      ],
      [
        "plot_correlations"
      ],
      [
        "plot_forecast_counts"
      ],
      [
        "plot_heatmap"
      ],
      [
        "plot_interval_coverage"
      ],
      [
        "plot_pairwise_comparisons"
      ],
      [
        "plot_quantile_coverage"
      ],
      [
        "plot_wis"
      ],
      [
        "quantile_score"
      ],
      [
        "rps_ordinal"
      ],
      [
        "score"
      ],
      [
        "se_mean_sample"
      ],
      [
        "select_metrics"
      ],
      [
        "summarise_scores"
      ],
      [
        "summarize_scores"
      ],
      [
        "theme_scoringutils"
      ],
      [
        "transform_forecasts"
      ],
      [
        "underprediction_quantile"
      ],
      [
        "underprediction_sample"
      ],
      [
        "wis"
      ]
    ],
    "topics": [
      [
        "forecast-evaluation"
      ],
      [
        "forecasting"
      ]
    ],
    "score": 11.3713,
    "stars": 60,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "scoringutils Utilities for Scoring and Assessing Predictions Facilitate the evaluation of forecasts in a convenient\nframework based on data.table. It allows user to to check their\nforecasts and diagnose issues, to visualise forecasts and\nmissing data, to transform data before scoring, to handle\nmissing forecasts, to aggregate scores, and to visualise the\nresults of the evaluation. The package mostly focuses on the\nevaluation of probabilistic forecasts and allows evaluating\nseveral different forecast types and input formats. Find more\ninformation about the package in the Vignettes as well as in\nthe accompanying paper, <doi:10.48550/arXiv.2205.07090>. add_relative_skill ae_median_quantile ae_median_sample as_forecast_binary as_forecast_nominal as_forecast_ordinal as_forecast_point as_forecast_quantile as_forecast_sample assert_forecast bias_quantile bias_sample brier_score crps_sample dispersion_quantile dispersion_sample dss_sample get_correlations get_coverage get_duplicate_forecasts get_forecast_counts get_forecast_unit get_metrics get_pairwise_comparisons get_pit_histogram interval_coverage is_forecast is_forecast_binary is_forecast_nominal is_forecast_ordinal is_forecast_point is_forecast_quantile is_forecast_sample log_shift logs_binary logs_categorical logs_sample mad_sample new_forecast overprediction_quantile overprediction_sample pit_histogram_sample plot_correlations plot_forecast_counts plot_heatmap plot_interval_coverage plot_pairwise_comparisons plot_quantile_coverage plot_wis quantile_score rps_ordinal score se_mean_sample select_metrics summarise_scores summarize_scores theme_scoringutils transform_forecasts underprediction_quantile underprediction_sample wis forecast-evaluation forecasting"
  },
  {
    "id": 835,
    "package_name": "modeltime",
    "title": "The Tidymodels Extension for Time Series Modeling",
    "description": "The time series forecasting framework for use with the\n'tidymodels' ecosystem. Models include ARIMA, Exponential\nSmoothing, and additional time series models from the\n'forecast' and 'prophet' packages. Refer to \"Forecasting\nPrinciples & Practice, Second edition\"\n(<https://otexts.com/fpp2/>). Refer to \"Prophet: forecasting at\nscale\"\n(<https://research.facebook.com/blog/2017/02/prophet-forecasting-at-scale/>.).",
    "version": "1.3.3.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nBusiness Science [cph]",
    "url": "https://github.com/business-science/modeltime,\nhttps://business-science.github.io/modeltime/",
    "bug_reports": "https://github.com/business-science/modeltime/issues",
    "repository": "",
    "exports": [
      [
        ":="
      ],
      [
        ".data"
      ],
      [
        ".prepare_panel_transform"
      ],
      [
        ".prepare_transform"
      ],
      [
        "%>%"
      ],
      [
        "adam_fit_impl"
      ],
      [
        "Adam_predict_impl"
      ],
      [
        "adam_reg"
      ],
      [
        "add_modeltime_model"
      ],
      [
        "arima_boost"
      ],
      [
        "Arima_fit_impl"
      ],
      [
        "Arima_predict_impl"
      ],
      [
        "arima_reg"
      ],
      [
        "arima_xgboost_fit_impl"
      ],
      [
        "arima_xgboost_predict_impl"
      ],
      [
        "as_label"
      ],
      [
        "as_modeltime_table"
      ],
      [
        "as_name"
      ],
      [
        "auto_adam_fit_impl"
      ],
      [
        "Auto_adam_predict_impl"
      ],
      [
        "auto_arima_fit_impl"
      ],
      [
        "auto_arima_xgboost_fit_impl"
      ],
      [
        "bake_xreg_recipe"
      ],
      [
        "changepoint_num"
      ],
      [
        "changepoint_range"
      ],
      [
        "combination_method"
      ],
      [
        "combine_modeltime_tables"
      ],
      [
        "control_fit_workflowset"
      ],
      [
        "control_nested_fit"
      ],
      [
        "control_nested_forecast"
      ],
      [
        "control_nested_refit"
      ],
      [
        "control_refit"
      ],
      [
        "create_model_grid"
      ],
      [
        "create_xreg_recipe"
      ],
      [
        "croston_fit_impl"
      ],
      [
        "croston_predict_impl"
      ],
      [
        "damping"
      ],
      [
        "damping_smooth"
      ],
      [
        "default_forecast_accuracy_metric_set"
      ],
      [
        "distribution"
      ],
      [
        "drop_modeltime_model"
      ],
      [
        "enquo"
      ],
      [
        "enquos"
      ],
      [
        "error"
      ],
      [
        "ets_fit_impl"
      ],
      [
        "ets_model"
      ],
      [
        "ets_predict_impl"
      ],
      [
        "exp_smoothing"
      ],
      [
        "expr"
      ],
      [
        "extend_timeseries"
      ],
      [
        "extended_forecast_accuracy_metric_set"
      ],
      [
        "extract_nested_best_model_report"
      ],
      [
        "extract_nested_error_report"
      ],
      [
        "extract_nested_future_forecast"
      ],
      [
        "extract_nested_modeltime_table"
      ],
      [
        "extract_nested_test_accuracy"
      ],
      [
        "extract_nested_test_forecast"
      ],
      [
        "extract_nested_test_split"
      ],
      [
        "extract_nested_train_split"
      ],
      [
        "get_arima_description"
      ],
      [
        "get_model_description"
      ],
      [
        "get_tbats_description"
      ],
      [
        "growth"
      ],
      [
        "information_criteria"
      ],
      [
        "is_calibrated"
      ],
      [
        "is_modeltime_model"
      ],
      [
        "is_modeltime_table"
      ],
      [
        "is_residuals"
      ],
      [
        "juice_xreg_recipe"
      ],
      [
        "load_namespace"
      ],
      [
        "loss"
      ],
      [
        "maape"
      ],
      [
        "maape_vec"
      ],
      [
        "make_ts_splits"
      ],
      [
        "mdl_time_forecast"
      ],
      [
        "mdl_time_refit"
      ],
      [
        "modeltime_accuracy"
      ],
      [
        "modeltime_calibrate"
      ],
      [
        "modeltime_fit_workflowset"
      ],
      [
        "modeltime_forecast"
      ],
      [
        "modeltime_nested_fit"
      ],
      [
        "modeltime_nested_forecast"
      ],
      [
        "modeltime_nested_refit"
      ],
      [
        "modeltime_nested_select_best"
      ],
      [
        "modeltime_refit"
      ],
      [
        "modeltime_residuals"
      ],
      [
        "modeltime_residuals_test"
      ],
      [
        "modeltime_table"
      ],
      [
        "naive_fit_impl"
      ],
      [
        "naive_predict_impl"
      ],
      [
        "naive_reg"
      ],
      [
        "nest_timeseries"
      ],
      [
        "new_modeltime_bridge"
      ],
      [
        "nnetar_fit_impl"
      ],
      [
        "nnetar_predict_impl"
      ],
      [
        "nnetar_reg"
      ],
      [
        "non_seasonal_ar"
      ],
      [
        "non_seasonal_differences"
      ],
      [
        "non_seasonal_ma"
      ],
      [
        "num_networks"
      ],
      [
        "outliers_treatment"
      ],
      [
        "panel_tail"
      ],
      [
        "parallel_start"
      ],
      [
        "parallel_stop"
      ],
      [
        "parse_index_from_data"
      ],
      [
        "parse_period_from_index"
      ],
      [
        "plot_modeltime_forecast"
      ],
      [
        "plot_modeltime_residuals"
      ],
      [
        "pluck_modeltime_model"
      ],
      [
        "prior_scale_changepoints"
      ],
      [
        "prior_scale_holidays"
      ],
      [
        "prior_scale_seasonality"
      ],
      [
        "probability_model"
      ],
      [
        "prophet_boost"
      ],
      [
        "prophet_fit_impl"
      ],
      [
        "prophet_predict_impl"
      ],
      [
        "prophet_reg"
      ],
      [
        "prophet_xgboost_fit_impl"
      ],
      [
        "prophet_xgboost_predict_impl"
      ],
      [
        "pull_modeltime_model"
      ],
      [
        "pull_modeltime_residuals"
      ],
      [
        "pull_parsnip_preprocessor"
      ],
      [
        "recursive"
      ],
      [
        "regressors_treatment"
      ],
      [
        "season"
      ],
      [
        "seasonal_ar"
      ],
      [
        "seasonal_differences"
      ],
      [
        "seasonal_ma"
      ],
      [
        "seasonal_period"
      ],
      [
        "seasonal_reg"
      ],
      [
        "seasonality_daily"
      ],
      [
        "seasonality_weekly"
      ],
      [
        "seasonality_yearly"
      ],
      [
        "select_order"
      ],
      [
        "smooth_fit_impl"
      ],
      [
        "smooth_level"
      ],
      [
        "smooth_predict_impl"
      ],
      [
        "smooth_seasonal"
      ],
      [
        "smooth_trend"
      ],
      [
        "snaive_fit_impl"
      ],
      [
        "snaive_predict_impl"
      ],
      [
        "split_nested_timeseries"
      ],
      [
        "stlm_arima_fit_impl"
      ],
      [
        "stlm_arima_predict_impl"
      ],
      [
        "stlm_ets_fit_impl"
      ],
      [
        "stlm_ets_predict_impl"
      ],
      [
        "summarize_accuracy_metrics"
      ],
      [
        "sym"
      ],
      [
        "syms"
      ],
      [
        "table_modeltime_accuracy"
      ],
      [
        "tbats_fit_impl"
      ],
      [
        "tbats_predict_impl"
      ],
      [
        "temporal_hier_fit_impl"
      ],
      [
        "temporal_hier_predict_impl"
      ],
      [
        "temporal_hierarchy"
      ],
      [
        "theta_fit_impl"
      ],
      [
        "theta_predict_impl"
      ],
      [
        "trend"
      ],
      [
        "trend_smooth"
      ],
      [
        "update_model_description"
      ],
      [
        "update_modeltime_description"
      ],
      [
        "update_modeltime_model"
      ],
      [
        "use_constant"
      ],
      [
        "use_model"
      ],
      [
        "window_function_fit_impl"
      ],
      [
        "window_function_predict_impl"
      ],
      [
        "window_reg"
      ],
      [
        "xgboost_impl"
      ],
      [
        "xgboost_predict"
      ]
    ],
    "topics": [
      [
        "arima"
      ],
      [
        "data-science"
      ],
      [
        "deep-learning"
      ],
      [
        "ets"
      ],
      [
        "forecasting"
      ],
      [
        "machine-learning"
      ],
      [
        "machine-learning-algorithms"
      ],
      [
        "modeltime"
      ],
      [
        "prophet"
      ],
      [
        "tbats"
      ],
      [
        "tidymodeling"
      ],
      [
        "tidymodels"
      ],
      [
        "time"
      ],
      [
        "time-series"
      ],
      [
        "time-series-analysis"
      ],
      [
        "timeseries"
      ],
      [
        "timeseries-forecasting"
      ]
    ],
    "score": 11.3124,
    "stars": 566,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "modeltime The Tidymodels Extension for Time Series Modeling The time series forecasting framework for use with the\n'tidymodels' ecosystem. Models include ARIMA, Exponential\nSmoothing, and additional time series models from the\n'forecast' and 'prophet' packages. Refer to \"Forecasting\nPrinciples & Practice, Second edition\"\n(<https://otexts.com/fpp2/>). Refer to \"Prophet: forecasting at\nscale\"\n(<https://research.facebook.com/blog/2017/02/prophet-forecasting-at-scale/>.). := .data .prepare_panel_transform .prepare_transform %>% adam_fit_impl Adam_predict_impl adam_reg add_modeltime_model arima_boost Arima_fit_impl Arima_predict_impl arima_reg arima_xgboost_fit_impl arima_xgboost_predict_impl as_label as_modeltime_table as_name auto_adam_fit_impl Auto_adam_predict_impl auto_arima_fit_impl auto_arima_xgboost_fit_impl bake_xreg_recipe changepoint_num changepoint_range combination_method combine_modeltime_tables control_fit_workflowset control_nested_fit control_nested_forecast control_nested_refit control_refit create_model_grid create_xreg_recipe croston_fit_impl croston_predict_impl damping damping_smooth default_forecast_accuracy_metric_set distribution drop_modeltime_model enquo enquos error ets_fit_impl ets_model ets_predict_impl exp_smoothing expr extend_timeseries extended_forecast_accuracy_metric_set extract_nested_best_model_report extract_nested_error_report extract_nested_future_forecast extract_nested_modeltime_table extract_nested_test_accuracy extract_nested_test_forecast extract_nested_test_split extract_nested_train_split get_arima_description get_model_description get_tbats_description growth information_criteria is_calibrated is_modeltime_model is_modeltime_table is_residuals juice_xreg_recipe load_namespace loss maape maape_vec make_ts_splits mdl_time_forecast mdl_time_refit modeltime_accuracy modeltime_calibrate modeltime_fit_workflowset modeltime_forecast modeltime_nested_fit modeltime_nested_forecast modeltime_nested_refit modeltime_nested_select_best modeltime_refit modeltime_residuals modeltime_residuals_test modeltime_table naive_fit_impl naive_predict_impl naive_reg nest_timeseries new_modeltime_bridge nnetar_fit_impl nnetar_predict_impl nnetar_reg non_seasonal_ar non_seasonal_differences non_seasonal_ma num_networks outliers_treatment panel_tail parallel_start parallel_stop parse_index_from_data parse_period_from_index plot_modeltime_forecast plot_modeltime_residuals pluck_modeltime_model prior_scale_changepoints prior_scale_holidays prior_scale_seasonality probability_model prophet_boost prophet_fit_impl prophet_predict_impl prophet_reg prophet_xgboost_fit_impl prophet_xgboost_predict_impl pull_modeltime_model pull_modeltime_residuals pull_parsnip_preprocessor recursive regressors_treatment season seasonal_ar seasonal_differences seasonal_ma seasonal_period seasonal_reg seasonality_daily seasonality_weekly seasonality_yearly select_order smooth_fit_impl smooth_level smooth_predict_impl smooth_seasonal smooth_trend snaive_fit_impl snaive_predict_impl split_nested_timeseries stlm_arima_fit_impl stlm_arima_predict_impl stlm_ets_fit_impl stlm_ets_predict_impl summarize_accuracy_metrics sym syms table_modeltime_accuracy tbats_fit_impl tbats_predict_impl temporal_hier_fit_impl temporal_hier_predict_impl temporal_hierarchy theta_fit_impl theta_predict_impl trend trend_smooth update_model_description update_modeltime_description update_modeltime_model use_constant use_model window_function_fit_impl window_function_predict_impl window_reg xgboost_impl xgboost_predict arima data-science deep-learning ets forecasting machine-learning machine-learning-algorithms modeltime prophet tbats tidymodeling tidymodels time time-series time-series-analysis timeseries timeseries-forecasting"
  },
  {
    "id": 865,
    "package_name": "nanoparquet",
    "title": "Read and Write 'Parquet' Files",
    "description": "Self-sufficient reader and writer for flat 'Parquet'\nfiles. Can read most 'Parquet' data types. Can write many 'R'\ndata types, including factors and temporal types. See docs for\nlimitations.",
    "version": "0.4.3.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nHannes M\u00fchleisen [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-8552-0029>),\nGoogle Inc. [cph],\nApache Software Foundation [cph],\nPosit Software, PBC [cph],\nRAD Game Tools [cph],\nValve Software [cph],\nTenacious Software LLC [cph],\nFacebook, Inc. [cph]",
    "url": "https://github.com/r-lib/nanoparquet,\nhttps://nanoparquet.r-lib.org/",
    "bug_reports": "https://github.com/r-lib/nanoparquet/issues",
    "repository": "",
    "exports": [
      [
        "append_parquet"
      ],
      [
        "infer_parquet_schema"
      ],
      [
        "parquet_column_types"
      ],
      [
        "parquet_info"
      ],
      [
        "parquet_metadata"
      ],
      [
        "parquet_options"
      ],
      [
        "parquet_schema"
      ],
      [
        "read_parquet"
      ],
      [
        "read_parquet_info"
      ],
      [
        "read_parquet_metadata"
      ],
      [
        "read_parquet_schema"
      ],
      [
        "write_parquet"
      ]
    ],
    "topics": [
      [
        "parquet"
      ],
      [
        "cpp"
      ]
    ],
    "score": 10.909,
    "stars": 79,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "nanoparquet Read and Write 'Parquet' Files Self-sufficient reader and writer for flat 'Parquet'\nfiles. Can read most 'Parquet' data types. Can write many 'R'\ndata types, including factors and temporal types. See docs for\nlimitations. append_parquet infer_parquet_schema parquet_column_types parquet_info parquet_metadata parquet_options parquet_schema read_parquet read_parquet_info read_parquet_metadata read_parquet_schema write_parquet parquet cpp"
  },
  {
    "id": 1337,
    "package_name": "tibbletime",
    "title": "Time Aware Tibbles",
    "description": "Built on top of the 'tibble' package, 'tibbletime' is an\nextension that allows for the creation of time aware tibbles.\nSome immediate advantages of this include: the ability to\nperform time-based subsetting on tibbles, quickly summarising\nand aggregating results by time periods, and creating columns\nthat can be used as 'dplyr' time-based groups.",
    "version": "0.1.9.9000",
    "maintainer": "Davis Vaughan <davis@posit.co>",
    "author": "Davis Vaughan [aut, cre],\nMatt Dancho [aut]",
    "url": "https://github.com/business-science/tibbletime",
    "bug_reports": "https://github.com/business-science/tibbletime/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "as_period"
      ],
      [
        "as_tbl_time"
      ],
      [
        "ceiling_index"
      ],
      [
        "collapse_by"
      ],
      [
        "collapse_index"
      ],
      [
        "create_series"
      ],
      [
        "filter"
      ],
      [
        "filter_time"
      ],
      [
        "floor_index"
      ],
      [
        "get_index_char"
      ],
      [
        "get_index_class"
      ],
      [
        "get_index_col"
      ],
      [
        "get_index_quo"
      ],
      [
        "get_index_time_zone"
      ],
      [
        "new_tbl_time"
      ],
      [
        "parse_period"
      ],
      [
        "partition_index"
      ],
      [
        "reconstruct"
      ],
      [
        "rollify"
      ],
      [
        "tbl_time"
      ]
    ],
    "topics": [
      [
        "periodicity"
      ],
      [
        "tibble"
      ],
      [
        "time"
      ],
      [
        "time-series"
      ],
      [
        "timeseries"
      ],
      [
        "cpp"
      ]
    ],
    "score": 10.7528,
    "stars": 177,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "tibbletime Time Aware Tibbles Built on top of the 'tibble' package, 'tibbletime' is an\nextension that allows for the creation of time aware tibbles.\nSome immediate advantages of this include: the ability to\nperform time-based subsetting on tibbles, quickly summarising\nand aggregating results by time periods, and creating columns\nthat can be used as 'dplyr' time-based groups. %>% as_period as_tbl_time ceiling_index collapse_by collapse_index create_series filter filter_time floor_index get_index_char get_index_class get_index_col get_index_quo get_index_time_zone new_tbl_time parse_period partition_index reconstruct rollify tbl_time periodicity tibble time time-series timeseries cpp"
  },
  {
    "id": 1284,
    "package_name": "surveillance",
    "title": "Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic\nPhenomena",
    "description": "Statistical methods for the modeling and monitoring of\ntime series of counts, proportions and categorical data, as\nwell as for the modeling of continuous-time point processes of\nepidemic phenomena. The monitoring methods focus on aberration\ndetection in count data time series from public health\nsurveillance of communicable diseases, but applications could\njust as well originate from environmetrics, reliability\nengineering, econometrics, or social sciences. The package\nimplements many typical outbreak detection procedures such as\nthe (improved) Farrington algorithm, or the negative binomial\nGLR-CUSUM method of Hoehle and Paul (2008)\n<doi:10.1016/j.csda.2008.02.015>. A novel CUSUM approach\ncombining logistic and multinomial logistic modeling is also\nincluded. The package contains several real-world data sets,\nthe ability to simulate outbreak data, and to visualize the\nresults of the monitoring in a temporal, spatial or\nspatio-temporal fashion. A recent overview of the available\nmonitoring procedures is given by Salmon et al. (2016)\n<doi:10.18637/jss.v070.i10>. For the retrospective analysis of\nepidemic spread, the package provides three endemic-epidemic\nmodeling frameworks with tools for visualization, likelihood\ninference, and simulation. hhh4() estimates models for\n(multivariate) count time series following Paul and Held (2011)\n<doi:10.1002/sim.4177> and Meyer and Held (2014)\n<doi:10.1214/14-AOAS743>. twinSIR() models the\nsusceptible-infectious-recovered (SIR) event history of a fixed\npopulation, e.g, epidemics across farms or networks, as a\nmultivariate point process as proposed by Hoehle (2009)\n<doi:10.1002/bimj.200900050>. twinstim() estimates\nself-exciting point process models for a spatio-temporal point\npattern of infective events, e.g., time-stamped geo-referenced\nsurveillance data, as proposed by Meyer et al. (2012)\n<doi:10.1111/j.1541-0420.2011.01684.x>. A recent overview of\nthe implemented space-time modeling frameworks for epidemic\nphenomena is given by Meyer et al. (2017)\n<doi:10.18637/jss.v077.i11>.",
    "version": "1.25.0.9000",
    "maintainer": "Sebastian Meyer <seb.meyer@fau.de>",
    "author": "Michael Hoehle [aut, ths] (ORCID:\n<https://orcid.org/0000-0002-0423-6702>),\nSebastian Meyer [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-1791-9449>),\nMichaela Paul [aut],\nLeonhard Held [ctb, ths] (ORCID:\n<https://orcid.org/0000-0002-8686-5325>),\nHoward Burkom [ctb],\nThais Correa [ctb],\nMathias Hofmann [ctb],\nChristian Lang [ctb],\nJuliane Manitz [ctb],\nSophie Reichert [ctb],\nAndrea Riebler [ctb],\nDaniel Sabanes Bove [ctb],\nMaelle Salmon [ctb],\nDirk Schumacher [ctb],\nStefan Steiner [ctb],\nMikko Virtanen [ctb],\nWei Wei [ctb],\nValentin Wimmer [ctb],\nR Core Team [ctb] (ROR: <https://ror.org/02zz1nj61>, src/ks.c and a few\ncode fragments of standard S3 methods)",
    "url": "https://surveillance.R-Forge.R-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "addFormattedXAxis"
      ],
      [
        "addSeason2formula"
      ],
      [
        "aggregate"
      ],
      [
        "alarms"
      ],
      [
        "alarms<-"
      ],
      [
        "algo.bayes"
      ],
      [
        "algo.bayes1"
      ],
      [
        "algo.bayes2"
      ],
      [
        "algo.bayes3"
      ],
      [
        "algo.bayesLatestTimepoint"
      ],
      [
        "algo.call"
      ],
      [
        "algo.cdc"
      ],
      [
        "algo.cdcLatestTimepoint"
      ],
      [
        "algo.compare"
      ],
      [
        "algo.cusum"
      ],
      [
        "algo.farrington"
      ],
      [
        "algo.farrington.assign.weights"
      ],
      [
        "algo.farrington.fitGLM"
      ],
      [
        "algo.farrington.fitGLM.fast"
      ],
      [
        "algo.farrington.fitGLM.populationOffset"
      ],
      [
        "algo.farrington.threshold"
      ],
      [
        "algo.glrnb"
      ],
      [
        "algo.glrpois"
      ],
      [
        "algo.hmm"
      ],
      [
        "algo.outbreakP"
      ],
      [
        "algo.quality"
      ],
      [
        "algo.rki"
      ],
      [
        "algo.rki1"
      ],
      [
        "algo.rki2"
      ],
      [
        "algo.rki3"
      ],
      [
        "algo.rkiLatestTimepoint"
      ],
      [
        "algo.rogerson"
      ],
      [
        "algo.summary"
      ],
      [
        "animate"
      ],
      [
        "animate_nowcasts"
      ],
      [
        "animate.epidataCS"
      ],
      [
        "anscombe.residuals"
      ],
      [
        "arlCusum"
      ],
      [
        "as.data.frame"
      ],
      [
        "as.epidata"
      ],
      [
        "as.epidata.data.frame"
      ],
      [
        "as.epidata.default"
      ],
      [
        "as.epidata.epidataCS"
      ],
      [
        "as.epidataCS"
      ],
      [
        "as.hhh4simslist"
      ],
      [
        "as.xts.sts"
      ],
      [
        "at2ndChange"
      ],
      [
        "atChange"
      ],
      [
        "atMedian"
      ],
      [
        "autoplot.sts"
      ],
      [
        "backprojNP"
      ],
      [
        "bayes"
      ],
      [
        "bestCombination"
      ],
      [
        "boda"
      ],
      [
        "bodaDelay"
      ],
      [
        "calibrationTest"
      ],
      [
        "calibrationTest.default"
      ],
      [
        "categoricalCUSUM"
      ],
      [
        "checkResidualProcess"
      ],
      [
        "clapply"
      ],
      [
        "coeflist"
      ],
      [
        "coefW"
      ],
      [
        "control"
      ],
      [
        "control<-"
      ],
      [
        "cox"
      ],
      [
        "create.disProg"
      ],
      [
        "cusum"
      ],
      [
        "decompose.hhh4"
      ],
      [
        "delayCDF"
      ],
      [
        "discpoly"
      ],
      [
        "disProg2sts"
      ],
      [
        "dss"
      ],
      [
        "earsC"
      ],
      [
        "epidataCS2sts"
      ],
      [
        "epidataCSplot_space"
      ],
      [
        "epidataCSplot_time"
      ],
      [
        "epitest"
      ],
      [
        "epoch"
      ],
      [
        "epoch<-"
      ],
      [
        "epochInYear"
      ],
      [
        "estimateGLRNbHook"
      ],
      [
        "fanplot"
      ],
      [
        "farrington"
      ],
      [
        "farringtonFlexible"
      ],
      [
        "find.kh"
      ],
      [
        "findH"
      ],
      [
        "findK"
      ],
      [
        "fixef"
      ],
      [
        "formatDate"
      ],
      [
        "formatPval"
      ],
      [
        "frequency"
      ],
      [
        "getMaxEV"
      ],
      [
        "getMaxEV_season"
      ],
      [
        "getNEweights"
      ],
      [
        "getSourceDists"
      ],
      [
        "glm_epidataCS"
      ],
      [
        "glrnb"
      ],
      [
        "glrpois"
      ],
      [
        "hhh4"
      ],
      [
        "hValues"
      ],
      [
        "iafplot"
      ],
      [
        "intensity.twinstim"
      ],
      [
        "intensityplot"
      ],
      [
        "intensityplot.simEpidata"
      ],
      [
        "intensityplot.simEpidataCS"
      ],
      [
        "intensityplot.twinSIR"
      ],
      [
        "intensityplot.twinstim"
      ],
      [
        "intersectPolyCircle"
      ],
      [
        "intersperse"
      ],
      [
        "isoWeekYear"
      ],
      [
        "knox"
      ],
      [
        "ks.plot.unif"
      ],
      [
        "layout.labels"
      ],
      [
        "layout.scalebar"
      ],
      [
        "linelist2sts"
      ],
      [
        "logs"
      ],
      [
        "LRCUSUM.runlength"
      ],
      [
        "magic.dim"
      ],
      [
        "makeControl"
      ],
      [
        "marks"
      ],
      [
        "marks.epidataCS"
      ],
      [
        "meanHHH"
      ],
      [
        "multinomialTS"
      ],
      [
        "multinomialTS<-"
      ],
      [
        "multiplicity"
      ],
      [
        "nbOrder"
      ],
      [
        "neighbourhood"
      ],
      [
        "neighbourhood<-"
      ],
      [
        "nowcast"
      ],
      [
        "observed"
      ],
      [
        "observed<-"
      ],
      [
        "oneStepAhead"
      ],
      [
        "outbreakP"
      ],
      [
        "pairedbinCUSUM"
      ],
      [
        "pairedbinCUSUM.runlength"
      ],
      [
        "permutationTest"
      ],
      [
        "permute.epidataCS"
      ],
      [
        "pit"
      ],
      [
        "pit.default"
      ],
      [
        "plapply"
      ],
      [
        "plot"
      ],
      [
        "plotHHH4_fitted"
      ],
      [
        "plotHHH4_fitted1"
      ],
      [
        "plotHHH4_maps"
      ],
      [
        "plotHHH4_maxEV"
      ],
      [
        "plotHHH4_neweights"
      ],
      [
        "plotHHH4_ri"
      ],
      [
        "plotHHH4_season"
      ],
      [
        "plotHHH4sims_fan"
      ],
      [
        "plotHHH4sims_size"
      ],
      [
        "plotHHH4sims_time"
      ],
      [
        "poly2adjmat"
      ],
      [
        "polyAtBorder"
      ],
      [
        "population"
      ],
      [
        "population<-"
      ],
      [
        "predint"
      ],
      [
        "primeFactors"
      ],
      [
        "R0"
      ],
      [
        "ranef"
      ],
      [
        "refvalIdxByDate"
      ],
      [
        "reportingTriangle"
      ],
      [
        "reset.surveillance.options"
      ],
      [
        "rki"
      ],
      [
        "rps"
      ],
      [
        "score"
      ],
      [
        "scores"
      ],
      [
        "ses"
      ],
      [
        "siaf"
      ],
      [
        "siaf.constant"
      ],
      [
        "siaf.exponential"
      ],
      [
        "siaf.gaussian"
      ],
      [
        "siaf.powerlaw"
      ],
      [
        "siaf.powerlaw1"
      ],
      [
        "siaf.powerlawL"
      ],
      [
        "siaf.step"
      ],
      [
        "siaf.student"
      ],
      [
        "sim.pointSource"
      ],
      [
        "sim.seasonalNoise"
      ],
      [
        "simEndemicEvents"
      ],
      [
        "simEpidata"
      ],
      [
        "simEpidataCS"
      ],
      [
        "simpleR0"
      ],
      [
        "simulate.twinSIR"
      ],
      [
        "simulate.twinstim"
      ],
      [
        "sizeHHH"
      ],
      [
        "start"
      ],
      [
        "stateplot"
      ],
      [
        "stcd"
      ],
      [
        "stepComponent"
      ],
      [
        "stKtest"
      ],
      [
        "sts"
      ],
      [
        "sts_creation"
      ],
      [
        "sts_observation"
      ],
      [
        "sts2disProg"
      ],
      [
        "stsplot_alarm"
      ],
      [
        "stsplot_space"
      ],
      [
        "stsplot_time"
      ],
      [
        "stsplot_time1"
      ],
      [
        "summary.twinstim"
      ],
      [
        "surveillance.options"
      ],
      [
        "tiaf"
      ],
      [
        "tiaf.constant"
      ],
      [
        "tiaf.exponential"
      ],
      [
        "tiaf.step"
      ],
      [
        "tidy.sts"
      ],
      [
        "toLatex"
      ],
      [
        "twinSIR"
      ],
      [
        "twinstim"
      ],
      [
        "unionSpatialPolygons"
      ],
      [
        "untie"
      ],
      [
        "update.epidataCS"
      ],
      [
        "update.hhh4"
      ],
      [
        "update.twinstim"
      ],
      [
        "upperbound"
      ],
      [
        "upperbound<-"
      ],
      [
        "W_np"
      ],
      [
        "W_powerlaw"
      ],
      [
        "wrap.algo"
      ],
      [
        "xtable.summary.twinstim"
      ],
      [
        "year"
      ],
      [
        "zetaweights"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 10.7272,
    "stars": 2,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "surveillance Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic\nPhenomena Statistical methods for the modeling and monitoring of\ntime series of counts, proportions and categorical data, as\nwell as for the modeling of continuous-time point processes of\nepidemic phenomena. The monitoring methods focus on aberration\ndetection in count data time series from public health\nsurveillance of communicable diseases, but applications could\njust as well originate from environmetrics, reliability\nengineering, econometrics, or social sciences. The package\nimplements many typical outbreak detection procedures such as\nthe (improved) Farrington algorithm, or the negative binomial\nGLR-CUSUM method of Hoehle and Paul (2008)\n<doi:10.1016/j.csda.2008.02.015>. A novel CUSUM approach\ncombining logistic and multinomial logistic modeling is also\nincluded. The package contains several real-world data sets,\nthe ability to simulate outbreak data, and to visualize the\nresults of the monitoring in a temporal, spatial or\nspatio-temporal fashion. A recent overview of the available\nmonitoring procedures is given by Salmon et al. (2016)\n<doi:10.18637/jss.v070.i10>. For the retrospective analysis of\nepidemic spread, the package provides three endemic-epidemic\nmodeling frameworks with tools for visualization, likelihood\ninference, and simulation. hhh4() estimates models for\n(multivariate) count time series following Paul and Held (2011)\n<doi:10.1002/sim.4177> and Meyer and Held (2014)\n<doi:10.1214/14-AOAS743>. twinSIR() models the\nsusceptible-infectious-recovered (SIR) event history of a fixed\npopulation, e.g, epidemics across farms or networks, as a\nmultivariate point process as proposed by Hoehle (2009)\n<doi:10.1002/bimj.200900050>. twinstim() estimates\nself-exciting point process models for a spatio-temporal point\npattern of infective events, e.g., time-stamped geo-referenced\nsurveillance data, as proposed by Meyer et al. (2012)\n<doi:10.1111/j.1541-0420.2011.01684.x>. A recent overview of\nthe implemented space-time modeling frameworks for epidemic\nphenomena is given by Meyer et al. (2017)\n<doi:10.18637/jss.v077.i11>. addFormattedXAxis addSeason2formula aggregate alarms alarms<- algo.bayes algo.bayes1 algo.bayes2 algo.bayes3 algo.bayesLatestTimepoint algo.call algo.cdc algo.cdcLatestTimepoint algo.compare algo.cusum algo.farrington algo.farrington.assign.weights algo.farrington.fitGLM algo.farrington.fitGLM.fast algo.farrington.fitGLM.populationOffset algo.farrington.threshold algo.glrnb algo.glrpois algo.hmm algo.outbreakP algo.quality algo.rki algo.rki1 algo.rki2 algo.rki3 algo.rkiLatestTimepoint algo.rogerson algo.summary animate animate_nowcasts animate.epidataCS anscombe.residuals arlCusum as.data.frame as.epidata as.epidata.data.frame as.epidata.default as.epidata.epidataCS as.epidataCS as.hhh4simslist as.xts.sts at2ndChange atChange atMedian autoplot.sts backprojNP bayes bestCombination boda bodaDelay calibrationTest calibrationTest.default categoricalCUSUM checkResidualProcess clapply coeflist coefW control control<- cox create.disProg cusum decompose.hhh4 delayCDF discpoly disProg2sts dss earsC epidataCS2sts epidataCSplot_space epidataCSplot_time epitest epoch epoch<- epochInYear estimateGLRNbHook fanplot farrington farringtonFlexible find.kh findH findK fixef formatDate formatPval frequency getMaxEV getMaxEV_season getNEweights getSourceDists glm_epidataCS glrnb glrpois hhh4 hValues iafplot intensity.twinstim intensityplot intensityplot.simEpidata intensityplot.simEpidataCS intensityplot.twinSIR intensityplot.twinstim intersectPolyCircle intersperse isoWeekYear knox ks.plot.unif layout.labels layout.scalebar linelist2sts logs LRCUSUM.runlength magic.dim makeControl marks marks.epidataCS meanHHH multinomialTS multinomialTS<- multiplicity nbOrder neighbourhood neighbourhood<- nowcast observed observed<- oneStepAhead outbreakP pairedbinCUSUM pairedbinCUSUM.runlength permutationTest permute.epidataCS pit pit.default plapply plot plotHHH4_fitted plotHHH4_fitted1 plotHHH4_maps plotHHH4_maxEV plotHHH4_neweights plotHHH4_ri plotHHH4_season plotHHH4sims_fan plotHHH4sims_size plotHHH4sims_time poly2adjmat polyAtBorder population population<- predint primeFactors R0 ranef refvalIdxByDate reportingTriangle reset.surveillance.options rki rps score scores ses siaf siaf.constant siaf.exponential siaf.gaussian siaf.powerlaw siaf.powerlaw1 siaf.powerlawL siaf.step siaf.student sim.pointSource sim.seasonalNoise simEndemicEvents simEpidata simEpidataCS simpleR0 simulate.twinSIR simulate.twinstim sizeHHH start stateplot stcd stepComponent stKtest sts sts_creation sts_observation sts2disProg stsplot_alarm stsplot_space stsplot_time stsplot_time1 summary.twinstim surveillance.options tiaf tiaf.constant tiaf.exponential tiaf.step tidy.sts toLatex twinSIR twinstim unionSpatialPolygons untie update.epidataCS update.hhh4 update.twinstim upperbound upperbound<- W_np W_powerlaw wrap.algo xtable.summary.twinstim year zetaweights cpp"
  },
  {
    "id": 48,
    "package_name": "EpiEstim",
    "title": "Estimate Time Varying Reproduction Numbers from Epidemic Curves",
    "description": "Tools to quantify transmissibility throughout an epidemic\nfrom the analysis of time series of incidence as described in\nCori et al. (2013) <doi:10.1093/aje/kwt133> and Wallinga and\nTeunis (2004) <doi:10.1093/aje/kwh255>.",
    "version": "2.4",
    "maintainer": "Anne Cori <a.cori@imperial.ac.uk>",
    "author": "Anne Cori [aut, cre] (ORCID: <https://orcid.org/0000-0002-8443-9162>),\nSimon Cauchemez [ctb],\nNeil M. Ferguson [ctb] (ORCID: <https://orcid.org/0000-0002-1154-8093>),\nChristophe Fraser [ctb] (ORCID:\n<https://orcid.org/0000-0003-2399-9657>),\nElisabeth Dahlqwist [ctb] (ORCID:\n<https://orcid.org/0000-0001-5797-6803>),\nP. Alex Demarsh [ctb],\nThibaut Jombart [ctb] (ORCID: <https://orcid.org/0000-0003-2226-8692>),\nZhian N. Kamvar [ctb] (ORCID: <https://orcid.org/0000-0003-1458-7108>),\nJustin Lessler [ctb] (ORCID: <https://orcid.org/0000-0002-9741-8109>),\nShikun Li [ctb],\nJonathan A. Polonsky [ctb] (ORCID:\n<https://orcid.org/0000-0002-8634-4255>),\nJake Stockwin [ctb],\nRobin Thompson [ctb] (ORCID: <https://orcid.org/0000-0001-8545-5212>),\nRolina van Gaalen [ctb],\nRebecca Nash [ctb] (ORCID: <https://orcid.org/0000-0002-5213-4364>),\nSangeeta Bhatia [ctb] (ORCID: <https://orcid.org/0000-0001-6525-101X>),\nJack Wardle [ctb] (ORCID: <https://orcid.org/0000-0002-5363-1653>),\nAndrea Brizzi [ctb] (ORCID: <https://orcid.org/0000-0002-5639-8260>)",
    "url": "https://github.com/mrc-ide/EpiEstim",
    "bug_reports": "https://github.com/mrc-ide/EpiEstim/issues",
    "repository": "",
    "exports": [
      [
        "aggregate_inc"
      ],
      [
        "backimpute_I"
      ],
      [
        "check_cdt_samples_convergence"
      ],
      [
        "coarse2estim"
      ],
      [
        "compute_lambda"
      ],
      [
        "compute_si_cutoff"
      ],
      [
        "compute_t_min"
      ],
      [
        "default_mcmc_controls"
      ],
      [
        "default_priors"
      ],
      [
        "discr_si"
      ],
      [
        "DiscrSI"
      ],
      [
        "draw_epsilon"
      ],
      [
        "draw_R"
      ],
      [
        "estimate_advantage"
      ],
      [
        "estimate_R"
      ],
      [
        "estimate_R_agg"
      ],
      [
        "estimate_R_plots"
      ],
      [
        "EstimateR"
      ],
      [
        "first_nonzero_incid"
      ],
      [
        "get_shape_epsilon"
      ],
      [
        "get_shape_R_flat"
      ],
      [
        "init_mcmc_params"
      ],
      [
        "make_config"
      ],
      [
        "make_mcmc_control"
      ],
      [
        "overall_infectivity"
      ],
      [
        "OverallInfectivity"
      ],
      [
        "process_I_multivariant"
      ],
      [
        "sample_posterior_R"
      ],
      [
        "wallinga_teunis"
      ],
      [
        "WT"
      ]
    ],
    "topics": [],
    "score": 10.6498,
    "stars": 101,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "EpiEstim Estimate Time Varying Reproduction Numbers from Epidemic Curves Tools to quantify transmissibility throughout an epidemic\nfrom the analysis of time series of incidence as described in\nCori et al. (2013) <doi:10.1093/aje/kwt133> and Wallinga and\nTeunis (2004) <doi:10.1093/aje/kwh255>. aggregate_inc backimpute_I check_cdt_samples_convergence coarse2estim compute_lambda compute_si_cutoff compute_t_min default_mcmc_controls default_priors discr_si DiscrSI draw_epsilon draw_R estimate_advantage estimate_R estimate_R_agg estimate_R_plots EstimateR first_nonzero_incid get_shape_epsilon get_shape_R_flat init_mcmc_params make_config make_mcmc_control overall_infectivity OverallInfectivity process_I_multivariant sample_posterior_R wallinga_teunis WT "
  },
  {
    "id": 1199,
    "package_name": "sftime",
    "title": "Classes and Methods for Simple Feature Objects that Have a Time\nColumn",
    "description": "Classes and methods for spatial objects that have a\nregistered time column, in particular for irregular\nspatiotemporal data. The time column can be of any type, but\nneeds to be ordinal. Regularly laid out spatiotemporal data\n(vector or raster data cubes) are handled by package 'stars'.",
    "version": "0.3.1.9000",
    "maintainer": "Henning Teickner <henning.teickner@uni-muenster.de>",
    "author": "Henning Teickner [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0002-3993-1182>),\nEdzer Pebesma [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-8049-7069>),\nBenedikt Graeler [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-5443-4304>)",
    "url": "https://r-spatial.github.io/sftime/,\nhttps://github.com/r-spatial/sftime",
    "bug_reports": "https://github.com/r-spatial/sftime/issues/",
    "repository": "",
    "exports": [
      [
        "is_sortable"
      ],
      [
        "st_as_sftime"
      ],
      [
        "st_drop_time"
      ],
      [
        "st_set_time"
      ],
      [
        "st_sftime"
      ],
      [
        "st_time"
      ],
      [
        "st_time<-"
      ]
    ],
    "topics": [],
    "score": 10.6317,
    "stars": 50,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "sftime Classes and Methods for Simple Feature Objects that Have a Time\nColumn Classes and methods for spatial objects that have a\nregistered time column, in particular for irregular\nspatiotemporal data. The time column can be of any type, but\nneeds to be ordinal. Regularly laid out spatiotemporal data\n(vector or raster data cubes) are handled by package 'stars'. is_sortable st_as_sftime st_drop_time st_set_time st_sftime st_time st_time<- "
  },
  {
    "id": 1390,
    "package_name": "tsbox",
    "title": "Class-Agnostic Time Series",
    "description": "Time series toolkit with identical behavior for all time\nseries classes: 'ts','xts', 'data.frame', 'data.table',\n'tibble', 'zoo', 'timeSeries', 'tsibble', 'tis' or 'irts'. Also\nconverts reliably between these classes.",
    "version": "0.4.2",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7192-7044>),\nCathy Chamberlin [rev],\nNunes Matt [rev]",
    "url": "https://docs.ropensci.org/tsbox/,\nhttps://github.com/ropensci/tsbox",
    "bug_reports": "https://github.com/ropensci/tsbox/issues",
    "repository": "",
    "exports": [
      [
        "%ts-%"
      ],
      [
        "%ts*%"
      ],
      [
        "%ts/%"
      ],
      [
        "%ts+%"
      ],
      [
        "check_ts_boxable"
      ],
      [
        "colors_tsbox"
      ],
      [
        "copy_class"
      ],
      [
        "load_suggested"
      ],
      [
        "relevant_class"
      ],
      [
        "scale_color_tsbox"
      ],
      [
        "scale_fill_tsbox"
      ],
      [
        "theme_tsbox"
      ],
      [
        "ts_"
      ],
      [
        "ts_apply"
      ],
      [
        "ts_bind"
      ],
      [
        "ts_boxable"
      ],
      [
        "ts_c"
      ],
      [
        "ts_chain"
      ],
      [
        "ts_compound"
      ],
      [
        "ts_data.frame"
      ],
      [
        "ts_data.table"
      ],
      [
        "ts_default"
      ],
      [
        "ts_df"
      ],
      [
        "ts_diff"
      ],
      [
        "ts_diffy"
      ],
      [
        "ts_dt"
      ],
      [
        "ts_dts"
      ],
      [
        "ts_dygraphs"
      ],
      [
        "ts_end"
      ],
      [
        "ts_first_of_period"
      ],
      [
        "ts_forecast"
      ],
      [
        "ts_frequency"
      ],
      [
        "ts_ggplot"
      ],
      [
        "ts_index"
      ],
      [
        "ts_irts"
      ],
      [
        "ts_lag"
      ],
      [
        "ts_long"
      ],
      [
        "ts_na_interpolation"
      ],
      [
        "ts_na_omit"
      ],
      [
        "ts_pc"
      ],
      [
        "ts_pca"
      ],
      [
        "ts_pcy"
      ],
      [
        "ts_pick"
      ],
      [
        "ts_plot"
      ],
      [
        "ts_prcomp"
      ],
      [
        "ts_regular"
      ],
      [
        "ts_save"
      ],
      [
        "ts_scale"
      ],
      [
        "ts_seas"
      ],
      [
        "ts_span"
      ],
      [
        "ts_start"
      ],
      [
        "ts_summary"
      ],
      [
        "ts_tbl"
      ],
      [
        "ts_tibbletime"
      ],
      [
        "ts_timeSeries"
      ],
      [
        "ts_tis"
      ],
      [
        "ts_trend"
      ],
      [
        "ts_ts"
      ],
      [
        "ts_tsibble"
      ],
      [
        "ts_tslist"
      ],
      [
        "ts_wide"
      ],
      [
        "ts_xts"
      ],
      [
        "ts_zoo"
      ],
      [
        "ts_zooreg"
      ]
    ],
    "topics": [
      [
        "graphics"
      ],
      [
        "time-series"
      ]
    ],
    "score": 10.5974,
    "stars": 149,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "tsbox Class-Agnostic Time Series Time series toolkit with identical behavior for all time\nseries classes: 'ts','xts', 'data.frame', 'data.table',\n'tibble', 'zoo', 'timeSeries', 'tsibble', 'tis' or 'irts'. Also\nconverts reliably between these classes. %ts-% %ts*% %ts/% %ts+% check_ts_boxable colors_tsbox copy_class load_suggested relevant_class scale_color_tsbox scale_fill_tsbox theme_tsbox ts_ ts_apply ts_bind ts_boxable ts_c ts_chain ts_compound ts_data.frame ts_data.table ts_default ts_df ts_diff ts_diffy ts_dt ts_dts ts_dygraphs ts_end ts_first_of_period ts_forecast ts_frequency ts_ggplot ts_index ts_irts ts_lag ts_long ts_na_interpolation ts_na_omit ts_pc ts_pca ts_pcy ts_pick ts_plot ts_prcomp ts_regular ts_save ts_scale ts_seas ts_span ts_start ts_summary ts_tbl ts_tibbletime ts_timeSeries ts_tis ts_trend ts_ts ts_tsibble ts_tslist ts_wide ts_xts ts_zoo ts_zooreg graphics time-series"
  },
  {
    "id": 1257,
    "package_name": "spatsoc",
    "title": "Group Animal Relocation Data by Spatial and Temporal\nRelationship",
    "description": "Detects spatial and temporal groups in GPS relocations\n(Robitaille et al. (2019) <doi:10.1111/2041-210X.13215>).  It\ncan be used to convert GPS relocations to gambit-of-the-group\nformat to build proximity-based social networks In addition,\nthe randomizations function provides data-stream randomization\nmethods suitable for GPS data.",
    "version": "0.2.12.9004",
    "maintainer": "Alec L. Robitaille <robit.alec@gmail.com>",
    "author": "Alec L. Robitaille [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-4706-1762>),\nQuinn Webber [aut] (ORCID: <https://orcid.org/0000-0002-0434-9360>),\nEric Vander Wal [aut] (ORCID: <https://orcid.org/0000-0002-8534-4317>)",
    "url": "https://docs.ropensci.org/spatsoc/,\nhttps://github.com/ropensci/spatsoc",
    "bug_reports": "https://github.com/ropensci/spatsoc/issues",
    "repository": "",
    "exports": [
      [
        "build_lines"
      ],
      [
        "build_polys"
      ],
      [
        "centroid_dyad"
      ],
      [
        "centroid_fusion"
      ],
      [
        "centroid_group"
      ],
      [
        "direction_group"
      ],
      [
        "direction_polarization"
      ],
      [
        "direction_step"
      ],
      [
        "direction_to_centroid"
      ],
      [
        "direction_to_leader"
      ],
      [
        "distance_to_centroid"
      ],
      [
        "distance_to_leader"
      ],
      [
        "dyad_id"
      ],
      [
        "edge_alignment"
      ],
      [
        "edge_delay"
      ],
      [
        "edge_direction"
      ],
      [
        "edge_dist"
      ],
      [
        "edge_nn"
      ],
      [
        "edge_zones"
      ],
      [
        "fusion_id"
      ],
      [
        "get_gbi"
      ],
      [
        "get_geometry"
      ],
      [
        "group_lines"
      ],
      [
        "group_polys"
      ],
      [
        "group_pts"
      ],
      [
        "group_times"
      ],
      [
        "leader_direction_group"
      ],
      [
        "leader_edge_delay"
      ],
      [
        "randomizations"
      ]
    ],
    "topics": [
      [
        "animal"
      ],
      [
        "gps"
      ],
      [
        "network"
      ],
      [
        "social"
      ],
      [
        "spatial"
      ]
    ],
    "score": 10.5134,
    "stars": 24,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "spatsoc Group Animal Relocation Data by Spatial and Temporal\nRelationship Detects spatial and temporal groups in GPS relocations\n(Robitaille et al. (2019) <doi:10.1111/2041-210X.13215>).  It\ncan be used to convert GPS relocations to gambit-of-the-group\nformat to build proximity-based social networks In addition,\nthe randomizations function provides data-stream randomization\nmethods suitable for GPS data. build_lines build_polys centroid_dyad centroid_fusion centroid_group direction_group direction_polarization direction_step direction_to_centroid direction_to_leader distance_to_centroid distance_to_leader dyad_id edge_alignment edge_delay edge_direction edge_dist edge_nn edge_zones fusion_id get_gbi get_geometry group_lines group_polys group_pts group_times leader_direction_group leader_edge_delay randomizations animal gps network social spatial"
  },
  {
    "id": 870,
    "package_name": "nasapower",
    "title": "NASA POWER API Client",
    "description": "An API client for NASA POWER global meteorology, surface\nsolar energy and climatology data API.  POWER (Prediction Of\nWorldwide Energy Resources) data are freely available for\ndownload with varying spatial resolutions dependent on the\noriginal data and with several temporal resolutions depending\non the POWER parameter and community. This work is funded\nthrough the NASA Earth Science Directorate Applied Science\nProgram.  For more on the data themselves, the methodologies\nused in creating, a web-based data viewer and web access,\nplease see <https://power.larc.nasa.gov/>.",
    "version": "4.2.5.9000",
    "maintainer": "Adam H. Sparks <adamhsparks@gmail.com>",
    "author": "Adam H. Sparks [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-0061-8359>),\nScott Chamberlain [rev] (ORCID:\n<https://orcid.org/0000-0003-1444-9135>, Scott Chamberlain reviewed\nnasapower for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/155>.),\nHazel Kavili [rev] (Hazel Kavili reviewed nasapower for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/155>.),\nAlison Boyer [rev] (Alison Boyer reviewed nasapower for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/155>.),\nFernando Miguez [ctb] (ORCID: <https://orcid.org/0000-0002-4627-8329>,\nFernando Miguez provided assistance in identifying improper missing\nvalue handling in the POWER data, see\n<https://github.com/femiguez/apsimx/pull/26>.),\nMa\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>,\nMa\u00eblle Salmon contributed a patch to fix issues with using the R\npackage, 'vcr', for testing the API queries, see\n<https://github.com/ropensci/nasapower/pull/64>.),\nPhillip D. Alderman [ctb] (ORCID:\n<https://orcid.org/0000-0003-1467-2337>, Phillip Alderman\ncontributed a patch to fix an issue with, 'The `file` argument of\n`vroom()` must use `I()` for literal data as of vroom 1.5.0.', see\n<https://github.com/ropensci/nasapower/pull/67>.),\nAleksandar Blagoti\u0107 [ctb, cph] (Author of the CRAN package\n'rapportools', from which the '.is_boolean()' was taken.),\nGergely Dar\u00f3czi [ctb, cph] (Author of the CRAN package 'rapportools',\nfrom which the '.is_boolean()' was taken.),\nCurtin University [cph] (Supported the development of 'nasapower'\nthrough Adam H.  Sparks' time.),\nJames J. Balamuta [ctb, cph] (Author of the GitHub package 'rops', from\nwhich the '%notin%' function was taken.)",
    "url": "https://docs.ropensci.org/nasapower/",
    "bug_reports": "https://github.com/ropensci/nasapower/issues",
    "repository": "",
    "exports": [
      [
        "get_power"
      ],
      [
        "query_groupings"
      ],
      [
        "query_parameters"
      ],
      [
        "query_surfaces"
      ]
    ],
    "topics": [
      [
        "nasa"
      ],
      [
        "meteorological-data"
      ],
      [
        "weather"
      ],
      [
        "global"
      ],
      [
        "weather-data"
      ],
      [
        "meteorology"
      ],
      [
        "nasa-power"
      ],
      [
        "agroclimatology"
      ],
      [
        "earth-science"
      ],
      [
        "data-access"
      ],
      [
        "climate-data"
      ],
      [
        "agroclimatology-data"
      ],
      [
        "weather-variables"
      ]
    ],
    "score": 10.4456,
    "stars": 106,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "nasapower NASA POWER API Client An API client for NASA POWER global meteorology, surface\nsolar energy and climatology data API.  POWER (Prediction Of\nWorldwide Energy Resources) data are freely available for\ndownload with varying spatial resolutions dependent on the\noriginal data and with several temporal resolutions depending\non the POWER parameter and community. This work is funded\nthrough the NASA Earth Science Directorate Applied Science\nProgram.  For more on the data themselves, the methodologies\nused in creating, a web-based data viewer and web access,\nplease see <https://power.larc.nasa.gov/>. get_power query_groupings query_parameters query_surfaces nasa meteorological-data weather global weather-data meteorology nasa-power agroclimatology earth-science data-access climate-data agroclimatology-data weather-variables"
  },
  {
    "id": 261,
    "package_name": "auk",
    "title": "eBird Data Extraction and Processing in R",
    "description": "Extract and process bird sightings records from eBird\n(<http://ebird.org>), an online tool for recording bird\nobservations.  Public access to the full eBird database is via\nthe eBird Basic Dataset (EBD; see\n<http://ebird.org/ebird/data/download> for access), a\ndownloadable text file. This package is an interface to AWK for\nextracting data from the EBD based on taxonomic, spatial, or\ntemporal filters, to produce a manageable file size that can be\nimported into R.",
    "version": "0.9.0",
    "maintainer": "Matthew Strimas-Mackey <mes335@cornell.edu>",
    "author": "Matthew Strimas-Mackey [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8929-7776>),\nEliot Miller [aut],\nWesley Hochachka [aut],\nCornell Lab of Ornithology [cph]",
    "url": "https://cornelllabofornithology.github.io/auk/",
    "bug_reports": "https://github.com/CornellLabofOrnithology/auk/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "auk_bbox"
      ],
      [
        "auk_bcr"
      ],
      [
        "auk_breeding"
      ],
      [
        "auk_clean"
      ],
      [
        "auk_complete"
      ],
      [
        "auk_country"
      ],
      [
        "auk_county"
      ],
      [
        "auk_date"
      ],
      [
        "auk_distance"
      ],
      [
        "auk_duration"
      ],
      [
        "auk_ebd"
      ],
      [
        "auk_ebd_version"
      ],
      [
        "auk_exotic"
      ],
      [
        "auk_extent"
      ],
      [
        "auk_filter"
      ],
      [
        "auk_get_awk_path"
      ],
      [
        "auk_get_ebd_path"
      ],
      [
        "auk_last_edited"
      ],
      [
        "auk_observer"
      ],
      [
        "auk_project"
      ],
      [
        "auk_protocol"
      ],
      [
        "auk_rollup"
      ],
      [
        "auk_sampling"
      ],
      [
        "auk_select"
      ],
      [
        "auk_set_awk_path"
      ],
      [
        "auk_set_ebd_path"
      ],
      [
        "auk_species"
      ],
      [
        "auk_split"
      ],
      [
        "auk_state"
      ],
      [
        "auk_time"
      ],
      [
        "auk_unique"
      ],
      [
        "auk_version"
      ],
      [
        "auk_year"
      ],
      [
        "auk_zerofill"
      ],
      [
        "collapse_zerofill"
      ],
      [
        "ebird_species"
      ],
      [
        "filter_repeat_visits"
      ],
      [
        "format_unmarked_occu"
      ],
      [
        "get_ebird_taxonomy"
      ],
      [
        "process_barcharts"
      ],
      [
        "read_ebd"
      ],
      [
        "read_sampling"
      ]
    ],
    "topics": [
      [
        "dataset"
      ],
      [
        "ebird"
      ]
    ],
    "score": 9.9999,
    "stars": 152,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "auk eBird Data Extraction and Processing in R Extract and process bird sightings records from eBird\n(<http://ebird.org>), an online tool for recording bird\nobservations.  Public access to the full eBird database is via\nthe eBird Basic Dataset (EBD; see\n<http://ebird.org/ebird/data/download> for access), a\ndownloadable text file. This package is an interface to AWK for\nextracting data from the EBD based on taxonomic, spatial, or\ntemporal filters, to produce a manageable file size that can be\nimported into R. %>% auk_bbox auk_bcr auk_breeding auk_clean auk_complete auk_country auk_county auk_date auk_distance auk_duration auk_ebd auk_ebd_version auk_exotic auk_extent auk_filter auk_get_awk_path auk_get_ebd_path auk_last_edited auk_observer auk_project auk_protocol auk_rollup auk_sampling auk_select auk_set_awk_path auk_set_ebd_path auk_species auk_split auk_state auk_time auk_unique auk_version auk_year auk_zerofill collapse_zerofill ebird_species filter_repeat_visits format_unmarked_occu get_ebird_taxonomy process_barcharts read_ebd read_sampling dataset ebird"
  },
  {
    "id": 240,
    "package_name": "anomalize",
    "title": "Tidy Anomaly Detection",
    "description": "The 'anomalize' package enables a \"tidy\" workflow for\ndetecting anomalies in data. The main functions are\ntime_decompose(), anomalize(), and time_recompose(). When\ncombined, it's quite simple to decompose time series, detect\nanomalies, and create bands separating the \"normal\" data from\nthe anomalous data at scale (i.e. for multiple time series).\nTime series decomposition is used to remove trend and seasonal\ncomponents via the time_decompose() function and methods\ninclude seasonal decomposition of time series by Loess (\"stl\")\nand seasonal decomposition by piecewise medians (\"twitter\").\nThe anomalize() function implements two methods for anomaly\ndetection of residuals including using an inner quartile range\n(\"iqr\") and generalized extreme studentized deviation (\"gesd\").\nThese methods are based on those used in the 'forecast' package\nand the Twitter 'AnomalyDetection' package. Refer to the\nassociated functions for specific references for these methods.",
    "version": "0.3.0.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nDavis Vaughan [aut]",
    "url": "https://business-science.github.io/anomalize/,\nhttps://github.com/business-science/anomalize",
    "bug_reports": "https://github.com/business-science/anomalize/issues",
    "repository": "",
    "exports": [
      [
        "anomalize"
      ],
      [
        "clean_anomalies"
      ],
      [
        "decompose_stl"
      ],
      [
        "decompose_twitter"
      ],
      [
        "gesd"
      ],
      [
        "get_time_scale_template"
      ],
      [
        "iqr"
      ],
      [
        "plot_anomalies"
      ],
      [
        "plot_anomaly_decomposition"
      ],
      [
        "prep_tbl_time"
      ],
      [
        "set_time_scale_template"
      ],
      [
        "time_apply"
      ],
      [
        "time_decompose"
      ],
      [
        "time_frequency"
      ],
      [
        "time_recompose"
      ],
      [
        "time_scale_template"
      ],
      [
        "time_trend"
      ]
    ],
    "topics": [
      [
        "anomaly"
      ],
      [
        "anomaly-detection"
      ],
      [
        "decomposition"
      ],
      [
        "detect-anomalies"
      ],
      [
        "iqr"
      ],
      [
        "time-series"
      ]
    ],
    "score": 9.7673,
    "stars": 339,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "anomalize Tidy Anomaly Detection The 'anomalize' package enables a \"tidy\" workflow for\ndetecting anomalies in data. The main functions are\ntime_decompose(), anomalize(), and time_recompose(). When\ncombined, it's quite simple to decompose time series, detect\nanomalies, and create bands separating the \"normal\" data from\nthe anomalous data at scale (i.e. for multiple time series).\nTime series decomposition is used to remove trend and seasonal\ncomponents via the time_decompose() function and methods\ninclude seasonal decomposition of time series by Loess (\"stl\")\nand seasonal decomposition by piecewise medians (\"twitter\").\nThe anomalize() function implements two methods for anomaly\ndetection of residuals including using an inner quartile range\n(\"iqr\") and generalized extreme studentized deviation (\"gesd\").\nThese methods are based on those used in the 'forecast' package\nand the Twitter 'AnomalyDetection' package. Refer to the\nassociated functions for specific references for these methods. anomalize clean_anomalies decompose_stl decompose_twitter gesd get_time_scale_template iqr plot_anomalies plot_anomaly_decomposition prep_tbl_time set_time_scale_template time_apply time_decompose time_frequency time_recompose time_scale_template time_trend anomaly anomaly-detection decomposition detect-anomalies iqr time-series"
  },
  {
    "id": 836,
    "package_name": "modeltime.ensemble",
    "title": "Ensemble Algorithms for Time Series Forecasting with Modeltime",
    "description": "A 'modeltime' extension that implements time series\nensemble forecasting methods including model averaging,\nweighted averaging, and stacking. These techniques are popular\nmethods to improve forecast accuracy and stability.",
    "version": "1.1.0.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nBusiness Science [cph]",
    "url": "https://business-science.github.io/modeltime.ensemble/,\nhttps://github.com/business-science/modeltime.ensemble",
    "bug_reports": "https://github.com/business-science/modeltime.ensemble/issues",
    "repository": "",
    "exports": [
      [
        ":="
      ],
      [
        ".data"
      ],
      [
        "%>%"
      ],
      [
        "as_label"
      ],
      [
        "as_name"
      ],
      [
        "enquo"
      ],
      [
        "enquos"
      ],
      [
        "ensemble_average"
      ],
      [
        "ensemble_model_spec"
      ],
      [
        "ensemble_nested_average"
      ],
      [
        "ensemble_nested_weighted"
      ],
      [
        "ensemble_weighted"
      ],
      [
        "expr"
      ],
      [
        "sym"
      ],
      [
        "syms"
      ]
    ],
    "topics": [
      [
        "ensemble"
      ],
      [
        "ensemble-learning"
      ],
      [
        "forecast"
      ],
      [
        "forecasting"
      ],
      [
        "modeltime"
      ],
      [
        "stacking"
      ],
      [
        "stacking-ensemble"
      ],
      [
        "tidymodels"
      ],
      [
        "time"
      ],
      [
        "time-series"
      ],
      [
        "timeseries"
      ]
    ],
    "score": 9.3876,
    "stars": 80,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "modeltime.ensemble Ensemble Algorithms for Time Series Forecasting with Modeltime A 'modeltime' extension that implements time series\nensemble forecasting methods including model averaging,\nweighted averaging, and stacking. These techniques are popular\nmethods to improve forecast accuracy and stability. := .data %>% as_label as_name enquo enquos ensemble_average ensemble_model_spec ensemble_nested_average ensemble_nested_weighted ensemble_weighted expr sym syms ensemble ensemble-learning forecast forecasting modeltime stacking stacking-ensemble tidymodels time time-series timeseries"
  },
  {
    "id": 1291,
    "package_name": "sweep",
    "title": "Tidy Tools for Forecasting",
    "description": "Tidies up the forecasting modeling and prediction work\nflow, extends the 'broom' package with 'sw_tidy', 'sw_glance',\n'sw_augment', and 'sw_tidy_decomp' functions for various\nforecasting models, and enables converting 'forecast' objects\nto \"tidy\" data frames with 'sw_sweep'.",
    "version": "0.2.6.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nDavis Vaughan [aut]",
    "url": "https://business-science.github.io/sweep/,\nhttps://github.com/business-science/sweep",
    "bug_reports": "https://github.com/business-science/sweep/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "sw_augment"
      ],
      [
        "sw_glance"
      ],
      [
        "sw_sweep"
      ],
      [
        "sw_tidy"
      ],
      [
        "sw_tidy_decomp"
      ]
    ],
    "topics": [
      [
        "broom"
      ],
      [
        "forecast"
      ],
      [
        "forecasting-models"
      ],
      [
        "prediction"
      ],
      [
        "tidy"
      ],
      [
        "tidyverse"
      ],
      [
        "time"
      ],
      [
        "time-series"
      ],
      [
        "timeseries"
      ]
    ],
    "score": 9.3732,
    "stars": 154,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "sweep Tidy Tools for Forecasting Tidies up the forecasting modeling and prediction work\nflow, extends the 'broom' package with 'sw_tidy', 'sw_glance',\n'sw_augment', and 'sw_tidy_decomp' functions for various\nforecasting models, and enables converting 'forecast' objects\nto \"tidy\" data frames with 'sw_sweep'. %>% sw_augment sw_glance sw_sweep sw_tidy sw_tidy_decomp broom forecast forecasting-models prediction tidy tidyverse time time-series timeseries"
  },
  {
    "id": 1230,
    "package_name": "sits",
    "title": "Satellite Image Time Series Analysis for Earth Observation Data\nCubes",
    "description": "An end-to-end toolkit for land use and land cover\nclassification using big Earth observation data. Builds\nsatellite image data cubes from cloud collections. Supports\nvisualization methods for images and time series and smoothing\nfilters for dealing with noisy time series. Enables merging of\nmulti-source imagery (SAR, optical, DEM). Includes functions\nfor quality assessment of training samples using self-organized\nmaps and to reduce training samples imbalance. Provides machine\nlearning algorithms including support vector machines, random\nforests, extreme gradient boosting, multi-layer perceptrons,\ntemporal convolution neural networks, and temporal attention\nencoders. Performs efficient classification of big Earth\nobservation data cubes and includes functions for\npost-classification smoothing based on Bayesian inference.\nEnables best practices for estimating area and assessing\naccuracy of land change. Includes object-based spatio-temporal\nsegmentation for space-time OBIA. Minimum recommended\nrequirements: 16 GB RAM and 4 CPU dual-core.",
    "version": "1.5.3-1",
    "maintainer": "Gilberto Camara <gilberto.camara.inpe@gmail.com>",
    "author": "Rolf Simoes [aut],\nGilberto Camara [aut, cre, ths],\nFelipe Souza [aut],\nFelipe Carlos [aut],\nLorena Santos [ctb],\nCharlotte Pelletier [ctb],\nEstefania Pizarro [ctb],\nKarine Ferreira [ctb, ths],\nAlber Sanchez [ctb],\nAlexandre Assuncao [ctb],\nDaniel Falbel [ctb],\nGilberto Queiroz [ctb],\nJohannes Reiche [ctb],\nPedro Andrade [ctb],\nPedro Brito [ctb],\nRenato Assuncao [ctb],\nRicardo Cartaxo [ctb]",
    "url": "https://github.com/e-sensing/sits/,\nhttps://e-sensing.github.io/sitsbook/,\nhttps://e-sensing.github.io/sits/",
    "bug_reports": "https://github.com/e-sensing/sits/issues",
    "repository": "",
    "exports": [
      [
        "impute_linear"
      ],
      [
        "sits_accuracy"
      ],
      [
        "sits_accuracy_summary"
      ],
      [
        "sits_add_base_cube"
      ],
      [
        "sits_apply"
      ],
      [
        "sits_as_sf"
      ],
      [
        "sits_as_stars"
      ],
      [
        "sits_as_terra"
      ],
      [
        "sits_bands"
      ],
      [
        "sits_bands<-"
      ],
      [
        "sits_bbox"
      ],
      [
        "sits_classify"
      ],
      [
        "sits_clean"
      ],
      [
        "sits_cluster_clean"
      ],
      [
        "sits_cluster_dendro"
      ],
      [
        "sits_cluster_frequency"
      ],
      [
        "sits_colors"
      ],
      [
        "sits_colors_qgis"
      ],
      [
        "sits_colors_reset"
      ],
      [
        "sits_colors_set"
      ],
      [
        "sits_colors_show"
      ],
      [
        "sits_combine_predictions"
      ],
      [
        "sits_confidence_sampling"
      ],
      [
        "sits_config"
      ],
      [
        "sits_config_show"
      ],
      [
        "sits_config_user_file"
      ],
      [
        "sits_cube"
      ],
      [
        "sits_cube_copy"
      ],
      [
        "sits_factory_function"
      ],
      [
        "sits_filter"
      ],
      [
        "sits_formula_linear"
      ],
      [
        "sits_formula_logref"
      ],
      [
        "sits_geo_dist"
      ],
      [
        "sits_get_class"
      ],
      [
        "sits_get_data"
      ],
      [
        "sits_get_probs"
      ],
      [
        "sits_impute"
      ],
      [
        "sits_kfold_validate"
      ],
      [
        "sits_label_classification"
      ],
      [
        "sits_labels"
      ],
      [
        "sits_labels_summary"
      ],
      [
        "sits_labels<-"
      ],
      [
        "sits_lightgbm"
      ],
      [
        "sits_lighttae"
      ],
      [
        "sits_list_collections"
      ],
      [
        "sits_merge"
      ],
      [
        "sits_mgrs_to_roi"
      ],
      [
        "sits_mixture_model"
      ],
      [
        "sits_mlp"
      ],
      [
        "sits_model_export"
      ],
      [
        "sits_mosaic"
      ],
      [
        "sits_patterns"
      ],
      [
        "sits_pred_features"
      ],
      [
        "sits_pred_normalize"
      ],
      [
        "sits_pred_references"
      ],
      [
        "sits_pred_sample"
      ],
      [
        "sits_predictors"
      ],
      [
        "sits_reclassify"
      ],
      [
        "sits_reduce"
      ],
      [
        "sits_reduce_imbalance"
      ],
      [
        "sits_regularize"
      ],
      [
        "sits_resnet"
      ],
      [
        "sits_rfor"
      ],
      [
        "sits_roi_to_mgrs"
      ],
      [
        "sits_roi_to_tiles"
      ],
      [
        "sits_run_examples"
      ],
      [
        "sits_run_tests"
      ],
      [
        "sits_sample"
      ],
      [
        "sits_sampling_design"
      ],
      [
        "sits_segment"
      ],
      [
        "sits_select"
      ],
      [
        "sits_sgolay"
      ],
      [
        "sits_show_prediction"
      ],
      [
        "sits_slic"
      ],
      [
        "sits_smooth"
      ],
      [
        "sits_som_clean_samples"
      ],
      [
        "sits_som_evaluate_cluster"
      ],
      [
        "sits_som_map"
      ],
      [
        "sits_som_remove_samples"
      ],
      [
        "sits_stats"
      ],
      [
        "sits_stratified_sampling"
      ],
      [
        "sits_svm"
      ],
      [
        "sits_tae"
      ],
      [
        "sits_tempcnn"
      ],
      [
        "sits_texture"
      ],
      [
        "sits_tiles_to_roi"
      ],
      [
        "sits_timeline"
      ],
      [
        "sits_timeseries_to_csv"
      ],
      [
        "sits_to_csv"
      ],
      [
        "sits_to_xlsx"
      ],
      [
        "sits_train"
      ],
      [
        "sits_tuning"
      ],
      [
        "sits_tuning_hparams"
      ],
      [
        "sits_uncertainty"
      ],
      [
        "sits_uncertainty_sampling"
      ],
      [
        "sits_validate"
      ],
      [
        "sits_variance"
      ],
      [
        "sits_view"
      ],
      [
        "sits_whittaker"
      ],
      [
        "sits_xgboost"
      ]
    ],
    "topics": [
      [
        "big-earth-data"
      ],
      [
        "cbers"
      ],
      [
        "earth-observation"
      ],
      [
        "eo-datacubes"
      ],
      [
        "geospatial"
      ],
      [
        "image-time-series"
      ],
      [
        "land-cover-classification"
      ],
      [
        "landsat"
      ],
      [
        "planetary-computer"
      ],
      [
        "r-spatial"
      ],
      [
        "remote-sensing"
      ],
      [
        "rspatial"
      ],
      [
        "satellite-image-time-series"
      ],
      [
        "satellite-imagery"
      ],
      [
        "sentinel-2"
      ],
      [
        "stac-api"
      ],
      [
        "stac-catalog"
      ],
      [
        "openblas"
      ],
      [
        "cpp"
      ],
      [
        "openmp"
      ]
    ],
    "score": 9.1713,
    "stars": 521,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "sits Satellite Image Time Series Analysis for Earth Observation Data\nCubes An end-to-end toolkit for land use and land cover\nclassification using big Earth observation data. Builds\nsatellite image data cubes from cloud collections. Supports\nvisualization methods for images and time series and smoothing\nfilters for dealing with noisy time series. Enables merging of\nmulti-source imagery (SAR, optical, DEM). Includes functions\nfor quality assessment of training samples using self-organized\nmaps and to reduce training samples imbalance. Provides machine\nlearning algorithms including support vector machines, random\nforests, extreme gradient boosting, multi-layer perceptrons,\ntemporal convolution neural networks, and temporal attention\nencoders. Performs efficient classification of big Earth\nobservation data cubes and includes functions for\npost-classification smoothing based on Bayesian inference.\nEnables best practices for estimating area and assessing\naccuracy of land change. Includes object-based spatio-temporal\nsegmentation for space-time OBIA. Minimum recommended\nrequirements: 16 GB RAM and 4 CPU dual-core. impute_linear sits_accuracy sits_accuracy_summary sits_add_base_cube sits_apply sits_as_sf sits_as_stars sits_as_terra sits_bands sits_bands<- sits_bbox sits_classify sits_clean sits_cluster_clean sits_cluster_dendro sits_cluster_frequency sits_colors sits_colors_qgis sits_colors_reset sits_colors_set sits_colors_show sits_combine_predictions sits_confidence_sampling sits_config sits_config_show sits_config_user_file sits_cube sits_cube_copy sits_factory_function sits_filter sits_formula_linear sits_formula_logref sits_geo_dist sits_get_class sits_get_data sits_get_probs sits_impute sits_kfold_validate sits_label_classification sits_labels sits_labels_summary sits_labels<- sits_lightgbm sits_lighttae sits_list_collections sits_merge sits_mgrs_to_roi sits_mixture_model sits_mlp sits_model_export sits_mosaic sits_patterns sits_pred_features sits_pred_normalize sits_pred_references sits_pred_sample sits_predictors sits_reclassify sits_reduce sits_reduce_imbalance sits_regularize sits_resnet sits_rfor sits_roi_to_mgrs sits_roi_to_tiles sits_run_examples sits_run_tests sits_sample sits_sampling_design sits_segment sits_select sits_sgolay sits_show_prediction sits_slic sits_smooth sits_som_clean_samples sits_som_evaluate_cluster sits_som_map sits_som_remove_samples sits_stats sits_stratified_sampling sits_svm sits_tae sits_tempcnn sits_texture sits_tiles_to_roi sits_timeline sits_timeseries_to_csv sits_to_csv sits_to_xlsx sits_train sits_tuning sits_tuning_hparams sits_uncertainty sits_uncertainty_sampling sits_validate sits_variance sits_view sits_whittaker sits_xgboost big-earth-data cbers earth-observation eo-datacubes geospatial image-time-series land-cover-classification landsat planetary-computer r-spatial remote-sensing rspatial satellite-image-time-series satellite-imagery sentinel-2 stac-api stac-catalog openblas cpp openmp"
  },
  {
    "id": 531,
    "package_name": "epinowcast",
    "title": "A Bayesian Framework for Real-time Infectious Disease\nSurveillance",
    "description": "A modular Bayesian framework for real-time infectious\ndisease surveillance. Provides tools for nowcasting,\nreproduction number estimation, delay estimation, and\nforecasting from data subject to reporting delays,\nright-truncation, missing data, and incomplete ascertainment.\nUsers can build models suited to their setting using a flexible\nformula interface supporting fixed effects, random effects,\nrandom walks, and time-varying parameters, with options\nincluding parametric and non-parametric delay distributions\nwith optional modifiers (via discrete-time hazard models),\nrenewal processes, observation models, missing data imputation,\nand stratified analyses with partial pooling. By jointly\nestimating disease dynamics and reporting patterns, our\nframework enables earlier and more reliable detection of\ntrends. While designed with epidemiological applications in\nmind, the framework can be applied to any right-truncated time\nseries count data.",
    "version": "0.4.0",
    "maintainer": "Sam Abbott <contact@samabbott.co.uk>",
    "author": "Sam Abbott [aut, cre] (ORCID: <https://orcid.org/0000-0001-8057-8037>),\nAdrian Lison [aut] (ORCID: <https://orcid.org/0000-0002-6822-8437>),\nSebastian Funk [aut],\nCarl Pearson [aut] (ORCID: <https://orcid.org/0000-0003-0701-7860>),\nHugo Gruson [aut] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nFelix Guenther [aut] (ORCID: <https://orcid.org/0000-0001-6582-1174>),\nMichael DeWitt [aut] (ORCID: <https://orcid.org/0000-0001-8940-1967>),\nJames Mba Azam [aut] (ORCID: <https://orcid.org/0000-0001-5782-7330>),\nJessalyn Sebastian [aut] (ORCID:\n<https://orcid.org/0000-0002-1768-3229>),\nHannah Choi [ctb],\nPratik Gupte [ctb] (ORCID: <https://orcid.org/0000-0001-5294-7819>),\nJoel Hellewell [ctb] (ORCID: <https://orcid.org/0000-0003-2683-0849>),\nLuis Rivas [ctb],\nSang Woo Park [ctb] (ORCID: <https://orcid.org/0000-0003-2202-3361>),\nNathan McIntosh [ctb],\nKath Sherratt [ctb] (ORCID: <https://orcid.org/0000-0003-2049-3423>),\nNikos Bosse [ctb] (ORCID: <https://orcid.org/0000-0002-7750-5280>),\nAdam Howes [ctb] (ORCID: <https://orcid.org/0000-0003-2386-4031>),\nKaitlyn Johnson [ctb] (ORCID: <https://orcid.org/0000-0001-8011-0012>),\nBarbora Nemcova [ctb] (ORCID: <https://orcid.org/0009-0004-7565-4145>)",
    "url": "https://package.epinowcast.org,\nhttps://github.com/epinowcast/epinowcast/",
    "bug_reports": "https://github.com/epinowcast/epinowcast/issues/",
    "repository": "",
    "exports": [
      [
        "add_pmfs"
      ],
      [
        "as_forecast_sample"
      ],
      [
        "check_max_delay"
      ],
      [
        "coerce_date"
      ],
      [
        "convolution_matrix"
      ],
      [
        "enw_add_cumulative"
      ],
      [
        "enw_add_cumulative_membership"
      ],
      [
        "enw_add_delay"
      ],
      [
        "enw_add_incidence"
      ],
      [
        "enw_add_latest_obs_to_nowcast"
      ],
      [
        "enw_add_max_reported"
      ],
      [
        "enw_add_metaobs_features"
      ],
      [
        "enw_add_pooling_effect"
      ],
      [
        "enw_aggregate_cumulative"
      ],
      [
        "enw_assign_group"
      ],
      [
        "enw_complete_dates"
      ],
      [
        "enw_construct_data"
      ],
      [
        "enw_design"
      ],
      [
        "enw_effects_metadata"
      ],
      [
        "enw_example"
      ],
      [
        "enw_expectation"
      ],
      [
        "enw_extend_date"
      ],
      [
        "enw_filter_delay"
      ],
      [
        "enw_filter_reference_dates"
      ],
      [
        "enw_filter_report_dates"
      ],
      [
        "enw_fit_opts"
      ],
      [
        "enw_flag_observed_observations"
      ],
      [
        "enw_formula"
      ],
      [
        "enw_formula_as_data_list"
      ],
      [
        "enw_get_cache"
      ],
      [
        "enw_impute_na_observations"
      ],
      [
        "enw_incidence_to_linelist"
      ],
      [
        "enw_latest_data"
      ],
      [
        "enw_linelist_to_incidence"
      ],
      [
        "enw_manual_formula"
      ],
      [
        "enw_metadata"
      ],
      [
        "enw_metadata_delay"
      ],
      [
        "enw_missing"
      ],
      [
        "enw_missing_reference"
      ],
      [
        "enw_model"
      ],
      [
        "enw_nowcast_samples"
      ],
      [
        "enw_nowcast_summary"
      ],
      [
        "enw_obs"
      ],
      [
        "enw_one_hot_encode_feature"
      ],
      [
        "enw_pathfinder"
      ],
      [
        "enw_plot_nowcast_quantiles"
      ],
      [
        "enw_plot_obs"
      ],
      [
        "enw_plot_pp_quantiles"
      ],
      [
        "enw_plot_quantiles"
      ],
      [
        "enw_plot_theme"
      ],
      [
        "enw_posterior"
      ],
      [
        "enw_pp_summary"
      ],
      [
        "enw_preprocess_data"
      ],
      [
        "enw_priors_as_data_list"
      ],
      [
        "enw_quantiles_to_long"
      ],
      [
        "enw_reference"
      ],
      [
        "enw_replace_priors"
      ],
      [
        "enw_report"
      ],
      [
        "enw_reporting_triangle"
      ],
      [
        "enw_reporting_triangle_to_long"
      ],
      [
        "enw_sample"
      ],
      [
        "enw_set_cache"
      ],
      [
        "enw_simulate_missing_reference"
      ],
      [
        "enw_stan_to_r"
      ],
      [
        "enw_summarise_samples"
      ],
      [
        "enw_unset_cache"
      ],
      [
        "epinowcast"
      ],
      [
        "extract_sparse_matrix"
      ],
      [
        "re"
      ],
      [
        "rw"
      ]
    ],
    "topics": [
      [
        "cmdstanr"
      ],
      [
        "effective-reproduction-number-estimation"
      ],
      [
        "epidemiology"
      ],
      [
        "infectious-disease-surveillance"
      ],
      [
        "nowcasting"
      ],
      [
        "outbreak-analysis"
      ],
      [
        "pandemic-preparedness"
      ],
      [
        "real-time-infectious-disease-modelling"
      ],
      [
        "stan"
      ]
    ],
    "score": 8.4145,
    "stars": 62,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "epinowcast A Bayesian Framework for Real-time Infectious Disease\nSurveillance A modular Bayesian framework for real-time infectious\ndisease surveillance. Provides tools for nowcasting,\nreproduction number estimation, delay estimation, and\nforecasting from data subject to reporting delays,\nright-truncation, missing data, and incomplete ascertainment.\nUsers can build models suited to their setting using a flexible\nformula interface supporting fixed effects, random effects,\nrandom walks, and time-varying parameters, with options\nincluding parametric and non-parametric delay distributions\nwith optional modifiers (via discrete-time hazard models),\nrenewal processes, observation models, missing data imputation,\nand stratified analyses with partial pooling. By jointly\nestimating disease dynamics and reporting patterns, our\nframework enables earlier and more reliable detection of\ntrends. While designed with epidemiological applications in\nmind, the framework can be applied to any right-truncated time\nseries count data. add_pmfs as_forecast_sample check_max_delay coerce_date convolution_matrix enw_add_cumulative enw_add_cumulative_membership enw_add_delay enw_add_incidence enw_add_latest_obs_to_nowcast enw_add_max_reported enw_add_metaobs_features enw_add_pooling_effect enw_aggregate_cumulative enw_assign_group enw_complete_dates enw_construct_data enw_design enw_effects_metadata enw_example enw_expectation enw_extend_date enw_filter_delay enw_filter_reference_dates enw_filter_report_dates enw_fit_opts enw_flag_observed_observations enw_formula enw_formula_as_data_list enw_get_cache enw_impute_na_observations enw_incidence_to_linelist enw_latest_data enw_linelist_to_incidence enw_manual_formula enw_metadata enw_metadata_delay enw_missing enw_missing_reference enw_model enw_nowcast_samples enw_nowcast_summary enw_obs enw_one_hot_encode_feature enw_pathfinder enw_plot_nowcast_quantiles enw_plot_obs enw_plot_pp_quantiles enw_plot_quantiles enw_plot_theme enw_posterior enw_pp_summary enw_preprocess_data enw_priors_as_data_list enw_quantiles_to_long enw_reference enw_replace_priors enw_report enw_reporting_triangle enw_reporting_triangle_to_long enw_sample enw_set_cache enw_simulate_missing_reference enw_stan_to_r enw_summarise_samples enw_unset_cache epinowcast extract_sparse_matrix re rw cmdstanr effective-reproduction-number-estimation epidemiology infectious-disease-surveillance nowcasting outbreak-analysis pandemic-preparedness real-time-infectious-disease-modelling stan"
  },
  {
    "id": 837,
    "package_name": "modeltime.resample",
    "title": "Resampling Tools for Time Series Forecasting",
    "description": "A 'modeltime' extension that implements forecast\nresampling tools that assess time-based model performance and\nstability for a single time series, panel data, and\ncross-sectional time series analysis.",
    "version": "0.3.0.9000",
    "maintainer": "Matt Dancho <mdancho@business-science.io>",
    "author": "Matt Dancho [aut, cre],\nBusiness Science [cph]",
    "url": "https://business-science.github.io/modeltime.resample/,\nhttps://github.com/business-science/modeltime.resample",
    "bug_reports": "https://github.com/business-science/modeltime.resample/issues",
    "repository": "",
    "exports": [
      [
        ":="
      ],
      [
        ".data"
      ],
      [
        "%>%"
      ],
      [
        "as_label"
      ],
      [
        "as_name"
      ],
      [
        "enquo"
      ],
      [
        "enquos"
      ],
      [
        "expr"
      ],
      [
        "get_target_text_from_resamples"
      ],
      [
        "mdl_time_fit_resamples"
      ],
      [
        "modeltime_fit_resamples"
      ],
      [
        "modeltime_resample_accuracy"
      ],
      [
        "plot_modeltime_resamples"
      ],
      [
        "plot_time_series_cv_plan"
      ],
      [
        "sym"
      ],
      [
        "syms"
      ],
      [
        "time_series_cv"
      ],
      [
        "time_series_split"
      ],
      [
        "tk_time_series_cv_plan"
      ],
      [
        "unnest_modeltime_resamples"
      ]
    ],
    "topics": [
      [
        "accuracy-metrics"
      ],
      [
        "backtesting"
      ],
      [
        "bootstrap"
      ],
      [
        "bootstrapping"
      ],
      [
        "cross-validation"
      ],
      [
        "forecasting"
      ],
      [
        "modeltime"
      ],
      [
        "modeltime-resample"
      ],
      [
        "resampling"
      ],
      [
        "statistics"
      ],
      [
        "tidymodels"
      ],
      [
        "time-series"
      ]
    ],
    "score": 7.9769,
    "stars": 21,
    "primary_category": "tidyverse",
    "source_universe": "business-science",
    "search_text": "modeltime.resample Resampling Tools for Time Series Forecasting A 'modeltime' extension that implements forecast\nresampling tools that assess time-based model performance and\nstability for a single time series, panel data, and\ncross-sectional time series analysis. := .data %>% as_label as_name enquo enquos expr get_target_text_from_resamples mdl_time_fit_resamples modeltime_fit_resamples modeltime_resample_accuracy plot_modeltime_resamples plot_time_series_cv_plan sym syms time_series_cv time_series_split tk_time_series_cv_plan unnest_modeltime_resamples accuracy-metrics backtesting bootstrap bootstrapping cross-validation forecasting modeltime modeltime-resample resampling statistics tidymodels time-series"
  },
  {
    "id": 1431,
    "package_name": "weatherOz",
    "title": "An API Client for Australian Weather and Climate Data Resources",
    "description": "Provides automated downloading, parsing and formatting of\nweather data for Australia through API endpoints provided by\nthe Department of Primary Industries and Regional Development\n(DPIRD) of Western Australia and by the Science and Technology\nDivision of the Queensland Government's Department of\nEnvironment and Science (DES). As well as the Bureau of\nMeteorology (BOM) of the Australian government precis and\ncoastal forecasts, and downloading and importing radar and\nsatellite imagery files. DPIRD weather data are accessed\nthrough public APIs provided by DPIRD,\n<https://www.dpird.wa.gov.au/online-tools/apis/>, providing\naccess to weather station data from the DPIRD weather station\nnetwork.  Australia-wide weather data are based on data from\nthe Australian Bureau of Meteorology (BOM) data and accessed\nthrough SILO (Scientific Information for Land Owners) Jeffrey\net al. (2001) <doi:10.1016/S1364-8152(01)00008-1>.  DPIRD data\nare made available under a Creative Commons Attribution 3.0\nLicence (CC BY 3.0 AU) license\n<https://creativecommons.org/licenses/by/3.0/au/deed.en>. SILO\ndata are released under a Creative Commons Attribution 4.0\nInternational licence (CC BY 4.0)\n<https://creativecommons.org/licenses/by/4.0/>. BOM data are\n(c) Australian Government Bureau of Meteorology and released\nunder a Creative Commons (CC) Attribution 3.0 licence or Public\nAccess Licence (PAL) as appropriate, see\n<http://www.bom.gov.au/other/copyright.shtml> for further\ndetails.",
    "version": "2.0.2",
    "maintainer": "Rodrigo Pires <rodrigo.pires@dpird.wa.gov.au>",
    "author": "Rodrigo Pires [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-7384-6849>),\nAnna Hepworth [aut] (ORCID: <https://orcid.org/0000-0003-0204-6347>),\nRebecca O'Leary [aut],\nJonathan Carroll [aut] (ORCID: <https://orcid.org/0000-0002-1404-5264>),\nJames Goldie [aut] (ORCID: <https://orcid.org/0000-0002-5024-6207>),\nDean Marchiori [aut] (ORCID: <https://orcid.org/0000-0002-3430-7225>),\nPaul Melloy [aut] (ORCID: <https://orcid.org/0000-0003-4253-7167>),\nMark Padgham [aut] (ORCID: <https://orcid.org/0000-0003-2172-5265>),\nHugh Parsonage [aut] (ORCID: <https://orcid.org/0000-0003-4055-0835>),\nKeith Pembleton [ctb] (ORCID: <https://orcid.org/0000-0002-1896-4516>,\nContributed code and ideas for original bomrang package that was\nused in the creation of weatherOz.),\nMa\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>,\nContributed to debugging a nasty little bug with CI where timezones\ncaused tests to fail due to vcr not recognising the URL when run\noutside of Australia-Perth TZ! Suggested the use of\nlocal_timzeone().),\nMax Moldovan [ctb] (ORCID: <https://orcid.org/0000-0001-9680-8474>,\nContributed valuable feedback on package usage leading to\nimprovements in the package structure and functionality.),\nJimmy Ng [ctb],\nSteve Collins [ctb] (Designed the hex logo for 'weatherOz' hex logo.),\nAdam H. Sparks [aut] (ORCID: <https://orcid.org/0000-0002-0061-8359>),\nLaurens Geffert [rev],\nSam Rogers [rev],\nWestern Australia Agriculture Authority (WAAA) [cph],\nCurtin University [cph]",
    "url": "https://github.com/ropensci/weatherOz/,\nhttps://docs.ropensci.org/weatherOz/",
    "bug_reports": "https://github.com/ropensci/weatherOz/issues",
    "repository": "",
    "exports": [
      [
        "find_forecast_towns"
      ],
      [
        "find_nearby_stations"
      ],
      [
        "find_stations_in"
      ],
      [
        "get_available_imagery"
      ],
      [
        "get_available_radar"
      ],
      [
        "get_coastal_forecast"
      ],
      [
        "get_data_drill"
      ],
      [
        "get_data_drill_apsim"
      ],
      [
        "get_dpird_apsim"
      ],
      [
        "get_dpird_availability"
      ],
      [
        "get_dpird_extremes"
      ],
      [
        "get_dpird_minute"
      ],
      [
        "get_dpird_summaries"
      ],
      [
        "get_key"
      ],
      [
        "get_patched_point"
      ],
      [
        "get_patched_point_apsim"
      ],
      [
        "get_precis_forecast"
      ],
      [
        "get_radar_imagery"
      ],
      [
        "get_satellite_imagery"
      ],
      [
        "get_stations_metadata"
      ],
      [
        "parse_ag_bulletin"
      ],
      [
        "parse_coastal_forecast"
      ],
      [
        "parse_precis_forecast"
      ],
      [
        "plot"
      ],
      [
        "write_apsim_met"
      ]
    ],
    "topics": [
      [
        "dpird"
      ],
      [
        "bom"
      ],
      [
        "meteorological-data"
      ],
      [
        "weather-forecast"
      ],
      [
        "australia"
      ],
      [
        "weather"
      ],
      [
        "weather-data"
      ],
      [
        "meteorology"
      ],
      [
        "western-australia"
      ],
      [
        "australia-bureau-of-meteorology"
      ],
      [
        "western-australia-agriculture"
      ],
      [
        "australia-agriculture"
      ],
      [
        "australia-climate"
      ],
      [
        "australia-weather"
      ],
      [
        "api-client"
      ],
      [
        "climate"
      ],
      [
        "data"
      ],
      [
        "rainfall"
      ],
      [
        "weather-api"
      ]
    ],
    "score": 7.9754,
    "stars": 35,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "weatherOz An API Client for Australian Weather and Climate Data Resources Provides automated downloading, parsing and formatting of\nweather data for Australia through API endpoints provided by\nthe Department of Primary Industries and Regional Development\n(DPIRD) of Western Australia and by the Science and Technology\nDivision of the Queensland Government's Department of\nEnvironment and Science (DES). As well as the Bureau of\nMeteorology (BOM) of the Australian government precis and\ncoastal forecasts, and downloading and importing radar and\nsatellite imagery files. DPIRD weather data are accessed\nthrough public APIs provided by DPIRD,\n<https://www.dpird.wa.gov.au/online-tools/apis/>, providing\naccess to weather station data from the DPIRD weather station\nnetwork.  Australia-wide weather data are based on data from\nthe Australian Bureau of Meteorology (BOM) data and accessed\nthrough SILO (Scientific Information for Land Owners) Jeffrey\net al. (2001) <doi:10.1016/S1364-8152(01)00008-1>.  DPIRD data\nare made available under a Creative Commons Attribution 3.0\nLicence (CC BY 3.0 AU) license\n<https://creativecommons.org/licenses/by/3.0/au/deed.en>. SILO\ndata are released under a Creative Commons Attribution 4.0\nInternational licence (CC BY 4.0)\n<https://creativecommons.org/licenses/by/4.0/>. BOM data are\n(c) Australian Government Bureau of Meteorology and released\nunder a Creative Commons (CC) Attribution 3.0 licence or Public\nAccess Licence (PAL) as appropriate, see\n<http://www.bom.gov.au/other/copyright.shtml> for further\ndetails. find_forecast_towns find_nearby_stations find_stations_in get_available_imagery get_available_radar get_coastal_forecast get_data_drill get_data_drill_apsim get_dpird_apsim get_dpird_availability get_dpird_extremes get_dpird_minute get_dpird_summaries get_key get_patched_point get_patched_point_apsim get_precis_forecast get_radar_imagery get_satellite_imagery get_stations_metadata parse_ag_bulletin parse_coastal_forecast parse_precis_forecast plot write_apsim_met dpird bom meteorological-data weather-forecast australia weather weather-data meteorology western-australia australia-bureau-of-meteorology western-australia-agriculture australia-agriculture australia-climate australia-weather api-client climate data rainfall weather-api"
  },
  {
    "id": 86,
    "package_name": "MODIStsp",
    "title": "Find, Download and Process MODIS Land Products Data",
    "description": "Allows automating the creation of time series of rasters\nderived from MODIS satellite land products data. It performs\nseveral typical preprocessing steps such as download,\nmosaicking, reprojecting and resizing data acquired on a\nspecified time period. All processing parameters can be set\nusing a user-friendly GUI. Users can select which layers of the\noriginal MODIS HDF files they want to process, which additional\nquality indicators should be extracted from aggregated MODIS\nquality assurance layers and, in the case of surface\nreflectance products, which spectral indexes should be computed\nfrom the original reflectance bands. For each output layer,\noutputs are saved as single-band raster files corresponding to\neach available acquisition date. Virtual files allowing access\nto the entire time series as a single file are also created.\nCommand-line execution exploiting a previously saved processing\noptions file is also possible, allowing users to automatically\nupdate time series related to a MODIS product whenever a new\nimage is available. For additional documentation refer to the\nfollowing article: Busetto and Ranghetti (2016)\n<doi:10.1016/j.cageo.2016.08.020>.",
    "version": "2.1.0.9001",
    "maintainer": "Luigi Ranghetti <rpackages.ranghetti@gmail.com>",
    "author": "Lorenzo Busetto [aut] (ORCID: <https://orcid.org/0000-0001-9634-6038>),\nLuigi Ranghetti [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-6207-5188>),\nLeah Wasser [rev] (Leah Wasser reviewed the package for rOpenSci, see\nhttps://github.com/ropensci/software-review/issues/184),\nJeff Hanson [rev] (Jeff Hanson reviewed the package for rOpenSci, see\nhttps://github.com/ropensci/software-review/issues/184),\nBabak Naimi [ctb] (Babak Naimi wrote the function ModisDownload(), on\nwhich some MODIStsp internal functions are based)",
    "url": "https://github.com/ropensci/MODIStsp/,\nhttps://docs.ropensci.org/MODIStsp/",
    "bug_reports": "https://github.com/ropensci/MODIStsp/issues",
    "repository": "",
    "exports": [
      [
        "check_projection"
      ],
      [
        "install_MODIStsp_launcher"
      ],
      [
        "MODIStsp"
      ],
      [
        "MODIStsp_addindex"
      ],
      [
        "MODIStsp_extract"
      ],
      [
        "MODIStsp_get_prodlayers"
      ],
      [
        "MODIStsp_get_prodnames"
      ],
      [
        "MODIStsp_process"
      ],
      [
        "MODIStsp_resetindexes"
      ]
    ],
    "topics": [
      [
        "gdal"
      ],
      [
        "modis"
      ],
      [
        "modis-data"
      ],
      [
        "modis-land-products"
      ],
      [
        "peer-reviewed"
      ],
      [
        "preprocessing"
      ],
      [
        "remote-sensing"
      ],
      [
        "satellite-imagery"
      ],
      [
        "time-series"
      ]
    ],
    "score": 7.9501,
    "stars": 159,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "MODIStsp Find, Download and Process MODIS Land Products Data Allows automating the creation of time series of rasters\nderived from MODIS satellite land products data. It performs\nseveral typical preprocessing steps such as download,\nmosaicking, reprojecting and resizing data acquired on a\nspecified time period. All processing parameters can be set\nusing a user-friendly GUI. Users can select which layers of the\noriginal MODIS HDF files they want to process, which additional\nquality indicators should be extracted from aggregated MODIS\nquality assurance layers and, in the case of surface\nreflectance products, which spectral indexes should be computed\nfrom the original reflectance bands. For each output layer,\noutputs are saved as single-band raster files corresponding to\neach available acquisition date. Virtual files allowing access\nto the entire time series as a single file are also created.\nCommand-line execution exploiting a previously saved processing\noptions file is also possible, allowing users to automatically\nupdate time series related to a MODIS product whenever a new\nimage is available. For additional documentation refer to the\nfollowing article: Busetto and Ranghetti (2016)\n<doi:10.1016/j.cageo.2016.08.020>. check_projection install_MODIStsp_launcher MODIStsp MODIStsp_addindex MODIStsp_extract MODIStsp_get_prodlayers MODIStsp_get_prodnames MODIStsp_process MODIStsp_resetindexes gdal modis modis-data modis-land-products peer-reviewed preprocessing remote-sensing satellite-imagery time-series"
  },
  {
    "id": 505,
    "package_name": "dynamite",
    "title": "Bayesian Modeling and Causal Inference for Multivariate\nLongitudinal Data",
    "description": "Easy-to-use and efficient interface for Bayesian inference\nof complex panel (time series) data using dynamic multivariate\npanel models by Helske and Tikka (2024)\n<doi:10.1016/j.alcr.2024.100617>. The package supports joint\nmodeling of multiple measurements per individual, time-varying\nand time-invariant effects, and a wide range of discrete and\ncontinuous distributions. Estimation of these dynamic\nmultivariate panel models is carried out via 'Stan'. For an\nin-depth tutorial of the package, see (Tikka and Helske, 2024)\n<doi:10.48550/arXiv.2302.01607>.",
    "version": "1.6.2",
    "maintainer": "Santtu Tikka <santtuth@gmail.com>",
    "author": "Santtu Tikka [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-4039-4342>),\nJouni Helske [aut] (ORCID: <https://orcid.org/0000-0001-7130-793X>),\nNicholas Clark [rev],\nLucy D'Agostino McGowan [rev]",
    "url": "https://docs.ropensci.org/dynamite/,\nhttps://github.com/ropensci/dynamite/",
    "bug_reports": "https://github.com/ropensci/dynamite/issues/",
    "repository": "",
    "exports": [
      [
        "as_draws"
      ],
      [
        "as_draws_df"
      ],
      [
        "as.data.table"
      ],
      [
        "aux"
      ],
      [
        "dynamice"
      ],
      [
        "dynamite"
      ],
      [
        "dynamiteformula"
      ],
      [
        "get_algorithm"
      ],
      [
        "get_code"
      ],
      [
        "get_data"
      ],
      [
        "get_diagnostics"
      ],
      [
        "get_draws"
      ],
      [
        "get_elapsed_time"
      ],
      [
        "get_max_treedepth"
      ],
      [
        "get_model_code"
      ],
      [
        "get_nchains"
      ],
      [
        "get_ndraws"
      ],
      [
        "get_parameter_dims"
      ],
      [
        "get_parameter_names"
      ],
      [
        "get_parameter_types"
      ],
      [
        "get_pars_oi"
      ],
      [
        "get_priors"
      ],
      [
        "hmc_diagnostics"
      ],
      [
        "lags"
      ],
      [
        "lfactor"
      ],
      [
        "lfo"
      ],
      [
        "loo"
      ],
      [
        "mcmc_diagnostics"
      ],
      [
        "mice.impute.lag"
      ],
      [
        "mice.impute.lead"
      ],
      [
        "ndraws"
      ],
      [
        "obs"
      ],
      [
        "plot_betas"
      ],
      [
        "plot_deltas"
      ],
      [
        "plot_lambdas"
      ],
      [
        "plot_nus"
      ],
      [
        "plot_psis"
      ],
      [
        "random_spec"
      ],
      [
        "splines"
      ]
    ],
    "topics": [
      [
        "bayesian-inference"
      ],
      [
        "panel-data"
      ],
      [
        "stan"
      ],
      [
        "statistical-models"
      ],
      [
        "quarto"
      ]
    ],
    "score": 7.8126,
    "stars": 35,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "dynamite Bayesian Modeling and Causal Inference for Multivariate\nLongitudinal Data Easy-to-use and efficient interface for Bayesian inference\nof complex panel (time series) data using dynamic multivariate\npanel models by Helske and Tikka (2024)\n<doi:10.1016/j.alcr.2024.100617>. The package supports joint\nmodeling of multiple measurements per individual, time-varying\nand time-invariant effects, and a wide range of discrete and\ncontinuous distributions. Estimation of these dynamic\nmultivariate panel models is carried out via 'Stan'. For an\nin-depth tutorial of the package, see (Tikka and Helske, 2024)\n<doi:10.48550/arXiv.2302.01607>. as_draws as_draws_df as.data.table aux dynamice dynamite dynamiteformula get_algorithm get_code get_data get_diagnostics get_draws get_elapsed_time get_max_treedepth get_model_code get_nchains get_ndraws get_parameter_dims get_parameter_names get_parameter_types get_pars_oi get_priors hmc_diagnostics lags lfactor lfo loo mcmc_diagnostics mice.impute.lag mice.impute.lead ndraws obs plot_betas plot_deltas plot_lambdas plot_nus plot_psis random_spec splines bayesian-inference panel-data stan statistical-models quarto"
  },
  {
    "id": 1149,
    "package_name": "rsat",
    "title": "Dealing with Multiplatform Satellite Images",
    "description": "Downloading, customizing, and processing time series of\nsatellite images for a region of interest. 'rsat' functions\nallow a unified access to multispectral images from Landsat,\nMODIS and Sentinel repositories. 'rsat' also offers\ncapabilities for customizing satellite images, such as tile\nmosaicking, image cropping and new variables computation.\nFinally, 'rsat' covers the processing, including cloud masking,\ncompositing and gap-filling/smoothing time series of images\n(Militino et al., 2018 <doi:10.3390/rs10030398> and Militino et\nal., 2019 <doi:10.1109/TGRS.2019.2904193>).",
    "version": "0.1.21",
    "maintainer": "Unai P\u00e9rez - Goya <unai.perez@unavarra.es>",
    "author": "Unai P\u00e9rez - Goya [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-2796-9079>),\nManuel Montesino - SanMartin [aut] (ORCID:\n<https://orcid.org/0000-0002-0822-600X>),\nAna F Militino [aut] (ORCID: <https://orcid.org/0000-0002-0631-3919>),\nMaria Dolores Ugarte [aut] (ORCID:\n<https://orcid.org/0000-0002-3505-8400>),\nMarc Weber [rev] (Marc reviewed rsat (v. 0.1.14) for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/437>),\nKelly Hondula [rev] (Kelly reviewed rsat (v. 0.1.14) for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/437>)",
    "url": "https://docs.ropensci.org/rsat/, https://github.com/ropensci/rsat",
    "bug_reports": "https://github.com/ropensci/rsat/issues",
    "repository": "",
    "exports": [
      [
        "as.data.frame"
      ],
      [
        "as.records"
      ],
      [
        "dates"
      ],
      [
        "dates<-"
      ],
      [
        "get_api_name"
      ],
      [
        "get_database"
      ],
      [
        "get_dir"
      ],
      [
        "get_download"
      ],
      [
        "get_order"
      ],
      [
        "get_order<-"
      ],
      [
        "get_preview"
      ],
      [
        "new_record"
      ],
      [
        "new_rtoi"
      ],
      [
        "plot"
      ],
      [
        "print"
      ],
      [
        "print_credentials"
      ],
      [
        "product"
      ],
      [
        "read_rtoi"
      ],
      [
        "records"
      ],
      [
        "records<-"
      ],
      [
        "region"
      ],
      [
        "region<-"
      ],
      [
        "rename"
      ],
      [
        "rsat_cloudMask"
      ],
      [
        "rsat_derive"
      ],
      [
        "rsat_download"
      ],
      [
        "rsat_get_raster"
      ],
      [
        "rsat_get_SpatRaster"
      ],
      [
        "rsat_get_stars"
      ],
      [
        "rsat_list_data"
      ],
      [
        "rsat_mosaic"
      ],
      [
        "rsat_preview"
      ],
      [
        "rsat_products"
      ],
      [
        "rsat_search"
      ],
      [
        "rsat_smoothing_images"
      ],
      [
        "sat_name"
      ],
      [
        "set_credentials"
      ],
      [
        "set_database"
      ],
      [
        "show"
      ],
      [
        "show_variables"
      ],
      [
        "subset"
      ],
      [
        "test_function"
      ],
      [
        "unique"
      ]
    ],
    "topics": [
      [
        "satellite-images"
      ]
    ],
    "score": 7.5837,
    "stars": 54,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rsat Dealing with Multiplatform Satellite Images Downloading, customizing, and processing time series of\nsatellite images for a region of interest. 'rsat' functions\nallow a unified access to multispectral images from Landsat,\nMODIS and Sentinel repositories. 'rsat' also offers\ncapabilities for customizing satellite images, such as tile\nmosaicking, image cropping and new variables computation.\nFinally, 'rsat' covers the processing, including cloud masking,\ncompositing and gap-filling/smoothing time series of images\n(Militino et al., 2018 <doi:10.3390/rs10030398> and Militino et\nal., 2019 <doi:10.1109/TGRS.2019.2904193>). as.data.frame as.records dates dates<- get_api_name get_database get_dir get_download get_order get_order<- get_preview new_record new_rtoi plot print print_credentials product read_rtoi records records<- region region<- rename rsat_cloudMask rsat_derive rsat_download rsat_get_raster rsat_get_SpatRaster rsat_get_stars rsat_list_data rsat_mosaic rsat_preview rsat_products rsat_search rsat_smoothing_images sat_name set_credentials set_database show show_variables subset test_function unique satellite-images"
  },
  {
    "id": 528,
    "package_name": "epidemics",
    "title": "Composable Epidemic Scenario Modelling",
    "description": "A library of compartmental epidemic models taken from the\npublished literature, and classes to represent affected\npopulations, public health response measures including\nnon-pharmaceutical interventions on social contacts,\nnon-pharmaceutical and pharmaceutical interventions that affect\ndisease transmissibility, vaccination regimes, and disease\nseasonality, which can be combined to compose epidemic scenario\nmodels.",
    "version": "0.4.0.9000",
    "maintainer": "Rosalind Eggo <rosalind.eggo@lshtm.ac.uk>",
    "author": "Pratik Gupte [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-5294-7819>),\nRosalind Eggo [aut, cph, cre] (ORCID:\n<https://orcid.org/0000-0002-0362-6717>),\nEdwin Van Leeuwen [aut, cph] (ORCID:\n<https://orcid.org/0000-0002-2383-5305>),\nAdam Kucharski [ctb, rev] (ORCID:\n<https://orcid.org/0000-0001-8814-9421>),\nTim Taylor [ctb, rev] (ORCID: <https://orcid.org/0000-0002-8587-7113>),\nBanky Ahadzie [ctb],\nAlexis Robert [ctb] (ORCID: <https://orcid.org/0000-0002-4516-2965>),\nHugo Gruson [rev] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nJoshua W. Lambert [rev] (ORCID:\n<https://orcid.org/0000-0001-5218-3046>),\nJames M. Azam [rev] (ORCID: <https://orcid.org/0000-0001-5782-7330>),\nAlexis Robert [rev] (ORCID: <https://orcid.org/0000-0002-4516-2965>)",
    "url": "https://github.com/epiverse-trace/epidemics,\nhttps://epiverse-trace.github.io/epidemics/",
    "bug_reports": "https://github.com/epiverse-trace/epidemics/issues",
    "repository": "",
    "exports": [
      [
        "as.intervention"
      ],
      [
        "as.vaccination"
      ],
      [
        "combine_populations"
      ],
      [
        "epidemic_peak"
      ],
      [
        "epidemic_size"
      ],
      [
        "gravity_contact"
      ],
      [
        "intervention"
      ],
      [
        "is_contacts_intervention"
      ],
      [
        "is_intervention"
      ],
      [
        "is_population"
      ],
      [
        "is_rate_intervention"
      ],
      [
        "is_vaccination"
      ],
      [
        "model_default"
      ],
      [
        "model_diphtheria"
      ],
      [
        "model_ebola"
      ],
      [
        "model_vacamole"
      ],
      [
        "new_infections"
      ],
      [
        "outcomes_averted"
      ],
      [
        "population"
      ],
      [
        "vaccination"
      ]
    ],
    "topics": [
      [
        "decision-support"
      ],
      [
        "epidemic-modelling"
      ],
      [
        "epidemic-simulations"
      ],
      [
        "epidemiology"
      ],
      [
        "epiverse"
      ],
      [
        "infectious-disease-dynamics"
      ],
      [
        "model-library"
      ],
      [
        "non-pharmaceutical-interventions"
      ],
      [
        "rcpp"
      ],
      [
        "rcppeigen"
      ],
      [
        "scenario-analysis"
      ],
      [
        "vaccination"
      ]
    ],
    "score": 7.4776,
    "stars": 13,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "epidemics Composable Epidemic Scenario Modelling A library of compartmental epidemic models taken from the\npublished literature, and classes to represent affected\npopulations, public health response measures including\nnon-pharmaceutical interventions on social contacts,\nnon-pharmaceutical and pharmaceutical interventions that affect\ndisease transmissibility, vaccination regimes, and disease\nseasonality, which can be combined to compose epidemic scenario\nmodels. as.intervention as.vaccination combine_populations epidemic_peak epidemic_size gravity_contact intervention is_contacts_intervention is_intervention is_population is_rate_intervention is_vaccination model_default model_diphtheria model_ebola model_vacamole new_infections outcomes_averted population vaccination decision-support epidemic-modelling epidemic-simulations epidemiology epiverse infectious-disease-dynamics model-library non-pharmaceutical-interventions rcpp rcppeigen scenario-analysis vaccination"
  },
  {
    "id": 553,
    "package_name": "fExtremes",
    "title": "Rmetrics - Modelling Extreme Events in Finance",
    "description": "Provides functions for analysing and modelling extreme\nevents in financial time Series. The topics include: (i) data\npre-processing, (ii) explorative data analysis, (iii) peak over\nthreshold modelling, (iv) block maxima modelling, (v)\nestimation of VaR and CVaR, and (vi) the computation of the\nextreme index.",
    "version": "4032.84",
    "maintainer": "Paul J. Northrop <p.northrop@ucl.ac.uk>",
    "author": "Diethelm Wuertz [aut],\nTobias Setz [aut],\nYohan Chalabi [aut],\nPaul J. Northrop [cre, ctb]",
    "url": "https://www.rmetrics.org",
    "bug_reports": "https://r-forge.r-project.org/projects/rmetrics",
    "repository": "",
    "exports": [
      [
        ".gevmleFit"
      ],
      [
        ".gevpwmFit"
      ],
      [
        ".gevrlevelLLH"
      ],
      [
        ".gummleFit"
      ],
      [
        ".gumpwmFit"
      ],
      [
        "blockMaxima"
      ],
      [
        "blockTheta"
      ],
      [
        "clusterTheta"
      ],
      [
        "CVaR"
      ],
      [
        "deCluster"
      ],
      [
        "dgev"
      ],
      [
        "dgpd"
      ],
      [
        "emdPlot"
      ],
      [
        "exindexesPlot"
      ],
      [
        "exindexPlot"
      ],
      [
        "ferrosegersTheta"
      ],
      [
        "findThreshold"
      ],
      [
        "gevFit"
      ],
      [
        "gevMoments"
      ],
      [
        "gevrlevelPlot"
      ],
      [
        "gevSim"
      ],
      [
        "gevSlider"
      ],
      [
        "ghMeanExcessFit"
      ],
      [
        "ghtMeanExcessFit"
      ],
      [
        "gpdFit"
      ],
      [
        "gpdMoments"
      ],
      [
        "gpdQPlot"
      ],
      [
        "gpdQuantPlot"
      ],
      [
        "gpdRiskMeasures"
      ],
      [
        "gpdSfallPlot"
      ],
      [
        "gpdShapePlot"
      ],
      [
        "gpdSim"
      ],
      [
        "gpdSlider"
      ],
      [
        "gpdTailPlot"
      ],
      [
        "gumbelFit"
      ],
      [
        "gumbelSim"
      ],
      [
        "hillPlot"
      ],
      [
        "hypMeanExcessFit"
      ],
      [
        "lilPlot"
      ],
      [
        "mePlot"
      ],
      [
        "mrlPlot"
      ],
      [
        "msratioPlot"
      ],
      [
        "mxfPlot"
      ],
      [
        "nigMeanExcessFit"
      ],
      [
        "normMeanExcessFit"
      ],
      [
        "pgev"
      ],
      [
        "pgpd"
      ],
      [
        "pointProcess"
      ],
      [
        "qgev"
      ],
      [
        "qgpd"
      ],
      [
        "qqparetoPlot"
      ],
      [
        "recordsPlot"
      ],
      [
        "rgev"
      ],
      [
        "rgpd"
      ],
      [
        "runTheta"
      ],
      [
        "shaparmDEHaan"
      ],
      [
        "shaparmHill"
      ],
      [
        "shaparmPickands"
      ],
      [
        "shaparmPlot"
      ],
      [
        "sllnPlot"
      ],
      [
        "ssrecordsPlot"
      ],
      [
        "tailPlot"
      ],
      [
        "tailRisk"
      ],
      [
        "tailSlider"
      ],
      [
        "thetaSim"
      ],
      [
        "VaR"
      ],
      [
        "xacfPlot"
      ]
    ],
    "topics": [],
    "score": 7.3466,
    "stars": 1,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "fExtremes Rmetrics - Modelling Extreme Events in Finance Provides functions for analysing and modelling extreme\nevents in financial time Series. The topics include: (i) data\npre-processing, (ii) explorative data analysis, (iii) peak over\nthreshold modelling, (iv) block maxima modelling, (v)\nestimation of VaR and CVaR, and (vi) the computation of the\nextreme index. .gevmleFit .gevpwmFit .gevrlevelLLH .gummleFit .gumpwmFit blockMaxima blockTheta clusterTheta CVaR deCluster dgev dgpd emdPlot exindexesPlot exindexPlot ferrosegersTheta findThreshold gevFit gevMoments gevrlevelPlot gevSim gevSlider ghMeanExcessFit ghtMeanExcessFit gpdFit gpdMoments gpdQPlot gpdQuantPlot gpdRiskMeasures gpdSfallPlot gpdShapePlot gpdSim gpdSlider gpdTailPlot gumbelFit gumbelSim hillPlot hypMeanExcessFit lilPlot mePlot mrlPlot msratioPlot mxfPlot nigMeanExcessFit normMeanExcessFit pgev pgpd pointProcess qgev qgpd qqparetoPlot recordsPlot rgev rgpd runTheta shaparmDEHaan shaparmHill shaparmPickands shaparmPlot sllnPlot ssrecordsPlot tailPlot tailRisk tailSlider thetaSim VaR xacfPlot "
  },
  {
    "id": 358,
    "package_name": "chirps",
    "title": "API Client for CHIRPS and CHIRTS",
    "description": "API Client for the Climate Hazards Center 'CHIRPS' and\n'CHIRTS'.  The 'CHIRPS' data is a quasi-global (50\u00b0S \u2013 50\u00b0N)\nhigh-resolution (0.05 arc-degrees) rainfall data set, which\nincorporates satellite imagery and in-situ station data to\ncreate gridded rainfall time series for trend analysis and\nseasonal drought monitoring. 'CHIRTS' is a quasi-global (60\u00b0S \u2013\n70\u00b0N), high-resolution data set of daily maximum and minimum\ntemperatures. For more details on 'CHIRPS' and 'CHIRTS' data\nplease visit its official home page\n<https://www.chc.ucsb.edu/data>.",
    "version": "1.1",
    "maintainer": "Kau\u00ea de Sousa <desousa.kaue@gmail.com>",
    "author": "Kau\u00ea de Sousa [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7571-7845>),\nAdam H. Sparks [aut] (ORCID: <https://orcid.org/0000-0002-0061-8359>),\nAniruddha Ghosh [aut] (ORCID: <https://orcid.org/0000-0003-3667-8019>),\nPete Peterson [ctb] (API Client implementation),\nWilliam Ashmall [ctb] (API Client implementation),\nJacob van Etten [ths] (ORCID: <https://orcid.org/0000-0001-7554-2558>),\nSvein \u00d8. Solberg [ths] (ORCID: <https://orcid.org/0000-0002-4491-4483>)",
    "url": "https://docs.ropensci.org/chirps/",
    "bug_reports": "https://github.com/ropensci/chirps/issues",
    "repository": "",
    "exports": [
      [
        "as.geojson"
      ],
      [
        "get_chirps"
      ],
      [
        "get_chirts"
      ],
      [
        "get_esi"
      ],
      [
        "get_imerg"
      ],
      [
        "precip_indices"
      ]
    ],
    "topics": [
      [
        "chirps"
      ],
      [
        "climatology"
      ],
      [
        "precipitation-data"
      ]
    ],
    "score": 7.036,
    "stars": 33,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "chirps API Client for CHIRPS and CHIRTS API Client for the Climate Hazards Center 'CHIRPS' and\n'CHIRTS'.  The 'CHIRPS' data is a quasi-global (50\u00b0S \u2013 50\u00b0N)\nhigh-resolution (0.05 arc-degrees) rainfall data set, which\nincorporates satellite imagery and in-situ station data to\ncreate gridded rainfall time series for trend analysis and\nseasonal drought monitoring. 'CHIRTS' is a quasi-global (60\u00b0S \u2013\n70\u00b0N), high-resolution data set of daily maximum and minimum\ntemperatures. For more details on 'CHIRPS' and 'CHIRTS' data\nplease visit its official home page\n<https://www.chc.ucsb.edu/data>. as.geojson get_chirps get_chirts get_esi get_imerg precip_indices chirps climatology precipitation-data"
  },
  {
    "id": 1105,
    "package_name": "rglobi",
    "title": "Interface to Global Biotic Interactions",
    "description": "A programmatic interface to the web service methods\nprovided by Global Biotic Interactions (GloBI)\n(<https://www.globalbioticinteractions.org/>). GloBI provides\naccess to spatial-temporal species interaction records from\nsources all over the world. rglobi provides methods to search\nspecies interactions by location, interaction type, and\ntaxonomic name.",
    "version": "0.3.4",
    "maintainer": "Jorrit Poelen <jhpoelen@jhpoelen.nl>",
    "author": "Jorrit Poelen [aut, cre],\nStephen Gosnell [aut],\nSergey Slyusarev [aut],\nHelen Waters [aut]",
    "url": "https://docs.ropensci.org/rglobi/,\nhttps://github.com/ropensci/rglobi",
    "bug_reports": "https://github.com/ropensci/rglobi/issues",
    "repository": "",
    "exports": [
      [
        "get_data_fields"
      ],
      [
        "get_interaction_areas"
      ],
      [
        "get_interaction_matrix"
      ],
      [
        "get_interaction_types"
      ],
      [
        "get_interactions"
      ],
      [
        "get_interactions_by_taxa"
      ],
      [
        "get_interactions_by_type"
      ],
      [
        "get_interactions_in_area"
      ],
      [
        "get_predators_of"
      ],
      [
        "get_prey_of"
      ]
    ],
    "topics": [],
    "score": 6.8211,
    "stars": 18,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rglobi Interface to Global Biotic Interactions A programmatic interface to the web service methods\nprovided by Global Biotic Interactions (GloBI)\n(<https://www.globalbioticinteractions.org/>). GloBI provides\naccess to spatial-temporal species interaction records from\nsources all over the world. rglobi provides methods to search\nspecies interactions by location, interaction type, and\ntaxonomic name. get_data_fields get_interaction_areas get_interaction_matrix get_interaction_types get_interactions get_interactions_by_taxa get_interactions_by_type get_interactions_in_area get_predators_of get_prey_of "
  },
  {
    "id": 511,
    "package_name": "eia",
    "title": "API Wrapper for U.S. Energy Information Administration ('EIA')\nOpen Data",
    "description": "Provides API access to data from the U.S. Energy\nInformation Administration ('EIA') <https://www.eia.gov/>. Use\nof the EIA's API and this package requires a free API key\nobtainable at <https://www.eia.gov/opendata/register.php>. This\npackage includes functions for searching the EIA data directory\nand returning time series and geoset time series datasets.\nDatasets returned by these functions are provided by default in\na tidy format, or alternatively, in more raw formats. It also\noffers helper functions for working with EIA date strings and\ntime formats and for inspecting different summaries of series\nmetadata. The package also provides control over API key\nstorage and caching of API request results.",
    "version": "0.4.2",
    "maintainer": "Matthew Hoff <matthew.g.hoff@gmail.com>",
    "author": "Matthew Leonawicz [aut] (ORCID:\n<https://orcid.org/0000-0001-9452-2771>),\nMatthew Hoff [aut, cre]",
    "url": "https://docs.ropensci.org/eia/, https://github.com/ropensci/eia",
    "bug_reports": "https://github.com/ropensci/eia/issues",
    "repository": "",
    "exports": [
      [
        "date_to_eiadate"
      ],
      [
        "eia_clear_cache"
      ],
      [
        "eia_clear_data"
      ],
      [
        "eia_clear_dir"
      ],
      [
        "eia_clear_facets"
      ],
      [
        "eia_clear_metadata"
      ],
      [
        "eia_data"
      ],
      [
        "eia_dir"
      ],
      [
        "eia_facets"
      ],
      [
        "eia_get_key"
      ],
      [
        "eia_metadata"
      ],
      [
        "eia_set_key"
      ],
      [
        "eiadate_to_date"
      ],
      [
        "eiadate_to_date_seq"
      ]
    ],
    "topics": [
      [
        "eia"
      ],
      [
        "eia-api"
      ],
      [
        "energy-data"
      ],
      [
        "energy-information-administration"
      ],
      [
        "open-data"
      ]
    ],
    "score": 6.8108,
    "stars": 49,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "eia API Wrapper for U.S. Energy Information Administration ('EIA')\nOpen Data Provides API access to data from the U.S. Energy\nInformation Administration ('EIA') <https://www.eia.gov/>. Use\nof the EIA's API and this package requires a free API key\nobtainable at <https://www.eia.gov/opendata/register.php>. This\npackage includes functions for searching the EIA data directory\nand returning time series and geoset time series datasets.\nDatasets returned by these functions are provided by default in\na tidy format, or alternatively, in more raw formats. It also\noffers helper functions for working with EIA date strings and\ntime formats and for inspecting different summaries of series\nmetadata. The package also provides control over API key\nstorage and caching of API request results. date_to_eiadate eia_clear_cache eia_clear_data eia_clear_dir eia_clear_facets eia_clear_metadata eia_data eia_dir eia_facets eia_get_key eia_metadata eia_set_key eiadate_to_date eiadate_to_date_seq eia eia-api energy-data energy-information-administration open-data"
  },
  {
    "id": 127,
    "package_name": "RHRV",
    "title": "Heart Rate Variability Analysis of ECG Data",
    "description": "Allows users to import data files containing heartbeat\npositions in the most broadly used formats, to remove outliers\nor points with unacceptable physiological values present in the\ntime series, to plot HRV data, and to perform time domain,\nfrequency domain and nonlinear HRV analysis. See Garcia et al.\n(2017) <DOI:10.1007/978-3-319-65355-6>.",
    "version": "5.0.0",
    "maintainer": "Leandro Rodriguez-Linares <leandro@uvigo.es>",
    "author": "Leandro Rodriguez-Linares [aut, cre],\nXose Vila [aut],\nMaria Jose Lado [aut],\nArturo Mendez [aut],\nAbraham Otero [aut],\nConstantino Antonio Garcia [aut],\nMatti Lassila [ctb]",
    "url": "http://rhrv.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "AddEpisodes"
      ],
      [
        "AnalyzeHRbyEpisodes"
      ],
      [
        "AnalyzePowerBandsByEpisodes"
      ],
      [
        "AvgIntegralCorrelation"
      ],
      [
        "BuildNIHR"
      ],
      [
        "BuildTakens"
      ],
      [
        "BuildTakensVector"
      ],
      [
        "CalculateApEn"
      ],
      [
        "CalculateCorrDim"
      ],
      [
        "CalculateDFA"
      ],
      [
        "CalculateEmbeddingDim"
      ],
      [
        "CalculateEnergyInPSDBands"
      ],
      [
        "CalculateFracDim"
      ],
      [
        "CalculateInfDim"
      ],
      [
        "CalculateMaxLyapunov"
      ],
      [
        "CalculatePowerBand"
      ],
      [
        "CalculatePSD"
      ],
      [
        "CalculateRfromCorrelation"
      ],
      [
        "CalculateSampleEntropy"
      ],
      [
        "CalculateSpectrogram"
      ],
      [
        "CalculateTimeLag"
      ],
      [
        "CreateFreqAnalysis"
      ],
      [
        "CreateHRVData"
      ],
      [
        "CreateNonLinearAnalysis"
      ],
      [
        "CreateTimeAnalysis"
      ],
      [
        "EditNIHR"
      ],
      [
        "EstimateCorrDim"
      ],
      [
        "EstimateDFA"
      ],
      [
        "EstimateInfDim"
      ],
      [
        "EstimateMaxLyapunov"
      ],
      [
        "EstimatePSDSlope"
      ],
      [
        "EstimateSampleEntropy"
      ],
      [
        "ExtractTimeSegment"
      ],
      [
        "FilterNIHR"
      ],
      [
        "GenerateEpisodes"
      ],
      [
        "getNormSpectralUnits"
      ],
      [
        "IntegralCorrelation"
      ],
      [
        "InterpolateNIHR"
      ],
      [
        "ListEpisodes"
      ],
      [
        "LoadApneaWFDB"
      ],
      [
        "LoadBeat"
      ],
      [
        "LoadBeatAmbit"
      ],
      [
        "LoadBeatAscii"
      ],
      [
        "LoadBeatEDFPlus"
      ],
      [
        "LoadBeatPolar"
      ],
      [
        "LoadBeatRR"
      ],
      [
        "LoadBeatSuunto"
      ],
      [
        "LoadBeatVector"
      ],
      [
        "LoadBeatWFDB"
      ],
      [
        "LoadEpisodesAscii"
      ],
      [
        "LoadHeaderWFDB"
      ],
      [
        "ModifyEpisodes"
      ],
      [
        "NonlinearityTests"
      ],
      [
        "NonLinearNoiseReduction"
      ],
      [
        "OverplotEpisodes"
      ],
      [
        "PlotCorrDim"
      ],
      [
        "PlotDFA"
      ],
      [
        "PlotHR"
      ],
      [
        "PlotInfDim"
      ],
      [
        "PlotMaxLyapunov"
      ],
      [
        "PlotNIHR"
      ],
      [
        "PlotPowerBand"
      ],
      [
        "PlotPSD"
      ],
      [
        "PlotSampleEntropy"
      ],
      [
        "PlotSinglePowerBand"
      ],
      [
        "PlotSpectrogram"
      ],
      [
        "PoincarePlot"
      ],
      [
        "ReadFromFile"
      ],
      [
        "RecurrencePlot"
      ],
      [
        "RemoveEpisodes"
      ],
      [
        "RHRVEasy"
      ],
      [
        "RHRVEasyStats"
      ],
      [
        "RQA"
      ],
      [
        "SaveHRVIndices"
      ],
      [
        "SetVerbose"
      ],
      [
        "SplitHRbyEpisodes"
      ],
      [
        "SplitPowerBandByEpisodes"
      ],
      [
        "SurrogateTest"
      ],
      [
        "Window"
      ],
      [
        "WriteToFile"
      ]
    ],
    "topics": [],
    "score": 6.8091,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "RHRV Heart Rate Variability Analysis of ECG Data Allows users to import data files containing heartbeat\npositions in the most broadly used formats, to remove outliers\nor points with unacceptable physiological values present in the\ntime series, to plot HRV data, and to perform time domain,\nfrequency domain and nonlinear HRV analysis. See Garcia et al.\n(2017) <DOI:10.1007/978-3-319-65355-6>. AddEpisodes AnalyzeHRbyEpisodes AnalyzePowerBandsByEpisodes AvgIntegralCorrelation BuildNIHR BuildTakens BuildTakensVector CalculateApEn CalculateCorrDim CalculateDFA CalculateEmbeddingDim CalculateEnergyInPSDBands CalculateFracDim CalculateInfDim CalculateMaxLyapunov CalculatePowerBand CalculatePSD CalculateRfromCorrelation CalculateSampleEntropy CalculateSpectrogram CalculateTimeLag CreateFreqAnalysis CreateHRVData CreateNonLinearAnalysis CreateTimeAnalysis EditNIHR EstimateCorrDim EstimateDFA EstimateInfDim EstimateMaxLyapunov EstimatePSDSlope EstimateSampleEntropy ExtractTimeSegment FilterNIHR GenerateEpisodes getNormSpectralUnits IntegralCorrelation InterpolateNIHR ListEpisodes LoadApneaWFDB LoadBeat LoadBeatAmbit LoadBeatAscii LoadBeatEDFPlus LoadBeatPolar LoadBeatRR LoadBeatSuunto LoadBeatVector LoadBeatWFDB LoadEpisodesAscii LoadHeaderWFDB ModifyEpisodes NonlinearityTests NonLinearNoiseReduction OverplotEpisodes PlotCorrDim PlotDFA PlotHR PlotInfDim PlotMaxLyapunov PlotNIHR PlotPowerBand PlotPSD PlotSampleEntropy PlotSinglePowerBand PlotSpectrogram PoincarePlot ReadFromFile RecurrencePlot RemoveEpisodes RHRVEasy RHRVEasyStats RQA SaveHRVIndices SetVerbose SplitHRbyEpisodes SplitPowerBandByEpisodes SurrogateTest Window WriteToFile "
  },
  {
    "id": 1153,
    "package_name": "rsi",
    "title": "Efficiently Retrieve and Process Satellite Imagery",
    "description": "Downloads spatial data from spatiotemporal asset catalogs\n('STAC'), computes standard spectral indices from the Awesome\nSpectral Indices project (Montero et al. (2023)\n<doi:10.1038/s41597-023-02096-0>) against raster data, and\nglues the outputs together into predictor bricks. Methods focus\non interoperability with the broader spatial ecosystem;\nfunction arguments and outputs use classes from 'sf' and\n'terra', and data downloading functions support complex 'CQL2'\nqueries using 'rstac'.",
    "version": "0.3.2.9000",
    "maintainer": "Michael Mahoney <mike.mahoney.218@gmail.com>",
    "author": "Michael Mahoney [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2402-304X>),\nFelipe Carvalho [rev] (Felipe reviewed the package (v. 0.3.0) for\nrOpenSci, see\n<https://github.com/ropensci/software-review/issues/636>),\nMichael Sumner [rev] (Michael reviewed the package (v. 0.3.0) for\nrOpenSci, see\n<https://github.com/ropensci/software-review/issues/636>),\nPermian Global [cph, fnd]",
    "url": "https://github.com/Permian-Global-Research/rsi,\nhttps://permian-global-research.github.io/rsi/",
    "bug_reports": "https://github.com/Permian-Global-Research/rsi/issues",
    "repository": "",
    "exports": [
      [
        "alos_palsar_mask_function"
      ],
      [
        "calculate_indices"
      ],
      [
        "default_query_function"
      ],
      [
        "filter_bands"
      ],
      [
        "filter_platforms"
      ],
      [
        "get_alos_palsar_imagery"
      ],
      [
        "get_dem"
      ],
      [
        "get_landsat_imagery"
      ],
      [
        "get_naip_imagery"
      ],
      [
        "get_sentinel1_imagery"
      ],
      [
        "get_sentinel2_imagery"
      ],
      [
        "get_stac_data"
      ],
      [
        "landsat_mask_function"
      ],
      [
        "landsat_platform_filter"
      ],
      [
        "rsi_download_rasters"
      ],
      [
        "rsi_gdal_config_options"
      ],
      [
        "rsi_gdalwarp_options"
      ],
      [
        "rsi_query_api"
      ],
      [
        "sentinel2_mask_function"
      ],
      [
        "sign_planetary_computer"
      ],
      [
        "spectral_indices"
      ],
      [
        "spectral_indices_url"
      ],
      [
        "stack_rasters"
      ]
    ],
    "topics": [],
    "score": 6.7404,
    "stars": 55,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rsi Efficiently Retrieve and Process Satellite Imagery Downloads spatial data from spatiotemporal asset catalogs\n('STAC'), computes standard spectral indices from the Awesome\nSpectral Indices project (Montero et al. (2023)\n<doi:10.1038/s41597-023-02096-0>) against raster data, and\nglues the outputs together into predictor bricks. Methods focus\non interoperability with the broader spatial ecosystem;\nfunction arguments and outputs use classes from 'sf' and\n'terra', and data downloading functions support complex 'CQL2'\nqueries using 'rstac'. alos_palsar_mask_function calculate_indices default_query_function filter_bands filter_platforms get_alos_palsar_imagery get_dem get_landsat_imagery get_naip_imagery get_sentinel1_imagery get_sentinel2_imagery get_stac_data landsat_mask_function landsat_platform_filter rsi_download_rasters rsi_gdal_config_options rsi_gdalwarp_options rsi_query_api sentinel2_mask_function sign_planetary_computer spectral_indices spectral_indices_url stack_rasters "
  },
  {
    "id": 558,
    "package_name": "fUnitRoots",
    "title": "Rmetrics - Modelling Trends and Unit Roots",
    "description": "Provides four addons for analyzing trends and unit roots\nin financial time series: (i) functions for the density and\nprobability of the augmented Dickey-Fuller Test, (ii) functions\nfor the density and probability of MacKinnon's unit root test\nstatistics, (iii) reimplementations for the ADF and MacKinnon\nTest, and (iv) an 'urca' Unit Root Test Interface for Pfaff's\nunit root test suite.",
    "version": "4040.81",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Diethelm Wuertz [aut] (original code),\nTobias Setz [aut],\nYohan Chalabi [aut],\nGeorgi N. Boshnakov [cre] (ORCID:\n<https://orcid.org/0000-0003-2839-346X>)",
    "url": "https://r-forge.r-project.org/scm/viewvc.php/pkg/fUnitRoots/?root=rmetrics\n(devel), https://www.rmetrics.org",
    "bug_reports": "https://r-forge.r-project.org/projects/rmetrics",
    "repository": "",
    "exports": [
      [
        "adfTable"
      ],
      [
        "adfTest"
      ],
      [
        "padf"
      ],
      [
        "punitroot"
      ],
      [
        "qadf"
      ],
      [
        "qunitroot"
      ],
      [
        "unitrootTable"
      ],
      [
        "unitrootTest"
      ],
      [
        "urdfTest"
      ],
      [
        "urersTest"
      ],
      [
        "urkpssTest"
      ],
      [
        "urppTest"
      ],
      [
        "urspTest"
      ],
      [
        "urzaTest"
      ]
    ],
    "topics": [
      [
        "fortran"
      ]
    ],
    "score": 6.733,
    "stars": 1,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "fUnitRoots Rmetrics - Modelling Trends and Unit Roots Provides four addons for analyzing trends and unit roots\nin financial time series: (i) functions for the density and\nprobability of the augmented Dickey-Fuller Test, (ii) functions\nfor the density and probability of MacKinnon's unit root test\nstatistics, (iii) reimplementations for the ADF and MacKinnon\nTest, and (iv) an 'urca' Unit Root Test Interface for Pfaff's\nunit root test suite. adfTable adfTest padf punitroot qadf qunitroot unitrootTable unitrootTest urdfTest urersTest urkpssTest urppTest urspTest urzaTest fortran"
  },
  {
    "id": 524,
    "package_name": "epiCo",
    "title": "Statistical and Viz Tools for Vector-Borne Diseases in Colombia",
    "description": "Provides statistical and visualization tools for the\nanalysis of demographic indicators, and spatio-temporal\nbehavior and characterization of outbreaks of vector-borne\ndiseases (VBDs) in Colombia. It implements travel times\nestimated in Bravo-Vega C., Santos-Vega M., & Cordovez J.M.\n(2022), and the endemic channel method (Bortman, M.  (1999)\n<https://iris.paho.org/handle/10665.2/8562>).",
    "version": "1.0.1.9000",
    "maintainer": "Juan D. Uma\u00f1a <jd.umana10@uniandes.edu.co>",
    "author": "Juan D. Uma\u00f1a [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0003-0316-6164>),\nJuan Montenegro-Torres [aut] (ORCID:\n<https://orcid.org/0000-0003-2755-4743>),\nJulian Otero [aut] (ORCID: <https://orcid.org/0009-0006-0429-7747>),\nHugo Gruson [ctb] (ORCID: <https://orcid.org/0000-0002-4094-1476>)",
    "url": "https://epiverse-trace.github.io/epiCo/,\nhttps://github.com/epiverse-trace/epiCo",
    "bug_reports": "https://github.com/epiverse-trace/epiCo/issues",
    "repository": "",
    "exports": [
      [
        "age_risk"
      ],
      [
        "describe_ethnicity"
      ],
      [
        "describe_occupation"
      ],
      [
        "endemic_channel"
      ],
      [
        "epi_calendar"
      ],
      [
        "geometric_mean"
      ],
      [
        "geometric_sd"
      ],
      [
        "incidence_rate"
      ],
      [
        "morans_index"
      ],
      [
        "neighborhoods"
      ],
      [
        "population_pyramid"
      ]
    ],
    "topics": [
      [
        "colombia"
      ],
      [
        "decision-support"
      ],
      [
        "demographics"
      ],
      [
        "epiverse"
      ],
      [
        "outbreak-analysis"
      ],
      [
        "sdg-3"
      ],
      [
        "spatio-temporal-analysis"
      ],
      [
        "vector-borne-diseases"
      ]
    ],
    "score": 6.1931,
    "stars": 13,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "epiCo Statistical and Viz Tools for Vector-Borne Diseases in Colombia Provides statistical and visualization tools for the\nanalysis of demographic indicators, and spatio-temporal\nbehavior and characterization of outbreaks of vector-borne\ndiseases (VBDs) in Colombia. It implements travel times\nestimated in Bravo-Vega C., Santos-Vega M., & Cordovez J.M.\n(2022), and the endemic channel method (Bortman, M.  (1999)\n<https://iris.paho.org/handle/10665.2/8562>). age_risk describe_ethnicity describe_occupation endemic_channel epi_calendar geometric_mean geometric_sd incidence_rate morans_index neighborhoods population_pyramid colombia decision-support demographics epiverse outbreak-analysis sdg-3 spatio-temporal-analysis vector-borne-diseases"
  },
  {
    "id": 436,
    "package_name": "daiquiri",
    "title": "Data Quality Reporting for Temporal Datasets",
    "description": "Generate reports that enable quick visual review of\ntemporal shifts in record-level data. Time series plots showing\naggregated values are automatically created for each data field\n(column) depending on its contents (e.g. min/max/mean values\nfor numeric data, no. of distinct values for categorical data),\nas well as overviews for missing values, non-conformant values,\nand duplicated rows. The resulting reports are shareable and\ncan contribute to forming a transparent record of the entire\nanalysis process. It is designed with Electronic Health Records\nin mind, but can be used for any type of record-level temporal\ndata (i.e. tabular data where each row represents a single\n\"event\", one column contains the \"event date\", and other\ncolumns contain any associated values for the event).",
    "version": "1.2.1",
    "maintainer": "T. Phuong Quan <phuongquan567@outlook.com>",
    "author": "T. Phuong Quan [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8566-1817>),\nJack Cregan [ctb],\nUniversity of Oxford [cph],\nNational Institute for Health Research (NIHR) [fnd],\nBrad Cannell [rev]",
    "url": "https://github.com/ropensci/daiquiri,\nhttps://ropensci.github.io/daiquiri/",
    "bug_reports": "https://github.com/ropensci/daiquiri/issues",
    "repository": "",
    "exports": [
      [
        "aggregate_data"
      ],
      [
        "close_log"
      ],
      [
        "daiquiri_report"
      ],
      [
        "export_aggregated_data"
      ],
      [
        "field_types"
      ],
      [
        "field_types_advanced"
      ],
      [
        "ft_categorical"
      ],
      [
        "ft_datetime"
      ],
      [
        "ft_freetext"
      ],
      [
        "ft_ignore"
      ],
      [
        "ft_numeric"
      ],
      [
        "ft_simple"
      ],
      [
        "ft_strata"
      ],
      [
        "ft_timepoint"
      ],
      [
        "ft_uniqueidentifier"
      ],
      [
        "initialise_log"
      ],
      [
        "prepare_data"
      ],
      [
        "read_data"
      ],
      [
        "report_data"
      ],
      [
        "template_field_types"
      ]
    ],
    "topics": [
      [
        "data-quality"
      ],
      [
        "initial-data-analysis"
      ],
      [
        "reproducible-research"
      ],
      [
        "temporal-data"
      ],
      [
        "time-series"
      ]
    ],
    "score": 6.0682,
    "stars": 39,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "daiquiri Data Quality Reporting for Temporal Datasets Generate reports that enable quick visual review of\ntemporal shifts in record-level data. Time series plots showing\naggregated values are automatically created for each data field\n(column) depending on its contents (e.g. min/max/mean values\nfor numeric data, no. of distinct values for categorical data),\nas well as overviews for missing values, non-conformant values,\nand duplicated rows. The resulting reports are shareable and\ncan contribute to forming a transparent record of the entire\nanalysis process. It is designed with Electronic Health Records\nin mind, but can be used for any type of record-level temporal\ndata (i.e. tabular data where each row represents a single\n\"event\", one column contains the \"event date\", and other\ncolumns contain any associated values for the event). aggregate_data close_log daiquiri_report export_aggregated_data field_types field_types_advanced ft_categorical ft_datetime ft_freetext ft_ignore ft_numeric ft_simple ft_strata ft_timepoint ft_uniqueidentifier initialise_log prepare_data read_data report_data template_field_types data-quality initial-data-analysis reproducible-research temporal-data time-series"
  },
  {
    "id": 787,
    "package_name": "mantis",
    "title": "Multiple Time Series Scanner",
    "description": "Generate interactive html reports that enable quick visual\nreview of multiple related time series stored in a data frame.\nFor static datasets, this can help to identify any temporal\nartefacts that may affect the validity of subsequent analyses.\nFor live data feeds, regularly scheduled reports can help to\npro-actively identify data feed problems or unexpected trends\nthat may require action. The reports are self-contained and\nshareable without a web server.",
    "version": "1.0.0.9000",
    "maintainer": "T. Phuong Quan <phuongquan567@outlook.com>",
    "author": "T. Phuong Quan [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8566-1817>),\nUniversity of Oxford [cph],\nNational Institute for Health Research (NIHR) [fnd],\nRodrigo Pires [rev],\nMargaret Siple [rev]",
    "url": "https://github.com/ropensci/mantis,\nhttps://ropensci.github.io/mantis/",
    "bug_reports": "https://github.com/ropensci/mantis/issues",
    "repository": "",
    "exports": [
      [
        "alert_above"
      ],
      [
        "alert_below"
      ],
      [
        "alert_custom"
      ],
      [
        "alert_difference_above_perc"
      ],
      [
        "alert_difference_below_perc"
      ],
      [
        "alert_equals"
      ],
      [
        "alert_missing"
      ],
      [
        "alert_rules"
      ],
      [
        "alertspec"
      ],
      [
        "bespoke_rmd_alert_results"
      ],
      [
        "bespoke_rmd_initialise_widgets"
      ],
      [
        "bespoke_rmd_output"
      ],
      [
        "inputspec"
      ],
      [
        "mantis_alerts"
      ],
      [
        "mantis_report"
      ],
      [
        "outputspec_interactive"
      ],
      [
        "outputspec_static_heatmap"
      ],
      [
        "outputspec_static_multipanel"
      ]
    ],
    "topics": [],
    "score": 5.8573,
    "stars": 2,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "mantis Multiple Time Series Scanner Generate interactive html reports that enable quick visual\nreview of multiple related time series stored in a data frame.\nFor static datasets, this can help to identify any temporal\nartefacts that may affect the validity of subsequent analyses.\nFor live data feeds, regularly scheduled reports can help to\npro-actively identify data feed problems or unexpected trends\nthat may require action. The reports are self-contained and\nshareable without a web server. alert_above alert_below alert_custom alert_difference_above_perc alert_difference_below_perc alert_equals alert_missing alert_rules alertspec bespoke_rmd_alert_results bespoke_rmd_initialise_widgets bespoke_rmd_output inputspec mantis_alerts mantis_report outputspec_interactive outputspec_static_heatmap outputspec_static_multipanel "
  },
  {
    "id": 418,
    "package_name": "covidregionaldata",
    "title": "Subnational Data for COVID-19 Epidemiology",
    "description": "An interface to subnational and national level COVID-19\ndata sourced from both official sources, such as Public Health\nEngland in the UK, and from other COVID-19 data collections,\nincluding the World Health Organisation (WHO), European Centre\nfor Disease Prevention and Control (ECDC), John Hopkins\nUniversity (JHU), Google Open Data and others. Designed to\nstreamline COVID-19 data extraction, cleaning, and processing\nfrom a range of data sources in an open and transparent way.\nThis allows users to inspect and scrutinise the data, and tools\nused to process it, at every step. For all countries supported,\ndata includes a daily time-series of cases. Wherever available\ndata is also provided for deaths, hospitalisations, and tests.\nNational level data are also supported using a range of\nsources.",
    "version": "0.9.3",
    "maintainer": "Sam Abbott <sam.abbott@lshtm.ac.uk>",
    "author": "Joseph Palmer [aut] (ORCID: <https://orcid.org/0000-0002-5593-9352>),\nKatharine Sherratt [aut] (ORCID:\n<https://orcid.org/0000-0003-2049-3423>),\nRichard Martin-Nielsen [aut] (URL: https://github.com/RichardMN),\nJonnie Bevan [aut],\nHamish Gibbs [aut] (ORCID: <https://orcid.org/0000-0003-4413-453X>),\nHugo Gruson [aut] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nSophie Meakin [ctb],\nJoel Hellewell [ctb] (ORCID: <https://orcid.org/0000-0003-2683-0849>),\nPatrick Barks [ctb],\nPaul Campbell [ctb],\nFlavio Finger [ctb] (ORCID: <https://orcid.org/0000-0002-8613-5170>),\nRichard Boyes [ctb] (URL: https://github.com/rboyes),\nVang Le [ctb] (URL: https://github.com/biocyberman),\nSebastian Funk [aut],\nSam Abbott [aut, cre] (ORCID: <https://orcid.org/0000-0001-8057-8037>)",
    "url": "https://epiforecasts.io/covidregionaldata/,\nhttps://github.com/epiforecasts/covidregionaldata/",
    "bug_reports": "https://github.com/epiforecasts/covidregionaldata/issues/",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "Belgium"
      ],
      [
        "Brazil"
      ],
      [
        "Canada"
      ],
      [
        "Colombia"
      ],
      [
        "CountryDataClass"
      ],
      [
        "Covid19DataHub"
      ],
      [
        "Cuba"
      ],
      [
        "DataClass"
      ],
      [
        "ECDC"
      ],
      [
        "Estonia"
      ],
      [
        "expect_clean_cols"
      ],
      [
        "expect_columns_contain_data"
      ],
      [
        "expect_processed_cols"
      ],
      [
        "France"
      ],
      [
        "Germany"
      ],
      [
        "get_available_datasets"
      ],
      [
        "get_national_data"
      ],
      [
        "get_regional_data"
      ],
      [
        "Google"
      ],
      [
        "India"
      ],
      [
        "initialise_dataclass"
      ],
      [
        "Italy"
      ],
      [
        "JHU"
      ],
      [
        "JRC"
      ],
      [
        "Lithuania"
      ],
      [
        "make_github_workflow"
      ],
      [
        "make_new_data_source"
      ],
      [
        "Mexico"
      ],
      [
        "Netherlands"
      ],
      [
        "reset_cache"
      ],
      [
        "SouthAfrica"
      ],
      [
        "start_using_memoise"
      ],
      [
        "stop_using_memoise"
      ],
      [
        "Switzerland"
      ],
      [
        "test_cleaning"
      ],
      [
        "test_download"
      ],
      [
        "test_download_JSON"
      ],
      [
        "test_processing"
      ],
      [
        "test_return"
      ],
      [
        "UK"
      ],
      [
        "USA"
      ],
      [
        "WHO"
      ]
    ],
    "topics": [
      [
        "covid-19"
      ],
      [
        "data"
      ],
      [
        "open-science"
      ],
      [
        "r6"
      ],
      [
        "regional-data"
      ]
    ],
    "score": 5.6649,
    "stars": 37,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "covidregionaldata Subnational Data for COVID-19 Epidemiology An interface to subnational and national level COVID-19\ndata sourced from both official sources, such as Public Health\nEngland in the UK, and from other COVID-19 data collections,\nincluding the World Health Organisation (WHO), European Centre\nfor Disease Prevention and Control (ECDC), John Hopkins\nUniversity (JHU), Google Open Data and others. Designed to\nstreamline COVID-19 data extraction, cleaning, and processing\nfrom a range of data sources in an open and transparent way.\nThis allows users to inspect and scrutinise the data, and tools\nused to process it, at every step. For all countries supported,\ndata includes a daily time-series of cases. Wherever available\ndata is also provided for deaths, hospitalisations, and tests.\nNational level data are also supported using a range of\nsources. %>% Belgium Brazil Canada Colombia CountryDataClass Covid19DataHub Cuba DataClass ECDC Estonia expect_clean_cols expect_columns_contain_data expect_processed_cols France Germany get_available_datasets get_national_data get_regional_data Google India initialise_dataclass Italy JHU JRC Lithuania make_github_workflow make_new_data_source Mexico Netherlands reset_cache SouthAfrica start_using_memoise stop_using_memoise Switzerland test_cleaning test_download test_download_JSON test_processing test_return UK USA WHO covid-19 data open-science r6 regional-data"
  },
  {
    "id": 1385,
    "package_name": "trending",
    "title": "Model Temporal Trends",
    "description": "Provides a coherent interface to multiple modelling tools\nfor fitting trends along with a standardised approach for\ngenerating confidence and prediction intervals.",
    "version": "0.1.0",
    "maintainer": "Thibaut Jombart <thibautjombart@gmail.com>",
    "author": "Tim Taylor [aut] (ORCID: <https://orcid.org/0000-0002-8587-7113>),\nDirk Schumacher [ctb],\nThibaut Jombart [ctb, cre]",
    "url": "https://github.com/reconverse/trending",
    "bug_reports": "https://github.com/reconverse/trending/issues",
    "repository": "",
    "exports": [
      [
        "brm_model"
      ],
      [
        "fit"
      ],
      [
        "get_errors"
      ],
      [
        "get_estimate"
      ],
      [
        "get_fitted_data"
      ],
      [
        "get_fitted_model"
      ],
      [
        "get_formula"
      ],
      [
        "get_predictors"
      ],
      [
        "get_response"
      ],
      [
        "get_result"
      ],
      [
        "get_warnings"
      ],
      [
        "glm_model"
      ],
      [
        "glm_nb_model"
      ],
      [
        "glm.nb"
      ],
      [
        "lm_model"
      ]
    ],
    "topics": [],
    "score": 5.6355,
    "stars": 8,
    "primary_category": "epidemiology",
    "source_universe": "reconverse",
    "search_text": "trending Model Temporal Trends Provides a coherent interface to multiple modelling tools\nfor fitting trends along with a standardised approach for\ngenerating confidence and prediction intervals. brm_model fit get_errors get_estimate get_fitted_data get_fitted_model get_formula get_predictors get_response get_result get_warnings glm_model glm_nb_model glm.nb lm_model "
  },
  {
    "id": 329,
    "package_name": "butterfly",
    "title": "Verification for Continually Updating Time Series Data",
    "description": "Verification of continually updating time series data\nwhere we expect new values, but want to ensure previous data\nremains unchanged. Data previously recorded could change for a\nnumber of reasons, such as discovery of an error in model code,\na change in methodology or instrument recalibration. Monitoring\ndata sources for these changes is not always possible. Other\nunnoticed changes could include a jump in time or measurement\nfrequency, due to instrument failure or software updates.\nFunctionality is provided that can be used to check and flag\nchanges to previous data to prevent changes going unnoticed, as\nwell as unexpected jumps in time.",
    "version": "1.1.2",
    "maintainer": "Thomas Zwagerman <thozwa@bas.ac.uk>",
    "author": "Thomas Zwagerman [aut, cre] (ORCID:\n<https://orcid.org/0009-0003-3742-3234>),\nBritish Antarctic Survey [cph],\nQuentin Read [rev] (Quentin reviewed the package (v. 1.1.0) for\nrOpenSci, see\n<https://github.com/ropensci/software-review/issues/676>)",
    "url": "https://docs.ropensci.org/butterfly/,\nhttps://github.com/ropensci/butterfly/",
    "bug_reports": "https://github.com/ropensci/butterfly/issues",
    "repository": "",
    "exports": [
      [
        "catch"
      ],
      [
        "create_object_list"
      ],
      [
        "loupe"
      ],
      [
        "release"
      ],
      [
        "timeline"
      ],
      [
        "timeline_group"
      ]
    ],
    "topics": [
      [
        "data-versioning"
      ],
      [
        "qaqc"
      ],
      [
        "timeseries"
      ],
      [
        "verification"
      ]
    ],
    "score": 5.5563,
    "stars": 10,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "butterfly Verification for Continually Updating Time Series Data Verification of continually updating time series data\nwhere we expect new values, but want to ensure previous data\nremains unchanged. Data previously recorded could change for a\nnumber of reasons, such as discovery of an error in model code,\na change in methodology or instrument recalibration. Monitoring\ndata sources for these changes is not always possible. Other\nunnoticed changes could include a jump in time or measurement\nfrequency, due to instrument failure or software updates.\nFunctionality is provided that can be used to check and flag\nchanges to previous data to prevent changes going unnoticed, as\nwell as unexpected jumps in time. catch create_object_list loupe release timeline timeline_group data-versioning qaqc timeseries verification"
  },
  {
    "id": 1391,
    "package_name": "tscount",
    "title": "Analysis of Count Time Series",
    "description": "Likelihood-based methods for model fitting and assessment,\nprediction and intervention analysis of count time series\nfollowing generalized linear models are provided, see Liboschik\net al. (2017) <doi:10.18637/jss.v082.i05>. Models with the\nidentity and with the logarithmic link function are allowed.\nThe conditional distribution can be Poisson or Negative\nBinomial.",
    "version": "1.4.4",
    "maintainer": "Tobias Liboschik <liboschik@statistik.tu-dortmund.de>",
    "author": "Tobias Liboschik [aut, cre],\nRoland Fried [aut],\nKonstantinos Fokianos [aut],\nPhilipp Probst [aut],\nJonathan Rathjens [ctb],\nNicol\u00f2 Rubattu [ctb]",
    "url": "http://tscount.r-forge.r-project.org",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "ardistr"
      ],
      [
        "checkdistr"
      ],
      [
        "ddistr"
      ],
      [
        "ingarch.acf"
      ],
      [
        "ingarch.mean"
      ],
      [
        "ingarch.var"
      ],
      [
        "interv_covariate"
      ],
      [
        "interv_detect"
      ],
      [
        "interv_multiple"
      ],
      [
        "interv_test"
      ],
      [
        "invertinfo"
      ],
      [
        "marcal"
      ],
      [
        "pdistr"
      ],
      [
        "pit"
      ],
      [
        "qdistr"
      ],
      [
        "QIC"
      ],
      [
        "rdistr"
      ],
      [
        "scoring"
      ],
      [
        "sddistr"
      ],
      [
        "se"
      ],
      [
        "tsglm"
      ],
      [
        "tsglm.meanfit"
      ],
      [
        "tsglm.sim"
      ]
    ],
    "topics": [],
    "score": 5.5002,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "tscount Analysis of Count Time Series Likelihood-based methods for model fitting and assessment,\nprediction and intervention analysis of count time series\nfollowing generalized linear models are provided, see Liboschik\net al. (2017) <doi:10.18637/jss.v082.i05>. Models with the\nidentity and with the logarithmic link function are allowed.\nThe conditional distribution can be Poisson or Negative\nBinomial. ardistr checkdistr ddistr ingarch.acf ingarch.mean ingarch.var interv_covariate interv_detect interv_multiple interv_test invertinfo marcal pdistr pit qdistr QIC rdistr scoring sddistr se tsglm tsglm.meanfit tsglm.sim "
  },
  {
    "id": 1040,
    "package_name": "qualV",
    "title": "Qualitative Validation Methods",
    "description": "Qualitative methods for the validation of dynamic models.\nIt contains (i) an orthogonal set of deviance measures for\nabsolute, relative and ordinal scale and (ii) approaches\naccounting for time shifts. The first approach transforms time\nto take time delays and speed differences into account. The\nsecond divides the time series into interval units according to\ntheir main features and finds the longest common subsequence\n(LCS) using a dynamic programming algorithm.",
    "version": "0.3-5",
    "maintainer": "Thomas Petzoldt <thomas.petzoldt@tu-dresden.de>",
    "author": "K. Gerald van den Boogaart [aut, ths]\n(<https://orcid.org/0000-0003-4646-943X>), Stefanie Rost [aut],\nThomas Petzoldt [aut, ths, cre]\n(<https://orcid.org/0000-0002-4951-6468>)",
    "url": "http://qualV.R-Forge.R-Project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "CMAE"
      ],
      [
        "CMSE"
      ],
      [
        "compareME"
      ],
      [
        "EF"
      ],
      [
        "f.curve"
      ],
      [
        "f.level"
      ],
      [
        "f.slope"
      ],
      [
        "f.steep"
      ],
      [
        "generalME"
      ],
      [
        "GRI"
      ],
      [
        "LCS"
      ],
      [
        "MAE"
      ],
      [
        "MAGE"
      ],
      [
        "MALE"
      ],
      [
        "MAOE"
      ],
      [
        "MAPE"
      ],
      [
        "MSE"
      ],
      [
        "MSLE"
      ],
      [
        "MSOE"
      ],
      [
        "plot.qvalLCS"
      ],
      [
        "plot.timeTransME"
      ],
      [
        "print.compareME"
      ],
      [
        "print.qvalLCS"
      ],
      [
        "print.timeTransME"
      ],
      [
        "qvalLCS"
      ],
      [
        "RCMSE"
      ],
      [
        "RMSE"
      ],
      [
        "RMSGE"
      ],
      [
        "RMSLE"
      ],
      [
        "RMSOE"
      ],
      [
        "RSMSE"
      ],
      [
        "RSMSGE"
      ],
      [
        "RSMSLE"
      ],
      [
        "SMAE"
      ],
      [
        "SMAGE"
      ],
      [
        "SMALE"
      ],
      [
        "SMSE"
      ],
      [
        "SMSLE"
      ],
      [
        "summary.compareME"
      ],
      [
        "summary.qvalLCS"
      ],
      [
        "summary.timeTransME"
      ],
      [
        "timeTransME"
      ],
      [
        "transBeta"
      ],
      [
        "transBezier"
      ],
      [
        "transSimplex"
      ]
    ],
    "topics": [],
    "score": 5.4739,
    "stars": 1,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "qualV Qualitative Validation Methods Qualitative methods for the validation of dynamic models.\nIt contains (i) an orthogonal set of deviance measures for\nabsolute, relative and ordinal scale and (ii) approaches\naccounting for time shifts. The first approach transforms time\nto take time delays and speed differences into account. The\nsecond divides the time series into interval units according to\ntheir main features and finds the longest common subsequence\n(LCS) using a dynamic programming algorithm. CMAE CMSE compareME EF f.curve f.level f.slope f.steep generalME GRI LCS MAE MAGE MALE MAOE MAPE MSE MSLE MSOE plot.qvalLCS plot.timeTransME print.compareME print.qvalLCS print.timeTransME qvalLCS RCMSE RMSE RMSGE RMSLE RMSOE RSMSE RSMSGE RSMSLE SMAE SMAGE SMALE SMSE SMSLE summary.compareME summary.qvalLCS summary.timeTransME timeTransME transBeta transBezier transSimplex "
  },
  {
    "id": 1427,
    "package_name": "wateRinfo",
    "title": "Download Time Series Data from Waterinfo.be",
    "description": "wateRinfo facilitates access to waterinfo.be\n(<https://www.waterinfo.be>), a website managed by the Flanders\nEnvironment Agency (VMM) and Flanders Hydraulics Research. The\nwebsite provides access to real-time water and weather related\nenvironmental variables for Flanders (Belgium), such as\nrainfall, air pressure, discharge, and water level. The package\nprovides functions to search for stations and variables, and\ndownload time series.",
    "version": "0.3.0.9065",
    "maintainer": "Stijn Van Hoey <stijnvanhoey@gmail.com>",
    "author": "Stijn Van Hoey [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-6413-3185>),\nWillem Maetens [ctb],\nPeter Desmet [ctb] (ORCID: <https://orcid.org/0000-0002-8442-8025>),\nResearch Institute for Nature and Forest (INBO) [cph]\n(https://www.vlaanderen.be/inbo/en-gb/),\nLifeWatch Belgium [fnd] (https://lifewatch.be)",
    "url": "https://github.com/ropensci/wateRinfo,\nhttps://docs.ropensci.org/wateRinfo",
    "bug_reports": "https://github.com/ropensci/wateRinfo/issues",
    "repository": "",
    "exports": [
      [
        "check_period_format"
      ],
      [
        "expires.in"
      ],
      [
        "get_stations"
      ],
      [
        "get_timeseries_tsid"
      ],
      [
        "get_token"
      ],
      [
        "get_variables"
      ],
      [
        "is_supported_variable"
      ],
      [
        "is.expired"
      ],
      [
        "resolve_datasource"
      ],
      [
        "resolve_timeseriesgroupid"
      ],
      [
        "show.token"
      ],
      [
        "supported_frequencies"
      ],
      [
        "supported_variables"
      ]
    ],
    "topics": [
      [
        "api"
      ],
      [
        "climate"
      ],
      [
        "lifewatch"
      ],
      [
        "open-science"
      ],
      [
        "oscibio"
      ],
      [
        "ropensci"
      ],
      [
        "water"
      ],
      [
        "weather"
      ]
    ],
    "score": 5.4558,
    "stars": 14,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "wateRinfo Download Time Series Data from Waterinfo.be wateRinfo facilitates access to waterinfo.be\n(<https://www.waterinfo.be>), a website managed by the Flanders\nEnvironment Agency (VMM) and Flanders Hydraulics Research. The\nwebsite provides access to real-time water and weather related\nenvironmental variables for Flanders (Belgium), such as\nrainfall, air pressure, discharge, and water level. The package\nprovides functions to search for stations and variables, and\ndownload time series. check_period_format expires.in get_stations get_timeseries_tsid get_token get_variables is_supported_variable is.expired resolve_datasource resolve_timeseriesgroupid show.token supported_frequencies supported_variables api climate lifewatch open-science oscibio ropensci water weather"
  },
  {
    "id": 587,
    "package_name": "forecast.vocs",
    "title": "Forecast Case and Sequence Notifications using Variant of\nConcern Strain Dynamics",
    "description": "Contains models and tools to produce short-term forecasts\nfor both case and sequence notifications assuming circulation\nof either one or two variants. Tools are also provided to allow\nthe evaluation of the use of sequence data for short-term\nforecasts in both real-world settings and in user generated\nscenarios.",
    "version": "0.9.0",
    "maintainer": "Sam Abbott <sam.abbott@lshtm.ac.uk>",
    "author": "Sam Abbott [aut, cre] (ORCID: <https://orcid.org/0000-0001-8057-8037>),\nSebastian Funk [ctb] (ORCID: <https://orcid.org/0000-0002-2842-3406>)",
    "url": "https://epiforecasts.io/forecast.vocs/,\nhttps://github.com/epiforecasts/forecast.vocs/",
    "bug_reports": "https://github.com/epiforecasts/forecast.vocs/issues/",
    "repository": "",
    "exports": [
      [
        "add_forecast_dates"
      ],
      [
        "bp_launch_shinystan"
      ],
      [
        "check_observations"
      ],
      [
        "define_scenarios"
      ],
      [
        "extract_forecast_dates"
      ],
      [
        "filter_by_availability"
      ],
      [
        "forecast"
      ],
      [
        "forecast_across_dates"
      ],
      [
        "forecast_across_scenarios"
      ],
      [
        "fv_as_data_list"
      ],
      [
        "fv_dow_period"
      ],
      [
        "fv_example"
      ],
      [
        "fv_extract_forecast"
      ],
      [
        "fv_inits"
      ],
      [
        "fv_model"
      ],
      [
        "fv_posterior"
      ],
      [
        "fv_sample"
      ],
      [
        "fv_score_forecast"
      ],
      [
        "fv_tidy_posterior"
      ],
      [
        "generate_obs"
      ],
      [
        "generate_obs_scenario"
      ],
      [
        "latest_obs"
      ],
      [
        "plot_cases"
      ],
      [
        "plot_default"
      ],
      [
        "plot_growth"
      ],
      [
        "plot_posterior"
      ],
      [
        "plot_rt"
      ],
      [
        "plot_theme"
      ],
      [
        "plot_voc_advantage"
      ],
      [
        "plot_voc_frac"
      ],
      [
        "quantiles_to_long"
      ],
      [
        "sample_sequences"
      ],
      [
        "save_plots"
      ],
      [
        "unnest_posterior"
      ],
      [
        "update_obs_availability"
      ],
      [
        "update_voc_label"
      ]
    ],
    "topics": [],
    "score": 5.2455,
    "stars": 8,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "forecast.vocs Forecast Case and Sequence Notifications using Variant of\nConcern Strain Dynamics Contains models and tools to produce short-term forecasts\nfor both case and sequence notifications assuming circulation\nof either one or two variants. Tools are also provided to allow\nthe evaluation of the use of sequence data for short-term\nforecasts in both real-world settings and in user generated\nscenarios. add_forecast_dates bp_launch_shinystan check_observations define_scenarios extract_forecast_dates filter_by_availability forecast forecast_across_dates forecast_across_scenarios fv_as_data_list fv_dow_period fv_example fv_extract_forecast fv_inits fv_model fv_posterior fv_sample fv_score_forecast fv_tidy_posterior generate_obs generate_obs_scenario latest_obs plot_cases plot_default plot_growth plot_posterior plot_rt plot_theme plot_voc_advantage plot_voc_frac quantiles_to_long sample_sequences save_plots unnest_posterior update_obs_availability update_voc_label "
  },
  {
    "id": 776,
    "package_name": "lopensemble",
    "title": "Create Mixture Models From Predictive Samples",
    "description": "The `lopensemble` package provides an easy way to combine\npredictions from individual time series or panel data models to\nan ensemble. `lopensemble` stacks (Yuling Yao, Aki Vehtari,\nDaniel Simpson, and Andrew Gelman (2018)\n<doi:10.1214/17-BA1091>) Models according to the Continuous\nRanked Probability Score (CRPS) (Tilmann Gneiting & Adrian E\nRaftery (2007) <doi:10.1198/016214506000001437>) over k-step\nahead predictions. It is therefore especially suited for\ntimeseries and panel data. A function for leave-one-out CRPS\nmay be added in the future. Predictions need to be predictive\ndistributions represented by predictive samples. Usually, these\nwill be sets of posterior predictive simulation draws generated\nby an MCMC algorithm. Given some training data with true\nobserved values as well as predictive samples generated from\ndifferent models, `crps_weights` finds the optimal (in the\nsense of minimizing expected cross-validation predictive error)\nweights to form an ensemble from these models. Using these\nweights, `mixture_from_samples` can then provide samples from\nthe optimal model mixture by drawing from the predictice\nsamples of the individual models in the correct proportion.\nThis gives a mixture model solely based on predictive samples\nand is in this regard superior to other ensembling techniques\nlike Bayesian Model Averaging.",
    "version": "0.1.2",
    "maintainer": "Nikos Bosse <nikosbosse@gmail.com>",
    "author": "Nikos Bosse [aut, cre] (ORCID: <https://orcid.org/0000-0002-7750-5280>),\nYuling Yao [aut],\nSam Abbott [aut] (ORCID: <https://orcid.org/0000-0001-8057-8037>),\nSebastian Funk [aut] (ORCID: <https://orcid.org/0000-0002-2842-3406>)",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "crps_weights"
      ],
      [
        "mixture_from_samples"
      ]
    ],
    "topics": [
      [
        "crps"
      ],
      [
        "ensembles"
      ],
      [
        "forecasting"
      ],
      [
        "stacking"
      ]
    ],
    "score": 5.0334,
    "stars": 6,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "lopensemble Create Mixture Models From Predictive Samples The `lopensemble` package provides an easy way to combine\npredictions from individual time series or panel data models to\nan ensemble. `lopensemble` stacks (Yuling Yao, Aki Vehtari,\nDaniel Simpson, and Andrew Gelman (2018)\n<doi:10.1214/17-BA1091>) Models according to the Continuous\nRanked Probability Score (CRPS) (Tilmann Gneiting & Adrian E\nRaftery (2007) <doi:10.1198/016214506000001437>) over k-step\nahead predictions. It is therefore especially suited for\ntimeseries and panel data. A function for leave-one-out CRPS\nmay be added in the future. Predictions need to be predictive\ndistributions represented by predictive samples. Usually, these\nwill be sets of posterior predictive simulation draws generated\nby an MCMC algorithm. Given some training data with true\nobserved values as well as predictive samples generated from\ndifferent models, `crps_weights` finds the optimal (in the\nsense of minimizing expected cross-validation predictive error)\nweights to form an ensemble from these models. Using these\nweights, `mixture_from_samples` can then provide samples from\nthe optimal model mixture by drawing from the predictice\nsamples of the individual models in the correct proportion.\nThis gives a mixture model solely based on predictive samples\nand is in this regard superior to other ensembling techniques\nlike Bayesian Model Averaging. crps_weights mixture_from_samples crps ensembles forecasting stacking"
  },
  {
    "id": 697,
    "package_name": "hydroscoper",
    "title": "Interface to the Greek National Data Bank for\nHydrometeorological Information",
    "description": "R interface to the Greek National Data Bank for\nHydrological and Meteorological Information. It covers\nHydroscope's data sources and provides functions to\ntransliterate, translate and download them into tidy\ndataframes.",
    "version": "1.7.0",
    "maintainer": "Konstantinos Vantas <kon.vantas@gmail.com>",
    "author": "Konstantinos Vantas [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-6387-8791>),\nSharla Gelfand [ctb, rev] (Sharla Gelfand reviewed the package for\nrOpenSci, see https://github.com/ropensci/onboarding/issues/185),\nTim Trice [rev] (Tim Trice reviewed the package for rOpenSci, see\nhttps://github.com/ropensci/onboarding/issues/185)",
    "url": "https://github.com/ropensci/hydroscoper,\nhttps://docs.ropensci.org/hydroscoper/",
    "bug_reports": "https://github.com/ropensci/hydroscoper/issues",
    "repository": "",
    "exports": [
      [
        "find_stations"
      ],
      [
        "get_data"
      ],
      [
        "get_database"
      ],
      [
        "get_instruments"
      ],
      [
        "get_instruments_type"
      ],
      [
        "get_owners"
      ],
      [
        "get_political_divisions"
      ],
      [
        "get_station_type"
      ],
      [
        "get_stations"
      ],
      [
        "get_time_steps"
      ],
      [
        "get_timeseries"
      ],
      [
        "get_units_of_measurement"
      ],
      [
        "get_variables"
      ],
      [
        "get_water_basins"
      ],
      [
        "get_water_divisions"
      ],
      [
        "hydro_coords"
      ],
      [
        "hydro_translate"
      ]
    ],
    "topics": [
      [
        "climate"
      ],
      [
        "greece"
      ],
      [
        "hydrology"
      ],
      [
        "hydrometeorology"
      ],
      [
        "hydroscope"
      ],
      [
        "meteorological-data"
      ],
      [
        "meteorological-stations"
      ],
      [
        "peer-reviewed"
      ],
      [
        "tidy-data"
      ],
      [
        "time-series"
      ],
      [
        "water-resources"
      ]
    ],
    "score": 5.0154,
    "stars": 14,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "hydroscoper Interface to the Greek National Data Bank for\nHydrometeorological Information R interface to the Greek National Data Bank for\nHydrological and Meteorological Information. It covers\nHydroscope's data sources and provides functions to\ntransliterate, translate and download them into tidy\ndataframes. find_stations get_data get_database get_instruments get_instruments_type get_owners get_political_divisions get_station_type get_stations get_time_steps get_timeseries get_units_of_measurement get_variables get_water_basins get_water_divisions hydro_coords hydro_translate climate greece hydrology hydrometeorology hydroscope meteorological-data meteorological-stations peer-reviewed tidy-data time-series water-resources"
  },
  {
    "id": 50,
    "package_name": "EpiSoon",
    "title": "Forecast Cases Using Reproduction Numbers",
    "description": "To forecast the time-varying reproduction number and use\nthis to forecast reported case counts. Includes tools to\nevaluate a range of models across samples and time series using\nproper scoring rules.",
    "version": "0.3.1",
    "maintainer": "Sam Abbott <contact@samabbott.co.uk>",
    "author": "Sam Abbott [aut, cre] (ORCID: <https://orcid.org/0000-0001-8057-8037>),\nNikos Bosse [aut],\nJoel Hellewell [aut] (ORCID: <https://orcid.org/0000-0003-2683-0849>),\nKatharine Sherratt [aut],\nJames Munday [aut],\nRobin Thompson [aut],\nAurelien Chateigner [aut],\nSylvain Mareschal [aut],\nAndrea Rau [aut],\nNathalie Vialaneix [aut],\nMichael DeWitt [aut] (ORCID: <https://orcid.org/0000-0001-8940-1967>),\nSebastian Funk [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "brms_model"
      ],
      [
        "bsts_model"
      ],
      [
        "compare_models"
      ],
      [
        "compare_timeseries"
      ],
      [
        "draw_from_si_prob"
      ],
      [
        "evaluate_model"
      ],
      [
        "fable_model"
      ],
      [
        "forecast_cases"
      ],
      [
        "forecast_cases_directly"
      ],
      [
        "forecast_model"
      ],
      [
        "forecast_rt"
      ],
      [
        "forecastHybrid_model"
      ],
      [
        "iterative_case_forecast"
      ],
      [
        "iterative_direct_case_forecast"
      ],
      [
        "iterative_rt_forecast"
      ],
      [
        "lopensemble_model"
      ],
      [
        "plot_compare_timeseries"
      ],
      [
        "plot_forecast"
      ],
      [
        "plot_forecast_evaluation"
      ],
      [
        "plot_scores"
      ],
      [
        "predict_cases"
      ],
      [
        "predict_current_cases"
      ],
      [
        "score_case_forecast"
      ],
      [
        "score_forecast"
      ],
      [
        "summarise_case_forecast"
      ],
      [
        "summarise_forecast"
      ],
      [
        "summarise_scores"
      ]
    ],
    "topics": [
      [
        "case-forecasts"
      ],
      [
        "forecasts"
      ]
    ],
    "score": 4.7871,
    "stars": 7,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "EpiSoon Forecast Cases Using Reproduction Numbers To forecast the time-varying reproduction number and use\nthis to forecast reported case counts. Includes tools to\nevaluate a range of models across samples and time series using\nproper scoring rules. %>% brms_model bsts_model compare_models compare_timeseries draw_from_si_prob evaluate_model fable_model forecast_cases forecast_cases_directly forecast_model forecast_rt forecastHybrid_model iterative_case_forecast iterative_direct_case_forecast iterative_rt_forecast lopensemble_model plot_compare_timeseries plot_forecast plot_forecast_evaluation plot_scores predict_cases predict_current_cases score_case_forecast score_forecast summarise_case_forecast summarise_forecast summarise_scores case-forecasts forecasts"
  },
  {
    "id": 335,
    "package_name": "camsRad",
    "title": "Client for CAMS Radiation Service",
    "description": "Copernicus Atmosphere Monitoring Service (CAMS) Radiation\nService provides time series of global, direct, and diffuse\nirradiations on horizontal surface, and direct irradiation on\nnormal plane for the actual weather conditions as well as for\nclear-sky conditions. The geographical coverage is the\nfield-of-view of the Meteosat satellite, roughly speaking\nEurope, Africa, Atlantic Ocean, Middle East. The time coverage\nof data is from 2004-02-01 up to 2 days ago. Data are available\nwith a time step ranging from 15 min to 1 month. For license\nterms and to create an account, please see\n<http://www.soda-pro.com/web-services/radiation/cams-radiation-service>.",
    "version": "0.3.0.9001",
    "maintainer": "Lukas Lundstrom <lukas.rokka@gmail.com>",
    "author": "Lukas Lundstrom [aut, cre]",
    "url": "https://docs.ropensci.org/camsRad,\nhttps://github.com/ropensci/camsRad",
    "bug_reports": "https://github.com/ropensci/camsRad/issues",
    "repository": "",
    "exports": [
      [
        "cams_api"
      ],
      [
        "cams_get_mcclear"
      ],
      [
        "cams_get_radiation"
      ],
      [
        "cams_set_user"
      ]
    ],
    "topics": [
      [
        "peer-reviewed"
      ]
    ],
    "score": 4.6946,
    "stars": 9,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "camsRad Client for CAMS Radiation Service Copernicus Atmosphere Monitoring Service (CAMS) Radiation\nService provides time series of global, direct, and diffuse\nirradiations on horizontal surface, and direct irradiation on\nnormal plane for the actual weather conditions as well as for\nclear-sky conditions. The geographical coverage is the\nfield-of-view of the Meteosat satellite, roughly speaking\nEurope, Africa, Atlantic Ocean, Middle East. The time coverage\nof data is from 2004-02-01 up to 2 days ago. Data are available\nwith a time step ranging from 15 min to 1 month. For license\nterms and to create an account, please see\n<http://www.soda-pro.com/web-services/radiation/cams-radiation-service>. cams_api cams_get_mcclear cams_get_radiation cams_set_user peer-reviewed"
  },
  {
    "id": 876,
    "package_name": "nfidd",
    "title": "Material to support course on nowcasting and forecasting of\ninfectious disease dynamics",
    "description": "Resources to support a short course on nowcasting and\nforecasting of infectious disease dynamics.",
    "version": "1.1.2.9000",
    "maintainer": "NFIDD course contributors <epiforecasts@gmail.com>",
    "author": "NFIDD course contributors [cre, aut]",
    "url": "https://github.com/nfidd/nfidd",
    "bug_reports": "https://github.com/nfidd/nfidd/issues",
    "repository": "",
    "exports": [
      [
        "add_delays"
      ],
      [
        "censored_delay_pmf"
      ],
      [
        "condition_onsets_by_report"
      ],
      [
        "convolve_with_delay"
      ],
      [
        "geometric_diff_ar"
      ],
      [
        "geometric_random_walk"
      ],
      [
        "make_daily_infections"
      ],
      [
        "make_gen_time_pmf"
      ],
      [
        "make_ip_pmf"
      ],
      [
        "nfidd_cmdstan_model"
      ],
      [
        "nfidd_load_stan_functions"
      ],
      [
        "nfidd_sample"
      ],
      [
        "nfidd_stan_function_files"
      ],
      [
        "nfidd_stan_functions"
      ],
      [
        "nfidd_stan_models"
      ],
      [
        "nfidd_stan_path"
      ],
      [
        "renewal"
      ],
      [
        "simulate_onsets"
      ],
      [
        "summarise_lognormal"
      ]
    ],
    "topics": [
      [
        "delay-estimation"
      ],
      [
        "epidemics"
      ],
      [
        "forecasting"
      ],
      [
        "infectious-disease-dynamics"
      ],
      [
        "learning"
      ],
      [
        "nowcasting"
      ],
      [
        "outbreak-analysis"
      ],
      [
        "outbreaks"
      ]
    ],
    "score": 4.4393,
    "stars": 22,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "nfidd Material to support course on nowcasting and forecasting of\ninfectious disease dynamics Resources to support a short course on nowcasting and\nforecasting of infectious disease dynamics. add_delays censored_delay_pmf condition_onsets_by_report convolve_with_delay geometric_diff_ar geometric_random_walk make_daily_infections make_gen_time_pmf make_ip_pmf nfidd_cmdstan_model nfidd_load_stan_functions nfidd_sample nfidd_stan_function_files nfidd_stan_functions nfidd_stan_models nfidd_stan_path renewal simulate_onsets summarise_lognormal delay-estimation epidemics forecasting infectious-disease-dynamics learning nowcasting outbreak-analysis outbreaks"
  },
  {
    "id": 1328,
    "package_name": "tframe",
    "title": "Time Frame Coding Kernel",
    "description": "A kernel of functions for programming time series methods\nin a way that is relatively independently of the representation\nof time. Also provides plotting, time windowing, and some other\nutility functions which are specifically intended for time\nseries. See the Guide distributed as a vignette, or\n'?tframe.Intro' for more details. (User utilities are in\npackage 'tfplot'.)",
    "version": "2019.6-1",
    "maintainer": "Paul Gilbert <pgilbert.ttv9z@ncf.ca>",
    "author": "Paul Gilbert <pgilbert.ttv9z@ncf.ca>",
    "url": "http://tsanalysis.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "as.tframe"
      ],
      [
        "checktframeConsistent"
      ],
      [
        "classed"
      ],
      [
        "earliestEnd"
      ],
      [
        "earliestEndIndex"
      ],
      [
        "earliestStart"
      ],
      [
        "earliestStartIndex"
      ],
      [
        "is.tframe"
      ],
      [
        "is.tframed"
      ],
      [
        "latestEnd"
      ],
      [
        "latestEndIndex"
      ],
      [
        "latestStart"
      ],
      [
        "latestStartIndex"
      ],
      [
        "nseries"
      ],
      [
        "selectSeries"
      ],
      [
        "seqN"
      ],
      [
        "seriesNames"
      ],
      [
        "seriesNames<-"
      ],
      [
        "splice"
      ],
      [
        "tbind"
      ],
      [
        "testEqual"
      ],
      [
        "testEqualtframes"
      ],
      [
        "tfend"
      ],
      [
        "tfExpand"
      ],
      [
        "tffrequency"
      ],
      [
        "tfL"
      ],
      [
        "tfprint"
      ],
      [
        "tframe"
      ],
      [
        "tframe<-"
      ],
      [
        "tframed"
      ],
      [
        "tfSet"
      ],
      [
        "tfspan"
      ],
      [
        "tfstart"
      ],
      [
        "tftime"
      ],
      [
        "tfTruncate"
      ],
      [
        "tfwindow"
      ],
      [
        "Tobs"
      ],
      [
        "trimNA"
      ]
    ],
    "topics": [],
    "score": 4.0212,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "tframe Time Frame Coding Kernel A kernel of functions for programming time series methods\nin a way that is relatively independently of the representation\nof time. Also provides plotting, time windowing, and some other\nutility functions which are specifically intended for time\nseries. See the Guide distributed as a vignette, or\n'?tframe.Intro' for more details. (User utilities are in\npackage 'tfplot'.) as.tframe checktframeConsistent classed earliestEnd earliestEndIndex earliestStart earliestStartIndex is.tframe is.tframed latestEnd latestEndIndex latestStart latestStartIndex nseries selectSeries seqN seriesNames seriesNames<- splice tbind testEqual testEqualtframes tfend tfExpand tffrequency tfL tfprint tframe tframe<- tframed tfSet tfspan tfstart tftime tfTruncate tfwindow Tobs trimNA "
  },
  {
    "id": 339,
    "package_name": "cardidates",
    "title": "Identification of Cardinal Dates in Ecological Time Series",
    "description": "Identification of cardinal dates (begin, time of maximum,\nend of mass developments) in ecological time series using\nfitted Weibull functions.",
    "version": "0.4.9",
    "maintainer": "Thomas Petzoldt <thomas.petzoldt@tu-dresden.de>",
    "author": "Susanne Rolinski [aut], Ren\u00e9 Sachse [aut], Thomas Petzoldt\n[aut, cre]",
    "url": "http://cardidates.r-forge.r-project.org",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "aweibull4"
      ],
      [
        "aweibull6"
      ],
      [
        "aweibull7"
      ],
      [
        "CDW"
      ],
      [
        "fitweibull4"
      ],
      [
        "fitweibull6"
      ],
      [
        "fweibull4"
      ],
      [
        "fweibull6"
      ],
      [
        "fweibull7"
      ],
      [
        "metaCDW"
      ],
      [
        "peakwindow"
      ]
    ],
    "topics": [],
    "score": 3.3424,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "cardidates Identification of Cardinal Dates in Ecological Time Series Identification of cardinal dates (begin, time of maximum,\nend of mass developments) in ecological time series using\nfitted Weibull functions. aweibull4 aweibull6 aweibull7 CDW fitweibull4 fitweibull6 fweibull4 fweibull6 fweibull7 metaCDW peakwindow "
  },
  {
    "id": 1037,
    "package_name": "qrensemble",
    "title": "Forecast ensembles using Quantile Regression Average (QRA)",
    "description": "Performs quantile regression average",
    "version": "0.1.3",
    "maintainer": "Sebastian Funk <sebastian.funk@lshtm.ac.uk>",
    "author": "Sebastian Funk [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-2842-3406>),\nSam Abbott [aut] (ORCID: <https://orcid.org/0000-0001-8057-8037>)",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "qra"
      ]
    ],
    "topics": [],
    "score": 3.1761,
    "stars": 3,
    "primary_category": "epidemiology",
    "source_universe": "epiforecasts",
    "search_text": "qrensemble Forecast ensembles using Quantile Regression Average (QRA) Performs quantile regression average qra "
  },
  {
    "id": 1146,
    "package_name": "rrricanesdata",
    "title": "Data for Atlantic and east Pacific tropical cyclones since 1998",
    "description": "Includes storm discussions, forecast/advisories, public\nadvisories, wind speed probabilities, strike probabilities and\nmore. This package can be used along with rrricanes (>=\n0.2.0-6). Data is considered public domain via the National\nHurricane Center.",
    "version": "0.2.1",
    "maintainer": "Tim Trice <tim.trice@gmail.com>",
    "author": "Tim Trice [aut, cre]",
    "url": "https://docs.ropensci.org/rrricanesdata,\nhttps://github.com/ropensci/rrricanesdata",
    "bug_reports": "https://github.com/ropensci/rrricanesdata/issues",
    "repository": "",
    "exports": [],
    "topics": [
      [
        "weather"
      ]
    ],
    "score": 2.6385,
    "stars": 3,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rrricanesdata Data for Atlantic and east Pacific tropical cyclones since 1998 Includes storm discussions, forecast/advisories, public\nadvisories, wind speed probabilities, strike probabilities and\nmore. This package can be used along with rrricanes (>=\n0.2.0-6). Data is considered public domain via the National\nHurricane Center.  weather"
  },
  {
    "id": 258,
    "package_name": "assessr",
    "title": "Performance metrics for probabilitic forecasts",
    "description": "This package implements various metrics for assessing the\nperformance of probabilitic forecasts.",
    "version": "1.0.0",
    "maintainer": "Sangeeta Bhatia <sangeetabhatia03@gmail.com>",
    "author": "Sangeeta Bhatia [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "abs_madm"
      ],
      [
        "avg_residual"
      ],
      [
        "bias"
      ],
      [
        "mae"
      ],
      [
        "prop_in_ci"
      ],
      [
        "rel_madm"
      ],
      [
        "rel_mae"
      ],
      [
        "rel_mean_dvtn"
      ],
      [
        "rel_mse"
      ]
    ],
    "topics": [],
    "score": 2.3802,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "assessr Performance metrics for probabilitic forecasts This package implements various metrics for assessing the\nperformance of probabilitic forecasts. abs_madm avg_residual bias mae prop_in_ci rel_madm rel_mae rel_mean_dvtn rel_mse "
  },
  {
    "id": 1113,
    "package_name": "rincewind",
    "title": "Utilities for processing forecasts matrices",
    "description": "This package contains utility functions for processing\nforecasts matrices.",
    "version": "1.4.7",
    "maintainer": "Sangeeta Bhatia <s.bhatia@imperial.ac.uk>",
    "author": "Sangeeta Bhatia [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "age_wtd_ifr"
      ],
      [
        "all_forecasts_calendar"
      ],
      [
        "all_metrics"
      ],
      [
        "alternating_palette"
      ],
      [
        "assign_epidemic_phase"
      ],
      [
        "assign_epidemic_phase2"
      ],
      [
        "cap_predictions"
      ],
      [
        "continent_colorscale"
      ],
      [
        "country_to_continent"
      ],
      [
        "customise_for_rows"
      ],
      [
        "daily_to_weekly"
      ],
      [
        "deaths_threshold"
      ],
      [
        "empirical_probability"
      ],
      [
        "extract_predictions_qntls"
      ],
      [
        "nice_country_name"
      ],
      [
        "overlaps"
      ],
      [
        "plot_projections"
      ],
      [
        "poisson_probability"
      ],
      [
        "pool_predictions_weighted"
      ],
      [
        "restimates_linegraph"
      ],
      [
        "round_and_format"
      ],
      [
        "save_multiple"
      ],
      [
        "scale_date_manuscript"
      ],
      [
        "theme_manuscript"
      ],
      [
        "ts_to_incid"
      ]
    ],
    "topics": [],
    "score": 1,
    "stars": 1,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "rincewind Utilities for processing forecasts matrices This package contains utility functions for processing\nforecasts matrices. age_wtd_ifr all_forecasts_calendar all_metrics alternating_palette assign_epidemic_phase assign_epidemic_phase2 cap_predictions continent_colorscale country_to_continent customise_for_rows daily_to_weekly deaths_threshold empirical_probability extract_predictions_qntls nice_country_name overlaps plot_projections poisson_probability pool_predictions_weighted restimates_linegraph round_and_format save_multiple scale_date_manuscript theme_manuscript ts_to_incid "
  },
  {
    "id": 12,
    "package_name": "CDSim",
    "title": "Simulating Climate Data for Research and Modelling",
    "description": "Generate synthetic station-based monthly climate time-series including\n    temperature and rainfall, export to Network Common Data Form (NetCDF), \n    and provide visualization helpers for climate workflows. The approach is \n    inspired by statistical weather generator concepts described in Wilks (1992)\n    <doi:10.1016/S0168-1923(99)00037-4> and Richardson (1981) <doi:10.1029/WR017i001p00182>.",
    "version": "0.1.1",
    "maintainer": "Isaac Osei <ikemillar65@gmail.com>",
    "author": "Isaac Osei [aut, cre],\n  Acheampong Baafi-Adomako [aut],\n  Sivaparvathi Dusari [aut]",
    "url": "https://github.com/ikemillar/CDSim",
    "bug_reports": "https://github.com/ikemillar/CDSim/issues",
    "repository": "https://cran.r-project.org/package=CDSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CDSim Simulating Climate Data for Research and Modelling Generate synthetic station-based monthly climate time-series including\n    temperature and rainfall, export to Network Common Data Form (NetCDF), \n    and provide visualization helpers for climate workflows. The approach is \n    inspired by statistical weather generator concepts described in Wilks (1992)\n    <doi:10.1016/S0168-1923(99)00037-4> and Richardson (1981) <doi:10.1029/WR017i001p00182>.  "
  },
  {
    "id": 17,
    "package_name": "CepReg",
    "title": "A Cepstral Model for Covariate-Dependent Time Series",
    "description": "Modeling associations between covariates and power spectra of replicated time series using a cepstral-based semiparametric framework. Implements a fast two-stage estimation procedure via Whittle likelihood and multivariate regression.The methodology is based on Li and Dong (2025) <doi:10.1080/10618600.2025.2473936>. ",
    "version": "0.1.3",
    "maintainer": "Qi Xia <xiaqi1010@gmail.com>",
    "author": "Qi Xia [aut, cre],\n  Zeda Li [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CepReg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CepReg A Cepstral Model for Covariate-Dependent Time Series Modeling associations between covariates and power spectra of replicated time series using a cepstral-based semiparametric framework. Implements a fast two-stage estimation procedure via Whittle likelihood and multivariate regression.The methodology is based on Li and Dong (2025) <doi:10.1080/10618600.2025.2473936>.   "
  },
  {
    "id": 62,
    "package_name": "ForecastFramework",
    "title": "A Basis for Modular Model Creation",
    "description": "Create modular models.  Quickly prototype models whose input includes (multiple) time series data.  Create pieces of model use cases separately, and swap out particular models as desired. Create modeling competitions, data processing pipelines, and re-useable models.",
    "version": "0.10.2",
    "maintainer": "Joshua Kaminsky <jkaminsky@jhu.edu>",
    "author": "",
    "url": "https://github.com/HopkinsIDD/ForecastFramework",
    "bug_reports": "https://github.com/HopkinsIDD/ForecastFramework/issues",
    "repository": "https://github.com/HopkinsIDD/ForecastFramework",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 12,
    "primary_category": "epidemiology",
    "source_universe": "github:HopkinsIDD",
    "search_text": "ForecastFramework A Basis for Modular Model Creation Create modular models.  Quickly prototype models whose input includes (multiple) time series data.  Create pieces of model use cases separately, and swap out particular models as desired. Create modeling competitions, data processing pipelines, and re-useable models.  "
  },
  {
    "id": 63,
    "package_name": "GACE",
    "title": "Generalized Adaptive Capped Estimator for Time Series\nForecasting",
    "description": "\n    Provides deterministic forecasting for weekly, monthly, quarterly, and yearly\n    time series using the Generalized Adaptive Capped Estimator. The method\n    includes preprocessing for missing and extreme values, extraction of multiple\n    growth components (including long-term, short-term, rolling, and drift-based\n    signals), volatility-aware asymmetric capping, optional seasonal adjustment\n    via damped and normalized seasonal factors, and a recursive forecast\n    formulation with moderated growth. The package includes a user-facing\n    forecasting interface and a plotting helper for visualization. Related\n    forecasting background is discussed in Hyndman and Athanasopoulos (2021)\n    <https://otexts.com/fpp3/> and Hyndman and Khandakar (2008)\n    <doi:10.18637/jss.v027.i03>. The method extends classical extrapolative\n    forecasting approaches and is suited for operational and business planning\n    contexts where stability and interpretability are important.",
    "version": "1.0.0",
    "maintainer": "Vinodhkumar Gunasekaran <vinoalles@gmail.com>",
    "author": "Vinodhkumar Gunasekaran [aut, cre]",
    "url": "https://github.com/vinoalles/GACE",
    "bug_reports": "https://github.com/vinoalles/GACE/issues",
    "repository": "https://cran.r-project.org/package=GACE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GACE Generalized Adaptive Capped Estimator for Time Series\nForecasting \n    Provides deterministic forecasting for weekly, monthly, quarterly, and yearly\n    time series using the Generalized Adaptive Capped Estimator. The method\n    includes preprocessing for missing and extreme values, extraction of multiple\n    growth components (including long-term, short-term, rolling, and drift-based\n    signals), volatility-aware asymmetric capping, optional seasonal adjustment\n    via damped and normalized seasonal factors, and a recursive forecast\n    formulation with moderated growth. The package includes a user-facing\n    forecasting interface and a plotting helper for visualization. Related\n    forecasting background is discussed in Hyndman and Athanasopoulos (2021)\n    <https://otexts.com/fpp3/> and Hyndman and Khandakar (2008)\n    <doi:10.18637/jss.v027.i03>. The method extends classical extrapolative\n    forecasting approaches and is suited for operational and business planning\n    contexts where stability and interpretability are important.  "
  },
  {
    "id": 72,
    "package_name": "GpGp",
    "title": "Fast Gaussian Process Computation Using Vecchia's Approximation",
    "description": "Functions for fitting and doing predictions with\n    Gaussian process models using Vecchia's (1988) approximation. \n    Package also includes functions for reordering input locations, \n    finding ordered nearest neighbors (with help from 'FNN' package), \n    grouping operations, and conditional simulations.\n    Covariance functions for spatial and spatial-temporal data\n    on Euclidean domains and spheres are provided. The original \n    approximation is due to Vecchia (1988) \n    <http://www.jstor.org/stable/2345768>, and the reordering and\n    grouping methods are from Guinness (2018) \n    <doi:10.1080/00401706.2018.1437476>.\n    Model fitting employs a Fisher scoring algorithm described\n    in Guinness (2019) <doi:10.48550/arXiv.1905.08374>.",
    "version": "1.0.0",
    "maintainer": "Joseph Guinness <joeguinness@gmail.com>",
    "author": "Joseph Guinness [aut, cre],\n  Matthias Katzfuss [aut],\n  Youssef Fahmy [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GpGp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GpGp Fast Gaussian Process Computation Using Vecchia's Approximation Functions for fitting and doing predictions with\n    Gaussian process models using Vecchia's (1988) approximation. \n    Package also includes functions for reordering input locations, \n    finding ordered nearest neighbors (with help from 'FNN' package), \n    grouping operations, and conditional simulations.\n    Covariance functions for spatial and spatial-temporal data\n    on Euclidean domains and spheres are provided. The original \n    approximation is due to Vecchia (1988) \n    <http://www.jstor.org/stable/2345768>, and the reordering and\n    grouping methods are from Guinness (2018) \n    <doi:10.1080/00401706.2018.1437476>.\n    Model fitting employs a Fisher scoring algorithm described\n    in Guinness (2019) <doi:10.48550/arXiv.1905.08374>.  "
  },
  {
    "id": 96,
    "package_name": "NlinTS",
    "title": "Models for Non Linear Causality Detection in Time Series",
    "description": "Models for non-linear time series analysis and causality detection. The main functionalities of this package consist of an implementation of the classical causality test (C.W.J.Granger 1980) <doi:10.1016/0165-1889(80)90069-X>,  and a non-linear version of it based on feed-forward neural networks. This package contains also an implementation of the Transfer Entropy <doi:10.1103/PhysRevLett.85.461>, and the continuous Transfer Entropy using an approximation based on the k-nearest neighbors <doi:10.1103/PhysRevE.69.066138>. There are also some other useful tools, like the VARNN (Vector Auto-Regressive Neural Network) prediction model, the Augmented test of stationarity, and the discrete and continuous entropy and mutual information.",
    "version": "1.4.6",
    "maintainer": "Youssef Hmamouche <hmamoucheyussef@gmail.com>",
    "author": "Youssef Hmamouche [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NlinTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NlinTS Models for Non Linear Causality Detection in Time Series Models for non-linear time series analysis and causality detection. The main functionalities of this package consist of an implementation of the classical causality test (C.W.J.Granger 1980) <doi:10.1016/0165-1889(80)90069-X>,  and a non-linear version of it based on feed-forward neural networks. This package contains also an implementation of the Transfer Entropy <doi:10.1103/PhysRevLett.85.461>, and the continuous Transfer Entropy using an approximation based on the k-nearest neighbors <doi:10.1103/PhysRevE.69.066138>. There are also some other useful tools, like the VARNN (Vector Auto-Regressive Neural Network) prediction model, the Augmented test of stationarity, and the discrete and continuous entropy and mutual information.  "
  },
  {
    "id": 112,
    "package_name": "PanelMatch",
    "title": "Matching Methods for Causal Inference with Time-Series\nCross-Sectional Data",
    "description": "Implements a set of methodological tools\n\t     that enable researchers to apply matching methods to\n\t     time-series cross-sectional data. Imai, Kim, and Wang\n\t     (2023) <http://web.mit.edu/insong/www/pdf/tscs.pdf> \n\t     proposes a nonparametric generalization of the\n\t     difference-in-differences estimator, which does not rely\n\t     on the linearity assumption as often done in\n\t     practice. Researchers first select a method of matching\n\t     each treated observation for a given unit in a\n\t     particular time period with control observations from\n\t     other units in the same time period that have a similar\n\t     treatment and covariate history. These methods include\n\t     standard matching methods based on propensity score and\n\t     Mahalanobis distance, as well as weighting methods. Once \n\t     matching and refinement is done,  \n\t     treatment effects can be estimated with \n\t     standard errors. The package also offers diagnostics for researchers to assess the quality \n\t     of their results.",
    "version": "3.1.3",
    "maintainer": "In Song Kim <insong@mit.edu>",
    "author": "In Song Kim [aut, cre],\n  Adam Rauh [aut],\n  Erik Wang [aut],\n  Kosuke Imai [aut]",
    "url": "",
    "bug_reports": "https://github.com/insongkim/PanelMatch/issues",
    "repository": "https://cran.r-project.org/package=PanelMatch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PanelMatch Matching Methods for Causal Inference with Time-Series\nCross-Sectional Data Implements a set of methodological tools\n\t     that enable researchers to apply matching methods to\n\t     time-series cross-sectional data. Imai, Kim, and Wang\n\t     (2023) <http://web.mit.edu/insong/www/pdf/tscs.pdf> \n\t     proposes a nonparametric generalization of the\n\t     difference-in-differences estimator, which does not rely\n\t     on the linearity assumption as often done in\n\t     practice. Researchers first select a method of matching\n\t     each treated observation for a given unit in a\n\t     particular time period with control observations from\n\t     other units in the same time period that have a similar\n\t     treatment and covariate history. These methods include\n\t     standard matching methods based on propensity score and\n\t     Mahalanobis distance, as well as weighting methods. Once \n\t     matching and refinement is done,  \n\t     treatment effects can be estimated with \n\t     standard errors. The package also offers diagnostics for researchers to assess the quality \n\t     of their results.  "
  },
  {
    "id": 151,
    "package_name": "RPEIF",
    "title": "Computation and Plots of Influence Functions for Risk and\nPerformance Measures",
    "description": "Computes the influence functions time series of the returns for the risk and \n             performance measures as mentioned in Chen and Martin (2018) \n             <https://www.ssrn.com/abstract=3085672>, as well as in Zhang et al. (2019)\n             <https://www.ssrn.com/abstract=3415903>. Also evaluates estimators influence\n             functions at a set of parameter values and plots them to display the shapes of \n             the influence functions.",
    "version": "1.2.5",
    "maintainer": "Anthony Christidis <anthony.christidis@stat.ubc.ca>",
    "author": "Anthony Christidis [aut, cre],\n  Shengyu Zhang [aut],\n  Douglas Martin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RPEIF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RPEIF Computation and Plots of Influence Functions for Risk and\nPerformance Measures Computes the influence functions time series of the returns for the risk and \n             performance measures as mentioned in Chen and Martin (2018) \n             <https://www.ssrn.com/abstract=3085672>, as well as in Zhang et al. (2019)\n             <https://www.ssrn.com/abstract=3415903>. Also evaluates estimators influence\n             functions at a set of parameter values and plots them to display the shapes of \n             the influence functions.  "
  },
  {
    "id": 259,
    "package_name": "astsa",
    "title": "Applied Statistical Time Series Analysis",
    "description": "Contains data sets and scripts for analyzing time series in both the frequency and time domains including state space modeling as well as supporting the texts Time Series Analysis and Its Applications: With R Examples (5th ed), by R.H. Shumway and D.S. Stoffer. Springer Texts in Statistics, 2025, <DOI:10.1007/978-3-031-70584-7>, and Time Series: A Data Analysis Approach Using R (2nd ed). Chapman-Hall, 2026, <https://www.routledge.com/Time-Series-A-Data-Analysis-Approach-Using-R/Shumway-Stoffer/p/book/9781041031642>. Most scripts are designed to require minimal input to produce aesthetically pleasing output for ease of use in live demonstrations and course work.",
    "version": "2.4",
    "maintainer": "David Stoffer <stoffer@pitt.edu>",
    "author": "David Stoffer [aut, cre],\n  Nicky Poison [ctb, mus, spy]",
    "url": "https://dsstoffer.github.io/, https://nickpoison.github.io/",
    "bug_reports": "https://github.com/nickpoison/astsa/issues",
    "repository": "https://cran.r-project.org/package=astsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "astsa Applied Statistical Time Series Analysis Contains data sets and scripts for analyzing time series in both the frequency and time domains including state space modeling as well as supporting the texts Time Series Analysis and Its Applications: With R Examples (5th ed), by R.H. Shumway and D.S. Stoffer. Springer Texts in Statistics, 2025, <DOI:10.1007/978-3-031-70584-7>, and Time Series: A Data Analysis Approach Using R (2nd ed). Chapman-Hall, 2026, <https://www.routledge.com/Time-Series-A-Data-Analysis-Approach-Using-R/Shumway-Stoffer/p/book/9781041031642>. Most scripts are designed to require minimal input to produce aesthetically pleasing output for ease of use in live demonstrations and course work.  "
  },
  {
    "id": 306,
    "package_name": "boiwsa",
    "title": "Seasonal Adjustment of Weekly Data",
    "description": "Perform seasonal adjustment and forecasting of weekly data.\n    The package provides a user-friendly interface for computing seasonally\n    adjusted estimates and forecasts of weekly time series and includes\n    functions for the construction of country-specific prior adjustment\n    variables, as well as diagnostic tools to assess the quality of the\n    adjustments. The methodology is described in more detail in\n    Ginker (2024) <doi:10.13140/RG.2.2.12221.44000>.",
    "version": "1.1.4",
    "maintainer": "Tim Ginker <tim.ginker@gmail.com>",
    "author": "Tim Ginker [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7138-5417>),\n  Jon Lachman [ctb]",
    "url": "https://github.com/timginker/boiwsa",
    "bug_reports": "https://github.com/timginker/boiwsa/issues",
    "repository": "https://cran.r-project.org/package=boiwsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "boiwsa Seasonal Adjustment of Weekly Data Perform seasonal adjustment and forecasting of weekly data.\n    The package provides a user-friendly interface for computing seasonally\n    adjusted estimates and forecasts of weekly time series and includes\n    functions for the construction of country-specific prior adjustment\n    variables, as well as diagnostic tools to assess the quality of the\n    adjustments. The methodology is described in more detail in\n    Ginker (2024) <doi:10.13140/RG.2.2.12221.44000>.  "
  },
  {
    "id": 314,
    "package_name": "bpvars",
    "title": "Forecasting with Bayesian Panel Vector Autoregressions",
    "description": "\n  Provides Bayesian estimation and forecasting of dynamic panel data using \n  Bayesian Panel Vector Autoregressions with hierarchical prior distributions. \n  The models include country-specific VARs that share a global prior \n  distribution that extend the model by Jaroci\u0144ski (2010) <doi:10.1002/jae.1082>. \n  Under this prior expected value, each country's system follows \n  a global VAR with country-invariant parameters. Further flexibility is \n  provided by the hierarchical prior structure that retains the Minnesota prior \n  interpretation for the global VAR and features estimated prior covariance \n  matrices, shrinkage, and persistence levels. Bayesian forecasting is developed \n  for models including exogenous variables, allowing conditional forecasts given \n  the future trajectories of some variables and restricted forecasts assuring \n  that rates are forecasted to stay positive and less than 100. The package \n  implements the model specification, estimation, and forecasting routines, \n  facilitating coherent workflows and reproducibility. It also includes automated\n  pseudo-out-of-sample forecasting and computation of forecasting performance \n  measures. Beautiful plots, \n  informative summary functions, and extensive documentation complement all \n  this. An extraordinary computational speed is achieved thanks to employing \n  frontier econometric and numerical techniques and algorithms written in 'C++'. \n  The 'bpvars' package is aligned regarding objects, workflows, and code \n  structure with the 'R' packages 'bsvars' by \n  Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars> and 'bsvarSIGNs' by \n  Wang & Wo\u017aniak (2025) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they \n  constitute an integrated toolset. Copyright: 2025 International Labour \n  Organization.",
    "version": "1.0",
    "maintainer": "Tomasz Wo\u017aniak <wozniak.tom@pm.me>",
    "author": "Tomasz Wo\u017aniak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2212-2378>),\n  Miguel Sanchez-Martinez [ctb],\n  International Labour Organization [cph]",
    "url": "https://bsvars.org/bpvars/",
    "bug_reports": "https://github.com/bsvars/bpvars/issues",
    "repository": "https://cran.r-project.org/package=bpvars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bpvars Forecasting with Bayesian Panel Vector Autoregressions \n  Provides Bayesian estimation and forecasting of dynamic panel data using \n  Bayesian Panel Vector Autoregressions with hierarchical prior distributions. \n  The models include country-specific VARs that share a global prior \n  distribution that extend the model by Jaroci\u0144ski (2010) <doi:10.1002/jae.1082>. \n  Under this prior expected value, each country's system follows \n  a global VAR with country-invariant parameters. Further flexibility is \n  provided by the hierarchical prior structure that retains the Minnesota prior \n  interpretation for the global VAR and features estimated prior covariance \n  matrices, shrinkage, and persistence levels. Bayesian forecasting is developed \n  for models including exogenous variables, allowing conditional forecasts given \n  the future trajectories of some variables and restricted forecasts assuring \n  that rates are forecasted to stay positive and less than 100. The package \n  implements the model specification, estimation, and forecasting routines, \n  facilitating coherent workflows and reproducibility. It also includes automated\n  pseudo-out-of-sample forecasting and computation of forecasting performance \n  measures. Beautiful plots, \n  informative summary functions, and extensive documentation complement all \n  this. An extraordinary computational speed is achieved thanks to employing \n  frontier econometric and numerical techniques and algorithms written in 'C++'. \n  The 'bpvars' package is aligned regarding objects, workflows, and code \n  structure with the 'R' packages 'bsvars' by \n  Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars> and 'bsvarSIGNs' by \n  Wang & Wo\u017aniak (2025) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they \n  constitute an integrated toolset. Copyright: 2025 International Labour \n  Organization.  "
  },
  {
    "id": 343,
    "package_name": "casecountapp",
    "title": "Create an interactive application to view case count data",
    "description": "Functions to create, view, and deploy interactive applications of multi-resolution geographical case count time series data.",
    "version": "0.0.2",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/WorldHealthOrganization/casecountapp",
    "bug_reports": "https://github.com/WorldHealthOrganization/casecountapp/issues",
    "repository": "https://github.com/WorldHealthOrganization/casecountapp",
    "exports": [],
    "topics": [
      "case-counts",
      "eios",
      "r",
      "visualization"
    ],
    "score": "NA",
    "stars": 2,
    "primary_category": "epidemiology",
    "source_universe": "github:WorldHealthOrganization",
    "search_text": "casecountapp Create an interactive application to view case count data Functions to create, view, and deploy interactive applications of multi-resolution geographical case count time series data.  case-counts eios r visualization"
  },
  {
    "id": 346,
    "package_name": "cdcForecastUtils",
    "title": "Utility functions for CDC forecasts",
    "description": "Utility functions for generating and plotting forecasts from a variety of models for infectious disease forecasting challenges run by the CDC.",
    "version": "0.1.9.6",
    "maintainer": "Nutcha Wattanachit <nwattanachit@umass.edu>",
    "author": "",
    "url": "https://github.com/reichlab/cdcForecastUtils",
    "bug_reports": "https://github.com/reichlab/cdcForecastUtils/issues",
    "repository": "https://github.com/reichlab/cdcForecastUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 4,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "cdcForecastUtils Utility functions for CDC forecasts Utility functions for generating and plotting forecasts from a variety of models for infectious disease forecasting challenges run by the CDC.  "
  },
  {
    "id": 348,
    "package_name": "cdcfluutils",
    "title": "Utility functions for CDC flu forecasts for team Kernel of Truth",
    "description": "Utility functions for generating and plotting forecasts from a variety of",
    "version": "0.0.0.9000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/cdcfluutils",
    "bug_reports": "https://github.com/reichlab/cdcfluutils/issues",
    "repository": "https://github.com/reichlab/cdcfluutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 1,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "cdcfluutils Utility functions for CDC flu forecasts for team Kernel of Truth Utility functions for generating and plotting forecasts from a variety of  "
  },
  {
    "id": 538,
    "package_name": "ergm.sign",
    "title": "Exponential-Family Models for Signed Networks",
    "description": "Extends the 'ergm.multi' packages from the Statnet suite to fit (temporal) exponential-family random graph models for signed networks. The framework models positive and negative ties as interdependent, which allows estimation and testing of structural balance theory. The package also includes options for descriptive summaries, visualization, and simulation of signed networks. See Krivitsky, Koehly, and Marcum (2020) <doi:10.1007/s11336-020-09720-7> and Fritz, C., Mehrl, M., Thurner, P. W., & Kauermann, G. (2025) <doi:10.1017/pan.2024.21>.",
    "version": "0.1.1",
    "maintainer": "Marc Schalberger <m.schalberger@fu-berlin.de>",
    "author": "Marc Schalberger [cre],\n  Cornelius Fritz [aut],\n  Pavel Krivitsky [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ergm.sign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ergm.sign Exponential-Family Models for Signed Networks Extends the 'ergm.multi' packages from the Statnet suite to fit (temporal) exponential-family random graph models for signed networks. The framework models positive and negative ties as interdependent, which allows estimation and testing of structural balance theory. The package also includes options for descriptive summaries, visualization, and simulation of signed networks. See Krivitsky, Koehly, and Marcum (2020) <doi:10.1007/s11336-020-09720-7> and Fritz, C., Mehrl, M., Thurner, P. W., & Kauermann, G. (2025) <doi:10.1017/pan.2024.21>.  "
  },
  {
    "id": 554,
    "package_name": "fGarch",
    "title": "Rmetrics - Autoregressive Conditional Heteroskedastic Modelling",
    "description": "Analyze and model heteroskedastic behavior in financial time series.",
    "version": "4052.93",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Diethelm Wuertz [aut] (original code),\n  Yohan Chalabi [aut],\n  Tobias Setz [aut],\n  Martin Maechler [aut] (ORCID: <https://orcid.org/0000-0002-8685-9910>),\n  Chris Boudt [ctb],\n  Pierre Chausse [ctb],\n  Michal Miklovac [ctb],\n  Georgi N. Boshnakov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>)",
    "url": "https://geobosh.github.io/fGarchDoc/ (doc),\nhttps://CRAN.R-project.org/package=fGarch,\nhttps://www.rmetrics.org",
    "bug_reports": "https://r-forge.r-project.org/tracker/?func=browse&group_id=156&atid=633",
    "repository": "https://cran.r-project.org/package=fGarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fGarch Rmetrics - Autoregressive Conditional Heteroskedastic Modelling Analyze and model heteroskedastic behavior in financial time series.  "
  },
  {
    "id": 588,
    "package_name": "forecastTools",
    "title": "Evaluation of time-series forecasts",
    "description": "An R package with tools for managing, evaluating forecasts of time-series",
    "version": "0.0.1",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/forecastTools",
    "bug_reports": "https://github.com/reichlab/forecastTools/issues",
    "repository": "https://github.com/reichlab/forecastTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "forecastTools Evaluation of time-series forecasts An R package with tools for managing, evaluating forecasts of time-series  "
  },
  {
    "id": 601,
    "package_name": "gctsc",
    "title": "Modeling Count Time Series Data via Gaussian Copula Models",
    "description": "Gaussian copula models for count time series. Includes simulation utilities, likelihood approximation, maximum-likelihood estimation, residual diagnostics, and predictive inference. Implements the Time Series Minimax Exponential Tilting (TMET) method, an adaptation of Minimax Exponential Tilting (Botev, 2017) <doi:10.1111/rssb.12162> and the Vecchia-based tilting framework of Cao and Katzfuss (2025) <doi:10.1080/01621459.2025.2546586>. Also provides a linear-cost implementation of the Geweke\u2013Hajivassiliou\u2013Keane (GHK) simulator inspired by Masarotto and Varin (2012) <doi:10.1214/12-EJS721>, and the Continuous Extension (CE) approximation of Nguyen and De Oliveira (2025) <doi:10.1080/02664763.2025.2498502>. The package follows the S3 structure of 'gcmr', but all code in 'gctsc' was developed independently.",
    "version": "0.1.3",
    "maintainer": "Quynh Nguyen <nqnhu2209@gmail.com>",
    "author": "Quynh Nguyen [aut, cre],\n  Victor De Oliveira [aut]",
    "url": "https://github.com/QNNHU/gctsc",
    "bug_reports": "https://github.com/QNNHU/gctsc/issues",
    "repository": "https://cran.r-project.org/package=gctsc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gctsc Modeling Count Time Series Data via Gaussian Copula Models Gaussian copula models for count time series. Includes simulation utilities, likelihood approximation, maximum-likelihood estimation, residual diagnostics, and predictive inference. Implements the Time Series Minimax Exponential Tilting (TMET) method, an adaptation of Minimax Exponential Tilting (Botev, 2017) <doi:10.1111/rssb.12162> and the Vecchia-based tilting framework of Cao and Katzfuss (2025) <doi:10.1080/01621459.2025.2546586>. Also provides a linear-cost implementation of the Geweke\u2013Hajivassiliou\u2013Keane (GHK) simulator inspired by Masarotto and Varin (2012) <doi:10.1214/12-EJS721>, and the Continuous Extension (CE) approximation of Nguyen and De Oliveira (2025) <doi:10.1080/02664763.2025.2498502>. The package follows the S3 structure of 'gcmr', but all code in 'gctsc' was developed independently.  "
  },
  {
    "id": 602,
    "package_name": "geeLite",
    "title": "Building and Managing Local Databases from 'Google Earth Engine'",
    "description": "Simplifies the creation, management, and updating of local databases using data extracted from 'Google Earth Engine' ('GEE'). It integrates with 'GEE' to store, aggregate, and process spatio-temporal data, leveraging 'SQLite' for efficient, serverless storage. The 'geeLite' package provides utilities for data transformation and supports real-time monitoring and analysis of geospatial features, making it suitable for researchers and practitioners in geospatial science. For details, see Kurbucz and Andr\u00e9e (2025) \"Building and Managing Local Databases from Google Earth Engine with the geeLite R Package\" <https://hdl.handle.net/10986/43165>.",
    "version": "1.0.6",
    "maintainer": "Marcell T. Kurbucz <m.kurbucz@ucl.ac.uk>",
    "author": "Marcell T. Kurbucz [aut, cre],\n  Bo Pieter Johannes Andr\u00e9e [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geeLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geeLite Building and Managing Local Databases from 'Google Earth Engine' Simplifies the creation, management, and updating of local databases using data extracted from 'Google Earth Engine' ('GEE'). It integrates with 'GEE' to store, aggregate, and process spatio-temporal data, leveraging 'SQLite' for efficient, serverless storage. The 'geeLite' package provides utilities for data transformation and supports real-time monitoring and analysis of geospatial features, making it suitable for researchers and practitioners in geospatial science. For details, see Kurbucz and Andr\u00e9e (2025) \"Building and Managing Local Databases from Google Earth Engine with the geeLite R Package\" <https://hdl.handle.net/10986/43165>.  "
  },
  {
    "id": 694,
    "package_name": "hubEnsembles",
    "title": "Building Simple Ensembles from Hub Forecasts",
    "description": "",
    "version": "0.0.0.9000",
    "maintainer": "Nicholas G. Reich <nick@umass.edu>",
    "author": "",
    "url": "https://github.com/reichlab/hubEnsembles",
    "bug_reports": "https://github.com/reichlab/hubEnsembles/issues",
    "repository": "https://github.com/reichlab/hubEnsembles",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 2,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "hubEnsembles Building Simple Ensembles from Hub Forecasts   "
  },
  {
    "id": 696,
    "package_name": "hydroEvents",
    "title": "Extract Event Statistics in Hydrologic Time Series",
    "description": "Events from individual hydrologic time series are extracted, and events\n are matched across multiple time series. The package has been applied in studies\n such as Wasko and Guo (2022) <doi:10.1002/hyp.14563> and Mohammadpour Khoie,\n Guo and Wasko (2025) <doi:10.1016/j.envsoft.2025.106521>.",
    "version": "0.13.0",
    "maintainer": "Conrad Wasko <conrad.wasko@gmail.com>",
    "author": "Conrad Wasko [aut, cre],\n  Danlu Guo [aut],\n  Mohammad Masoud Mohammadpour Khoie [ctb]",
    "url": "https://github.com/conradwasko/hydroEvents",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hydroEvents",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydroEvents Extract Event Statistics in Hydrologic Time Series Events from individual hydrologic time series are extracted, and events\n are matched across multiple time series. The package has been applied in studies\n such as Wasko and Guo (2022) <doi:10.1002/hyp.14563> and Mohammadpour Khoie,\n Guo and Wasko (2025) <doi:10.1016/j.envsoft.2025.106521>.  "
  },
  {
    "id": 702,
    "package_name": "idforecastutils",
    "title": "Utility functions for general infectious disease forecasting use",
    "description": "A set of utility functions for various infectious disease forecasting models, exercises, and rounds.",
    "version": "0.0.0.9000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/idforecastutils",
    "bug_reports": "https://github.com/reichlab/idforecastutils/issues",
    "repository": "https://github.com/reichlab/idforecastutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "idforecastutils Utility functions for general infectious disease forecasting use A set of utility functions for various infectious disease forecasting models, exercises, and rounds.  "
  },
  {
    "id": 755,
    "package_name": "lessR",
    "title": "Less Code with More Comprehensive Results",
    "description": "Each function replaces multiple standard R functions. For example,\n    two function calls, Read() and CountAll(), generate summary statistics for\n    all variables in the data frame, plus histograms and bar charts. Other\n    functions provide data aggregation via pivot tables; comprehensive\n    regression, ANOVA, and t-test; visualizations including integrated\n    Violin/Box/Scatter plot for a numerical variable, bar chart, histogram,\n    box plot, density curves, calibrated power curve; reading multiple data\n    formats with the same call; variable labels; time series with aggregation\n    and forecasting; color themes; and Trellis (facet) graphics. Also includes\n    a confirmatory factor analysis of multiple-indicator measurement models,\n    pedagogical routines for data simulation (e.g., Central Limit Theorem),\n    generation and rendering of regression instructions for interpretative output,\n    and both interactive construction of visualizations and interactive\n    visualizations with plotly.",
    "version": "4.5",
    "maintainer": "David W. Gerbing <gerbing@pdx.edu>",
    "author": "David W. Gerbing [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6998-8350>, Affiliation: School of\n    Business, Portland State University)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lessR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lessR Less Code with More Comprehensive Results Each function replaces multiple standard R functions. For example,\n    two function calls, Read() and CountAll(), generate summary statistics for\n    all variables in the data frame, plus histograms and bar charts. Other\n    functions provide data aggregation via pivot tables; comprehensive\n    regression, ANOVA, and t-test; visualizations including integrated\n    Violin/Box/Scatter plot for a numerical variable, bar chart, histogram,\n    box plot, density curves, calibrated power curve; reading multiple data\n    formats with the same call; variable labels; time series with aggregation\n    and forecasting; color themes; and Trellis (facet) graphics. Also includes\n    a confirmatory factor analysis of multiple-indicator measurement models,\n    pedagogical routines for data simulation (e.g., Central Limit Theorem),\n    generation and rendering of regression instructions for interpretative output,\n    and both interactive construction of visualizations and interactive\n    visualizations with plotly.  "
  },
  {
    "id": 756,
    "package_name": "lfl",
    "title": "Linguistic Fuzzy Logic",
    "description": "Various algorithms related to linguistic fuzzy logic: mining for linguistic fuzzy association\n    rules, composition of fuzzy relations, performing perception-based logical deduction (PbLD), \n    and forecasting time-series using fuzzy rule-based ensemble (FRBE). The package also contains basic\n    fuzzy-related algebraic functions capable of handling missing values in different styles (Bochvar,\n    Sobocinski, Kleene etc.), computation of Sugeno integrals and fuzzy transform.",
    "version": "2.3.1",
    "maintainer": "Michal Burda <michal.burda@osu.cz>",
    "author": "Michal Burda [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4182-4407>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lfl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lfl Linguistic Fuzzy Logic Various algorithms related to linguistic fuzzy logic: mining for linguistic fuzzy association\n    rules, composition of fuzzy relations, performing perception-based logical deduction (PbLD), \n    and forecasting time-series using fuzzy rule-based ensemble (FRBE). The package also contains basic\n    fuzzy-related algebraic functions capable of handling missing values in different styles (Bochvar,\n    Sobocinski, Kleene etc.), computation of Sugeno integrals and fuzzy transform.  "
  },
  {
    "id": 809,
    "package_name": "mesonet",
    "title": "Download and Process Oklahoma Mesonet Data",
    "description": "A collection of functions to download and process weather data from\n  the Oklahoma Mesonet <https://mesonet.org>. Functions are available for downloading station metadata,\n  downloading Mesonet time series (MTS) files, importing MTS files into R, and \n  converting soil temperature change measurements into soil matric potential and\n  volumetric soil moisture.",
    "version": "0.0.2",
    "maintainer": "Phillip D. Alderman <phillip.alderman@okstate.edu>",
    "author": "Phillip D. Alderman [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mesonet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mesonet Download and Process Oklahoma Mesonet Data A collection of functions to download and process weather data from\n  the Oklahoma Mesonet <https://mesonet.org>. Functions are available for downloading station metadata,\n  downloading Mesonet time series (MTS) files, importing MTS files into R, and \n  converting soil temperature change measurements into soil matric potential and\n  volumetric soil moisture.  "
  },
  {
    "id": 819,
    "package_name": "mixAR",
    "title": "Mixture Autoregressive Models",
    "description": "Model time series using mixture autoregressive (MAR)\n             models.  Implemented are frequentist (EM) and Bayesian\n             methods for estimation, prediction and model\n             evaluation. See Wong and Li (2002)\n             <doi:10.1111/1467-9868.00222>, Boshnakov (2009)\n             <doi:10.1016/j.spl.2009.04.009>), and the extensive\n             references in the documentation.",
    "version": "0.22.9",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Georgi N. Boshnakov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>),\n  Davide Ravagli [aut] (ORCID: <https://orcid.org/0000-0001-7146-7685>)",
    "url": "https://geobosh.github.io/mixAR/ (doc),\nhttps://CRAN.R-project.org/package=mixAR/",
    "bug_reports": "https://github.com/GeoBosh/mixAR/issues",
    "repository": "https://cran.r-project.org/package=mixAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mixAR Mixture Autoregressive Models Model time series using mixture autoregressive (MAR)\n             models.  Implemented are frequentist (EM) and Bayesian\n             methods for estimation, prediction and model\n             evaluation. See Wong and Li (2002)\n             <doi:10.1111/1467-9868.00222>, Boshnakov (2009)\n             <doi:10.1016/j.spl.2009.04.009>), and the extensive\n             references in the documentation.  "
  },
  {
    "id": 838,
    "package_name": "modernBoot",
    "title": "Modern Resampling Methods: Bootstraps, Wild, Block, Permutation,\nand Selection Guidance",
    "description": "Implements modern resampling and permutation methods for robust \n    statistical inference without restrictive parametric assumptions. Provides \n    bias-corrected and accelerated (BCa) bootstrap (Efron and Tibshirani (1993) \n    <doi:10.1201/9780429246593>), wild bootstrap for heteroscedastic regression \n    (Liu (1988) <doi:10.1214/aos/1176351062>, Davidson and Flachaire (2008) \n    <doi:10.1016/j.jeconom.2008.08.003>), block bootstrap for time series \n    (Politis and Romano (1994) <doi:10.1080/01621459.1994.10476870>), and \n    permutation-based multiple testing correction (Westfall and Young (1993) \n    <ISBN:0-471-55761-7>). Methods handle non-normal data, \n    heteroscedasticity, time series correlation, and multiple comparisons.",
    "version": "0.1.1",
    "maintainer": "Ibrahim Kholil Rakib <ikrakib1010@gmail.com>",
    "author": "Ibrahim Kholil Rakib [aut, cre]",
    "url": "https://github.com/ikrakib/modernBoot",
    "bug_reports": "https://github.com/ikrakib/modernBoot/issues",
    "repository": "https://cran.r-project.org/package=modernBoot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modernBoot Modern Resampling Methods: Bootstraps, Wild, Block, Permutation,\nand Selection Guidance Implements modern resampling and permutation methods for robust \n    statistical inference without restrictive parametric assumptions. Provides \n    bias-corrected and accelerated (BCa) bootstrap (Efron and Tibshirani (1993) \n    <doi:10.1201/9780429246593>), wild bootstrap for heteroscedastic regression \n    (Liu (1988) <doi:10.1214/aos/1176351062>, Davidson and Flachaire (2008) \n    <doi:10.1016/j.jeconom.2008.08.003>), block bootstrap for time series \n    (Politis and Romano (1994) <doi:10.1080/01621459.1994.10476870>), and \n    permutation-based multiple testing correction (Westfall and Young (1993) \n    <ISBN:0-471-55761-7>). Methods handle non-normal data, \n    heteroscedasticity, time series correlation, and multiple comparisons.  "
  },
  {
    "id": 862,
    "package_name": "nadaverse",
    "title": "Browse Microdata Catalogs Using 'NADA' REST API",
    "description": "Provides a unified, programmatic interface for searching, browsing,\n  and retrieving metadata from various international organization data repositories\n  that use the National Data Archive ('NADA') software, such as the World Bank,\n  'FAO', and the International Household Survey Network ('IHSN'). Functions allow users to\n  discover available data collections, country codes, and access types, perform\n  complex searches using keyword and spatial/temporal filters, and retrieve\n  detailed study information, including file lists and variable-level data\n  dictionaries. It simplifies access to microdata for researchers and policy\n  analysts globally.",
    "version": "0.1.0",
    "maintainer": "Gutama Girja Urago <girjagutama@gmail.com>",
    "author": "Gutama Girja Urago [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5588-2301>)",
    "url": "https://github.com/guturago/nadaverse",
    "bug_reports": "https://github.com/guturago/nadaverse/issues",
    "repository": "https://cran.r-project.org/package=nadaverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nadaverse Browse Microdata Catalogs Using 'NADA' REST API Provides a unified, programmatic interface for searching, browsing,\n  and retrieving metadata from various international organization data repositories\n  that use the National Data Archive ('NADA') software, such as the World Bank,\n  'FAO', and the International Household Survey Network ('IHSN'). Functions allow users to\n  discover available data collections, country codes, and access types, perform\n  complex searches using keyword and spatial/temporal filters, and retrieve\n  detailed study information, including file lists and variable-level data\n  dictionaries. It simplifies access to microdata for researchers and policy\n  analysts globally.  "
  },
  {
    "id": 1093,
    "package_name": "resourcecode",
    "title": "Access to the 'RESOURCECODE' Hindcast Database",
    "description": "Utility functions to download data from the 'RESOURCECODE'\n    hindcast database of sea-states, time series of sea-state parameters\n    and time series of 1D and 2D wave spectra.  See\n    <https://resourcecode.ifremer.fr> for more details about the available\n    data.  Also provides facilities to plot and analyse downloaded data,\n    such as computing the sea-state parameters from both the 1D and 2D\n    surface elevation variance spectral density.",
    "version": "0.5.1",
    "maintainer": "Nicolas Raillard <nicolas.raillard@ifremer.fr>",
    "author": "Nicolas Raillard [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3385-5104>)",
    "url": "https://github.com/Resourcecode-project/r-resourcecode,\nhttps://resourcecode-project.github.io/r-resourcecode/,\nhttps://resourcecode-project.r-universe.dev/resourcecode",
    "bug_reports": "https://github.com/Resourcecode-project/r-resourcecode/issues",
    "repository": "https://cran.r-project.org/package=resourcecode",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "resourcecode Access to the 'RESOURCECODE' Hindcast Database Utility functions to download data from the 'RESOURCECODE'\n    hindcast database of sea-states, time series of sea-state parameters\n    and time series of 1D and 2D wave spectra.  See\n    <https://resourcecode.ifremer.fr> for more details about the available\n    data.  Also provides facilities to plot and analyse downloaded data,\n    such as computing the sea-state parameters from both the 1D and 2D\n    surface elevation variance spectral density.  "
  },
  {
    "id": 1177,
    "package_name": "sarima",
    "title": "Simulation and Prediction with Seasonal ARIMA Models",
    "description": "Functions, classes and methods for time series modelling with ARIMA\n    and related models. The aim of the package is to provide consistent\n    interface for the user. For example, a single function autocorrelations()\n    computes various kinds of theoretical and sample autocorrelations. This is\n    work in progress, see the documentation and vignettes for the current\n    functionality.  Function sarima() fits extended multiplicative seasonal\n    ARIMA models with trends, exogenous variables and arbitrary roots on the\n    unit circle, which can be fixed or estimated (for the algebraic basis for\n    this see <doi:10.48550/arXiv.2208.05055>, a paper on the methodology is being prepared).",
    "version": "0.9.5",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Georgi N. Boshnakov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>),\n  Jamie Halliday [aut]",
    "url": "https://geobosh.github.io/sarima/ (doc)\nhttps://github.com/GeoBosh/sarima (devel)",
    "bug_reports": "https://github.com/GeoBosh/sarima/issues",
    "repository": "https://cran.r-project.org/package=sarima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sarima Simulation and Prediction with Seasonal ARIMA Models Functions, classes and methods for time series modelling with ARIMA\n    and related models. The aim of the package is to provide consistent\n    interface for the user. For example, a single function autocorrelations()\n    computes various kinds of theoretical and sample autocorrelations. This is\n    work in progress, see the documentation and vignettes for the current\n    functionality.  Function sarima() fits extended multiplicative seasonal\n    ARIMA models with trends, exogenous variables and arbitrary roots on the\n    unit circle, which can be fixed or estimated (for the algebraic basis for\n    this see <doi:10.48550/arXiv.2208.05055>, a paper on the methodology is being prepared).  "
  },
  {
    "id": 1178,
    "package_name": "sarimaTD",
    "title": "SARIMA Models with Transformations and Seasonal Differencing",
    "description": "A set of wrapper functions around the forecast package to simplify",
    "version": "0.0.0.9000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/sarimaTD",
    "bug_reports": "https://github.com/reichlab/sarimaTD/issues",
    "repository": "https://github.com/reichlab/sarimaTD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 4,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "sarimaTD SARIMA Models with Transformations and Seasonal Differencing A set of wrapper functions around the forecast package to simplify  "
  },
  {
    "id": 1185,
    "package_name": "seasonalytics",
    "title": "Compute Seasonality Index, Seasonalized and Deseaonalised the\nTime Series Data",
    "description": "The computation of a seasonal index is a fundamental step in time-series forecasting when the data exhibits seasonality. Specifically, a seasonal index quantifies \u2014 for each season (e.g. month, quarter, week) \u2014 the relative magnitude of the seasonal effect compared to the overall average level of the series. This package has been developed to compute seasonal index for time series data and it also seasonalise and desesaonalise the time series data.",
    "version": "0.1.0",
    "maintainer": "Mr. Ankit Kumar Singh <ankitsinghvns32@gmail.com>",
    "author": "Dr. Pramit Pandit [aut],\n  Mr. Ankit Kumar Singh [aut, cre],\n  Ms. Anita Sarkar [aut],\n  Ms. Moumita Paul [aut],\n  Dr. Bikramjeet Ghose [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=seasonalytics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonalytics Compute Seasonality Index, Seasonalized and Deseaonalised the\nTime Series Data The computation of a seasonal index is a fundamental step in time-series forecasting when the data exhibits seasonality. Specifically, a seasonal index quantifies \u2014 for each season (e.g. month, quarter, week) \u2014 the relative magnitude of the seasonal effect compared to the overall average level of the series. This package has been developed to compute seasonal index for time series data and it also seasonalise and desesaonalise the time series data.  "
  },
  {
    "id": 1226,
    "package_name": "simplets",
    "title": "Simple models for time series forecasting",
    "description": "Simple models for time series forecasting",
    "version": "0.0.0.1000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/simplets",
    "bug_reports": "https://github.com/reichlab/simplets/issues",
    "repository": "https://github.com/reichlab/simplets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 2,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "simplets Simple models for time series forecasting Simple models for time series forecasting  "
  },
  {
    "id": 1355,
    "package_name": "timeSeries",
    "title": "Financial Time Series Objects (Rmetrics)",
    "description": "'S4' classes and various tools for financial time series:\n  Basic functions such as scaling and sorting, subsetting,\n  mathematical operations and statistical functions.",
    "version": "4052.112",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Diethelm Wuertz [aut] (original code),\n  Tobias Setz [aut],\n  Yohan Chalabi [aut],\n  Martin Maechler [ctb] (ORCID: <https://orcid.org/0000-0002-8685-9910>),\n  Georgi N. Boshnakov [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>)",
    "url": "https://geobosh.github.io/timeSeriesDoc/ (doc),\nhttps://CRAN.R-project.org/package=timeSeries,\nhttps://www.rmetrics.org",
    "bug_reports": "https://r-forge.r-project.org/tracker/?atid=633&group_id=156&func=browse",
    "repository": "https://cran.r-project.org/package=timeSeries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timeSeries Financial Time Series Objects (Rmetrics) 'S4' classes and various tools for financial time series:\n  Basic functions such as scaling and sorting, subsetting,\n  mathematical operations and statistical functions.  "
  },
  {
    "id": 1392,
    "package_name": "tsforecast",
    "title": "Time Series Forecasting Functions",
    "description": "Fundamental time series forecasting models such as autoregressive integrated moving average (ARIMA), exponential smoothing, and simple moving average are included. For ARIMA models, the output follows the traditional parameterisation by Box and Jenkins (1970, ISBN: 0816210942, 9780816210947). Furthermore, there are functions for detailed time series exploration and decomposition, respectively. All data and result visualisations are generated by 'ggplot2' instead of conventional R graphical output. For more details regarding the theoretical background of the models see Hyndman, R.J. and Athanasopoulos, G. (2021) <https://otexts.com/fpp3/>.",
    "version": "1.2.0",
    "maintainer": "Ka Yui Karl Wu <karlwuky@suss.edu.sg>",
    "author": "Ka Yui Karl Wu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsforecast Time Series Forecasting Functions Fundamental time series forecasting models such as autoregressive integrated moving average (ARIMA), exponential smoothing, and simple moving average are included. For ARIMA models, the output follows the traditional parameterisation by Box and Jenkins (1970, ISBN: 0816210942, 9780816210947). Furthermore, there are functions for detailed time series exploration and decomposition, respectively. All data and result visualisations are generated by 'ggplot2' instead of conventional R graphical output. For more details regarding the theoretical background of the models see Hyndman, R.J. and Athanasopoulos, G. (2021) <https://otexts.com/fpp3/>.  "
  },
  {
    "id": 1477,
    "package_name": "zoltr",
    "title": "Interface to the 'Zoltar' Forecast Repository API",
    "description": "'Zoltar' <https://www.zoltardata.com/> is a website that provides a repository of model forecast results",
    "version": "1.0.2",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/zoltr",
    "bug_reports": "https://github.com/reichlab/zoltr/issues",
    "repository": "https://github.com/reichlab/zoltr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 2,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "zoltr Interface to the 'Zoltar' Forecast Repository API 'Zoltar' <https://www.zoltardata.com/> is a website that provides a repository of model forecast results  "
  },
  {
    "id": 1494,
    "package_name": "ACEsearch",
    "title": "'ACE' Search Engine API",
    "description": "'ACE' (Advanced Cohort Engine) is a powerful tool that allows constructing cohorts of patients \n             extremely quickly and efficiently. This package is designed to interface directly with an \n             instance of 'ACE' search engine and facilitates API queries and data dumps. Prerequisite\n             is a good knowledge of the temporal language to be able to efficiently construct a query.\n             More information available at <https://shahlab.stanford.edu/start>.",
    "version": "1.0.0",
    "maintainer": "Vladimir Polony <podalv@gmail.com>",
    "author": "Vladimir Polony",
    "url": "https://shahlab.stanford.edu/start",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ACEsearch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ACEsearch 'ACE' Search Engine API 'ACE' (Advanced Cohort Engine) is a powerful tool that allows constructing cohorts of patients \n             extremely quickly and efficiently. This package is designed to interface directly with an \n             instance of 'ACE' search engine and facilitates API queries and data dumps. Prerequisite\n             is a good knowledge of the temporal language to be able to efficiently construct a query.\n             More information available at <https://shahlab.stanford.edu/start>.  "
  },
  {
    "id": 1501,
    "package_name": "ACV",
    "title": "Optimal Out-of-Sample Forecast Evaluation and Testing under\nStationarity",
    "description": "Package 'ACV' (short for Affine Cross-Validation) offers an improved time-series cross-validation loss estimator which utilizes both in-sample and out-of-sample forecasting performance via a carefully constructed affine weighting scheme. Under the assumption of stationarity, the estimator is the best linear unbiased estimator of the out-of-sample loss. Besides that, the package also offers improved versions of Diebold-Mariano and Ibragimov-Muller tests of equal predictive ability which deliver more power relative to their conventional counterparts. For more information, see the accompanying article Stanek (2021) <doi:10.2139/ssrn.3996166>.",
    "version": "1.0.2",
    "maintainer": "Filip Stanek <stanek.fi@gmail.com>",
    "author": "Filip Stanek [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ACV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ACV Optimal Out-of-Sample Forecast Evaluation and Testing under\nStationarity Package 'ACV' (short for Affine Cross-Validation) offers an improved time-series cross-validation loss estimator which utilizes both in-sample and out-of-sample forecasting performance via a carefully constructed affine weighting scheme. Under the assumption of stationarity, the estimator is the best linear unbiased estimator of the out-of-sample loss. Besides that, the package also offers improved versions of Diebold-Mariano and Ibragimov-Muller tests of equal predictive ability which deliver more power relative to their conventional counterparts. For more information, see the accompanying article Stanek (2021) <doi:10.2139/ssrn.3996166>.  "
  },
  {
    "id": 1508,
    "package_name": "ADLP",
    "title": "Accident and Development Period Adjusted Linear Pools for\nActuarial Stochastic Reserving",
    "description": "Loss reserving generally focuses on identifying a single model that can generate superior predictive performance. However, different loss reserving models specialise in capturing different aspects of loss data.\n    This is recognised in practice in the sense that results from different models are often considered, and sometimes combined. For instance, actuaries may take a weighted average of the prediction outcomes from\n    various loss reserving models, often based on subjective assessments.\n        This package allows for the use of a systematic framework to objectively combine (i.e. ensemble) multiple stochastic loss reserving models such that the strengths offered by different models can be utilised effectively. Our\n    framework is developed in Avanzi et al. (2023). Firstly, our criteria model combination considers the full distributional properties of the ensemble and not just the central\n    estimate - which is of particular importance in the reserving context. Secondly, our framework is that it is tailored for the features inherent to reserving data. These include, for instance, accident, development,\n    calendar, and claim maturity effects. Crucially, the relative importance and scarcity of data across accident periods renders the problem distinct from the traditional ensemble techniques in statistical learning.\n        Our framework is illustrated with a complex synthetic dataset. In the results, the optimised ensemble outperforms both (i) traditional model selection strategies, and (ii) an equally weighted ensemble. In\n    particular, the improvement occurs not only with central estimates but also relevant quantiles, such as the 75th percentile of reserves (typically of interest to both insurers and regulators).\n    Reference: Avanzi B, Li Y, Wong B, Xian A (2023) \"Ensemble distributional forecasting for insurance loss reserving\" <doi:10.48550/arXiv.2206.08541>.",
    "version": "0.1.0",
    "maintainer": "Yanfeng Li <yanfeng.li@student.unsw.edu.au>",
    "author": "Benjamin Avanzi [aut],\n  William Ho [aut],\n  Yanfeng Li [aut, cre],\n  Bernard Wong [aut],\n  Alan Xian [aut]",
    "url": "https://github.com/agi-lab/ADLP",
    "bug_reports": "https://github.com/agi-lab/ADLP/issues",
    "repository": "https://cran.r-project.org/package=ADLP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ADLP Accident and Development Period Adjusted Linear Pools for\nActuarial Stochastic Reserving Loss reserving generally focuses on identifying a single model that can generate superior predictive performance. However, different loss reserving models specialise in capturing different aspects of loss data.\n    This is recognised in practice in the sense that results from different models are often considered, and sometimes combined. For instance, actuaries may take a weighted average of the prediction outcomes from\n    various loss reserving models, often based on subjective assessments.\n        This package allows for the use of a systematic framework to objectively combine (i.e. ensemble) multiple stochastic loss reserving models such that the strengths offered by different models can be utilised effectively. Our\n    framework is developed in Avanzi et al. (2023). Firstly, our criteria model combination considers the full distributional properties of the ensemble and not just the central\n    estimate - which is of particular importance in the reserving context. Secondly, our framework is that it is tailored for the features inherent to reserving data. These include, for instance, accident, development,\n    calendar, and claim maturity effects. Crucially, the relative importance and scarcity of data across accident periods renders the problem distinct from the traditional ensemble techniques in statistical learning.\n        Our framework is illustrated with a complex synthetic dataset. In the results, the optimised ensemble outperforms both (i) traditional model selection strategies, and (ii) an equally weighted ensemble. In\n    particular, the improvement occurs not only with central estimates but also relevant quantiles, such as the 75th percentile of reserves (typically of interest to both insurers and regulators).\n    Reference: Avanzi B, Li Y, Wong B, Xian A (2023) \"Ensemble distributional forecasting for insurance loss reserving\" <doi:10.48550/arXiv.2206.08541>.  "
  },
  {
    "id": 1514,
    "package_name": "ADTSA",
    "title": "Time Series Analysis",
    "description": "Analyzes autocorrelation and partial autocorrelation using surrogate methods and \n  bootstrapping, and computes the acceleration constants for the vectorized moving block \n  bootstrap provided by this package. It generates percentile, bias-corrected, and accelerated \n  intervals and estimates partial autocorrelations using Durbin-Levinson. This package \n  calculates the autocorrelation power spectrum, computes cross-correlations between two \n  time series, computes bandwidth for any time series, and performs autocorrelation frequency \n  analysis. It also calculates the periodicity of a time series.",
    "version": "1.0.1",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Masoud Yarmohammadi [aut],\n  Mohammad Reza Yeganegi [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ADTSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ADTSA Time Series Analysis Analyzes autocorrelation and partial autocorrelation using surrogate methods and \n  bootstrapping, and computes the acceleration constants for the vectorized moving block \n  bootstrap provided by this package. It generates percentile, bias-corrected, and accelerated \n  intervals and estimates partial autocorrelations using Durbin-Levinson. This package \n  calculates the autocorrelation power spectrum, computes cross-correlations between two \n  time series, computes bandwidth for any time series, and performs autocorrelation frequency \n  analysis. It also calculates the periodicity of a time series.  "
  },
  {
    "id": 1516,
    "package_name": "AEDForecasting",
    "title": "Change Point Analysis in ARIMA Forecasting",
    "description": "Package to incorporate change point analysis in ARIMA forecasting.",
    "version": "0.20.0",
    "maintainer": "Nhat Cuong Pham <acmetal74@gmail.com>",
    "author": "Claster William B. [aut],\n  Philip Sallis [aut],\n  Nhat Cuong Pham [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AEDForecasting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AEDForecasting Change Point Analysis in ARIMA Forecasting Package to incorporate change point analysis in ARIMA forecasting.  "
  },
  {
    "id": 1522,
    "package_name": "AFR",
    "title": "Toolkit for Regression Analysis of Kazakhstan Banking Sector\nData",
    "description": "Tool is created for regression, prediction and forecast analysis of macroeconomic and credit data.\n  The package includes functions from existing R packages adapted for banking sector of Kazakhstan.\n  The purpose of the package is to optimize statistical functions for easier interpretation for bank analysts and non-statisticians.",
    "version": "0.3.7",
    "maintainer": "Sultan Zhaparov <saldau.sultan@gmail.com>",
    "author": "Timur Abilkassymov [aut],\n  Shyngys Shuneyev [aut],\n  Alua Makhmetova [aut],\n  Sultan Zhaparov [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AFR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AFR Toolkit for Regression Analysis of Kazakhstan Banking Sector\nData Tool is created for regression, prediction and forecast analysis of macroeconomic and credit data.\n  The package includes functions from existing R packages adapted for banking sector of Kazakhstan.\n  The purpose of the package is to optimize statistical functions for easier interpretation for bank analysts and non-statisticians.  "
  },
  {
    "id": 1570,
    "package_name": "APCtools",
    "title": "Routines for Descriptive and Model-Based APC Analysis",
    "description": "Age-Period-Cohort (APC) analyses are used to differentiate relevant drivers for long-term developments.\n    The 'APCtools' package offers visualization techniques and general routines to simplify the workflow of an APC analysis.\n    Sophisticated functions are available both for descriptive and regression model-based analyses.\n    For the former, we use density (or ridgeline) matrices and (hexagonally binned) heatmaps as innovative visualization\n    techniques building on the concept of Lexis diagrams.\n    Model-based analyses build on the separation of the temporal dimensions based on generalized additive models,\n    where a tensor product interaction surface (usually between age and period) is utilized\n    to represent the third dimension (usually cohort) on its diagonal.\n    Such tensor product surfaces can also be estimated while accounting for\n    further covariates in the regression model.\n    See Weigert et al. (2021) <doi:10.1177/1354816620987198> for methodological details.",
    "version": "1.0.8",
    "maintainer": "Alexander Bauer <baueralexander@posteo.de>",
    "author": "Alexander Bauer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3495-5131>),\n  Maximilian Weigert [aut] (ORCID:\n    <https://orcid.org/0000-0003-4400-134X>),\n  Hawre Jalal [aut] (ORCID: <https://orcid.org/0000-0002-8224-6834>)",
    "url": "https://bauer-alex.github.io/APCtools/",
    "bug_reports": "https://github.com/bauer-alex/APCtools/issues",
    "repository": "https://cran.r-project.org/package=APCtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "APCtools Routines for Descriptive and Model-Based APC Analysis Age-Period-Cohort (APC) analyses are used to differentiate relevant drivers for long-term developments.\n    The 'APCtools' package offers visualization techniques and general routines to simplify the workflow of an APC analysis.\n    Sophisticated functions are available both for descriptive and regression model-based analyses.\n    For the former, we use density (or ridgeline) matrices and (hexagonally binned) heatmaps as innovative visualization\n    techniques building on the concept of Lexis diagrams.\n    Model-based analyses build on the separation of the temporal dimensions based on generalized additive models,\n    where a tensor product interaction surface (usually between age and period) is utilized\n    to represent the third dimension (usually cohort) on its diagonal.\n    Such tensor product surfaces can also be estimated while accounting for\n    further covariates in the regression model.\n    See Weigert et al. (2021) <doi:10.1177/1354816620987198> for methodological details.  "
  },
  {
    "id": 1578,
    "package_name": "AQEval",
    "title": "Air Quality Evaluation",
    "description": "Developed for use by those tasked with the routine detection, characterisation and quantification of\n            discrete changes in air quality time-series, such as identifying the impacts of air quality policy\n            interventions. The main functions use signal isolation then break-point/segment (BP/S) methods based\n            on 'strucchange' and 'segmented' methods to detect and quantify change events (Ropkins & Tate, 2021,\n            <doi:10.1016/j.scitotenv.2020.142374>).",
    "version": "0.6.2",
    "maintainer": "Karl Ropkins <k.ropkins@its.leeds.ac.uk>",
    "author": "Karl Ropkins [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0294-6997>),\n  Anthony Walker [aut] (ORCID: <https://orcid.org/0000-0003-3979-0989>),\n  James Tate [aut]",
    "url": "https://github.com/karlropkins/AQEval,\nhttps://karlropkins.github.io/AQEval/",
    "bug_reports": "https://github.com/karlropkins/AQEval/issues",
    "repository": "https://cran.r-project.org/package=AQEval",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AQEval Air Quality Evaluation Developed for use by those tasked with the routine detection, characterisation and quantification of\n            discrete changes in air quality time-series, such as identifying the impacts of air quality policy\n            interventions. The main functions use signal isolation then break-point/segment (BP/S) methods based\n            on 'strucchange' and 'segmented' methods to detect and quantify change events (Ropkins & Tate, 2021,\n            <doi:10.1016/j.scitotenv.2020.142374>).  "
  },
  {
    "id": 1590,
    "package_name": "ARIMAANN",
    "title": "Time Series Forecasting using ARIMA-ANN Hybrid Model",
    "description": "Testing, Implementation, and Forecasting of the ARIMA-ANN hybrid model. The ARIMA-ANN hybrid model combines the distinct strengths of the Auto-Regressive Integrated Moving Average (ARIMA) model and the Artificial Neural Network (ANN) model for time series forecasting.For method details see Zhang, GP (2003) <doi:10.1016/S0925-2312(01)00702-0>.",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Ramasubramanian V. [aut, ctb],\n  Mrinmoy Ray [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ARIMAANN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ARIMAANN Time Series Forecasting using ARIMA-ANN Hybrid Model Testing, Implementation, and Forecasting of the ARIMA-ANN hybrid model. The ARIMA-ANN hybrid model combines the distinct strengths of the Auto-Regressive Integrated Moving Average (ARIMA) model and the Artificial Neural Network (ANN) model for time series forecasting.For method details see Zhang, GP (2003) <doi:10.1016/S0925-2312(01)00702-0>.  "
  },
  {
    "id": 1592,
    "package_name": "ARMALSTM",
    "title": "Fitting of Hybrid ARMA-LSTM Models",
    "description": "The real-life time series data are hardly pure linear or nonlinear. Merging a linear time series model like the autoregressive moving average (ARMA) model with a nonlinear neural network model such as the Long Short-Term Memory (LSTM) model can be used as a hybrid model for more accurate modeling purposes. Both the autoregressive integrated moving average (ARIMA) and autoregressive fractionally integrated moving average (ARFIMA) models can be implemented. Details can be found in Box et al. (2015, ISBN: 978-1-118-67502-1) and Hochreiter and Schmidhuber (1997) <doi:10.1162/neco.1997.9.8.1735>.",
    "version": "0.1.0",
    "maintainer": "Debopam Rakshit <rakshitdebopam@yahoo.com>",
    "author": "Debopam Rakshit [aut, cre],\n  Ritwika Das [aut],\n  Dwaipayan Bardhan [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ARMALSTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ARMALSTM Fitting of Hybrid ARMA-LSTM Models The real-life time series data are hardly pure linear or nonlinear. Merging a linear time series model like the autoregressive moving average (ARMA) model with a nonlinear neural network model such as the Long Short-Term Memory (LSTM) model can be used as a hybrid model for more accurate modeling purposes. Both the autoregressive integrated moving average (ARIMA) and autoregressive fractionally integrated moving average (ARFIMA) models can be implemented. Details can be found in Box et al. (2015, ISBN: 978-1-118-67502-1) and Hochreiter and Schmidhuber (1997) <doi:10.1162/neco.1997.9.8.1735>.  "
  },
  {
    "id": 1604,
    "package_name": "ASSA",
    "title": "Applied Singular Spectrum Analysis (ASSA)",
    "description": "Functions to model and decompose time series into principal components using singular spectrum analysis (de Carvalho and Rua (2017) <doi:10.1016/j.ijforecast.2015.09.004>; de Carvalho et al (2012) <doi:10.1016/j.econlet.2011.09.007>).",
    "version": "2.0",
    "maintainer": "Miguel de Carvalho <miguel.decarvalho@ed.ac.uk>",
    "author": "Miguel de Carvalho [aut, cre],\n  Gabriel Martos [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ASSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ASSA Applied Singular Spectrum Analysis (ASSA) Functions to model and decompose time series into principal components using singular spectrum analysis (de Carvalho and Rua (2017) <doi:10.1016/j.ijforecast.2015.09.004>; de Carvalho et al (2012) <doi:10.1016/j.econlet.2011.09.007>).  "
  },
  {
    "id": 1606,
    "package_name": "AST",
    "title": "Age-Spatial-Temporal Model",
    "description": "Fits a model to adjust and consider additional variations in three dimensions of age groups, time, and space on residuals excluded from a prediction model that have residual such as: linear regression, mixed model and so on. Details are given in Foreman et al. (2015) <doi:10.1186/1478-7954-10-1>.",
    "version": "0.1.0",
    "maintainer": "Ali Ghanbari  <a.ghanbari541@gmail.com>",
    "author": "Parinaz Mehdipour <mehdipoor.p@gmail.com> [aut], Ali Ghanbari <a.ghanbari541@gmail.com> [cre,aut], Farshad Farzadfar <farzadfar3@yahoo.com> [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AST Age-Spatial-Temporal Model Fits a model to adjust and consider additional variations in three dimensions of age groups, time, and space on residuals excluded from a prediction model that have residual such as: linear regression, mixed model and so on. Details are given in Foreman et al. (2015) <doi:10.1186/1478-7954-10-1>.  "
  },
  {
    "id": 1608,
    "package_name": "ATAforecasting",
    "title": "Automatic Time Series Analysis and Forecasting using the Ata\nMethod",
    "description": "The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016) <doi:10.15672/HJMS.201614320580>,\n\tYapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides innovative solutions to issues faced during the\n\tinitialization and optimization stages of existing forecasting methods. Forecasting performance of the Ata method is superior to existing methods both in terms of easy\n\timplementation and accurate forecasting. It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend\n\tand seasonal). This methodology performed well on the M3 and M4-competition data. This package was written based on Ali Sabri Taylan\u2019s PhD dissertation.",
    "version": "0.0.61",
    "maintainer": "Ali Sabri Taylan <alisabritaylan@gmail.com>",
    "author": "Ali Sabri Taylan [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9514-934X>),\n  Hanife Taylan Selamlar [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-4091-884X>),\n  Guckan Yapar [aut, ths, cph] (ORCID:\n    <https://orcid.org/0000-0002-0971-6676>)",
    "url": "https://alsabtay.github.io/ATAforecasting/,\nhttps://github.com/alsabtay/ATAforecasting,\nhttps://atamethod.wordpress.com/",
    "bug_reports": "https://github.com/alsabtay/ATAforecasting/issues",
    "repository": "https://cran.r-project.org/package=ATAforecasting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ATAforecasting Automatic Time Series Analysis and Forecasting using the Ata\nMethod The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016) <doi:10.15672/HJMS.201614320580>,\n\tYapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides innovative solutions to issues faced during the\n\tinitialization and optimization stages of existing forecasting methods. Forecasting performance of the Ata method is superior to existing methods both in terms of easy\n\timplementation and accurate forecasting. It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend\n\tand seasonal). This methodology performed well on the M3 and M4-competition data. This package was written based on Ali Sabri Taylan\u2019s PhD dissertation.  "
  },
  {
    "id": 1610,
    "package_name": "ATNr",
    "title": "Run Allometric Trophic Networks Models",
    "description": "Implements the differential equations associated to different versions of Allometric Trophic Models (ATN) to estimate the temporal dynamics of species biomasses in food webs. It offers several features to generate synthetic food webs and to parametrise models as well as a wrapper to the ODE solver deSolve.",
    "version": "1.1.2",
    "maintainer": "Benoit Gauzens <benoit.gauzens@gmail.com>",
    "author": "Benoit Gauzens [cre, aut],\n  Emilio Berti [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ATNr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ATNr Run Allometric Trophic Networks Models Implements the differential equations associated to different versions of Allometric Trophic Models (ATN) to estimate the temporal dynamics of species biomasses in food webs. It offers several features to generate synthetic food webs and to parametrise models as well as a wrapper to the ODE solver deSolve.  "
  },
  {
    "id": 1652,
    "package_name": "AeRobiology",
    "title": "A Computational Tool for Aerobiological Data",
    "description": "Different tools for managing databases of airborne particles, elaborating the main calculations and visualization of results. In a first step, data are checked using tools for quality control and all missing gaps are completed. Then, the main parameters of the pollen season are calculated and represented graphically. Multiple graphical tools are available: pollen calendars, phenological plots, time series, tendencies, interactive plots, abundance plots...",
    "version": "2.0.1",
    "maintainer": "\"Jose Oteros\" <OterosJose@gmail.com>",
    "author": "Jesus Rojo <Jesus.Rojo@uclm.es>, Antonio Picornell <picornell@uma.es>, Jose Oteros <OterosJose@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AeRobiology",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AeRobiology A Computational Tool for Aerobiological Data Different tools for managing databases of airborne particles, elaborating the main calculations and visualization of results. In a first step, data are checked using tools for quality control and all missing gaps are completed. Then, the main parameters of the pollen season are calculated and represented graphically. Multiple graphical tools are available: pollen calendars, phenological plots, time series, tendencies, interactive plots, abundance plots...  "
  },
  {
    "id": 1660,
    "package_name": "AgroTech",
    "title": "Data Analysis of Pesticide Application Technology",
    "description": "In total it has 7 functions, three for calculating machine calibration, which determine application rate (L/ha), nozzle flow (L/min) and amount of product (L or kg) to be added. to the tank with each sprayer filling. Two functions for graphs of the flow distribution of the nozzles (L/min) in the application bar and, of the temporal variability of the meteorological conditions (air temperature, relative humidity of the air and wind speed). Two functions to determine the spray deposit (uL/cm2), through the methodology called spectrophotometry, with the aid of bright blue (Palladini, L.A., Raetano, C.G., Velini, E.D. (2005), <doi:10.1590/S0103-90162005000500005>) or metallic markers (Chaim, A., Castro, V.L.S.S., Correles, F.M., Galv\u00e3o, J.A.H., Cabral, O.M.R., Nicolella, G. (1999), <doi:10.1590/S0100-204X1999000500003>). The package supports the analysis and representation of information, using a single free software that meets the most diverse areas of activity in application technology.",
    "version": "1.0.2",
    "maintainer": "Rodrigo Yudi Palhaci Marubayashi <marubayashi@uel.br>",
    "author": "Rodrigo Yudi Palhaci Marubayashi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2778-8654>),\n  Gabriel Danilo Shimizu [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-8524-508X>),\n  Otavio Jorge Grigoli Abi Saab [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-1757-636X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AgroTech",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AgroTech Data Analysis of Pesticide Application Technology In total it has 7 functions, three for calculating machine calibration, which determine application rate (L/ha), nozzle flow (L/min) and amount of product (L or kg) to be added. to the tank with each sprayer filling. Two functions for graphs of the flow distribution of the nozzles (L/min) in the application bar and, of the temporal variability of the meteorological conditions (air temperature, relative humidity of the air and wind speed). Two functions to determine the spray deposit (uL/cm2), through the methodology called spectrophotometry, with the aid of bright blue (Palladini, L.A., Raetano, C.G., Velini, E.D. (2005), <doi:10.1590/S0103-90162005000500005>) or metallic markers (Chaim, A., Castro, V.L.S.S., Correles, F.M., Galv\u00e3o, J.A.H., Cabral, O.M.R., Nicolella, G. (1999), <doi:10.1590/S0100-204X1999000500003>). The package supports the analysis and representation of information, using a single free software that meets the most diverse areas of activity in application technology.  "
  },
  {
    "id": 1663,
    "package_name": "AirExposure",
    "title": "Exposure Model to Air Pollutants Based on Mobility and Daily\nActivities",
    "description": "Model that assesses daily exposure to air pollution, which considers daily population mobility on a geographical scale and the spatial and temporal variability of pollutant concentrations, in addition to traditional parameters such as exposure time and pollutant concentration.",
    "version": "1.0",
    "maintainer": "Josefina Urquiza <jurquiza@conicet.gov.ar>",
    "author": "Josefina Urquiza [aut, cre],\n  Maria Florencia Tames [aut],\n  Maela Lupo [aut],\n  Alfredo Rigalli [aut]",
    "url": "https://github.com/flortames/Air-Exposure-Model",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AirExposure",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AirExposure Exposure Model to Air Pollutants Based on Mobility and Daily\nActivities Model that assesses daily exposure to air pollution, which considers daily population mobility on a geographical scale and the spatial and temporal variability of pollutant concentrations, in addition to traditional parameters such as exposure time and pollutant concentration.  "
  },
  {
    "id": 1674,
    "package_name": "AlleleShift",
    "title": "Predict and Visualize Population-Level Changes in Allele\nFrequencies in Response to Climate Change",
    "description": "Methods (<doi:10.7717/peerj.11534>) are provided of calibrating and predicting shifts in allele frequencies through redundancy analysis ('vegan::rda()') and generalized additive models ('mgcv::gam()'). Visualization functions for predicted changes in allele frequencies include 'shift.dot.ggplot()', 'shift.pie.ggplot()', 'shift.moon.ggplot()', 'shift.waffle.ggplot()' and 'shift.surf.ggplot()' that are made with input data sets that are prepared by helper functions for each visualization method. Examples in the documentation show how to prepare animated climate change graphics through a time series with the 'gganimate' package. Function 'amova.rda()' shows how Analysis of Molecular Variance can be directly conducted with the results from redundancy analysis.",
    "version": "1.1-3",
    "maintainer": "Roeland Kindt <RoelandCEKindt@gmail.com>",
    "author": "Roeland Kindt [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-7672-0712>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AlleleShift",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AlleleShift Predict and Visualize Population-Level Changes in Allele\nFrequencies in Response to Climate Change Methods (<doi:10.7717/peerj.11534>) are provided of calibrating and predicting shifts in allele frequencies through redundancy analysis ('vegan::rda()') and generalized additive models ('mgcv::gam()'). Visualization functions for predicted changes in allele frequencies include 'shift.dot.ggplot()', 'shift.pie.ggplot()', 'shift.moon.ggplot()', 'shift.waffle.ggplot()' and 'shift.surf.ggplot()' that are made with input data sets that are prepared by helper functions for each visualization method. Examples in the documentation show how to prepare animated climate change graphics through a time series with the 'gganimate' package. Function 'amova.rda()' shows how Analysis of Molecular Variance can be directly conducted with the results from redundancy analysis.  "
  },
  {
    "id": 1680,
    "package_name": "Amelia",
    "title": "A Program for Missing Data",
    "description": "A tool that \"multiply imputes\" missing data in a single cross-section\n  (such as a survey), from a time series (like variables collected for\n  each year in a country), or from a time-series-cross-sectional data\n  set (such as collected by years for each of several countries).\n  Amelia II implements our bootstrapping-based algorithm that gives\n  essentially the same answers as the standard IP or EMis approaches,\n  is usually considerably faster than existing approaches and can\n  handle many more variables.  Unlike Amelia I and other statistically\n  rigorous imputation software, it virtually never crashes (but please\n  let us know if you find to the contrary!).  The program also\n  generalizes existing approaches by allowing for trends in time series\n  across observations within a cross-sectional unit, as well as priors\n  that allow experts to incorporate beliefs they have about the values\n  of missing cells in their data.  Amelia II also includes useful\n  diagnostics of the fit of multiple imputation models.  The program\n  works from the R command line or via a graphical user interface that\n  does not require users to know R.",
    "version": "1.8.3",
    "maintainer": "Matthew Blackwell <mblackwell@gmail.com>",
    "author": "James Honaker [aut],\n  Gary King [aut],\n  Matthew Blackwell [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3689-9527>)",
    "url": "https://gking.harvard.edu/amelia",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Amelia",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Amelia A Program for Missing Data A tool that \"multiply imputes\" missing data in a single cross-section\n  (such as a survey), from a time series (like variables collected for\n  each year in a country), or from a time-series-cross-sectional data\n  set (such as collected by years for each of several countries).\n  Amelia II implements our bootstrapping-based algorithm that gives\n  essentially the same answers as the standard IP or EMis approaches,\n  is usually considerably faster than existing approaches and can\n  handle many more variables.  Unlike Amelia I and other statistically\n  rigorous imputation software, it virtually never crashes (but please\n  let us know if you find to the contrary!).  The program also\n  generalizes existing approaches by allowing for trends in time series\n  across observations within a cross-sectional unit, as well as priors\n  that allow experts to incorporate beliefs they have about the values\n  of missing cells in their data.  Amelia II also includes useful\n  diagnostics of the fit of multiple imputation models.  The program\n  works from the R command line or via a graphical user interface that\n  does not require users to know R.  "
  },
  {
    "id": 1702,
    "package_name": "AnomalyScore",
    "title": "Anomaly Scoring for Multivariate Time Series",
    "description": "Compute an anomaly score for multivariate time series based on the k-nearest neighbors algorithm. Different computations of distances between time series are provided.  ",
    "version": "0.1",
    "maintainer": "Guillermo Granados <guillermo.granadosgarcia@outlook.com>",
    "author": "Guillermo Granados [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4868-6163>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AnomalyScore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AnomalyScore Anomaly Scoring for Multivariate Time Series Compute an anomaly score for multivariate time series based on the k-nearest neighbors algorithm. Different computations of distances between time series are provided.    "
  },
  {
    "id": 1721,
    "package_name": "ArDec",
    "title": "Time Series Autoregressive-Based Decomposition",
    "description": "Autoregressive-based decomposition of a time series based on the approach in West (1997). Particular cases include the extraction of trend and seasonal components.",
    "version": "2.1-1",
    "maintainer": "Susana Barbosa <sabarbosa@fc.ul.pt>",
    "author": "Susana Barbosa",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ArDec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ArDec Time Series Autoregressive-Based Decomposition Autoregressive-based decomposition of a time series based on the approach in West (1997). Particular cases include the extraction of trend and seasonal components.  "
  },
  {
    "id": 1727,
    "package_name": "AriGaMyANNSVR",
    "title": "Hybrid ARIMA-GARCH and Two Specially Designed ML-Based Models",
    "description": "Describes a series first. After that does time series analysis using one hybrid model and two specially structured Machine Learning (ML) (Artificial Neural Network or ANN and Support Vector Regression or SVR) models. More information can be obtained from Paul and Garai (2022) <doi:10.1007/s41096-022-00128-3>. ",
    "version": "0.1.0",
    "maintainer": "Mr. Sandip Garai <sandipnicksandy@gmail.com>",
    "author": "Mr. Sandip Garai [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AriGaMyANNSVR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AriGaMyANNSVR Hybrid ARIMA-GARCH and Two Specially Designed ML-Based Models Describes a series first. After that does time series analysis using one hybrid model and two specially structured Machine Learning (ML) (Artificial Neural Network or ANN and Support Vector Regression or SVR) models. More information can be obtained from Paul and Garai (2022) <doi:10.1007/s41096-022-00128-3>.   "
  },
  {
    "id": 1744,
    "package_name": "AutoAds",
    "title": "Advertisement Metrics Calculation",
    "description": "Calculations of the most common metrics of automated advertisement and plotting of them with trend and forecast. Calculations and description of metrics is taken from different RTB platforms support documentation. Plotting and forecasting is based on packages 'forecast', described in Rob J Hyndman and George Athanasopoulos (2021) \"Forecasting: Principles and Practice\" <https://otexts.com/fpp3/> and Rob J Hyndman et al \"Documentation for 'forecast'\" (2003) <https://pkg.robjhyndman.com/forecast/>, and 'ggplot2', described in Hadley Wickham et al \"Documentation for 'ggplot2'\" (2015) <https://ggplot2.tidyverse.org/>, and Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2015) \"ggplot2: Elegant Graphics for Data Analysis\" <https://ggplot2-book.org/>.",
    "version": "0.1.0",
    "maintainer": "Ivan Nemtsev <nemtsev.v@gmail.com>",
    "author": "Ivan Nemtsev [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AutoAds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AutoAds Advertisement Metrics Calculation Calculations of the most common metrics of automated advertisement and plotting of them with trend and forecast. Calculations and description of metrics is taken from different RTB platforms support documentation. Plotting and forecasting is based on packages 'forecast', described in Rob J Hyndman and George Athanasopoulos (2021) \"Forecasting: Principles and Practice\" <https://otexts.com/fpp3/> and Rob J Hyndman et al \"Documentation for 'forecast'\" (2003) <https://pkg.robjhyndman.com/forecast/>, and 'ggplot2', described in Hadley Wickham et al \"Documentation for 'ggplot2'\" (2015) <https://ggplot2.tidyverse.org/>, and Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2015) \"ggplot2: Elegant Graphics for Data Analysis\" <https://ggplot2-book.org/>.  "
  },
  {
    "id": 1752,
    "package_name": "AutoWeatherIndices",
    "title": "Calculating Weather Indices",
    "description": "Weather indices are formed from weather variables in this package. The users can input any number of weather variables recorded over any number of weeks. This package has no restriction on the number of weeks and weather variables to be taken as input.The details of the method can be seen (i)'Joint effects of weather variables on rice yields' by  R. Agrawal, R. C. Jain  and M. P. Jha in Mausam, vol. 34, pp. 189-194, 1983,<doi:10.54302/mausam.v34i2.2392>,(ii)'Improved weather indices based Bayesian regression model for forecasting crop yield' by  M. Yeasin, K. N. Singh, A. Lama and B. Gurung in Mausam, vol. 72, pp.879-886, 2021,<doi:10.54302/mausam.v72i4.670>.",
    "version": "0.1.0",
    "maintainer": "Achal Lama <achal.lama@icar.gov.in>",
    "author": "Achal Lama [aut, cre],\n  Kamlesh N Singh [aut],\n  Bishal Gurung [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AutoWeatherIndices",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AutoWeatherIndices Calculating Weather Indices Weather indices are formed from weather variables in this package. The users can input any number of weather variables recorded over any number of weeks. This package has no restriction on the number of weeks and weather variables to be taken as input.The details of the method can be seen (i)'Joint effects of weather variables on rice yields' by  R. Agrawal, R. C. Jain  and M. P. Jha in Mausam, vol. 34, pp. 189-194, 1983,<doi:10.54302/mausam.v34i2.2392>,(ii)'Improved weather indices based Bayesian regression model for forecasting crop yield' by  M. Yeasin, K. N. Singh, A. Lama and B. Gurung in Mausam, vol. 72, pp.879-886, 2021,<doi:10.54302/mausam.v72i4.670>.  "
  },
  {
    "id": 1806,
    "package_name": "BCT",
    "title": "Bayesian Context Trees for Discrete Time Series",
    "description": "An implementation of a collection of tools for exact Bayesian inference with discrete times series. This package contains functions that can be used for prediction, model selection, estimation, segmentation/change-point detection and other statistical tasks. Specifically, the functions provided can be used for the exact computation of the prior predictive likelihood of the data, for the identification of the a posteriori most likely (MAP) variable-memory Markov models, for calculating the exact posterior probabilities and the AIC and BIC scores of these models, for prediction with respect to log-loss and 0-1 loss and segmentation/change-point detection. Example data sets from finance, genetics, animal communication and meteorology are also provided. Detailed descriptions of the underlying theory and algorithms can be found in [Kontoyiannis et al. 'Bayesian Context Trees: Modelling and exact inference for discrete time series.' Journal of the Royal Statistical Society: Series B (Statistical Methodology), April 2022. Available at: <arXiv:2007.14900> [stat.ME], July 2020] and [Lungu et al. 'Change-point Detection and Segmentation of Discrete Data using Bayesian Context Trees' <arXiv:2203.04341> [stat.ME], March 2022]. ",
    "version": "1.2",
    "maintainer": "Valentinian Mihai Lungu <valentinian.mihai@gmail.com>",
    "author": "Ioannis Papageorgiou, Valentinian Mihai Lungu, Ioannis Kontoyiannis",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BCT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BCT Bayesian Context Trees for Discrete Time Series An implementation of a collection of tools for exact Bayesian inference with discrete times series. This package contains functions that can be used for prediction, model selection, estimation, segmentation/change-point detection and other statistical tasks. Specifically, the functions provided can be used for the exact computation of the prior predictive likelihood of the data, for the identification of the a posteriori most likely (MAP) variable-memory Markov models, for calculating the exact posterior probabilities and the AIC and BIC scores of these models, for prediction with respect to log-loss and 0-1 loss and segmentation/change-point detection. Example data sets from finance, genetics, animal communication and meteorology are also provided. Detailed descriptions of the underlying theory and algorithms can be found in [Kontoyiannis et al. 'Bayesian Context Trees: Modelling and exact inference for discrete time series.' Journal of the Royal Statistical Society: Series B (Statistical Methodology), April 2022. Available at: <arXiv:2007.14900> [stat.ME], July 2020] and [Lungu et al. 'Change-point Detection and Segmentation of Discrete Data using Bayesian Context Trees' <arXiv:2203.04341> [stat.ME], March 2022].   "
  },
  {
    "id": 1809,
    "package_name": "BDAlgo",
    "title": "Bloom Detecting Algorithm",
    "description": "The Bloom Detecting Algorithm enables the detection of blooms within a time series of species abundance and extracts 22 phenological variables. For details, see Karasiewicz et al. (2022) <doi:10.3390/jmse10020174>.",
    "version": "0.1.0",
    "maintainer": "Stephane Karasiewicz <skaraz.science@gmail.com>",
    "author": "Stephane Karasiewicz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1652-9921>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BDAlgo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BDAlgo Bloom Detecting Algorithm The Bloom Detecting Algorithm enables the detection of blooms within a time series of species abundance and extracts 22 phenological variables. For details, see Karasiewicz et al. (2022) <doi:10.3390/jmse10020174>.  "
  },
  {
    "id": 1819,
    "package_name": "BEKKs",
    "title": "Multivariate Conditional Volatility Modelling and Forecasting",
    "description": "Methods and tools for estimating, simulating and forecasting of so-called BEKK-models (named after Baba, Engle, Kraft and Kroner) based on the fast Berndt\u2013Hall\u2013Hall\u2013Hausman (BHHH) algorithm described in Hafner and Herwartz (2008) <doi:10.1007/s00184-007-0130-y>. For an overview, we refer the reader to F\u00fclle et al. (2024) <doi:10.18637/jss.v111.i04>.  ",
    "version": "1.4.6",
    "maintainer": "Markus J. F\u00fclle <markus.fuelle@gmail.com>",
    "author": "Markus J. F\u00fclle [aut, cre],\n  Alexander Lange [aut],\n  Christian M. Hafner [aut],\n  Helmut Herwartz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BEKKs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BEKKs Multivariate Conditional Volatility Modelling and Forecasting Methods and tools for estimating, simulating and forecasting of so-called BEKK-models (named after Baba, Engle, Kraft and Kroner) based on the fast Berndt\u2013Hall\u2013Hall\u2013Hausman (BHHH) algorithm described in Hafner and Herwartz (2008) <doi:10.1007/s00184-007-0130-y>. For an overview, we refer the reader to F\u00fclle et al. (2024) <doi:10.18637/jss.v111.i04>.    "
  },
  {
    "id": 1823,
    "package_name": "BETS",
    "title": "Brazilian Economic Time Series",
    "description": "It provides access to and information about the most important\n    Brazilian economic time series - from the Getulio Vargas Foundation <http://portal.fgv.br/en>,\n    the Central Bank of Brazil <http://www.bcb.gov.br> and the Brazilian Institute of Geography\n    and Statistics <http://www.ibge.gov.br>. It also presents tools for managing, analysing (e.g.\n    generating dynamic reports with a complete analysis of a series) and exporting\n    these time series.",
    "version": "0.4.9",
    "maintainer": "Talitha Speranza <talitha.speranza@fgv.br>",
    "author": "Pedro Costa Ferreira [aut],\n  Talitha Speranza [aut, cre],\n  Jonatha Costa [aut],\n  Fernando Teixeira [ctb],\n  Daiane Marcolino [ctb]",
    "url": "https://github.com/nmecsys/BETS",
    "bug_reports": "https://github.com/nmecsys/BETS/issues",
    "repository": "https://cran.r-project.org/package=BETS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BETS Brazilian Economic Time Series It provides access to and information about the most important\n    Brazilian economic time series - from the Getulio Vargas Foundation <http://portal.fgv.br/en>,\n    the Central Bank of Brazil <http://www.bcb.gov.br> and the Brazilian Institute of Geography\n    and Statistics <http://www.ibge.gov.br>. It also presents tools for managing, analysing (e.g.\n    generating dynamic reports with a complete analysis of a series) and exporting\n    these time series.  "
  },
  {
    "id": 1835,
    "package_name": "BGVAR",
    "title": "Bayesian Global Vector Autoregressions",
    "description": "Estimation of Bayesian Global Vector Autoregressions (BGVAR) with different prior setups and the possibility to introduce stochastic volatility. Built-in priors include the Minnesota, the stochastic search variable selection and Normal-Gamma (NG) prior. For a reference see also Crespo Cuaresma, J., Feldkircher, M. and F. Huber (2016) \"Forecasting with Global Vector Autoregressive Models: a Bayesian Approach\", Journal of Applied Econometrics, Vol. 31(7), pp. 1371-1391 <doi:10.1002/jae.2504>. Post-processing functions allow for doing predictions, structurally identify the model with short-run or sign-restrictions and compute impulse response functions, historical decompositions and forecast error variance decompositions. Plotting functions are also available. The package has a companion paper: Boeck, M., Feldkircher, M. and F. Huber (2022) \"BGVAR: Bayesian Global Vector Autoregressions with Shrinkage Priors in R\", Journal of Statistical Software, Vol. 104(9), pp. 1-28 <doi:10.18637/jss.v104.i09>.",
    "version": "2.5.9",
    "maintainer": "Maximilian Boeck <maximilian.boeck@fau.de>",
    "author": "Maximilian Boeck [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6024-8305>),\n  Martin Feldkircher [aut] (ORCID:\n    <https://orcid.org/0000-0002-5511-9215>),\n  Florian Huber [aut] (ORCID: <https://orcid.org/0000-0002-2896-7921>),\n  Darjus Hosszejni [ctb] (ORCID: <https://orcid.org/0000-0002-3803-691X>)",
    "url": "https://github.com/mboeck11/BGVAR",
    "bug_reports": "https://github.com/mboeck11/BGVAR/issues",
    "repository": "https://cran.r-project.org/package=BGVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BGVAR Bayesian Global Vector Autoregressions Estimation of Bayesian Global Vector Autoregressions (BGVAR) with different prior setups and the possibility to introduce stochastic volatility. Built-in priors include the Minnesota, the stochastic search variable selection and Normal-Gamma (NG) prior. For a reference see also Crespo Cuaresma, J., Feldkircher, M. and F. Huber (2016) \"Forecasting with Global Vector Autoregressive Models: a Bayesian Approach\", Journal of Applied Econometrics, Vol. 31(7), pp. 1371-1391 <doi:10.1002/jae.2504>. Post-processing functions allow for doing predictions, structurally identify the model with short-run or sign-restrictions and compute impulse response functions, historical decompositions and forecast error variance decompositions. Plotting functions are also available. The package has a companion paper: Boeck, M., Feldkircher, M. and F. Huber (2022) \"BGVAR: Bayesian Global Vector Autoregressions with Shrinkage Priors in R\", Journal of Statistical Software, Vol. 104(9), pp. 1-28 <doi:10.18637/jss.v104.i09>.  "
  },
  {
    "id": 1849,
    "package_name": "BINCOR",
    "title": "Estimate the Correlation Between Two Irregular Time Series",
    "description": "Estimate the correlation between two irregular time series that are not necessarily sampled on identical time points. This program is also applicable to the situation of two evenly spaced time series that are not on the same time grid. 'BINCOR' is based on a novel estimation approach proposed by Mudelsee (2010, 2014) to estimate the correlation between two climate time series with different timescales. The idea is that autocorrelation (AR1 process) allows to correlate values obtained on different time points. 'BINCOR' contains four functions: bin_cor() (the main function to build the binned time series), plot_ts() (to plot and compare the irregular and binned time series, cor_ts() (to estimate the correlation between the binned time series) and ccf_ts() (to estimate the cross-correlation between the binned time series).",
    "version": "0.2.0",
    "maintainer": "Josu\u00e9 M. Polanco-Mart\u00ednez <josue.m.polanco@gmail.com>",
    "author": "Josu\u00e9 M. Polanco-Mart\u00ednez [aut, cph, cre],\n  Mikko Korpela [ctb, trl],\n  Aalto University [cph],\n  Manfred Mudelsee [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BINCOR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BINCOR Estimate the Correlation Between Two Irregular Time Series Estimate the correlation between two irregular time series that are not necessarily sampled on identical time points. This program is also applicable to the situation of two evenly spaced time series that are not on the same time grid. 'BINCOR' is based on a novel estimation approach proposed by Mudelsee (2010, 2014) to estimate the correlation between two climate time series with different timescales. The idea is that autocorrelation (AR1 process) allows to correlate values obtained on different time points. 'BINCOR' contains four functions: bin_cor() (the main function to build the binned time series), plot_ts() (to plot and compare the irregular and binned time series, cor_ts() (to estimate the correlation between the binned time series) and ccf_ts() (to estimate the cross-correlation between the binned time series).  "
  },
  {
    "id": 1850,
    "package_name": "BINtools",
    "title": "Bayesian BIN (Bias, Information, Noise) Model of Forecasting",
    "description": "A recently proposed Bayesian BIN model disentangles the underlying processes \n    that enable forecasters and forecasting methods to improve, decomposing forecasting accuracy into \n    three components: bias, partial information, and noise. By describing the differences between two \n    groups of forecasters, the model allows the user to carry out useful inference, such as calculating \n    the posterior probabilities of the treatment reducing bias, diminishing noise, or increasing information.\n    It also provides insight into how much tamping down bias and noise in judgment or enhancing the efficient \n    extraction of valid information from the environment improves forecasting accuracy. This package provides \n    easy access to the BIN model. For further information refer to the paper Ville A. Satop\u00e4\u00e4, Marat Salikhov,\n    Philip E. Tetlock, and Barbara Mellers (2021) \"Bias, Information, Noise: The BIN \n    Model of Forecasting\" <doi:10.1287/mnsc.2020.3882>. ",
    "version": "0.2.0",
    "maintainer": "Ville Satop\u00e4\u00e4 <ville.satopaa@gmail.com>",
    "author": "Ville Satop\u00e4\u00e4 [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3787-7303>),\n  Marat Salikhov [aut],\n  Elvira Moreno [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BINtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BINtools Bayesian BIN (Bias, Information, Noise) Model of Forecasting A recently proposed Bayesian BIN model disentangles the underlying processes \n    that enable forecasters and forecasting methods to improve, decomposing forecasting accuracy into \n    three components: bias, partial information, and noise. By describing the differences between two \n    groups of forecasters, the model allows the user to carry out useful inference, such as calculating \n    the posterior probabilities of the treatment reducing bias, diminishing noise, or increasing information.\n    It also provides insight into how much tamping down bias and noise in judgment or enhancing the efficient \n    extraction of valid information from the environment improves forecasting accuracy. This package provides \n    easy access to the BIN model. For further information refer to the paper Ville A. Satop\u00e4\u00e4, Marat Salikhov,\n    Philip E. Tetlock, and Barbara Mellers (2021) \"Bias, Information, Noise: The BIN \n    Model of Forecasting\" <doi:10.1287/mnsc.2020.3882>.   "
  },
  {
    "id": 1852,
    "package_name": "BIOdry",
    "title": "Multilevel Modeling of Dendroclimatical Fluctuations",
    "description": "Multilevel ecological data series (MEDS) are sequences of observations ordered according to temporal/spatial hierarchies that are defined by sample designs, with sample variability confined to ecological factors. Dendroclimatic MEDS of tree rings and climate are modeled into normalized fluctuations of tree growth and aridity.  Modeled fluctuations (model frames) are compared with Mantel correlograms on multiple levels defined by sample design. Package implementation can be understood by running examples in modelFrame(), and muleMan() functions. ",
    "version": "0.9.1",
    "maintainer": "Wilson Lara <wilarhen@gmail.com>",
    "author": "Wilson Lara [aut, cre] (ORCID: <https://orcid.org/0000-0003-3527-1380>),\n  Felipe Bravo [aut] (ORCID: <https://orcid.org/0000-0001-7348-6695>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BIOdry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BIOdry Multilevel Modeling of Dendroclimatical Fluctuations Multilevel ecological data series (MEDS) are sequences of observations ordered according to temporal/spatial hierarchies that are defined by sample designs, with sample variability confined to ecological factors. Dendroclimatic MEDS of tree rings and climate are modeled into normalized fluctuations of tree growth and aridity.  Modeled fluctuations (model frames) are compared with Mantel correlograms on multiple levels defined by sample design. Package implementation can be understood by running examples in modelFrame(), and muleMan() functions.   "
  },
  {
    "id": 1857,
    "package_name": "BKTR",
    "title": "Bayesian Kernelized Tensor Regression",
    "description": "Facilitates scalable spatiotemporally varying coefficient\n    modelling with Bayesian kernelized tensor regression.\n    The important features of this package are:\n    (a) Enabling local temporal and spatial modeling of the relationship between\n    the response variable and covariates.\n    (b) Implementing the model described by Lei et al. (2023) <doi:10.48550/arXiv.2109.00046>.\n    (c) Using a Bayesian Markov Chain Monte Carlo (MCMC) algorithm to sample from the posterior\n    distribution of the model parameters.\n    (d) Employing a tensor decomposition to reduce the number of estimated parameters.\n    (e) Accelerating tensor operations and enabling graphics processing unit (GPU) acceleration\n    with the 'torch' package.",
    "version": "0.2.0",
    "maintainer": "Julien Lanthier <julien.lanthier@hec.ca>",
    "author": "Julien Lanthier [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0008-8728-4996>),\n  Mengying Lei [aut] (ORCID: <https://orcid.org/0000-0001-7343-3323>),\n  Aur\u00e9lie Labbe [aut] (ORCID: <https://orcid.org/0000-0002-4207-8143>),\n  Lijun Sun [aut] (ORCID: <https://orcid.org/0000-0001-9488-0712>)",
    "url": "",
    "bug_reports": "https://github.com/julien-hec/BKTR/issues",
    "repository": "https://cran.r-project.org/package=BKTR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BKTR Bayesian Kernelized Tensor Regression Facilitates scalable spatiotemporally varying coefficient\n    modelling with Bayesian kernelized tensor regression.\n    The important features of this package are:\n    (a) Enabling local temporal and spatial modeling of the relationship between\n    the response variable and covariates.\n    (b) Implementing the model described by Lei et al. (2023) <doi:10.48550/arXiv.2109.00046>.\n    (c) Using a Bayesian Markov Chain Monte Carlo (MCMC) algorithm to sample from the posterior\n    distribution of the model parameters.\n    (d) Employing a tensor decomposition to reduce the number of estimated parameters.\n    (e) Accelerating tensor operations and enabling graphics processing unit (GPU) acceleration\n    with the 'torch' package.  "
  },
  {
    "id": 1861,
    "package_name": "BLModel",
    "title": "Black-Litterman Posterior Distribution",
    "description": "Posterior distribution in the Black-Litterman model is computed from a prior distribution given in the form of a time series of asset returns and a continuous distribution of views provided by the user as an external function.",
    "version": "1.0.2",
    "maintainer": "Andrzej Palczewski <A.Palczewski@mimuw.edu.pl>",
    "author": "Andrzej Palczewski [aut, cre],\n  Jan Palczewski [aut],\n  Alicja Gosiewska [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BLModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BLModel Black-Litterman Posterior Distribution Posterior distribution in the Black-Litterman model is computed from a prior distribution given in the form of a time series of asset returns and a continuous distribution of views provided by the user as an external function.  "
  },
  {
    "id": 1865,
    "package_name": "BLRPM",
    "title": "Stochastic Rainfall Generator Bartlett-Lewis Rectangular Pulse\nModel",
    "description": "Due to a limited availability of observed high-resolution precipitation records with adequate length, simulations with stochastic precipitation models are used to generate series for subsequent studies [e.g. Khaliq and Cunmae, 1996, <doi:10.1016/0022-1694(95)02894-3>, Vandenberghe et al., 2011, <doi:10.1029/2009WR008388>]. This package contains an R implementation of the original Bartlett-Lewis rectangular pulse model (BLRPM), developed by Rodriguez-Iturbe et al. (1987) <doi:10.1098/rspa.1987.0039>. It contains a function for simulating a precipitation time series based on storms and cells generated by the model with given or estimated model parameters. Additionally BLRPM parameters can be estimated from a given or simulated precipitation time series. The model simulations can be plotted in a three-layer plot including an overview of generated storms and cells by the model (which can also be plotted individually), a continuous step-function and a discrete precipitation time series at a chosen aggregation level. ",
    "version": "1.0",
    "maintainer": "Christoph Ritschel <christoph.ritschel@met.fu-berlin.de>",
    "author": "Christoph Ritschel",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BLRPM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BLRPM Stochastic Rainfall Generator Bartlett-Lewis Rectangular Pulse\nModel Due to a limited availability of observed high-resolution precipitation records with adequate length, simulations with stochastic precipitation models are used to generate series for subsequent studies [e.g. Khaliq and Cunmae, 1996, <doi:10.1016/0022-1694(95)02894-3>, Vandenberghe et al., 2011, <doi:10.1029/2009WR008388>]. This package contains an R implementation of the original Bartlett-Lewis rectangular pulse model (BLRPM), developed by Rodriguez-Iturbe et al. (1987) <doi:10.1098/rspa.1987.0039>. It contains a function for simulating a precipitation time series based on storms and cells generated by the model with given or estimated model parameters. Additionally BLRPM parameters can be estimated from a given or simulated precipitation time series. The model simulations can be plotted in a three-layer plot including an overview of generated storms and cells by the model (which can also be plotted individually), a continuous step-function and a discrete precipitation time series at a chosen aggregation level.   "
  },
  {
    "id": 1869,
    "package_name": "BLSloadR",
    "title": "Download Time Series Data from the U.S. Bureau of Labor\nStatistics",
    "description": "These functions provide a convenient interface for downloading data from the U.S. Bureau of Labor Statistics <https://www.bls.gov>.  The functions in this package utilize flat files produced by the Bureau of Labor Statistics, which contain full series history.  These files include employment, unemployment, wages, prices, industry and occupational data at a national, state, and sub-state level, depending on the series.  Individual functions are included for those programs which have data available at the state level.  The core functions provide direct access to the Current Employment Statistics (CES) <https://www.bls.gov/ces/>, Local Area Unemployment Statistics (LAUS) <https://www.bls.gov/lau/>, Occupational Employment and Wage Statistics (OEWS) <https://www.bls.gov/oes/> and Alternative Measures of Labor Underutilization (SALT) <https://www.bls.gov/lau/stalt.htm> data produced by the Bureau of Labor Statistics.",
    "version": "0.2",
    "maintainer": "David Schmidt <deschmidt@detr.nv.gov>",
    "author": "Nevada Department of Employment, Training, and Rehabilitation [cph],\n  David Schmidt [aut, cre]",
    "url": "https://schmidtdetr.github.io/BLSloadR/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BLSloadR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BLSloadR Download Time Series Data from the U.S. Bureau of Labor\nStatistics These functions provide a convenient interface for downloading data from the U.S. Bureau of Labor Statistics <https://www.bls.gov>.  The functions in this package utilize flat files produced by the Bureau of Labor Statistics, which contain full series history.  These files include employment, unemployment, wages, prices, industry and occupational data at a national, state, and sub-state level, depending on the series.  Individual functions are included for those programs which have data available at the state level.  The core functions provide direct access to the Current Employment Statistics (CES) <https://www.bls.gov/ces/>, Local Area Unemployment Statistics (LAUS) <https://www.bls.gov/lau/>, Occupational Employment and Wage Statistics (OEWS) <https://www.bls.gov/oes/> and Alternative Measures of Labor Underutilization (SALT) <https://www.bls.gov/lau/stalt.htm> data produced by the Bureau of Labor Statistics.  "
  },
  {
    "id": 1880,
    "package_name": "BNPTSclust",
    "title": "A Bayesian Nonparametric Algorithm for Time Series Clustering",
    "description": "Performs the algorithm for time series clustering described in Nieto-Barajas and Contreras-Cristan (2014).",
    "version": "2.0",
    "maintainer": "David Alejandro Martell Juarez <alex91599@gmail.com>",
    "author": "Martell-Juarez, D.A. & Nieto-Barajas, L.E.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BNPTSclust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BNPTSclust A Bayesian Nonparametric Algorithm for Time Series Clustering Performs the algorithm for time series clustering described in Nieto-Barajas and Contreras-Cristan (2014).  "
  },
  {
    "id": 1912,
    "package_name": "BSTFA",
    "title": "Bayesian Spatio-Temporal Factor Analysis Model",
    "description": "Implements Bayesian spatio-temporal factor analysis models for multivariate data observed across space and time. The package provides tools for model fitting via Markov chain Monte Carlo (MCMC), spatial and temporal interpolation, and visualization of latent factors and loadings to support inference and exploration of underlying spatio-temporal patterns. Designed for use in environmental, ecological, or public health applications, with support for posterior prediction and uncertainty quantification. Includes functions such as BSTFA() for model fitting and plot_factor() to visualize the latent processes.  Functions are based on and extended from methods described in Berrett, et al. (2020) <doi:10.1002/env.2609>.",
    "version": "0.1.0",
    "maintainer": "Candace Berrett <cberrett@stat.byu.edu>",
    "author": "Adam Simpson [aut],\n  Candace Berrett [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4721-3065>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BSTFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BSTFA Bayesian Spatio-Temporal Factor Analysis Model Implements Bayesian spatio-temporal factor analysis models for multivariate data observed across space and time. The package provides tools for model fitting via Markov chain Monte Carlo (MCMC), spatial and temporal interpolation, and visualization of latent factors and loadings to support inference and exploration of underlying spatio-temporal patterns. Designed for use in environmental, ecological, or public health applications, with support for posterior prediction and uncertainty quantification. Includes functions such as BSTFA() for model fitting and plot_factor() to visualize the latent processes.  Functions are based on and extended from methods described in Berrett, et al. (2020) <doi:10.1002/env.2609>.  "
  },
  {
    "id": 1913,
    "package_name": "BSTZINB",
    "title": "Association Among Disease Counts and Socio-Environmental Factors",
    "description": "Estimation of association between disease or death counts (e.g. COVID-19) and socio-environmental risk factors using a zero-inflated Bayesian spatiotemporal model. Non-spatiotemporal models and/or models without zero-inflation are also included for comparison. Functions to produce corresponding maps are also included. See Chakraborty et al. (2022) <doi:10.1007/s13253-022-00487-1> for more details on the method.",
    "version": "2.0.1",
    "maintainer": "Suman Majumder <smajumd2@gmail.com>",
    "author": "Suman Majumder [cre, aut, cph],\n  Yoon-Bae Jun [aut, cph],\n  Sounak Chakraborty [ctb],\n  Chae-Young Lim [ctb],\n  Tanujit Dey [ctb]",
    "url": "https://github.com/SumanM47/BSTZINB",
    "bug_reports": "https://github.com/SumanM47/BSTZINB/issues",
    "repository": "https://cran.r-project.org/package=BSTZINB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BSTZINB Association Among Disease Counts and Socio-Environmental Factors Estimation of association between disease or death counts (e.g. COVID-19) and socio-environmental risk factors using a zero-inflated Bayesian spatiotemporal model. Non-spatiotemporal models and/or models without zero-inflation are also included for comparison. Functions to produce corresponding maps are also included. See Chakraborty et al. (2022) <doi:10.1007/s13253-022-00487-1> for more details on the method.  "
  },
  {
    "id": 1919,
    "package_name": "BTSPAS",
    "title": "Bayesian Time-Stratified Population Analysis",
    "description": "Provides advanced Bayesian methods to estimate\n\t     abundance and run-timing from temporally-stratified\n\t     Petersen mark-recapture experiments. Methods include\n\t     hierarchical modelling of the capture probabilities\n  \t     and spline smoothing of the daily run size. Theory\n  \t     described in Bonner and Schwarz (2011)\n         <doi:10.1111/j.1541-0420.2011.01599.x>.",
    "version": "2024.11.1",
    "maintainer": "Carl J Schwarz <cschwarz.stat.sfu.ca@gmail.com>",
    "author": "Carl J Schwarz [aut, cre],\n  Simon J Bonner [aut]",
    "url": "https://github.com/cschwarz-stat-sfu-ca/BTSPAS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BTSPAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BTSPAS Bayesian Time-Stratified Population Analysis Provides advanced Bayesian methods to estimate\n\t     abundance and run-timing from temporally-stratified\n\t     Petersen mark-recapture experiments. Methods include\n\t     hierarchical modelling of the capture probabilities\n  \t     and spline smoothing of the daily run size. Theory\n  \t     described in Bonner and Schwarz (2011)\n         <doi:10.1111/j.1541-0420.2011.01599.x>.  "
  },
  {
    "id": 1920,
    "package_name": "BTSR",
    "title": "Bounded Time Series Regression",
    "description": "Simulate, estimate and forecast a wide range of regression\n    based dynamic models for bounded time series, covering the most\n    commonly applied models in the literature. The main calculations are\n    done in FORTRAN, which translates into very fast algorithms.",
    "version": "1.0.0",
    "maintainer": "Taiane Schaedler Prass <taianeprass@gmail.com>",
    "author": "Taiane Schaedler Prass [aut, cre, com] (ORCID:\n    <https://orcid.org/0000-0003-3136-909X>),\n  Guilherme Pumi [ctb, aut] (ORCID:\n    <https://orcid.org/0000-0002-6256-3170>),\n  F\u00e1bio Mariano Bayer [ctb] (ORCID:\n    <https://orcid.org/0000-0002-1464-0805>),\n  Jack Joseph Dongarra [ctb] (LINPACK subroutines (dtrsl, dpofa, ddot)),\n  Cleve Moler [ctb] (LINPACK subroutines (dtrsl, dpofa, ddot)),\n  Gilbert Wright Stewart [ctb] (LINPACK subroutines (dtrsl, dpofa, ddot)),\n  Ciyou Zhu [ctb] (L-BFGS-B algorithm subroutines),\n  Richard H. Byrd [ctb] (L-BFGS-B algorithm subroutines),\n  Jorge Nocedal [ctb] (L-BFGS-B algorithm subroutines),\n  Jose Luis Morales [ctb] (L-BFGS-B algorithm subroutines),\n  Peihuang Lu-Chen [ctb] (L-BFGS-B algorithm subroutines),\n  John Burkardt [ctb] (Trigamma function (FORTRAN90 version)),\n  Alan Miller [ctb] (FORTRAN90 version of NSWC special function psi and\n    amendments to minim subroutine),\n  D.E. Shaw [ctb] (Original minim subroutine),\n  Robert W.M. Wedderburn [ctb] (Amendments to minim subroutine)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BTSR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BTSR Bounded Time Series Regression Simulate, estimate and forecast a wide range of regression\n    based dynamic models for bounded time series, covering the most\n    commonly applied models in the literature. The main calculations are\n    done in FORTRAN, which translates into very fast algorithms.  "
  },
  {
    "id": 1926,
    "package_name": "BVAR",
    "title": "Hierarchical Bayesian Vector Autoregression",
    "description": "Estimation of hierarchical Bayesian vector autoregressive models\n    following Kuschnig & Vashold (2021) <doi:10.18637/jss.v100.i14>.\n    Implements hierarchical prior selection for conjugate priors in the fashion\n    of Giannone, Lenza & Primiceri (2015) <doi:10.1162/REST_a_00483>.\n    Functions to compute and identify impulse responses, calculate forecasts,\n    forecast error variance decompositions and scenarios are available.\n    Several methods to print, plot and summarise results facilitate analysis.",
    "version": "1.0.5",
    "maintainer": "Nikolas Kuschnig <nikolas.kuschnig@wu.ac.at>",
    "author": "Nikolas Kuschnig [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6642-2543>),\n  Lukas Vashold [aut] (ORCID: <https://orcid.org/0000-0002-3562-3414>),\n  Nirai Tomass [ctb],\n  Michael McCracken [dtc],\n  Serena Ng [dtc]",
    "url": "https://github.com/nk027/bvar",
    "bug_reports": "https://github.com/nk027/bvar/issues",
    "repository": "https://cran.r-project.org/package=BVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BVAR Hierarchical Bayesian Vector Autoregression Estimation of hierarchical Bayesian vector autoregressive models\n    following Kuschnig & Vashold (2021) <doi:10.18637/jss.v100.i14>.\n    Implements hierarchical prior selection for conjugate priors in the fashion\n    of Giannone, Lenza & Primiceri (2015) <doi:10.1162/REST_a_00483>.\n    Functions to compute and identify impulse responses, calculate forecasts,\n    forecast error variance decompositions and scenarios are available.\n    Several methods to print, plot and summarise results facilitate analysis.  "
  },
  {
    "id": 1951,
    "package_name": "BayesARIMAX",
    "title": "Bayesian Estimation of ARIMAX Model",
    "description": "The Autoregressive Integrated Moving Average (ARIMA) model is very popular univariate time series model. Its application has been widened by the incorporation of exogenous variable(s) (X) in the model and modified as ARIMAX by Bierens (1987) <doi:10.1016/0304-4076(87)90086-8>. In this package we estimate the ARIMAX model using Bayesian framework. ",
    "version": "0.1.1",
    "maintainer": "Achal Lama <achal.lama@icar.gov.in>",
    "author": "Achal Lama [aut, cre],\n  Kn Singh [aut],\n  Bishal Gurung [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesARIMAX",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesARIMAX Bayesian Estimation of ARIMAX Model The Autoregressive Integrated Moving Average (ARIMA) model is very popular univariate time series model. Its application has been widened by the incorporation of exogenous variable(s) (X) in the model and modified as ARIMAX by Bierens (1987) <doi:10.1016/0304-4076(87)90086-8>. In this package we estimate the ARIMAX model using Bayesian framework.   "
  },
  {
    "id": 1953,
    "package_name": "BayesBEKK",
    "title": "Bayesian Estimation of Bivariate Volatility Model",
    "description": "The Multivariate Generalized Autoregressive Conditional Heteroskedasticity (MGARCH) models are used for modelling the volatile multivariate data sets. In this package a variant of MGARCH called BEKK (Baba, Engle, Kraft, Kroner) proposed by Engle and Kroner (1995) <http://www.jstor.org/stable/3532933> has been used to estimate the bivariate time series data using Bayesian technique.",
    "version": "0.1.1",
    "maintainer": "Achal Lama <achal.lama@icar.gov.in>",
    "author": "Achal Lama, Girish K Jha, K N Singh and Bishal Gurung",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesBEKK",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesBEKK Bayesian Estimation of Bivariate Volatility Model The Multivariate Generalized Autoregressive Conditional Heteroskedasticity (MGARCH) models are used for modelling the volatile multivariate data sets. In this package a variant of MGARCH called BEKK (Baba, Engle, Kraft, Kroner) proposed by Engle and Kroner (1995) <http://www.jstor.org/stable/3532933> has been used to estimate the bivariate time series data using Bayesian technique.  "
  },
  {
    "id": 1962,
    "package_name": "BayesChange",
    "title": "Bayesian Methods for Change Points Analysis",
    "description": "Perform change points detection on univariate and multivariate time series according to the methods presented by Asael Fabian Mart\u00ednez and Rams\u00e9s H. Mena (2014) <doi:10.1214/14-BA878> and Corradin, Danese and Ongaro (2022) <doi:10.1016/j.ijar.2021.12.019>. It also clusters different types of time dependent data with common change points, see \"Model-based clustering of time-dependent observations with common structural changes\" (Corradin,Danese,KhudaBukhsh and Ongaro, 2024) <doi:10.48550/arXiv.2410.09552> for details. ",
    "version": "2.1.3",
    "maintainer": "Luca Danese <l.danese1@campus.unimib.it>",
    "author": "Luca Danese [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-8444-8563>),\n  Riccardo Corradin [aut],\n  Andrea Ongaro [aut]",
    "url": "https://github.com/lucadanese/BayesChange",
    "bug_reports": "https://github.com/lucadanese/BayesChange/issues",
    "repository": "https://cran.r-project.org/package=BayesChange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesChange Bayesian Methods for Change Points Analysis Perform change points detection on univariate and multivariate time series according to the methods presented by Asael Fabian Mart\u00ednez and Rams\u00e9s H. Mena (2014) <doi:10.1214/14-BA878> and Corradin, Danese and Ongaro (2022) <doi:10.1016/j.ijar.2021.12.019>. It also clusters different types of time dependent data with common change points, see \"Model-based clustering of time-dependent observations with common structural changes\" (Corradin,Danese,KhudaBukhsh and Ongaro, 2024) <doi:10.48550/arXiv.2410.09552> for details.   "
  },
  {
    "id": 1987,
    "package_name": "BayesMoFo",
    "title": "Bayesian Mortality Forecasting",
    "description": "Carry out Bayesian estimation and forecasting for a variety of stochastic mortality models using vague prior distributions. Models supported include numerous well-established approaches introduced in the actuarial and demographic literature, such as the Lee-Carter (1992) <doi:10.1080/01621459.1992.10475265>, the Cairns-Blake-Dowd (2009) <doi:10.1080/10920277.2009.10597538>, the Li-Lee (2005) <doi:10.1353/dem.2005.0021>, and the Plat (2009) <doi:10.1016/j.insmatheco.2009.08.006> models. The package is designed to analyse stratified mortality data structured as a 3-dimensional array of dimensions p \u00d7 A \u00d7 T (strata \u00d7 age \u00d7 year). Stratification can represent factors such as cause of death, country, deprivation level, sex, geographic region, insurance product, marital status, socioeconomic group, or smoking behavior. While the primary focus is on analysing stratified data (p > 1), the package can also handle mortality data that are not stratified (p = 1). Model selection via the Deviance Information Criterion (DIC) is supported.",
    "version": "0.1.0",
    "maintainer": "Jackie Siaw Tze Wong <jw19203@essex.ac.uk>",
    "author": "Jackie Siaw Tze Wong [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0314-6684>),\n  Alex Diana [ctb],\n  Aniketh Pittea [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesMoFo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesMoFo Bayesian Mortality Forecasting Carry out Bayesian estimation and forecasting for a variety of stochastic mortality models using vague prior distributions. Models supported include numerous well-established approaches introduced in the actuarial and demographic literature, such as the Lee-Carter (1992) <doi:10.1080/01621459.1992.10475265>, the Cairns-Blake-Dowd (2009) <doi:10.1080/10920277.2009.10597538>, the Li-Lee (2005) <doi:10.1353/dem.2005.0021>, and the Plat (2009) <doi:10.1016/j.insmatheco.2009.08.006> models. The package is designed to analyse stratified mortality data structured as a 3-dimensional array of dimensions p \u00d7 A \u00d7 T (strata \u00d7 age \u00d7 year). Stratification can represent factors such as cause of death, country, deprivation level, sex, geographic region, insurance product, marital status, socioeconomic group, or smoking behavior. While the primary focus is on analysing stratified data (p > 1), the package can also handle mortality data that are not stratified (p = 1). Model selection via the Deviance Information Criterion (DIC) is supported.  "
  },
  {
    "id": 1988,
    "package_name": "BayesMortalityPlus",
    "title": "Bayesian Mortality Modelling",
    "description": "Fit Bayesian graduation mortality using the Heligman-Pollard model, as seen in Heligman, L., & Pollard, J. H. (1980) <doi:10.1017/S0020268100040257> and Dellaportas, Petros, et al. (2001) <doi:10.1111/1467-985X.00202>, and dynamic linear model (Campagnoli, P., Petris, G., and Petrone, S. (2009) <doi:10.1007/b135794_2>). While Heligman-Pollard has parameters with a straightforward interpretation yielding some rich analysis, the dynamic linear model provides a very flexible adjustment of the mortality curves by controlling the discount factor value. Closing methods for both Heligman-Pollard and dynamic linear model were also implemented according to Dodd, Erengul, et al. (2018) <https://www.jstor.org/stable/48547511>. The Bayesian Lee-Carter model is also implemented to fit historical mortality tables time series to predict the mortality in the following years and to do improvement analysis, as seen in Lee, R. D., & Carter, L. R. (1992) <doi:10.1080/01621459.1992.10475265> and Pedroza, C. (2006) <doi:10.1093/biostatistics/kxj024>. Journal publication available at <doi:10.18637/jss.v113.i09>.",
    "version": "1.0.0",
    "maintainer": "Luiz F. V. Figueiredo <labmapackage@gmail.com>",
    "author": "Luiz F. V. Figueiredo [aut, cre] (ORCID:\n    <https://orcid.org/0009-0007-9002-1997>),\n  Lucas M. F. Silva [aut] (ORCID:\n    <https://orcid.org/0009-0000-7452-3486>),\n  Viviana G. R. Lobo [aut] (ORCID:\n    <https://orcid.org/0000-0002-4076-8327>),\n  Thais C. O. Fonseca [aut] (ORCID:\n    <https://orcid.org/0000-0002-4943-3259>),\n  Mariane B. Alves [aut] (ORCID: <https://orcid.org/0000-0002-2489-9300>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesMortalityPlus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesMortalityPlus Bayesian Mortality Modelling Fit Bayesian graduation mortality using the Heligman-Pollard model, as seen in Heligman, L., & Pollard, J. H. (1980) <doi:10.1017/S0020268100040257> and Dellaportas, Petros, et al. (2001) <doi:10.1111/1467-985X.00202>, and dynamic linear model (Campagnoli, P., Petris, G., and Petrone, S. (2009) <doi:10.1007/b135794_2>). While Heligman-Pollard has parameters with a straightforward interpretation yielding some rich analysis, the dynamic linear model provides a very flexible adjustment of the mortality curves by controlling the discount factor value. Closing methods for both Heligman-Pollard and dynamic linear model were also implemented according to Dodd, Erengul, et al. (2018) <https://www.jstor.org/stable/48547511>. The Bayesian Lee-Carter model is also implemented to fit historical mortality tables time series to predict the mortality in the following years and to do improvement analysis, as seen in Lee, R. D., & Carter, L. R. (1992) <doi:10.1080/01621459.1992.10475265> and Pedroza, C. (2006) <doi:10.1093/biostatistics/kxj024>. Journal publication available at <doi:10.18637/jss.v113.i09>.  "
  },
  {
    "id": 2019,
    "package_name": "BayesianFitForecast",
    "title": "Bayesian Parameter Estimation and Forecasting for\nEpidemiological Models",
    "description": "Methods for Bayesian parameter estimation and forecasting in epidemiological models. \n    Functions enable model fitting using Bayesian methods and generate forecasts with uncertainty quantification. \n    Implements approaches described in <doi:10.48550/arXiv.2411.05371> and <doi:10.1002/sim.9164>.",
    "version": "1.1.0",
    "maintainer": "Gerardo Chowell <gchowell@gsu.edu>",
    "author": "Hamed Karami [aut],\n  Amanda Bleichrodt [aut],\n  Ruiyan Luo [aut],\n  Gerardo Chowell [aut, cre]",
    "url": "https://github.com/gchowell/BayesianFitForecast",
    "bug_reports": "https://github.com/gchowell/BayesianFitForecast/issues",
    "repository": "https://cran.r-project.org/package=BayesianFitForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesianFitForecast Bayesian Parameter Estimation and Forecasting for\nEpidemiological Models Methods for Bayesian parameter estimation and forecasting in epidemiological models. \n    Functions enable model fitting using Bayesian methods and generate forecasts with uncertainty quantification. \n    Implements approaches described in <doi:10.48550/arXiv.2411.05371> and <doi:10.1002/sim.9164>.  "
  },
  {
    "id": 2067,
    "package_name": "BigVAR",
    "title": "Dimension Reduction Methods for Multivariate Time Series",
    "description": "Estimates VAR and VARX models with Structured Penalties.",
    "version": "1.1.4",
    "maintainer": "Will Nicholson <wbn8@cornell.edu>",
    "author": "Will Nicholson [cre, aut],\n  David Matteson [aut],\n  Jacob Bien [aut]",
    "url": "https://github.com/wbnicholson/BigVAR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BigVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BigVAR Dimension Reduction Methods for Multivariate Time Series Estimates VAR and VARX models with Structured Penalties.  "
  },
  {
    "id": 2091,
    "package_name": "BioTIMEr",
    "title": "Tools to Use and Explore the 'BioTIME' Database",
    "description": "The 'BioTIME' database was first published in\n    2018 and inspired ideas, questions, project and research\n    article. To make it even more accessible, an R package\n    was created.\n    The 'BioTIMEr' package provides tools designed to interact with the\n    'BioTIME' database. The functions provided include the 'BioTIME' recommended\n    methods for preparing (gridding and rarefaction) time series data, a\n    selection of standard biodiversity metrics (including species richness,\n    numerical abundance and exponential Shannon) alongside examples on how to\n    display change over time. It also includes a sample subset of both the query\n    and meta data, the full versions of which are freely available on the 'BioTIME'\n    website <https://biotime.st-andrews.ac.uk/home.php>.",
    "version": "0.3.0",
    "maintainer": "Alban Sagouis <alban.sagouis@idiv.de>",
    "author": "Alban Sagouis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3827-1063>),\n  Faye Moyes [aut] (ORCID: <https://orcid.org/0000-0001-9687-0593>),\n  In\u00eas S. Martins [aut, rev] (ORCID:\n    <https://orcid.org/0000-0003-4328-7286>),\n  Shane A. Blowes [ctb] (ORCID: <https://orcid.org/0000-0001-6310-3670>),\n  Viviana Brambilla [ctb] (ORCID:\n    <https://orcid.org/0000-0002-0560-4693>),\n  Cher F. Y. Chow [ctb] (ORCID: <https://orcid.org/0000-0002-1020-8409>),\n  Ada Fontrodona-Eslava [ctb] (ORCID:\n    <https://orcid.org/0000-0001-7275-7174>),\n  Laura Ant\u00e3o [ctb, rev] (ORCID: <https://orcid.org/0000-0001-6612-9366>),\n  Jonathan M. Chase [fnd] (ORCID:\n    <https://orcid.org/0000-0001-5580-4303>),\n  Maria Dornelas [fnd, cph] (ORCID:\n    <https://orcid.org/0000-0003-2077-7055>),\n  Anne E. Magurran [fnd] (ORCID: <https://orcid.org/0000-0002-0036-2795>),\n  European Research Council grant AdG BioTIME 250189 [fnd],\n  European Research Council grant PoC BioCHANGE 727440 [fnd],\n  European Research Council grant AdG MetaCHANGE 101098020 [fnd],\n  The Leverhulme Centre for Anthropocene Biodiversity grant RC-2018-021\n    [fnd],\n  German Centre for Integrative Biodiversity Research (iDiv)\n    Halle-Jena-Leipzig [fnd] (ROR: <https://ror.org/01jty7g66>),\n  Martin Luther University Halle-Wittenberg [fnd] (ROR:\n    <https://ror.org/05gqaka33>),\n  University of St Andrews [fnd] (ROR: <https://ror.org/02wn5qz54>)",
    "url": "https://github.com/bioTIMEHub/BioTIMEr",
    "bug_reports": "https://github.com/bioTIMEHub/BioTIMEr/issues",
    "repository": "https://cran.r-project.org/package=BioTIMEr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BioTIMEr Tools to Use and Explore the 'BioTIME' Database The 'BioTIME' database was first published in\n    2018 and inspired ideas, questions, project and research\n    article. To make it even more accessible, an R package\n    was created.\n    The 'BioTIMEr' package provides tools designed to interact with the\n    'BioTIME' database. The functions provided include the 'BioTIME' recommended\n    methods for preparing (gridding and rarefaction) time series data, a\n    selection of standard biodiversity metrics (including species richness,\n    numerical abundance and exponential Shannon) alongside examples on how to\n    display change over time. It also includes a sample subset of both the query\n    and meta data, the full versions of which are freely available on the 'BioTIME'\n    website <https://biotime.st-andrews.ac.uk/home.php>.  "
  },
  {
    "id": 2127,
    "package_name": "BondValuation",
    "title": "Fixed Coupon Bond Valuation Allowing for Odd Coupon Periods and\nVarious Day Count Conventions",
    "description": "Analysis of large datasets of fixed coupon bonds, allowing for irregular first and last coupon periods and various day count conventions. With this package you can compute the yield to maturity, the modified and MacAulay durations and the convexity of fixed-rate bonds. It provides the function AnnivDates, which can be used to evaluate the quality of the data and return time-invariant properties and temporal structure of a bond.",
    "version": "0.1.1",
    "maintainer": "Djatschenko Wadim <wadim.djatschenko@gmx.de>",
    "author": "Djatschenko Wadim [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BondValuation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BondValuation Fixed Coupon Bond Valuation Allowing for Odd Coupon Periods and\nVarious Day Count Conventions Analysis of large datasets of fixed coupon bonds, allowing for irregular first and last coupon periods and various day count conventions. With this package you can compute the yield to maturity, the modified and MacAulay durations and the convexity of fixed-rate bonds. It provides the function AnnivDates, which can be used to evaluate the quality of the data and return time-invariant properties and temporal structure of a bond.  "
  },
  {
    "id": 2131,
    "package_name": "BoolNet",
    "title": "Construction, Simulation and Analysis of Boolean Networks",
    "description": "Functions to reconstruct, generate, and simulate synchronous, asynchronous, probabilistic, and temporal Boolean networks. Provides also functions to analyze and visualize attractors in Boolean networks <doi:10.1093/bioinformatics/btq124>.",
    "version": "2.1.9",
    "maintainer": "Hans A. Kestler <hans.kestler@uni-ulm.de>",
    "author": "Christoph M\u00fcssel [aut],\n  Martin Hopfensitz [aut],\n  Dao Zhou [aut],\n  Hans A. Kestler [aut, cre],\n  Armin Biere [ctb] (contributed PicoSAT code),\n  Troy D. Hanson [ctb] (contributed uthash macros)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BoolNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BoolNet Construction, Simulation and Analysis of Boolean Networks Functions to reconstruct, generate, and simulate synchronous, asynchronous, probabilistic, and temporal Boolean networks. Provides also functions to analyze and visualize attractors in Boolean networks <doi:10.1093/bioinformatics/btq124>.  "
  },
  {
    "id": 2136,
    "package_name": "BootPR",
    "title": "Bootstrap Prediction Intervals and Bias-Corrected Forecasting",
    "description": "Contains functions for bias-Corrected Forecasting and Bootstrap Prediction Intervals for Autoregressive Time Series.",
    "version": "1.0",
    "maintainer": "Jae H. Kim <jaekim8080@gmail.com>",
    "author": "Jae. H. Kim <jaekim8080@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BootPR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BootPR Bootstrap Prediction Intervals and Bias-Corrected Forecasting Contains functions for bias-Corrected Forecasting and Bootstrap Prediction Intervals for Autoregressive Time Series.  "
  },
  {
    "id": 2137,
    "package_name": "BootWPTOS",
    "title": "Test Stationarity using Bootstrap Wavelet Packet Tests",
    "description": "Provides significance tests for second-order stationarity\n\tfor time series using bootstrap wavelet packet tests.\n\tProvides functionality to visualize the time series with\n\tthe results of the hypothesis tests superimposed.\n\tThe methodology is described in Cardinali, A and Nason, G P (2016)\n\t\"Practical powerful wavelet packet tests for second-order stationarity.\"\n\tApplied and Computational Harmonic Analysis, 44, 558-585\n\t<doi:10.1016/j.acha.2016.06.006>.",
    "version": "1.2.1",
    "maintainer": "Guy Nason <g.nason@imperial.ac.uk>",
    "author": "Guy Nason [aut, cre],\n  Alessandro Cardinali [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BootWPTOS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BootWPTOS Test Stationarity using Bootstrap Wavelet Packet Tests Provides significance tests for second-order stationarity\n\tfor time series using bootstrap wavelet packet tests.\n\tProvides functionality to visualize the time series with\n\tthe results of the hypothesis tests superimposed.\n\tThe methodology is described in Cardinali, A and Nason, G P (2016)\n\t\"Practical powerful wavelet packet tests for second-order stationarity.\"\n\tApplied and Computational Harmonic Analysis, 44, 558-585\n\t<doi:10.1016/j.acha.2016.06.006>.  "
  },
  {
    "id": 2146,
    "package_name": "BrainCon",
    "title": "Inference the Partial Correlations Based on Time Series Data",
    "description": "A statistical tool to inference the multi-level partial correlations based on multi-subject time series data, especially for brain functional connectivity. It combines both individual and population level inference by using  the methods of Qiu and Zhou. (2021)<DOI: 10.1080/01621459.2021.1917417> and Genovese and Wasserman. (2006)<DOI: 10.1198/016214506000000339>. It realizes two reliable estimation methods of partial correlation coefficients, using scaled lasso and lasso. It can be used to estimate individual- or population-level partial correlations, identify nonzero ones, and find out unequal partial correlation coefficients between two populations.",
    "version": "0.3.0",
    "maintainer": "Yunhaonan Yang <haonan_yy@pku.edu.cn>",
    "author": "Yunhaonan Yang [aut, cre],\n  Peng Wu [aut],\n  Xin Gai [aut],\n  Yumou Qiu [aut],\n  Xiaohua Zhou [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BrainCon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BrainCon Inference the Partial Correlations Based on Time Series Data A statistical tool to inference the multi-level partial correlations based on multi-subject time series data, especially for brain functional connectivity. It combines both individual and population level inference by using  the methods of Qiu and Zhou. (2021)<DOI: 10.1080/01621459.2021.1917417> and Genovese and Wasserman. (2006)<DOI: 10.1198/016214506000000339>. It realizes two reliable estimation methods of partial correlation coefficients, using scaled lasso and lasso. It can be used to estimate individual- or population-level partial correlations, identify nonzero ones, and find out unequal partial correlation coefficients between two populations.  "
  },
  {
    "id": 2172,
    "package_name": "CADFtest",
    "title": "A Package to Perform Covariate Augmented Dickey-Fuller Unit Root\nTests",
    "description": "Hansen's (1995) Covariate-Augmented\n        Dickey-Fuller (CADF) test. The only required argument is y, the\n        Tx1 time series to be tested. If no stationary covariate X is\n        passed to the procedure, then an ordinary ADF test is\n        performed. The p-values of the test are computed using the\n        procedure illustrated in Lupi (2009).",
    "version": "0.3-3",
    "maintainer": "Claudio Lupi <lupi@unimol.it>",
    "author": "Claudio Lupi",
    "url": "http://www.jstatsoft.org/v32/i02",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CADFtest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CADFtest A Package to Perform Covariate Augmented Dickey-Fuller Unit Root\nTests Hansen's (1995) Covariate-Augmented\n        Dickey-Fuller (CADF) test. The only required argument is y, the\n        Tx1 time series to be tested. If no stationary covariate X is\n        passed to the procedure, then an ordinary ADF test is\n        performed. The p-values of the test are computed using the\n        procedure illustrated in Lupi (2009).  "
  },
  {
    "id": 2174,
    "package_name": "CAGR",
    "title": "Compound Annual Growth Rate",
    "description": "A time series usually does not have a uniform growth rate. Compound Annual Growth Rate measures the average annual growth over a given period. More details can be found in Bardhan et al. (2022) <DOI:10.18805/ag.D-5418>.",
    "version": "1.1.1",
    "maintainer": "Debopam Rakshit <rakshitdebopam@yahoo.com>",
    "author": "Debopam Rakshit [aut, cre],\n  Dwaipayan Bardhan [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CAGR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CAGR Compound Annual Growth Rate A time series usually does not have a uniform growth rate. Compound Annual Growth Rate measures the average annual growth over a given period. More details can be found in Bardhan et al. (2022) <DOI:10.18805/ag.D-5418>.  "
  },
  {
    "id": 2182,
    "package_name": "CARBayesST",
    "title": "Spatio-Temporal Generalised Linear Mixed Models for Areal Unit\nData",
    "description": "Implements a class of univariate and multivariate spatio-temporal generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, or Poisson, but for some models only the binomial and Poisson data likelihoods are available. The spatio-temporal autocorrelation is modelled by  random effects, which are assigned conditional autoregressive (CAR) style prior distributions. A number of different random effects structures are available, including models similar to Rushworth et al. (2014) <doi:10.1016/j.sste.2014.05.001>. Full details are given in the vignette accompanying this package. The creation and development of this package was supported by the Engineering and Physical Sciences Research Council  (EPSRC) grants EP/J017442/1 and EP/T004878/1 and the Medical Research Council (MRC) grant MR/L022184/1.",
    "version": "4.0",
    "maintainer": "Duncan Lee <Duncan.Lee@glasgow.ac.uk>",
    "author": "Duncan Lee, Alastair Rushworth, Gary Napier and William Pettersson ",
    "url": "https://github.com/duncanplee/CARBayesST",
    "bug_reports": "https://github.com/duncanplee/CARBayesST/issues",
    "repository": "https://cran.r-project.org/package=CARBayesST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CARBayesST Spatio-Temporal Generalised Linear Mixed Models for Areal Unit\nData Implements a class of univariate and multivariate spatio-temporal generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, or Poisson, but for some models only the binomial and Poisson data likelihoods are available. The spatio-temporal autocorrelation is modelled by  random effects, which are assigned conditional autoregressive (CAR) style prior distributions. A number of different random effects structures are available, including models similar to Rushworth et al. (2014) <doi:10.1016/j.sste.2014.05.001>. Full details are given in the vignette accompanying this package. The creation and development of this package was supported by the Engineering and Physical Sciences Research Council  (EPSRC) grants EP/J017442/1 and EP/T004878/1 and the Medical Research Council (MRC) grant MR/L022184/1.  "
  },
  {
    "id": 2183,
    "package_name": "CARBayesdata",
    "title": "Data Used in the Vignettes Accompanying the CARBayes and\nCARBayesST Packages",
    "description": "Spatio-temporal data from Scotland used in the vignettes accompanying the CARBayes (spatial modelling) and CARBayesST (spatio-temporal modelling) packages. Most of the data relate to the set of 271 Intermediate Zones (IZ)  that make up the 2001 definition of the  Greater Glasgow and Clyde health board. ",
    "version": "3.0",
    "maintainer": "Duncan Lee <Duncan.Lee@glasgow.ac.uk>",
    "author": "Duncan Lee",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CARBayesdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CARBayesdata Data Used in the Vignettes Accompanying the CARBayes and\nCARBayesST Packages Spatio-temporal data from Scotland used in the vignettes accompanying the CARBayes (spatial modelling) and CARBayesST (spatio-temporal modelling) packages. Most of the data relate to the set of 271 Intermediate Zones (IZ)  that make up the 2001 definition of the  Greater Glasgow and Clyde health board.   "
  },
  {
    "id": 2185,
    "package_name": "CARME",
    "title": "CAR-MM Modelling in Stan",
    "description": "'Stan' based functions to estimate CAR-MM models. These models allow to estimate Generalised Linear Models with CAR (conditional autoregressive) spatial random effects for spatially and temporally misaligned data, provided a suitable Multiple Membership matrix. The main references are Gramatica, Liverani and Congdon (2023) <doi:10.1214/23-BA1370>, Petrof, Neyens, Nuyts, Nackaerts, Nemery and Faes (2020) <doi:10.1002/sim.8697> and Gramatica, Congdon and Liverani <doi:10.1111/rssc.12480>.",
    "version": "0.1.1",
    "maintainer": "Marco Gramatica <gramaticamarco@gmail.com>",
    "author": "Marco Gramatica [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6374-0933>),\n  Silvia Liverani [aut] (ORCID: <https://orcid.org/0000-0002-1870-3017>),\n  Peter Congdon [aut] (ORCID: <https://orcid.org/0000-0003-1934-9205>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CARME",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CARME CAR-MM Modelling in Stan 'Stan' based functions to estimate CAR-MM models. These models allow to estimate Generalised Linear Models with CAR (conditional autoregressive) spatial random effects for spatially and temporally misaligned data, provided a suitable Multiple Membership matrix. The main references are Gramatica, Liverani and Congdon (2023) <doi:10.1214/23-BA1370>, Petrof, Neyens, Nuyts, Nackaerts, Nemery and Faes (2020) <doi:10.1002/sim.8697> and Gramatica, Congdon and Liverani <doi:10.1111/rssc.12480>.  "
  },
  {
    "id": 2191,
    "package_name": "CAST",
    "title": "'caret' Applications for Spatial-Temporal Models",
    "description": "Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. CAST includes functions to improve spatial or spatial-temporal modelling tasks using 'caret'. It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables in view to their contribution to the spatial model performance. CAST further includes functionality to estimate the (spatial) area of applicability of prediction models. Methods are described in Meyer et al. (2018) <doi:10.1016/j.envsoft.2017.12.001>; Meyer et al. (2019) <doi:10.1016/j.ecolmodel.2019.108815>; Meyer and Pebesma (2021) <doi:10.1111/2041-210X.13650>; Mil\u00e0 et al. (2022) <doi:10.1111/2041-210X.13851>; Meyer and Pebesma (2022) <doi:10.1038/s41467-022-29838-9>; Linnenbrink et al. (2023) <doi:10.5194/egusphere-2023-1308>; Schumacher et al. (2024) <doi:10.5194/egusphere-2024-2730>. The package is described in detail in Meyer et al. (2024) <doi:10.48550/arXiv.2404.06978>.",
    "version": "1.0.3",
    "maintainer": "Hanna Meyer <hanna.meyer@uni-muenster.de>",
    "author": "Hanna Meyer [cre, aut],\n  Carles Mil\u00e0 [aut],\n  Marvin Ludwig [aut],\n  Jan Linnenbrink [aut],\n  Fabian Schumacher [aut],\n  Philipp Otto [ctb],\n  Chris Reudenbach [ctb],\n  Thomas Nauss [ctb],\n  Edzer Pebesma [ctb],\n  Jakub Nowosad [ctb]",
    "url": "https://github.com/HannaMeyer/CAST,\nhttps://hannameyer.github.io/CAST/",
    "bug_reports": "https://github.com/HannaMeyer/CAST/issues/",
    "repository": "https://cran.r-project.org/package=CAST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CAST 'caret' Applications for Spatial-Temporal Models Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. CAST includes functions to improve spatial or spatial-temporal modelling tasks using 'caret'. It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables in view to their contribution to the spatial model performance. CAST further includes functionality to estimate the (spatial) area of applicability of prediction models. Methods are described in Meyer et al. (2018) <doi:10.1016/j.envsoft.2017.12.001>; Meyer et al. (2019) <doi:10.1016/j.ecolmodel.2019.108815>; Meyer and Pebesma (2021) <doi:10.1111/2041-210X.13650>; Mil\u00e0 et al. (2022) <doi:10.1111/2041-210X.13851>; Meyer and Pebesma (2022) <doi:10.1038/s41467-022-29838-9>; Linnenbrink et al. (2023) <doi:10.5194/egusphere-2023-1308>; Schumacher et al. (2024) <doi:10.5194/egusphere-2024-2730>. The package is described in detail in Meyer et al. (2024) <doi:10.48550/arXiv.2404.06978>.  "
  },
  {
    "id": 2203,
    "package_name": "CBRT",
    "title": "CBRT Data on Turkish Economy",
    "description": "The Central Bank of the Republic of Turkey (CBRT) provides one of \n  the most comprehensive time series databases on the Turkish economy. The 'CBRT' \n  package provides functions for accessing the CBRT's electronic data delivery \n  system <https://evds2.tcmb.gov.tr/>. It contains the lists of all data \n  categories and data groups for searching the available variables (data series).  \n  As of November 3, 2024, there were 40,826 variables in the dataset. The lists \n  of data categories and data groups can be updated by the user at any time. A \n  specific variable, a group of variables, or all variables in a data group can \n  be downloaded at different frequencies using a variety of aggregation methods.",
    "version": "0.1.1",
    "maintainer": "Erol Taymaz <etaymaz@metu.edu.tr>",
    "author": "Erol Taymaz [aut, cre] (ORCID: <https://orcid.org/0000-0001-7525-6674>)",
    "url": "https://github.com/etaymaz/CBRT",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CBRT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CBRT CBRT Data on Turkish Economy The Central Bank of the Republic of Turkey (CBRT) provides one of \n  the most comprehensive time series databases on the Turkish economy. The 'CBRT' \n  package provides functions for accessing the CBRT's electronic data delivery \n  system <https://evds2.tcmb.gov.tr/>. It contains the lists of all data \n  categories and data groups for searching the available variables (data series).  \n  As of November 3, 2024, there were 40,826 variables in the dataset. The lists \n  of data categories and data groups can be updated by the user at any time. A \n  specific variable, a group of variables, or all variables in a data group can \n  be downloaded at different frequencies using a variety of aggregation methods.  "
  },
  {
    "id": 2204,
    "package_name": "CBSr",
    "title": "Fits Cubic Bezier Spline Functions to Intertemporal and Risky\nChoice Data",
    "description": "Uses monotonically constrained Cubic Bezier Splines (CBS) to approximate latent utility functions in intertemporal choice and risky choice data. For more information, see Lee, Glaze, Bradlow, and Kable <doi:10.1007/s11336-020-09723-4>.",
    "version": "1.0.5",
    "maintainer": "Sangil Lee <sangillee3rd@gmail.com>",
    "author": "Sangil Lee [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CBSr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CBSr Fits Cubic Bezier Spline Functions to Intertemporal and Risky\nChoice Data Uses monotonically constrained Cubic Bezier Splines (CBS) to approximate latent utility functions in intertemporal choice and risky choice data. For more information, see Lee, Glaze, Bradlow, and Kable <doi:10.1007/s11336-020-09723-4>.  "
  },
  {
    "id": 2232,
    "package_name": "CEEMDANML",
    "title": "CEEMDAN Decomposition Based Hybrid Machine Learning Models",
    "description": "Noise in the time-series data significantly affects the accuracy of the Machine Learning (ML) models (Artificial Neural Network and Support Vector Regression are considered here). Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) decomposes the time series data into sub-series and help to improve the model performance. The models can achieve higher prediction accuracy than the traditional ML models. Two models have been provided here for time series forecasting. More information may be obtained from Garai and Paul (2023) <doi:10.1016/j.iswa.2023.200202>.",
    "version": "0.1.0",
    "maintainer": "Mr. Sandip Garai <sandipnicksandy@gmail.com>",
    "author": "Mr. Sandip Garai [aut, cre],\n  Dr. Ranjit Kumar Paul [aut],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CEEMDANML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CEEMDANML CEEMDAN Decomposition Based Hybrid Machine Learning Models Noise in the time-series data significantly affects the accuracy of the Machine Learning (ML) models (Artificial Neural Network and Support Vector Regression are considered here). Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) decomposes the time series data into sub-series and help to improve the model performance. The models can achieve higher prediction accuracy than the traditional ML models. Two models have been provided here for time series forecasting. More information may be obtained from Garai and Paul (2023) <doi:10.1016/j.iswa.2023.200202>.  "
  },
  {
    "id": 2242,
    "package_name": "CFtime",
    "title": "Using CF-Compliant Calendars with Climate Projection Data",
    "description": "Support for all calendars as specified in the Climate and Forecast \n    (CF) Metadata Conventions for climate and forecasting data. The CF Metadata \n    Conventions is widely used for distributing files with climate observations \n    or projections, including the Coupled Model Intercomparison Project (CMIP) \n    data used by climate change scientists and the Intergovernmental Panel on\n    Climate Change (IPCC). This package specifically allows the user to work \n    with any of the CF-compliant calendars (many of which are not compliant with \n    POSIXt). The CF time coordinate is formally defined in the CF Metadata \n    Conventions document available at <https://cfconventions.org/Data/cf-conventions/cf-conventions-1.12/cf-conventions.html#time-coordinate>.",
    "version": "1.7.2",
    "maintainer": "Patrick Van Laake <patrick@vanlaake.net>",
    "author": "Patrick Van Laake [aut, cre, cph]",
    "url": "https://r-cf.github.io/CFtime/, https://github.com/R-CF/CFtime",
    "bug_reports": "https://github.com/R-CF/CFtime/issues",
    "repository": "https://cran.r-project.org/package=CFtime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CFtime Using CF-Compliant Calendars with Climate Projection Data Support for all calendars as specified in the Climate and Forecast \n    (CF) Metadata Conventions for climate and forecasting data. The CF Metadata \n    Conventions is widely used for distributing files with climate observations \n    or projections, including the Coupled Model Intercomparison Project (CMIP) \n    data used by climate change scientists and the Intergovernmental Panel on\n    Climate Change (IPCC). This package specifically allows the user to work \n    with any of the CF-compliant calendars (many of which are not compliant with \n    POSIXt). The CF time coordinate is formally defined in the CF Metadata \n    Conventions document available at <https://cfconventions.org/Data/cf-conventions/cf-conventions-1.12/cf-conventions.html#time-coordinate>.  "
  },
  {
    "id": 2278,
    "package_name": "CLIC",
    "title": "The LIC for Distributed Cosine Regression Analysis",
    "description": "This comprehensive framework for periodic time series modeling is designated as \"CLIC\" (The LIC for Distributed Cosine Regression Analysis) analysis. It is predicated on the assumption that the underlying data exhibits complex periodic structures beyond simple harmonic components. The philosophy of the method is articulated in Guo G. (2020) <doi:10.1080/02664763.2022.2053949>.",
    "version": "0.1",
    "maintainer": "Guangbao Guo <ggb11111111@163.com>",
    "author": "Guangbao Guo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4115-6218>),\n  Pengbo Kong [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CLIC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CLIC The LIC for Distributed Cosine Regression Analysis This comprehensive framework for periodic time series modeling is designated as \"CLIC\" (The LIC for Distributed Cosine Regression Analysis) analysis. It is predicated on the assumption that the underlying data exhibits complex periodic structures beyond simple harmonic components. The philosophy of the method is articulated in Guo G. (2020) <doi:10.1080/02664763.2022.2053949>.  "
  },
  {
    "id": 2284,
    "package_name": "CLimd",
    "title": "Generating Rainfall Rasters from IMD NetCDF Data",
    "description": "The developed function is a comprehensive tool for the analysis of India Meteorological Department (IMD) NetCDF rainfall data. Specifically designed to process high-resolution daily\n             gridded rainfall datasets. It provides four key functions to process IMD NetCDF rainfall data and create rasters for various temporal scales, including annual, seasonal, monthly, and weekly\n             rainfall. For method details see, Malik, A. (2019).<DOI:10.1007/s12517-019-4454-5>. It supports different aggregation methods, such as sum, min, max, mean, and standard deviation. These functions\n             are designed for spatio-temporal analysis of rainfall patterns, trend analysis,geostatistical modeling of rainfall variability, identifying rainfall anomalies and extreme events and can be an input\n             for hydrological and agricultural models.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <nobin.paul@icar.gov.in>",
    "author": "Nirmal Kumar [aut, cph],\n  Nobin Chandra Paul [aut, cre],\n  G.P. Obi Reddy [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CLimd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CLimd Generating Rainfall Rasters from IMD NetCDF Data The developed function is a comprehensive tool for the analysis of India Meteorological Department (IMD) NetCDF rainfall data. Specifically designed to process high-resolution daily\n             gridded rainfall datasets. It provides four key functions to process IMD NetCDF rainfall data and create rasters for various temporal scales, including annual, seasonal, monthly, and weekly\n             rainfall. For method details see, Malik, A. (2019).<DOI:10.1007/s12517-019-4454-5>. It supports different aggregation methods, such as sum, min, max, mean, and standard deviation. These functions\n             are designed for spatio-temporal analysis of rainfall patterns, trend analysis,geostatistical modeling of rainfall variability, identifying rainfall anomalies and extreme events and can be an input\n             for hydrological and agricultural models.  "
  },
  {
    "id": 2322,
    "package_name": "COST",
    "title": "Copula-Based Semiparametric Models for Spatio-Temporal Data",
    "description": "Parameter estimation, one-step ahead forecast and new location\n    prediction methods for spatio-temporal data.",
    "version": "0.1.0",
    "maintainer": "Yanlin Tang <yanlintang2018@163.com>",
    "author": "Yanlin Tang, Huixia Judy Wang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=COST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "COST Copula-Based Semiparametric Models for Spatio-Temporal Data Parameter estimation, one-step ahead forecast and new location\n    prediction methods for spatio-temporal data.  "
  },
  {
    "id": 2356,
    "package_name": "CSTools",
    "title": "Assessing Skill of Climate Forecasts on Seasonal-to-Decadal\nTimescales",
    "description": "Exploits dynamical seasonal forecasts in order to provide\n    information relevant to stakeholders at the seasonal timescale. The package\n    contains process-based methods for forecast calibration, bias correction,\n    statistical and stochastic downscaling, optimal forecast combination and\n    multivariate verification, as well as basic and advanced tools to obtain\n    tailored products. This package was developed in the context of the ERA4CS \n    project MEDSCOPE and the H2020 S2S4E project and includes contributions from \n    ArticXchange project founded by EU-PolarNet 2. Implements methods described in\n    P\u00e9rez-Zan\u00f3n et al. (2022) <doi:10.5194/gmd-15-6115-2022>,\n    Doblas-Reyes et al. (2005) <doi:10.1111/j.1600-0870.2005.00104.x>,\n    Mishra et al. (2018) <doi:10.1007/s00382-018-4404-z>,\n    Sanchez-Garcia et al. (2019) <doi:10.5194/asr-16-165-2019>,\n    Straus et al. (2007) <doi:10.1175/JCLI4070.1>,\n    Terzago et al. (2018) <doi:10.5194/nhess-18-2825-2018>,\n    Torralba et al. (2017) <doi:10.1175/JAMC-D-16-0204.1>,\n    D'Onofrio et al. (2014) <doi:10.1175/JHM-D-13-096.1>,\n    Verfaillie et al. (2017) <doi:10.5194/gmd-10-4257-2017>,\n    Van Schaeybroeck et al. (2019) <doi:10.1016/B978-0-12-812372-0.00010-8>,\n    Yiou et al. (2013) <doi:10.1007/s00382-012-1626-3>.",
    "version": "5.3.0",
    "maintainer": "Theertha Kariyathan <theertha.kariyathan@bsc.es>",
    "author": "Nuria Perez-Zanon [aut] (ORCID:\n    <https://orcid.org/0000-0001-8568-3071>),\n  Louis-Philippe Caron [aut] (ORCID:\n    <https://orcid.org/0000-0001-5221-0147>),\n  Carmen Alvarez-Castro [aut] (ORCID:\n    <https://orcid.org/0000-0002-9958-010X>),\n  Lauriane Batte [aut],\n  Carlos Delgado [aut],\n  Jost von Hardenberg [aut] (ORCID:\n    <https://orcid.org/0000-0002-5312-8070>),\n  Lloren\u00e7 LLedo [aut],\n  Nicolau Manubens [aut],\n  Llu\u00eds Palma [aut],\n  Eroteida Sanchez-Garcia [aut],\n  Bert van Schaeybroeck [aut],\n  Veronica Torralba [aut],\n  Deborah Verfaillie [aut],\n  Eva Rif\u00e0 [ctb],\n  Filippo Cali Quaglia [ctb],\n  Maria M. Chaves-Montero [ctb],\n  Chihchung Chou [ctb],\n  Nicola Cortesi [ctb],\n  Susanna Corti [ctb],\n  Paolo Davini [ctb],\n  Gildas Dayon [ctb],\n  Marta Dominguez [ctb],\n  Federico Fabiano [ctb],\n  Ignazio Giuntoli [ctb],\n  Raul Marcos [ctb],\n  Paola Marson [ctb],\n  Niti Mishra [ctb],\n  Jesus Pe\u00f1a [ctb],\n  Francesc Roura-Adserias [ctb],\n  Silvia Terzago [ctb],\n  Danila Volpi [ctb],\n  An-Chi Ho [ctb],\n  Victoria Agudetse [ctb],\n  Theertha Kariyathan [cre],\n  BSC-CNS [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CSTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CSTools Assessing Skill of Climate Forecasts on Seasonal-to-Decadal\nTimescales Exploits dynamical seasonal forecasts in order to provide\n    information relevant to stakeholders at the seasonal timescale. The package\n    contains process-based methods for forecast calibration, bias correction,\n    statistical and stochastic downscaling, optimal forecast combination and\n    multivariate verification, as well as basic and advanced tools to obtain\n    tailored products. This package was developed in the context of the ERA4CS \n    project MEDSCOPE and the H2020 S2S4E project and includes contributions from \n    ArticXchange project founded by EU-PolarNet 2. Implements methods described in\n    P\u00e9rez-Zan\u00f3n et al. (2022) <doi:10.5194/gmd-15-6115-2022>,\n    Doblas-Reyes et al. (2005) <doi:10.1111/j.1600-0870.2005.00104.x>,\n    Mishra et al. (2018) <doi:10.1007/s00382-018-4404-z>,\n    Sanchez-Garcia et al. (2019) <doi:10.5194/asr-16-165-2019>,\n    Straus et al. (2007) <doi:10.1175/JCLI4070.1>,\n    Terzago et al. (2018) <doi:10.5194/nhess-18-2825-2018>,\n    Torralba et al. (2017) <doi:10.1175/JAMC-D-16-0204.1>,\n    D'Onofrio et al. (2014) <doi:10.1175/JHM-D-13-096.1>,\n    Verfaillie et al. (2017) <doi:10.5194/gmd-10-4257-2017>,\n    Van Schaeybroeck et al. (2019) <doi:10.1016/B978-0-12-812372-0.00010-8>,\n    Yiou et al. (2013) <doi:10.1007/s00382-012-1626-3>.  "
  },
  {
    "id": 2387,
    "package_name": "CalSim",
    "title": "The Calibration Simplex",
    "description": "Generates the calibration simplex (a generalization of the reliability diagram) for three-category probability forecasts, as proposed by Wilks (2013) <doi:10.1175/WAF-D-13-00027.1>.",
    "version": "0.5.4",
    "maintainer": "Johannes Resin <johannes.resin@h-its.org>",
    "author": "Johannes Resin [aut, cre] (ORCID:\n    <https://orcid.org/0009-0003-6846-2260>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CalSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CalSim The Calibration Simplex Generates the calibration simplex (a generalization of the reliability diagram) for three-category probability forecasts, as proposed by Wilks (2013) <doi:10.1175/WAF-D-13-00027.1>.  "
  },
  {
    "id": 2397,
    "package_name": "Canopy",
    "title": "Accessing Intra-Tumor Heterogeneity and Tracking Longitudinal\nand Spatial Clonal Evolutionary History by Next-Generation\nSequencing",
    "description": "A statistical framework and computational procedure for identifying\n  the sub-populations within a tumor, determining the mutation profiles of each \n  subpopulation, and inferring the tumor's phylogenetic history. The input are \n  variant allele frequencies (VAFs) of somatic single nucleotide alterations \n  (SNAs) along with allele-specific coverage ratios between the tumor and matched\n  normal sample for somatic copy number alterations (CNAs). These quantities can\n  be directly taken from the output of existing software. Canopy provides a \n  general mathematical framework for pooling data across samples and sites to \n  infer the underlying parameters. For SNAs that fall within CNA regions, Canopy\n  infers their temporal ordering and resolves their phase.  When there are \n  multiple evolutionary configurations consistent with the data, Canopy outputs \n  all configurations along with their confidence assessment.",
    "version": "1.3.0",
    "maintainer": "Yuchao Jiang <yuchaoj@email.unc.edu>",
    "author": "Yuchao Jiang, Nancy R. Zhang",
    "url": "https://github.com/yuchaojiang/Canopy",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Canopy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Canopy Accessing Intra-Tumor Heterogeneity and Tracking Longitudinal\nand Spatial Clonal Evolutionary History by Next-Generation\nSequencing A statistical framework and computational procedure for identifying\n  the sub-populations within a tumor, determining the mutation profiles of each \n  subpopulation, and inferring the tumor's phylogenetic history. The input are \n  variant allele frequencies (VAFs) of somatic single nucleotide alterations \n  (SNAs) along with allele-specific coverage ratios between the tumor and matched\n  normal sample for somatic copy number alterations (CNAs). These quantities can\n  be directly taken from the output of existing software. Canopy provides a \n  general mathematical framework for pooling data across samples and sites to \n  infer the underlying parameters. For SNAs that fall within CNA regions, Canopy\n  infers their temporal ordering and resolves their phase.  When there are \n  multiple evolutionary configurations consistent with the data, Canopy outputs \n  all configurations along with their confidence assessment.  "
  },
  {
    "id": 2416,
    "package_name": "CausalImpact",
    "title": "Inferring Causal Effects using Bayesian Structural Time-Series\nModels",
    "description": "Implements a Bayesian approach to causal impact estimation in time\n  series, as described in Brodersen et al. (2015) <DOI:10.1214/14-AOAS788>.\n  See the package documentation on GitHub\n  <https://google.github.io/CausalImpact/> to get started.",
    "version": "1.4.1",
    "maintainer": "Alain Hauser <alhauser@google.com>",
    "author": "Kay H. Brodersen [aut],\n  Alain Hauser [aut, cre]",
    "url": "https://google.github.io/CausalImpact/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CausalImpact",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CausalImpact Inferring Causal Effects using Bayesian Structural Time-Series\nModels Implements a Bayesian approach to causal impact estimation in time\n  series, as described in Brodersen et al. (2015) <DOI:10.1214/14-AOAS788>.\n  See the package documentation on GitHub\n  <https://google.github.io/CausalImpact/> to get started.  "
  },
  {
    "id": 2417,
    "package_name": "CausalMBSTS",
    "title": "MBSTS Models for Causal Inference and Forecasting",
    "description": "Infers the causal effect of an intervention on a multivariate response through the use of Multivariate \n    Bayesian Structural Time Series models (MBSTS) as described in Menchetti & Bojinov (2020) <arXiv:2006.12269>. \n    The package also includes functions for model building and forecasting.  ",
    "version": "0.1.1",
    "maintainer": "Fiammetta Menchetti <fiammetta.menchetti@gmail.com>",
    "author": "Iavor Bojinov [aut],\n  Fiammetta Menchetti [aut, cre],\n  Victoria L. Prince [ctb],\n  Ista Zahn [ctb]",
    "url": "",
    "bug_reports": "https://github.com/FMenchetti/CausalMBSTS/issues",
    "repository": "https://cran.r-project.org/package=CausalMBSTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CausalMBSTS MBSTS Models for Causal Inference and Forecasting Infers the causal effect of an intervention on a multivariate response through the use of Multivariate \n    Bayesian Structural Time Series models (MBSTS) as described in Menchetti & Bojinov (2020) <arXiv:2006.12269>. \n    The package also includes functions for model building and forecasting.    "
  },
  {
    "id": 2428,
    "package_name": "Census2016",
    "title": "Data from the Australian Census 2016",
    "description": "Contains selected variables from the time series profiles for statistical areas level 2 from the 2006, 2011, and 2016 censuses of population and housing, Australia. Also provides methods for viewing the questions asked for convenience during analysis.",
    "version": "0.2.0",
    "maintainer": "Hugh Parsonage <hugh.parsonage@gmail.com>",
    "author": "Hugh Parsonage [aut, cre],\n  Nick Evershed [dtc],\n  Australian Bureau of Statistics [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Census2016",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Census2016 Data from the Australian Census 2016 Contains selected variables from the time series profiles for statistical areas level 2 from the 2006, 2011, and 2016 censuses of population and housing, Australia. Also provides methods for viewing the questions asked for convenience during analysis.  "
  },
  {
    "id": 2470,
    "package_name": "CircSpaceTime",
    "title": "Spatial and Spatio-Temporal Bayesian Model for Circular Data",
    "description": "Implementation of Bayesian models for spatial and spatio-temporal\n             interpolation of circular data using Gaussian Wrapped and Gaussian Projected distributions.\n             We developed the methods described in Jona Lasinio G. et al. (2012) <doi: 10.1214/12-aoas576>, \n             Wang F. et al. (2014) <doi: 10.1080/01621459.2014.934454> and \n             Mastrantonio G. et al. (2016) <doi: 10.1007/s11749-015-0458-y>.",
    "version": "0.9.0",
    "maintainer": "Mario Santoro <santoro.ma@gmail.com>",
    "author": "Giovanna Jona Lasinio [aut] (ORCID:\n    <https://orcid.org/0000-0001-8912-5018>),\n  Gianluca Mastrantonio [aut] (ORCID:\n    <https://orcid.org/0000-0002-2963-6729>),\n  Mario Santoro [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6626-9430>)",
    "url": "https://github.com/santoroma/CircSpaceTime",
    "bug_reports": "https://github.com/santoroma/CircSpaceTime",
    "repository": "https://cran.r-project.org/package=CircSpaceTime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CircSpaceTime Spatial and Spatio-Temporal Bayesian Model for Circular Data Implementation of Bayesian models for spatial and spatio-temporal\n             interpolation of circular data using Gaussian Wrapped and Gaussian Projected distributions.\n             We developed the methods described in Jona Lasinio G. et al. (2012) <doi: 10.1214/12-aoas576>, \n             Wang F. et al. (2014) <doi: 10.1080/01621459.2014.934454> and \n             Mastrantonio G. et al. (2016) <doi: 10.1007/s11749-015-0458-y>.  "
  },
  {
    "id": 2477,
    "package_name": "Ckmeans.1d.dp",
    "title": "Optimal, Fast, and Reproducible Univariate Clustering",
    "description": "Fast, optimal, and reproducible weighted univariate\n clustering by dynamic programming. Four problems are solved, including\n univariate k-means (Wang & Song 2011) <doi:10.32614/RJ-2011-015>\n (Song & Zhong 2020) <doi:10.1093/bioinformatics/btaa613>, k-median,\n k-segments, and multi-channel weighted k-means. Dynamic programming\n is used to minimize the sum of (weighted) within-cluster distances\n using respective metrics. Its advantage over heuristic clustering in\n efficiency and accuracy is pronounced when there are many clusters.\n Multi-channel weighted k-means groups multiple univariate\n signals into k clusters. An auxiliary function generates histograms\n adaptive to patterns in data. This package provides a powerful set\n of tools for univariate data analysis with guaranteed optimality,\n efficiency, and reproducibility, useful for peak calling on temporal,\n spatial, and spectral data.",
    "version": "4.3.5",
    "maintainer": "Joe Song <joemsong@cs.nmsu.edu>",
    "author": "Joe Song [aut, cre] (ORCID: <https://orcid.org/0000-0002-6883-6547>),\n  Hua Zhong [aut] (ORCID: <https://orcid.org/0000-0003-1962-2603>),\n  Haizhou Wang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Ckmeans.1d.dp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Ckmeans.1d.dp Optimal, Fast, and Reproducible Univariate Clustering Fast, optimal, and reproducible weighted univariate\n clustering by dynamic programming. Four problems are solved, including\n univariate k-means (Wang & Song 2011) <doi:10.32614/RJ-2011-015>\n (Song & Zhong 2020) <doi:10.1093/bioinformatics/btaa613>, k-median,\n k-segments, and multi-channel weighted k-means. Dynamic programming\n is used to minimize the sum of (weighted) within-cluster distances\n using respective metrics. Its advantage over heuristic clustering in\n efficiency and accuracy is pronounced when there are many clusters.\n Multi-channel weighted k-means groups multiple univariate\n signals into k clusters. An auxiliary function generates histograms\n adaptive to patterns in data. This package provides a powerful set\n of tools for univariate data analysis with guaranteed optimality,\n efficiency, and reproducibility, useful for peak calling on temporal,\n spatial, and spectral data.  "
  },
  {
    "id": 2480,
    "package_name": "ClamR",
    "title": "Time Series Modeling for Climate Change Proxies",
    "description": "Implementation of the Wilkinson and Ivany (2002) approach to paleoclimate analysis, applied to isotope data extracted from clams.",
    "version": "2.1-3",
    "maintainer": "Jonathan M. Lees<jonathan.lees@unc.edu>",
    "author": "Jonathan M. Lees",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ClamR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ClamR Time Series Modeling for Climate Change Proxies Implementation of the Wilkinson and Ivany (2002) approach to paleoclimate analysis, applied to isotope data extracted from clams.  "
  },
  {
    "id": 2488,
    "package_name": "CliftLRD",
    "title": "Complex-Valued Wavelet Lifting Estimators of the Hurst Exponent\nfor Irregularly Sampled Time Series",
    "description": "Implementation of Hurst exponent estimators based on complex-valued lifting wavelet energy from Knight, M. I and Nunes, M. A. (2018) <doi:10.1007/s11222-018-9820-8>. ",
    "version": "0.1-2",
    "maintainer": "Matt Nunes <nunesrpackages@gmail.com>",
    "author": "Matt Nunes [aut, cre],\n  Marina Knight [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CliftLRD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CliftLRD Complex-Valued Wavelet Lifting Estimators of the Hurst Exponent\nfor Irregularly Sampled Time Series Implementation of Hurst exponent estimators based on complex-valued lifting wavelet energy from Knight, M. I and Nunes, M. A. (2018) <doi:10.1007/s11222-018-9820-8>.   "
  },
  {
    "id": 2492,
    "package_name": "ClimProjDiags",
    "title": "Set of Tools to Compute Various Climate Indices",
    "description": "Set of tools to compute metrics and indices for climate analysis.\n    The package provides functions to compute extreme indices, evaluate the\n    agreement between models and combine theses models into an ensemble. Multi-model\n    time series of climate indices can be computed either after averaging the 2-D\n    fields from different models provided they share a common grid or by combining\n    time series computed on the model native grid. Indices can be assigned weights\n    and/or combined to construct new indices. The package makes use of some of the\n    methods described in:\n    N. Manubens et al. (2018) <doi:10.1016/j.envsoft.2018.01.018>.",
    "version": "0.3.4",
    "maintainer": "Vict\u00f2ria Agudetse <victoria.agudetse@bsc.es>",
    "author": "BSC-CNS [aut, cph],\n  Nuria Perez-Zanon [aut] (ORCID:\n    <https://orcid.org/0000-0001-8568-3071>),\n  An-Chi Ho [ctb],\n  Vict\u00f2ria Agudetse [cre],\n  Nicolau Manubens [ctb],\n  Alasdair Hunter [aut],\n  Louis-Philippe Caron [ctb],\n  Eva Rif\u00e0 [ctb],\n  Ulrich Drepper [ctb],\n  David Bronaugh [ctb],\n  James Hiebert [ctb]",
    "url": "https://earth.bsc.es/gitlab/es/ClimProjDiags",
    "bug_reports": "https://earth.bsc.es/gitlab/es/ClimProjDiags/-/issues",
    "repository": "https://cran.r-project.org/package=ClimProjDiags",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ClimProjDiags Set of Tools to Compute Various Climate Indices Set of tools to compute metrics and indices for climate analysis.\n    The package provides functions to compute extreme indices, evaluate the\n    agreement between models and combine theses models into an ensemble. Multi-model\n    time series of climate indices can be computed either after averaging the 2-D\n    fields from different models provided they share a common grid or by combining\n    time series computed on the model native grid. Indices can be assigned weights\n    and/or combined to construct new indices. The package makes use of some of the\n    methods described in:\n    N. Manubens et al. (2018) <doi:10.1016/j.envsoft.2018.01.018>.  "
  },
  {
    "id": 2517,
    "package_name": "ClusterGVis",
    "title": "One-Step to Cluster and Visualize Gene Expression Data",
    "description": "Streamlining the clustering and visualization of time-series gene expression data from RNA-Seq experiments, this tool supports fuzzy c-means and k-means clustering algorithms. It is compatible with outputs from widely-used packages such as 'Seurat', 'Monocle', and 'WGCNA', enabling seamless downstream visualization and analysis. See Lokesh Kumar and Matthias E Futschik (2007) <doi:10.6026/97320630002005> for more details.",
    "version": "0.1.4",
    "maintainer": "Jun Zhang <3219030654@stu.cpu.edu.cn>",
    "author": "Jun Zhang [aut, cre] (ORCID: <https://orcid.org/0000-0001-7692-9105>)",
    "url": "https://github.com/junjunlab/ClusterGVis/,\nhttps://junjunlab.github.io/ClusterGvis-manual/",
    "bug_reports": "https://github.com/junjunlab/ClusterGVis/issues",
    "repository": "https://cran.r-project.org/package=ClusterGVis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ClusterGVis One-Step to Cluster and Visualize Gene Expression Data Streamlining the clustering and visualization of time-series gene expression data from RNA-Seq experiments, this tool supports fuzzy c-means and k-means clustering algorithms. It is compatible with outputs from widely-used packages such as 'Seurat', 'Monocle', and 'WGCNA', enabling seamless downstream visualization and analysis. See Lokesh Kumar and Matthias E Futschik (2007) <doi:10.6026/97320630002005> for more details.  "
  },
  {
    "id": 2521,
    "package_name": "ClusterVAR",
    "title": "Fitting Latent Class Vector-Autoregressive (VAR) Models",
    "description": "Estimates latent class vector-autoregressive models via EM algorithm on time-series data for model-based clustering and classification. Includes model selection criteria for selecting the number of lags and clusters.",
    "version": "0.0.8",
    "maintainer": "Anja Ernst <a.f.ernst@rug.nl>",
    "author": "Anja Ernst [aut, cre],\n  Jonas Haslbeck [aut]",
    "url": "",
    "bug_reports": "https://github.com/anieBee/ClusterVAR/issues",
    "repository": "https://cran.r-project.org/package=ClusterVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ClusterVAR Fitting Latent Class Vector-Autoregressive (VAR) Models Estimates latent class vector-autoregressive models via EM algorithm on time-series data for model-based clustering and classification. Includes model selection criteria for selecting the number of lags and clusters.  "
  },
  {
    "id": 2526,
    "package_name": "CoDaLoMic",
    "title": "Compositional Models to Longitudinal Microbiome Data",
    "description": "Implementation of models to analyse compositional microbiome time series taking into account the interaction between groups of bacteria. The models implemented are described in Creus-Mart\u00ed et al (2018, ISBN:978-84-09-07541-6), Creus-Mart\u00ed et al (2021) <doi:10.1155/2021/9951817> and Creus-Mart\u00ed et al (2022) <doi:10.1155/2022/4907527>.",
    "version": "0.1.1",
    "maintainer": "Irene Creus Mart\u00ed <ircrmar@mat.upv.es>",
    "author": "Irene Creus Mart\u00ed [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7962-4478>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CoDaLoMic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CoDaLoMic Compositional Models to Longitudinal Microbiome Data Implementation of models to analyse compositional microbiome time series taking into account the interaction between groups of bacteria. The models implemented are described in Creus-Mart\u00ed et al (2018, ISBN:978-84-09-07541-6), Creus-Mart\u00ed et al (2021) <doi:10.1155/2021/9951817> and Creus-Mart\u00ed et al (2022) <doi:10.1155/2022/4907527>.  "
  },
  {
    "id": 2533,
    "package_name": "CoSMoS",
    "title": "Complete Stochastic Modelling Solution",
    "description": "Makes univariate, multivariate, or random fields simulations precise and simple. Just select the desired time series or random fields\u2019 properties and it will do the rest. CoSMoS is based on the framework described in Papalexiou (2018, <doi:10.1016/j.advwatres.2018.02.013>), extended for random fields in Papalexiou and Serinaldi (2020, <doi:10.1029/2019WR026331>), and further advanced in Papalexiou et al. (2021, <doi:10.1029/2020WR029466>) to allow fine-scale space-time simulation of storms (or even cyclone-mimicking fields).",
    "version": "2.1.1",
    "maintainer": "Kevin Shook <kevin.shook@usask.ca>",
    "author": "Simon Michael Papalexiou [aut],\n  Francesco Serinaldi [aut],\n  Filip Strnad [aut],\n  Yannis Markonis [aut],\n  Kevin Shook [ctb, cre]",
    "url": "https://github.com/TycheLab/CoSMoS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CoSMoS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CoSMoS Complete Stochastic Modelling Solution Makes univariate, multivariate, or random fields simulations precise and simple. Just select the desired time series or random fields\u2019 properties and it will do the rest. CoSMoS is based on the framework described in Papalexiou (2018, <doi:10.1016/j.advwatres.2018.02.013>), extended for random fields in Papalexiou and Serinaldi (2020, <doi:10.1029/2019WR026331>), and further advanced in Papalexiou et al. (2021, <doi:10.1029/2020WR029466>) to allow fine-scale space-time simulation of storms (or even cyclone-mimicking fields).  "
  },
  {
    "id": 2544,
    "package_name": "Coinprofile",
    "title": "Coincident Profile",
    "description": "Builds the \n  coincident profile proposed by Martinez, W and Nieto, Fabio H and Poncela, P (2016) \n  <doi:10.1016/j.spl.2015.11.008>.\n  This methodology studies the relationship between a couple of\n  time series based on the the set of turning points of each\n  time series. The coincident profile establishes if two time\n  series are coincident, or one of them leads the second.",
    "version": "0.1.9",
    "maintainer": "Wilmer Martinez <womartin@asu.edu>",
    "author": "Wilmer Martinez <womartin@asu.edu>",
    "url": "https://github.com/WilmerMartinezR/Coinprofile",
    "bug_reports": "https://github.com/WilmerMartinezR/Coinprofile/issues",
    "repository": "https://cran.r-project.org/package=Coinprofile",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Coinprofile Coincident Profile Builds the \n  coincident profile proposed by Martinez, W and Nieto, Fabio H and Poncela, P (2016) \n  <doi:10.1016/j.spl.2015.11.008>.\n  This methodology studies the relationship between a couple of\n  time series based on the the set of turning points of each\n  time series. The coincident profile establishes if two time\n  series are coincident, or one of them leads the second.  "
  },
  {
    "id": 2585,
    "package_name": "ConNEcT",
    "title": "Contingency Measure-Based Networks for Binary Time Series",
    "description": "The ConNEcT approach investigates the pairwise association strength of binary time series by calculating contingency measures and depicts the results in a network. The package includes features to explore and visualize the data. To calculate the pairwise concurrent or temporal sequenced relationship between the variables, the package provides seven contingency measures (proportion of agreement, classical & corrected Jaccard, Cohen's kappa, phi correlation coefficient, odds ratio, and log odds ratio), however, others can easily be implemented. The package also includes non-parametric significance tests, that can be applied to test whether the contingency value quantifying the relationship between the variables is significantly higher than chance level. Most importantly this test accounts for auto-dependence and relative frequency.See Bodner et al.(2021) <doi: 10.1111/bmsp.12222>.Finally, a network can be drawn. Variables depicted the nodes of the network, with the node size adapted to the prevalence. The association strength between the variables defines the undirected (concurrent) or directed (temporal sequenced) links between the nodes. The results of the non-parametric significance test can be included by depicting either all links or only the significant ones. Tutorial see Bodner et al.(2021) <doi:10.3758/s13428-021-01760-w>.",
    "version": "0.7.27",
    "maintainer": "Nadja Bodner <nadja.bodner@kuleuven.be>",
    "author": "Nadja Bodner [aut, cre],\n  Eva Ceulemans [ctb, rev]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ConNEcT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ConNEcT Contingency Measure-Based Networks for Binary Time Series The ConNEcT approach investigates the pairwise association strength of binary time series by calculating contingency measures and depicts the results in a network. The package includes features to explore and visualize the data. To calculate the pairwise concurrent or temporal sequenced relationship between the variables, the package provides seven contingency measures (proportion of agreement, classical & corrected Jaccard, Cohen's kappa, phi correlation coefficient, odds ratio, and log odds ratio), however, others can easily be implemented. The package also includes non-parametric significance tests, that can be applied to test whether the contingency value quantifying the relationship between the variables is significantly higher than chance level. Most importantly this test accounts for auto-dependence and relative frequency.See Bodner et al.(2021) <doi: 10.1111/bmsp.12222>.Finally, a network can be drawn. Variables depicted the nodes of the network, with the node size adapted to the prevalence. The association strength between the variables defines the undirected (concurrent) or directed (temporal sequenced) links between the nodes. The results of the non-parametric significance test can be included by depicting either all links or only the significant ones. Tutorial see Bodner et al.(2021) <doi:10.3758/s13428-021-01760-w>.  "
  },
  {
    "id": 2609,
    "package_name": "ConsReg",
    "title": "Fits Regression & ARMA Models Subject to Constraints to the\nCoefficient",
    "description": "Fits or generalized linear models either a regression with Autoregressive moving-average (ARMA) errors for time series data. \n       The package makes it easy to incorporate constraints into the model's coefficients. \n          The model is specified by an objective function (Gaussian, Binomial or Poisson) or an ARMA order (p,q), \n          a vector of bound constraints \n          for the coefficients (i.e beta1 > 0) and the possibility to incorporate restrictions\n          among coefficients (i.e beta1 > beta2).\n          The references of this packages are the same as 'stats' package for glm() and arima() functions.\n          See Brockwell, P. J. and Davis, R. A. (1996, ISBN-10: 9783319298528).\n          For the different optimizers implemented, it is recommended to consult the documentation of the corresponding packages. ",
    "version": "0.1.0",
    "maintainer": "Josep Puig <puigjos@gmail.com>",
    "author": "Josep Puig Sall\u00e9s",
    "url": "https://github.com/puigjos/ConsReg",
    "bug_reports": "https://github.com/puigjos/ConsReg/issues",
    "repository": "https://cran.r-project.org/package=ConsReg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ConsReg Fits Regression & ARMA Models Subject to Constraints to the\nCoefficient Fits or generalized linear models either a regression with Autoregressive moving-average (ARMA) errors for time series data. \n       The package makes it easy to incorporate constraints into the model's coefficients. \n          The model is specified by an objective function (Gaussian, Binomial or Poisson) or an ARMA order (p,q), \n          a vector of bound constraints \n          for the coefficients (i.e beta1 > 0) and the possibility to incorporate restrictions\n          among coefficients (i.e beta1 > beta2).\n          The references of this packages are the same as 'stats' package for glm() and arima() functions.\n          See Brockwell, P. J. and Davis, R. A. (1996, ISBN-10: 9783319298528).\n          For the different optimizers implemented, it is recommended to consult the documentation of the corresponding packages.   "
  },
  {
    "id": 2623,
    "package_name": "CopCTS",
    "title": "Copula-Based Semiparametric Analysis for Time Series Data with\nDetection Limits",
    "description": "Semiparametric estimation for censored time series\n    with lower detection limit. The latent response is a sequence of\n    stationary process with Markov property\n    of order one.\n    Estimation of copula parameter(COPC) and Conditional quantile estimation\n    are included for five available copula functions.\n    Copula selection methods based on L2 distance from empirical copula function\n    are also included.",
    "version": "1.0.0",
    "maintainer": "Fuyuan David Li <LFY@gwmail.gwu.edu>",
    "author": "Fuyuan David Li",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CopCTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CopCTS Copula-Based Semiparametric Analysis for Time Series Data with\nDetection Limits Semiparametric estimation for censored time series\n    with lower detection limit. The latent response is a sequence of\n    stationary process with Markov property\n    of order one.\n    Estimation of copula parameter(COPC) and Conditional quantile estimation\n    are included for five available copula functions.\n    Copula selection methods based on L2 distance from empirical copula function\n    are also included.  "
  },
  {
    "id": 2626,
    "package_name": "Copula.Markov",
    "title": "Copula-Based Estimation and Statistical Process Control for\nSerially Correlated Time Series",
    "description": "Estimation and statistical process control are performed under\n copula-based time-series models.\n Available are statistical methods in Long and Emura (2014 JCSA),\n Emura et al. (2017 Commun Stat-Simul) <DOI:10.1080/03610918.2015.1073303>,\n Huang and Emura (2021 Commun Stat-Simul) <DOI:10.1080/03610918.2019.1602647>,\n Lin et al. (2021 Comm Stat-Simul) <DOI:10.1080/03610918.2019.1652318>,\n Sun et al. (2020 JSS Series in Statistics)<DOI:10.1007/978-981-15-4998-4>,\n and Huang and Emura (2021, in revision).",
    "version": "2.9",
    "maintainer": "Takeshi Emura <takeshiemura@gmail.com>",
    "author": "Takeshi Emura, Xinwei Huang, Ting-Hsuan Long, Li-Hsien Sun",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Copula.Markov",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Copula.Markov Copula-Based Estimation and Statistical Process Control for\nSerially Correlated Time Series Estimation and statistical process control are performed under\n copula-based time-series models.\n Available are statistical methods in Long and Emura (2014 JCSA),\n Emura et al. (2017 Commun Stat-Simul) <DOI:10.1080/03610918.2015.1073303>,\n Huang and Emura (2021 Commun Stat-Simul) <DOI:10.1080/03610918.2019.1602647>,\n Lin et al. (2021 Comm Stat-Simul) <DOI:10.1080/03610918.2019.1652318>,\n Sun et al. (2020 JSS Series in Statistics)<DOI:10.1007/978-981-15-4998-4>,\n and Huang and Emura (2021, in revision).  "
  },
  {
    "id": 2661,
    "package_name": "CptNonPar",
    "title": "Nonparametric Change Point Detection for Multivariate Time\nSeries",
    "description": "Implements the nonparametric moving sum procedure for detecting \n    changes in the joint characteristic function (NP-MOJO) for multiple change\n    point detection in multivariate time series. See McGonigle, E. T., Cho, H. \n    (2025) <doi:10.1093/biomet/asaf024> for description of the NP-MOJO methodology.",
    "version": "0.3.1",
    "maintainer": "Euan T. McGonigle <e.t.mcgonigle@soton.ac.uk>",
    "author": "Euan T. McGonigle [aut, cre],\n  Haeran Cho [aut]",
    "url": "https://github.com/EuanMcGonigle/CptNonPar",
    "bug_reports": "https://github.com/EuanMcGonigle/CptNonPar/issues",
    "repository": "https://cran.r-project.org/package=CptNonPar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CptNonPar Nonparametric Change Point Detection for Multivariate Time\nSeries Implements the nonparametric moving sum procedure for detecting \n    changes in the joint characteristic function (NP-MOJO) for multiple change\n    point detection in multivariate time series. See McGonigle, E. T., Cho, H. \n    (2025) <doi:10.1093/biomet/asaf024> for description of the NP-MOJO methodology.  "
  },
  {
    "id": 2683,
    "package_name": "CvmortalityMult",
    "title": "Cross-Validation for Multi-Population Mortality Models",
    "description": "Implementation of cross-validation method for testing the forecasting accuracy of several multi-population mortality models. The family of multi-population includes several multi-population mortality models proposed through the actuarial and demography literature. The package includes functions for fitting and forecast the mortality rates of several populations. Additionally, we include functions for testing the forecasting accuracy of different multi-population models.\n  References, <https://journal.r-project.org/articles/RJ-2025-018/>.\n  Atance, D., Debon, A., and Navarro, E. (2020) <doi:10.3390/math8091550>.\n  Bergmeir, C. & Benitez, J.M. (2012) <doi:10.1016/j.ins.2011.12.028>.\n  Debon, A., Montes, F., & Martinez-Ruiz, F. (2011) <doi:10.1007/s13385-011-0043-z>.\n  Lee, R.D. & Carter, L.R. (1992) <doi:10.1080/01621459.1992.10475265>.\n  Russolillo, M., Giordano, G., & Haberman, S. (2011) <doi:10.1080/03461231003611933>.\n  Santolino, M. (2023) <doi:10.3390/risks11100170>.",
    "version": "1.1.1",
    "maintainer": "David Atance <david.atance@uah.es>",
    "author": "David Atance [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5860-0584>),\n  Ana Deb\u00f3n [aut] (ORCID: <https://orcid.org/0000-0002-5116-289X>)",
    "url": "https://github.com/davidAtance/CvmortalityMult",
    "bug_reports": "https://github.com/davidAtance/CvmortalityMult/issues",
    "repository": "https://cran.r-project.org/package=CvmortalityMult",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CvmortalityMult Cross-Validation for Multi-Population Mortality Models Implementation of cross-validation method for testing the forecasting accuracy of several multi-population mortality models. The family of multi-population includes several multi-population mortality models proposed through the actuarial and demography literature. The package includes functions for fitting and forecast the mortality rates of several populations. Additionally, we include functions for testing the forecasting accuracy of different multi-population models.\n  References, <https://journal.r-project.org/articles/RJ-2025-018/>.\n  Atance, D., Debon, A., and Navarro, E. (2020) <doi:10.3390/math8091550>.\n  Bergmeir, C. & Benitez, J.M. (2012) <doi:10.1016/j.ins.2011.12.028>.\n  Debon, A., Montes, F., & Martinez-Ruiz, F. (2011) <doi:10.1007/s13385-011-0043-z>.\n  Lee, R.D. & Carter, L.R. (1992) <doi:10.1080/01621459.1992.10475265>.\n  Russolillo, M., Giordano, G., & Haberman, S. (2011) <doi:10.1080/03461231003611933>.\n  Santolino, M. (2023) <doi:10.3390/risks11100170>.  "
  },
  {
    "id": 2707,
    "package_name": "DATAstudio",
    "title": "The Research Data Warehouse of Miguel de Carvalho",
    "description": "Pulls together a collection of datasets from Miguel de Carvalho research articles. Including, for example:\n    - de Carvalho (2012) <doi:10.1016/j.jspi.2011.08.016>;\n    - de Carvalho et al (2012) <doi:10.1080/03610926.2012.709905>;\n    - de Carvalho et al (2012) <doi:10.1016/j.econlet.2011.09.007>);\n    - de Carvalho and Davison (2014) <doi:10.1080/01621459.2013.872651>;\n    - de Carvalho and Rua (2017) <doi:10.1016/j.ijforecast.2015.09.004>;\n    - de Carvalho et al (2023) <doi:10.1002/sta4.560>;\n    - de Carvalho et al (2022) <doi:10.1007/s13253-021-00469-9>;\n    - Palacios et al (2024) <doi:10.1214/24-BA1420>.",
    "version": "1.2.1",
    "maintainer": "Miguel de Carvalho <Miguel.deCarvalho@ed.ac.uk>",
    "author": "Miguel de Carvalho [aut, cre]",
    "url": "https://www.maths.ed.ac.uk/~mdecarv/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DATAstudio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DATAstudio The Research Data Warehouse of Miguel de Carvalho Pulls together a collection of datasets from Miguel de Carvalho research articles. Including, for example:\n    - de Carvalho (2012) <doi:10.1016/j.jspi.2011.08.016>;\n    - de Carvalho et al (2012) <doi:10.1080/03610926.2012.709905>;\n    - de Carvalho et al (2012) <doi:10.1016/j.econlet.2011.09.007>);\n    - de Carvalho and Davison (2014) <doi:10.1080/01621459.2013.872651>;\n    - de Carvalho and Rua (2017) <doi:10.1016/j.ijforecast.2015.09.004>;\n    - de Carvalho et al (2023) <doi:10.1002/sta4.560>;\n    - de Carvalho et al (2022) <doi:10.1007/s13253-021-00469-9>;\n    - Palacios et al (2024) <doi:10.1214/24-BA1420>.  "
  },
  {
    "id": 2718,
    "package_name": "DBfit",
    "title": "A Double Bootstrap Method for Analyzing Linear Models with\nAutoregressive Errors",
    "description": "Computes the double bootstrap as discussed in McKnight, McKean, and Huitema (2000) <doi:10.1037/1082-989X.5.1.87>. \n              The double bootstrap method provides a better fit for a linear model with autoregressive errors than ARIMA when the sample size is small.",
    "version": "2.0",
    "maintainer": "Shaofeng Zhang <shaofeng.zhang@wmich.edu>",
    "author": "Joseph W. McKean and Shaofeng Zhang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DBfit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DBfit A Double Bootstrap Method for Analyzing Linear Models with\nAutoregressive Errors Computes the double bootstrap as discussed in McKnight, McKean, and Huitema (2000) <doi:10.1037/1082-989X.5.1.87>. \n              The double bootstrap method provides a better fit for a linear model with autoregressive errors than ARIMA when the sample size is small.  "
  },
  {
    "id": 2725,
    "package_name": "DCL",
    "title": "Claims Reserving under the Double Chain Ladder Model",
    "description": "Statistical modelling and forecasting in claims reserving in non-life insurance under the Double Chain Ladder framework by Martinez-Miranda, Nielsen and Verrall (2012).",
    "version": "0.1.2",
    "maintainer": "Maria Dolores Martinez-Miranda <mmiranda@ugr.es>",
    "author": "Maria Dolores Martinez-Miranda, Jens Perch Nielsen and Richard Verrall ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DCL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DCL Claims Reserving under the Double Chain Ladder Model Statistical modelling and forecasting in claims reserving in non-life insurance under the Double Chain Ladder framework by Martinez-Miranda, Nielsen and Verrall (2012).  "
  },
  {
    "id": 2729,
    "package_name": "DChaos",
    "title": "Chaotic Time Series Analysis",
    "description": "Chaos theory has been hailed as a revolution of thoughts and attracting ever increasing \n    attention of many scientists from diverse disciplines. Chaotic systems are nonlinear deterministic \n    dynamic systems which can behave like an erratic and apparently random motion. A relevant field\n    inside chaos theory and nonlinear time series analysis is the detection of a chaotic behaviour \n    from empirical time series data. One of the main features of chaos is the well known initial value \n    sensitivity property. Methods and techniques related to test the hypothesis of chaos try to quantify \n    the initial value sensitive property estimating the Lyapunov exponents. The DChaos package \n    provides different useful tools and efficient algorithms which test robustly the hypothesis of chaos \n    based on the Lyapunov exponent in order to know if the data generating process behind time series \n    behave chaotically or not.",
    "version": "0.1-7",
    "maintainer": "Julio E. Sandubete <jsandube@ucm.es>",
    "author": "Julio E. Sandubete [aut, cre],\n  Lorenzo Escot [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DChaos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DChaos Chaotic Time Series Analysis Chaos theory has been hailed as a revolution of thoughts and attracting ever increasing \n    attention of many scientists from diverse disciplines. Chaotic systems are nonlinear deterministic \n    dynamic systems which can behave like an erratic and apparently random motion. A relevant field\n    inside chaos theory and nonlinear time series analysis is the detection of a chaotic behaviour \n    from empirical time series data. One of the main features of chaos is the well known initial value \n    sensitivity property. Methods and techniques related to test the hypothesis of chaos try to quantify \n    the initial value sensitive property estimating the Lyapunov exponents. The DChaos package \n    provides different useful tools and efficient algorithms which test robustly the hypothesis of chaos \n    based on the Lyapunov exponent in order to know if the data generating process behind time series \n    behave chaotically or not.  "
  },
  {
    "id": 2740,
    "package_name": "DDRTree",
    "title": "Learning Principal Graphs with DDRTree",
    "description": "Provides an implementation of the framework of reversed graph embedding (RGE) which projects data into a reduced dimensional space while constructs a principal tree which passes through the middle of the data simultaneously. DDRTree shows superiority to alternatives (Wishbone, DPT) for inferring the ordering as well as the intrinsic structure of the single cell genomics data. In general, it could be used to reconstruct the temporal progression as well as bifurcation structure of any datatype. ",
    "version": "0.1.5",
    "maintainer": "Xiaojie Qiu <xqiu@uw.edu>",
    "author": "Xiaojie Qiu, Cole Trapnell, Qi Mao, Li Wang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DDRTree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DDRTree Learning Principal Graphs with DDRTree Provides an implementation of the framework of reversed graph embedding (RGE) which projects data into a reduced dimensional space while constructs a principal tree which passes through the middle of the data simultaneously. DDRTree shows superiority to alternatives (Wishbone, DPT) for inferring the ordering as well as the intrinsic structure of the single cell genomics data. In general, it could be used to reconstruct the temporal progression as well as bifurcation structure of any datatype.   "
  },
  {
    "id": 2771,
    "package_name": "DGM",
    "title": "Dynamic Graphical Models",
    "description": "\n    Dynamic graphical models for multivariate time series data to estimate directed\n    dynamic networks in functional magnetic resonance imaging (fMRI), see Schwab et\n    al. (2017) <doi:10.1016/j.neuroimage.2018.03.074>.",
    "version": "1.7.4",
    "maintainer": "Simon Schwab <schw4b@gmail.com>",
    "author": "Simon Schwab <schw4b@gmail.com>, Ruth Harbord <r.harbord@warwick.ac.uk>,\n    Lilia Costa <liliacosta@ufba.br>, Thomas Nichols <t.e.nichols@warwick.ac.uk>",
    "url": "https://github.com/schw4b/DGM",
    "bug_reports": "https://github.com/schw4b/DGM/issues",
    "repository": "https://cran.r-project.org/package=DGM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DGM Dynamic Graphical Models \n    Dynamic graphical models for multivariate time series data to estimate directed\n    dynamic networks in functional magnetic resonance imaging (fMRI), see Schwab et\n    al. (2017) <doi:10.1016/j.neuroimage.2018.03.074>.  "
  },
  {
    "id": 2773,
    "package_name": "DHARMa",
    "title": "Residual Diagnostics for Hierarchical (Multi-Level / Mixed)\nRegression Models",
    "description": "The 'DHARMa' package uses a simulation-based approach to create\n    readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed\n    models. Currently supported are linear and generalized linear (mixed) models from 'lme4'\n    (classes 'lmerMod', 'glmerMod'), 'glmmTMB', 'GLMMadaptive', and 'spaMM'; phylogenetic \n    linear models from 'phylolm' (classes 'phylolm' and 'phyloglm'); generalized additive \n    models ('gam' from 'mgcv'); 'glm' (including 'negbin' from 'MASS', but excluding quasi-distributions) and\n    'lm' model classes. Moreover, externally created simulations, e.g. posterior predictive simulations\n    from Bayesian software such as 'JAGS', 'STAN', or 'BUGS' can be processed as well.\n    The resulting residuals are standardized to values between 0 and 1 and can be interpreted\n    as intuitively as residuals from a linear regression. The package also provides a number of\n    plot and test functions for typical model misspecification problems, such as\n    over/underdispersion, zero-inflation, and residual spatial, phylogenetic and temporal autocorrelation.",
    "version": "0.4.7",
    "maintainer": "Florian Hartig <florian.hartig@biologie.uni-regensburg.de>",
    "author": "Florian Hartig [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6255-9059>),\n  Lukas Lohse [ctb],\n  Melina de Souza leite [ctb]",
    "url": "http://florianhartig.github.io/DHARMa/",
    "bug_reports": "https://github.com/florianhartig/DHARMa/issues",
    "repository": "https://cran.r-project.org/package=DHARMa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DHARMa Residual Diagnostics for Hierarchical (Multi-Level / Mixed)\nRegression Models The 'DHARMa' package uses a simulation-based approach to create\n    readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed\n    models. Currently supported are linear and generalized linear (mixed) models from 'lme4'\n    (classes 'lmerMod', 'glmerMod'), 'glmmTMB', 'GLMMadaptive', and 'spaMM'; phylogenetic \n    linear models from 'phylolm' (classes 'phylolm' and 'phyloglm'); generalized additive \n    models ('gam' from 'mgcv'); 'glm' (including 'negbin' from 'MASS', but excluding quasi-distributions) and\n    'lm' model classes. Moreover, externally created simulations, e.g. posterior predictive simulations\n    from Bayesian software such as 'JAGS', 'STAN', or 'BUGS' can be processed as well.\n    The resulting residuals are standardized to values between 0 and 1 and can be interpreted\n    as intuitively as residuals from a linear regression. The package also provides a number of\n    plot and test functions for typical model misspecification problems, such as\n    over/underdispersion, zero-inflation, and residual spatial, phylogenetic and temporal autocorrelation.  "
  },
  {
    "id": 2783,
    "package_name": "DIFM",
    "title": "Dynamic ICAR Spatiotemporal Factor Models",
    "description": "Bayesian factor models are effective tools for dimension reduction. This is especially applicable to multivariate large-scale datasets. It allows researchers to understand the latent factors of the data which are the linear or non-linear combination of the variables. Dynamic Intrinsic Conditional Autocorrelative Priors (ICAR) Spatiotemporal Factor Models 'DIFM' package provides function to run Markov Chain Monte Carlo (MCMC), evaluation methods and visual plots from Shin and Ferreira (2023)<doi:10.1016/j.spasta.2023.100763>. Our method is a class of Bayesian factor model which can account for spatial and temporal correlations. By incorporating these correlations, the model can capture specific behaviors and provide predictions. ",
    "version": "1.0.1",
    "maintainer": "Hwasoo Shin <hshin2@hfhs.org>",
    "author": "Hwasoo Shin [aut, cre],\n  Marco Ferreira [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DIFM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIFM Dynamic ICAR Spatiotemporal Factor Models Bayesian factor models are effective tools for dimension reduction. This is especially applicable to multivariate large-scale datasets. It allows researchers to understand the latent factors of the data which are the linear or non-linear combination of the variables. Dynamic Intrinsic Conditional Autocorrelative Priors (ICAR) Spatiotemporal Factor Models 'DIFM' package provides function to run Markov Chain Monte Carlo (MCMC), evaluation methods and visual plots from Shin and Ferreira (2023)<doi:10.1016/j.spasta.2023.100763>. Our method is a class of Bayesian factor model which can account for spatial and temporal correlations. By incorporating these correlations, the model can capture specific behaviors and provide predictions.   "
  },
  {
    "id": 2791,
    "package_name": "DIMORA",
    "title": "Diffusion Models R Analysis",
    "description": "The implemented methods are: Standard Bass model, Generalized Bass model (with rectangular shock, exponential shock, and mixed shock. You can choose to add from 1 to 3 shocks), Guseo-Guidolin model and Variable Potential Market model, and UCRCD model. The Bass model consists of a simple differential equation that describes the process of how new products get adopted in a population, the Generalized Bass model is a generalization of the Bass model in which there is a \"carrier\" function x(t) that allows to change the speed of time sliding. In some real processes the reachable potential of the resource available in a temporal instant may appear to be not constant over time, because of this we use Variable Potential Market model, in which the Guseo-Guidolin has a particular specification for the market function. The UCRCD model (Unbalanced Competition and Regime Change Diachronic) is a diffusion model used to capture the dynamics of the competitive or collaborative transition.",
    "version": "0.3.6",
    "maintainer": "Savio Andrea <svandr97@gmail.com>",
    "author": "Zanghi Federico, Savio Andrea, Filippo Ziliotto, Bessi Alessandro",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DIMORA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIMORA Diffusion Models R Analysis The implemented methods are: Standard Bass model, Generalized Bass model (with rectangular shock, exponential shock, and mixed shock. You can choose to add from 1 to 3 shocks), Guseo-Guidolin model and Variable Potential Market model, and UCRCD model. The Bass model consists of a simple differential equation that describes the process of how new products get adopted in a population, the Generalized Bass model is a generalization of the Bass model in which there is a \"carrier\" function x(t) that allows to change the speed of time sliding. In some real processes the reachable potential of the resource available in a temporal instant may appear to be not constant over time, because of this we use Variable Potential Market model, in which the Guseo-Guidolin has a particular specification for the market function. The UCRCD model (Unbalanced Competition and Regime Change Diachronic) is a diffusion model used to capture the dynamics of the competitive or collaborative transition.  "
  },
  {
    "id": 2792,
    "package_name": "DIRECT",
    "title": "Bayesian Clustering of Multivariate Data Under the\nDirichlet-Process Prior",
    "description": "A Bayesian clustering method for replicated time series or replicated measurements from multiple experimental conditions, e.g., time-course gene expression data.  It estimates the number of clusters directly from the data using a Dirichlet-process prior.  See Fu, A. Q., Russell, S., Bray, S. and Tavare, S. (2013) Bayesian clustering of replicated time-course gene expression data with weak signals. The Annals of Applied Statistics. 7(3) 1334-1361. <doi:10.1214/13-AOAS650>.",
    "version": "1.1.0",
    "maintainer": "Audrey Q. Fu <audreyqyfu@gmail.com>",
    "author": "Audrey Qiuyan Fu, Steven Russell, Sarah J. Bray and Simon Tavare",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DIRECT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIRECT Bayesian Clustering of Multivariate Data Under the\nDirichlet-Process Prior A Bayesian clustering method for replicated time series or replicated measurements from multiple experimental conditions, e.g., time-course gene expression data.  It estimates the number of clusters directly from the data using a Dirichlet-process prior.  See Fu, A. Q., Russell, S., Bray, S. and Tavare, S. (2013) Bayesian clustering of replicated time-course gene expression data with weak signals. The Annals of Applied Statistics. 7(3) 1334-1361. <doi:10.1214/13-AOAS650>.  "
  },
  {
    "id": 2802,
    "package_name": "DIscBIO",
    "title": "A User-Friendly Pipeline for Biomarker Discovery in Single-Cell\nTranscriptomics",
    "description": "An open, multi-algorithmic pipeline for easy, fast and efficient\n  analysis of cellular sub-populations and the molecular signatures that\n  characterize them. The pipeline consists of four successive steps: data\n  pre-processing, cellular clustering with pseudo-temporal ordering, defining\n  differential expressed genes and biomarker identification. More details on\n  Ghannoum et. al. (2021) <doi:10.3390/ijms22031399>. This package implements\n  extensions of the work published by Ghannoum et. al. (2019)\n  <doi:10.1101/700989>.",
    "version": "1.2.2",
    "maintainer": "Waldir Leoncio <w.l.netto@medisin.uio.no>",
    "author": "Salim Ghannoum [aut, cph],\n  Alvaro K\u00f6hn-Luque [aut, ths],\n  Waldir Leoncio [cre, aut],\n  Damiano Fantini [ctb]",
    "url": "https://github.com/ocbe-uio/DIscBIO",
    "bug_reports": "https://github.com/ocbe-uio/DIscBIO/issues",
    "repository": "https://cran.r-project.org/package=DIscBIO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIscBIO A User-Friendly Pipeline for Biomarker Discovery in Single-Cell\nTranscriptomics An open, multi-algorithmic pipeline for easy, fast and efficient\n  analysis of cellular sub-populations and the molecular signatures that\n  characterize them. The pipeline consists of four successive steps: data\n  pre-processing, cellular clustering with pseudo-temporal ordering, defining\n  differential expressed genes and biomarker identification. More details on\n  Ghannoum et. al. (2021) <doi:10.3390/ijms22031399>. This package implements\n  extensions of the work published by Ghannoum et. al. (2019)\n  <doi:10.1101/700989>.  "
  },
  {
    "id": 2803,
    "package_name": "DJL",
    "title": "Distance Measure Based Judgment and Learning",
    "description": "Implements various decision support tools related to the Econometrics & Technometrics.\n             Subroutines include correlation reliability test, Mahalanobis distance measure for outlier detection, combinatorial search (all possible subset regression), non-parametric efficiency analysis measures: DDF (directional distance function), DEA (data envelopment analysis), HDF (hyperbolic distance function), SBM (slack-based measure), and SF (shortage function), benchmarking, Malmquist productivity analysis, risk analysis, technology adoption model, new product target setting, network DEA, dynamic DEA, intertemporal budgeting, etc.",
    "version": "3.9",
    "maintainer": "Dong-Joon Lim <tgno3.com@gmail.com>",
    "author": "Dong-Joon Lim, Ph.D. <technometrics.org>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DJL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DJL Distance Measure Based Judgment and Learning Implements various decision support tools related to the Econometrics & Technometrics.\n             Subroutines include correlation reliability test, Mahalanobis distance measure for outlier detection, combinatorial search (all possible subset regression), non-parametric efficiency analysis measures: DDF (directional distance function), DEA (data envelopment analysis), HDF (hyperbolic distance function), SBM (slack-based measure), and SF (shortage function), benchmarking, Malmquist productivity analysis, risk analysis, technology adoption model, new product target setting, network DEA, dynamic DEA, intertemporal budgeting, etc.  "
  },
  {
    "id": 2882,
    "package_name": "DTSg",
    "title": "A Class for Working with Time Series Data Based on 'data.table'\nand 'R6' with Largely Optional Reference Semantics",
    "description": "Basic time series functionalities such as listing of missing\n    values, application of arbitrary aggregation as well as rolling (asymmetric)\n    window functions and automatic detection of periodicity. As it is mainly\n    based on 'data.table', it is fast and (in combination with the 'R6' package)\n    offers reference semantics. In addition to its native R6 interface, it\n    provides an S3 interface for those who prefer the latter. Finally yet\n    importantly, its functional approach allows for incorporating\n    functionalities from many other packages.",
    "version": "2.0.0",
    "maintainer": "Gerold Hepp <gisler@hepp.cc>",
    "author": "Gerold Hepp [aut, cre]",
    "url": "https://gisler.github.io/DTSg/",
    "bug_reports": "https://github.com/gisler/DTSg/issues",
    "repository": "https://cran.r-project.org/package=DTSg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DTSg A Class for Working with Time Series Data Based on 'data.table'\nand 'R6' with Largely Optional Reference Semantics Basic time series functionalities such as listing of missing\n    values, application of arbitrary aggregation as well as rolling (asymmetric)\n    window functions and automatic detection of periodicity. As it is mainly\n    based on 'data.table', it is fast and (in combination with the 'R6' package)\n    offers reference semantics. In addition to its native R6 interface, it\n    provides an S3 interface for those who prefer the latter. Finally yet\n    importantly, its functional approach allows for incorporating\n    functionalities from many other packages.  "
  },
  {
    "id": 2883,
    "package_name": "DTWBI",
    "title": "Imputation of Time Series Based on Dynamic Time Warping",
    "description": "Functions to impute large gaps within time series based on Dynamic Time Warping methods. It contains all required functions to create large missing consecutive values within time series and to fill them, according to the paper Phan et al. (2017), <DOI:10.1016/j.patrec.2017.08.019>. Performance criteria are added to compare similarity between two signals (query and reference).",
    "version": "1.1",
    "maintainer": "Emilie Poisson-Caillault <emilie.poisson@univ-littoral.fr>",
    "author": "Camille Dezecache, T. T. Hong Phan, Emilie Poisson-Caillault",
    "url": "http://mawenzi.univ-littoral.fr/DTWBI/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DTWBI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DTWBI Imputation of Time Series Based on Dynamic Time Warping Functions to impute large gaps within time series based on Dynamic Time Warping methods. It contains all required functions to create large missing consecutive values within time series and to fill them, according to the paper Phan et al. (2017), <DOI:10.1016/j.patrec.2017.08.019>. Performance criteria are added to compare similarity between two signals (query and reference).  "
  },
  {
    "id": 2884,
    "package_name": "DTWUMI",
    "title": "Imputation of Multivariate Time Series Based on Dynamic Time\nWarping",
    "description": "Functions to impute large gaps within multivariate time series based on Dynamic Time Warping methods. Gaps of size 1 or inferior to a defined threshold are filled using simple average and weighted moving average respectively. Larger gaps are filled using the methodology provided by Phan et al. (2017) <DOI:10.1109/MLSP.2017.8168165>: a query is built immediately before/after a gap and a moving window is used to find the most similar sequence to this query using Dynamic Time Warping. To lower the calculation time, similar sequences are pre-selected using global features. Contrary to the univariate method (package 'DTWBI'), these global features are not estimated over the sequence containing the gap(s), but a feature matrix is built to summarize general features of the whole multivariate signal. Once the most similar sequence to the query has been identified, the adjacent sequence to this window is used to fill the gap considered. This function can deal with multiple gaps over all the sequences componing the input multivariate signal. However, for better consistency, large gaps at the same location over all sequences should be avoided.",
    "version": "1.0",
    "maintainer": "POISSON-CAILLAULT Emilie <emilie.poisson@univ-littoral.fr>",
    "author": "DEZECACHE Camille, PHAN Thi Thu Hong, POISSON-CAILLAULT Emilie",
    "url": "http://mawenzi.univ-littoral.fr/DTWUMI/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DTWUMI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DTWUMI Imputation of Multivariate Time Series Based on Dynamic Time\nWarping Functions to impute large gaps within multivariate time series based on Dynamic Time Warping methods. Gaps of size 1 or inferior to a defined threshold are filled using simple average and weighted moving average respectively. Larger gaps are filled using the methodology provided by Phan et al. (2017) <DOI:10.1109/MLSP.2017.8168165>: a query is built immediately before/after a gap and a moving window is used to find the most similar sequence to this query using Dynamic Time Warping. To lower the calculation time, similar sequences are pre-selected using global features. Contrary to the univariate method (package 'DTWBI'), these global features are not estimated over the sequence containing the gap(s), but a feature matrix is built to summarize general features of the whole multivariate signal. Once the most similar sequence to the query has been identified, the adjacent sequence to this window is used to fill the gap considered. This function can deal with multiple gaps over all the sequences componing the input multivariate signal. However, for better consistency, large gaps at the same location over all sequences should be avoided.  "
  },
  {
    "id": 2891,
    "package_name": "DWaveNARDL",
    "title": "Dual Wavelet Based NARDL Model",
    "description": "Dual Wavelet based Nonlinear Autoregressive Distributed Lag model has been developed for noisy time series analysis. This package is designed to capture both short-run and long-run relationships in time series data, while incorporating wavelet transformations. The methodology combines the NARDL model with wavelet decomposition to better capture the nonlinear dynamics of the series and exogenous variables. The package is useful for analyzing economic and financial time series data that exhibit both long-term trends and short-term fluctuations. This package has been developed using algorithm of Jammazi et al. <doi:10.1016/j.intfin.2014.11.011>.",
    "version": "0.1.0",
    "maintainer": "Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Md Yeasin [aut, cre],\n  Ranjit Kumar Paul [aut],\n  Ranjit Kumar Upadhyay [aut],\n  Anita Sarkar [aut],\n  Amrit Kumar Paul [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DWaveNARDL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DWaveNARDL Dual Wavelet Based NARDL Model Dual Wavelet based Nonlinear Autoregressive Distributed Lag model has been developed for noisy time series analysis. This package is designed to capture both short-run and long-run relationships in time series data, while incorporating wavelet transformations. The methodology combines the NARDL model with wavelet decomposition to better capture the nonlinear dynamics of the series and exogenous variables. The package is useful for analyzing economic and financial time series data that exhibit both long-term trends and short-term fluctuations. This package has been developed using algorithm of Jammazi et al. <doi:10.1016/j.intfin.2014.11.011>.  "
  },
  {
    "id": 2911,
    "package_name": "DataSetsVerse",
    "title": "A Metapackage for Thematic and Domain-Specific Datasets",
    "description": "A metapackage that brings together a curated collection \n    of R packages containing domain-specific datasets. It includes time series data, \n    educational metrics, crime records, medical datasets, and oncology research data. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to structured and well-documented datasets, this metapackage \n    facilitates reproducible research, data exploration, and teaching applications across \n    a wide range of domains.\n    Included packages:\n    - 'timeSeriesDataSets': Time series data from economics, finance, energy, and healthcare.\n    - 'educationR': Datasets related to education, learning outcomes, and school metrics.\n    - 'crimedatasets': Datasets on global and local crime and criminal behavior.\n    - 'MedDataSets': Datasets related to medicine, public health, treatments, and clinical trials.\n    - 'OncoDataSets': Datasets focused on cancer research, survival, genetics, and biomarkers.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/datasetsverse,\nhttps://lightbluetitan.github.io/datasetsverse/",
    "bug_reports": "https://github.com/lightbluetitan/datasetsverse/issues",
    "repository": "https://cran.r-project.org/package=DataSetsVerse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DataSetsVerse A Metapackage for Thematic and Domain-Specific Datasets A metapackage that brings together a curated collection \n    of R packages containing domain-specific datasets. It includes time series data, \n    educational metrics, crime records, medical datasets, and oncology research data. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to structured and well-documented datasets, this metapackage \n    facilitates reproducible research, data exploration, and teaching applications across \n    a wide range of domains.\n    Included packages:\n    - 'timeSeriesDataSets': Time series data from economics, finance, energy, and healthcare.\n    - 'educationR': Datasets related to education, learning outcomes, and school metrics.\n    - 'crimedatasets': Datasets on global and local crime and criminal behavior.\n    - 'MedDataSets': Datasets related to medicine, public health, treatments, and clinical trials.\n    - 'OncoDataSets': Datasets focused on cancer research, survival, genetics, and biomarkers.  "
  },
  {
    "id": 2924,
    "package_name": "DeCAFS",
    "title": "Detecting Changes in Autocorrelated and Fluctuating Signals",
    "description": "Detect abrupt changes in time series with local fluctuations as a random walk process and autocorrelated noise as an AR(1) process. See Romano, G., Rigaill, G., Runge, V., Fearnhead, P. (2021) <doi:10.1080/01621459.2021.1909598>.",
    "version": "3.3.5",
    "maintainer": "Gaetano Romano <g.romano@lancaster.ac.uk>",
    "author": "Gaetano Romano [aut, cre],\n  Guillem Rigaill [aut],\n  Vincent Runge [aut],\n  Paul Fearnhead [aut]",
    "url": "",
    "bug_reports": "https://github.com/gtromano/DeCAFS/issues",
    "repository": "https://cran.r-project.org/package=DeCAFS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DeCAFS Detecting Changes in Autocorrelated and Fluctuating Signals Detect abrupt changes in time series with local fluctuations as a random walk process and autocorrelated noise as an AR(1) process. See Romano, G., Rigaill, G., Runge, V., Fearnhead, P. (2021) <doi:10.1080/01621459.2021.1909598>.  "
  },
  {
    "id": 2942,
    "package_name": "DendroSync",
    "title": "A Set of Tools for Calculating Spatial Synchrony Between\nTree-Ring Chronologies",
    "description": "Provides functions for the calculation and plotting of synchrony in \n      tree growth from tree-ring width chronologies (TRW index). It combines\n      variance-covariance (VCOV) mixed modelling with functions that quantify \n      the degree to which the TRW chronologies contain a common temporal \n      signal. It also implements temporal trends in spatial synchrony using a \n      moving window. These methods can also be used with other kind of ecological\n      variables that have temporal autocorrelation corrected.",
    "version": "0.1.5",
    "maintainer": "Josu G. Alday <josucham@gmail.com>",
    "author": "Josu G. Alday [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7510-8655>),\n  Tatiana A. Shestakova [aut] (ORCID:\n    <https://orcid.org/0000-0002-5605-0299>),\n  Victor Resco de Dios [aut] (ORCID:\n    <https://orcid.org/0000-0002-5721-1656>),\n  Jordi Voltas [aut] (ORCID: <https://orcid.org/0000-0003-4051-1158>)",
    "url": "https://bitbucket.org/josucham/dendrosync/src/issues/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DendroSync",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DendroSync A Set of Tools for Calculating Spatial Synchrony Between\nTree-Ring Chronologies Provides functions for the calculation and plotting of synchrony in \n      tree growth from tree-ring width chronologies (TRW index). It combines\n      variance-covariance (VCOV) mixed modelling with functions that quantify \n      the degree to which the TRW chronologies contain a common temporal \n      signal. It also implements temporal trends in spatial synchrony using a \n      moving window. These methods can also be used with other kind of ecological\n      variables that have temporal autocorrelation corrected.  "
  },
  {
    "id": 2991,
    "package_name": "DisaggregateTS",
    "title": "High-Dimensional Temporal Disaggregation",
    "description": "Provides tools for temporal disaggregation, including:\n    (1) High-dimensional and low-dimensional series generation for simulation studies;\n    (2) A toolkit for temporal disaggregation and benchmarking using low-dimensional indicator series \n        as proposed by Dagum and Cholette (2006, ISBN:978-0-387-35439-2);\n    (3) Novel techniques by Mosley, Gibberd, and Eckley (2022, <doi:10.1111/rssa.12952>)\n        for disaggregating low-frequency series in the presence of high-dimensional indicator matrices.",
    "version": "3.0.1",
    "maintainer": "Kaveh Salehzadeh Nobari <k.salehzadeh-nobari@imperial.ac.uk>",
    "author": "Kaveh Salehzadeh Nobari [aut, cre],\n  Luke Mosley [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DisaggregateTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DisaggregateTS High-Dimensional Temporal Disaggregation Provides tools for temporal disaggregation, including:\n    (1) High-dimensional and low-dimensional series generation for simulation studies;\n    (2) A toolkit for temporal disaggregation and benchmarking using low-dimensional indicator series \n        as proposed by Dagum and Cholette (2006, ISBN:978-0-387-35439-2);\n    (3) Novel techniques by Mosley, Gibberd, and Eckley (2022, <doi:10.1111/rssa.12952>)\n        for disaggregating low-frequency series in the presence of high-dimensional indicator matrices.  "
  },
  {
    "id": 2992,
    "package_name": "DisasterAlert",
    "title": "Disaster Alert and Sentiment Analysis",
    "description": "By systematically aggregating and processing textual reports from earthquakes, floods, storms,\n  wildfires, and other natural disasters, the framework enables a holistic assessment of crisis narratives.  \n  Intelligent cleaning and normalization techniques transform raw commentary into structured data, ensuring\n  precise extraction of disaster-specific insights. Collective sentiments of affected communities are  \n  quantitatively scored and qualitatively categorized, providing a multifaceted view of societal responses  \n  under duress. Interactive geographic maps and temporal charts illustrate the evolution and spatial dispersion\n  of emotional reactions and impact indicators. ",
    "version": "1.0.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Nadejda Komendantova [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DisasterAlert",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DisasterAlert Disaster Alert and Sentiment Analysis By systematically aggregating and processing textual reports from earthquakes, floods, storms,\n  wildfires, and other natural disasters, the framework enables a holistic assessment of crisis narratives.  \n  Intelligent cleaning and normalization techniques transform raw commentary into structured data, ensuring\n  precise extraction of disaster-specific insights. Collective sentiments of affected communities are  \n  quantitatively scored and qualitatively categorized, providing a multifaceted view of societal responses  \n  under duress. Interactive geographic maps and temporal charts illustrate the evolution and spatial dispersion\n  of emotional reactions and impact indicators.   "
  },
  {
    "id": 3050,
    "package_name": "DynClust",
    "title": "Denoising and Clustering for Dynamical Image Sequence (2D or\n3D)+t",
    "description": "A two-stage procedure for the denoising and clustering of stack of noisy images acquired over time. Clustering only assumes that the data contain an unknown but small number of dynamic features. The method first denoises the signals using local spatial and full temporal information. The clustering step uses the previous output to aggregate voxels based on the knowledge of their spatial neighborhood. Both steps use a single keytool based on the statistical comparison of the difference of two signals with the null signal. No assumption is therefore required on the shape of the signals. The data are assumed to be normally distributed (or at least follow a symmetric distribution) with a known constant variance. Working pixelwise, the method can be time-consuming depending on the size of the data-array but harnesses the power of multicore cpus.",
    "version": "3.24",
    "maintainer": "Yves Rozenholc <yves.rozenholc@u-paris.fr>",
    "author": "Yves Rozenholc (UR7537, Univ. Paris Cit\u00e9), Christophe Pouzat (IRMA, CNRS UMR 7501) and Tiffany Lieury (Cerebral Physiology lab, Univ. Paris Descartes)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DynClust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DynClust Denoising and Clustering for Dynamical Image Sequence (2D or\n3D)+t A two-stage procedure for the denoising and clustering of stack of noisy images acquired over time. Clustering only assumes that the data contain an unknown but small number of dynamic features. The method first denoises the signals using local spatial and full temporal information. The clustering step uses the previous output to aggregate voxels based on the knowledge of their spatial neighborhood. Both steps use a single keytool based on the statistical comparison of the difference of two signals with the null signal. No assumption is therefore required on the shape of the signals. The data are assumed to be normally distributed (or at least follow a symmetric distribution) with a known constant variance. Working pixelwise, the method can be time-consuming depending on the size of the data-array but harnesses the power of multicore cpus.  "
  },
  {
    "id": 3061,
    "package_name": "EBASE",
    "title": "Estuarine Bayesian Single-Station Estimation Method for\nEcosystem Metabolism",
    "description": "Estimate ecosystem metabolism in a Bayesian framework for\n  individual water quality monitoring stations with continuous dissolved\n  oxygen time series. A mass balance equation is used that provides\n  estimates of parameters for gross primary production, respiration,\n  and gas exchange. Methods adapted from Grace et al. (2015)\n  <doi:10.1002/lom3.10011> and Wanninkhof (2014) <doi:10.4319/lom.2014.12.351>.\n  Details in Beck et al. (2024) <doi:10.1002/lom3.10620>.",
    "version": "1.1.0",
    "maintainer": "Marcus Beck <mbeck@tbep.org>",
    "author": "Marcus Beck [aut, cre] (ORCID: <https://orcid.org/0000-0002-4996-0059>),\n  Maria Herrmann [aut],\n  Jill Arriola [aut] (ORCID: <https://orcid.org/0000-0003-2173-8349>),\n  Raymond Najjar [aut] (ORCID: <https://orcid.org/0000-0002-2960-5965>)",
    "url": "https://fawda123.github.io/EBASE/,\nhttps://github.com/fawda123/EBASE/",
    "bug_reports": "https://github.com/fawda123/EBASE/issues",
    "repository": "https://cran.r-project.org/package=EBASE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EBASE Estuarine Bayesian Single-Station Estimation Method for\nEcosystem Metabolism Estimate ecosystem metabolism in a Bayesian framework for\n  individual water quality monitoring stations with continuous dissolved\n  oxygen time series. A mass balance equation is used that provides\n  estimates of parameters for gross primary production, respiration,\n  and gas exchange. Methods adapted from Grace et al. (2015)\n  <doi:10.1002/lom3.10011> and Wanninkhof (2014) <doi:10.4319/lom.2014.12.351>.\n  Details in Beck et al. (2024) <doi:10.1002/lom3.10620>.  "
  },
  {
    "id": 3064,
    "package_name": "EBMAforecast",
    "title": "Estimate Ensemble Bayesian Model Averaging Forecasts using Gibbs\nSampling or EM-Algorithms",
    "description": "Create forecasts from multiple predictions using ensemble Bayesian model averaging (EBMA). EBMA models can be estimated using an expectation maximization (EM) algorithm or as fully Bayesian models via Gibbs sampling. The methods in this package are Montgomery, Hollenbach, and Ward (2015) <doi:10.1016/j.ijforecast.2014.08.001> and Montgomery, Hollenbach, and Ward (2012) <doi:10.1093/pan/mps002>.",
    "version": "1.0.32",
    "maintainer": "Florian M. Hollenbach <fho.egb@cbs.dk>",
    "author": "Florian M. Hollenbach [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9599-556X>),\n  Jacob M. Montgomery [aut],\n  Michael D. Ward [aut]",
    "url": "https://github.com/fhollenbach/EBMA/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EBMAforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EBMAforecast Estimate Ensemble Bayesian Model Averaging Forecasts using Gibbs\nSampling or EM-Algorithms Create forecasts from multiple predictions using ensemble Bayesian model averaging (EBMA). EBMA models can be estimated using an expectation maximization (EM) algorithm or as fully Bayesian models via Gibbs sampling. The methods in this package are Montgomery, Hollenbach, and Ward (2015) <doi:10.1016/j.ijforecast.2014.08.001> and Montgomery, Hollenbach, and Ward (2012) <doi:10.1093/pan/mps002>.  "
  },
  {
    "id": 3078,
    "package_name": "EDISON",
    "title": "Network Reconstruction and Changepoint Detection",
    "description": "Package EDISON (Estimation of Directed Interactions from\n    Sequences Of Non-homogeneous gene expression) runs an MCMC\n    simulation to reconstruct networks from time series data, using\n    a non-homogeneous, time-varying dynamic Bayesian network.\n    Networks segments and changepoints are inferred concurrently,\n    and information sharing priors provide a reduction of the\n    inference uncertainty.",
    "version": "1.1.1",
    "maintainer": "Frank Dondelinger <fdondelinger.work@gmail.com>",
    "author": "Frank Dondelinger, Sophie Lebre",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EDISON",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EDISON Network Reconstruction and Changepoint Detection Package EDISON (Estimation of Directed Interactions from\n    Sequences Of Non-homogeneous gene expression) runs an MCMC\n    simulation to reconstruct networks from time series data, using\n    a non-homogeneous, time-varying dynamic Bayesian network.\n    Networks segments and changepoints are inferred concurrently,\n    and information sharing priors provide a reduction of the\n    inference uncertainty.  "
  },
  {
    "id": 3084,
    "package_name": "EEMDSVR",
    "title": "Ensemble Empirical Mode Decomposition and Its Variant Based\nSupport Vector Regression Model",
    "description": "Application of Ensemble Empirical Mode Decomposition and its variant based Support Vector regression model for univariate time series forecasting. For method details see Das (2020).<http://krishi.icar.gov.in/jspui/handle/123456789/44138>.",
    "version": "0.1.0",
    "maintainer": "Pankaj Das <pankaj.das2@icar.gov.in>",
    "author": "Pankaj Das [aut, cre],\n  Kapil Choudhary [aut],\n  Girish Kumar Jha [aut],\n  Achal Lama [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EEMDSVR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EEMDSVR Ensemble Empirical Mode Decomposition and Its Variant Based\nSupport Vector Regression Model Application of Ensemble Empirical Mode Decomposition and its variant based Support Vector regression model for univariate time series forecasting. For method details see Das (2020).<http://krishi.icar.gov.in/jspui/handle/123456789/44138>.  "
  },
  {
    "id": 3085,
    "package_name": "EEMDelm",
    "title": "Ensemble Empirical Mode Decomposition and Its Variant Based ELM\nModel",
    "description": "Forecasting univariate time series with different decomposition based Extreme Learning Machine models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>, Parida M, Behera MK, Nayak N (2018). <doi:10.1109/ICSESP.2018.8376723>. ",
    "version": "0.1.1",
    "maintainer": "Girish Kumar Jha <girish.stat@gmail.com>",
    "author": "Girish Kumar Jha [aut, cre],\n  Kapil Choudhary [aut, ctb],\n  Rajeev Ranjan Kumar [ctb],\n  Ronit Jaiswal [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EEMDelm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EEMDelm Ensemble Empirical Mode Decomposition and Its Variant Based ELM\nModel Forecasting univariate time series with different decomposition based Extreme Learning Machine models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>, Parida M, Behera MK, Nayak N (2018). <doi:10.1109/ICSESP.2018.8376723>.   "
  },
  {
    "id": 3089,
    "package_name": "EFA.dimensions",
    "title": "Exploratory Factor Analysis Functions for Assessing\nDimensionality",
    "description": "Functions for eleven procedures for determining the number of \n    factors, including functions for parallel analysis and the minimum average partial \n    test. There are also functions for conducting principal components analysis, principal \n    axis factor analysis, maximum likelihood factor analysis, image factor analysis, \n    and extension factor analysis, all of which can take raw data or correlation matrices \n    as input and with options for conducting the analyses using Pearson correlations, \n    Kendall correlations, Spearman correlations, gamma correlations, or polychoric \n    correlations. Varimax rotation, promax rotation, and Procrustes rotations can be\n    performed. Additional functions focus on the factorability of a correlation matrix,\n    the congruences between factors from different datasets, the assessment of local\n    independence, the assessment of factor solution complexity, and internal consistency.\n    Auerswald & Moshagen (2019, ISSN:1939-1463);\n    Field, Miles, & Field (2012, ISBN:978-1-4462-0045-2);\n    Mulaik (2010, ISBN:978-1-4200-9981-2);\n    O'Connor (2000, <doi:10.3758/bf03200807>);\n    O'Connor (2001, ISSN:0146-6216).",
    "version": "0.1.8.4",
    "maintainer": "Brian P. O'Connor  <brian.oconnor@ubc.ca>",
    "author": "Brian P. O'Connor [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EFA.dimensions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EFA.dimensions Exploratory Factor Analysis Functions for Assessing\nDimensionality Functions for eleven procedures for determining the number of \n    factors, including functions for parallel analysis and the minimum average partial \n    test. There are also functions for conducting principal components analysis, principal \n    axis factor analysis, maximum likelihood factor analysis, image factor analysis, \n    and extension factor analysis, all of which can take raw data or correlation matrices \n    as input and with options for conducting the analyses using Pearson correlations, \n    Kendall correlations, Spearman correlations, gamma correlations, or polychoric \n    correlations. Varimax rotation, promax rotation, and Procrustes rotations can be\n    performed. Additional functions focus on the factorability of a correlation matrix,\n    the congruences between factors from different datasets, the assessment of local\n    independence, the assessment of factor solution complexity, and internal consistency.\n    Auerswald & Moshagen (2019, ISSN:1939-1463);\n    Field, Miles, & Field (2012, ISBN:978-1-4462-0045-2);\n    Mulaik (2010, ISBN:978-1-4200-9981-2);\n    O'Connor (2000, <doi:10.3758/bf03200807>);\n    O'Connor (2001, ISSN:0146-6216).  "
  },
  {
    "id": 3095,
    "package_name": "EGAnet",
    "title": "Exploratory Graph Analysis \u2013 a Framework for Estimating the\nNumber of Dimensions in Multivariate Data using Network\nPsychometrics",
    "description": "Implements the Exploratory Graph Analysis (EGA) framework for dimensionality\n             and psychometric assessment. EGA estimates the number of dimensions in\n\t     \t psychological data using network estimation methods and community detection\n             algorithms. A bootstrap method is provided to assess the stability of dimensions\n\t     \t and items. Fit is evaluated using the Entropy Fit family of indices. Unique \n             Variable Analysis evaluates the extent to which items are locally dependent (or\n             redundant). Network loadings provide similar information to factor loadings and\n\t     \t can be used to compute network scores. A bootstrap and permutation approach are\n             available to assess configural and metric invariance. Hierarchical structures\n             can be detected using Hierarchical EGA. Time series and intensive longitudinal \n\t     \t data can be analyzed using Dynamic EGA, supporting individual, group, and \n             population level assessments.",
    "version": "2.4.0",
    "maintainer": "Hudson Golino <hfg9s@virginia.edu>",
    "author": "Hudson Golino [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1601-1447>),\n  Alexander Christensen [aut] (ORCID:\n    <https://orcid.org/0000-0002-9798-7037>),\n  Robert Moulder [ctb] (ORCID: <https://orcid.org/0000-0001-7504-9560>),\n  Luis E. Garrido [ctb] (ORCID: <https://orcid.org/0000-0001-8932-6063>),\n  Laura Jamison [ctb] (ORCID: <https://orcid.org/0000-0002-4656-8684>),\n  Dingjing Shi [ctb] (ORCID: <https://orcid.org/0000-0002-5652-3818>)",
    "url": "https://r-ega.net",
    "bug_reports": "https://github.com/hfgolino/EGAnet/issues",
    "repository": "https://cran.r-project.org/package=EGAnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EGAnet Exploratory Graph Analysis \u2013 a Framework for Estimating the\nNumber of Dimensions in Multivariate Data using Network\nPsychometrics Implements the Exploratory Graph Analysis (EGA) framework for dimensionality\n             and psychometric assessment. EGA estimates the number of dimensions in\n\t     \t psychological data using network estimation methods and community detection\n             algorithms. A bootstrap method is provided to assess the stability of dimensions\n\t     \t and items. Fit is evaluated using the Entropy Fit family of indices. Unique \n             Variable Analysis evaluates the extent to which items are locally dependent (or\n             redundant). Network loadings provide similar information to factor loadings and\n\t     \t can be used to compute network scores. A bootstrap and permutation approach are\n             available to assess configural and metric invariance. Hierarchical structures\n             can be detected using Hierarchical EGA. Time series and intensive longitudinal \n\t     \t data can be analyzed using Dynamic EGA, supporting individual, group, and \n             population level assessments.  "
  },
  {
    "id": 3102,
    "package_name": "EIAapi",
    "title": "Query Data from the 'EIA' API",
    "description": "Provides a function to query and extract data from the 'US Energy Information Administration' ('EIA') API V2  <https://www.eia.gov/opendata/>. The 'EIA' API provides a variety of information, in a time series format, about the energy sector in the US. The API is open, free, and requires an access key and registration at <https://www.eia.gov/opendata/>.",
    "version": "0.2.0",
    "maintainer": "Rami Krispin <rami.krispin@gmail.com>",
    "author": "Rami Krispin [aut, cre]",
    "url": "https://github.com/RamiKrispin/EIAapi",
    "bug_reports": "https://github.com/RamiKrispin/EIAapi/issues",
    "repository": "https://cran.r-project.org/package=EIAapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EIAapi Query Data from the 'EIA' API Provides a function to query and extract data from the 'US Energy Information Administration' ('EIA') API V2  <https://www.eia.gov/opendata/>. The 'EIA' API provides a variety of information, in a time series format, about the energy sector in the US. The API is open, free, and requires an access key and registration at <https://www.eia.gov/opendata/>.  "
  },
  {
    "id": 3121,
    "package_name": "EMDANNhybrid",
    "title": "Empirical Mode Decomposition Based Artificial Neural Network\nModel",
    "description": "Application of empirical mode decomposition based artificial neural network model for nonlinear and non stationary univariate time series forecasting. For method details see (i) Choudhury (2019) <https://www.indianjournals.com/ijor.aspx?target=ijor:ijee3&volume=55&issue=1&article=013>; (ii) Das (2020) <https://www.indianjournals.com/ijor.aspx?target=ijor:ijee3&volume=56&issue=2&article=002>.",
    "version": "0.2.0",
    "maintainer": "Pankaj Das <pankaj.das2@icar.gov.in>",
    "author": "Pankaj Das [aut, cre] (ORCID: <https://orcid.org/0000-0003-1672-2502>),\n  Achal Lama [aut],\n  Girish Kumar Jha [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EMDANNhybrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EMDANNhybrid Empirical Mode Decomposition Based Artificial Neural Network\nModel Application of empirical mode decomposition based artificial neural network model for nonlinear and non stationary univariate time series forecasting. For method details see (i) Choudhury (2019) <https://www.indianjournals.com/ijor.aspx?target=ijor:ijee3&volume=55&issue=1&article=013>; (ii) Das (2020) <https://www.indianjournals.com/ijor.aspx?target=ijor:ijee3&volume=56&issue=2&article=002>.  "
  },
  {
    "id": 3122,
    "package_name": "EMDSVRhybrid",
    "title": "Empirical Mode Decomposition Based Support Vector Regression\nModel",
    "description": "Description: Application of empirical mode decomposition based support vector regression model for nonlinear and non stationary univariate time series forecasting. For method details see (i) Choudhury (2019) <http://krishi.icar.gov.in/jspui/handle/123456789/44873>; (ii) Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/43174>; (iii) Das (2023) <http://krishi.icar.gov.in/jspui/handle/123456789/77772>.",
    "version": "0.2.0",
    "maintainer": "Pankaj Das <pankaj.das2@icar.gov.in>",
    "author": "Pankaj Das [aut, cre] (ORCID: <https://orcid.org/0000-0003-1672-2502>),\n  Achal Lama [aut],\n  Girish Kumar Jha [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EMDSVRhybrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EMDSVRhybrid Empirical Mode Decomposition Based Support Vector Regression\nModel Description: Application of empirical mode decomposition based support vector regression model for nonlinear and non stationary univariate time series forecasting. For method details see (i) Choudhury (2019) <http://krishi.icar.gov.in/jspui/handle/123456789/44873>; (ii) Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/43174>; (iii) Das (2023) <http://krishi.icar.gov.in/jspui/handle/123456789/77772>.  "
  },
  {
    "id": 3147,
    "package_name": "EQRN",
    "title": "Extreme Quantile Regression Neural Networks for Risk Forecasting",
    "description": "This framework enables forecasting and extrapolating measures of conditional risk\n    (e.g. of extreme or unprecedented events), including quantiles and exceedance probabilities,\n    using extreme value statistics and flexible neural network architectures.\n    It allows for capturing complex multivariate dependencies,\n    including dependencies between observations, such as sequential dependence (time-series).\n    The methodology was introduced in Pasche and Engelke (2024) <doi:10.1214/24-AOAS1907>\n    (also available in preprint: Pasche and Engelke (2022) <doi:10.48550/arXiv.2208.07590>).",
    "version": "0.1.2",
    "maintainer": "Olivier C. Pasche <olivier_pasche@alumni.epfl.ch>",
    "author": "Olivier C. Pasche [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1202-9199>)",
    "url": "https://github.com/opasche/EQRN, https://opasche.github.io/EQRN/",
    "bug_reports": "https://github.com/opasche/EQRN/issues",
    "repository": "https://cran.r-project.org/package=EQRN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EQRN Extreme Quantile Regression Neural Networks for Risk Forecasting This framework enables forecasting and extrapolating measures of conditional risk\n    (e.g. of extreme or unprecedented events), including quantiles and exceedance probabilities,\n    using extreme value statistics and flexible neural network architectures.\n    It allows for capturing complex multivariate dependencies,\n    including dependencies between observations, such as sequential dependence (time-series).\n    The methodology was introduced in Pasche and Engelke (2024) <doi:10.1214/24-AOAS1907>\n    (also available in preprint: Pasche and Engelke (2022) <doi:10.48550/arXiv.2208.07590>).  "
  },
  {
    "id": 3151,
    "package_name": "EQUALrepeat",
    "title": "Algorithm Driven Time Series Analysis for Researchers without\nCoding Skills",
    "description": "Support functions for R-based 'EQUAL-STATS' software which automatically classifies the data and performs appropriate statistical tests. 'EQUAL-STATS' software is a shiny application with an user-friendly interface to perform complex statistical analysis. Gurusamy,K (2024)<doi:10.5281/zenodo.13354162>.",
    "version": "0.4.0",
    "maintainer": "Kurinchi Gurusamy <k.gurusamy@ucl.ac.uk>",
    "author": "Kurinchi Gurusamy [aut, cre]",
    "url": "https://sites.google.com/view/equal-group/home",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EQUALrepeat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EQUALrepeat Algorithm Driven Time Series Analysis for Researchers without\nCoding Skills Support functions for R-based 'EQUAL-STATS' software which automatically classifies the data and performs appropriate statistical tests. 'EQUAL-STATS' software is a shiny application with an user-friendly interface to perform complex statistical analysis. Gurusamy,K (2024)<doi:10.5281/zenodo.13354162>.  "
  },
  {
    "id": 3163,
    "package_name": "ETAS",
    "title": "Modeling Earthquake Data Using 'ETAS' Model",
    "description": "Fits the space-time Epidemic Type Aftershock Sequence\n    ('ETAS') model to earthquake catalogs using a stochastic 'declustering' \n    approach. The 'ETAS' model is a 'spatio-temporal' marked point process\n    model and a special case of the 'Hawkes' process. The package is based \n    on a Fortran program by 'Jiancang Zhuang'\n    (available at <https://bemlar.ism.ac.jp/zhuang/software.html>),\n    which is modified and translated into C++ and C such that it \n    can be called from R. Parallel computing with 'OpenMP' is possible \n    on supported platforms.",
    "version": "0.7.2",
    "maintainer": "Abdollah Jalilian <stat4aj@gmail.com>",
    "author": "Abdollah Jalilian [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6573-0069>),\n  Jiancang Zhuang [ctb] (ORCID: <https://orcid.org/0000-0002-9708-3871>)",
    "url": "https://github.com/jalilian/ETAS",
    "bug_reports": "https://github.com/jalilian/ETAS/issues",
    "repository": "https://cran.r-project.org/package=ETAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ETAS Modeling Earthquake Data Using 'ETAS' Model Fits the space-time Epidemic Type Aftershock Sequence\n    ('ETAS') model to earthquake catalogs using a stochastic 'declustering' \n    approach. The 'ETAS' model is a 'spatio-temporal' marked point process\n    model and a special case of the 'Hawkes' process. The package is based \n    on a Fortran program by 'Jiancang Zhuang'\n    (available at <https://bemlar.ism.ac.jp/zhuang/software.html>),\n    which is modified and translated into C++ and C such that it \n    can be called from R. Parallel computing with 'OpenMP' is possible \n    on supported platforms.  "
  },
  {
    "id": 3164,
    "package_name": "ETASbootstrap",
    "title": "Bootstrap Confidence Interval Estimation for 'ETAS' Model\nParameters",
    "description": "The 2-D spatial and temporal Epidemic Type Aftershock Sequence ('ETAS') Model is\n widely used to 'decluster' earthquake data catalogs. Usually, the calculation of standard\n errors of the 'ETAS' model parameter estimates is based on the Hessian matrix derived from\n the log-likelihood function of the fitted model. However, when an 'ETAS' model is fitted to\n a local data set over a time period that is limited or short, the standard errors based on\n the Hessian matrix may be inaccurate. It follows that the asymptotic confidence intervals\n for parameters may not always be reliable. As an alternative, this package allows for the\n construction of bootstrap confidence intervals based on empirical quantiles for the parameters\n of the 2-D spatial and temporal 'ETAS' model. This version improves on Version 0.1.0 of the\n package by enabling the study space window (renamed 'study region') to be polygonal rather\n than merely rectangular. A Japan earthquake data catalog is used in a second example to\n illustrate this new feature.",
    "version": "0.2.1",
    "maintainer": "Renjie Peng <renjie.peng@mail.mcgill.ca>",
    "author": "Renjie Peng [aut, cre],\n  Pierre Dutilleul [aut] (ORCID: <https://orcid.org/0000-0002-2381-3421>),\n  Christian Genest [aut] (ORCID: <https://orcid.org/0000-0002-1764-0202>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ETASbootstrap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ETASbootstrap Bootstrap Confidence Interval Estimation for 'ETAS' Model\nParameters The 2-D spatial and temporal Epidemic Type Aftershock Sequence ('ETAS') Model is\n widely used to 'decluster' earthquake data catalogs. Usually, the calculation of standard\n errors of the 'ETAS' model parameter estimates is based on the Hessian matrix derived from\n the log-likelihood function of the fitted model. However, when an 'ETAS' model is fitted to\n a local data set over a time period that is limited or short, the standard errors based on\n the Hessian matrix may be inaccurate. It follows that the asymptotic confidence intervals\n for parameters may not always be reliable. As an alternative, this package allows for the\n construction of bootstrap confidence intervals based on empirical quantiles for the parameters\n of the 2-D spatial and temporal 'ETAS' model. This version improves on Version 0.1.0 of the\n package by enabling the study space window (renamed 'study region') to be polygonal rather\n than merely rectangular. A Japan earthquake data catalog is used in a second example to\n illustrate this new feature.  "
  },
  {
    "id": 3175,
    "package_name": "EWS",
    "title": "Early Warning System",
    "description": "The purpose of Early Warning Systems (EWS) is to detect accurately the occurrence of a crisis, which is represented by a binary variable which takes the value of one when the event occurs, and the value of zero otherwise. EWS are a toolbox for policymakers to prevent or attenuate the impact of economic downturns. Modern EWS are based on the econometric framework of Kauppi and Saikkonen (2008) <doi:10.1162/rest.90.4.777>. Specifically, this framework includes four dichotomous models, relying on a logit approach to model the relationship between yield spreads and future recessions, controlling for recession risk factors. These models can be estimated in a univariate or a balanced panel framework as in Candelon, Dumitrescu and Hurlin (2014) <doi:10.1016/j.ijforecast.2014.03.015>. This package provides both methods for estimating these models and a dataset covering 13 OECD countries over a period of 45 years. In addition, this package also provides methods for the analysis of the propagation mechanisms of an exogenous shock, as well as robust confidence intervals for these response functions using a block-bootstrap method as in Lajaunie (2021). This package constitutes a useful toolbox (data and functions) for scholars as well as policymakers.",
    "version": "0.2.0",
    "maintainer": "Quentin Lajaunie <quentin_lajaunie@hotmail.fr>",
    "author": "Jean-Baptiste Hasse [aut], Quentin Lajaunie [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EWS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EWS Early Warning System The purpose of Early Warning Systems (EWS) is to detect accurately the occurrence of a crisis, which is represented by a binary variable which takes the value of one when the event occurs, and the value of zero otherwise. EWS are a toolbox for policymakers to prevent or attenuate the impact of economic downturns. Modern EWS are based on the econometric framework of Kauppi and Saikkonen (2008) <doi:10.1162/rest.90.4.777>. Specifically, this framework includes four dichotomous models, relying on a logit approach to model the relationship between yield spreads and future recessions, controlling for recession risk factors. These models can be estimated in a univariate or a balanced panel framework as in Candelon, Dumitrescu and Hurlin (2014) <doi:10.1016/j.ijforecast.2014.03.015>. This package provides both methods for estimating these models and a dataset covering 13 OECD countries over a period of 45 years. In addition, this package also provides methods for the analysis of the propagation mechanisms of an exogenous shock, as well as robust confidence intervals for these response functions using a block-bootstrap method as in Lajaunie (2021). This package constitutes a useful toolbox (data and functions) for scholars as well as policymakers.  "
  },
  {
    "id": 3176,
    "package_name": "EWSmethods",
    "title": "Forecasting Tipping Points at the Community Level",
    "description": "Rolling and expanding window approaches to assessing abundance based early warning signals, non-equilibrium resilience measures, and machine learning. See Dakos et al. (2012) <doi:10.1371/journal.pone.0041010>, Deb et al. (2022) <doi:10.1098/rsos.211475>, Drake and Griffen (2010) <doi:10.1038/nature09389>, Ushio et al. (2018) <doi:10.1038/nature25504> and Weinans et al. (2021) <doi:10.1038/s41598-021-87839-y> for methodological details. Graphical presentation of the outputs are also provided for clear and publishable figures. Visit the 'EWSmethods' website for more information, and tutorials.",
    "version": "1.3.1",
    "maintainer": "Duncan O'Brien <duncan.a.obrien@gmail.com>",
    "author": "Duncan O'Brien [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-3420-5210>),\n  Smita Deb [aut] (ORCID: <https://orcid.org/0000-0001-7037-7055>),\n  Sahil Sidheekh [aut],\n  Narayanan Krishnan [aut],\n  Partha Dutta [aut] (ORCID: <https://orcid.org/0000-0001-6067-1023>),\n  Christopher Clements [aut] (ORCID:\n    <https://orcid.org/0000-0001-5677-5401>)",
    "url": "https://github.com/duncanobrien/EWSmethods,\nhttps://duncanobrien.github.io/EWSmethods/",
    "bug_reports": "https://github.com/duncanobrien/EWSmethods/issues",
    "repository": "https://cran.r-project.org/package=EWSmethods",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EWSmethods Forecasting Tipping Points at the Community Level Rolling and expanding window approaches to assessing abundance based early warning signals, non-equilibrium resilience measures, and machine learning. See Dakos et al. (2012) <doi:10.1371/journal.pone.0041010>, Deb et al. (2022) <doi:10.1098/rsos.211475>, Drake and Griffen (2010) <doi:10.1038/nature09389>, Ushio et al. (2018) <doi:10.1038/nature25504> and Weinans et al. (2021) <doi:10.1038/s41598-021-87839-y> for methodological details. Graphical presentation of the outputs are also provided for clear and publishable figures. Visit the 'EWSmethods' website for more information, and tutorials.  "
  },
  {
    "id": 3177,
    "package_name": "EXPAR",
    "title": "Fitting of Exponential Autoregressive (EXPAR) Model",
    "description": "The amplitude-dependent exponential autoregressive (EXPAR) time series model, initially proposed by Haggan and Ozaki (1981) <doi:10.2307/2335819> has been implemented in this package. Throughout various studies, the model has been found to adequately capture the cyclical nature of datasets. Parameter estimation of such family of models has been tackled by the approach of minimizing the residual sum of squares (RSS). Model selection among various candidate orders has been implemented using various information criteria, viz., Akaike information criteria (AIC), corrected Akaike information criteria (AICc) and Bayesian information criteria (BIC). An illustration utilizing data of egg price indices has also been provided.",
    "version": "0.1.0",
    "maintainer": "Saikath Das <saikathdas007@gmail.com>",
    "author": "Saikath Das [aut, cre],\n  Bishal Gurung [aut],\n  Achal Lama [aut],\n  KN Singh [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EXPAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EXPAR Fitting of Exponential Autoregressive (EXPAR) Model The amplitude-dependent exponential autoregressive (EXPAR) time series model, initially proposed by Haggan and Ozaki (1981) <doi:10.2307/2335819> has been implemented in this package. Throughout various studies, the model has been found to adequately capture the cyclical nature of datasets. Parameter estimation of such family of models has been tackled by the approach of minimizing the residual sum of squares (RSS). Model selection among various candidate orders has been implemented using various information criteria, viz., Akaike information criteria (AIC), corrected Akaike information criteria (AICc) and Bayesian information criteria (BIC). An illustration utilizing data of egg price indices has also been provided.  "
  },
  {
    "id": 3178,
    "package_name": "EXPARMA",
    "title": "Fitting of Exponential Autoregressive Moving Average (EXPARMA)\nModel",
    "description": "The amplitude-dependent autoregressive time series model (EXPAR) proposed by Haggan and Ozaki (1981) <doi:10.2307/2335819> was improved by incorporating the moving average (MA) framework for capturing the variability efficiently. Parameters of the EXPARMA model can be estimated using this package. The user is provided with the best fitted EXPARMA model for the data set under consideration.",
    "version": "0.1.0",
    "maintainer": "Bishal Gurung <Bishal.Gurung@icar.gov.in>",
    "author": "Bishal Gurung [aut, cre],\n  Saikat Das [aut],\n  Achal Lama [aut],\n  Kn Singh [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EXPARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EXPARMA Fitting of Exponential Autoregressive Moving Average (EXPARMA)\nModel The amplitude-dependent autoregressive time series model (EXPAR) proposed by Haggan and Ozaki (1981) <doi:10.2307/2335819> was improved by incorporating the moving average (MA) framework for capturing the variability efficiently. Parameters of the EXPARMA model can be estimated using this package. The user is provided with the best fitted EXPARMA model for the data set under consideration.  "
  },
  {
    "id": 3180,
    "package_name": "EZFragility",
    "title": "Compute Neural Fragility for Ictal iEEG Time Series",
    "description": "Provides tools to compute the neural fragility matrix from intracranial electrocorticographic (iEEG) recordings, enabling the analysis of brain dynamics during seizures. The package implements the method described by Li et al. (2017) <doi:10.23919/ACC.2017.7963378> and includes functions for data preprocessing ('Epoch'), fragility computation ('calcAdjFrag'), and visualization.",
    "version": "2.0.1",
    "maintainer": "Jiefei Wang <szwjf08@gmail.com>",
    "author": "Jiefei Wang [aut, cre] (ORCID: <https://orcid.org/0000-0002-2709-5332>),\n  Patrick Karas [aut],\n  Anne-Cecile Lesage [aut] (ORCID:\n    <https://orcid.org/0000-0002-9528-4899>),\n  Ioannis Malagaris [aut] (ORCID:\n    <https://orcid.org/0000-0001-5126-2068>),\n  Oliver Zhou [aut],\n  Liliana Camarillo Rodriguez [aut] (ORCID:\n    <https://orcid.org/0000-0001-8288-6885>),\n  Sean O'Leary [aut] (ORCID: <https://orcid.org/0000-0003-3650-705X>),\n  Yuanyi Zhang [aut]",
    "url": "https://github.com/Jiefei-Wang/EZFragility",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EZFragility",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EZFragility Compute Neural Fragility for Ictal iEEG Time Series Provides tools to compute the neural fragility matrix from intracranial electrocorticographic (iEEG) recordings, enabling the analysis of brain dynamics during seizures. The package implements the method described by Li et al. (2017) <doi:10.23919/ACC.2017.7963378> and includes functions for data preprocessing ('Epoch'), fragility computation ('calcAdjFrag'), and visualization.  "
  },
  {
    "id": 3198,
    "package_name": "EconCausal",
    "title": "Causal Analysis for Macroeconomic Time Series (ECM-MARS, BSTS,\nBayesian GLM-AR(1))",
    "description": "Implements three complementary pipelines for causal analysis on macroeconomic time series:\n    (1) Error-Correction Models with Multivariate Adaptive Regression Splines (ECM-MARS),\n    (2) Bayesian Structural Time Series (BSTS), and \n    (3) Bayesian GLM with AR(1) errors validated with Leave-Future-Out (LFO). \n    Heavy backends (Stan) are optional and never used in examples or tests.",
    "version": "1.0.2",
    "maintainer": "Jos\u00e9 Mauricio G\u00f3mez Juli\u00e1n <isadore.nabi@pm.me>",
    "author": "Jos\u00e9 Mauricio G\u00f3mez Juli\u00e1n [aut, cre]",
    "url": "https://github.com/IsadoreNabi/EconCausal",
    "bug_reports": "https://github.com/IsadoreNabi/EconCausal/issues",
    "repository": "https://cran.r-project.org/package=EconCausal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EconCausal Causal Analysis for Macroeconomic Time Series (ECM-MARS, BSTS,\nBayesian GLM-AR(1)) Implements three complementary pipelines for causal analysis on macroeconomic time series:\n    (1) Error-Correction Models with Multivariate Adaptive Regression Splines (ECM-MARS),\n    (2) Bayesian Structural Time Series (BSTS), and \n    (3) Bayesian GLM with AR(1) errors validated with Leave-Future-Out (LFO). \n    Heavy backends (Stan) are optional and never used in examples or tests.  "
  },
  {
    "id": 3201,
    "package_name": "EcotoneFinder",
    "title": "Characterising and Locating Ecotones and Communities",
    "description": "Analytical methods to locate and characterise ecotones, ecosystems and environmental patchiness along ecological gradients. Methods are implemented for isolated sampling or for space/time series. It includes Detrended Correspondence Analysis (Hill & Gauch (1980) <doi:10.1007/BF00048870>), fuzzy clustering (De C\u00e1ceres et al. (2010) <doi:10.1080/01621459.1963.10500845>), biodiversity indices (Jost (2006) <doi:10.1111/j.2006.0030-1299.14714.x>), and network analyses (Epskamp et al. (2012) <doi:10.18637/jss.v048.i04>) - as well as tools to explore the number of clusters in the data. Functions to produce synthetic ecological datasets are also provided.",
    "version": "0.2.3",
    "maintainer": "Antoine Bagnaro <antoine.bagnaro@wanadoo.fr>",
    "author": "Antoine Bagnaro",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EcotoneFinder",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EcotoneFinder Characterising and Locating Ecotones and Communities Analytical methods to locate and characterise ecotones, ecosystems and environmental patchiness along ecological gradients. Methods are implemented for isolated sampling or for space/time series. It includes Detrended Correspondence Analysis (Hill & Gauch (1980) <doi:10.1007/BF00048870>), fuzzy clustering (De C\u00e1ceres et al. (2010) <doi:10.1080/01621459.1963.10500845>), biodiversity indices (Jost (2006) <doi:10.1111/j.2006.0030-1299.14714.x>), and network analyses (Epskamp et al. (2012) <doi:10.18637/jss.v048.i04>) - as well as tools to explore the number of clusters in the data. Functions to produce synthetic ecological datasets are also provided.  "
  },
  {
    "id": 3217,
    "package_name": "EloRating",
    "title": "Animal Dominance Hierarchies by Elo Rating",
    "description": "Provides functions to quantify animal dominance hierarchies. The major focus is on Elo rating and its ability to deal with temporal dynamics in dominance interaction sequences. For static data, David's score and de Vries' I&SI are also implemented. In addition, the package provides functions to assess transitivity, linearity and stability of dominance networks. See Neumann et al (2011) <doi:10.1016/j.anbehav.2011.07.016> for an introduction.",
    "version": "0.46.18",
    "maintainer": "Christof Neumann <christofneumann1@gmail.com>",
    "author": "Christof Neumann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0236-1219>),\n  Lars Kulik [aut]",
    "url": "https://github.com/gobbios/EloRating",
    "bug_reports": "https://github.com/gobbios/EloRating/issues",
    "repository": "https://cran.r-project.org/package=EloRating",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EloRating Animal Dominance Hierarchies by Elo Rating Provides functions to quantify animal dominance hierarchies. The major focus is on Elo rating and its ability to deal with temporal dynamics in dominance interaction sequences. For static data, David's score and de Vries' I&SI are also implemented. In addition, the package provides functions to assess transitivity, linearity and stability of dominance networks. See Neumann et al (2011) <doi:10.1016/j.anbehav.2011.07.016> for an introduction.  "
  },
  {
    "id": 3223,
    "package_name": "EncompassTest",
    "title": "Direct Multi-Step Forecast Based Comparison of Nested Models via\nan Encompassing Test",
    "description": "The encompassing test is developed based on multi-step-ahead predictions of two nested models as in Pitarakis, J. (2023) <doi:10.48550/arXiv.2312.16099>. The statistics are standardised to a normal distribution, and the null hypothesis is that the larger model contains no additional useful information. P-values will be provided in the output.",
    "version": "0.22",
    "maintainer": "Rong Peng <r.peng@soton.ac.uk>",
    "author": "Rong Peng [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EncompassTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EncompassTest Direct Multi-Step Forecast Based Comparison of Nested Models via\nan Encompassing Test The encompassing test is developed based on multi-step-ahead predictions of two nested models as in Pitarakis, J. (2023) <doi:10.48550/arXiv.2312.16099>. The statistics are standardised to a normal distribution, and the null hypothesis is that the larger model contains no additional useful information. P-values will be provided in the output.  "
  },
  {
    "id": 3224,
    "package_name": "EnergyOnlineCPM",
    "title": "Distribution Free Multivariate Control Chart Based on Energy\nTest",
    "description": "Provides a function for distribution free control chart based on the change point model, for multivariate statistical process control. The main constituent of the chart is the energy test that focuses on the discrepancy between empirical characteristic functions of two random vectors. This new control chart highlights in three aspects. Firstly, it is distribution free, requiring no knowledge of the random processes. Secondly, this control chart can monitor mean and variance simultaneously. Thirdly it is devised for multivariate time series which is more practical in real data application. Fourthly, it is designed for online detection (Phase II), which is central for real time surveillance of stream data. For more information please refer to O. Okhrin and Y.F. Xu (2017) <https://github.com/YafeiXu/working_paper/raw/master/CPM102.pdf>.",
    "version": "1.0",
    "maintainer": "Yafei Xu <yafei.xu@hotmail.de>",
    "author": "Yafei Xu",
    "url": "https://sites.google.com/site/EnergyOnlineCPM/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EnergyOnlineCPM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EnergyOnlineCPM Distribution Free Multivariate Control Chart Based on Energy\nTest Provides a function for distribution free control chart based on the change point model, for multivariate statistical process control. The main constituent of the chart is the energy test that focuses on the discrepancy between empirical characteristic functions of two random vectors. This new control chart highlights in three aspects. Firstly, it is distribution free, requiring no knowledge of the random processes. Secondly, this control chart can monitor mean and variance simultaneously. Thirdly it is devised for multivariate time series which is more practical in real data application. Fourthly, it is designed for online detection (Phase II), which is central for real time surveillance of stream data. For more information please refer to O. Okhrin and Y.F. Xu (2017) <https://github.com/YafeiXu/working_paper/raw/master/CPM102.pdf>.  "
  },
  {
    "id": 3243,
    "package_name": "EpiInvert",
    "title": "Variational Techniques in Epidemiology",
    "description": "Using variational techniques we address some epidemiological\n  problems as the incidence curve decomposition by inverting the renewal \n  equation as described in Alvarez et al. (2021) <doi:10.1073/pnas.2105112118> \n  and Alvarez et al. (2022) <doi:10.3390/biology11040540> or the estimation of \n  the functional relationship between epidemiological indicators. We also \n  propose a learning method for the short time forecast of the trend \n  incidence curve  as described in \n  Morel et al. (2022) <doi:10.1101/2022.11.05.22281904>.",
    "version": "0.3.1",
    "maintainer": "Luis Alvarez <lalvarez@ulpgc.es>",
    "author": "Luis Alvarez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6953-9587>),\n  Jean-David Morel [ctb] (ORCID: <https://orcid.org/0000-0002-7122-9924>),\n  Jean-Michel Morel [ctb] (ORCID:\n    <https://orcid.org/0000-0002-6108-897X>)",
    "url": "https://github.com/lalvarezmat/EpiInvert",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EpiInvert",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EpiInvert Variational Techniques in Epidemiology Using variational techniques we address some epidemiological\n  problems as the incidence curve decomposition by inverting the renewal \n  equation as described in Alvarez et al. (2021) <doi:10.1073/pnas.2105112118> \n  and Alvarez et al. (2022) <doi:10.3390/biology11040540> or the estimation of \n  the functional relationship between epidemiological indicators. We also \n  propose a learning method for the short time forecast of the trend \n  incidence curve  as described in \n  Morel et al. (2022) <doi:10.1101/2022.11.05.22281904>.  "
  },
  {
    "id": 3247,
    "package_name": "EpiReport",
    "title": "Epidemiological Report",
    "description": "Drafting an epidemiological report in 'Microsoft Word' format for a given disease,\n  similar to the Annual Epidemiological Reports published by the European Centre \n  for Disease Prevention and Control. Through standalone functions, it is specifically \n  designed to generate each disease specific output presented in these reports and includes:\n  - Table with the distribution of cases by Member State over the last five years;\n  - Seasonality plot with the distribution of cases at the European Union / European Economic Area level, \n  by month, over the past five years;\n  - Trend plot with the trend and number of cases at the European Union / European Economic Area level, \n  by month, over the past five years;\n  - Age and gender bar graph with the distribution of cases at the European Union / European Economic Area level.\n  Two types of datasets can be used:\n  - The default dataset of dengue 2015-2019 data;\n  - Any dataset specified as described in the vignette.",
    "version": "1.0.4",
    "maintainer": "Lore Merdrignac <l.merdrignac@epiconcept.fr>",
    "author": "Lore Merdrignac [aut, ctr, cre] (Author of the package and original\n    code),\n  Tommi Karki [aut, fnd],\n  Esther Kissling [aut, ctr],\n  Joana Gomes Dias [aut, fnd] (Project manager)",
    "url": "https://www.ecdc.europa.eu/en/publications-data/monitoring/all-annual-epidemiological-reports\nhttps://epiconcept-paris.github.io/EpiReport/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EpiReport",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EpiReport Epidemiological Report Drafting an epidemiological report in 'Microsoft Word' format for a given disease,\n  similar to the Annual Epidemiological Reports published by the European Centre \n  for Disease Prevention and Control. Through standalone functions, it is specifically \n  designed to generate each disease specific output presented in these reports and includes:\n  - Table with the distribution of cases by Member State over the last five years;\n  - Seasonality plot with the distribution of cases at the European Union / European Economic Area level, \n  by month, over the past five years;\n  - Trend plot with the trend and number of cases at the European Union / European Economic Area level, \n  by month, over the past five years;\n  - Age and gender bar graph with the distribution of cases at the European Union / European Economic Area level.\n  Two types of datasets can be used:\n  - The default dataset of dengue 2015-2019 data;\n  - Any dataset specified as described in the vignette.  "
  },
  {
    "id": 3249,
    "package_name": "EpiSignalDetection",
    "title": "Signal Detection Analysis",
    "description": "Exploring time series for signal detection. It is specifically designed\n    to detect possible outbreaks using infectious disease surveillance data\n    at the European Union / European Economic Area or country level.\n    Automatic detection tools used are presented in the paper\n    \"Monitoring count time series in R: aberration detection in public health surveillance\",\n    by Salmon (2016) <doi:10.18637/jss.v070.i10>.\n    The package includes:\n    - Signal Detection tool, an interactive 'shiny' application\n      in which the user can import external data and perform basic signal detection analyses;\n    - An automated report in HTML format, presenting the results of the time series analysis in tables and graphs.\n      This report can also be stratified by population characteristics (see 'Population' variable).\n    This project was funded by the European Centre for Disease Prevention and Control.",
    "version": "0.1.2",
    "maintainer": "Lore Merdrignac <l.merdrignac@epiconcept.fr>",
    "author": "Lore Merdrignac [aut, ctr, cre] (Author of the package and original\n    code),\n  Joana Gomes Dias [aut, fnd] (Project manager),\n  Esther Kissling [aut, ctr],\n  Tommi Karki [aut, fnd],\n  Margot Einoder-Moreno [ctb, fnd]",
    "url": "https://github.com/EU-ECDC/EpiSignalDetection",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EpiSignalDetection",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EpiSignalDetection Signal Detection Analysis Exploring time series for signal detection. It is specifically designed\n    to detect possible outbreaks using infectious disease surveillance data\n    at the European Union / European Economic Area or country level.\n    Automatic detection tools used are presented in the paper\n    \"Monitoring count time series in R: aberration detection in public health surveillance\",\n    by Salmon (2016) <doi:10.18637/jss.v070.i10>.\n    The package includes:\n    - Signal Detection tool, an interactive 'shiny' application\n      in which the user can import external data and perform basic signal detection analyses;\n    - An automated report in HTML format, presenting the results of the time series analysis in tables and graphs.\n      This report can also be stratified by population characteristics (see 'Population' variable).\n    This project was funded by the European Centre for Disease Prevention and Control.  "
  },
  {
    "id": 3261,
    "package_name": "EstemPMM",
    "title": "Polynomial Maximization Method for Non-Gaussian Regression",
    "description": "\n    Implements the Polynomial Maximization Method ('PMM') for parameter estimation\n    in linear and time series models when error distributions deviate from normality.\n    The 'PMM2' variant achieves lower variance parameter estimates compared to ordinary\n    least squares ('OLS') when errors exhibit significant skewness. Includes methods\n    for linear regression, 'AR'/'MA'/'ARMA'/'ARIMA' models, and bootstrap inference.\n    Methodology described in Zabolotnii, Warsza, and Tkachenko (2018) <doi:10.1007/978-3-319-77179-3_75>,\n    Zabolotnii, Tkachenko, and Warsza (2022) <doi:10.1007/978-3-031-03502-9_37>, and\n    Zabolotnii, Tkachenko, and Warsza (2023) <doi:10.1007/978-3-031-25844-2_21>.",
    "version": "0.1.1",
    "maintainer": "Serhii Zabolotnii <zabolotniua@gmail.com>",
    "author": "Serhii Zabolotnii [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0242-2234>)",
    "url": "https://github.com/SZabolotnii/EstemPMM",
    "bug_reports": "https://github.com/SZabolotnii/EstemPMM/issues",
    "repository": "https://cran.r-project.org/package=EstemPMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EstemPMM Polynomial Maximization Method for Non-Gaussian Regression \n    Implements the Polynomial Maximization Method ('PMM') for parameter estimation\n    in linear and time series models when error distributions deviate from normality.\n    The 'PMM2' variant achieves lower variance parameter estimates compared to ordinary\n    least squares ('OLS') when errors exhibit significant skewness. Includes methods\n    for linear regression, 'AR'/'MA'/'ARMA'/'ARIMA' models, and bootstrap inference.\n    Methodology described in Zabolotnii, Warsza, and Tkachenko (2018) <doi:10.1007/978-3-319-77179-3_75>,\n    Zabolotnii, Tkachenko, and Warsza (2022) <doi:10.1007/978-3-031-03502-9_37>, and\n    Zabolotnii, Tkachenko, and Warsza (2023) <doi:10.1007/978-3-031-25844-2_21>.  "
  },
  {
    "id": 3276,
    "package_name": "EventDetectR",
    "title": "Event Detection Framework",
    "description": "Detect events in time-series data. Combines multiple well-known R packages like 'forecast' and 'neuralnet' to deliver an easily configurable tool for multivariate event detection.",
    "version": "0.3.5",
    "maintainer": "Sowmya Chandrasekaran <sowzz.17@gmail.com>",
    "author": "Margarita Rebolledo [aut],\n  Sowmya Chandrasekaran [aut, cre],\n  Frederik Rehbach [aut],\n  Steffen Moritz [aut] (ORCID: <https://orcid.org/0000-0002-0085-1804>)",
    "url": "https://github.com/frehbach/EventDetectR",
    "bug_reports": "https://github.com/frehbach/EventDetectR/issues",
    "repository": "https://cran.r-project.org/package=EventDetectR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EventDetectR Event Detection Framework Detect events in time-series data. Combines multiple well-known R packages like 'forecast' and 'neuralnet' to deliver an easily configurable tool for multivariate event detection.  "
  },
  {
    "id": 3319,
    "package_name": "ExtremeRisks",
    "title": "Extreme Risk Measures",
    "description": "A set of procedures for estimating risks related to extreme events via risk measures such as Expectile, Value-at-Risk, etc. is provided. Estimation methods for univariate independent observations and temporal dependent observations are available. The methodology is extended to the case of independent multidimensional observations.  The statistical inference is performed through parametric and non-parametric estimators. Inferential procedures such as confidence intervals, confidence regions and hypothesis testing are obtained by exploiting the asymptotic theory. Adapts the methodologies derived in Padoan and Stupfler (2022) <doi:10.3150/21-BEJ1375>, Davison et al. (2023) <doi:10.1080/07350015.2022.2078332>, Daouia et al. (2018) <doi:10.1111/rssb.12254>, Drees (2000) <doi:10.1214/aoap/1019487617>, Drees (2003) <doi:10.3150/bj/1066223272>, de Haan and Ferreira (2006) <doi:10.1007/0-387-34471-3>, de Haan et al. (2016) <doi:10.1007/s00780-015-0287-6>, Padoan and Rizzelli (2024) <doi:10.3150/23-BEJ1668>, Daouia et al. (2024) <doi:10.3150/23-BEJ1632>.",
    "version": "0.0.5",
    "maintainer": "Simone Padoan <simone.padoan@unibocconi.it>",
    "author": "Simone Padoan [cre, aut],\n  Gilles Stupfler [aut],\n  Carlotta Pacifici [aut]",
    "url": "https://faculty.unibocconi.it/simonepadoan/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ExtremeRisks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ExtremeRisks Extreme Risk Measures A set of procedures for estimating risks related to extreme events via risk measures such as Expectile, Value-at-Risk, etc. is provided. Estimation methods for univariate independent observations and temporal dependent observations are available. The methodology is extended to the case of independent multidimensional observations.  The statistical inference is performed through parametric and non-parametric estimators. Inferential procedures such as confidence intervals, confidence regions and hypothesis testing are obtained by exploiting the asymptotic theory. Adapts the methodologies derived in Padoan and Stupfler (2022) <doi:10.3150/21-BEJ1375>, Davison et al. (2023) <doi:10.1080/07350015.2022.2078332>, Daouia et al. (2018) <doi:10.1111/rssb.12254>, Drees (2000) <doi:10.1214/aoap/1019487617>, Drees (2003) <doi:10.3150/bj/1066223272>, de Haan and Ferreira (2006) <doi:10.1007/0-387-34471-3>, de Haan et al. (2016) <doi:10.1007/s00780-015-0287-6>, Padoan and Rizzelli (2024) <doi:10.3150/23-BEJ1668>, Daouia et al. (2024) <doi:10.3150/23-BEJ1632>.  "
  },
  {
    "id": 3331,
    "package_name": "FARS",
    "title": "Factor-Augmented Regression Scenarios",
    "description": "Provides a comprehensive framework in R for modeling and forecasting economic scenarios based on multi-level dynamic factor model. The package enables users to: (i) extract global and group-specific factors using a flexible multi-level factor structure; (ii) compute asymptotically valid confidence regions for the estimated factors, accounting for uncertainty in the factor loadings; (iii) obtain estimates of the parameters of the factor-augmented quantile regressions together with their standard deviations; (iv) recover full predictive conditional densities from estimated quantiles; (v) obtain risk measures based on extreme quantiles of the conditional densities; (vi) estimate the conditional density and the corresponding extreme quantiles when the factors are stressed.",
    "version": "0.7.1",
    "maintainer": "Gian Pietro Bellocca <gbellocc@est-econ.uc3m.es>",
    "author": "Gian Pietro Bellocca [aut, cre],\n  Ignacio Garr\u00f3n [aut],\n  Vladimir Rodr\u00edguez-Caballero [aut],\n  Esther Ruiz [aut]",
    "url": "https://arxiv.org/abs/2507.10679",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FARS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FARS Factor-Augmented Regression Scenarios Provides a comprehensive framework in R for modeling and forecasting economic scenarios based on multi-level dynamic factor model. The package enables users to: (i) extract global and group-specific factors using a flexible multi-level factor structure; (ii) compute asymptotically valid confidence regions for the estimated factors, accounting for uncertainty in the factor loadings; (iii) obtain estimates of the parameters of the factor-augmented quantile regressions together with their standard deviations; (iv) recover full predictive conditional densities from estimated quantiles; (v) obtain risk measures based on extreme quantiles of the conditional densities; (vi) estimate the conditional density and the corresponding extreme quantiles when the factors are stressed.  "
  },
  {
    "id": 3334,
    "package_name": "FASeg",
    "title": "Joint Segmentation of Correlated Time Series",
    "description": "It contains a function designed to the joint segmentation in the mean of several correlated series. The method is described in the paper X. Collilieux, E. Lebarbier and S. Robin. A factor model approach for the joint segmentation with between-series correlation (2015) <arXiv:1505.05660>.",
    "version": "0.1.9",
    "maintainer": "Emilie Lebarbier <emilie.lebarbier@agroparistech.fr>",
    "author": "Xavier Collilieux, Emilie Lebarbier and Stephane Robin",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FASeg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FASeg Joint Segmentation of Correlated Time Series It contains a function designed to the joint segmentation in the mean of several correlated series. The method is described in the paper X. Collilieux, E. Lebarbier and S. Robin. A factor model approach for the joint segmentation with between-series correlation (2015) <arXiv:1505.05660>.  "
  },
  {
    "id": 3346,
    "package_name": "FCUSUM",
    "title": "Fourier CUSUM Cointegration Test",
    "description": "Implements the Fourier cumulative sum (CUSUM) cointegration test \n    for detecting cointegration relationships in time series data with \n    structural breaks. The test uses Fourier approximations to capture smooth \n    structural changes and CUSUM statistics to test for cointegration stability.\n    Based on methodology described in Zaghdoudi (2025) \n    <doi:10.46557/001c.144076>. The corrected Akaike Information Criterion \n    (AICc) is used for optimal frequency selection.",
    "version": "1.0.0",
    "maintainer": "Taha Zaghdoudi <zedtaha@gmail.com>",
    "author": "Taha Zaghdoudi [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FCUSUM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FCUSUM Fourier CUSUM Cointegration Test Implements the Fourier cumulative sum (CUSUM) cointegration test \n    for detecting cointegration relationships in time series data with \n    structural breaks. The test uses Fourier approximations to capture smooth \n    structural changes and CUSUM statistics to test for cointegration stability.\n    Based on methodology described in Zaghdoudi (2025) \n    <doi:10.46557/001c.144076>. The corrected Akaike Information Criterion \n    (AICc) is used for optimal frequency selection.  "
  },
  {
    "id": 3358,
    "package_name": "FESta",
    "title": "Fishing Effort Standardisation",
    "description": "Original idea was presented in the reference paper. Varghese et al. (2020, 74(1):35-42) \"Bayesian State-space Implementation of Schaefer Production Model for Assessment of Stock Status for Multi-gear Fishery\". Marine fisheries governance and management practices are very essential to ensure the sustainability of the marine resources. A widely accepted resource management strategy towards this is to derive sustainable fish harvest levels based on the status of marine fish stock. Various fish stock assessment models that describe the biomass dynamics using time series data on fish catch and fishing effort are generally used for this purpose. In the scenario of complex multi-species marine fishery in which different species are caught by a number of fishing gears and each gear harvests a number of species make it difficult to obtain the fishing effort corresponding to each fish species. Since the capacity of the gears varies, the effort made to catch a resource cannot be considered as the sum of efforts expended by different fishing gears. This necessitates standardisation of fishing effort in unit base.",
    "version": "1.0.0",
    "maintainer": "Eldho Varghese <eldhoiasri@gmail.com>",
    "author": "Eldho Varghese [aut, cre],\n  Sathianandan T V [aut],\n  Jayasankar J [aut],\n  Reshma Gills [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FESta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FESta Fishing Effort Standardisation Original idea was presented in the reference paper. Varghese et al. (2020, 74(1):35-42) \"Bayesian State-space Implementation of Schaefer Production Model for Assessment of Stock Status for Multi-gear Fishery\". Marine fisheries governance and management practices are very essential to ensure the sustainability of the marine resources. A widely accepted resource management strategy towards this is to derive sustainable fish harvest levels based on the status of marine fish stock. Various fish stock assessment models that describe the biomass dynamics using time series data on fish catch and fishing effort are generally used for this purpose. In the scenario of complex multi-species marine fishery in which different species are caught by a number of fishing gears and each gear harvests a number of species make it difficult to obtain the fishing effort corresponding to each fish species. Since the capacity of the gears varies, the effort made to catch a resource cannot be considered as the sum of efforts expended by different fishing gears. This necessitates standardisation of fishing effort in unit base.  "
  },
  {
    "id": 3361,
    "package_name": "FFdownload",
    "title": "Download Data from Kenneth French's Website",
    "description": "Downloads all the datasets (you can exclude the daily ones or specify a list of those you are targeting specifically) from Kenneth French's Website at <https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html>, process them and convert them to list of 'xts' (time series).",
    "version": "1.1.1",
    "maintainer": "Sebastian Stoeckl <sebastian.stoeckl@uni.li>",
    "author": "Sebastian Stoeckl [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4196-6093>, Package commissioner and\n    maintainer.),\n  Annar Massimov [ctb] (Original developer of FFdownload.)",
    "url": "https://github.com/sstoeckl/ffdownload,\nhttps://sstoeckl.github.io/ffdownload/",
    "bug_reports": "https://github.com/sstoeckl/ffdownload/issues",
    "repository": "https://cran.r-project.org/package=FFdownload",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FFdownload Download Data from Kenneth French's Website Downloads all the datasets (you can exclude the daily ones or specify a list of those you are targeting specifically) from Kenneth French's Website at <https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html>, process them and convert them to list of 'xts' (time series).  "
  },
  {
    "id": 3384,
    "package_name": "FLightR",
    "title": "Reconstruct Animal Paths from Solar Geolocation Loggers Data",
    "description": "Spatio-temporal locations of an animal are computed \n    from annotated data with a hidden Markov  model via particle\n    filter algorithm. The package is relatively robust to varying\n    degrees of shading.\n    The hidden Markov model is described in Movement Ecology - Rakhimberdiev et al. (2015) <doi:10.1186/s40462-015-0062-5>,\n    general package description is in the Methods in Ecology and Evolution - Rakhimberdiev et al. (2017) <doi:10.1111/2041-210X.12765>\n    and package accuracy assessed in the Journal of Avian Biology - Rakhimberdiev et al. (2016) <doi:10.1111/jav.00891>.",
    "version": "0.5.5",
    "maintainer": "Eldar Rakhimberdiev <eldar.rakhimberdiev@uva.nl>",
    "author": "Eldar Rakhimberdiev [aut, cre],\n  Anatoly Saveliev [aut],\n  Julia Karagicheva [aut],\n  Simeon Lisovski [ctb],\n  Johannes de Groeve [ctb]",
    "url": "https://CRAN.R-project.org/package=FLightR",
    "bug_reports": "https://github.com/eldarrak/FLightR/issues",
    "repository": "https://cran.r-project.org/package=FLightR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FLightR Reconstruct Animal Paths from Solar Geolocation Loggers Data Spatio-temporal locations of an animal are computed \n    from annotated data with a hidden Markov  model via particle\n    filter algorithm. The package is relatively robust to varying\n    degrees of shading.\n    The hidden Markov model is described in Movement Ecology - Rakhimberdiev et al. (2015) <doi:10.1186/s40462-015-0062-5>,\n    general package description is in the Methods in Ecology and Evolution - Rakhimberdiev et al. (2017) <doi:10.1111/2041-210X.12765>\n    and package accuracy assessed in the Journal of Avian Biology - Rakhimberdiev et al. (2016) <doi:10.1111/jav.00891>.  "
  },
  {
    "id": 3410,
    "package_name": "FRK",
    "title": "Fixed Rank Kriging",
    "description": "A tool for spatial/spatio-temporal modelling and prediction with large datasets. The approach models the field, and hence the covariance function, using a set of basis functions. This fixed-rank basis-function representation facilitates the modelling of big data, and the method naturally allows for non-stationary, anisotropic covariance functions. Discretisation of the spatial domain into so-called basic areal units (BAUs) facilitates the use of observations with varying support (i.e., both point-referenced and areal supports, potentially simultaneously), and prediction over arbitrary user-specified regions. `FRK` also supports inference over various manifolds, including the 2D plane and 3D sphere, and it provides helper functions to model, fit, predict, and plot with relative ease. Version 2.0.0 and above also supports the modelling of non-Gaussian data (e.g., Poisson, binomial, negative-binomial, gamma, and inverse-Gaussian) by employing a generalised linear mixed model (GLMM) framework. Zammit-Mangion and Cressie <doi:10.18637/jss.v098.i04> describe `FRK` in a Gaussian setting, and detail its use of basis functions and BAUs, while Sainsbury-Dale, Zammit-Mangion, and Cressie <doi:10.18637/jss.v108.i10> describe `FRK` in a non-Gaussian setting; two vignettes are available that summarise these papers and provide additional examples.",
    "version": "2.3.1",
    "maintainer": "Andrew Zammit-Mangion <andrewzm@gmail.com>",
    "author": "Andrew Zammit-Mangion [aut, cre],\n  Matthew Sainsbury-Dale [aut]",
    "url": "https://andrewzm.github.io/FRK/, https://github.com/andrewzm/FRK/",
    "bug_reports": "https://github.com/andrewzm/FRK/issues/",
    "repository": "https://cran.r-project.org/package=FRK",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FRK Fixed Rank Kriging A tool for spatial/spatio-temporal modelling and prediction with large datasets. The approach models the field, and hence the covariance function, using a set of basis functions. This fixed-rank basis-function representation facilitates the modelling of big data, and the method naturally allows for non-stationary, anisotropic covariance functions. Discretisation of the spatial domain into so-called basic areal units (BAUs) facilitates the use of observations with varying support (i.e., both point-referenced and areal supports, potentially simultaneously), and prediction over arbitrary user-specified regions. `FRK` also supports inference over various manifolds, including the 2D plane and 3D sphere, and it provides helper functions to model, fit, predict, and plot with relative ease. Version 2.0.0 and above also supports the modelling of non-Gaussian data (e.g., Poisson, binomial, negative-binomial, gamma, and inverse-Gaussian) by employing a generalised linear mixed model (GLMM) framework. Zammit-Mangion and Cressie <doi:10.18637/jss.v098.i04> describe `FRK` in a Gaussian setting, and detail its use of basis functions and BAUs, while Sainsbury-Dale, Zammit-Mangion, and Cressie <doi:10.18637/jss.v108.i10> describe `FRK` in a non-Gaussian setting; two vignettes are available that summarise these papers and provide additional examples.  "
  },
  {
    "id": 3422,
    "package_name": "FTSgof",
    "title": "White Noise and Goodness-of-Fit Tests for Functional Time Series",
    "description": "It offers comprehensive tools for the analysis of functional\n    time series data, focusing on white noise hypothesis testing and\n    goodness-of-fit evaluations, alongside functions for\n    simulating data and advanced visualization techniques, such as 3D\n    rainbow plots. These methods are described in Kokoszka, Rice, and Shang (2017)  <doi:10.1016/j.jmva.2017.08.004>, \n    Yeh, Rice, and Dubin (2023) <doi:10.1214/23-EJS2112>, Kim, Kokoszka, and Rice (2023) <doi:10.1214/23-ss143>, and \n    Rice, Wirjanto, and Zhao (2020) <doi:10.1111/jtsa.12532>.",
    "version": "1.0.0",
    "maintainer": "Mihyun Kim <mihyun.kim@mail.wvu.edu>",
    "author": "Mihyun Kim [aut, cre],\n  Chi-Kuang Yeh [aut] (ORCID: <https://orcid.org/0000-0001-7057-2096>),\n  Yuqian Zhao [aut],\n  Gregory Rice [ctb]",
    "url": "https://github.com/veritasmih/FTSgof",
    "bug_reports": "https://github.com/veritasmih/FTSgof/issues",
    "repository": "https://cran.r-project.org/package=FTSgof",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FTSgof White Noise and Goodness-of-Fit Tests for Functional Time Series It offers comprehensive tools for the analysis of functional\n    time series data, focusing on white noise hypothesis testing and\n    goodness-of-fit evaluations, alongside functions for\n    simulating data and advanced visualization techniques, such as 3D\n    rainbow plots. These methods are described in Kokoszka, Rice, and Shang (2017)  <doi:10.1016/j.jmva.2017.08.004>, \n    Yeh, Rice, and Dubin (2023) <doi:10.1214/23-EJS2112>, Kim, Kokoszka, and Rice (2023) <doi:10.1214/23-ss143>, and \n    Rice, Wirjanto, and Zhao (2020) <doi:10.1111/jtsa.12532>.  "
  },
  {
    "id": 3476,
    "package_name": "FinCal",
    "title": "Time Value of Money, Time Series Analysis and Computational\nFinance",
    "description": "Package for time value of money calculation, time series analysis and computational finance.",
    "version": "0.6.3",
    "maintainer": "Felix Yanhui Fan <nolanfyh@gmail.com>",
    "author": "Felix Yanhui Fan <nolanfyh@gmail.com>",
    "url": "http://felixfan.github.io/FinCal/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FinCal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FinCal Time Value of Money, Time Series Analysis and Computational\nFinance Package for time value of money calculation, time series analysis and computational finance.  "
  },
  {
    "id": 3479,
    "package_name": "FinTS",
    "title": "Companion to Tsay (2005) Analysis of Financial Time Series",
    "description": "R companion to Tsay (2005) Analysis of Financial Time\n   Series, second edition (Wiley).  Includes data sets, functions and\n   script files required to work some of the examples.  Version 0.3-x\n   includes R objects for all data files used in the text and script\n   files to recreate most of the analyses in chapters 1-3 and 9 plus\n   parts of chapters 4 and 11.",
    "version": "0.4-9",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Spencer Graves [aut],\n  Georgi N. Boshnakov [cre, ctb]",
    "url": "https://geobosh.github.io/FinTSDoc/ (doc),\nhttps://r-forge.r-project.org/projects/fints/ (devel)",
    "bug_reports": "https://r-forge.r-project.org/tracker/?group_id=84&atid=380",
    "repository": "https://cran.r-project.org/package=FinTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FinTS Companion to Tsay (2005) Analysis of Financial Time Series R companion to Tsay (2005) Analysis of Financial Time\n   Series, second edition (Wiley).  Includes data sets, functions and\n   script files required to work some of the examples.  Version 0.3-x\n   includes R objects for all data files used in the text and script\n   files to recreate most of the analyses in chapters 1-3 and 9 plus\n   parts of chapters 4 and 11.  "
  },
  {
    "id": 3503,
    "package_name": "FlowScreen",
    "title": "Daily Streamflow Trend and Change Point Screening",
    "description": "Screens daily streamflow time series for temporal trends and\n    change-points. This package has been primarily developed for assessing the\n    quality of daily streamflow time series. It also contains tools for plotting\n    and calculating many different streamflow metrics. The package can be used to\n    produce summary screening plots showing change-points and significant temporal\n    trends for high flow, low flow, and/or baseflow statistics, or it can be used\n    to perform more detailed hydrological time series analyses. The package was\n    designed for screening daily streamflow time series from Water Survey Canada\n    and the United States Geological Survey but will also work with streamflow time\n    series from many other agencies.  \n    Package update to version 2.0 made updates to read.flows function to allow \n    loading of GRDC and ROBIN streamflow record formats.\n    This package uses the `changepoint` package for change point detection.\n    For more information on change point methods, see the changepoint \n    package at <https://cran.r-project.org/package=changepoint>.",
    "version": "2.1",
    "maintainer": "Jennifer Dierauer <jen.r.brand@gmail.com>",
    "author": "Jennifer Dierauer [aut, cre],\n  Paul Whitfield [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FlowScreen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FlowScreen Daily Streamflow Trend and Change Point Screening Screens daily streamflow time series for temporal trends and\n    change-points. This package has been primarily developed for assessing the\n    quality of daily streamflow time series. It also contains tools for plotting\n    and calculating many different streamflow metrics. The package can be used to\n    produce summary screening plots showing change-points and significant temporal\n    trends for high flow, low flow, and/or baseflow statistics, or it can be used\n    to perform more detailed hydrological time series analyses. The package was\n    designed for screening daily streamflow time series from Water Survey Canada\n    and the United States Geological Survey but will also work with streamflow time\n    series from many other agencies.  \n    Package update to version 2.0 made updates to read.flows function to allow \n    loading of GRDC and ROBIN streamflow record formats.\n    This package uses the `changepoint` package for change point detection.\n    For more information on change point methods, see the changepoint \n    package at <https://cran.r-project.org/package=changepoint>.  "
  },
  {
    "id": 3508,
    "package_name": "FoCo2",
    "title": "Coherent Forecast Combination for Linearly Constrained Multiple\nTime Series",
    "description": "Methods and tools designed to improve the forecast accuracy for a linearly \n    constrained multiple time series, while fulfilling the linear/aggregation relationships \n    linking the components (Girolimetto and Di Fonzo, 2024 <doi:10.48550/arXiv.2412.03429>). \n    'FoCo2' offers multi-task forecast combination and reconciliation \n    approaches leveraging input from multiple forecasting models or experts and ensuring \n    that the resulting forecasts satisfy specified linear constraints. In addition, linear \n    inequality constraints (e.g., non-negativity of the forecasts) can be imposed, if needed.",
    "version": "0.1.2",
    "maintainer": "Daniele Girolimetto <daniele.girolimetto@unipd.it>",
    "author": "Daniele Girolimetto [aut, cre, fnd, cph] (ORCID:\n    <https://orcid.org/0000-0001-9387-1232>),\n  Tommaso Di Fonzo [aut, fnd] (ORCID:\n    <https://orcid.org/0000-0003-3388-7827>)",
    "url": "https://github.com/danigiro/FoCo2/,\nhttps://danigiro.github.io/FoCo2/",
    "bug_reports": "https://github.com/danigiro/FoCo2/issues/",
    "repository": "https://cran.r-project.org/package=FoCo2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FoCo2 Coherent Forecast Combination for Linearly Constrained Multiple\nTime Series Methods and tools designed to improve the forecast accuracy for a linearly \n    constrained multiple time series, while fulfilling the linear/aggregation relationships \n    linking the components (Girolimetto and Di Fonzo, 2024 <doi:10.48550/arXiv.2412.03429>). \n    'FoCo2' offers multi-task forecast combination and reconciliation \n    approaches leveraging input from multiple forecasting models or experts and ensuring \n    that the resulting forecasts satisfy specified linear constraints. In addition, linear \n    inequality constraints (e.g., non-negativity of the forecasts) can be imposed, if needed.  "
  },
  {
    "id": 3509,
    "package_name": "FoReco",
    "title": "Forecast Reconciliation",
    "description": "Classical (bottom-up and top-down), optimal combination and heuristic  \n    point (Di Fonzo and Girolimetto, 2023 <doi:10.1016/j.ijforecast.2021.08.004>) and \n    probabilistic (Girolimetto et al. 2024 <doi:10.1016/j.ijforecast.2023.10.003>) \n    forecast reconciliation procedures for linearly constrained time series \n    (e.g., hierarchical or grouped time series) in cross-sectional, temporal, \n    or cross-temporal frameworks.",
    "version": "1.1.0",
    "maintainer": "Daniele Girolimetto <daniele.girolimetto@unipd.it>",
    "author": "Daniele Girolimetto [aut, cre, fnd] (ORCID:\n    <https://orcid.org/0000-0001-9387-1232>),\n  Tommaso Di Fonzo [aut, fnd] (ORCID:\n    <https://orcid.org/0000-0003-3388-7827>)",
    "url": "https://github.com/danigiro/FoReco,\nhttps://danigiro.github.io/FoReco/,\nhttps://github.com/danigiro/FoReco",
    "bug_reports": "https://github.com/danigiro/FoReco/issues",
    "repository": "https://cran.r-project.org/package=FoReco",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FoReco Forecast Reconciliation Classical (bottom-up and top-down), optimal combination and heuristic  \n    point (Di Fonzo and Girolimetto, 2023 <doi:10.1016/j.ijforecast.2021.08.004>) and \n    probabilistic (Girolimetto et al. 2024 <doi:10.1016/j.ijforecast.2023.10.003>) \n    forecast reconciliation procedures for linearly constrained time series \n    (e.g., hierarchical or grouped time series) in cross-sectional, temporal, \n    or cross-temporal frameworks.  "
  },
  {
    "id": 3514,
    "package_name": "ForeCA",
    "title": "Forecastable Component Analysis",
    "description": "Implementation of Forecastable Component Analysis ('ForeCA'),\n    including main algorithms and auxiliary function (summary, plotting, etc.) to\n    apply 'ForeCA' to multivariate time series data. 'ForeCA' is a novel dimension\n    reduction (DR) technique for temporally dependent signals. Contrary to other\n    popular DR methods, such as 'PCA' or 'ICA', 'ForeCA' takes time dependency\n    explicitly into account and searches for the most ''forecastable'' signal.\n    The measure of forecastability is based on the Shannon entropy of the spectral\n    density of the transformed signal.",
    "version": "0.2.7",
    "maintainer": "Georg M. Goerg <im@gmge.org>",
    "author": "Georg M. Goerg [aut, cre]",
    "url": "https://github.com/gmgeorg/ForeCA",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ForeCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ForeCA Forecastable Component Analysis Implementation of Forecastable Component Analysis ('ForeCA'),\n    including main algorithms and auxiliary function (summary, plotting, etc.) to\n    apply 'ForeCA' to multivariate time series data. 'ForeCA' is a novel dimension\n    reduction (DR) technique for temporally dependent signals. Contrary to other\n    popular DR methods, such as 'PCA' or 'ICA', 'ForeCA' takes time dependency\n    explicitly into account and searches for the most ''forecastable'' signal.\n    The measure of forecastability is based on the Shannon entropy of the spectral\n    density of the transformed signal.  "
  },
  {
    "id": 3515,
    "package_name": "ForeComp",
    "title": "Size-Power Tradeoff Visualization for Equal Predictive Ability\nof Two Forecasts",
    "description": "Offers a set of tools for visualizing and analyzing size and power properties of the test for equal predictive accuracy, the Diebold-Mariano test that is based on heteroskedasticity and autocorrelation-robust (HAR) inference. A typical HAR inference is involved with non-parametric estimation of the long-run variance, and one of its tuning parameters, the truncation parameter, trades off a size and power. Lazarus, Lewis, and Stock (2021)<doi:10.3982/ECTA15404> theoretically characterize the size-power frontier for the Gaussian multivariate location model. 'ForeComp' computes and visualizes the finite-sample size-power frontier of the Diebold-Mariano test based on fixed-b asymptotics together with the Bartlett kernel. To compute the finite-sample size and power, it works with the best approximating ARMA process to the given dataset. It informs the user how their choice of the truncation parameter performs and how robust the testing outcomes are.",
    "version": "0.9.0",
    "maintainer": "Minchul Shin <visiblehand@gmail.com>",
    "author": "Nathan Schor [aut],\n  Minchul Shin [aut, cre, cph]",
    "url": "https://github.com/mcmcs/ForeComp",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ForeComp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ForeComp Size-Power Tradeoff Visualization for Equal Predictive Ability\nof Two Forecasts Offers a set of tools for visualizing and analyzing size and power properties of the test for equal predictive accuracy, the Diebold-Mariano test that is based on heteroskedasticity and autocorrelation-robust (HAR) inference. A typical HAR inference is involved with non-parametric estimation of the long-run variance, and one of its tuning parameters, the truncation parameter, trades off a size and power. Lazarus, Lewis, and Stock (2021)<doi:10.3982/ECTA15404> theoretically characterize the size-power frontier for the Gaussian multivariate location model. 'ForeComp' computes and visualizes the finite-sample size-power frontier of the Diebold-Mariano test based on fixed-b asymptotics together with the Bartlett kernel. To compute the finite-sample size and power, it works with the best approximating ARMA process to the given dataset. It informs the user how their choice of the truncation parameter performs and how robust the testing outcomes are.  "
  },
  {
    "id": 3516,
    "package_name": "ForecastCombinations",
    "title": "Forecast Combinations",
    "description": "Aim: Supports the most frequently used methods to combine forecasts. Among others: Simple average, Ordinary Least Squares, Least Absolute Deviation, Constrained Least Squares, Variance-based, Best Individual model, Complete subset regressions and Information-theoretic (information criteria based).",
    "version": "1.1",
    "maintainer": "Eran Raviv  <eeraviv@gmail.com>",
    "author": "Eran Raviv",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ForecastCombinations",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ForecastCombinations Forecast Combinations Aim: Supports the most frequently used methods to combine forecasts. Among others: Simple average, Ordinary Least Squares, Least Absolute Deviation, Constrained Least Squares, Variance-based, Best Individual model, Complete subset regressions and Information-theoretic (information criteria based).  "
  },
  {
    "id": 3517,
    "package_name": "ForecastingEnsembles",
    "title": "Time Series Forecasting Using 23 Individual Models",
    "description": "Runs multiple individual time series models, and combines them into an ensembles of time series models. This is mainly used to predict the results of the monthly labor market report from the \n    United States Bureau of Labor Statistics for virtually any part of the economy reported by the Bureau of Labor Statistics, but it can be easily modified to work with other types of time series data.\n    For example, the package was used to predict the winning men's and women's time for the 2024 London Marathon.",
    "version": "0.5.1",
    "maintainer": "Russ Conte <russconte@mac.com>",
    "author": "Russ Conte [aut, cre, cph]",
    "url": "https://github.com/InfiniteCuriosity/ForecastingEnsembles",
    "bug_reports": "https://github.com/InfiniteCuriosity/ForecastingEnsembles/issues",
    "repository": "https://cran.r-project.org/package=ForecastingEnsembles",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ForecastingEnsembles Time Series Forecasting Using 23 Individual Models Runs multiple individual time series models, and combines them into an ensembles of time series models. This is mainly used to predict the results of the monthly labor market report from the \n    United States Bureau of Labor Statistics for virtually any part of the economy reported by the Bureau of Labor Statistics, but it can be easily modified to work with other types of time series data.\n    For example, the package was used to predict the winning men's and women's time for the 2024 London Marathon.  "
  },
  {
    "id": 3584,
    "package_name": "GARCHIto",
    "title": "Class of GARCH-Ito Models",
    "description": "Provides functions to estimate model parameters and forecast future volatilities using the Unified GARCH-Ito [Kim and Wang (2016) <doi:10.1016/j.jeconom.2016.05.003>] and Realized GARCH-Ito [Song et. al. (2020) <doi:10.1016/j.jeconom.2020.07.007>] models. Optimization is done using augmented Lagrange multiplier method.  ",
    "version": "0.1.0",
    "maintainer": "Xinyu Song <song.xinyu@mail.shufe.edu.cn>",
    "author": "Xinyu Song",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GARCHIto",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GARCHIto Class of GARCH-Ito Models Provides functions to estimate model parameters and forecast future volatilities using the Unified GARCH-Ito [Kim and Wang (2016) <doi:10.1016/j.jeconom.2016.05.003>] and Realized GARCH-Ito [Song et. al. (2020) <doi:10.1016/j.jeconom.2020.07.007>] models. Optimization is done using augmented Lagrange multiplier method.    "
  },
  {
    "id": 3587,
    "package_name": "GAS",
    "title": "Generalized Autoregressive Score Models",
    "description": "Simulate, estimate and forecast using univariate and multivariate GAS models \n  as described in Ardia et al. (2019) <doi:10.18637/jss.v088.i06>.",
    "version": "0.3.4.1",
    "maintainer": "Leopoldo Catania <leopoldo.catania@econ.au.dk>",
    "author": "Leopoldo Catania [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0981-1921>),\n  David Ardia [ctb] (ORCID: <https://orcid.org/0000-0003-2823-782X>),\n  Kris Boudt [ctb] (ORCID: <https://orcid.org/0000-0002-1000-5142>)",
    "url": "https://github.com/LeopoldoCatania/GAS",
    "bug_reports": "https://github.com/LeopoldoCatania/GAS/issues",
    "repository": "https://cran.r-project.org/package=GAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GAS Generalized Autoregressive Score Models Simulate, estimate and forecast using univariate and multivariate GAS models \n  as described in Ardia et al. (2019) <doi:10.18637/jss.v088.i06>.  "
  },
  {
    "id": 3596,
    "package_name": "GCEstim",
    "title": "Regression Coefficients Estimation Using the Generalized Cross\nEntropy",
    "description": "Estimation and inference using the Generalized Maximum Entropy (GME) and Generalized Cross Entropy (GCE) framework, a flexible method for solving ill-posed inverse problems and parameter estimation under uncertainty (Golan, Judge, and Miller (1996, ISBN:978-0471145925) \"Maximum Entropy Econometrics: Robust Estimation with Limited Data\"). The package includes routines for generalized cross entropy estimation of linear models including the implementation of a GME-GCE two steps approach. Diagnostic tools, and options to incorporate prior information through support and prior distributions are available (Macedo, Cabral, Afreixo, Macedo and Angelelli (2025) <doi:10.1007/978-3-031-97589-9_21>). In particular, support spaces can be defined by the user or be internally computed based on the ridge trace or on the distribution of standardized regression coefficients. Different optimization methods for the objective function can be used. An adaptation of the normalized entropy aggregation (Macedo and Costa (2019) <doi:10.1007/978-3-030-26036-1_2> \"Normalized entropy aggregation for inhomogeneous large-scale data\") and a two-stage maximum entropy approach for time series regression (Macedo (2022) <doi:10.1080/03610918.2022.2057540>) are also available. Suitable for applications in econometrics, health, signal processing, and other fields requiring robust estimation under data constraints.",
    "version": "0.1.0",
    "maintainer": "Cabral Jorge <jorgecabral@ua.pt>",
    "author": "Cabral Jorge [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5721-4550>),\n  Macedo Pedro [ths],\n  Afreixo Vera [ths]",
    "url": "https://github.com/jorgevazcabral/GCEstim",
    "bug_reports": "https://github.com/jorgevazcabral/GCEstim/issues",
    "repository": "https://cran.r-project.org/package=GCEstim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GCEstim Regression Coefficients Estimation Using the Generalized Cross\nEntropy Estimation and inference using the Generalized Maximum Entropy (GME) and Generalized Cross Entropy (GCE) framework, a flexible method for solving ill-posed inverse problems and parameter estimation under uncertainty (Golan, Judge, and Miller (1996, ISBN:978-0471145925) \"Maximum Entropy Econometrics: Robust Estimation with Limited Data\"). The package includes routines for generalized cross entropy estimation of linear models including the implementation of a GME-GCE two steps approach. Diagnostic tools, and options to incorporate prior information through support and prior distributions are available (Macedo, Cabral, Afreixo, Macedo and Angelelli (2025) <doi:10.1007/978-3-031-97589-9_21>). In particular, support spaces can be defined by the user or be internally computed based on the ridge trace or on the distribution of standardized regression coefficients. Different optimization methods for the objective function can be used. An adaptation of the normalized entropy aggregation (Macedo and Costa (2019) <doi:10.1007/978-3-030-26036-1_2> \"Normalized entropy aggregation for inhomogeneous large-scale data\") and a two-stage maximum entropy approach for time series regression (Macedo (2022) <doi:10.1080/03610918.2022.2057540>) are also available. Suitable for applications in econometrics, health, signal processing, and other fields requiring robust estimation under data constraints.  "
  },
  {
    "id": 3609,
    "package_name": "GDPuc",
    "title": "Easily Convert GDP Data",
    "description": "Convert GDP time series data from one unit to\n    another. All common GDP units are included, i.e. current and constant\n    local currency units, US$ via market exchange rates and international\n    dollars via purchasing power parities. ",
    "version": "1.6.1",
    "maintainer": "Johannes Koch <jokoch@pik-potsdam.de>",
    "author": "Johannes Koch [aut, cre]",
    "url": "https://github.com/pik-piam/GDPuc,\nhttps://pik-piam.github.io/GDPuc/",
    "bug_reports": "https://github.com/pik-piam/GDPuc/issues",
    "repository": "https://cran.r-project.org/package=GDPuc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GDPuc Easily Convert GDP Data Convert GDP time series data from one unit to\n    another. All common GDP units are included, i.e. current and constant\n    local currency units, US$ via market exchange rates and international\n    dollars via purchasing power parities.   "
  },
  {
    "id": 3652,
    "package_name": "GHRexplore",
    "title": "Exploratory Analysis of Temporal and Spatio-Temporal Health Data",
    "description": "A collection of commonly used visualizations of temporal and\n    spatio-temporal health data including case counts, incidence rates, and\n    covariates. The available plot types include time series, heatmaps,\n    seasonality plots, maps and more. The package supports standard data\n    transformations such as temporal and spatial aggregations, while\n    offering extensive customization options for the resulting figures.",
    "version": "0.2.1",
    "maintainer": "Carles Mil\u00e0 <carles.milagarcia@bsc.es>",
    "author": "Carles Mil\u00e0 [aut, cre] (ORCID: <https://orcid.org/0000-0003-0470-0760>),\n  Giovenale Moirano [aut] (ORCID:\n    <https://orcid.org/0000-0001-8748-3321>),\n  Anna B. Kawiecki [aut] (ORCID: <https://orcid.org/0000-0002-0499-2612>),\n  Rachel Lowe [aut, cph] (ORCID: <https://orcid.org/0000-0003-3939-7343>)",
    "url": "https://gitlab.earth.bsc.es/ghr/ghrexplore,\nhttps://bsc-es.github.io/GHRtools/docs/GHRexplore/GHRexplore",
    "bug_reports": "https://gitlab.earth.bsc.es/ghr/ghrexplore/-/issues",
    "repository": "https://cran.r-project.org/package=GHRexplore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GHRexplore Exploratory Analysis of Temporal and Spatio-Temporal Health Data A collection of commonly used visualizations of temporal and\n    spatio-temporal health data including case counts, incidence rates, and\n    covariates. The available plot types include time series, heatmaps,\n    seasonality plots, maps and more. The package supports standard data\n    transformations such as temporal and spatial aggregations, while\n    offering extensive customization options for the resulting figures.  "
  },
  {
    "id": 3653,
    "package_name": "GHRmodel",
    "title": "Bayesian Hierarchical Modelling of Spatio-Temporal Health Data",
    "description": "Supports modeling health outcomes using Bayesian hierarchical \n  spatio-temporal models with complex covariate effects (e.g., linear, \n  non-linear, interactions, distributed lag linear and non-linear \n  models) in the 'INLA' framework. It is designed to help users identify key \n  drivers and  predictors of disease risk by enabling streamlined model \n  exploration, comparison, and visualization of complex covariate effects. \n  See an application of the modelling framework in Lowe, Lee, O'Reilly et al. (2021)\n  <doi:10.1016/S2542-5196(20)30292-8>.",
    "version": "0.1.1",
    "maintainer": "Carles Mil\u00e0 <carles.milagarcia@bsc.es>",
    "author": "Carles Mil\u00e0 [aut, cre] (ORCID: <https://orcid.org/0000-0003-0470-0760>),\n  Giovenale Moirano [aut] (ORCID:\n    <https://orcid.org/0000-0001-8748-3321>),\n  Anna B. Kawiecki [aut] (ORCID: <https://orcid.org/0000-0002-0499-2612>),\n  Rachel Lowe [aut] (ORCID: <https://orcid.org/0000-0003-3939-7343>)",
    "url": "https://gitlab.earth.bsc.es/ghr/ghrmodel,\nhttps://bsc-es.github.io/GHRtools/docs/GHRmodel/GHRmodel",
    "bug_reports": "https://gitlab.earth.bsc.es/ghr/ghrmodel/-/issues",
    "repository": "https://cran.r-project.org/package=GHRmodel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GHRmodel Bayesian Hierarchical Modelling of Spatio-Temporal Health Data Supports modeling health outcomes using Bayesian hierarchical \n  spatio-temporal models with complex covariate effects (e.g., linear, \n  non-linear, interactions, distributed lag linear and non-linear \n  models) in the 'INLA' framework. It is designed to help users identify key \n  drivers and  predictors of disease risk by enabling streamlined model \n  exploration, comparison, and visualization of complex covariate effects. \n  See an application of the modelling framework in Lowe, Lee, O'Reilly et al. (2021)\n  <doi:10.1016/S2542-5196(20)30292-8>.  "
  },
  {
    "id": 3659,
    "package_name": "GIMMEgVAR",
    "title": "Group Iterative Multiple Model Estimation with 'graphicalVAR'",
    "description": "Data-driven approach for arriving at person-specific time series models from within a Graphical Vector Autoregression (VAR) framework. The method first identifies which relations replicate across the majority of individuals to detect signal from noise. These group-level relations are then used as a foundation for starting the search for person-specific (or individual-level) relations. All estimates are obtained uniquely for each individual in the final models. The method for the 'graphicalVAR' approach is found in Epskamp, Waldorp, Mottus & Borsboom (2018) <doi:10.1080/00273171.2018.1454823>. ",
    "version": "0.1.0",
    "maintainer": "Sandra Williams Lee <wsandra@live.unc.edu>",
    "author": "Sandra Williams Lee [aut, cre],\n  Kathleen M. Gates [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GIMMEgVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GIMMEgVAR Group Iterative Multiple Model Estimation with 'graphicalVAR' Data-driven approach for arriving at person-specific time series models from within a Graphical Vector Autoregression (VAR) framework. The method first identifies which relations replicate across the majority of individuals to detect signal from noise. These group-level relations are then used as a foundation for starting the search for person-specific (or individual-level) relations. All estimates are obtained uniquely for each individual in the final models. The method for the 'graphicalVAR' approach is found in Epskamp, Waldorp, Mottus & Borsboom (2018) <doi:10.1080/00273171.2018.1454823>.   "
  },
  {
    "id": 3682,
    "package_name": "GMDH",
    "title": "Short Term Forecasting via GMDH-Type Neural Network Algorithms",
    "description": "Group method of data handling (GMDH) - type neural network algorithm is the heuristic self-organization method for modelling the complex systems. In this package, GMDH-type neural network algorithms are applied to make short term forecasting for a univariate time series. ",
    "version": "1.6",
    "maintainer": "Osman Dag <osman.dag@hacettepe.edu.tr>",
    "author": "Osman Dag, Ceylan Yozgatligil",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GMDH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GMDH Short Term Forecasting via GMDH-Type Neural Network Algorithms Group method of data handling (GMDH) - type neural network algorithm is the heuristic self-organization method for modelling the complex systems. In this package, GMDH-type neural network algorithms are applied to make short term forecasting for a univariate time series.   "
  },
  {
    "id": 3691,
    "package_name": "GNAR",
    "title": "Methods for Fitting Network Time Series Models",
    "description": "Simulation of, and fitting models for, Generalised Network Autoregressive (GNAR) time series models which take account of network structure, potentially with exogenous variables.  Such models are described in Knight et al. (2020) <doi:10.18637/jss.v096.i05> and Nason and Wei (2021) <doi:10.1111/rssa.12875>.  Diagnostic tools for GNAR(X) models can be found in Nason et al. (2023) <doi:10.48550/arXiv.2312.00530>.",
    "version": "1.1.4",
    "maintainer": "Matt Nunes <nunesrpackages@gmail.com>",
    "author": "Kathryn Leeming [aut],\n  Guy Nason [aut],\n  Matt Nunes [aut, cre],\n  Marina Knight [ctb],\n  James Wei [aut],\n  Daniel Salnikov [aut],\n  Mario Cortina Borja [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GNAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GNAR Methods for Fitting Network Time Series Models Simulation of, and fitting models for, Generalised Network Autoregressive (GNAR) time series models which take account of network structure, potentially with exogenous variables.  Such models are described in Knight et al. (2020) <doi:10.18637/jss.v096.i05> and Nason and Wei (2021) <doi:10.1111/rssa.12875>.  Diagnostic tools for GNAR(X) models can be found in Nason et al. (2023) <doi:10.48550/arXiv.2312.00530>.  "
  },
  {
    "id": 3693,
    "package_name": "GNSSseg",
    "title": "Homogenization of GNSS Series",
    "description": "Homogenize GNSS (Global Navigation Satellite System) time-series. The general model is a segmentation in the mean model including a periodic function and considering monthly variances,  see Quarello (2020) <arXiv:2005.04683>. ",
    "version": "6.0",
    "maintainer": "Annarosa Quarello <quarello.annarosa@gmail.com>",
    "author": "Annarosa Quarello [aut, cre], Emilie Lebarbier [aut], Olivier Bock [aut] ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GNSSseg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GNSSseg Homogenization of GNSS Series Homogenize GNSS (Global Navigation Satellite System) time-series. The general model is a segmentation in the mean model including a periodic function and considering monthly variances,  see Quarello (2020) <arXiv:2005.04683>.   "
  },
  {
    "id": 3702,
    "package_name": "GPBayes",
    "title": "Tools for Gaussian Process Modeling in Uncertainty\nQuantification",
    "description": "Gaussian processes ('GPs') have been widely used to model spatial data, 'spatio'-temporal data, and computer experiments in diverse areas of statistics including spatial statistics, 'spatio'-temporal statistics, uncertainty quantification, and machine learning. This package creates basic tools for fitting and prediction based on 'GPs' with spatial data, 'spatio'-temporal data, and computer experiments. Key characteristics for this GP tool include: (1) the comprehensive implementation of various covariance functions including the 'Mat\u00e9rn' family and the Confluent 'Hypergeometric' family with isotropic form, tensor form, and automatic relevance determination form, where the isotropic form is widely used in spatial statistics, the tensor form is widely used in design and analysis of computer experiments and uncertainty quantification, and the automatic relevance determination form is widely used in machine learning; (2) implementations via Markov chain Monte Carlo ('MCMC') algorithms and optimization algorithms for GP models with all the implemented covariance functions. The methods for fitting and prediction are mainly implemented in a Bayesian framework; (3) model evaluation via Fisher information and predictive metrics such as predictive scores; (4) built-in functionality for simulating 'GPs' with all the implemented covariance functions; (5) unified implementation to allow easy specification of various 'GPs'. ",
    "version": "0.1.0-6",
    "maintainer": "Pulong Ma <mpulong@gmail.com>",
    "author": "Pulong Ma [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/pulongma/GPBayes/issues",
    "repository": "https://cran.r-project.org/package=GPBayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GPBayes Tools for Gaussian Process Modeling in Uncertainty\nQuantification Gaussian processes ('GPs') have been widely used to model spatial data, 'spatio'-temporal data, and computer experiments in diverse areas of statistics including spatial statistics, 'spatio'-temporal statistics, uncertainty quantification, and machine learning. This package creates basic tools for fitting and prediction based on 'GPs' with spatial data, 'spatio'-temporal data, and computer experiments. Key characteristics for this GP tool include: (1) the comprehensive implementation of various covariance functions including the 'Mat\u00e9rn' family and the Confluent 'Hypergeometric' family with isotropic form, tensor form, and automatic relevance determination form, where the isotropic form is widely used in spatial statistics, the tensor form is widely used in design and analysis of computer experiments and uncertainty quantification, and the automatic relevance determination form is widely used in machine learning; (2) implementations via Markov chain Monte Carlo ('MCMC') algorithms and optimization algorithms for GP models with all the implemented covariance functions. The methods for fitting and prediction are mainly implemented in a Bayesian framework; (3) model evaluation via Fisher information and predictive metrics such as predictive scores; (4) built-in functionality for simulating 'GPs' with all the implemented covariance functions; (5) unified implementation to allow easy specification of various 'GPs'.   "
  },
  {
    "id": 3713,
    "package_name": "GPRMortality",
    "title": "Gaussian Process Regression for Mortality Rates",
    "description": "A Bayesian statistical model for estimating child (under-five age group) and adult (15-60 age group) mortality.  The main challenge is how to combine and integrate these different time series and how to produce unified estimates of mortality rates during a specified time span. GPR is a Bayesian statistical model for estimating child and adult mortality rates which its data likelihood is mortality rates from different data sources such as: Death Registration System, Censuses or surveys. There are also various hyper-parameters for completeness of DRS, mean, covariance functions and variances as priors. This function produces estimations and uncertainty (95% or any desirable percentiles) based on sampling and non-sampling errors due to variation in data sources. The GP model utilizes Bayesian inference to update predicted mortality rates as a posterior in Bayes rule by combining data and a prior probability distribution over parameters in mean, covariance function, and the regression model. This package uses Markov Chain Monte Carlo (MCMC) to sample from posterior probability distribution by 'rstan' package in R. Details are given in Wang H, Dwyer-Lindgren L, Lofgren KT, et al. (2012) <doi:10.1016/S0140-6736(12)61719-X>, Wang H, Liddell CA, Coates MM, et al. (2014) <doi:10.1016/S0140-6736(14)60497-9> and Mohammadi, Parsaeian, Mehdipour et al. (2017) <doi:10.1016/S2214-109X(17)30105-5>.",
    "version": "0.1.0",
    "maintainer": "Ali Ghanbari <a.ghanbari541@gmail.com>",
    "author": "Parinaz Mehdipour <mehdipoor.p@gmail.com> [aut], Ali Ghanbari <a.ghanbari541@gmail.com> [cre,aut] , Iman Navidi <iman.navidi.1988@gmail.com> [aut], Farshad Farzadfar <farzadfar3@yahoo.com> [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GPRMortality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GPRMortality Gaussian Process Regression for Mortality Rates A Bayesian statistical model for estimating child (under-five age group) and adult (15-60 age group) mortality.  The main challenge is how to combine and integrate these different time series and how to produce unified estimates of mortality rates during a specified time span. GPR is a Bayesian statistical model for estimating child and adult mortality rates which its data likelihood is mortality rates from different data sources such as: Death Registration System, Censuses or surveys. There are also various hyper-parameters for completeness of DRS, mean, covariance functions and variances as priors. This function produces estimations and uncertainty (95% or any desirable percentiles) based on sampling and non-sampling errors due to variation in data sources. The GP model utilizes Bayesian inference to update predicted mortality rates as a posterior in Bayes rule by combining data and a prior probability distribution over parameters in mean, covariance function, and the regression model. This package uses Markov Chain Monte Carlo (MCMC) to sample from posterior probability distribution by 'rstan' package in R. Details are given in Wang H, Dwyer-Lindgren L, Lofgren KT, et al. (2012) <doi:10.1016/S0140-6736(12)61719-X>, Wang H, Liddell CA, Coates MM, et al. (2014) <doi:10.1016/S0140-6736(14)60497-9> and Mohammadi, Parsaeian, Mehdipour et al. (2017) <doi:10.1016/S2214-109X(17)30105-5>.  "
  },
  {
    "id": 3722,
    "package_name": "GPoM",
    "title": "Generalized Polynomial Modelling",
    "description": "Platform dedicated to the Global Modelling technique. Its aim\n    is to obtain ordinary differential equations of polynomial form directly\n    from time series. It can be applied to single or multiple time series under\n    various conditions of noise, time series lengths, sampling, etc. This platform\n    is developped at the Centre d'Etudes Spatiales de la Biosphere (CESBIO),\n    UMR 5126 UPS/CNRS/CNES/IRD, 18 av. Edouard Belin, 31401 TOULOUSE, FRANCE.\n    The developments were funded by the French program Les Enveloppes Fluides\n    et l'Environnement (LEFE, MANU, projets GloMo, SpatioGloMo and MoMu). The\n    French program Defi InFiNiTi (CNRS) and PNTS are also acknowledged (projects\n    Crops'IChaos and Musc & SlowFast). The method is described in the article :\n    Mangiarotti S. and Huc M. (2019) <doi:10.1063/1.5081448>.",
    "version": "1.4",
    "maintainer": "Mireille Huc <mireille.huc@u-paris2.fr>",
    "author": "Sylvain Mangiarotti [aut],\n  Mireille Huc [cre, aut],\n  Flavie Le Jean [ctb],\n  Malika Chassan [ctb],\n  Laurent Drapeau [ctb],\n  Institut de Recherche pour le D\u00e9veloppement [fnd],\n  Centre National de la Recherche Scientifique [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GPoM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GPoM Generalized Polynomial Modelling Platform dedicated to the Global Modelling technique. Its aim\n    is to obtain ordinary differential equations of polynomial form directly\n    from time series. It can be applied to single or multiple time series under\n    various conditions of noise, time series lengths, sampling, etc. This platform\n    is developped at the Centre d'Etudes Spatiales de la Biosphere (CESBIO),\n    UMR 5126 UPS/CNRS/CNES/IRD, 18 av. Edouard Belin, 31401 TOULOUSE, FRANCE.\n    The developments were funded by the French program Les Enveloppes Fluides\n    et l'Environnement (LEFE, MANU, projets GloMo, SpatioGloMo and MoMu). The\n    French program Defi InFiNiTi (CNRS) and PNTS are also acknowledged (projects\n    Crops'IChaos and Musc & SlowFast). The method is described in the article :\n    Mangiarotti S. and Huc M. (2019) <doi:10.1063/1.5081448>.  "
  },
  {
    "id": 3764,
    "package_name": "GUTS",
    "title": "Fast Calculation of the Likelihood of a Stochastic Survival\nModel",
    "description": "Given exposure and survival time series as well as parameter values, GUTS allows for the fast calculation of the survival probabilities as well as the logarithm of the corresponding likelihood (see Albert, C., Vogel, S. and Ashauer, R. (2016) <doi:10.1371/journal.pcbi.1004978>).",
    "version": "1.2.6",
    "maintainer": "Oliver Jakoby <oliver.jakoby@rifcon.de>",
    "author": "Carlo Albert [aut],\n  S\u00f6ren Vogel [aut],\n  Oliver Jakoby [aut, cre],\n  Alexander Singer [aut],\n  Dirk Nickisch [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GUTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GUTS Fast Calculation of the Likelihood of a Stochastic Survival\nModel Given exposure and survival time series as well as parameter values, GUTS allows for the fast calculation of the survival probabilities as well as the logarithm of the corresponding likelihood (see Albert, C., Vogel, S. and Ashauer, R. (2016) <doi:10.1371/journal.pcbi.1004978>).  "
  },
  {
    "id": 3777,
    "package_name": "GWSDAT",
    "title": "GroundWater Spatiotemporal Data Analysis Tool (GWSDAT)",
    "description": "Shiny application for the analysis of groundwater\n    monitoring data, designed to work with simple time-series data for\n    solute concentration and ground water elevation, but can also plot\n    non-aqueous phase liquid (NAPL) thickness if required. Also provides\n    the import of a site basemap in GIS shapefile format.",
    "version": "3.2.1",
    "maintainer": "Wayne Jones <wayne.w.jones@shell.com>",
    "author": "Wayne Jones <wayne.w.jones@shell.com>, Ludger Evers\n    <ludger.evers@glasgow.ac.uk>, Andrej Aderhold\n    <andrej.aderhold@protonmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GWSDAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GWSDAT GroundWater Spatiotemporal Data Analysis Tool (GWSDAT) Shiny application for the analysis of groundwater\n    monitoring data, designed to work with simple time-series data for\n    solute concentration and ground water elevation, but can also plot\n    non-aqueous phase liquid (NAPL) thickness if required. Also provides\n    the import of a site basemap in GIS shapefile format.  "
  },
  {
    "id": 3789,
    "package_name": "GaussianHMM1d",
    "title": "Inference, Goodness-of-Fit and Forecast for Univariate Gaussian\nHidden Markov Models",
    "description": "Inference, goodness-of-fit test, and prediction densities and intervals for univariate Gaussian Hidden Markov Models (HMM). The goodness-of-fit is based on a Cramer-von Mises statistic and uses parametric bootstrap to estimate the p-value. The description of the methodology is taken from Chapter 10.2 of Remillard (2013) <doi:10.1201/b14285>.",
    "version": "1.1.2",
    "maintainer": "Bouchra R. Nasri <bouchra.nasri@umontreal.ca>",
    "author": "Bouchra R. Nasri [aut, cre, cph],\n  Bruno N Remillard [aut, ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GaussianHMM1d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GaussianHMM1d Inference, Goodness-of-Fit and Forecast for Univariate Gaussian\nHidden Markov Models Inference, goodness-of-fit test, and prediction densities and intervals for univariate Gaussian Hidden Markov Models (HMM). The goodness-of-fit is based on a Cramer-von Mises statistic and uses parametric bootstrap to estimate the p-value. The description of the methodology is taken from Chapter 10.2 of Remillard (2013) <doi:10.1201/b14285>.  "
  },
  {
    "id": 3807,
    "package_name": "GeneCycle",
    "title": "Identification of Periodically Expressed Genes",
    "description": "The GeneCycle package implements the approaches of Wichert\n        et al. (2004) <doi:10.1093/bioinformatics/btg364>, Ahdesmaki \n        et al. (2005) <doi:10.1186/1471-2105-6-117> and Ahdesmaki et al.\n        (2007) <DOI:10.1186/1471-2105-8-233> for detecting periodically \n        expressed genes from gene expression time series data.",
    "version": "1.1.6",
    "maintainer": "Miika Ahdesmaki <miika.ahdesmaki@gmail.com>",
    "author": "Miika Ahdesmaki [aut, cre],\n  Konstantinos Fokianos [aut],\n  Korbinian Strimmer [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GeneCycle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GeneCycle Identification of Periodically Expressed Genes The GeneCycle package implements the approaches of Wichert\n        et al. (2004) <doi:10.1093/bioinformatics/btg364>, Ahdesmaki \n        et al. (2005) <doi:10.1186/1471-2105-6-117> and Ahdesmaki et al.\n        (2007) <DOI:10.1186/1471-2105-8-233> for detecting periodically \n        expressed genes from gene expression time series data.  "
  },
  {
    "id": 3810,
    "package_name": "GeneNet",
    "title": "Modeling and Inferring Gene Networks",
    "description": "Analyzes gene expression\n  (time series) data with focus on the inference of gene networks.\n  In particular, GeneNet implements the methods of Schaefer and \n  Strimmer (2005a,b,c) and Opgen-Rhein and Strimmer (2006, 2007)\n  for learning large-scale gene association networks (including\n  assignment of putative directions).  ",
    "version": "1.2.17",
    "maintainer": "Korbinian Strimmer <strimmerlab@gmail.com>",
    "author": "Juliane Schaefer [aut],\n  Rainer Opgen-Rhein [aut],\n  Korbinian Strimmer [aut, cre]",
    "url": "https://strimmerlab.github.io/software/genenet/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GeneNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GeneNet Modeling and Inferring Gene Networks Analyzes gene expression\n  (time series) data with focus on the inference of gene networks.\n  In particular, GeneNet implements the methods of Schaefer and \n  Strimmer (2005a,b,c) and Opgen-Rhein and Strimmer (2006, 2007)\n  for learning large-scale gene association networks (including\n  assignment of putative directions).    "
  },
  {
    "id": 3829,
    "package_name": "GeoModels",
    "title": "Procedures for Gaussian and Non Gaussian Geostatistical (Large)\nData Analysis",
    "description": "Functions for Gaussian and Non Gaussian (bivariate) spatial and spatio-temporal data analysis are provided for a) (fast) simulation of random fields,  b) inference  for random fields using standard likelihood and a likelihood approximation  method called  weighted composite likelihood based on pairs and b) prediction using (local) best linear unbiased prediction. Weighted composite likelihood can be very efficient for estimating massive datasets. Both regression and spatial (temporal) dependence analysis can be jointly performed. Flexible covariance models for spatial and spatial-temporal data on Euclidean domains and spheres are provided. There are also many useful functions for plotting and performing diagnostic analysis. Different non Gaussian random fields can be considered in the analysis. Among them, random fields with marginal distributions such as Skew-Gaussian, Student-t, Tukey-h, Sin-Arcsin, Two-piece, Weibull, Gamma, Log-Gaussian, Binomial, Negative Binomial  and Poisson. See the URL for the papers associated with this package, as for instance, Bevilacqua and Gaetan (2015) <doi:10.1007/s11222-014-9460-6>, Bevilacqua et al. (2016) <doi:10.1007/s13253-016-0256-3>, Vallejos et al. (2020) <doi:10.1007/978-3-030-56681-4>, Bevilacqua et. al (2020) <doi:10.1002/env.2632>, Bevilacqua et. al (2021) <doi:10.1111/sjos.12447>, Bevilacqua et al. (2022) <doi:10.1016/j.jmva.2022.104949>, Morales-Navarrete et al. (2023) <doi:10.1080/01621459.2022.2140053>, and a large class of examples and tutorials.",
    "version": "2.2.1",
    "maintainer": "Moreno Bevilacqua <moreno.bevilacqua89@gmail.com>",
    "author": "Moreno Bevilacqua [aut, cre, cph],\n  V\u00edctor Morales-O\u00f1ate [ctb],\n  Francisco Cuevas-Pacheco [ctb],\n  Christian Caama\u00f1o-Carrillo [ctb]",
    "url": "https://vmoprojs.github.io/GeoModels-page/",
    "bug_reports": "https://github.com/vmoprojs/GeoModels/issues",
    "repository": "https://cran.r-project.org/package=GeoModels",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GeoModels Procedures for Gaussian and Non Gaussian Geostatistical (Large)\nData Analysis Functions for Gaussian and Non Gaussian (bivariate) spatial and spatio-temporal data analysis are provided for a) (fast) simulation of random fields,  b) inference  for random fields using standard likelihood and a likelihood approximation  method called  weighted composite likelihood based on pairs and b) prediction using (local) best linear unbiased prediction. Weighted composite likelihood can be very efficient for estimating massive datasets. Both regression and spatial (temporal) dependence analysis can be jointly performed. Flexible covariance models for spatial and spatial-temporal data on Euclidean domains and spheres are provided. There are also many useful functions for plotting and performing diagnostic analysis. Different non Gaussian random fields can be considered in the analysis. Among them, random fields with marginal distributions such as Skew-Gaussian, Student-t, Tukey-h, Sin-Arcsin, Two-piece, Weibull, Gamma, Log-Gaussian, Binomial, Negative Binomial  and Poisson. See the URL for the papers associated with this package, as for instance, Bevilacqua and Gaetan (2015) <doi:10.1007/s11222-014-9460-6>, Bevilacqua et al. (2016) <doi:10.1007/s13253-016-0256-3>, Vallejos et al. (2020) <doi:10.1007/978-3-030-56681-4>, Bevilacqua et. al (2020) <doi:10.1002/env.2632>, Bevilacqua et. al (2021) <doi:10.1111/sjos.12447>, Bevilacqua et al. (2022) <doi:10.1016/j.jmva.2022.104949>, Morales-Navarrete et al. (2023) <doi:10.1080/01621459.2022.2140053>, and a large class of examples and tutorials.  "
  },
  {
    "id": 3833,
    "package_name": "GeoTox",
    "title": "Spatiotemporal Mixture Risk Assessment",
    "description": "Connecting spatiotemporal exposure to individual and\n    population-level risk via source-to-outcome continuum modeling. The package,\n    methods, and case-studies are described in Messier, Reif, and Marvel (2024)\n    <doi:10.1101/2024.09.23.24314096> and Eccles et al. (2023)\n    <doi:10.1016/j.scitotenv.2022.158905>.",
    "version": "0.2.0",
    "maintainer": "Kyle Messier <kyle.messier@nih.gov>",
    "author": "Skylar Marvel [aut] (ORCID: <https://orcid.org/0000-0002-2971-9743>),\n  David Reif [aut] (ORCID: <https://orcid.org/0000-0001-7815-6767>),\n  Kyle Messier [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-9508-9623>),\n  Spatiotemporal Exposures and Toxicology Group [cph]",
    "url": "https://niehs.github.io/GeoTox/, https://github.com/NIEHS/GeoTox",
    "bug_reports": "https://github.com/NIEHS/GeoTox/issues",
    "repository": "https://cran.r-project.org/package=GeoTox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GeoTox Spatiotemporal Mixture Risk Assessment Connecting spatiotemporal exposure to individual and\n    population-level risk via source-to-outcome continuum modeling. The package,\n    methods, and case-studies are described in Messier, Reif, and Marvel (2024)\n    <doi:10.1101/2024.09.23.24314096> and Eccles et al. (2023)\n    <doi:10.1016/j.scitotenv.2022.158905>.  "
  },
  {
    "id": 3844,
    "package_name": "GetQuandlData",
    "title": "Fast and Cached Import of Data from 'Quandl' Using the 'json\nAPI'",
    "description": "Imports time series data from the 'Quandl' database <https://data.nasdaq.com/>. The package uses the  'json api' at <https://data.nasdaq.com/search>, local caching ('memoise' package) and the tidy format by default. \n   Also allows queries of databases, allowing the user to see which time series are available for each database id. In short, it is an alternative to package 'Quandl', with faster data importation in the tidy/long format.",
    "version": "1.0.0",
    "maintainer": "Marcelo S. Perlin <marceloperlin@gmail.com>",
    "author": "Marcelo S. Perlin",
    "url": "https://github.com/msperlin/GetQuandlData/",
    "bug_reports": "https://github.com/msperlin/GetQuandlData/issues",
    "repository": "https://cran.r-project.org/package=GetQuandlData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GetQuandlData Fast and Cached Import of Data from 'Quandl' Using the 'json\nAPI' Imports time series data from the 'Quandl' database <https://data.nasdaq.com/>. The package uses the  'json api' at <https://data.nasdaq.com/search>, local caching ('memoise' package) and the tidy format by default. \n   Also allows queries of databases, allowing the user to see which time series are available for each database id. In short, it is an alternative to package 'Quandl', with faster data importation in the tidy/long format.  "
  },
  {
    "id": 3867,
    "package_name": "GmptzCurve",
    "title": "Gompertz Curve Fitting",
    "description": "A system for fitting Gompertz Curve in a Time Series Data.",
    "version": "0.1.0",
    "maintainer": "Arnab Roy <arnabroy7640@gmail.com>",
    "author": "Arnab Roy [aut, cre],\n  Debarghya Baul [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GmptzCurve",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GmptzCurve Gompertz Curve Fitting A system for fitting Gompertz Curve in a Time Series Data.  "
  },
  {
    "id": 3890,
    "package_name": "GreyModel",
    "title": "Fitting and Forecasting of Grey Model",
    "description": "Testing, Implementation and Forecasting of Grey Model (GM(1, 1)). For method details see Hsu, L. and Wang, C. (2007). <doi:10.1016/j.techfore.2006.02.005>. ",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Mrinmoy Ray [aut, cre],\n  Rajeev Ranjan kumar [aut, ctb],\n  K.N. Singh [ctb],\n  Ramasubramanian V. [ctb],\n  Kanchan Sinha [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GreyModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GreyModel Fitting and Forecasting of Grey Model Testing, Implementation and Forecasting of Grey Model (GM(1, 1)). For method details see Hsu, L. and Wang, C. (2007). <doi:10.1016/j.techfore.2006.02.005>.   "
  },
  {
    "id": 3892,
    "package_name": "Greymodels",
    "title": "Shiny App for Grey Forecasting Model",
    "description": "The 'Greymodels' Shiny app is an interactive interface for statistical modelling and forecasting using grey-based models. It covers several state-of-the-art univariate and multivariate grey models. A user friendly interface allows users to easily compare the performance of different models for prediction and among others, visualize graphical plots of predicted values within user chosen confidence intervals. Chang, C. (2019) <doi:10.24818/18423264/53.1.19.11>, Li, K., Zhang, T. (2019) <doi:10.1007/s12667-019-00344-0>, Ou, S. (2012) <doi:10.1016/j.compag.2012.03.007>, Li, S., Zhou, M., Meng, W., Zhou, W. (2019) <doi:10.1080/23307706.2019.1666310>, Xie, N., Liu, S. (2009) <doi:10.1016/j.apm.2008.01.011>, Shao, Y., Su, H. (2012) <doi:10.1016/j.aasri.2012.06.003>, Xie, N., Liu, S., Yang, Y., Yuan, C. (2013) <doi:10.1016/j.apm.2012.10.037>, Li, S., Miao, Y., Li, G., Ikram, M. (2020) <doi:10.1016/j.matcom.2019.12.020>, Che, X., Luo, Y., He, Z. (2013) <doi:10.4028/www.scientific.net/AMM.364.207>, Zhu, J., Xu, Y., Leng, H., Tang, H., Gong, H., Zhang, Z. (2016) <doi:10.1109/appeec.2016.7779929>, Luo, Y., Liao, D. (2012) <doi:10.4028/www.scientific.net/AMR.507.265>, Bilgil, H. (2020) <doi:10.3934/math.2021091>, Li, D., Chang, C., Chen, W., Chen, C. (2011) <doi:10.1016/j.apm.2011.04.006>, Chen, C. (2008) <doi:10.1016/j.chaos.2006.08.024>, Zhou, W., Pei, L. (2020) <doi:10.1007/s00500-019-04248-0>, Xiao, X., Duan, H. (2020) <doi:10.1016/j.engappai.2019.103350>, Xu, N., Dang, Y. (2015) <doi:10.1155/2015/606707>, Chen, P., Yu, H.(2014) <doi:10.1155/2014/242809>, Zeng, B., Li, S., Meng, W., Zhang, D. (2019) <doi:10.1371/journal.pone.0221333>, Liu, L., Wu, L. (2021) <doi:10.1016/j.apm.2020.08.080>, Hu, Y. (2020) <doi:10.1007/s00500-020-04765-3>, Zhou, P., Ang, B., Poh, K. (2006) <doi:10.1016/j.energy.2005.12.002>, Cheng, M., Li, J., Liu, Y., Liu, B. (2020) <doi:10.3390/su12020698>, Wang, H., Wang, P., Senel, M., Li, T. (2019) <doi:10.1155/2019/9049815>, Ding, S., Li, R. (2020) <doi:10.1155/2020/4564653>, Zeng, B., Li, C. (2018) <doi:10.1016/j.cie.2018.02.042>, Xie, N., Liu, S. (2015) <doi:10.1109/JSEE.2015.00013>, Zeng, X., Yan, S., He, F., Shi, Y. (2019) <doi:10.1016/j.apm.2019.11.032>.  ",
    "version": "2.0.1",
    "maintainer": "Jahajeeah Havisha <hjahajeeah@utm.ac.mu>",
    "author": "Jahajeeah Havisha [aut, cre],\n  Saib Aslam Aly [aut]",
    "url": "https://github.com/havishaJ/Greymodels",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Greymodels",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Greymodels Shiny App for Grey Forecasting Model The 'Greymodels' Shiny app is an interactive interface for statistical modelling and forecasting using grey-based models. It covers several state-of-the-art univariate and multivariate grey models. A user friendly interface allows users to easily compare the performance of different models for prediction and among others, visualize graphical plots of predicted values within user chosen confidence intervals. Chang, C. (2019) <doi:10.24818/18423264/53.1.19.11>, Li, K., Zhang, T. (2019) <doi:10.1007/s12667-019-00344-0>, Ou, S. (2012) <doi:10.1016/j.compag.2012.03.007>, Li, S., Zhou, M., Meng, W., Zhou, W. (2019) <doi:10.1080/23307706.2019.1666310>, Xie, N., Liu, S. (2009) <doi:10.1016/j.apm.2008.01.011>, Shao, Y., Su, H. (2012) <doi:10.1016/j.aasri.2012.06.003>, Xie, N., Liu, S., Yang, Y., Yuan, C. (2013) <doi:10.1016/j.apm.2012.10.037>, Li, S., Miao, Y., Li, G., Ikram, M. (2020) <doi:10.1016/j.matcom.2019.12.020>, Che, X., Luo, Y., He, Z. (2013) <doi:10.4028/www.scientific.net/AMM.364.207>, Zhu, J., Xu, Y., Leng, H., Tang, H., Gong, H., Zhang, Z. (2016) <doi:10.1109/appeec.2016.7779929>, Luo, Y., Liao, D. (2012) <doi:10.4028/www.scientific.net/AMR.507.265>, Bilgil, H. (2020) <doi:10.3934/math.2021091>, Li, D., Chang, C., Chen, W., Chen, C. (2011) <doi:10.1016/j.apm.2011.04.006>, Chen, C. (2008) <doi:10.1016/j.chaos.2006.08.024>, Zhou, W., Pei, L. (2020) <doi:10.1007/s00500-019-04248-0>, Xiao, X., Duan, H. (2020) <doi:10.1016/j.engappai.2019.103350>, Xu, N., Dang, Y. (2015) <doi:10.1155/2015/606707>, Chen, P., Yu, H.(2014) <doi:10.1155/2014/242809>, Zeng, B., Li, S., Meng, W., Zhang, D. (2019) <doi:10.1371/journal.pone.0221333>, Liu, L., Wu, L. (2021) <doi:10.1016/j.apm.2020.08.080>, Hu, Y. (2020) <doi:10.1007/s00500-020-04765-3>, Zhou, P., Ang, B., Poh, K. (2006) <doi:10.1016/j.energy.2005.12.002>, Cheng, M., Li, J., Liu, Y., Liu, B. (2020) <doi:10.3390/su12020698>, Wang, H., Wang, P., Senel, M., Li, T. (2019) <doi:10.1155/2019/9049815>, Ding, S., Li, R. (2020) <doi:10.1155/2020/4564653>, Zeng, B., Li, C. (2018) <doi:10.1016/j.cie.2018.02.042>, Xie, N., Liu, S. (2015) <doi:10.1109/JSEE.2015.00013>, Zeng, X., Yan, S., He, F., Shi, Y. (2019) <doi:10.1016/j.apm.2019.11.032>.    "
  },
  {
    "id": 3937,
    "package_name": "HDTSA",
    "title": "High Dimensional Time Series Analysis Tools",
    "description": "An implementation for high-dimensional time series analysis methods, including factor model for vector time series \n      proposed by Lam and Yao (2012) <doi:10.1214/12-AOS970> and Chang, Guo and Yao (2015)\n      <doi:10.1016/j.jeconom.2015.03.024>, martingale difference test proposed by \n      Chang, Jiang and Shao (2023) <doi:10.1016/j.jeconom.2022.09.001>, principal \n      component analysis for vector time series proposed by Chang, Guo and Yao (2018) <doi:10.1214/17-AOS1613>,\n      cointegration analysis proposed by Zhang, Robinson and Yao (2019)\n      <doi:10.1080/01621459.2018.1458620>, unit root test proposed by Chang, Cheng and Yao (2022)\n      <doi:10.1093/biomet/asab034>, white noise test proposed by Chang, Yao and Zhou (2017)\n      <doi:10.1093/biomet/asw066>, CP-decomposition for matrix time \n      series proposed by Chang et al. (2023) <doi:10.1093/jrsssb/qkac011> and\n      Chang et al. (2024) <doi:10.48550/arXiv.2410.05634>, and statistical inference for\n      spectral density matrix proposed by Chang et al. (2022) \n      <doi:10.48550/arXiv.2212.13686>.",
    "version": "1.0.5-1",
    "maintainer": "Chen Lin <linchen@smail.swufe.edu.cn>",
    "author": "Jinyuan Chang [aut],\n  Jing He [aut],\n  Chen Lin [aut, cre],\n  Qiwei Yao [aut]",
    "url": "https://github.com/Linc2021/HDTSA",
    "bug_reports": "https://github.com/Linc2021/HDTSA/issues",
    "repository": "https://cran.r-project.org/package=HDTSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HDTSA High Dimensional Time Series Analysis Tools An implementation for high-dimensional time series analysis methods, including factor model for vector time series \n      proposed by Lam and Yao (2012) <doi:10.1214/12-AOS970> and Chang, Guo and Yao (2015)\n      <doi:10.1016/j.jeconom.2015.03.024>, martingale difference test proposed by \n      Chang, Jiang and Shao (2023) <doi:10.1016/j.jeconom.2022.09.001>, principal \n      component analysis for vector time series proposed by Chang, Guo and Yao (2018) <doi:10.1214/17-AOS1613>,\n      cointegration analysis proposed by Zhang, Robinson and Yao (2019)\n      <doi:10.1080/01621459.2018.1458620>, unit root test proposed by Chang, Cheng and Yao (2022)\n      <doi:10.1093/biomet/asab034>, white noise test proposed by Chang, Yao and Zhou (2017)\n      <doi:10.1093/biomet/asw066>, CP-decomposition for matrix time \n      series proposed by Chang et al. (2023) <doi:10.1093/jrsssb/qkac011> and\n      Chang et al. (2024) <doi:10.48550/arXiv.2410.05634>, and statistical inference for\n      spectral density matrix proposed by Chang et al. (2022) \n      <doi:10.48550/arXiv.2212.13686>.  "
  },
  {
    "id": 3941,
    "package_name": "HDcpDetect",
    "title": "Detect Change Points in Means of High Dimensional Data",
    "description": "Objective: Implement new methods for detecting change points in high-dimensional time series data. These new methods can be applied to non-Gaussian data, account for spatial and temporal dependence, and detect a wide variety of change-point configurations, including changes near the boundary and changes in close proximity. Additionally, this package helps address the \u201csmall n, large p\u201d problem, which occurs in many research contexts. This problem arises when a dataset contains changes that are visually evident but do not rise to the level of statistical significance due to the small number of observations and large number of parameters. The problem is overcome by treating the dimensions as a whole and scaling the test statistics only by its standard deviation, rather than scaling each dimension individually. Due to the computational complexity of the functions, the package runs best on datasets with a relatively large number of attributes but no more than a few hundred observations.",
    "version": "0.1.0",
    "maintainer": "Natasha Stewart <natashastewart@utexas.edu>",
    "author": "Jeffrey Okamoto [aut],\n        Natasha Stewart [aut],\n        Dr. Jun Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HDcpDetect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HDcpDetect Detect Change Points in Means of High Dimensional Data Objective: Implement new methods for detecting change points in high-dimensional time series data. These new methods can be applied to non-Gaussian data, account for spatial and temporal dependence, and detect a wide variety of change-point configurations, including changes near the boundary and changes in close proximity. Additionally, this package helps address the \u201csmall n, large p\u201d problem, which occurs in many research contexts. This problem arises when a dataset contains changes that are visually evident but do not rise to the level of statistical significance due to the small number of observations and large number of parameters. The problem is overcome by treating the dimensions as a whole and scaling the test statistics only by its standard deviation, rather than scaling each dimension individually. Due to the computational complexity of the functions, the package runs best on datasets with a relatively large number of attributes but no more than a few hundred observations.  "
  },
  {
    "id": 3945,
    "package_name": "HEDA",
    "title": "'Hydropeaking Events Detection Algorithm'",
    "description": "This tool identifies hydropeaking events from raw time-series flow record, a rapid flow variation induced by the hourly-adjusted electricity market. The novelty of 'HEDA' is to use vector angle instead of the first-order derivative to detect change points which not only largely improves the computing efficiency but also accounts for the rate of change of the flow variation. More details <doi:10.1016/j.jhydrol.2021.126392>.",
    "version": "0.1.5",
    "maintainer": "Tingyu Li <styli@ucdavis.edu>",
    "author": "Tingyu Li [aut, cre],\n  Xiaotian Zou [aut],\n  Gregory Pasternack [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HEDA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HEDA 'Hydropeaking Events Detection Algorithm' This tool identifies hydropeaking events from raw time-series flow record, a rapid flow variation induced by the hourly-adjusted electricity market. The novelty of 'HEDA' is to use vector angle instead of the first-order derivative to detect change points which not only largely improves the computing efficiency but also accounts for the rate of change of the flow variation. More details <doi:10.1016/j.jhydrol.2021.126392>.  "
  },
  {
    "id": 3971,
    "package_name": "HMMpa",
    "title": "Analysing Accelerometer Data Using Hidden Markov Models",
    "description": "Analysing time-series accelerometer data to quantify length and \n             intensity of physical activity using hidden Markov models. \n             It also contains the traditional cut-off point method.\n             Witowski V, Foraita R, Pitsiladis Y, Pigeot I, Wirsik N (2014).\n             <doi:10.1371/journal.pone.0114089>.",
    "version": "1.0.2",
    "maintainer": "Foraita Ronja <foraita@leibniz-bips.de>",
    "author": "Vitali Witowski [aut],\n  Foraita Ronja [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-2216-6653>)",
    "url": "https://github.com/bips-hb/HMMpa",
    "bug_reports": "https://github.com/bips-hb/HMMpa/issues",
    "repository": "https://cran.r-project.org/package=HMMpa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HMMpa Analysing Accelerometer Data Using Hidden Markov Models Analysing time-series accelerometer data to quantify length and \n             intensity of physical activity using hidden Markov models. \n             It also contains the traditional cut-off point method.\n             Witowski V, Foraita R, Pitsiladis Y, Pigeot I, Wirsik N (2014).\n             <doi:10.1371/journal.pone.0114089>.  "
  },
  {
    "id": 4013,
    "package_name": "Hassani.SACF",
    "title": "Computing Lower Bound of Ljung-Box Test",
    "description": "The Ljung-Box test is one of the most important tests for time series diagnostics and model selection. \n    The  Hassani SACF (Sum of the Sample Autocorrelation Function) Theorem , however, indicates that the sum of sample autocorrelation function is always fix for \n    any stationary time series with arbitrary length. This package confirms for sensitivity of the Ljung-Box test to \n    the number of lags involved in the test and therefore it should be used with extra caution.\n    The Hassani SACF Theorem has been described in : Hassani, Yeganegi and M. R. (2019) <doi:10.1016/j.physa.2018.12.028>.",
    "version": "2.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Masoud Yarmohammdi [aut],\n  Mohammad Reza Yeganegi [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Hassani.SACF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Hassani.SACF Computing Lower Bound of Ljung-Box Test The Ljung-Box test is one of the most important tests for time series diagnostics and model selection. \n    The  Hassani SACF (Sum of the Sample Autocorrelation Function) Theorem , however, indicates that the sum of sample autocorrelation function is always fix for \n    any stationary time series with arbitrary length. This package confirms for sensitivity of the Ljung-Box test to \n    the number of lags involved in the test and therefore it should be used with extra caution.\n    The Hassani SACF Theorem has been described in : Hassani, Yeganegi and M. R. (2019) <doi:10.1016/j.physa.2018.12.028>.  "
  },
  {
    "id": 4014,
    "package_name": "Hassani.Silva",
    "title": "A Test for Comparing the Predictive Accuracy of Two Sets of\nForecasts",
    "description": "A non-parametric test founded upon the principles of the Kolmogorov-Smirnov (KS) \n  test, referred to as the KS Predictive Accuracy (KSPA) test. The KSPA test is able to serve\n  two distinct purposes. Initially, the test seeks to determine whether there exists a \n  statistically significant difference between the distribution of forecast errors, and \n  secondly it exploits the principles of stochastic dominance to determine whether the \n  forecasts with the lower error also reports a stochastically smaller error than forecasts \n  from a competing model, and thereby enables distinguishing between the predictive accuracy \n  of forecasts. KSPA test has been described in : Hassani and Silva (2015) <doi:10.3390/econometrics3030590>.",
    "version": "1.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Emmanuel Sirimal Silva [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Hassani.Silva",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Hassani.Silva A Test for Comparing the Predictive Accuracy of Two Sets of\nForecasts A non-parametric test founded upon the principles of the Kolmogorov-Smirnov (KS) \n  test, referred to as the KS Predictive Accuracy (KSPA) test. The KSPA test is able to serve\n  two distinct purposes. Initially, the test seeks to determine whether there exists a \n  statistically significant difference between the distribution of forecast errors, and \n  secondly it exploits the principles of stochastic dominance to determine whether the \n  forecasts with the lower error also reports a stochastically smaller error than forecasts \n  from a competing model, and thereby enables distinguishing between the predictive accuracy \n  of forecasts. KSPA test has been described in : Hassani and Silva (2015) <doi:10.3390/econometrics3030590>.  "
  },
  {
    "id": 4020,
    "package_name": "HelpersMG",
    "title": "Tools for Environmental Analyses, Ecotoxicology and Various R\nFunctions",
    "description": "Contains miscellaneous functions useful for managing 'NetCDF' files (see <https://en.wikipedia.org/wiki/NetCDF>), get moon phase and time for sun rise and fall, tide level, analyse and reconstruct periodic time series of temperature with irregular sinusoidal pattern, show scales and wind rose in plot with change of color of text, Metropolis-Hastings algorithm for Bayesian MCMC analysis, plot graphs or boxplot with error bars, search files in disk by there names or their content, read the contents of all files from a folder at one time.",
    "version": "6.6",
    "maintainer": "Marc Girondot <marc.girondot@gmail.com>",
    "author": "Marc Girondot [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6645-8530>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HelpersMG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HelpersMG Tools for Environmental Analyses, Ecotoxicology and Various R\nFunctions Contains miscellaneous functions useful for managing 'NetCDF' files (see <https://en.wikipedia.org/wiki/NetCDF>), get moon phase and time for sun rise and fall, tide level, analyse and reconstruct periodic time series of temperature with irregular sinusoidal pattern, show scales and wind rose in plot with change of color of text, Metropolis-Hastings algorithm for Bayesian MCMC analysis, plot graphs or boxplot with error bars, search files in disk by there names or their content, read the contents of all files from a folder at one time.  "
  },
  {
    "id": 4036,
    "package_name": "HistDAWass",
    "title": "Histogram-Valued Data Analysis",
    "description": "In the framework of Symbolic Data Analysis, a relatively new\n    approach to the statistical analysis of multi-valued data, we consider\n    histogram-valued data, i.e., data described by univariate histograms. The\n    methods and the basic statistics for histogram-valued data are mainly based\n    on the L2 Wasserstein metric between distributions, i.e., the Euclidean metric\n    between quantile functions. The package contains unsupervised classification\n    techniques, least square regression and tools for histogram-valued data and for\n    histogram time series. An introducing paper is Irpino A. Verde R. (2015) <doi: 10.1007/s11634-014-0176-4>.",
    "version": "1.0.8",
    "maintainer": "Antonio Irpino <antonio.irpino@unicampania.it>",
    "author": "Antonio Irpino [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9293-7180>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HistDAWass",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HistDAWass Histogram-Valued Data Analysis In the framework of Symbolic Data Analysis, a relatively new\n    approach to the statistical analysis of multi-valued data, we consider\n    histogram-valued data, i.e., data described by univariate histograms. The\n    methods and the basic statistics for histogram-valued data are mainly based\n    on the L2 Wasserstein metric between distributions, i.e., the Euclidean metric\n    between quantile functions. The package contains unsupervised classification\n    techniques, least square regression and tools for histogram-valued data and for\n    histogram time series. An introducing paper is Irpino A. Verde R. (2015) <doi: 10.1007/s11634-014-0176-4>.  "
  },
  {
    "id": 4048,
    "package_name": "Horsekicks",
    "title": "Provide Extensions to the Prussian Army Death by Horsekick Data",
    "description": "We provide extensions to the classical dataset \"Example 4:\n             Death by the kick of a horse in the Prussian Army\" first\n\t           used by Ladislaus von Bortkeiwicz in his treatise on\n\t           the Poisson distribution \"Das Gesetz der kleinen Zahlen\",\n\t           <DOI:10.1017/S0370164600019453>.  As well as an\n\t           extended time series for the horse-kick death data, we also\n             provide, in parallel, deaths by falling from a horse and by\n\t     drowning.",
    "version": "1.0.2",
    "maintainer": "Bill Venables <bill.venables@gmail.com>",
    "author": "Bill Venables [aut, cre],\n  Antony Unwin [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Horsekicks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Horsekicks Provide Extensions to the Prussian Army Death by Horsekick Data We provide extensions to the classical dataset \"Example 4:\n             Death by the kick of a horse in the Prussian Army\" first\n\t           used by Ladislaus von Bortkeiwicz in his treatise on\n\t           the Poisson distribution \"Das Gesetz der kleinen Zahlen\",\n\t           <DOI:10.1017/S0370164600019453>.  As well as an\n\t           extended time series for the horse-kick death data, we also\n             provide, in parallel, deaths by falling from a horse and by\n\t     drowning.  "
  },
  {
    "id": 4054,
    "package_name": "HyMETT",
    "title": "Hydrologic Model Evaluation and Time-Series Tools",
    "description": "Facilitates the analysis and evaluation of hydrologic model output and \n    time-series data with functions focused on comparison of modeled (simulated) and observed data, \n    period-of-record statistics, and trends.  ",
    "version": "1.1.3",
    "maintainer": "Colin Penn <cpenn@usgs.gov>",
    "author": "Colin Penn [aut, cre] (ORCID: <https://orcid.org/0000-0002-5195-2744>),\n  Caelan Simeone [aut] (ORCID: <https://orcid.org/0000-0003-3263-6452>),\n  Sara Levin [aut] (ORCID: <https://orcid.org/0000-0002-2448-3129>),\n  Samuel Saxe [aut] (ORCID: <https://orcid.org/0000-0003-1151-8908>),\n  Sydney Foks [aut] (ORCID: <https://orcid.org/0000-0002-7668-9735>),\n  Robert Dudley [dtc] (ORCID: <https://orcid.org/0000-0002-0934-0568>),\n  Glenn Hodgkins [dtc] (ORCID: <https://orcid.org/0000-0002-4916-5565>),\n  Timothy Hodson [aut] (ORCID: <https://orcid.org/0000-0003-0962-5130>),\n  Thomas Over [dtc] (ORCID: <https://orcid.org/0000-0001-8280-4368>),\n  Amy Russell [dtc] (ORCID: <https://orcid.org/0000-0003-0582-0094>)",
    "url": "https://code.usgs.gov/hymett/hymett",
    "bug_reports": "https://code.usgs.gov/hymett/hymett/-/issues",
    "repository": "https://cran.r-project.org/package=HyMETT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HyMETT Hydrologic Model Evaluation and Time-Series Tools Facilitates the analysis and evaluation of hydrologic model output and \n    time-series data with functions focused on comparison of modeled (simulated) and observed data, \n    period-of-record statistics, and trends.    "
  },
  {
    "id": 4075,
    "package_name": "IBMPopSim",
    "title": "Individual Based Model Population Simulation",
    "description": "Simulation of the random evolution of heterogeneous populations using stochastic Individual-Based Models (IBMs) <doi:10.48550/arXiv.2303.06183>. \n    The package enables users to simulate population evolution, in which individuals are characterized by their age and some characteristics, and the population is modified by different types of events, including births/arrivals, death/exit events, or changes of characteristics. The frequency at which an event can occur to an individual can depend on their age and characteristics, but also on the characteristics of other individuals (interactions). \n    Such models have a wide range of applications. For instance, IBMs can be used for simulating the evolution of a heterogeneous insurance portfolio with selection or for validating  mortality forecasts. \n    This package overcomes the limitations of time-consuming IBMs simulations by implementing new efficient algorithms  based on thinning methods, which are compiled using the 'Rcpp' package while providing a user-friendly interface.",
    "version": "1.1.0",
    "maintainer": "Daphn\u00e9 Giorgi <daphne.giorgi@sorbonne-universite.fr>",
    "author": "Daphn\u00e9 Giorgi [aut, cre],\n  Sarah Kaakai [aut],\n  Vincent Lemaire [aut]",
    "url": "https://github.com/DaphneGiorgi/IBMPopSim,\nhttps://DaphneGiorgi.github.io/IBMPopSim/",
    "bug_reports": "https://github.com/DaphneGiorgi/IBMPopSim/issues",
    "repository": "https://cran.r-project.org/package=IBMPopSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IBMPopSim Individual Based Model Population Simulation Simulation of the random evolution of heterogeneous populations using stochastic Individual-Based Models (IBMs) <doi:10.48550/arXiv.2303.06183>. \n    The package enables users to simulate population evolution, in which individuals are characterized by their age and some characteristics, and the population is modified by different types of events, including births/arrivals, death/exit events, or changes of characteristics. The frequency at which an event can occur to an individual can depend on their age and characteristics, but also on the characteristics of other individuals (interactions). \n    Such models have a wide range of applications. For instance, IBMs can be used for simulating the evolution of a heterogeneous insurance portfolio with selection or for validating  mortality forecasts. \n    This package overcomes the limitations of time-consuming IBMs simulations by implementing new efficient algorithms  based on thinning methods, which are compiled using the 'Rcpp' package while providing a user-friendly interface.  "
  },
  {
    "id": 4105,
    "package_name": "ICompELM",
    "title": "Independent Component Analysis Based Extreme Learning Machine",
    "description": "Single Layer Feed-forward Neural networks (SLFNs) have many applications in various fields of statistical modelling, especially for time-series forecasting. However, there are some major disadvantages of training such networks via the widely accepted 'gradient-based backpropagation' algorithm, such as convergence to local minima, dependencies on learning rate and large training time. These concerns were addressed by Huang et al. (2006) <doi:10.1016/j.neucom.2005.12.126>, wherein they introduced the Extreme Learning Machine (ELM), an extremely fast learning algorithm for SLFNs which randomly chooses the weights connecting input and hidden nodes and analytically determines the output weights of SLFNs. It shows good generalized performance, but is still subject to a high degree of randomness. To mitigate this issue, this package uses a dimensionality reduction technique given in Hyvarinen (1999) <doi:10.1109/72.761722>, namely, the Independent Component Analysis (ICA) to determine the input-hidden connections and thus, remove any sort of randomness from the algorithm. This leads to a robust, fast and stable ELM model. Using functions within this package, the proposed model can also be compared with an existing alternative based on the Principal Component Analysis (PCA) algorithm given by Pearson (1901) <doi:10.1080/14786440109462720>, i.e., the PCA based ELM model given by Castano et al. (2013) <doi:10.1007/s11063-012-9253-x>, from which the implemented ICA based algorithm is greatly inspired.",
    "version": "0.1.0",
    "maintainer": "Saikath Das <saikathdas007@gmail.com>",
    "author": "Saikath Das [aut, cre],\n  Ranjit Kumar Paul [aut],\n  Md Yeasin [aut],\n  Amrit Kumar Paul [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ICompELM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ICompELM Independent Component Analysis Based Extreme Learning Machine Single Layer Feed-forward Neural networks (SLFNs) have many applications in various fields of statistical modelling, especially for time-series forecasting. However, there are some major disadvantages of training such networks via the widely accepted 'gradient-based backpropagation' algorithm, such as convergence to local minima, dependencies on learning rate and large training time. These concerns were addressed by Huang et al. (2006) <doi:10.1016/j.neucom.2005.12.126>, wherein they introduced the Extreme Learning Machine (ELM), an extremely fast learning algorithm for SLFNs which randomly chooses the weights connecting input and hidden nodes and analytically determines the output weights of SLFNs. It shows good generalized performance, but is still subject to a high degree of randomness. To mitigate this issue, this package uses a dimensionality reduction technique given in Hyvarinen (1999) <doi:10.1109/72.761722>, namely, the Independent Component Analysis (ICA) to determine the input-hidden connections and thus, remove any sort of randomness from the algorithm. This leads to a robust, fast and stable ELM model. Using functions within this package, the proposed model can also be compared with an existing alternative based on the Principal Component Analysis (PCA) algorithm given by Pearson (1901) <doi:10.1080/14786440109462720>, i.e., the PCA based ELM model given by Castano et al. (2013) <doi:10.1007/s11063-012-9253-x>, from which the implemented ICA based algorithm is greatly inspired.  "
  },
  {
    "id": 4108,
    "package_name": "ICvectorfields",
    "title": "Vector Fields from Spatial Time Series of Population Abundance",
    "description": "Functions for converting time series of spatial abundance or density \n    data in raster format to vector fields of population movement using the digital \n    image correlation technique. More specifically, the functions in the package \n    compute cross-covariance using discrete fast Fourier transforms for computational \n    efficiency. Vectors in vector fields point in the direction of highest two \n    dimensional cross-covariance. The package has a novel implementation of the \n    digital image correlation algorithm that is designed to detect persistent \n    directional movement when image time series extend beyond a sequence of \n    two raster images. ",
    "version": "0.1.2",
    "maintainer": "Devin Goodsman <goodsman@ualberta.ca>",
    "author": "Devin Goodsman [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1935-5779>)",
    "url": "",
    "bug_reports": "https://github.com/goodsman/ICvectorfields/issues",
    "repository": "https://cran.r-project.org/package=ICvectorfields",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ICvectorfields Vector Fields from Spatial Time Series of Population Abundance Functions for converting time series of spatial abundance or density \n    data in raster format to vector fields of population movement using the digital \n    image correlation technique. More specifically, the functions in the package \n    compute cross-covariance using discrete fast Fourier transforms for computational \n    efficiency. Vectors in vector fields point in the direction of highest two \n    dimensional cross-covariance. The package has a novel implementation of the \n    digital image correlation algorithm that is designed to detect persistent \n    directional movement when image time series extend beyond a sequence of \n    two raster images.   "
  },
  {
    "id": 4110,
    "package_name": "IDE",
    "title": "Integro-Difference Equation Spatio-Temporal Models",
    "description": "The Integro-Difference Equation model is a linear, dynamical model used to model\n   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,\n   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the\n   heart of the model is the kernel, which dictates how the process evolves from one time\n   point to the next. Both process and parameter reduction are used to facilitate computation,\n   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed\n   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted\n   by maximum likelihood, and estimation is carried out using an evolution algorithm. ",
    "version": "0.3.1",
    "maintainer": "Andrew Zammit-Mangion <andrewzm@gmail.com>",
    "author": "Andrew Zammit-Mangion [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/andrewzm/IDE/issues/",
    "repository": "https://cran.r-project.org/package=IDE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IDE Integro-Difference Equation Spatio-Temporal Models The Integro-Difference Equation model is a linear, dynamical model used to model\n   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,\n   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the\n   heart of the model is the kernel, which dictates how the process evolves from one time\n   point to the next. Both process and parameter reduction are used to facilitate computation,\n   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed\n   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted\n   by maximum likelihood, and estimation is carried out using an evolution algorithm.   "
  },
  {
    "id": 4113,
    "package_name": "IDF",
    "title": "Estimation and Plotting of IDF Curves",
    "description": "Intensity-duration-frequency (IDF) curves are a widely used analysis-tool\n              in hydrology to assess extreme values of precipitation\n              [e.g. Mailhot et al., 2007, <doi:10.1016/j.jhydrol.2007.09.019>].\n              The package 'IDF' provides functions to estimate IDF parameters for given\n              precipitation time series on the basis of a duration-dependent\n              generalized extreme value distribution\n              [Koutsoyiannis et al., 1998, <doi:10.1016/S0022-1694(98)00097-3>].",
    "version": "2.1.3",
    "maintainer": "Felix S. Fauer <felix.fauer@met.fu-berlin.de>",
    "author": "Jana Ulrich [aut],\n  Laura Mack [ctb],\n  Oscar E. Jurado [ctb],\n  Felix S. Fauer [ctb, cre],\n  Christoph Ritschel [aut],\n  Carola Detring [ctb],\n  Sarah Joedicke [ctb]",
    "url": "https://gitlab.met.fu-berlin.de/Rpackages/idf_package",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IDF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IDF Estimation and Plotting of IDF Curves Intensity-duration-frequency (IDF) curves are a widely used analysis-tool\n              in hydrology to assess extreme values of precipitation\n              [e.g. Mailhot et al., 2007, <doi:10.1016/j.jhydrol.2007.09.019>].\n              The package 'IDF' provides functions to estimate IDF parameters for given\n              precipitation time series on the basis of a duration-dependent\n              generalized extreme value distribution\n              [Koutsoyiannis et al., 1998, <doi:10.1016/S0022-1694(98)00097-3>].  "
  },
  {
    "id": 4114,
    "package_name": "IDLFM",
    "title": "Individual Dynamic Latent Factor Model",
    "description": "A personalized dynamic latent factor model (Zhang et al. (2024) <doi:10.1093/biomet/asae015>) for irregular multi-resolution time series data, to interpolate unsampled measurements from low-resolution time series.",
    "version": "1.0.0",
    "maintainer": "Siyang Liu <liusiyang.lucia@gmail.com>",
    "author": "Siyang Liu [aut, cre],\n  Jiuchen Zhang [aut],\n  Annie Qu [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IDLFM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IDLFM Individual Dynamic Latent Factor Model A personalized dynamic latent factor model (Zhang et al. (2024) <doi:10.1093/biomet/asae015>) for irregular multi-resolution time series data, to interpolate unsampled measurements from low-resolution time series.  "
  },
  {
    "id": 4129,
    "package_name": "IETD",
    "title": "Inter-Event Time Definition",
    "description": "Computes characteristics of independent rainfall events (duration, total rainfall depth, and intensity) \n  extracted from a sub-daily rainfall time series based on the inter-event time definition (IETD) method. To have a \n  reference value of IETD, it also analyzes/computes IETD values through three methods: autocorrelation analysis, the \n  average annual number of events analysis, and coefficient of variation analysis. Ideal for analyzing the sensitivity \n  of IETD to characteristics of independent rainfall events.\n  Adams B, Papa F (2000) <ISBN: 978-0-471-33217-6>.\n  Joo J et al. (2014) <doi:10.3390/w6010045>.\n  Restrepo-Posada P, Eagleson P (1982) <doi:10.1016/0022-1694(82)90136-6>.",
    "version": "1.0.0",
    "maintainer": "Luis F. Duque <lfduquey@gmail.com>",
    "author": "Luis F. Duque <lfduquey@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IETD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IETD Inter-Event Time Definition Computes characteristics of independent rainfall events (duration, total rainfall depth, and intensity) \n  extracted from a sub-daily rainfall time series based on the inter-event time definition (IETD) method. To have a \n  reference value of IETD, it also analyzes/computes IETD values through three methods: autocorrelation analysis, the \n  average annual number of events analysis, and coefficient of variation analysis. Ideal for analyzing the sensitivity \n  of IETD to characteristics of independent rainfall events.\n  Adams B, Papa F (2000) <ISBN: 978-0-471-33217-6>.\n  Joo J et al. (2014) <doi:10.3390/w6010045>.\n  Restrepo-Posada P, Eagleson P (1982) <doi:10.1016/0022-1694(82)90136-6>.  "
  },
  {
    "id": 4142,
    "package_name": "ILRCM",
    "title": "Convert Irregular Longitudinal Data to Regular Intervals and\nPerform Clustering",
    "description": "Convert irregularly spaced longitudinal data into regular intervals for further analysis, \n             and perform clustering using advanced machine learning techniques. \n             The package is designed for handling complex longitudinal datasets, \n             optimizing them for research in healthcare, demography, and other fields \n             requiring temporal data modeling.",
    "version": "0.2.0",
    "maintainer": "Atanu Bhattacharjee <atanustat@gmail.com>",
    "author": "Atanu Bhattacharjee [aut, cre, ctb],\n  Tanmoy Majumdar [aut, ctb],\n  Gajendra Kumar Vishwakarma [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ILRCM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ILRCM Convert Irregular Longitudinal Data to Regular Intervals and\nPerform Clustering Convert irregularly spaced longitudinal data into regular intervals for further analysis, \n             and perform clustering using advanced machine learning techniques. \n             The package is designed for handling complex longitudinal datasets, \n             optimizing them for research in healthcare, demography, and other fields \n             requiring temporal data modeling.  "
  },
  {
    "id": 4156,
    "package_name": "INFOSET",
    "title": "Computing a New Informative Distribution Set of Asset Returns",
    "description": "Estimation of the most-left informative set of gross returns \n             (i.e., the informative set).\n             The procedure to compute the informative set adjusts the method \n             proposed by \n             Mariani et al. (2022a) <doi:10.1007/s11205-020-02440-6> \n             and \n             Mariani et al. (2022b) <doi:10.1007/s10287-022-00422-2> \n             to gross returns of financial assets. \n             This is accomplished through an adaptive algorithm\n             that identifies sub-groups of gross returns in \n             each iteration by approximating their distribution with a\n             sequence of two-component log-normal mixtures. \n             These sub-groups emerge when a significant change\n             in the distribution occurs below the median of the \n             financial returns, with their boundary termed as\n             the \u201cchange point\" of the mixture. \n             The process concludes when no further change points are detected.\n             The outcome encompasses parameters of the leftmost mixture \n             distributions and change points of the\n             analyzed financial time series.\n             The functionalities of the INFOSET package include: (i) modelling asset distribution\n             detecting the parameters which describe left tail behaviour (infoset function), (ii) clustering, (iii) labeling of the financial\n             series for predictive and classification purposes through a Left Risk measure based on the first change point (LR_cp function)\n             (iv) portfolio construction (ptf_construction function).\n             The package also provide a specific function to construct rolling windows of different length size and overlapping time.",
    "version": "4.1",
    "maintainer": "Gloria Polinesi <g.polinesi@staff.univpm.it>",
    "author": "Gloria Polinesi [aut, cre],\n  Francesca Mariani [aut],\n  Maria Cristina Recchioni [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=INFOSET",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "INFOSET Computing a New Informative Distribution Set of Asset Returns Estimation of the most-left informative set of gross returns \n             (i.e., the informative set).\n             The procedure to compute the informative set adjusts the method \n             proposed by \n             Mariani et al. (2022a) <doi:10.1007/s11205-020-02440-6> \n             and \n             Mariani et al. (2022b) <doi:10.1007/s10287-022-00422-2> \n             to gross returns of financial assets. \n             This is accomplished through an adaptive algorithm\n             that identifies sub-groups of gross returns in \n             each iteration by approximating their distribution with a\n             sequence of two-component log-normal mixtures. \n             These sub-groups emerge when a significant change\n             in the distribution occurs below the median of the \n             financial returns, with their boundary termed as\n             the \u201cchange point\" of the mixture. \n             The process concludes when no further change points are detected.\n             The outcome encompasses parameters of the leftmost mixture \n             distributions and change points of the\n             analyzed financial time series.\n             The functionalities of the INFOSET package include: (i) modelling asset distribution\n             detecting the parameters which describe left tail behaviour (infoset function), (ii) clustering, (iii) labeling of the financial\n             series for predictive and classification purposes through a Left Risk measure based on the first change point (LR_cp function)\n             (iv) portfolio construction (ptf_construction function).\n             The package also provide a specific function to construct rolling windows of different length size and overlapping time.  "
  },
  {
    "id": 4159,
    "package_name": "INLAspacetime",
    "title": "Spatial and Spatio-Temporal Models using 'INLA'",
    "description": "Prepare objects to implement models over spatial and \n  spacetime domains with the 'INLA' package (<https://www.r-inla.org>).\n  These objects contain data to for the 'cgeneric' interface in\n  'INLA', enabling fast parallel computations.\n  We implemented the spatial barrier model, see Bakka et. al. (2019) \n  <doi:10.1016/j.spasta.2019.01.002>, and some of the spatio-temporal \n  models proposed in Lindgren et. al. (2023) \n  <https://www.idescat.cat/sort/sort481/48.1.1.Lindgren-etal.pdf>. \n  Details are provided in the available vignettes and from the URL bellow.",
    "version": "0.1.12",
    "maintainer": "Elias Teixeira Krainski <eliaskrainski@gmail.com>",
    "author": "Elias Teixeira Krainski [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7063-2615>),\n  Finn Lindgren [aut] (ORCID: <https://orcid.org/0000-0002-5833-2011>),\n  Haavard Rue [aut] (ORCID: <https://orcid.org/0000-0002-0222-1881>)",
    "url": "https://github.com/eliaskrainski/INLAspacetime",
    "bug_reports": "https://github.com/eliaskrainski/INLAspacetime/issues",
    "repository": "https://cran.r-project.org/package=INLAspacetime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "INLAspacetime Spatial and Spatio-Temporal Models using 'INLA' Prepare objects to implement models over spatial and \n  spacetime domains with the 'INLA' package (<https://www.r-inla.org>).\n  These objects contain data to for the 'cgeneric' interface in\n  'INLA', enabling fast parallel computations.\n  We implemented the spatial barrier model, see Bakka et. al. (2019) \n  <doi:10.1016/j.spasta.2019.01.002>, and some of the spatio-temporal \n  models proposed in Lindgren et. al. (2023) \n  <https://www.idescat.cat/sort/sort481/48.1.1.Lindgren-etal.pdf>. \n  Details are provided in the available vignettes and from the URL bellow.  "
  },
  {
    "id": 4160,
    "package_name": "INLAtools",
    "title": "Functionalities for the 'INLA' Package",
    "description": "Contain code to work with a C struct, in short\n  cgeneric, to define a Gaussian Markov random (GMRF) model.\n  The cgeneric contain code to specify GMRF elements such as\n  the graph and the precision matrix, and also the initial and \n  prior for its parameters, useful for model inference. \n  It can be accessed from a C program and is the recommended \n  way to implement new GMRF models in the 'INLA' package \n  (<https://www.r-inla.org>).\n  The 'INLAtools' implement functions to evaluate \n  each one of the model specifications from R.\n  The implemented functionalities leverage the use \n  of 'cgeneric' models and provide a way to debug \n  the code as well to work with the prior for the \n  model parameters and to sample from it. \n  A very useful functionality is the Kronecker product method \n  that creates a new model from multiple cgeneric models.\n  It also works with the rgeneric, the R version of the \n  cgeneric intended to easy try implementation of new GMRF models.\n  The Kronecker between two cgeneric models was used in \n  Sterrantino et. al. (2024) <doi:10.1007/s10260-025-00788-y>,\n  and can be used to build the spatio-temporal intrinsic interaction \n  models for what the needed constraints are automatically set.",
    "version": "0.0.5",
    "maintainer": "Elias Teixeira Krainski <eliaskrainski@gmail.com>",
    "author": "Elias Teixeira Krainski [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7063-2615>),\n  Finn Lindgren [aut] (ORCID: <https://orcid.org/0000-0002-5833-2011>),\n  Haavard Rue\u2019 [aut] (ORCID: <https://orcid.org/0000-0002-0222-1881>)",
    "url": "https://github.com/eliaskrainski/INLAtools",
    "bug_reports": "https://github.com/eliaskrainski/INLAtools/issues",
    "repository": "https://cran.r-project.org/package=INLAtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "INLAtools Functionalities for the 'INLA' Package Contain code to work with a C struct, in short\n  cgeneric, to define a Gaussian Markov random (GMRF) model.\n  The cgeneric contain code to specify GMRF elements such as\n  the graph and the precision matrix, and also the initial and \n  prior for its parameters, useful for model inference. \n  It can be accessed from a C program and is the recommended \n  way to implement new GMRF models in the 'INLA' package \n  (<https://www.r-inla.org>).\n  The 'INLAtools' implement functions to evaluate \n  each one of the model specifications from R.\n  The implemented functionalities leverage the use \n  of 'cgeneric' models and provide a way to debug \n  the code as well to work with the prior for the \n  model parameters and to sample from it. \n  A very useful functionality is the Kronecker product method \n  that creates a new model from multiple cgeneric models.\n  It also works with the rgeneric, the R version of the \n  cgeneric intended to easy try implementation of new GMRF models.\n  The Kronecker between two cgeneric models was used in \n  Sterrantino et. al. (2024) <doi:10.1007/s10260-025-00788-y>,\n  and can be used to build the spatio-temporal intrinsic interaction \n  models for what the needed constraints are automatically set.  "
  },
  {
    "id": 4161,
    "package_name": "INQC",
    "title": "Quality Control of Climatological Daily Time Series",
    "description": "Collection of functions for quality control (QC) of climatological daily time series (e.g. the ECA&D station data).",
    "version": "2.0.5",
    "maintainer": "Enric Aguilar <enric.aguilar@urv.cat>",
    "author": "Enric Aguilar [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8384-377X>),\n  Oleg Skrynyk [aut] (ORCID: <https://orcid.org/0000-0001-8827-0280>)",
    "url": "https://github.com/INDECIS-Project/INQC",
    "bug_reports": "https://github.com/INDECIS-Project/INQC/issues",
    "repository": "https://cran.r-project.org/package=INQC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "INQC Quality Control of Climatological Daily Time Series Collection of functions for quality control (QC) of climatological daily time series (e.g. the ECA&D station data).  "
  },
  {
    "id": 4229,
    "package_name": "IncDTW",
    "title": "Incremental Calculation of Dynamic Time Warping",
    "description": "The Dynamic Time Warping (DTW) distance measure for time series allows non-linear alignments of time series to match  similar patterns in time series of different lengths and or different speeds. IncDTW is characterized by (1) the incremental calculation of DTW (reduces runtime complexity to a linear level for updating the DTW distance) - especially for life data streams or subsequence matching, (2) the vector based implementation of DTW which is faster because no matrices are allocated (reduces the space complexity from a quadratic to a linear level in the number of observations) - for all runtime intensive DTW computations, (3) the subsequence matching algorithm runDTW, that efficiently finds the k-NN to a query pattern in a long time series, and (4) C++ in the heart. For details about DTW see the original paper \"Dynamic programming algorithm optimization for spoken word recognition\" by Sakoe and Chiba (1978) <DOI:10.1109/TASSP.1978.1163055>. For details about this package, Dynamic Time Warping and Incremental Dynamic Time Warping please see \"IncDTW: An R Package for Incremental Calculation of Dynamic Time Warping\" by Leodolter et al. (2021) <doi:10.18637/jss.v099.i09>.",
    "version": "1.1.4.5",
    "maintainer": "Maximilian Leodolter <maximilian.leodolter@gmail.com>",
    "author": "Maximilian Leodolter [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IncDTW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IncDTW Incremental Calculation of Dynamic Time Warping The Dynamic Time Warping (DTW) distance measure for time series allows non-linear alignments of time series to match  similar patterns in time series of different lengths and or different speeds. IncDTW is characterized by (1) the incremental calculation of DTW (reduces runtime complexity to a linear level for updating the DTW distance) - especially for life data streams or subsequence matching, (2) the vector based implementation of DTW which is faster because no matrices are allocated (reduces the space complexity from a quadratic to a linear level in the number of observations) - for all runtime intensive DTW computations, (3) the subsequence matching algorithm runDTW, that efficiently finds the k-NN to a query pattern in a long time series, and (4) C++ in the heart. For details about DTW see the original paper \"Dynamic programming algorithm optimization for spoken word recognition\" by Sakoe and Chiba (1978) <DOI:10.1109/TASSP.1978.1163055>. For details about this package, Dynamic Time Warping and Incremental Dynamic Time Warping please see \"IncDTW: An R Package for Incremental Calculation of Dynamic Time Warping\" by Leodolter et al. (2021) <doi:10.18637/jss.v099.i09>.  "
  },
  {
    "id": 4232,
    "package_name": "IndGenErrors",
    "title": "Tests of Independence Between Innovations of Generalized Error\nModels",
    "description": "Computation of test statistics of independence between  (continuous) innovations of time series. They can be used with stochastic volatility models and Hidden Markov Models (HMM). This improves the results in Duchesne, Ghoudi & Remillard (2012) <doi:10.1002/cjs.11141>.",
    "version": "0.1.6",
    "maintainer": "Bruno N Remillard <bruno.remillard@hec.ca>",
    "author": "Kilani Ghoudi [aut, ctb, cph],\n  Bouchra R. Nasri [aut, ctb, cph],\n  Bruno N Remillard [aut, cre, cph],\n  Pierre Duchesne [aut, ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IndGenErrors",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IndGenErrors Tests of Independence Between Innovations of Generalized Error\nModels Computation of test statistics of independence between  (continuous) innovations of time series. They can be used with stochastic volatility models and Hidden Markov Models (HMM). This improves the results in Duchesne, Ghoudi & Remillard (2012) <doi:10.1002/cjs.11141>.  "
  },
  {
    "id": 4235,
    "package_name": "IndexConstruction",
    "title": "Index Construction for Time Series Data",
    "description": "Derivation of indexes for benchmarking purposes. A methodology with flexible number of constituents is implemented. Also functions for market capitalization and volume weighted indexes with fixed number of constituents are available. The main function of the package, indexComp(), provides the derived index, suitable for analysis purposes. The functions indexUpdate(), indexMemberSelection() and indexMembersUpdate() are components of indexComp() and enable one to construct and continuously update an index, e.g. for display on a website. The methodology behind the functions provided gets introduced in Trimborn and Haerdle (2018) <doi:10.1016/j.jempfin.2018.08.004>.",
    "version": "0.1-3",
    "maintainer": "Simon Trimborn <trimborn.econometrics@gmail.com>",
    "author": "Simon Trimborn <trimborn.econometrics@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IndexConstruction",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IndexConstruction Index Construction for Time Series Data Derivation of indexes for benchmarking purposes. A methodology with flexible number of constituents is implemented. Also functions for market capitalization and volume weighted indexes with fixed number of constituents are available. The main function of the package, indexComp(), provides the derived index, suitable for analysis purposes. The functions indexUpdate(), indexMemberSelection() and indexMembersUpdate() are components of indexComp() and enable one to construct and continuously update an index, e.g. for display on a website. The methodology behind the functions provided gets introduced in Trimborn and Haerdle (2018) <doi:10.1016/j.jempfin.2018.08.004>.  "
  },
  {
    "id": 4253,
    "package_name": "InspectChangepoint",
    "title": "High-Dimensional Changepoint Estimation via Sparse Projection",
    "description": "Provides a data-driven projection-based method for estimating changepoints in high-dimensional time series. Multiple changepoints are estimated using a (wild) binary segmentation scheme.",
    "version": "1.2",
    "maintainer": "Tengyao Wang <t.wang59@lse.ac.uk>",
    "author": "Tengyao Wang, Bertille Follain and Richard Samworth",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=InspectChangepoint",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "InspectChangepoint High-Dimensional Changepoint Estimation via Sparse Projection Provides a data-driven projection-based method for estimating changepoints in high-dimensional time series. Multiple changepoints are estimated using a (wild) binary segmentation scheme.  "
  },
  {
    "id": 4260,
    "package_name": "InterNL",
    "title": "Time Series Intervention Model Using Non-Linear Function",
    "description": "Intervention analysis is used to investigate structural changes in data resulting from external events. Traditional time series intervention models, viz. Autoregressive Integrated Moving Average model with exogeneous variables (ARIMA-X) and Artificial Neural Networks with exogeneous variables (ANN-X), rely on linear intervention functions such as step or ramp functions, or their combinations. In this package, the Gompertz, Logistic, Monomolecular, Richard and Hoerl function have been used as non-linear intervention function. The equation of the above models are represented as: Gompertz: A * exp(-B * exp(-k * t)); Logistic: K / (1 + ((K - N0) / N0) * exp(-r * t)); Monomolecular: A * exp(-k * t); Richard: A + (K - A) / (1 + exp(-B * (C - t)))^(1/beta) and Hoerl: a*(b^t)*(t^c).This package introduced algorithm for time series intervention analysis employing ARIMA and ANN models with a non-linear intervention function. This package has been developed using algorithm of Yeasin et al. <doi:10.1016/j.hazadv.2023.100325> and Paul and Yeasin <doi:10.1371/journal.pone.0272999>.",
    "version": "0.1.0",
    "maintainer": "Dr. Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Dr. Amrit Kumar Paul [aut],\n  Dr. Md Yeasin [aut, cre],\n  Dr. Ranjit Kumar Paul [aut],\n  Mr. Subhankar Biswas [aut],\n  Dr. HS Roy [aut],\n  Dr. Prakash Kumar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=InterNL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "InterNL Time Series Intervention Model Using Non-Linear Function Intervention analysis is used to investigate structural changes in data resulting from external events. Traditional time series intervention models, viz. Autoregressive Integrated Moving Average model with exogeneous variables (ARIMA-X) and Artificial Neural Networks with exogeneous variables (ANN-X), rely on linear intervention functions such as step or ramp functions, or their combinations. In this package, the Gompertz, Logistic, Monomolecular, Richard and Hoerl function have been used as non-linear intervention function. The equation of the above models are represented as: Gompertz: A * exp(-B * exp(-k * t)); Logistic: K / (1 + ((K - N0) / N0) * exp(-r * t)); Monomolecular: A * exp(-k * t); Richard: A + (K - A) / (1 + exp(-B * (C - t)))^(1/beta) and Hoerl: a*(b^t)*(t^c).This package introduced algorithm for time series intervention analysis employing ARIMA and ANN models with a non-linear intervention function. This package has been developed using algorithm of Yeasin et al. <doi:10.1016/j.hazadv.2023.100325> and Paul and Yeasin <doi:10.1371/journal.pone.0272999>.  "
  },
  {
    "id": 4297,
    "package_name": "JFE",
    "title": "Tools for Analyzing Time Series Data of Just Finance and\nEconometrics",
    "description": "Offer procedures to download financial-economic time series data and enhanced procedures for computing the investment performance indices of Bacon (2004) <DOI:10.1002/9781119206309>.",
    "version": "2.5.11",
    "maintainer": "Ho Tsung-wu <tsungwu@ntnu.edu.tw>",
    "author": "Ho Tsung-wu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=JFE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "JFE Tools for Analyzing Time Series Data of Just Finance and\nEconometrics Offer procedures to download financial-economic time series data and enhanced procedures for computing the investment performance indices of Bacon (2004) <DOI:10.1002/9781119206309>.  "
  },
  {
    "id": 4346,
    "package_name": "KFAS",
    "title": "Kalman Filter and Smoother for Exponential Family State Space\nModels",
    "description": "State space modelling is an efficient and flexible framework for \n    statistical inference of a broad class of time series and other data. KFAS \n    includes computationally efficient functions for Kalman filtering, smoothing, \n    forecasting, and simulation of multivariate exponential family state space models, \n    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma \n    distributions. See the paper by Helske (2017) <doi:10.18637/jss.v078.i10> for details.",
    "version": "1.6.0",
    "maintainer": "Jouni Helske <jouni.helske@iki.fi>",
    "author": "Jouni Helske [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7130-793X>)",
    "url": "https://github.com/helske/KFAS",
    "bug_reports": "https://github.com/helske/KFAS/issues",
    "repository": "https://cran.r-project.org/package=KFAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KFAS Kalman Filter and Smoother for Exponential Family State Space\nModels State space modelling is an efficient and flexible framework for \n    statistical inference of a broad class of time series and other data. KFAS \n    includes computationally efficient functions for Kalman filtering, smoothing, \n    forecasting, and simulation of multivariate exponential family state space models, \n    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma \n    distributions. See the paper by Helske (2017) <doi:10.18637/jss.v078.i10> for details.  "
  },
  {
    "id": 4360,
    "package_name": "KOFM",
    "title": "Test the Kronecker Product Structure in Tensor Factor Models",
    "description": "To test if a tensor time series following a Tucker-decomposition factor model has a Kronecker product structure. Supplementary functions for tensor reshape and its reversal are also included.",
    "version": "0.1.1",
    "maintainer": "Zetai Cen <z.cen@lse.ac.uk>",
    "author": "Zetai Cen [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=KOFM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KOFM Test the Kronecker Product Structure in Tensor Factor Models To test if a tensor time series following a Tucker-decomposition factor model has a Kronecker product structure. Supplementary functions for tensor reshape and its reversal are also included.  "
  },
  {
    "id": 4381,
    "package_name": "KarsTS",
    "title": "An Interface for Microclimate Time Series Analysis",
    "description": "An R code with a GUI for microclimate time series, with an emphasis on underground environments. 'KarsTS' provides linear and nonlinear methods, including recurrence analysis (Marwan et al. (2007) <doi:10.1016/j.physrep.2006.11.001>) and filling methods (Moffat et al. (2007) <doi:10.1016/j.agrformet.2007.08.011>), as well as tools to manipulate easily time series and gap sets.",
    "version": "2.4.1",
    "maintainer": "Marina Saez <marinasaez_andreu@hotmail.com>",
    "author": "Marina Saez [aut, cre],\n  David Benavente [ths],\n  Soledad Cuezva [ths],\n  Concepcion Pla [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=KarsTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KarsTS An Interface for Microclimate Time Series Analysis An R code with a GUI for microclimate time series, with an emphasis on underground environments. 'KarsTS' provides linear and nonlinear methods, including recurrence analysis (Marwan et al. (2007) <doi:10.1016/j.physrep.2006.11.001>) and filling methods (Moffat et al. (2007) <doi:10.1016/j.agrformet.2007.08.011>), as well as tools to manipulate easily time series and gap sets.  "
  },
  {
    "id": 4417,
    "package_name": "L2hdchange",
    "title": "L2 Inference for Change Points in High-Dimensional Time Series",
    "description": "Provides a method for detecting multiple change points in high-dimensional time\n    series, targeting dense or spatially clustered signals. See Li et al. (2023) \n    \"L2 Inference for Change Points in High-Dimensional Time Series via a Two-Way MOSUM\". \n    arXiv preprint <arXiv:2208.13074>.",
    "version": "1.0",
    "maintainer": "Rui Lin <ruilin1081@gmail.com>",
    "author": "Jiaqi Li [aut],\n  Likai Chen [aut],\n  Weining Wang [aut],\n  Wei Biao Wu [aut],\n  Rui Lin [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=L2hdchange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "L2hdchange L2 Inference for Change Points in High-Dimensional Time Series Provides a method for detecting multiple change points in high-dimensional time\n    series, targeting dense or spatially clustered signals. See Li et al. (2023) \n    \"L2 Inference for Change Points in High-Dimensional Time Series via a Two-Way MOSUM\". \n    arXiv preprint <arXiv:2208.13074>.  "
  },
  {
    "id": 4420,
    "package_name": "LAGOSNE",
    "title": "Interface to the Lake Multi-Scaled Geospatial and Temporal\nDatabase",
    "description": "Client for programmatic access to the Lake\n    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions\n    for accessing lake water quality and ecological context data for the US.",
    "version": "2.0.4",
    "maintainer": "Jemma Stachelek <jemma.stachelek@gmail.com>",
    "author": "Jemma Stachelek [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5924-2464>),\n  Samantha Oliver [aut] (ORCID: <https://orcid.org/0000-0001-5668-1165>),\n  Farzan Masrour [aut]",
    "url": "https://github.com/cont-limno/LAGOSNE,\nhttps://cont-limno.github.io/LAGOSNE/",
    "bug_reports": "https://github.com/cont-limno/LAGOSNE/issues",
    "repository": "https://cran.r-project.org/package=LAGOSNE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LAGOSNE Interface to the Lake Multi-Scaled Geospatial and Temporal\nDatabase Client for programmatic access to the Lake\n    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions\n    for accessing lake water quality and ecological context data for the US.  "
  },
  {
    "id": 4430,
    "package_name": "LBPG",
    "title": "The Length-Biased Power Garima Distribution",
    "description": "The Length-Biased Power Garima distribution for computes the probability density,\n    the cumulative density distribution and the quantile function of the distribution, \n    and generates sample values with random variables based on Kittipong and Sirinapa(2021)<DOI: 10.14456/sjst-psu.2021.89>.",
    "version": "0.1.2",
    "maintainer": "Kittipong Klinjan <kittipong_k@rmutt.ac.th>",
    "author": "Kittipong Klinjan [cre, aut],\n  Onrampa Thepdaeng [aut],\n  Tadaporn Sombunpen [aut],\n  Atchanut Rattanalertnusorn [aut],\n  Sirinapa Aryuyuen [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LBPG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LBPG The Length-Biased Power Garima Distribution The Length-Biased Power Garima distribution for computes the probability density,\n    the cumulative density distribution and the quantile function of the distribution, \n    and generates sample values with random variables based on Kittipong and Sirinapa(2021)<DOI: 10.14456/sjst-psu.2021.89>.  "
  },
  {
    "id": 4439,
    "package_name": "LDATS",
    "title": "Latent Dirichlet Allocation Coupled with Time Series Analyses",
    "description": "Combines Latent Dirichlet Allocation (LDA) and Bayesian multinomial time series methods in a two-stage analysis to quantify dynamics in high-dimensional temporal data. LDA decomposes multivariate data into lower-dimension latent groupings, whose relative proportions are modeled using generalized Bayesian time series models that include abrupt changepoints and smooth dynamics. The methods are described in Blei et al. (2003) <doi:10.1162/jmlr.2003.3.4-5.993>, Western and Kleykamp (2004) <doi:10.1093/pan/mph023>, Venables and Ripley (2002, ISBN-13:978-0387954578), and Christensen et al. (2018) <doi:10.1002/ecy.2373>.",
    "version": "0.3.0",
    "maintainer": "Juniper L. Simonis <juniper.simonis@weecology.org>",
    "author": "Juniper L. Simonis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9798-0460>),\n  Erica M. Christensen [aut] (ORCID:\n    <https://orcid.org/0000-0002-5635-2502>),\n  David J. Harris [aut] (ORCID: <https://orcid.org/0000-0003-3332-9307>),\n  Renata M. Diaz [aut] (ORCID: <https://orcid.org/0000-0003-0803-4734>),\n  Hao Ye [aut] (ORCID: <https://orcid.org/0000-0002-8630-1458>),\n  Ethan P. White [aut] (ORCID: <https://orcid.org/0000-0001-6728-7745>),\n  S.K. Morgan Ernest [aut] (ORCID:\n    <https://orcid.org/0000-0002-6026-8530>),\n  Weecology [cph]",
    "url": "https://weecology.github.io/LDATS/,\nhttps://github.com/weecology/LDATS",
    "bug_reports": "https://github.com/weecology/LDATS/issues",
    "repository": "https://cran.r-project.org/package=LDATS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LDATS Latent Dirichlet Allocation Coupled with Time Series Analyses Combines Latent Dirichlet Allocation (LDA) and Bayesian multinomial time series methods in a two-stage analysis to quantify dynamics in high-dimensional temporal data. LDA decomposes multivariate data into lower-dimension latent groupings, whose relative proportions are modeled using generalized Bayesian time series models that include abrupt changepoints and smooth dynamics. The methods are described in Blei et al. (2003) <doi:10.1162/jmlr.2003.3.4-5.993>, Western and Kleykamp (2004) <doi:10.1093/pan/mph023>, Venables and Ripley (2002, ISBN-13:978-0387954578), and Christensen et al. (2018) <doi:10.1002/ecy.2373>.  "
  },
  {
    "id": 4466,
    "package_name": "LLMAgentR",
    "title": "Language Model Agents in R for AI Workflows and Research",
    "description": "Provides modular, graph-based agents powered by large language models (LLMs) for intelligent task execution in R. \n      Supports structured workflows for tasks such as forecasting, data visualization, feature engineering, data wrangling, data cleaning, 'SQL', code generation, weather reporting, and research-driven question answering. \n      Each agent performs iterative reasoning: recommending steps, generating R code, executing, debugging, and explaining results. \n      Includes built-in support for packages such as 'tidymodels', 'modeltime', 'plotly', 'ggplot2', and 'prophet'. Designed for analysts, developers, and teams building intelligent, reproducible AI workflows in R. \n      Compatible with LLM providers such as 'OpenAI', 'Anthropic', 'Groq', and 'Ollama'. Inspired by the Python package 'langagent'.",
    "version": "0.3.0",
    "maintainer": "Kwadwo Daddy Nyame Owusu Boakye <kwadwo.owusuboakye@outlook.com>",
    "author": "Kwadwo Daddy Nyame Owusu Boakye [aut, cre]",
    "url": "https://github.com/knowusuboaky/LLMAgentR,\nhttps://knowusuboaky.github.io/LLMAgentR/",
    "bug_reports": "https://github.com/knowusuboaky/LLMAgentR/issues",
    "repository": "https://cran.r-project.org/package=LLMAgentR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LLMAgentR Language Model Agents in R for AI Workflows and Research Provides modular, graph-based agents powered by large language models (LLMs) for intelligent task execution in R. \n      Supports structured workflows for tasks such as forecasting, data visualization, feature engineering, data wrangling, data cleaning, 'SQL', code generation, weather reporting, and research-driven question answering. \n      Each agent performs iterative reasoning: recommending steps, generating R code, executing, debugging, and explaining results. \n      Includes built-in support for packages such as 'tidymodels', 'modeltime', 'plotly', 'ggplot2', and 'prophet'. Designed for analysts, developers, and teams building intelligent, reproducible AI workflows in R. \n      Compatible with LLM providers such as 'OpenAI', 'Anthropic', 'Groq', and 'Ollama'. Inspired by the Python package 'langagent'.  "
  },
  {
    "id": 4474,
    "package_name": "LMMsolver",
    "title": "Linear Mixed Models with Sparse Matrix Methods and Smoothing",
    "description": "Provides tools for fitting linear mixed models using sparse matrix \n    methods and variance component estimation. Applications include spline-based \n    modeling of spatial and temporal trends using penalized splines (Boer, 2023) \n    <doi:10.1177/1471082X231178591>.",
    "version": "1.0.12",
    "maintainer": "Bart-Jan van Rossum <bart-jan.vanrossum@wur.nl>",
    "author": "Martin Boer [aut] (ORCID: <https://orcid.org/0000-0002-1879-4588>),\n  Bart-Jan van Rossum [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8673-2514>)",
    "url": "https://biometris.github.io/LMMsolver/index.html,\nhttps://github.com/Biometris/LMMsolver/",
    "bug_reports": "https://github.com/Biometris/LMMsolver/issues",
    "repository": "https://cran.r-project.org/package=LMMsolver",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LMMsolver Linear Mixed Models with Sparse Matrix Methods and Smoothing Provides tools for fitting linear mixed models using sparse matrix \n    methods and variance component estimation. Applications include spline-based \n    modeling of spatial and temporal trends using penalized splines (Boer, 2023) \n    <doi:10.1177/1471082X231178591>.  "
  },
  {
    "id": 4490,
    "package_name": "LPDynR",
    "title": "Land Productivity Dynamics Indicator",
    "description": "It uses 'phenological' and productivity-related variables derived from time series of vegetation \n    indexes, such as the Normalized Difference Vegetation Index, to assess ecosystem dynamics and change, which \n    eventually might drive to land degradation. The final result of the Land Productivity Dynamics indicator \n    is a categorical map with 5 classes of land productivity dynamics, ranging from declining to increasing \n    productivity. See www.sciencedirect.com/science/article/pii/S1470160X21010517/ for a description \n    of the methods used in the package to calculate the indicator.",
    "version": "1.0.5",
    "maintainer": "Xavier Rotllan-Puig <xavier.rotllan.puig@aster-projects.cat>",
    "author": "Xavier Rotllan-Puig [aut, cre],\n  Eva Ivits [aut],\n  Michael Cherlet [aut]",
    "url": "https://github.com/xavi-rp/LPDynR",
    "bug_reports": "https://github.com/xavi-rp/LPDynR/issues",
    "repository": "https://cran.r-project.org/package=LPDynR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LPDynR Land Productivity Dynamics Indicator It uses 'phenological' and productivity-related variables derived from time series of vegetation \n    indexes, such as the Normalized Difference Vegetation Index, to assess ecosystem dynamics and change, which \n    eventually might drive to land degradation. The final result of the Land Productivity Dynamics indicator \n    is a categorical map with 5 classes of land productivity dynamics, ranging from declining to increasing \n    productivity. See www.sciencedirect.com/science/article/pii/S1470160X21010517/ for a description \n    of the methods used in the package to calculate the indicator.  "
  },
  {
    "id": 4519,
    "package_name": "LSTS",
    "title": "Locally Stationary Time Series",
    "description": "A set of functions that allow stationary analysis and locally stationary time series analysis.",
    "version": "2.1",
    "maintainer": "Mauricio Vargas <mavargas11@uc.cl>",
    "author": "Ricardo Olea [aut, cph],\n  Wilfredo Palma [aut, cph],\n  Pilar Rubio [aut],\n  Mauricio Vargas [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1017-7574>)",
    "url": "https://pacha.dev/LSTS/",
    "bug_reports": "https://github.com/pachadotdev/LSTS/issues/",
    "repository": "https://cran.r-project.org/package=LSTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LSTS Locally Stationary Time Series A set of functions that allow stationary analysis and locally stationary time series analysis.  "
  },
  {
    "id": 4542,
    "package_name": "LakeMetabolizer",
    "title": "Tools for the Analysis of Ecosystem Metabolism",
    "description": "A collection of tools for the calculation of freewater metabolism\n    from in situ time series of dissolved oxygen, water temperature, and,\n    optionally, additional environmental variables. LakeMetabolizer implements\n    5 different metabolism models with diverse statistical underpinnings:\n    bookkeeping, ordinary least squares, maximum likelihood, Kalman filter,\n    and Bayesian. Each of these 5 metabolism models can be combined with\n    1 of 7 models for computing the coefficient of gas exchange across the\n    air\u2013water interface (k). LakeMetabolizer also features a variety of\n    supporting functions that compute conversions and implement calculations\n    commonly applied to raw data prior to estimating metabolism (e.g., oxygen\n    saturation and optical conversion models).",
    "version": "1.5.6",
    "maintainer": "Jacob Zwart <jayzlimno@gmail.com>",
    "author": "Luke Winslow [aut],\n  Jacob Zwart [cre, aut] (ORCID: <https://orcid.org/0000-0002-3870-405X>),\n  Ryan Batt [aut],\n  Jessica Corman [aut],\n  Hilary Dugan [aut],\n  Paul Hanson [aut],\n  Aline Jaimes [aut],\n  Jordan Read [aut],\n  Richard Woolway [aut]",
    "url": "https://www.tandfonline.com/doi/abs/10.1080/IW-6.4.883",
    "bug_reports": "https://github.com/GLEON/LakeMetabolizer/issues",
    "repository": "https://cran.r-project.org/package=LakeMetabolizer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LakeMetabolizer Tools for the Analysis of Ecosystem Metabolism A collection of tools for the calculation of freewater metabolism\n    from in situ time series of dissolved oxygen, water temperature, and,\n    optionally, additional environmental variables. LakeMetabolizer implements\n    5 different metabolism models with diverse statistical underpinnings:\n    bookkeeping, ordinary least squares, maximum likelihood, Kalman filter,\n    and Bayesian. Each of these 5 metabolism models can be combined with\n    1 of 7 models for computing the coefficient of gas exchange across the\n    air\u2013water interface (k). LakeMetabolizer also features a variety of\n    supporting functions that compute conversions and implement calculations\n    commonly applied to raw data prior to estimating metabolism (e.g., oxygen\n    saturation and optical conversion models).  "
  },
  {
    "id": 4546,
    "package_name": "Langevin",
    "title": "Langevin Analysis in One and Two Dimensions",
    "description": "Estimate drift and diffusion functions from time series and\n    generate synthetic time series from given drift and diffusion coefficients.",
    "version": "1.3.3",
    "maintainer": "Philip Rinn <philip.rinn@uni-oldenburg.de>",
    "author": "Philip Rinn [aut, cre],\n  Pedro G. Lind [aut],\n  David Bastine [ctb]",
    "url": "https://gitlab.uni-oldenburg.de/TWiSt/Langevin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Langevin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Langevin Langevin Analysis in One and Two Dimensions Estimate drift and diffusion functions from time series and\n    generate synthetic time series from given drift and diffusion coefficients.  "
  },
  {
    "id": 4654,
    "package_name": "MAPA",
    "title": "Multiple Aggregation Prediction Algorithm",
    "description": "Functions and wrappers for using the Multiple Aggregation Prediction Algorithm (MAPA) for time series forecasting. MAPA models and forecasts time series at multiple temporal aggregation levels, thus strengthening and attenuating the various time series components for better holistic estimation of its structure. For details see Kourentzes et al. (2014) <doi:10.1016/j.ijforecast.2013.09.006>.",
    "version": "2.0.7",
    "maintainer": "Nikolaos Kourentzes <nikolaos@kourentzes.com>",
    "author": "Nikolaos Kourentzes [aut, cre],\n  Fotios Petropoulos [aut]",
    "url": "https://kourentzes.com/forecasting/2014/04/19/multiple-aggregation-prediction-algorithm-mapa/",
    "bug_reports": "https://github.com/trnnick/mapa/issues",
    "repository": "https://cran.r-project.org/package=MAPA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MAPA Multiple Aggregation Prediction Algorithm Functions and wrappers for using the Multiple Aggregation Prediction Algorithm (MAPA) for time series forecasting. MAPA models and forecasts time series at multiple temporal aggregation levels, thus strengthening and attenuating the various time series components for better holistic estimation of its structure. For details see Kourentzes et al. (2014) <doi:10.1016/j.ijforecast.2013.09.006>.  "
  },
  {
    "id": 4670,
    "package_name": "MB",
    "title": "The Use of Marginal Distributions in Conditional Forecasting",
    "description": "A new way to predict time series using the marginal distribution table in the absence of the significance of traditional models.",
    "version": "0.1.1",
    "maintainer": "Bushra Alsaeed <alsaeedbushra41@gmail.com>",
    "author": "Mohamad-Taher Anan [aut],\n  Mohamad Alawad [aut],\n  Bushra Alsaeed [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MB The Use of Marginal Distributions in Conditional Forecasting A new way to predict time series using the marginal distribution table in the absence of the significance of traditional models.  "
  },
  {
    "id": 4709,
    "package_name": "MCTrend",
    "title": "Monte Carlo Trend Analysis",
    "description": "Application of a test to rule out that trends detected in hydrological time series are explained exclusively by the randomness of the climate. Based on: Ricchetti, (2018) <https://repositorio.uchile.cl/handle/2250/168487>.",
    "version": "1.0.1",
    "maintainer": "Alonso Arriagada <alonso.arriagada@usach.cl>",
    "author": "Alonso Arriagada [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MCTrend",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MCTrend Monte Carlo Trend Analysis Application of a test to rule out that trends detected in hydrological time series are explained exclusively by the randomness of the climate. Based on: Ricchetti, (2018) <https://repositorio.uchile.cl/handle/2250/168487>.  "
  },
  {
    "id": 4731,
    "package_name": "MEFM",
    "title": "Perform MEFM Estimation on Matrix Time Series",
    "description": "To perform main effect matrix factor model (MEFM) estimation for a given matrix time series as described in Lam and Cen (2024) <doi:10.48550/arXiv.2406.00128>. Estimation of traditional matrix factor models is also supported. Supplementary functions for testing MEFM over factor models are included.",
    "version": "0.1.1",
    "maintainer": "Zetai Cen <z.cen@lse.ac.uk>",
    "author": "Zetai Cen [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MEFM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MEFM Perform MEFM Estimation on Matrix Time Series To perform main effect matrix factor model (MEFM) estimation for a given matrix time series as described in Lam and Cen (2024) <doi:10.48550/arXiv.2406.00128>. Estimation of traditional matrix factor models is also supported. Supplementary functions for testing MEFM over factor models are included.  "
  },
  {
    "id": 4745,
    "package_name": "MFT",
    "title": "The Multiple Filter Test for Change Point Detection",
    "description": "Provides statistical tests and algorithms for the detection of change points in time series and point processes - particularly for changes in the mean in time series and for changes in the rate and in the variance in point processes. References - Michael Messer, Marietta Kirchner, Julia Schiemann, Jochen Roeper, Ralph Neininger and Gaby Schneider (2014), A multiple filter test for the detection of rate changes in renewal processes with varying variance <doi:10.1214/14-AOAS782>. Stefan Albert, Michael Messer, Julia Schiemann, Jochen Roeper, Gaby Schneider (2017), Multi-scale detection of variance changes in renewal processes in the presence of rate change points <doi:10.1111/jtsa.12254>. Michael Messer, Kaue M. Costa, Jochen Roeper and Gaby Schneider (2017), Multi-scale detection of rate changes in spike trains with weak dependencies <doi:10.1007/s10827-016-0635-3>. Michael Messer, Stefan Albert and Gaby Schneider (2018), The multiple filter test for change point detection in time series <doi:10.1007/s00184-018-0672-1>. Michael Messer, Hendrik Backhaus, Albrecht Stroh and Gaby Schneider (2019+) Peak detection in time series.  ",
    "version": "2.0",
    "maintainer": "Michael Messer <messer@math.uni-frankfurt.de>",
    "author": "Michael Messer, Stefan Albert, Solveig Plomer, Gaby Schneider",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MFT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MFT The Multiple Filter Test for Change Point Detection Provides statistical tests and algorithms for the detection of change points in time series and point processes - particularly for changes in the mean in time series and for changes in the rate and in the variance in point processes. References - Michael Messer, Marietta Kirchner, Julia Schiemann, Jochen Roeper, Ralph Neininger and Gaby Schneider (2014), A multiple filter test for the detection of rate changes in renewal processes with varying variance <doi:10.1214/14-AOAS782>. Stefan Albert, Michael Messer, Julia Schiemann, Jochen Roeper, Gaby Schneider (2017), Multi-scale detection of variance changes in renewal processes in the presence of rate change points <doi:10.1111/jtsa.12254>. Michael Messer, Kaue M. Costa, Jochen Roeper and Gaby Schneider (2017), Multi-scale detection of rate changes in spike trains with weak dependencies <doi:10.1007/s10827-016-0635-3>. Michael Messer, Stefan Albert and Gaby Schneider (2018), The multiple filter test for change point detection in time series <doi:10.1007/s00184-018-0672-1>. Michael Messer, Hendrik Backhaus, Albrecht Stroh and Gaby Schneider (2019+) Peak detection in time series.    "
  },
  {
    "id": 4753,
    "package_name": "MGPSDK",
    "title": "Interact with the Maxar 'MGP' Application Programming Interfaces",
    "description": "Provides an interface to the Maxar Geospatial Platform (MGP) Application Programming Interface. <https://www.maxar.com/maxar-geospatial-platform>\n    It facilitates imagery searches using the MGP Streaming Application Programming Interface via the Web Feature Service (WFS) method, and supports image downloads through Web Map Service (WMS) and Web Map Tile Service (WMTS)\n    Open Geospatial Consortium (OGC) methods. \n    Additionally, it integrates with the Maxar Geospatial Platform Basemaps Application Programming Interface for accessing Maxar basemaps imagery and seamlines. \n    The package also offers seamless integration with the Maxar Geospatial Platform Discovery Application Programming Interface, allowing users to search, filter, and sort Maxar content, \n    while retrieving detailed metadata in formats like SpatioTemporal Asset Catalog (STAC) and GeoJSON.",
    "version": "1.0.0",
    "maintainer": "Nathan Carr <nathan.carr@maxar.com>",
    "author": "Nathan Carr [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MGPSDK",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MGPSDK Interact with the Maxar 'MGP' Application Programming Interfaces Provides an interface to the Maxar Geospatial Platform (MGP) Application Programming Interface. <https://www.maxar.com/maxar-geospatial-platform>\n    It facilitates imagery searches using the MGP Streaming Application Programming Interface via the Web Feature Service (WFS) method, and supports image downloads through Web Map Service (WMS) and Web Map Tile Service (WMTS)\n    Open Geospatial Consortium (OGC) methods. \n    Additionally, it integrates with the Maxar Geospatial Platform Basemaps Application Programming Interface for accessing Maxar basemaps imagery and seamlines. \n    The package also offers seamless integration with the Maxar Geospatial Platform Discovery Application Programming Interface, allowing users to search, filter, and sort Maxar content, \n    while retrieving detailed metadata in formats like SpatioTemporal Asset Catalog (STAC) and GeoJSON.  "
  },
  {
    "id": 4836,
    "package_name": "MODISTools",
    "title": "Interface to the 'MODIS Land Products Subsets' Web Services",
    "description": "Programmatic interface to the Oak Ridge National Laboratories\n    'MODIS Land Products Subsets' web services \n    (<https://modis.ornl.gov/data/modis_webservice.html>). Allows for easy\n    downloads of 'MODIS' time series directly to your R workspace or\n    your computer.",
    "version": "1.1.5",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "author": "Koen Hufkens [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5070-8109>),\n  BlueGreen Labs [cph, fnd]",
    "url": "https://github.com/bluegreen-labs/MODISTools",
    "bug_reports": "https://github.com/bluegreen-labs/MODISTools/issues",
    "repository": "https://cran.r-project.org/package=MODISTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MODISTools Interface to the 'MODIS Land Products Subsets' Web Services Programmatic interface to the Oak Ridge National Laboratories\n    'MODIS Land Products Subsets' web services \n    (<https://modis.ornl.gov/data/modis_webservice.html>). Allows for easy\n    downloads of 'MODIS' time series directly to your R workspace or\n    your computer.  "
  },
  {
    "id": 4881,
    "package_name": "MSCMT",
    "title": "Multivariate Synthetic Control Method Using Time Series",
    "description": "Three generalizations of the synthetic control method (which has \n    already an implementation in package 'Synth') are implemented: first, \n    'MSCMT' allows for using multiple outcome variables, second, time series \n    can be supplied as economic predictors, and third, a well-defined \n    cross-validation approach can be used.\n    Much effort has been taken to make the implementation as stable as possible \n    (including edge cases) without losing computational efficiency.\n    A detailed description of the main algorithms is given in \n    Becker and Kl\u00f6\u00dfner (2018) <doi:10.1016/j.ecosta.2017.08.002>.",
    "version": "1.4.1",
    "maintainer": "Martin Becker <martin.becker@mx.uni-saarland.de>",
    "author": "Martin Becker [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2336-9751>),\n  Stefan Kl\u00f6\u00dfner [aut],\n  Karline Soetaert [com],\n  Jack Dongarra [cph],\n  R.J. Hanson [cph],\n  K.H. Haskell [cph],\n  Cleve Moler [cph],\n  LAPACK authors [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MSCMT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MSCMT Multivariate Synthetic Control Method Using Time Series Three generalizations of the synthetic control method (which has \n    already an implementation in package 'Synth') are implemented: first, \n    'MSCMT' allows for using multiple outcome variables, second, time series \n    can be supplied as economic predictors, and third, a well-defined \n    cross-validation approach can be used.\n    Much effort has been taken to make the implementation as stable as possible \n    (including edge cases) without losing computational efficiency.\n    A detailed description of the main algorithms is given in \n    Becker and Kl\u00f6\u00dfner (2018) <doi:10.1016/j.ecosta.2017.08.002>.  "
  },
  {
    "id": 4886,
    "package_name": "MSGARCH",
    "title": "Markov-Switching GARCH Models",
    "description": "Fit (by Maximum Likelihood or MCMC/Bayesian), simulate, and forecast various Markov-Switching GARCH models as described in Ardia et al. (2019) <doi:10.18637/jss.v091.i04>.",
    "version": "2.51",
    "maintainer": "Keven Bluteau <Keven.Bluteau@usherbrooke.ca>",
    "author": "David Ardia [aut] (ORCID: <https://orcid.org/0000-0003-2823-782X>),\n  Keven Bluteau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2990-4807>),\n  Kris Boudt [ctb] (ORCID: <https://orcid.org/0000-0002-1000-5142>),\n  Leopoldo Catania [aut] (ORCID: <https://orcid.org/0000-0002-0981-1921>),\n  Alexios Ghalanos [ctb],\n  Brian Peterson [ctb],\n  Denis-Alexandre Trottier [aut]",
    "url": "https://github.com/keblu/MSGARCH",
    "bug_reports": "https://github.com/keblu/MSGARCH/issues",
    "repository": "https://cran.r-project.org/package=MSGARCH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MSGARCH Markov-Switching GARCH Models Fit (by Maximum Likelihood or MCMC/Bayesian), simulate, and forecast various Markov-Switching GARCH models as described in Ardia et al. (2019) <doi:10.18637/jss.v091.i04>.  "
  },
  {
    "id": 4887,
    "package_name": "MSGARCHelm",
    "title": "Hybridization of MS-GARCH and ELM Model",
    "description": "Implements the three parallel forecast combinations of Markov Switching GARCH and extreme learning machine model along with the selection of appropriate model for volatility forecasting. For method details see Hsiao C, Wan SK (2014). <doi:10.1016/j.jeconom.2013.11.003>, Hansen BE (2007). <doi:10.1111/j.1468-0262.2007.00785.x>, Elliott G, Gargano A, Timmermann A (2013). <doi:10.1016/j.jeconom.2013.04.017>. ",
    "version": "0.1.0",
    "maintainer": "Rajeev Ranjan Kumar <rrk.uasd@gmail.com>",
    "author": "Rajeev Ranjan Kumar [aut, cre],\n  Girish Kumar Jha [aut, ths, ctb],\n  Neeraj Budhlakoti [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MSGARCHelm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MSGARCHelm Hybridization of MS-GARCH and ELM Model Implements the three parallel forecast combinations of Markov Switching GARCH and extreme learning machine model along with the selection of appropriate model for volatility forecasting. For method details see Hsiao C, Wan SK (2014). <doi:10.1016/j.jeconom.2013.11.003>, Hansen BE (2007). <doi:10.1111/j.1468-0262.2007.00785.x>, Elliott G, Gargano A, Timmermann A (2013). <doi:10.1016/j.jeconom.2013.04.017>.   "
  },
  {
    "id": 4904,
    "package_name": "MSinference",
    "title": "Multiscale Inference for Nonparametric Time Trend(s)",
    "description": "Performs a multiscale analysis of a nonparametric\n  regression or nonparametric regressions with time series errors. In case\n  of one regression, with the help of this package it is possible to detect\n  the regions where the trend function is increasing or decreasing.\n  In case of multiple regressions, the test identifies regions where\n  the trend functions are different from each other. See\n  Khismatullina and Vogt (2020) <doi:10.1111/rssb.12347>,\n  Khismatullina and Vogt (2022) <doi:10.48550/arXiv.2209.10841> and\n  Khismatullina and Vogt (2023) <doi:10.1016/j.jeconom.2021.04.010>\n  for more details on theory and applications.",
    "version": "0.2.1",
    "maintainer": "Marina Khismatullina <khismatullina@ese.eur.nl>",
    "author": "Marina Khismatullina [aut, cre],\n  Michael Vogt [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MSinference",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MSinference Multiscale Inference for Nonparametric Time Trend(s) Performs a multiscale analysis of a nonparametric\n  regression or nonparametric regressions with time series errors. In case\n  of one regression, with the help of this package it is possible to detect\n  the regions where the trend function is increasing or decreasing.\n  In case of multiple regressions, the test identifies regions where\n  the trend functions are different from each other. See\n  Khismatullina and Vogt (2020) <doi:10.1111/rssb.12347>,\n  Khismatullina and Vogt (2022) <doi:10.48550/arXiv.2209.10841> and\n  Khismatullina and Vogt (2023) <doi:10.1016/j.jeconom.2021.04.010>\n  for more details on theory and applications.  "
  },
  {
    "id": 4913,
    "package_name": "MTS",
    "title": "All-Purpose Toolkit for Analyzing Multivariate Time Series (MTS)\nand Estimating Multivariate Volatility Models",
    "description": "Multivariate Time Series (MTS) is a general package for analyzing multivariate linear time series and estimating multivariate volatility models. It also handles factor models, constrained factor models, asymptotic principal component analysis commonly used in finance and econometrics, and principal volatility component analysis.  (a) For the multivariate linear time series analysis, the package performs model specification, estimation, model checking, and prediction for many widely used models, including vector AR models, vector MA models, vector ARMA models, seasonal vector ARMA models, VAR models with exogenous variables, multivariate regression models with time series errors, augmented VAR models, and Error-correction VAR models for co-integrated time series. For model specification, the package performs structural specification to overcome the difficulties of identifiability of VARMA models. The methods used for structural specification include Kronecker indices and Scalar Component Models.  (b) For multivariate volatility modeling, the MTS package handles several commonly used models, including multivariate exponentially weighted moving-average volatility, Cholesky decomposition volatility models, dynamic conditional correlation (DCC) models, copula-based volatility models, and low-dimensional BEKK models. The package also considers multiple tests for conditional heteroscedasticity, including rank-based statistics.  (c) Finally, the MTS package also performs forecasting using diffusion index , transfer function analysis, Bayesian estimation of VAR models, and multivariate time series analysis with missing values.Users can also use the package to simulate VARMA models, to compute impulse response functions of a fitted VARMA model, and to calculate theoretical cross-covariance matrices of a given VARMA model. ",
    "version": "1.2.1",
    "maintainer": "Ruey S. Tsay <ruey.tsay@chicagobooth.edu>",
    "author": "Ruey S. Tsay [aut, cre], David Wood [aut], Jon Lachmann [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MTS All-Purpose Toolkit for Analyzing Multivariate Time Series (MTS)\nand Estimating Multivariate Volatility Models Multivariate Time Series (MTS) is a general package for analyzing multivariate linear time series and estimating multivariate volatility models. It also handles factor models, constrained factor models, asymptotic principal component analysis commonly used in finance and econometrics, and principal volatility component analysis.  (a) For the multivariate linear time series analysis, the package performs model specification, estimation, model checking, and prediction for many widely used models, including vector AR models, vector MA models, vector ARMA models, seasonal vector ARMA models, VAR models with exogenous variables, multivariate regression models with time series errors, augmented VAR models, and Error-correction VAR models for co-integrated time series. For model specification, the package performs structural specification to overcome the difficulties of identifiability of VARMA models. The methods used for structural specification include Kronecker indices and Scalar Component Models.  (b) For multivariate volatility modeling, the MTS package handles several commonly used models, including multivariate exponentially weighted moving-average volatility, Cholesky decomposition volatility models, dynamic conditional correlation (DCC) models, copula-based volatility models, and low-dimensional BEKK models. The package also considers multiple tests for conditional heteroscedasticity, including rank-based statistics.  (c) Finally, the MTS package also performs forecasting using diffusion index , transfer function analysis, Bayesian estimation of VAR models, and multivariate time series analysis with missing values.Users can also use the package to simulate VARMA models, to compute impulse response functions of a fitted VARMA model, and to calculate theoretical cross-covariance matrices of a given VARMA model.   "
  },
  {
    "id": 4914,
    "package_name": "MTSYS",
    "title": "Methods in Mahalanobis-Taguchi (MT) System",
    "description": "Mahalanobis-Taguchi (MT) system is a collection of multivariate\n    analysis methods developed for the field of quality engineering. MT system\n    consists of two families depending on their purpose. One is a family of\n    Mahalanobis-Taguchi (MT) methods (in the broad sense) for diagnosis (see\n    Woodall, W. H., Koudelik, R., Tsui, K. L., Kim, S. B., Stoumbos, Z. G., and\n    Carvounis, C. P. (2003) <doi:10.1198/004017002188618626>) and the other is a\n    family of Taguchi (T) methods for forecasting (see Kawada, H., and Nagata, Y.\n    (2015) <doi:10.17929/tqs.1.12>). The MT package contains three basic methods\n    for the family of MT methods and one basic method for the family of T\n    methods. The MT method (in the narrow sense), the Mahalanobis-Taguchi\n    Adjoint (MTA) methods, and the Recognition-Taguchi (RT) method are for the\n    MT method and the two-sided Taguchi (T1) method is for the family of T\n    methods. In addition, the Ta and Tb methods, which are the improved versions\n    of the T1 method, are included.",
    "version": "1.2.0",
    "maintainer": "Akifumi Okayama <akifumi.okayama@akane.waseda.jp>",
    "author": "Akifumi Okayama [aut, cre],\n  Masato Ohkubo [ctb],\n  Yasushi Nagata [ctb]",
    "url": "https://github.com/okayaa/MTSYS",
    "bug_reports": "https://github.com/okayaa/MTSYS/issues",
    "repository": "https://cran.r-project.org/package=MTSYS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MTSYS Methods in Mahalanobis-Taguchi (MT) System Mahalanobis-Taguchi (MT) system is a collection of multivariate\n    analysis methods developed for the field of quality engineering. MT system\n    consists of two families depending on their purpose. One is a family of\n    Mahalanobis-Taguchi (MT) methods (in the broad sense) for diagnosis (see\n    Woodall, W. H., Koudelik, R., Tsui, K. L., Kim, S. B., Stoumbos, Z. G., and\n    Carvounis, C. P. (2003) <doi:10.1198/004017002188618626>) and the other is a\n    family of Taguchi (T) methods for forecasting (see Kawada, H., and Nagata, Y.\n    (2015) <doi:10.17929/tqs.1.12>). The MT package contains three basic methods\n    for the family of MT methods and one basic method for the family of T\n    methods. The MT method (in the narrow sense), the Mahalanobis-Taguchi\n    Adjoint (MTA) methods, and the Recognition-Taguchi (RT) method are for the\n    MT method and the two-sided Taguchi (T1) method is for the family of T\n    methods. In addition, the Ta and Tb methods, which are the improved versions\n    of the T1 method, are included.  "
  },
  {
    "id": 4943,
    "package_name": "MagmaClustR",
    "title": "Clustering and Prediction using Multi-Task Gaussian Processes\nwith Common Mean",
    "description": "An implementation for the multi-task Gaussian processes with common \n    mean framework. Two main algorithms, called 'Magma' and 'MagmaClust', \n    are available to perform predictions for supervised learning problems, in\n    particular for time series or any functional/continuous data applications.\n    The corresponding articles has been respectively proposed by Arthur Leroy, \n    Pierre Latouche, Benjamin Guedj and Servane Gey (2022) \n    <doi:10.1007/s10994-022-06172-1>, and Arthur Leroy, Pierre Latouche, \n    Benjamin Guedj and Servane Gey (2023) <https://jmlr.org/papers/v24/20-1321.html>.\n    Theses approaches leverage the learning of cluster-specific mean processes,\n    which are common across similar tasks, to provide enhanced prediction\n    performances (even far from data) at a linear computational cost (in\n    the number of tasks).  'MagmaClust' is a generalisation of 'Magma'\n    where the tasks are simultaneously clustered into groups, each being\n    associated to a specific mean process.  User-oriented functions in the\n    package are decomposed into training, prediction and plotting\n    functions. Some basic features (classic kernels, training, prediction) of\n    standard Gaussian processes are also implemented. ",
    "version": "1.2.1",
    "maintainer": "Arthur Leroy <arthur.leroy.pro@gmail.com>",
    "author": "Arthur Leroy [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0806-8934>),\n  Pierre Latouche [aut],\n  Pierre Path\u00e9 [ctb],\n  Alexia Grenouillat [ctb],\n  Hugo Lelievre [ctb]",
    "url": "https://github.com/ArthurLeroy/MagmaClustR,\nhttps://arthurleroy.github.io/MagmaClustR/",
    "bug_reports": "https://github.com/ArthurLeroy/MagmaClustR/issues",
    "repository": "https://cran.r-project.org/package=MagmaClustR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MagmaClustR Clustering and Prediction using Multi-Task Gaussian Processes\nwith Common Mean An implementation for the multi-task Gaussian processes with common \n    mean framework. Two main algorithms, called 'Magma' and 'MagmaClust', \n    are available to perform predictions for supervised learning problems, in\n    particular for time series or any functional/continuous data applications.\n    The corresponding articles has been respectively proposed by Arthur Leroy, \n    Pierre Latouche, Benjamin Guedj and Servane Gey (2022) \n    <doi:10.1007/s10994-022-06172-1>, and Arthur Leroy, Pierre Latouche, \n    Benjamin Guedj and Servane Gey (2023) <https://jmlr.org/papers/v24/20-1321.html>.\n    Theses approaches leverage the learning of cluster-specific mean processes,\n    which are common across similar tasks, to provide enhanced prediction\n    performances (even far from data) at a linear computational cost (in\n    the number of tasks).  'MagmaClust' is a generalisation of 'Magma'\n    where the tasks are simultaneously clustered into groups, each being\n    associated to a specific mean process.  User-oriented functions in the\n    package are decomposed into training, prediction and plotting\n    functions. Some basic features (classic kernels, training, prediction) of\n    standard Gaussian processes are also implemented.   "
  },
  {
    "id": 4966,
    "package_name": "MarketMatching",
    "title": "Market Matching and Causal Impact Inference",
    "description": "For a given test market find the best control markets using time series matching and analyze the impact of an intervention. The intervention could be a marketing event or some other local business tactic that is being tested. The workflow implemented in the Market Matching package utilizes dynamic time warping (the 'dtw' package) to do the matching and the 'CausalImpact' package to analyze the causal impact. In fact, this package can be considered a \"workflow wrapper\" for those two packages. In addition, if you don't have a chosen set of test markets to match, the Market Matching package can provide suggested test/control market pairs and pseudo prospective power analysis (measuring causal impact at fake interventions). ",
    "version": "1.2.1",
    "maintainer": "Larsen Kim <kblarsen4@gmail.com>",
    "author": "Larsen Kim [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MarketMatching",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MarketMatching Market Matching and Causal Impact Inference For a given test market find the best control markets using time series matching and analyze the impact of an intervention. The intervention could be a marketing event or some other local business tactic that is being tested. The workflow implemented in the Market Matching package utilizes dynamic time warping (the 'dtw' package) to do the matching and the 'CausalImpact' package to analyze the causal impact. In fact, this package can be considered a \"workflow wrapper\" for those two packages. In addition, if you don't have a chosen set of test markets to match, the Market Matching package can provide suggested test/control market pairs and pseudo prospective power analysis (measuring causal impact at fake interventions).   "
  },
  {
    "id": 4989,
    "package_name": "MazamaCoreUtils",
    "title": "Utility Functions for Production R Code",
    "description": "A suite of utility functions providing functionality commonly\n    needed for production level projects such as logging, error handling,\n    cache management and date-time parsing. Functions for date-time parsing and \n    formatting require that time zones be specified explicitly, avoiding a common \n    source of error when working with environmental time series.",
    "version": "0.5.3",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "author": "Jonathan Callahan [aut, cre],\n  Eli Grosman [ctb],\n  Spencer Pease [ctb],\n  Thomas Bergamaschi [ctb]",
    "url": "https://github.com/MazamaScience/MazamaCoreUtils",
    "bug_reports": "https://github.com/MazamaScience/MazamaCoreUtils/issues",
    "repository": "https://cran.r-project.org/package=MazamaCoreUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MazamaCoreUtils Utility Functions for Production R Code A suite of utility functions providing functionality commonly\n    needed for production level projects such as logging, error handling,\n    cache management and date-time parsing. Functions for date-time parsing and \n    formatting require that time zones be specified explicitly, avoiding a common \n    source of error when working with environmental time series.  "
  },
  {
    "id": 4991,
    "package_name": "MazamaRollUtils",
    "title": "Efficient Rolling Functions",
    "description": "A suite of compiled functions calculating rolling mins, means, \n    maxes and other statistics. This package is designed to meet the needs of\n    data processing systems for environmental time series.",
    "version": "0.1.4",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "author": "Jonathan Callahan [aut, cre],\n  Hans Martin [aut]",
    "url": "https://github.com/MazamaScience/MazamaRollUtils",
    "bug_reports": "https://github.com/MazamaScience/MazamaRollUtils/issues",
    "repository": "https://cran.r-project.org/package=MazamaRollUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MazamaRollUtils Efficient Rolling Functions A suite of compiled functions calculating rolling mins, means, \n    maxes and other statistics. This package is designed to meet the needs of\n    data processing systems for environmental time series.  "
  },
  {
    "id": 4994,
    "package_name": "MazamaTimeSeries",
    "title": "Core Functionality for Environmental Time Series",
    "description": "Utility functions for working with environmental time series data from known \n    locations. The compact data model is structured as a list with two dataframes. A \n    'meta' dataframe contains spatial and measuring device metadata associated with \n    deployments at known locations. A 'data' dataframe contains a 'datetime' column \n    followed by columns of measurements associated with each \"device-deployment\".\n    Ephemerides calculations are based on code originally found in NOAA's\n    \"Solar Calculator\" <https://gml.noaa.gov/grad/solcalc/>.",
    "version": "0.3.1",
    "maintainer": "Jonathan Callahan <jonathan.s.callahan@gmail.com>",
    "author": "Jonathan Callahan [aut, cre],\n  Hans Martin [ctb],\n  Eli Grosman [ctb],\n  Roger Bivand [ctb],\n  Sebastian Luque [ctb]",
    "url": "https://github.com/MazamaScience/MazamaTimeSeries,\nhttps://mazamascience.github.io/MazamaTimeSeries/",
    "bug_reports": "https://github.com/MazamaScience/MazamaTimeSeries/issues",
    "repository": "https://cran.r-project.org/package=MazamaTimeSeries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MazamaTimeSeries Core Functionality for Environmental Time Series Utility functions for working with environmental time series data from known \n    locations. The compact data model is structured as a list with two dataframes. A \n    'meta' dataframe contains spatial and measuring device metadata associated with \n    deployments at known locations. A 'data' dataframe contains a 'datetime' column \n    followed by columns of measurements associated with each \"device-deployment\".\n    Ephemerides calculations are based on code originally found in NOAA's\n    \"Solar Calculator\" <https://gml.noaa.gov/grad/solcalc/>.  "
  },
  {
    "id": 4996,
    "package_name": "Mcomp",
    "title": "Data from the M-Competitions",
    "description": "\n  The 1001 time series from the M-competition (Makridakis et al. 1982) <DOI:10.1002/for.3980010202> and the 3003 time series from the IJF-M3 competition (Makridakis and Hibon, 2000) <DOI:10.1016/S0169-2070(00)00057-1>.",
    "version": "2.8",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  Muhammad Akram [ctb],\n  Christoph Bergmeir [ctb] (ORCID:\n    <https://orcid.org/0000-0002-3665-9021>),\n  Mitchell O'Hara-Wild [ctb]",
    "url": "http://pkg.robjhyndman.com/Mcomp/,\nhttps://github.com/robjhyndman/Mcomp",
    "bug_reports": "https://github.com/robjhyndman/Mcomp/issues",
    "repository": "https://cran.r-project.org/package=Mcomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Mcomp Data from the M-Competitions \n  The 1001 time series from the M-competition (Makridakis et al. 1982) <DOI:10.1002/for.3980010202> and the 3003 time series from the IJF-M3 competition (Makridakis and Hibon, 2000) <DOI:10.1016/S0169-2070(00)00057-1>.  "
  },
  {
    "id": 5016,
    "package_name": "MetaCycle",
    "title": "Evaluate Periodicity in Large Scale Data",
    "description": "There are two functions-meta2d and meta3d for\n    detecting rhythmic signals from time-series datasets. For analyzing\n    time-series datasets without individual information, 'meta2d' is \n    suggested, which could incorporates multiple methods from ARSER, \n    JTK_CYCLE and Lomb-Scargle in the detection of interested rhythms. For \n    analyzing time-series datasets with individual information, 'meta3d' is \n    suggested, which takes use of any one of these three methods to analyze \n\ttime-series data individual by individual and gives out integrated values \n    based on analysis result of each individual.",
    "version": "1.2.0",
    "maintainer": "Gang Wu <wggucas@gmail.com>",
    "author": "Gang Wu [aut, cre],\n  Ron Anafi [aut, ctb],\n  John Hogenesch [aut, ctb],\n  Michael Hughes [aut, ctb],\n  Karl Kornacker [aut, ctb],\n  Xavier Li [aut, ctb],\n  Matthew Carlucci [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MetaCycle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MetaCycle Evaluate Periodicity in Large Scale Data There are two functions-meta2d and meta3d for\n    detecting rhythmic signals from time-series datasets. For analyzing\n    time-series datasets without individual information, 'meta2d' is \n    suggested, which could incorporates multiple methods from ARSER, \n    JTK_CYCLE and Lomb-Scargle in the detection of interested rhythms. For \n    analyzing time-series datasets with individual information, 'meta3d' is \n    suggested, which takes use of any one of these three methods to analyze \n\ttime-series data individual by individual and gives out integrated values \n    based on analysis result of each individual.  "
  },
  {
    "id": 5038,
    "package_name": "Metrics",
    "title": "Evaluation Metrics for Machine Learning",
    "description": "An implementation of evaluation metrics in R that are commonly\n             used in supervised machine learning. It implements metrics for\n             regression, time series, binary classification, classification,\n             and information retrieval problems. It has zero dependencies and\n             a consistent, simple interface for all functions.",
    "version": "0.1.4",
    "maintainer": "Michael Frasco <mfrasco6@gmail.com>",
    "author": "Ben Hamner [aut, cph],\n  Michael Frasco [aut, cre],\n  Erin LeDell [ctb]",
    "url": "https://github.com/mfrasco/Metrics",
    "bug_reports": "https://github.com/mfrasco/Metrics/issues",
    "repository": "https://cran.r-project.org/package=Metrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Metrics Evaluation Metrics for Machine Learning An implementation of evaluation metrics in R that are commonly\n             used in supervised machine learning. It implements metrics for\n             regression, time series, binary classification, classification,\n             and information retrieval problems. It has zero dependencies and\n             a consistent, simple interface for all functions.  "
  },
  {
    "id": 5053,
    "package_name": "MicrobTiSDA",
    "title": "Microbiome Time-Series Data Analysis",
    "description": "Provides tools specifically designed for analyzing longitudinal microbiome data. This tool integrates seven functional modules, providing a systematic framework for microbiome time-series analysis. For more details on inferences involving interspecies interactions see Fisher (2014) <doi:10.1371/journal.pone.0102451>. Details on this package are also described in an unpublished manuscript.",
    "version": "0.1.0",
    "maintainer": "Shijia Li <s.li2@uva.nl>",
    "author": "Shijia Li [aut, cre] (ORCID: <https://orcid.org/0009-0006-6827-5344>)",
    "url": "https://github.com/Lishijiagg/MicrobTiSDA",
    "bug_reports": "https://github.com/Lishijiagg/MicrobTiSDA/issues",
    "repository": "https://cran.r-project.org/package=MicrobTiSDA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MicrobTiSDA Microbiome Time-Series Data Analysis Provides tools specifically designed for analyzing longitudinal microbiome data. This tool integrates seven functional modules, providing a systematic framework for microbiome time-series analysis. For more details on inferences involving interspecies interactions see Fisher (2014) <doi:10.1371/journal.pone.0102451>. Details on this package are also described in an unpublished manuscript.  "
  },
  {
    "id": 5059,
    "package_name": "MigrationDetectR",
    "title": "Segment-Based Migration Detection Algorithm",
    "description": "Detection of migration events and segments of continuous residence \n    based on irregular time series of location data\n    as published in Chi et al. (2020) <doi:10.1371/journal.pone.0239408>.",
    "version": "0.1.1",
    "maintainer": "Johannes Mast <johannes.mast@dlr.de>",
    "author": "Johannes Mast [aut, cre] (Author of R code and wrappers, ORCID:\n    <https://orcid.org/0000-0001-6595-5834>),\n  Guanghua Chi [aut] (Developer of the Algorithm, ORCID:\n    <https://orcid.org/0000-0003-0430-7483>),\n  German Aerospace Center DLR [cph, fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MigrationDetectR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MigrationDetectR Segment-Based Migration Detection Algorithm Detection of migration events and segments of continuous residence \n    based on irregular time series of location data\n    as published in Chi et al. (2020) <doi:10.1371/journal.pone.0239408>.  "
  },
  {
    "id": 5064,
    "package_name": "MisRepARMA",
    "title": "Misreported Time Series Analysis",
    "description": "Provides a simple and trustworthy methodology for the analysis of misreported continuous time series. See Mori\u00f1a, D, Fern\u00e1ndez-Fontelo, A, Caba\u00f1a, A, Puig P. (2021) <arXiv:2003.09202v2>.",
    "version": "0.0.2",
    "maintainer": "David Mori\u00f1a Soler <dmorina@ub.edu>",
    "author": "David Mori\u00f1a Soler [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5949-7443>),\n  Amanda Fern\u00e1ndez-Fontelo [aut],\n  Alejandra Caba\u00f1a [aut],\n  Pedro Puig [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MisRepARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MisRepARMA Misreported Time Series Analysis Provides a simple and trustworthy methodology for the analysis of misreported continuous time series. See Mori\u00f1a, D, Fern\u00e1ndez-Fontelo, A, Caba\u00f1a, A, Puig P. (2021) <arXiv:2003.09202v2>.  "
  },
  {
    "id": 5085,
    "package_name": "MixedIndTests",
    "title": "Tests of Randomness and Tests of Independence",
    "description": "Functions for testing randomness for a univariate time series with arbitrary distribution  (discrete, continuous, mixture of both types) and for testing  independence between random variables with arbitrary distributions. The test statistics are based on the multilinear empirical copula and multipliers are used to compute P-values. The test of independence between random variables appeared in  Genest, Ne\u0161lehov\u00e1, R\u00e9millard & Murphy (2019) and the test of randomness appeared in Nasri (2022).",
    "version": "1.2.0",
    "maintainer": "Bouchra R. Nasri <bouchra.nasri@umontreal.ca>",
    "author": "Bouchra R. Nasri [aut, cre, cph],\n  Bruno N Remillard [aut],\n  Johanna G Neslehova [aut],\n  Christian Genest [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MixedIndTests",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MixedIndTests Tests of Randomness and Tests of Independence Functions for testing randomness for a univariate time series with arbitrary distribution  (discrete, continuous, mixture of both types) and for testing  independence between random variables with arbitrary distributions. The test statistics are based on the multilinear empirical copula and multipliers are used to compute P-values. The test of independence between random variables appeared in  Genest, Ne\u0161lehov\u00e1, R\u00e9millard & Murphy (2019) and the test of randomness appeared in Nasri (2022).  "
  },
  {
    "id": 5124,
    "package_name": "MortalityGaps",
    "title": "The Double-Gap Life Expectancy Forecasting Model",
    "description": "Life expectancy is highly correlated over time among countries and \n  between males and females. These associations can be used to improve forecasts. \n  Here we have implemented a method for forecasting female life expectancy based on \n  analysis of the gap between female life expectancy in a country compared with\n  the record level of female life expectancy in the world. Second, to forecast \n  male life expectancy, the gap between male life expectancy and female life \n  expectancy in a country is analysed. We named this method the Double-Gap model.\n  For a detailed description of the method see Pascariu et al. (2018). \n  <doi:10.1016/j.insmatheco.2017.09.011>.",
    "version": "1.0.7",
    "maintainer": "Marius D. Pascariu <rpascariu@outlook.com>",
    "author": "Marius D. Pascariu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2568-6489>)",
    "url": "https://github.com/mpascariu/MortalityGaps",
    "bug_reports": "https://github.com/mpascariu/MortalityGaps/issues",
    "repository": "https://cran.r-project.org/package=MortalityGaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MortalityGaps The Double-Gap Life Expectancy Forecasting Model Life expectancy is highly correlated over time among countries and \n  between males and females. These associations can be used to improve forecasts. \n  Here we have implemented a method for forecasting female life expectancy based on \n  analysis of the gap between female life expectancy in a country compared with\n  the record level of female life expectancy in the world. Second, to forecast \n  male life expectancy, the gap between male life expectancy and female life \n  expectancy in a country is analysed. We named this method the Double-Gap model.\n  For a detailed description of the method see Pascariu et al. (2018). \n  <doi:10.1016/j.insmatheco.2017.09.011>.  "
  },
  {
    "id": 5140,
    "package_name": "MultIS",
    "title": "Reconstruction of Clones from Integration Site Readouts and\nVisualization",
    "description": "Tools necessary to reconstruct clonal affiliations from\n    temporally and/or spatially separated measurements of viral\n    integration sites. For this means it utilizes correlations present\n    in the relative readouts of the integration sites. Furthermore,\n    facilities for filtering of the data and visualization of different\n    steps in the pipeline are provided with the package.",
    "version": "0.6.2",
    "maintainer": "Sebastian Wagner <sebastian.wagner3@tu-dresden.de>",
    "author": "Sebastian Wagner [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-6468-4833>),\n  Christoph Baldow [aut] (ORCID: <https://orcid.org/0000-0002-4366-1453>),\n  Ingmar Glauche [ths] (ORCID: <https://orcid.org/0000-0002-2524-1199>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MultIS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultIS Reconstruction of Clones from Integration Site Readouts and\nVisualization Tools necessary to reconstruct clonal affiliations from\n    temporally and/or spatially separated measurements of viral\n    integration sites. For this means it utilizes correlations present\n    in the relative readouts of the integration sites. Furthermore,\n    facilities for filtering of the data and visualization of different\n    steps in the pipeline are provided with the package.  "
  },
  {
    "id": 5145,
    "package_name": "MultiATSM",
    "title": "Multicountry Term Structure of Interest Rates Models",
    "description": "Package for estimating, analyzing, and forecasting multi-country macro-finance affine term structure models (ATSMs). All setups build on the single-country unspanned macroeconomic risk framework from Joslin, Priebsch, and Singleton (2014, JF) <doi:10.1111/jofi.12131>. Multicountry extensions by Jotikasthira, Le, and Lundblad (2015, JFE) <doi:10.1016/j.jfineco.2014.09.004>, Candelon and Moura (2023, EM) <doi:10.1016/j.econmod.2023.106453>, and Candelon and Moura (2024, JFEC) <doi:10.1093/jjfinec/nbae008> are also available. The package also provides tools for bias correction as in Bauer Rudebusch and Wu (2012, JBES) <doi:10.1080/07350015.2012.693855>, bootstrap analysis, and several graphical/numerical outputs. ",
    "version": "1.5.1",
    "maintainer": "Rubens Moura <rubens.gtmoura@gmail.com>",
    "author": "Rubens Moura [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8105-4729>)",
    "url": "https://github.com/rubensmoura87/MultiATSM,\nhttps://rubensmoura87.github.io/MultiATSM/",
    "bug_reports": "https://github.com/rubensmoura87/MultiATSM/issues",
    "repository": "https://cran.r-project.org/package=MultiATSM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultiATSM Multicountry Term Structure of Interest Rates Models Package for estimating, analyzing, and forecasting multi-country macro-finance affine term structure models (ATSMs). All setups build on the single-country unspanned macroeconomic risk framework from Joslin, Priebsch, and Singleton (2014, JF) <doi:10.1111/jofi.12131>. Multicountry extensions by Jotikasthira, Le, and Lundblad (2015, JFE) <doi:10.1016/j.jfineco.2014.09.004>, Candelon and Moura (2023, EM) <doi:10.1016/j.econmod.2023.106453>, and Candelon and Moura (2024, JFEC) <doi:10.1093/jjfinec/nbae008> are also available. The package also provides tools for bias correction as in Bauer Rudebusch and Wu (2012, JBES) <doi:10.1080/07350015.2012.693855>, bootstrap analysis, and several graphical/numerical outputs.   "
  },
  {
    "id": 5151,
    "package_name": "MultiGrey",
    "title": "Fitting and Forecasting of Grey Model for Multivariate Time\nSeries Data",
    "description": "Grey model is commonly used in time series forecasting when statistical assumptions are violated with a limited number of data points. The minimum number of data points\n             required to fit a grey model is four observations. This package fits Grey model of First order and One Variable, i.e., GM (1,1) for multivariate time series data and returns\n             the parameters of the model, model evaluation criteria and h-step ahead forecast values for each of the time series variables. For method details see, Akay, D. and Atak, M. (2007) <DOI:10.1016/j.energy.2006.11.014>,\n             Hsu, L. and Wang, C. (2007).<DOI:10.1016/j.techfore.2006.02.005>.",
    "version": "0.1.0",
    "maintainer": "Pradip Basak <pradip@ubkv.ac.in>",
    "author": "Pradip Basak [aut, cph, cre],\n  Nobin Chandra Paul [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MultiGrey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultiGrey Fitting and Forecasting of Grey Model for Multivariate Time\nSeries Data Grey model is commonly used in time series forecasting when statistical assumptions are violated with a limited number of data points. The minimum number of data points\n             required to fit a grey model is four observations. This package fits Grey model of First order and One Variable, i.e., GM (1,1) for multivariate time series data and returns\n             the parameters of the model, model evaluation criteria and h-step ahead forecast values for each of the time series variables. For method details see, Akay, D. and Atak, M. (2007) <DOI:10.1016/j.energy.2006.11.014>,\n             Hsu, L. and Wang, C. (2007).<DOI:10.1016/j.techfore.2006.02.005>.  "
  },
  {
    "id": 5158,
    "package_name": "MultiNMix",
    "title": "Multi-Species N-Mixture (MNM) Models with 'nimble'",
    "description": "Simulating data and fitting multi-species N-mixture models using 'nimble'. Includes features for handling zero-inflation and temporal correlation, Bayesian inference, model diagnostics, parameter estimation, and predictive checks. Designed for ecological studies with zero-altered or time-series data. Mimnagh, N., Parnell, A., Prado, E., & Moral, R. A. (2022) <doi:10.1007/s10651-022-00542-7>. Royle, J. A. (2004) <doi:10.1111/j.0006-341X.2004.00142.x>.",
    "version": "0.1.0",
    "maintainer": "Niamh Mimnagh <niamhmimnagh@gmail.com>",
    "author": "Niamh Mimnagh [aut, cre],\n  Rafael de Andrade Moral [aut]",
    "url": "https://github.com/niamhmimnagh/MultiNMix",
    "bug_reports": "https://github.com/niamhmimnagh/MultiNMix/issues",
    "repository": "https://cran.r-project.org/package=MultiNMix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultiNMix Multi-Species N-Mixture (MNM) Models with 'nimble' Simulating data and fitting multi-species N-mixture models using 'nimble'. Includes features for handling zero-inflation and temporal correlation, Bayesian inference, model diagnostics, parameter estimation, and predictive checks. Designed for ecological studies with zero-altered or time-series data. Mimnagh, N., Parnell, A., Prado, E., & Moral, R. A. (2022) <doi:10.1007/s10651-022-00542-7>. Royle, J. A. (2004) <doi:10.1111/j.0006-341X.2004.00142.x>.  "
  },
  {
    "id": 5171,
    "package_name": "MultipleBubbles",
    "title": "Test and Detection of Explosive Behaviors for Time Series",
    "description": "Provides the Augmented Dickey-Fuller test and its variations to check the existence of bubbles (explosive behavior) for time series, based on the article by Peter C. B. Phillips, Shuping Shi and Jun Yu (2015a) <doi:10.1111/iere.12131>. Some functions may take a while depending on the size of the data used, or the number of Monte Carlo replications applied.",
    "version": "0.2.0",
    "maintainer": "Pedro Araujo <pharaujo1094@gmail.com>",
    "author": "Pedro Araujo <pharaujo1094@gmail.com>\n     Gustavo Lacerda <gustavolacerdas@gmail.com>\n     Peter C.B. Phillips <peter.phillips@yale.edu>\n     Shu-Ping Shi <shuping.shi@mq.edu.au>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MultipleBubbles",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultipleBubbles Test and Detection of Explosive Behaviors for Time Series Provides the Augmented Dickey-Fuller test and its variations to check the existence of bubbles (explosive behavior) for time series, based on the article by Peter C. B. Phillips, Shuping Shi and Jun Yu (2015a) <doi:10.1111/iere.12131>. Some functions may take a while depending on the size of the data used, or the number of Monte Carlo replications applied.  "
  },
  {
    "id": 5206,
    "package_name": "NBtsVarSel",
    "title": "Variable Selection in a Specific Regression Time Series of\nCounts",
    "description": "Performs variable selection in sparse negative binomial GLARMA (Generalised Linear Autoregressive Moving Average) models. For further details we refer the reader to the paper Gomtsyan (2023), <arXiv:2307.00929>.",
    "version": "1.0",
    "maintainer": "Marina Gomtsyan <mgomtsian@gmail.com>",
    "author": "Marina Gomtsyan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NBtsVarSel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NBtsVarSel Variable Selection in a Specific Regression Time Series of\nCounts Performs variable selection in sparse negative binomial GLARMA (Generalised Linear Autoregressive Moving Average) models. For further details we refer the reader to the paper Gomtsyan (2023), <arXiv:2307.00929>.  "
  },
  {
    "id": 5216,
    "package_name": "NFCP",
    "title": "N-Factor Commodity Pricing Through Term Structure Estimation",
    "description": "Commodity pricing models are (systems of) stochastic differential equations that are utilized for the valuation and hedging of commodity contingent claims (i.e. derivative products on the commodity) and other commodity related investments. Commodity pricing models that capture market dynamics are of great importance to commodity market participants in order to exercise sound investment and risk-management strategies. Parameters of commodity pricing models are estimated through maximum likelihood estimation, using available term structure futures data of a commodity. 'NFCP' (n-factor commodity pricing) provides a framework for the modeling, parameter estimation, probabilistic forecasting, option valuation and simulation of commodity prices through state space and Monte Carlo methods, risk-neutral valuation and Kalman filtering. 'NFCP' allows the commodity pricing model to consist of n correlated factors, with both random walk and mean-reverting elements. The n-factor commodity pricing model framework was first presented in the work of Cortazar and Naranjo (2006) <doi:10.1002/fut.20198>. Examples presented in 'NFCP' replicate the two-factor crude oil commodity pricing model presented in the prolific work of Schwartz and Smith (2000) <doi:10.1287/mnsc.46.7.893.12034> with the approximate term structure futures data applied within this study provided in the 'NFCP' package.",
    "version": "1.2.2",
    "maintainer": "Thomas Aspinall <tomaspinall2512@gmail.com>",
    "author": "Thomas Aspinall [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6968-1989>),\n  Adrian Gepp [aut] (ORCID: <https://orcid.org/0000-0003-1666-5501>),\n  Geoff Harris [aut] (ORCID: <https://orcid.org/0000-0003-4284-8619>),\n  Simone Kelly [aut] (ORCID: <https://orcid.org/0000-0002-6528-8557>),\n  Colette Southam [aut] (ORCID: <https://orcid.org/0000-0001-7263-2347>),\n  Bruce Vanstone [aut] (ORCID: <https://orcid.org/0000-0002-3977-2468>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NFCP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NFCP N-Factor Commodity Pricing Through Term Structure Estimation Commodity pricing models are (systems of) stochastic differential equations that are utilized for the valuation and hedging of commodity contingent claims (i.e. derivative products on the commodity) and other commodity related investments. Commodity pricing models that capture market dynamics are of great importance to commodity market participants in order to exercise sound investment and risk-management strategies. Parameters of commodity pricing models are estimated through maximum likelihood estimation, using available term structure futures data of a commodity. 'NFCP' (n-factor commodity pricing) provides a framework for the modeling, parameter estimation, probabilistic forecasting, option valuation and simulation of commodity prices through state space and Monte Carlo methods, risk-neutral valuation and Kalman filtering. 'NFCP' allows the commodity pricing model to consist of n correlated factors, with both random walk and mean-reverting elements. The n-factor commodity pricing model framework was first presented in the work of Cortazar and Naranjo (2006) <doi:10.1002/fut.20198>. Examples presented in 'NFCP' replicate the two-factor crude oil commodity pricing model presented in the prolific work of Schwartz and Smith (2000) <doi:10.1287/mnsc.46.7.893.12034> with the approximate term structure futures data applied within this study provided in the 'NFCP' package.  "
  },
  {
    "id": 5231,
    "package_name": "NIRStat",
    "title": "Novel Statistical Methods for Studying Near-Infrared\nSpectroscopy (NIRS) Time Series Data",
    "description": "Provides transfusion-related differential tests on Near-infrared spectroscopy (NIRS) time series with detection limit, which contains two testing statistics: Mean Area Under the Curve (MAUC) and slope statistic. This package applied a penalized spline method within imputation setting. Testing is conducted by a nested permutation approach within imputation. Refer to Guo et al (2018) <doi:10.1177/0962280218786302> for further details.",
    "version": "1.1",
    "maintainer": "Yikai Wang <johnzon.wyk@gmail.com>",
    "author": "Yikai Wang [Emory University], Xiao Wang [ICF]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NIRStat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NIRStat Novel Statistical Methods for Studying Near-Infrared\nSpectroscopy (NIRS) Time Series Data Provides transfusion-related differential tests on Near-infrared spectroscopy (NIRS) time series with detection limit, which contains two testing statistics: Mean Area Under the Curve (MAUC) and slope statistic. This package applied a penalized spline method within imputation setting. Testing is conducted by a nested permutation approach within imputation. Refer to Guo et al (2018) <doi:10.1177/0962280218786302> for further details.  "
  },
  {
    "id": 5254,
    "package_name": "NNS",
    "title": "Nonlinear Nonparametric Statistics",
    "description": "NNS (Nonlinear Nonparametric Statistics) leverages partial moments \u2013 the fundamental elements of variance that asymptotically approximate the area under f(x) \u2013 to provide a robust foundation for nonlinear analysis while maintaining linear equivalences.  NNS delivers a comprehensive suite of advanced statistical techniques, including: Numerical integration, Numerical differentiation, Clustering, Correlation, Dependence, Causal analysis, ANOVA, Regression, Classification, Seasonality, Autoregressive modeling, Normalization, Stochastic dominance and Advanced Monte Carlo sampling.  All routines based on: Viole, F. and Nawrocki, D. (2013), Nonlinear Nonparametric Statistics: Using Partial Moments (ISBN: 1490523995).",
    "version": "11.6.3",
    "maintainer": "Fred Viole <ovvo.financial.systems@gmail.com>",
    "author": "Fred Viole [aut, cre],\n  Roberto Spadim [ctb]",
    "url": "",
    "bug_reports": "https://github.com/OVVO-Financial/NNS/issues",
    "repository": "https://cran.r-project.org/package=NNS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NNS Nonlinear Nonparametric Statistics NNS (Nonlinear Nonparametric Statistics) leverages partial moments \u2013 the fundamental elements of variance that asymptotically approximate the area under f(x) \u2013 to provide a robust foundation for nonlinear analysis while maintaining linear equivalences.  NNS delivers a comprehensive suite of advanced statistical techniques, including: Numerical integration, Numerical differentiation, Clustering, Correlation, Dependence, Causal analysis, ANOVA, Regression, Classification, Seasonality, Autoregressive modeling, Normalization, Stochastic dominance and Advanced Monte Carlo sampling.  All routines based on: Viole, F. and Nawrocki, D. (2013), Nonlinear Nonparametric Statistics: Using Partial Moments (ISBN: 1490523995).  "
  },
  {
    "id": 5281,
    "package_name": "NTS",
    "title": "Nonlinear Time Series Analysis",
    "description": "Simulation, estimation, prediction procedure, and model identification methods for nonlinear time series analysis, including threshold autoregressive models, Markov-switching models, convolutional functional autoregressive models, nonlinearity tests, Kalman filters and various sequential Monte Carlo methods. More examples and details about this package can be found in the book \"Nonlinear Time Series Analysis\" by Ruey S. Tsay and Rong Chen, John Wiley & Sons, 2018 (ISBN: 978-1-119-26407-1).",
    "version": "1.1.3",
    "maintainer": "Xialu Liu <xialu.liu@sdsu.edu>",
    "author": "Ruey Tsay [aut],\n  Rong Chen [aut],\n  Xialu Liu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NTS Nonlinear Time Series Analysis Simulation, estimation, prediction procedure, and model identification methods for nonlinear time series analysis, including threshold autoregressive models, Markov-switching models, convolutional functional autoregressive models, nonlinearity tests, Kalman filters and various sequential Monte Carlo methods. More examples and details about this package can be found in the book \"Nonlinear Time Series Analysis\" by Ruey S. Tsay and Rong Chen, John Wiley & Sons, 2018 (ISBN: 978-1-119-26407-1).  "
  },
  {
    "id": 5317,
    "package_name": "NetVAR",
    "title": "Network Structures in VAR Models",
    "description": "Vector AutoRegressive (VAR) type models with tailored regularisation structures are provided to uncover network type structures in the data, such as influential time series (influencers). Currently the package implements the LISAR model from Zhang and Trimborn (2023) <doi:10.2139/ssrn.4619531>. The package automatically derives the required regularisation sequences and refines it during the estimation to provide the optimal model. The package allows for model optimisation under various loss functions such as Mean Squared Forecasting Error (MSFE), Akaike Information Criterion (AIC), and Bayesian Information Criterion (BIC). It provides a dedicated class, allowing for summary prints of the optimal model and a plotting function to conveniently analyse the optimal model via heatmaps.",
    "version": "0.1-2",
    "maintainer": "Simon Trimborn <trimborn.econometrics@gmail.com>",
    "author": "Simon Trimborn [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NetVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NetVAR Network Structures in VAR Models Vector AutoRegressive (VAR) type models with tailored regularisation structures are provided to uncover network type structures in the data, such as influential time series (influencers). Currently the package implements the LISAR model from Zhang and Trimborn (2023) <doi:10.2139/ssrn.4619531>. The package automatically derives the required regularisation sequences and refines it during the estimation to provide the optimal model. The package allows for model optimisation under various loss functions such as Mean Squared Forecasting Error (MSFE), Akaike Information Criterion (AIC), and Bayesian Information Criterion (BIC). It provides a dedicated class, allowing for summary prints of the optimal model and a plotting function to conveniently analyse the optimal model via heatmaps.  "
  },
  {
    "id": 5348,
    "package_name": "NonParRolCor",
    "title": "a Non-Parametric Statistical Significance Test for Rolling\nWindow Correlation",
    "description": "Estimates and plots (as a single plot and as a heat map) the rolling window correlation coefficients between two time series and computes their statistical significance, which is carried out through a non-parametric computing-intensive method. This method addresses the effects due to the multiple testing (inflation of the Type I error) when the statistical significance is estimated for the rolling window correlation coefficients. The method is based on Monte Carlo simulations by permuting one of the variables (e.g., the dependent) under analysis and keeping fixed the other variable (e.g., the independent). We improve the computational efficiency of this method to reduce the computation time through parallel computing. The 'NonParRolCor' package also provides examples with synthetic and real-life environmental time series to exemplify its use. Methods derived from R. Telford (2013) <https://quantpalaeo.wordpress.com/2013/01/04/> and J.M. Polanco-Martinez and J.L. Lopez-Martinez (2021) <doi:10.1016/j.ecoinf.2021.101379>.",
    "version": "0.8.0",
    "maintainer": "Josue M. Polanco-Martinez <josue.m.polanco@gmail.com>",
    "author": "Josue M. Polanco-Martinez [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>),\n  Jose L. Lopez-Martinez [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2489-7559>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NonParRolCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NonParRolCor a Non-Parametric Statistical Significance Test for Rolling\nWindow Correlation Estimates and plots (as a single plot and as a heat map) the rolling window correlation coefficients between two time series and computes their statistical significance, which is carried out through a non-parametric computing-intensive method. This method addresses the effects due to the multiple testing (inflation of the Type I error) when the statistical significance is estimated for the rolling window correlation coefficients. The method is based on Monte Carlo simulations by permuting one of the variables (e.g., the dependent) under analysis and keeping fixed the other variable (e.g., the independent). We improve the computational efficiency of this method to reduce the computation time through parallel computing. The 'NonParRolCor' package also provides examples with synthetic and real-life environmental time series to exemplify its use. Methods derived from R. Telford (2013) <https://quantpalaeo.wordpress.com/2013/01/04/> and J.M. Polanco-Martinez and J.L. Lopez-Martinez (2021) <doi:10.1016/j.ecoinf.2021.101379>.  "
  },
  {
    "id": 5350,
    "package_name": "NonlinearTSA",
    "title": "Nonlinear Time Series Analysis",
    "description": "Function and data sets in the book entitled \"Nonlinear Time Series Analysis with R Applications\" B.Guris (2020). The book will be published in Turkish and the original name of this book will be \"R Uygulamali Dogrusal Olmayan Zaman Serileri Analizi\". It is possible to perform nonlinearity tests, nonlinear unit root tests, nonlinear cointegration tests and estimate nonlinear error correction models by using the functions written in this package. The Momentum Threshold Autoregressive (MTAR), the Smooth Threshold Autoregressive (STAR) and the Self Exciting Threshold Autoregressive (SETAR) type unit root tests can be performed using the functions written. In addition, cointegration tests using the Momentum Threshold Autoregressive (MTAR), the Smooth Threshold Autoregressive (STAR) and the Self Exciting Threshold Autoregressive (SETAR) models can be applied. It is possible to estimate nonlinear error correction models. The Granger causality test performed using nonlinear models can also be applied.",
    "version": "0.5.0",
    "maintainer": "Burak Guris <bguris@istanbul.edu.tr>",
    "author": "Burak Guris <bguris@istanbul.edu.tr>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NonlinearTSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NonlinearTSA Nonlinear Time Series Analysis Function and data sets in the book entitled \"Nonlinear Time Series Analysis with R Applications\" B.Guris (2020). The book will be published in Turkish and the original name of this book will be \"R Uygulamali Dogrusal Olmayan Zaman Serileri Analizi\". It is possible to perform nonlinearity tests, nonlinear unit root tests, nonlinear cointegration tests and estimate nonlinear error correction models by using the functions written in this package. The Momentum Threshold Autoregressive (MTAR), the Smooth Threshold Autoregressive (STAR) and the Self Exciting Threshold Autoregressive (SETAR) type unit root tests can be performed using the functions written. In addition, cointegration tests using the Momentum Threshold Autoregressive (MTAR), the Smooth Threshold Autoregressive (STAR) and the Self Exciting Threshold Autoregressive (SETAR) models can be applied. It is possible to estimate nonlinear error correction models. The Granger causality test performed using nonlinear models can also be applied.  "
  },
  {
    "id": 5362,
    "package_name": "NutrienTrackeR",
    "title": "Food Composition Information and Dietary Assessment",
    "description": "Provides a tool set for food information and dietary assessment. It \n    uses food composition data from several reference databases, including: 'USDA' (United States), \n    'CIQUAL' (France), 'BEDCA' (Spain), 'CNF' (Canada) and 'STFCJ' (Japan). 'NutrienTrackeR' calculates \n    the intake levels for both macronutrient and micronutrients, and compares them with the recommended \n    dietary allowances (RDA). It includes a number of visualization tools, such as time series \n    plots of nutrient intake, and pie-charts showing the main foods contributing to the intake \n    level of a given nutrient. A shiny app exposing the main functionalities of the package is also \n    provided.",
    "version": "1.4.0",
    "maintainer": "Rafael Ayala <rafaelayalahernandez@gmail.com>",
    "author": "Andrea Rodriguez-Martinez [aut],\n  Rafael Ayala [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9332-4623>),\n  Mark Balchunas [aut],\n  Pablo Hernandez [aut] (ORCID: <https://orcid.org/0009-0000-9279-6744>),\n  Lara Sell\u00e9s Vidal [aut] (ORCID:\n    <https://orcid.org/0000-0003-2537-6824>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NutrienTrackeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NutrienTrackeR Food Composition Information and Dietary Assessment Provides a tool set for food information and dietary assessment. It \n    uses food composition data from several reference databases, including: 'USDA' (United States), \n    'CIQUAL' (France), 'BEDCA' (Spain), 'CNF' (Canada) and 'STFCJ' (Japan). 'NutrienTrackeR' calculates \n    the intake levels for both macronutrient and micronutrients, and compares them with the recommended \n    dietary allowances (RDA). It includes a number of visualization tools, such as time series \n    plots of nutrient intake, and pie-charts showing the main foods contributing to the intake \n    level of a given nutrient. A shiny app exposing the main functionalities of the package is also \n    provided.  "
  },
  {
    "id": 5381,
    "package_name": "OLCPM",
    "title": "Online Change Point Detection for Matrix-Valued Time Series",
    "description": "We provide two algorithms for monitoring change points with online matrix-valued time series, under the assumption of a two-way factor structure. The algorithms are based on different calculations of the second moment matrices. One is based on stacking the columns of matrix observations, while another is by a more delicate projected approach. A well-known fact is that, in the presence of a change point, a factor model can be rewritten as a model with a larger number of common factors. In turn, this entails that, in the presence of a change point, the number of spiked eigenvalues in the second moment matrix of the data increases. Based on this, we propose two families of procedures - one based on the fluctuations of partial sums, and one based on extreme value theory - to monitor whether the first non-spiked eigenvalue diverges after a point in time in the monitoring horizon, thereby indicating the presence of a change point. This package also provides some simple functions for detecting and removing outliers, imputing missing entries and testing moments. See more details in He et al. (2021)<doi:10.48550/arXiv.2112.13479>.",
    "version": "0.1.2",
    "maintainer": "Long Yu <fduyulong@163.com>",
    "author": "Yong He [aut],\n  Xinbing Kong [aut],\n  Lorenzo Trapani [aut],\n  Long Yu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OLCPM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OLCPM Online Change Point Detection for Matrix-Valued Time Series We provide two algorithms for monitoring change points with online matrix-valued time series, under the assumption of a two-way factor structure. The algorithms are based on different calculations of the second moment matrices. One is based on stacking the columns of matrix observations, while another is by a more delicate projected approach. A well-known fact is that, in the presence of a change point, a factor model can be rewritten as a model with a larger number of common factors. In turn, this entails that, in the presence of a change point, the number of spiked eigenvalues in the second moment matrix of the data increases. Based on this, we propose two families of procedures - one based on the fluctuations of partial sums, and one based on extreme value theory - to monitor whether the first non-spiked eigenvalue diverges after a point in time in the monitoring horizon, thereby indicating the presence of a change point. This package also provides some simple functions for detecting and removing outliers, imputing missing entries and testing moments. See more details in He et al. (2021)<doi:10.48550/arXiv.2112.13479>.  "
  },
  {
    "id": 5414,
    "package_name": "OTUtable",
    "title": "North Temperate Lakes - Microbial Observatory 16S Time Series\nData and Functions",
    "description": "Analyses of OTU tables produced by 16S rRNA gene amplicon sequencing, as well as example data. It contains the data and scripts used in the paper Linz, et al. (2017) \"Bacterial community composition and dynamics spanning five years in freshwater bog lakes,\" <doi: 10.1128/mSphere.00169-17>.",
    "version": "1.1.2",
    "maintainer": "Alexandra Linz <amlinz16@gmail.com>",
    "author": "Alexandra Linz",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OTUtable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OTUtable North Temperate Lakes - Microbial Observatory 16S Time Series\nData and Functions Analyses of OTU tables produced by 16S rRNA gene amplicon sequencing, as well as example data. It contains the data and scripts used in the paper Linz, et al. (2017) \"Bacterial community composition and dynamics spanning five years in freshwater bog lakes,\" <doi: 10.1128/mSphere.00169-17>.  "
  },
  {
    "id": 5446,
    "package_name": "OnboardClient",
    "title": "Bindings for Onboard Data's Building Data API",
    "description": "Provides a wrapper for the Onboard Data building data API <https://api.onboarddata.io/swagger>. Along with streamlining access to the API, this package simplifies access to sensor time series data, metadata (sensors, equipment, and buildings), and details about the Onboard data model/ontology.",
    "version": "1.0.0",
    "maintainer": "Christopher Dudas-Thomas <christopher@onboarddata.io>",
    "author": "Pranay Shah [aut],\n  Christopher Dudas-Thomas [cre, aut],\n  Onboard Data [cph, fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OnboardClient",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OnboardClient Bindings for Onboard Data's Building Data API Provides a wrapper for the Onboard Data building data API <https://api.onboarddata.io/swagger>. Along with streamlining access to the API, this package simplifies access to sensor time series data, metadata (sensors, equipment, and buildings), and details about the Onboard data model/ontology.  "
  },
  {
    "id": 5462,
    "package_name": "OpeNoise",
    "title": "Environmental Noise Pollution Data Analysis",
    "description": "Provides analyse, interpret and understand noise pollution data. Data are typically regular time series measured with sound meter. The package is partially described in Fogola, Grasso, Masera and Scordino (2023, <DOI:10.61782/fa.2023.0063>).",
    "version": "0.2-18",
    "maintainer": "Pasquale Scordino <scordino.pasquale@gmail.com>",
    "author": "Pasquale Scordino [aut, cre],\n  Simone Sperotto [ctb],\n  Stefano Masera [ctb],\n  Daniele Grasso [ctb],\n  Jacopo Fogola [ctb]",
    "url": "https://arpapiemonte.github.io/openoise-analysis/,\nhttps://github.com/Arpapiemonte/openoise-analysis/",
    "bug_reports": "https://github.com/Arpapiemonte/openoise-analysis/issues/",
    "repository": "https://cran.r-project.org/package=OpeNoise",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OpeNoise Environmental Noise Pollution Data Analysis Provides analyse, interpret and understand noise pollution data. Data are typically regular time series measured with sound meter. The package is partially described in Fogola, Grasso, Masera and Scordino (2023, <DOI:10.61782/fa.2023.0063>).  "
  },
  {
    "id": 5466,
    "package_name": "OpenLand",
    "title": "Quantitative Analysis and Visualization of LUCC",
    "description": "Tools for the analysis of land use and cover (LUC) time series. It \n    includes support for loading spatiotemporal raster data and synthesized \n    spatial plotting. Several LUC change (LUCC) metrics in regular or irregular \n    time intervals can be extracted and visualized through one- and multistep \n    sankey and chord diagrams. A complete intensity analysis according to \n    Aldwaik and Pontius (2012) <doi:10.1016/j.landurbplan.2012.02.010> is \n    implemented, including tools for the generation of standardized multilevel \n    output graphics.",
    "version": "1.0.3",
    "maintainer": "Reginal Exavier <reginalexavier@rocketmail.com>",
    "author": "Reginal Exavier [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5237-523X>),\n  Peter Zeilhofer [aut]",
    "url": "https://reginalexavier.github.io/OpenLand/,\nhttps://github.com/reginalexavier/OpenLand",
    "bug_reports": "https://github.com/reginalexavier/OpenLand/issues",
    "repository": "https://cran.r-project.org/package=OpenLand",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OpenLand Quantitative Analysis and Visualization of LUCC Tools for the analysis of land use and cover (LUC) time series. It \n    includes support for loading spatiotemporal raster data and synthesized \n    spatial plotting. Several LUC change (LUCC) metrics in regular or irregular \n    time intervals can be extracted and visualized through one- and multistep \n    sankey and chord diagrams. A complete intensity analysis according to \n    Aldwaik and Pontius (2012) <doi:10.1016/j.landurbplan.2012.02.010> is \n    implemented, including tools for the generation of standardized multilevel \n    output graphics.  "
  },
  {
    "id": 5502,
    "package_name": "OscillatorGenerator",
    "title": "Generation of Customizable, Discretized Time Series of\nOscillating Species",
    "description": "The supplied code allows for the generation of discrete time series of oscillating species. General shapes can be selected by means of individual functions, which are widely customizable by means of function arguments. All code was developed in the Biological Information Processing Group at the BioQuant Center at Heidelberg University, Germany.",
    "version": "0.1.0",
    "maintainer": "Arne Schoch <arne_schoch@gmx.net>",
    "author": "Arne Schoch [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OscillatorGenerator",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OscillatorGenerator Generation of Customizable, Discretized Time Series of\nOscillating Species The supplied code allows for the generation of discrete time series of oscillating species. General shapes can be selected by means of individual functions, which are widely customizable by means of function arguments. All code was developed in the Biological Information Processing Group at the BioQuant Center at Heidelberg University, Germany.  "
  },
  {
    "id": 5515,
    "package_name": "PAFit",
    "title": "Generative Mechanism Estimation in Temporal Complex Networks",
    "description": "Statistical methods for estimating preferential attachment and node fitness generative mechanisms in temporal complex networks are provided. Thong Pham et al. (2015) <doi:10.1371/journal.pone.0137796>. Thong Pham et al. (2016) <doi:10.1038/srep32558>. Thong Pham et al. (2020) <doi:10.18637/jss.v092.i03>. Thong Pham et al. (2021) <doi:10.1093/comnet/cnab024>.  ",
    "version": "1.2.11",
    "maintainer": "Thong Pham <thongphamthe@gmail.com>",
    "author": "Thong Pham [aut, cre],\n  Paul Sheridan [aut],\n  Hidetoshi Shimodaira [aut]",
    "url": "https://github.com/thongphamthe/PAFit",
    "bug_reports": "https://github.com/thongphamthe/PAFit/issues",
    "repository": "https://cran.r-project.org/package=PAFit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PAFit Generative Mechanism Estimation in Temporal Complex Networks Statistical methods for estimating preferential attachment and node fitness generative mechanisms in temporal complex networks are provided. Thong Pham et al. (2015) <doi:10.1371/journal.pone.0137796>. Thong Pham et al. (2016) <doi:10.1038/srep32558>. Thong Pham et al. (2020) <doi:10.18637/jss.v092.i03>. Thong Pham et al. (2021) <doi:10.1093/comnet/cnab024>.    "
  },
  {
    "id": 5570,
    "package_name": "PDMIF",
    "title": "Fits Heterogeneous Panel Data Models",
    "description": "Fits heterogeneous panel data models with interactive effects for linear regression, logistic, count, probit, quantile, and clustering. Based on Ando, T. and Bai, J. (2015) \"A simple new test for slope homogeneity in panel data models with interactive effects\" <doi: 10.1016/j.econlet.2015.09.019>, Ando, T. and Bai, J. (2015) \"Asset Pricing with a General Multifactor Structure\" <doi: 10.1093/jjfinex/nbu026> , Ando, T. and Bai, J. (2016) \"Panel data models with grouped factor structure under unknown group membership\" <doi: 10.1002/jae.2467>, Ando, T. and Bai, J. (2017) \"Clustering huge number of financial time series: A panel data approach with high-dimensional predictors and factor structures\" <doi: 10.1080/01621459.2016.1195743>, Ando, T. and Bai, J. (2020) \"Quantile co-movement in financial markets\" <doi: 10.1080/01621459.2018.1543598>, Ando, T., Bai, J. and Li, K. (2021) \"Bayesian and maximum likelihood analysis of large-scale panel choice models with unobserved heterogeneity\" <doi: 10.1016/j.jeconom.2020.11.013.>.",
    "version": "0.1.0",
    "maintainer": "Tomohiro Ando <t.ando@mbs.edu>",
    "author": "Tomohiro Ando [aut, cre],\n  Hani Fayad [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PDMIF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PDMIF Fits Heterogeneous Panel Data Models Fits heterogeneous panel data models with interactive effects for linear regression, logistic, count, probit, quantile, and clustering. Based on Ando, T. and Bai, J. (2015) \"A simple new test for slope homogeneity in panel data models with interactive effects\" <doi: 10.1016/j.econlet.2015.09.019>, Ando, T. and Bai, J. (2015) \"Asset Pricing with a General Multifactor Structure\" <doi: 10.1093/jjfinex/nbu026> , Ando, T. and Bai, J. (2016) \"Panel data models with grouped factor structure under unknown group membership\" <doi: 10.1002/jae.2467>, Ando, T. and Bai, J. (2017) \"Clustering huge number of financial time series: A panel data approach with high-dimensional predictors and factor structures\" <doi: 10.1080/01621459.2016.1195743>, Ando, T. and Bai, J. (2020) \"Quantile co-movement in financial markets\" <doi: 10.1080/01621459.2018.1543598>, Ando, T., Bai, J. and Li, K. (2021) \"Bayesian and maximum likelihood analysis of large-scale panel choice models with unobserved heterogeneity\" <doi: 10.1016/j.jeconom.2020.11.013.>.  "
  },
  {
    "id": 5591,
    "package_name": "PGaGEV",
    "title": "Power Garima-Generalized Extreme Value Distribution",
    "description": "Density, distribution function, quantile function, \n    and random generation function based on Kittipong Klinjan,Tipat Sottiwan and Sirinapa Aryuyuen (2024)<DOI:10.28919/cmbn/8833>.",
    "version": "0.1.0",
    "maintainer": "Kittipong Klinjan <kittipong_k@rmutt.ac.th>",
    "author": "Kittipong Klinjan [cre, aut],\n  Tipat Sottiwan [aut],\n  Sirinapa Aryuyuen [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PGaGEV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PGaGEV Power Garima-Generalized Extreme Value Distribution Density, distribution function, quantile function, \n    and random generation function based on Kittipong Klinjan,Tipat Sottiwan and Sirinapa Aryuyuen (2024)<DOI:10.28919/cmbn/8833>.  "
  },
  {
    "id": 5597,
    "package_name": "PHSMM",
    "title": "Penalised Maximum Likelihood Estimation for Hidden Semi-Markov\nModels",
    "description": "Provides tools for penalised maximum likelihood estimation of hidden semi-Markov models (HSMMs) with flexible state dwell-time distributions. These include functions for model fitting, model checking and state-decoding. The package considers HSMMs for univariate time series with state-dependent gamma, normal, Poisson or Bernoulli distributions. For details, see Pohle, J., Adam, T. and Beumer, L.T. (2021): Flexible estimation of the state dwell-time distribution in hidden semi-Markov models. <arXiv:2101.09197>.",
    "version": "1.0",
    "maintainer": "Jennifer Pohle <jennifer.pohle@uni-bielefeld.de>",
    "author": "Jennifer Pohle",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PHSMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PHSMM Penalised Maximum Likelihood Estimation for Hidden Semi-Markov\nModels Provides tools for penalised maximum likelihood estimation of hidden semi-Markov models (HSMMs) with flexible state dwell-time distributions. These include functions for model fitting, model checking and state-decoding. The package considers HSMMs for univariate time series with state-dependent gamma, normal, Poisson or Bernoulli distributions. For details, see Pohle, J., Adam, T. and Beumer, L.T. (2021): Flexible estimation of the state dwell-time distribution in hidden semi-Markov models. <arXiv:2101.09197>.  "
  },
  {
    "id": 5622,
    "package_name": "PLRModels",
    "title": "Statistical Inference in Partial Linear Regression Models",
    "description": "Contains statistical inference tools applied to Partial Linear Regression (PLR) models. Specifically, point estimation, confidence intervals estimation, bandwidth selection, goodness-of-fit tests and analysis of covariance are considered. Kernel-based methods, combined with ordinary least squares estimation, are used and time series errors are allowed. In addition, these techniques are also implemented for both parametric (linear) and nonparametric regression models.",
    "version": "1.4",
    "maintainer": "Ana Lopez-Cheda <ana.lopez.cheda@udc.es>",
    "author": "German Aneiros Perez and Ana Lopez-Cheda",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PLRModels",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PLRModels Statistical Inference in Partial Linear Regression Models Contains statistical inference tools applied to Partial Linear Regression (PLR) models. Specifically, point estimation, confidence intervals estimation, bandwidth selection, goodness-of-fit tests and analysis of covariance are considered. Kernel-based methods, combined with ordinary least squares estimation, are used and time series errors are allowed. In addition, these techniques are also implemented for both parametric (linear) and nonparametric regression models.  "
  },
  {
    "id": 5634,
    "package_name": "PNAR",
    "title": "Poisson Network Autoregressive Models",
    "description": "Quasi likelihood-based methods for estimating linear and log-linear Poisson Network Autoregression models with p lags and covariates. Tools for testing the linearity versus several non-linear alternatives. Tools for simulation of multivariate count distributions, from linear and non-linear PNAR models, by using a specific copula construction. References include: Armillotta, M. and K. Fokianos (2023). \"Nonlinear network autoregression\". Annals of Statistics, 51(6): 2526--2552. <doi:10.1214/23-AOS2345>. Armillotta, M. and K. Fokianos (2024). \"Count network autoregression\". Journal of Time Series Analysis, 45(4): 584--612. <doi:10.1111/jtsa.12728>. Armillotta, M., Tsagris, M. and Fokianos, K. (2024). \"Inference for Network Count Time Series with the R Package PNAR\". The R Journal, 15/4: 255--269. <doi:10.32614/RJ-2023-094>.",
    "version": "1.7",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "author": "Michail Tsagris [aut, cre],\n  Mirko Armillotta [aut, cph],\n  Konstantinos Fokianos [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PNAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PNAR Poisson Network Autoregressive Models Quasi likelihood-based methods for estimating linear and log-linear Poisson Network Autoregression models with p lags and covariates. Tools for testing the linearity versus several non-linear alternatives. Tools for simulation of multivariate count distributions, from linear and non-linear PNAR models, by using a specific copula construction. References include: Armillotta, M. and K. Fokianos (2023). \"Nonlinear network autoregression\". Annals of Statistics, 51(6): 2526--2552. <doi:10.1214/23-AOS2345>. Armillotta, M. and K. Fokianos (2024). \"Count network autoregression\". Journal of Time Series Analysis, 45(4): 584--612. <doi:10.1111/jtsa.12728>. Armillotta, M., Tsagris, M. and Fokianos, K. (2024). \"Inference for Network Count Time Series with the R Package PNAR\". The R Journal, 15/4: 255--269. <doi:10.32614/RJ-2023-094>.  "
  },
  {
    "id": 5674,
    "package_name": "PRISM.forecast",
    "title": "Penalized Regression with Inferred Seasonality Module -\nForecasting Unemployment Initial Claims using 'Google Trends'\nData",
    "description": "Implements Penalized Regression with Inferred Seasonality Module (PRISM) to generate forecast estimation of weekly unemployment initial claims using 'Google Trends' data. It includes required data and tools for backtesting the performance in 2007-2020.",
    "version": "0.2.1",
    "maintainer": "Dingdong Yi <ryan.ddyi@gmail.com>",
    "author": "Dingdong Yi [aut, cre],\n  Samuel Kou [aut],\n  Shaoyang Ning [aut]",
    "url": "https://github.com/ryanddyi/prism",
    "bug_reports": "https://github.com/ryanddyi/prism/issues",
    "repository": "https://cran.r-project.org/package=PRISM.forecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PRISM.forecast Penalized Regression with Inferred Seasonality Module -\nForecasting Unemployment Initial Claims using 'Google Trends'\nData Implements Penalized Regression with Inferred Seasonality Module (PRISM) to generate forecast estimation of weekly unemployment initial claims using 'Google Trends' data. It includes required data and tools for backtesting the performance in 2007-2020.  "
  },
  {
    "id": 5696,
    "package_name": "PSF",
    "title": "Forecasting of Univariate Time Series Using the Pattern\nSequence-Based Forecasting (PSF) Algorithm",
    "description": "Pattern Sequence Based Forecasting (PSF) takes univariate\n    time series data as input and assist to forecast its future values.\n    This algorithm forecasts the behavior of time series\n    based on similarity of pattern sequences. Initially, clustering is done with the\n    labeling of samples from database. The labels associated with samples are then\n    used for forecasting the future behaviour of time series data. The further\n    technical details and references regarding PSF are discussed in Vignette.",
    "version": "0.5",
    "maintainer": "Neeraj Bokde <neerajdhanraj@gmail.com>",
    "author": "Neeraj Bokde, Gualberto Asencio-Cortes and Francisco Martinez-Alvarez",
    "url": "https://www.neerajbokde.in/viggnette/2021-10-13-PSF/",
    "bug_reports": "https://github.com/neerajdhanraj/PSF/issues",
    "repository": "https://cran.r-project.org/package=PSF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PSF Forecasting of Univariate Time Series Using the Pattern\nSequence-Based Forecasting (PSF) Algorithm Pattern Sequence Based Forecasting (PSF) takes univariate\n    time series data as input and assist to forecast its future values.\n    This algorithm forecasts the behavior of time series\n    based on similarity of pattern sequences. Initially, clustering is done with the\n    labeling of samples from database. The labels associated with samples are then\n    used for forecasting the future behaviour of time series data. The further\n    technical details and references regarding PSF are discussed in Vignette.  "
  },
  {
    "id": 5704,
    "package_name": "PSRICalc",
    "title": "Plant Stress Response Index Calculator",
    "description": "Calculate Plant Stress Response Index (PSRI) from time-series\n    germination data with optional radicle vigor integration. Built on the\n    methodological foundation of the Osmotic Stress Response Index (OSRI)\n    framework developed by Walne et al. (2020) <doi:10.1002/agg2.20087>.\n    Provides clean, direct PSRI calculations suitable for agricultural research\n    and statistical analysis. Note: This package implements methodology\n    currently under peer review. Please contact the author before publication\n    using this approach.",
    "version": "1.0.0",
    "maintainer": "Richard Feiss <feiss026@umn.edu>",
    "author": "Richard Feiss [aut, cre],\n  University of Minnesota [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PSRICalc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PSRICalc Plant Stress Response Index Calculator Calculate Plant Stress Response Index (PSRI) from time-series\n    germination data with optional radicle vigor integration. Built on the\n    methodological foundation of the Osmotic Stress Response Index (OSRI)\n    framework developed by Walne et al. (2020) <doi:10.1002/agg2.20087>.\n    Provides clean, direct PSRI calculations suitable for agricultural research\n    and statistical analysis. Note: This package implements methodology\n    currently under peer review. Please contact the author before publication\n    using this approach.  "
  },
  {
    "id": 5717,
    "package_name": "PTSR",
    "title": "Positive Time Series Regression",
    "description": "A collection of functions to simulate, estimate and forecast a wide range of regression based dynamic models for positive time series. This package implements the results presented in Prass, T.S.; Pumi, G.; Taufemback, C.G. and Carlos, J.H. (2025). \"Positive time series regression models: theoretical and computational aspects\". Computational Statistics 40, 1185\u20131215. <doi:10.1007/s00180-024-01531-z>.",
    "version": "0.1.3",
    "maintainer": "Taiane Schaedler Prass <taianeprass@gmail.com>",
    "author": "Taiane Schaedler Prass [aut, cre, com] (ORCID:\n    <https://orcid.org/0000-0003-3136-909X>),\n  Jonas Hendler Carlos [aut],\n  Cleiton Guollo Taufemback [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PTSR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PTSR Positive Time Series Regression A collection of functions to simulate, estimate and forecast a wide range of regression based dynamic models for positive time series. This package implements the results presented in Prass, T.S.; Pumi, G.; Taufemback, C.G. and Carlos, J.H. (2025). \"Positive time series regression models: theoretical and computational aspects\". Computational Statistics 40, 1185\u20131215. <doi:10.1007/s00180-024-01531-z>.  "
  },
  {
    "id": 5726,
    "package_name": "PVAClone",
    "title": "Population Viability Analysis with Data Cloning",
    "description": "Likelihood based population viability analysis in the\n  presence of observation error and missing data.\n  The package can be used to fit, compare, predict,\n  and forecast various growth model types using data cloning.",
    "version": "0.1-8",
    "maintainer": "Peter Solymos <psolymos@gmail.com>",
    "author": "Khurram Nadeem [aut],\n  Peter Solymos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7337-1740>)",
    "url": "https://github.com/psolymos/PVAClone",
    "bug_reports": "https://github.com/psolymos/PVAClone/issues",
    "repository": "https://cran.r-project.org/package=PVAClone",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PVAClone Population Viability Analysis with Data Cloning Likelihood based population viability analysis in the\n  presence of observation error and missing data.\n  The package can be used to fit, compare, predict,\n  and forecast various growth model types using data cloning.  "
  },
  {
    "id": 5730,
    "package_name": "PWEV",
    "title": "PSO Based Weighted Ensemble Algorithm for Volatility Modelling",
    "description": "Price volatility refers to the degree of variation in series over a certain period of time. This volatility is especially noticeable in agricultural commodities, adding uncertainty for farmers, traders, and others in the agricultural supply chain. Commonly and popularly used four volatility models viz, GARCH, Glosten Jagannatan Runkle-GARCH (GJR-GARCH) model, exponentially weighted moving average (EWMA) model and Multiplicative Error Model (MEM) are selected and implemented. PWAVE, weighted ensemble model based on particle swarm optimization (PSO) is proposed to combine the forecast obtained from all the candidate models. This package has been developed using algorithm of Paul et al. <doi:10.1007/s40009-023-01218-x> and Yeasin and Paul (2024) <doi:10.1007/s11227-023-05542-3>.",
    "version": "0.1.0",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Mr. Ankit Kumar Singh [aut],\n  Dr. Ranjit Kumar Paul [aut, cre],\n  Dr. Amrit Kumar Paul [aut],\n  Dr. Md Yeasin [aut],\n  Ms. Anita Sarkar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PWEV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PWEV PSO Based Weighted Ensemble Algorithm for Volatility Modelling Price volatility refers to the degree of variation in series over a certain period of time. This volatility is especially noticeable in agricultural commodities, adding uncertainty for farmers, traders, and others in the agricultural supply chain. Commonly and popularly used four volatility models viz, GARCH, Glosten Jagannatan Runkle-GARCH (GJR-GARCH) model, exponentially weighted moving average (EWMA) model and Multiplicative Error Model (MEM) are selected and implemented. PWAVE, weighted ensemble model based on particle swarm optimization (PSO) is proposed to combine the forecast obtained from all the candidate models. This package has been developed using algorithm of Paul et al. <doi:10.1007/s40009-023-01218-x> and Yeasin and Paul (2024) <doi:10.1007/s11227-023-05542-3>.  "
  },
  {
    "id": 5758,
    "package_name": "PanelTM",
    "title": "Two- And Three-Way Dynamic Panel Threshold Regression Model for\nChange Point Detection",
    "description": "Estimation of two- and three-way dynamic panel threshold regression models (Di Lascio and Perazzini (2024) <https://repec.unibz.it/bemps104.pdf>; Di Lascio and Perazzini (2022, ISBN:978-88-9193-231-0); Seo and Shin (2016) <doi:10.1016/j.jeconom.2016.03.005>) through the generalized method of moments based on the first difference transformation and the use of instrumental variables. The models can be used to find a change point detection in the time series. In addition, random number generation is also implemented.",
    "version": "1.0",
    "maintainer": "F. Marta L. Di Lascio <marta.dilascio@unibz.it>",
    "author": "Selene Perazzini [aut],\n  F. Marta L. Di Lascio [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PanelTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PanelTM Two- And Three-Way Dynamic Panel Threshold Regression Model for\nChange Point Detection Estimation of two- and three-way dynamic panel threshold regression models (Di Lascio and Perazzini (2024) <https://repec.unibz.it/bemps104.pdf>; Di Lascio and Perazzini (2022, ISBN:978-88-9193-231-0); Seo and Shin (2016) <doi:10.1016/j.jeconom.2016.03.005>) through the generalized method of moments based on the first difference transformation and the use of instrumental variables. The models can be used to find a change point detection in the time series. In addition, random number generation is also implemented.  "
  },
  {
    "id": 5794,
    "package_name": "PerMat",
    "title": "Performance Metrics in Predictive Modeling",
    "description": "Performance metric provides different performance measures like mean squared error, root mean square error, mean absolute deviation, mean absolute percentage error etc. of a fitted model. These can provide a way for forecasters to quantitatively compare the performance of competing models. For method details see (i) Pankaj Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/44138>.",
    "version": "0.1.0",
    "maintainer": "Pankaj Das <pankaj.das2@icar.gov.in>",
    "author": "Pankaj Das [aut, cre] (ORCID: <https://orcid.org/0000-0003-1672-2502>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PerMat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PerMat Performance Metrics in Predictive Modeling Performance metric provides different performance measures like mean squared error, root mean square error, mean absolute deviation, mean absolute percentage error etc. of a fitted model. These can provide a way for forecasters to quantitatively compare the performance of competing models. For method details see (i) Pankaj Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/44138>.  "
  },
  {
    "id": 5807,
    "package_name": "Petersen",
    "title": "Estimators for Two-Sample Capture-Recapture Studies",
    "description": "A comprehensive implementation of Petersen-type estimators\n    and its many variants for two-sample capture-recapture studies.\n    A conditional likelihood approach is used that allows\n    for tag loss; non reporting of tags; reward tags; categorical, geographical and temporal stratification;\n    partial stratification; reverse capture-recapture;\n    and continuous variables in modeling the probability of capture.\n    Many examples from fisheries management are presented.",
    "version": "2025.3.1",
    "maintainer": "Carl Schwarz <cschwarz.stat.sfu.ca@gmail.com>",
    "author": "Carl Schwarz [aut, cre]",
    "url": "https://github.com/cschwarz-stat-sfu-ca/Petersen",
    "bug_reports": "https://github.com/cschwarz-stat-sfu-ca/Petersen/issues",
    "repository": "https://cran.r-project.org/package=Petersen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Petersen Estimators for Two-Sample Capture-Recapture Studies A comprehensive implementation of Petersen-type estimators\n    and its many variants for two-sample capture-recapture studies.\n    A conditional likelihood approach is used that allows\n    for tag loss; non reporting of tags; reward tags; categorical, geographical and temporal stratification;\n    partial stratification; reverse capture-recapture;\n    and continuous variables in modeling the probability of capture.\n    Many examples from fisheries management are presented.  "
  },
  {
    "id": 5862,
    "package_name": "PointFore",
    "title": "Interpretation of Point Forecasts as State-Dependent Quantiles\nand Expectiles",
    "description": "Estimate specification models for the state-dependent level of an optimal quantile/expectile forecast.\n  Wald Tests and the test of overidentifying restrictions are implemented. Plotting of the estimated specification model is possible.\n  The package contains two data sets with forecasts and realizations: the daily accumulated precipitation at London, UK from the high-resolution model of the\n  European Centre for Medium-Range Weather Forecasts (ECMWF, <https://www.ecmwf.int/>) and GDP growth Greenbook data by the US Federal Reserve.\n  See Schmidt, Katzfuss and Gneiting (2015) <arXiv:1506.01917> for more details on the identification and estimation of a directive behind a point forecast.",
    "version": "0.2.0",
    "maintainer": "Patrick Schmidt <pschmidte@gmail.com>",
    "author": "Patrick Schmidt [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PointFore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PointFore Interpretation of Point Forecasts as State-Dependent Quantiles\nand Expectiles Estimate specification models for the state-dependent level of an optimal quantile/expectile forecast.\n  Wald Tests and the test of overidentifying restrictions are implemented. Plotting of the estimated specification model is possible.\n  The package contains two data sets with forecasts and realizations: the daily accumulated precipitation at London, UK from the high-resolution model of the\n  European Centre for Medium-Range Weather Forecasts (ECMWF, <https://www.ecmwf.int/>) and GDP growth Greenbook data by the US Federal Reserve.\n  See Schmidt, Katzfuss and Gneiting (2015) <arXiv:1506.01917> for more details on the identification and estimation of a directive behind a point forecast.  "
  },
  {
    "id": 5884,
    "package_name": "PoolDilutionR",
    "title": "Calculate Gross Biogeochemical Flux Rates from Isotope Pool\nDilution Data",
    "description": "Pool dilution is a isotope tracer technique wherein a \n    biogeochemical pool is artifically enriched with its heavy isotopologue \n    and the gross productive and consumptive fluxes of that pool are \n    quantified by the change in pool size and isotopic composition over time. \n    This package calculates gross production and consumption rates from\n    closed-system isotopic pool dilution time series data. Pool size \n    concentrations and heavy isotope (e.g., 15N) content are measured over time \n    and the model optimizes production rate (P) and the first order rate \n    constant (k) by minimizing error in the model-predicted total pool size, \n    as well as the isotopic signature. The model optimizes rates by weighting \n    information against the signal:noise ratio of concentration and heavy-\n    isotope signatures using measurement precision as well as the magnitude of \n    change over time. The calculations used here are based on von Fischer and \n    Hedin (2002) <doi:10.1029/2001GB001448> with some modifications.",
    "version": "1.0.0",
    "maintainer": "Kendalynn A. Morris <kendalynn.morris@gmail.com>",
    "author": "Kendalynn A. Morris [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0388-6965>),\n  Ben Bond-Lamberty [ctb] (ORCID:\n    <https://orcid.org/0000-0001-9525-4633>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PoolDilutionR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PoolDilutionR Calculate Gross Biogeochemical Flux Rates from Isotope Pool\nDilution Data Pool dilution is a isotope tracer technique wherein a \n    biogeochemical pool is artifically enriched with its heavy isotopologue \n    and the gross productive and consumptive fluxes of that pool are \n    quantified by the change in pool size and isotopic composition over time. \n    This package calculates gross production and consumption rates from\n    closed-system isotopic pool dilution time series data. Pool size \n    concentrations and heavy isotope (e.g., 15N) content are measured over time \n    and the model optimizes production rate (P) and the first order rate \n    constant (k) by minimizing error in the model-predicted total pool size, \n    as well as the isotopic signature. The model optimizes rates by weighting \n    information against the signal:noise ratio of concentration and heavy-\n    isotope signatures using measurement precision as well as the magnitude of \n    change over time. The calculations used here are based on von Fischer and \n    Hedin (2002) <doi:10.1029/2001GB001448> with some modifications.  "
  },
  {
    "id": 5894,
    "package_name": "PopulationGrowthR",
    "title": "Linear Population Growth Scenarios",
    "description": "Fit linear splines to species time series to detect population growth scenarios based on Hyndman, R J and Mesgaran, M B and Cousens, R D (2015) <doi:10.1007/s10530-015-0962-8>.",
    "version": "0.1.1",
    "maintainer": "Biman Chakraborty <biman_c@yahoo.com>",
    "author": "Philipp Robeck [aut],\n  Biman Chakraborty [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PopulationGrowthR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PopulationGrowthR Linear Population Growth Scenarios Fit linear splines to species time series to detect population growth scenarios based on Hyndman, R J and Mesgaran, M B and Cousens, R D (2015) <doi:10.1007/s10530-015-0962-8>.  "
  },
  {
    "id": 5895,
    "package_name": "PortalHacienda",
    "title": "Acceder Con R a Los Datos Del Portal De Hacienda",
    "description": "Obtener listado de datos, acceder y extender series del Portal de \n    Datos de Hacienda.Las proyecciones se realizan con 'forecast', \n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>. \n    Search, download and forecast time-series from the Ministry of Economy \n    of Argentina. Forecasts are built with the 'forecast' package, \n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>. ",
    "version": "0.1.7",
    "maintainer": "Fernando Garcia Diaz <fmgarciadiaz78@gmail.com>",
    "author": "Fernando Garcia Diaz [aut, cre]",
    "url": "https://github.com/fmgarciadiaz/PortalHacienda-CRAN",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PortalHacienda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PortalHacienda Acceder Con R a Los Datos Del Portal De Hacienda Obtener listado de datos, acceder y extender series del Portal de \n    Datos de Hacienda.Las proyecciones se realizan con 'forecast', \n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>. \n    Search, download and forecast time-series from the Ministry of Economy \n    of Argentina. Forecasts are built with the 'forecast' package, \n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>.   "
  },
  {
    "id": 5920,
    "package_name": "PredictorSelect",
    "title": "Out-of-Sample Predictability in Predictive Regressions with Many\nPredictor Candidates",
    "description": "Consider a linear predictive regression setting with a potentially large set of candidate predictors. This work is concerned with detecting the presence of out of sample predictability based on out of sample mean squared error comparisons given in Gonzalo and Pitarakis (2023) <doi:10.1016/j.ijforecast.2023.10.005>.",
    "version": "0.1.0",
    "maintainer": "Rong Peng <r.peng@soton.ac.uk>",
    "author": "Rong Peng [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PredictorSelect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PredictorSelect Out-of-Sample Predictability in Predictive Regressions with Many\nPredictor Candidates Consider a linear predictive regression setting with a potentially large set of candidate predictors. This work is concerned with detecting the presence of out of sample predictability based on out of sample mean squared error comparisons given in Gonzalo and Pitarakis (2023) <doi:10.1016/j.ijforecast.2023.10.005>.  "
  },
  {
    "id": 5977,
    "package_name": "PytrendsLongitudinalR",
    "title": "Create Longitudinal Google Trends Data",
    "description": "'Google Trends' provides cross-sectional and time-series data on searches, but lacks readily available \n    longitudinal data. Researchers, who want to create longitudinal 'Google Trends' on their own, face practical challenges, such as normalized counts that make it difficult to combine \n    cross-sectional and time-series data and limitations in data formats and timelines that limit data \n    granularity over extended time periods. \n    This package addresses these issues and enables researchers to generate longitudinal 'Google Trends' data.  \n    This package is built on 'pytrends', a Python library that acts as the unofficial 'Google Trends API' to collect 'Google Trends' data. As long as the 'Google Trends API', 'pytrends' and all their dependencies are working, this package will work.\n    During testing, we noticed that for the same input (keyword, topic, data_format, timeline), the output index can vary from time to time. Besides, if the keyword is not very popular, then the resulting dataset will contain a lot of zeros, which will greatly affect the final result. While this package has no control over the accuracy or quality of 'Google Trends' data, once the data is created, this package coverts it to longitudinal data.  \n    In addition, the user may encounter a 429 Too Many Requests error when using cross_section() and time_series() to collect 'Google Trends' data. This error indicates that the user has exceeded the rate limits set by the 'Google Trends API'. For more information about the 'Google Trends API' - 'pytrends', visit <https://pypi.org/project/pytrends/>.",
    "version": "0.1.4",
    "maintainer": "Taeyong Park <taeyongp@andrew.cmu.edu>",
    "author": "Taeyong Park [cre, cph, aut],\n  Malika Dixit [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PytrendsLongitudinalR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PytrendsLongitudinalR Create Longitudinal Google Trends Data 'Google Trends' provides cross-sectional and time-series data on searches, but lacks readily available \n    longitudinal data. Researchers, who want to create longitudinal 'Google Trends' on their own, face practical challenges, such as normalized counts that make it difficult to combine \n    cross-sectional and time-series data and limitations in data formats and timelines that limit data \n    granularity over extended time periods. \n    This package addresses these issues and enables researchers to generate longitudinal 'Google Trends' data.  \n    This package is built on 'pytrends', a Python library that acts as the unofficial 'Google Trends API' to collect 'Google Trends' data. As long as the 'Google Trends API', 'pytrends' and all their dependencies are working, this package will work.\n    During testing, we noticed that for the same input (keyword, topic, data_format, timeline), the output index can vary from time to time. Besides, if the keyword is not very popular, then the resulting dataset will contain a lot of zeros, which will greatly affect the final result. While this package has no control over the accuracy or quality of 'Google Trends' data, once the data is created, this package coverts it to longitudinal data.  \n    In addition, the user may encounter a 429 Too Many Requests error when using cross_section() and time_series() to collect 'Google Trends' data. This error indicates that the user has exceeded the rate limits set by the 'Google Trends API'. For more information about the 'Google Trends API' - 'pytrends', visit <https://pypi.org/project/pytrends/>.  "
  },
  {
    "id": 5983,
    "package_name": "QCA",
    "title": "Qualitative Comparative Analysis",
    "description": "An extensive set of functions to perform Qualitative Comparative Analysis:\n       crisp sets ('csQCA'), temporal ('tQCA'), multi-value ('mvQCA')\n       and fuzzy sets ('fsQCA'), using a GUI - graphical user interface.\n       'QCA' is a methodology that bridges the qualitative and quantitative\n       divide in social science research. It uses a Boolean minimization\n       algorithm, resulting in a minimal causal configuration associated\n       with a given phenomenon.",
    "version": "3.23",
    "maintainer": "Adrian Dusa <dusa.adrian@unibuc.ro>",
    "author": "Adrian Dusa [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-3525-9253>),\n  Ciprian Paduraru [ctb] (ORCID: <https://orcid.org/0000-0002-4518-374X>),\n  jQuery Foundation [cph] (jQuery library and jQuery UI library),\n  jQuery contributors [ctb, cph] (jQuery library; authors listed in\n    inst/gui/www/lib/jquery-AUTHORS.txt),\n  Vasil Dinkov [ctb, cph] (jquery.smartmenus.js library),\n  Dmitry Baranovskiy [ctb, cph] (raphael.js library),\n  Emmanuel Quentin [ctb, cph] (raphael.inline_text_editing.js library),\n  Jimmy Breck-McKye [ctb, cph] (raphael-paragraph.js library),\n  Alrik Thiem [aut] (from version 1.0-0 up to version 1.1-3)",
    "url": "https://github.com/dusadrian/QCA",
    "bug_reports": "https://github.com/dusadrian/QCA/issues",
    "repository": "https://cran.r-project.org/package=QCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QCA Qualitative Comparative Analysis An extensive set of functions to perform Qualitative Comparative Analysis:\n       crisp sets ('csQCA'), temporal ('tQCA'), multi-value ('mvQCA')\n       and fuzzy sets ('fsQCA'), using a GUI - graphical user interface.\n       'QCA' is a methodology that bridges the qualitative and quantitative\n       divide in social science research. It uses a Boolean minimization\n       algorithm, resulting in a minimal causal configuration associated\n       with a given phenomenon.  "
  },
  {
    "id": 6004,
    "package_name": "QR.break",
    "title": "Structural Breaks in Quantile Regression",
    "description": "Methods for detecting structural breaks, determining the\n    number of breaks, and estimating break locations in linear quantile\n    regression, using one or multiple quantiles, based on Qu (2008) and\n    Oka and Qu (2011).  Applicable to both time series and repeated\n    cross-sectional data. The main function is rq.break().\n\n        References for detailed theoretical and empirical explanations:\n\n        (1) Qu, Z. (2008).  \"Testing for Structural Change in Regression\n    Quantiles.\"  Journal of Econometrics, 146(1), 170-184\n    <doi:10.1016/j.jeconom.2008.08.006>\n\n        (2) Oka, T., and Qu, Z. (2011).  \"Estimating Structural Changes in\n    Regression Quantiles.\"  Journal of Econometrics, 162(2), 248-267\n    <doi:10.1016/j.jeconom.2011.01.005>.",
    "version": "1.0.2",
    "maintainer": "Zhongjun Qu <qu@bu.edu>",
    "author": "Zhongjun Qu [aut, cre],\n  Tatsushi Oka [aut],\n  Samuel Messer [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=QR.break",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QR.break Structural Breaks in Quantile Regression Methods for detecting structural breaks, determining the\n    number of breaks, and estimating break locations in linear quantile\n    regression, using one or multiple quantiles, based on Qu (2008) and\n    Oka and Qu (2011).  Applicable to both time series and repeated\n    cross-sectional data. The main function is rq.break().\n\n        References for detailed theoretical and empirical explanations:\n\n        (1) Qu, Z. (2008).  \"Testing for Structural Change in Regression\n    Quantiles.\"  Journal of Econometrics, 146(1), 170-184\n    <doi:10.1016/j.jeconom.2008.08.006>\n\n        (2) Oka, T., and Qu, Z. (2011).  \"Estimating Structural Changes in\n    Regression Quantiles.\"  Journal of Econometrics, 162(2), 248-267\n    <doi:10.1016/j.jeconom.2011.01.005>.  "
  },
  {
    "id": 6017,
    "package_name": "QWDAP",
    "title": "Quantum Walk-Based Data Analysis and Prediction",
    "description": "The modeling and prediction of graph-associated time series(GATS) based on continuous time quantum walk. This software is mainly used for feature extraction, modeling, prediction and result evaluation of GATS, including continuous time quantum walk simulation, feature selection, regression analysis, time series prediction, and series fit calculation. A paper is attached to the package for reference.",
    "version": "1.1.20",
    "maintainer": "Binghuang Pan <bright1up@163.com>",
    "author": "Binghuang Pan [aut, cre],\n  Zhaoyuan Yu [aut],\n  Xu Hu [ctb],\n  Yuhao Teng [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=QWDAP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QWDAP Quantum Walk-Based Data Analysis and Prediction The modeling and prediction of graph-associated time series(GATS) based on continuous time quantum walk. This software is mainly used for feature extraction, modeling, prediction and result evaluation of GATS, including continuous time quantum walk simulation, feature selection, regression analysis, time series prediction, and series fit calculation. A paper is attached to the package for reference.  "
  },
  {
    "id": 6025,
    "package_name": "QregBB",
    "title": "Block Bootstrap Methods for Quantile Regression in Time Series",
    "description": "Implements moving-blocks bootstrap and extended tapered-blocks bootstrap, as well as smooth versions of each, for quantile regression in time series. This package accompanies the paper: Gregory, K. B., Lahiri, S. N., & Nordman, D. J. (2018). A smooth block bootstrap for quantile regression with time series. The Annals of Statistics, 46(3), 1138-1166.",
    "version": "1.0.0",
    "maintainer": "Karl Gregory <gregorkb@stat.sc.edu>",
    "author": "Karl Gregory",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=QregBB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QregBB Block Bootstrap Methods for Quantile Regression in Time Series Implements moving-blocks bootstrap and extended tapered-blocks bootstrap, as well as smooth versions of each, for quantile regression in time series. This package accompanies the paper: Gregory, K. B., Lahiri, S. N., & Nordman, D. J. (2018). A smooth block bootstrap for quantile regression with time series. The Annals of Statistics, 46(3), 1138-1166.  "
  },
  {
    "id": 6124,
    "package_name": "RCMinification",
    "title": "Random Coefficient Minification Time Series Models",
    "description": "Data sets, and functions for simulating and fitting nonlinear time series with minification and nonparametric models.",
    "version": "1.2",
    "maintainer": "L. Han <lengyi.han@ubc.ca>",
    "author": "L. Han [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RCMinification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RCMinification Random Coefficient Minification Time Series Models Data sets, and functions for simulating and fitting nonlinear time series with minification and nonparametric models.  "
  },
  {
    "id": 6134,
    "package_name": "RCTS",
    "title": "Clustering Time Series While Resisting Outliers",
    "description": "Robust Clustering of Time Series (RCTS) has the functionality to cluster time series using both the classical and the robust interactive fixed effects framework. \n  The classical framework is developed in Ando & Bai (2017) <doi:10.1080/01621459.2016.1195743>. The implementation within this package excludes the SCAD-penalty on the estimations of beta. \n  This robust framework is developed in Boudt & Heyndels (2022) <doi:10.1016/j.ecosta.2022.01.002> and is made robust against different kinds of outliers.\n  The algorithm iteratively updates beta (the coefficients of the observable variables), group membership, and the latent factors (which can be common and/or group-specific) along\n  with their loadings. The number of groups and factors can be estimated if they are unknown.",
    "version": "0.2.4",
    "maintainer": "Ewoud Heyndels <ewoud.heyndels@vub.be>",
    "author": "Ewoud Heyndels [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4540-8571>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RCTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RCTS Clustering Time Series While Resisting Outliers Robust Clustering of Time Series (RCTS) has the functionality to cluster time series using both the classical and the robust interactive fixed effects framework. \n  The classical framework is developed in Ando & Bai (2017) <doi:10.1080/01621459.2016.1195743>. The implementation within this package excludes the SCAD-penalty on the estimations of beta. \n  This robust framework is developed in Boudt & Heyndels (2022) <doi:10.1016/j.ecosta.2022.01.002> and is made robust against different kinds of outliers.\n  The algorithm iteratively updates beta (the coefficients of the observable variables), group membership, and the latent factors (which can be common and/or group-specific) along\n  with their loadings. The number of groups and factors can be estimated if they are unknown.  "
  },
  {
    "id": 6138,
    "package_name": "RChest",
    "title": "Locating Distributional Changes in Highly Dependent Time Series",
    "description": "Provides algorithms to locate multiple\n    distributional change-points in piecewise stationary time series. The\n    algorithms are provably consistent, even in the presence of long-range\n    dependencies. Knowledge of the number of change-points is not\n    required. The code is written in Go and interfaced with R.",
    "version": "1.0.3",
    "maintainer": "Lukas Zierahn <lukas@kappa-mm.de>",
    "author": "Lukas Zierahn [cre, aut],\n  Azadeh Khaleghi [aut]",
    "url": "https://github.com/azalk/GoChest",
    "bug_reports": "https://github.com/azalk/GoChest/issues",
    "repository": "https://cran.r-project.org/package=RChest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RChest Locating Distributional Changes in Highly Dependent Time Series Provides algorithms to locate multiple\n    distributional change-points in piecewise stationary time series. The\n    algorithms are provably consistent, even in the presence of long-range\n    dependencies. Knowledge of the number of change-points is not\n    required. The code is written in Go and interfaced with R.  "
  },
  {
    "id": 6142,
    "package_name": "RClimacell",
    "title": "R Wrapper for the 'Climacell' API",
    "description": "'Climacell' is a weather platform that provides hyper-local forecasts and weather \n    data. This package enables the user to query the core layers of the \n    time line interface of the 'Climacell' v4 API <https://www.climacell.co/weather-api/>. \n    This package requires a valid API key. See vignettes for instructions on use.",
    "version": "0.1.4",
    "maintainer": "Nikhil Agarwal <gitnik@niks.me>",
    "author": "Nikhil Agarwal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1470-7472>)",
    "url": "https://nikdata.github.io/RClimacell/",
    "bug_reports": "https://github.com/nikdata/RClimacell/issues",
    "repository": "https://cran.r-project.org/package=RClimacell",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RClimacell R Wrapper for the 'Climacell' API 'Climacell' is a weather platform that provides hyper-local forecasts and weather \n    data. This package enables the user to query the core layers of the \n    time line interface of the 'Climacell' v4 API <https://www.climacell.co/weather-api/>. \n    This package requires a valid API key. See vignettes for instructions on use.  "
  },
  {
    "id": 6180,
    "package_name": "REPS",
    "title": "Hedonic and Multilateral Index Methods for Real Estate Price\nStatistics",
    "description": "Compute price indices using various Hedonic and\n    multilateral methods, including Laspeyres, Paasche, Fisher, and HMTS (Hedonic\n    Multilateral Time series re-estimation with splicing). The central function\n    calculate_price_index() offers a unified interface for running these methods\n    on structured datasets. This package is designed to support index construction workflows across a wide range of domains \n    \u2014 including but not limited to real estate \u2014 where quality-adjusted price comparisons over time are essential. \n    The development of this package was funded by Eurostat and Statistics Netherlands (CBS), and carried out by Statistics Netherlands.\n    The HMTS method implemented here is described in Ishaak, Ouwehand and Rem\u00f8y (2024)\n    <doi:10.1177/0282423X241246617>. For broader methodological context, see Eurostat\n    (2013, ISBN:978-92-79-25984-5, <doi:10.2785/34007>).",
    "version": "1.0.0",
    "maintainer": "Vivek Gajadhar <v.gajadhar@cbs.nl>",
    "author": "Farley Ishaak [aut],\n  Pim Ouwehand [aut],\n  David Pietersz [aut],\n  Liu Nuo Su [aut],\n  Cynthia Cao [aut],\n  Mohammed Kardal [aut],\n  Odens van der Zwan [aut],\n  Vivek Gajadhar [aut, cre]",
    "url": "https://github.com/vivekag7/REPS",
    "bug_reports": "https://github.com/vivekag7/REPS/issues",
    "repository": "https://cran.r-project.org/package=REPS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REPS Hedonic and Multilateral Index Methods for Real Estate Price\nStatistics Compute price indices using various Hedonic and\n    multilateral methods, including Laspeyres, Paasche, Fisher, and HMTS (Hedonic\n    Multilateral Time series re-estimation with splicing). The central function\n    calculate_price_index() offers a unified interface for running these methods\n    on structured datasets. This package is designed to support index construction workflows across a wide range of domains \n    \u2014 including but not limited to real estate \u2014 where quality-adjusted price comparisons over time are essential. \n    The development of this package was funded by Eurostat and Statistics Netherlands (CBS), and carried out by Statistics Netherlands.\n    The HMTS method implemented here is described in Ishaak, Ouwehand and Rem\u00f8y (2024)\n    <doi:10.1177/0282423X241246617>. For broader methodological context, see Eurostat\n    (2013, ISBN:978-92-79-25984-5, <doi:10.2785/34007>).  "
  },
  {
    "id": 6202,
    "package_name": "RFplus",
    "title": "Machine Learning for Merging Satellite and Ground Precipitation\nData",
    "description": "A machine learning algorithm that merges satellite and ground precipitation data using Random Forest for spatial prediction, residual modeling for bias correction, and quantile mapping for adjustment, ensuring accurate estimates across temporal scales and regions.",
    "version": "1.5-4",
    "maintainer": "Jonnathan Augusto Landi Bermeo <jonnathan.landi@outlook.com>",
    "author": "Jonnathan Augusto Landi Bermeo [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0003-3162-6647>),\n  Alex Avil\u00e9s [aut] (ORCID: <https://orcid.org/0000-0001-9278-5738>),\n  Dar\u00edo Zhi\u00f1a [aut] (ORCID: <https://orcid.org/0000-0001-9556-4025>),\n  Marco Mogro [aut] (ORCID: <https://orcid.org/0009-0007-1802-9417>),\n  Anthony Guam\u00e1n [aut] (ORCID: <https://orcid.org/0009-0005-0204-7536>)",
    "url": "https://github.com/Jonnathan-Landi/RFplus",
    "bug_reports": "https://github.com/Jonnathan-Landi/RFplus/issues",
    "repository": "https://cran.r-project.org/package=RFplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RFplus Machine Learning for Merging Satellite and Ground Precipitation\nData A machine learning algorithm that merges satellite and ground precipitation data using Random Forest for spatial prediction, residual modeling for bias correction, and quantile mapping for adjustment, ensuring accurate estimates across temporal scales and regions.  "
  },
  {
    "id": 6209,
    "package_name": "RGENERATE",
    "title": "Tools to Generate Vector Time Series",
    "description": "A method 'generate()' is implemented in this package for the random\n    generation of vector time series according to models obtained by 'RMAWGEN',\n    'vars' or other packages.  This package was created to generalize the\n    algorithms of the 'RMAWGEN' package for the analysis and generation of any\n    environmental vector time series.",
    "version": "1.3.8",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>)",
    "url": "https://github.com/ecor/RGENERATE",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RGENERATE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RGENERATE Tools to Generate Vector Time Series A method 'generate()' is implemented in this package for the random\n    generation of vector time series according to models obtained by 'RMAWGEN',\n    'vars' or other packages.  This package was created to generalize the\n    algorithms of the 'RMAWGEN' package for the analysis and generation of any\n    environmental vector time series.  "
  },
  {
    "id": 6210,
    "package_name": "RGENERATEPREC",
    "title": "Tools to Generate Daily-Precipitation Time Series",
    "description": "The method 'generate()' is extended for spatial multi-site\n    stochastic generation of daily precipitation. It generates precipitation\n    occurrence in several sites using logit regression (Generalized Linear\n    Models) and the approach by D.S. Wilks (1998) <doi:10.1016/S0022-1694(98)00186-3> . ",
    "version": "1.3.2",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>)",
    "url": "https://ecor.github.io/RGENERATEPREC/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RGENERATEPREC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RGENERATEPREC Tools to Generate Daily-Precipitation Time Series The method 'generate()' is extended for spatial multi-site\n    stochastic generation of daily precipitation. It generates precipitation\n    occurrence in several sites using logit regression (Generalized Linear\n    Models) and the approach by D.S. Wilks (1998) <doi:10.1016/S0022-1694(98)00186-3> .   "
  },
  {
    "id": 6248,
    "package_name": "RJDemetra",
    "title": "Interface to 'JDemetra+' Seasonal Adjustment Software",
    "description": "Interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>), the seasonal adjustment software officially\n    recommended to the members of the European Statistical System (ESS) and the European System of Central Banks.\n    It offers full access to all options and outputs of 'JDemetra+', including the two leading seasonal adjustment methods\n    TRAMO/SEATS+ and X-12ARIMA/X-13ARIMA-SEATS.",
    "version": "0.2.8",
    "maintainer": "Alain Quartier-la-Tente <alain.quartier@yahoo.fr>",
    "author": "Alain Quartier-la-Tente [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7890-3857>),\n  Anna Michalek [aut],\n  Jean Palate [aut],\n  Raf Baeyens [aut]",
    "url": "https://rjdverse.github.io/rjdemetra/,\nhttps://github.com/rjdverse/rjdemetra",
    "bug_reports": "https://github.com/rjdverse/rjdemetra/issues",
    "repository": "https://cran.r-project.org/package=RJDemetra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RJDemetra Interface to 'JDemetra+' Seasonal Adjustment Software Interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>), the seasonal adjustment software officially\n    recommended to the members of the European Statistical System (ESS) and the European System of Central Banks.\n    It offers full access to all options and outputs of 'JDemetra+', including the two leading seasonal adjustment methods\n    TRAMO/SEATS+ and X-12ARIMA/X-13ARIMA-SEATS.  "
  },
  {
    "id": 6274,
    "package_name": "RMAWGEN",
    "title": "Multi-Site Auto-Regressive Weather GENerator",
    "description": "S3 and S4 functions are implemented for spatial multi-site\n    stochastic generation of daily time series of temperature and\n    precipitation. These tools make use of Vector AutoRegressive models (VARs).\n    The weather generator model is then saved as an object and is calibrated by\n    daily instrumental \"Gaussianized\" time series through the 'vars' package\n    tools. Once obtained this model, it can it can be used for weather\n    generations and be adapted to work with several climatic monthly time\n    series.",
    "version": "1.3.9.3",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>),\n  Emanuele Eccel [aut] (ORCID: <https://orcid.org/0000-0003-3239-828X>),\n  Eike Luedeling [ctb] (ORCID: <https://orcid.org/0000-0002-7316-3631>)",
    "url": "https://ecor.github.io/RMAWGEN/,https://github.com/ecor/RMAWGEN,\nhttps://docs.google.com/file/d/0B66otCUk3Bv6V3RPbm1mUG4zVHc/edit",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RMAWGEN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RMAWGEN Multi-Site Auto-Regressive Weather GENerator S3 and S4 functions are implemented for spatial multi-site\n    stochastic generation of daily time series of temperature and\n    precipitation. These tools make use of Vector AutoRegressive models (VARs).\n    The weather generator model is then saved as an object and is calibrated by\n    daily instrumental \"Gaussianized\" time series through the 'vars' package\n    tools. Once obtained this model, it can it can be used for weather\n    generations and be adapted to work with several climatic monthly time\n    series.  "
  },
  {
    "id": 6307,
    "package_name": "RNCEP",
    "title": "Obtain, Organize, and Visualize NCEP Weather Data",
    "description": "Contains functions to retrieve, organize, and visualize weather data from the NCEP/NCAR Reanalysis (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html>) and NCEP/DOE Reanalysis II (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis2.html>) datasets.  Data are queried via the Internet and may be obtained for a specified spatial and temporal extent or interpolated to a point in space and time.  We also provide functions to visualize these weather data on a map.  There are also functions to simulate flight trajectories according to specified behavior using either NCEP wind data or data specified by the user.",
    "version": "1.0.11",
    "maintainer": "Michael U. Kemp <mukemp+RNCEP@gmail.com>",
    "author": "Michael U. Kemp [aut, cre],\n  E. Emiel van Loon [ths],\n  Judy Shamoun-Baranes [ths],\n  Willem Bouten [ths]",
    "url": "https://psl.noaa.gov/data/gridded/index.html\nhttps://sites.google.com/site/michaelukemp/home",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RNCEP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RNCEP Obtain, Organize, and Visualize NCEP Weather Data Contains functions to retrieve, organize, and visualize weather data from the NCEP/NCAR Reanalysis (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html>) and NCEP/DOE Reanalysis II (<https://psl.noaa.gov/data/gridded/data.ncep.reanalysis2.html>) datasets.  Data are queried via the Internet and may be obtained for a specified spatial and temporal extent or interpolated to a point in space and time.  We also provide functions to visualize these weather data on a map.  There are also functions to simulate flight trajectories according to specified behavior using either NCEP wind data or data specified by the user.  "
  },
  {
    "id": 6343,
    "package_name": "ROpenWeatherMap",
    "title": "R Interface to OpenWeatherMap API",
    "description": "OpenWeatherMap (OWM) <http://openweathermap.org/api> is a service providing weather related data.\n           This package can be used to access current weather data for one location or several locations.\n           It can also be used to forecast weather for 5 days with data for every 3 hours.",
    "version": "1.1",
    "maintainer": "Mukul Chaware <mukul.chaware13@gmail.com>",
    "author": "Mukul Chaware[aut,cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ROpenWeatherMap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ROpenWeatherMap R Interface to OpenWeatherMap API OpenWeatherMap (OWM) <http://openweathermap.org/api> is a service providing weather related data.\n           This package can be used to access current weather data for one location or several locations.\n           It can also be used to forecast weather for 5 days with data for every 3 hours.  "
  },
  {
    "id": 6394,
    "package_name": "RSDC",
    "title": "Regime-Switching Dynamic Correlation Models",
    "description": "Estimation, forecasting, simulation, and portfolio construction for \n    regime-switching models with exogenous variables as in \n    Pelletier (2006) <doi:10.1016/j.jeconom.2005.01.013>.",
    "version": "1.1-2",
    "maintainer": "David Ardia <david.ardia.ch@gmail.com>",
    "author": "David Ardia [aut, cre] (ORCID: <https://orcid.org/0000-0003-2823-782X>),\n  Benjamin Seguin [aut]",
    "url": "https://github.com/ArdiaD/RSDC",
    "bug_reports": "https://github.com/ArdiaD/RSDC/issues",
    "repository": "https://cran.r-project.org/package=RSDC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSDC Regime-Switching Dynamic Correlation Models Estimation, forecasting, simulation, and portfolio construction for \n    regime-switching models with exogenous variables as in \n    Pelletier (2006) <doi:10.1016/j.jeconom.2005.01.013>.  "
  },
  {
    "id": 6397,
    "package_name": "RSEIS",
    "title": "Seismic Time Series Analysis Tools",
    "description": "Multiple interactive codes to view and analyze seismic data, via spectrum analysis, wavelet transforms, particle motion, hodograms.  Includes general time-series tools, plotting, filtering, interactive display.",
    "version": "4.2-4",
    "maintainer": "Jonathan M. Lees <jonathan.lees@unc.edu>",
    "author": "Jonathan M. Lees [aut, cre],\n  Jake Anderson [ctb],\n  Leonard Lisapaly [ctb],\n  Dave Harris [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RSEIS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSEIS Seismic Time Series Analysis Tools Multiple interactive codes to view and analyze seismic data, via spectrum analysis, wavelet transforms, particle motion, hodograms.  Includes general time-series tools, plotting, filtering, interactive display.  "
  },
  {
    "id": 6425,
    "package_name": "RTFA",
    "title": "Robust Factor Analysis for Tensor Time Series",
    "description": "Tensor Factor Models (TFM) are appealing dimension reduction tools for high-order tensor time series, and have wide applications in economics, finance and medical imaging. We propose an one-step projection estimator by minimizing the least-square loss function, and further propose a robust estimator with an iterative weighted projection technique by utilizing the Huber loss function. The methods are discussed in Barigozzi et al. (2022) <arXiv:2206.09800>, and Barigozzi et al. (2023) <arXiv:2303.18163>.",
    "version": "0.1.0",
    "maintainer": "Lingxiao Li <lilingxiao@mail.sdu.edu.cn>",
    "author": "Matteo Barigozzi [aut],\n  Yong He [aut],\n  Lorenzo Trapani [aut],\n  Lingxiao Li [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RTFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RTFA Robust Factor Analysis for Tensor Time Series Tensor Factor Models (TFM) are appealing dimension reduction tools for high-order tensor time series, and have wide applications in economics, finance and medical imaging. We propose an one-step projection estimator by minimizing the least-square loss function, and further propose a robust estimator with an iterative weighted projection technique by utilizing the Huber loss function. The methods are discussed in Barigozzi et al. (2022) <arXiv:2206.09800>, and Barigozzi et al. (2023) <arXiv:2303.18163>.  "
  },
  {
    "id": 6434,
    "package_name": "RTransferEntropy",
    "title": "Measuring Information Flow Between Time Series with Shannon and\nRenyi Transfer Entropy",
    "description": "Measuring information flow between time series with Shannon and R\u00e9nyi transfer entropy. See also Dimpfl and Peter (2013) <doi:10.1515/snde-2012-0044> and Dimpfl and Peter (2014) <doi:10.1016/j.intfin.2014.03.004> for theory and applications to financial time series. Additional references can be found in the theory part of the vignette.",
    "version": "0.2.21",
    "maintainer": "David Zimmermann <david_j_zimmermann@hotmail.com>",
    "author": "David Zimmermann [aut, cre],\n  Simon Behrendt [aut],\n  Thomas Dimpfl [aut],\n  Franziska Peter [aut]",
    "url": "https://github.com/BZPaper/RTransferEntropy",
    "bug_reports": "https://github.com/BZPaper/RTransferEntropy/issues",
    "repository": "https://cran.r-project.org/package=RTransferEntropy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RTransferEntropy Measuring Information Flow Between Time Series with Shannon and\nRenyi Transfer Entropy Measuring information flow between time series with Shannon and R\u00e9nyi transfer entropy. See also Dimpfl and Peter (2013) <doi:10.1515/snde-2012-0044> and Dimpfl and Peter (2014) <doi:10.1016/j.intfin.2014.03.004> for theory and applications to financial time series. Additional references can be found in the theory part of the vignette.  "
  },
  {
    "id": 6499,
    "package_name": "RavenR",
    "title": "Raven Hydrological Modelling Framework R Support and Analysis",
    "description": "Utilities for processing input and output files associated with the Raven Hydrological Modelling Framework. Includes various plotting functions, model diagnostics, reading output files into extensible time series format, and support for writing Raven input files. \n    The 'RavenR' package is also archived at Chlumsky et al. (2020) <doi:10.5281/zenodo.4248183>.\n    The Raven Hydrologic Modelling Framework method can be referenced with Craig et al. (2020) <doi:10.1016/j.envsoft.2020.104728>.",
    "version": "2.2.4",
    "maintainer": "Robert Chlumsky <rchlumsk@uwaterloo.ca>",
    "author": "Robert Chlumsky [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-1303-5064>),\n  James Craig [ctb, aut] (ORCID: <https://orcid.org/0000-0003-2715-7166>),\n  Leland Scantlebury [ctb, aut],\n  Simon Lin [ctb, aut],\n  Sarah Grass [ctb, aut],\n  Genevieve Brown [ctb, aut],\n  Rezgar Arabzadeh [ctb, aut]",
    "url": "https://github.com/rchlumsk/RavenR",
    "bug_reports": "https://github.com/rchlumsk/RavenR/issues",
    "repository": "https://cran.r-project.org/package=RavenR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RavenR Raven Hydrological Modelling Framework R Support and Analysis Utilities for processing input and output files associated with the Raven Hydrological Modelling Framework. Includes various plotting functions, model diagnostics, reading output files into extensible time series format, and support for writing Raven input files. \n    The 'RavenR' package is also archived at Chlumsky et al. (2020) <doi:10.5281/zenodo.4248183>.\n    The Raven Hydrologic Modelling Framework method can be referenced with Craig et al. (2020) <doi:10.1016/j.envsoft.2020.104728>.  "
  },
  {
    "id": 6501,
    "package_name": "Rbeast",
    "title": "Bayesian Change-Point Detection and Time Series Decomposition",
    "description": "Interpretation of time series data is affected by model choices. Different models can give different or even contradicting estimates of patterns, trends, and mechanisms for the same data--a limitation alleviated by the Bayesian estimator of abrupt change,seasonality, and trend (BEAST) of this package. BEAST seeks to improve time series decomposition by forgoing the \"single-best-model\" concept and embracing all competing models into the inference via a Bayesian model averaging scheme. It is a flexible tool to uncover abrupt changes (i.e., change-points, breakpoints, structural breaks, or join-points), cyclic variations (e.g., seasonality), and nonlinear trends in time-series observations. BEAST not just tells when changes occur but also quantifies how likely the detected changes are true. It detects not just piecewise linear trends but also arbitrary nonlinear trends. BEAST is applicable to real-valued time series data of all kinds, be it for remote sensing, economics, climate sciences, ecology, and hydrology. Example applications include its use to identify regime shifts in ecological data, map forest disturbance and land degradation from satellite imagery, detect market trends in economic data, pinpoint anomaly and extreme events in climate data, and unravel system dynamics in biological data. Details on BEAST are reported in Zhao et al. (2019) <doi:10.1016/j.rse.2019.04.034>.",
    "version": "1.0.1",
    "maintainer": "Kaiguang Zhao <zhao.1423@osu.edu>",
    "author": "Tongxi Hu [aut],\n  Yang Li [aut],\n  Xuesong Zhang [aut],\n  Kaiguang Zhao [aut, cre],\n  Jack Dongarra [ctb],\n  Cleve Moler [ctb]",
    "url": "https://github.com/zhaokg/Rbeast",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rbeast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rbeast Bayesian Change-Point Detection and Time Series Decomposition Interpretation of time series data is affected by model choices. Different models can give different or even contradicting estimates of patterns, trends, and mechanisms for the same data--a limitation alleviated by the Bayesian estimator of abrupt change,seasonality, and trend (BEAST) of this package. BEAST seeks to improve time series decomposition by forgoing the \"single-best-model\" concept and embracing all competing models into the inference via a Bayesian model averaging scheme. It is a flexible tool to uncover abrupt changes (i.e., change-points, breakpoints, structural breaks, or join-points), cyclic variations (e.g., seasonality), and nonlinear trends in time-series observations. BEAST not just tells when changes occur but also quantifies how likely the detected changes are true. It detects not just piecewise linear trends but also arbitrary nonlinear trends. BEAST is applicable to real-valued time series data of all kinds, be it for remote sensing, economics, climate sciences, ecology, and hydrology. Example applications include its use to identify regime shifts in ecological data, map forest disturbance and land degradation from satellite imagery, detect market trends in economic data, pinpoint anomaly and extreme events in climate data, and unravel system dynamics in biological data. Details on BEAST are reported in Zhao et al. (2019) <doi:10.1016/j.rse.2019.04.034>.  "
  },
  {
    "id": 6507,
    "package_name": "RcamelsCL",
    "title": "Easy Handling of the CAMELS-CL Dataset",
    "description": "Download and handle spatial and temporal data from the CAMELS-CL dataset (Catchment Attributes and Meteorology for Large Sample Studies, Chile) <https://camels.cr2.cl/>, developed by Alvarez-Garreton et al. (2018) <doi:10.5194/hess-22-5817-2018>. The package does not generate new data, it only facilitates direct access to the original dataset for hydrological analyses.",
    "version": "0.1-11",
    "maintainer": "Hector Garces-Figueroa <hegarcesf@gmail.com>",
    "author": "Hector Garces-Figueroa [aut, cph, cre] (ORCID:\n    <https://orcid.org/0009-0001-2496-4854>),\n  Mauricio Zambrano-Bigiarini [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-9536-643X>)",
    "url": "https://gitlab.com/hgarcesf/RcamelsCL",
    "bug_reports": "https://gitlab.com/hgarcesf/RcamelsCL/-/issues",
    "repository": "https://cran.r-project.org/package=RcamelsCL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcamelsCL Easy Handling of the CAMELS-CL Dataset Download and handle spatial and temporal data from the CAMELS-CL dataset (Catchment Attributes and Meteorology for Large Sample Studies, Chile) <https://camels.cr2.cl/>, developed by Alvarez-Garreton et al. (2018) <doi:10.5194/hess-22-5817-2018>. The package does not generate new data, it only facilitates direct access to the original dataset for hydrological analyses.  "
  },
  {
    "id": 6509,
    "package_name": "Rcatch22",
    "title": "Calculation of 22 Canonical Time-Series Characteristics",
    "description": "Calculate 22 summary statistics coded in C on time-series vectors to enable \n    pattern detection, classification, and regression applications in the \n    feature space as proposed by <doi:10.1007/s10618-019-00647-x>.",
    "version": "0.2.3",
    "maintainer": "Trent Henderson <then6675@uni.sydney.edu.au>",
    "author": "Trent Henderson [cre, aut],\n  Carl Lubba [ctb]",
    "url": "",
    "bug_reports": "https://github.com/hendersontrent/Rcatch22/issues/",
    "repository": "https://cran.r-project.org/package=Rcatch22",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rcatch22 Calculation of 22 Canonical Time-Series Characteristics Calculate 22 summary statistics coded in C on time-series vectors to enable \n    pattern detection, classification, and regression applications in the \n    feature space as proposed by <doi:10.1007/s10618-019-00647-x>.  "
  },
  {
    "id": 6547,
    "package_name": "RcmdrPlugin.temis",
    "title": "Graphical Integrated Text Mining Solution",
    "description": "An 'R Commander' plug-in providing an integrated solution to perform\n    a series of text mining tasks such as importing and cleaning a corpus, and\n    analyses like terms and documents counts, vocabulary tables, terms\n    co-occurrences and documents similarity measures, time series analysis,\n    correspondence analysis and hierarchical clustering. Corpora can be imported\n    from spreadsheet-like files, directories of raw text files,\n    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.",
    "version": "0.7.12",
    "maintainer": "Milan Bouchet-Valat <nalimilan@club.fr>",
    "author": "Milan Bouchet-Valat [aut, cre],\n  Gilles Bastin [aut]",
    "url": "https://github.com/nalimilan/R.TeMiS",
    "bug_reports": "https://github.com/nalimilan/R.TeMiS/issues",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.temis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.temis Graphical Integrated Text Mining Solution An 'R Commander' plug-in providing an integrated solution to perform\n    a series of text mining tasks such as importing and cleaning a corpus, and\n    analyses like terms and documents counts, vocabulary tables, terms\n    co-occurrences and documents similarity measures, time series analysis,\n    correspondence analysis and hierarchical clustering. Corpora can be imported\n    from spreadsheet-like files, directories of raw text files,\n    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.  "
  },
  {
    "id": 6611,
    "package_name": "Rcriticor",
    "title": "Pierre-Goldwin Correlogram",
    "description": "Goldwin-Pierre correlogram. Research of critical periods in the past. Integrates a time series in a given window.  ",
    "version": "2.0",
    "maintainer": "J.S. Pierre <jean-sebastien.pierre@univ-rennes1.fr>",
    "author": "Jean-Sebastien PIERRE [aut,cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rcriticor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rcriticor Pierre-Goldwin Correlogram Goldwin-Pierre correlogram. Research of critical periods in the past. Integrates a time series in a given window.    "
  },
  {
    "id": 6622,
    "package_name": "Rdrw",
    "title": "Univariate and Multivariate Damped Random Walk Processes",
    "description": "We provide a toolbox to fit and simulate a univariate or multivariate damped random walk process that is also known as an Ornstein-Uhlenbeck process or a continuous-time autoregressive model of the first order, i.e., CAR(1) or CARMA(1, 0). This process is suitable for analyzing univariate or multivariate time series data with irregularly-spaced observation times and heteroscedastic measurement errors. When it comes to the multivariate case, the number of data points (measurements/observations) available at each observation time does not need to be the same, and the length of each time series can vary. The number of time series data sets that can be modeled simultaneously is limited to ten in this version of the package. We use Kalman-filtering to evaluate the resulting likelihood function, which leads to a scalable and efficient computation in finding maximum likelihood estimates of the model parameters or in drawing their posterior samples. Please pay attention to loading the data if this package is used for astronomical data analyses; see the details in the manual. Also see Hu and Tak (2020) <arXiv:2005.08049>.",
    "version": "1.0.2",
    "maintainer": "Hyungsuk Tak <hyungsuk.tak@gmail.com>",
    "author": "Zhirui Hu and Hyungsuk Tak",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rdrw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rdrw Univariate and Multivariate Damped Random Walk Processes We provide a toolbox to fit and simulate a univariate or multivariate damped random walk process that is also known as an Ornstein-Uhlenbeck process or a continuous-time autoregressive model of the first order, i.e., CAR(1) or CARMA(1, 0). This process is suitable for analyzing univariate or multivariate time series data with irregularly-spaced observation times and heteroscedastic measurement errors. When it comes to the multivariate case, the number of data points (measurements/observations) available at each observation time does not need to be the same, and the length of each time series can vary. The number of time series data sets that can be modeled simultaneously is limited to ten in this version of the package. We use Kalman-filtering to evaluate the resulting likelihood function, which leads to a scalable and efficient computation in finding maximum likelihood estimates of the model parameters or in drawing their posterior samples. Please pay attention to loading the data if this package is used for astronomical data analyses; see the details in the manual. Also see Hu and Tak (2020) <arXiv:2005.08049>.  "
  },
  {
    "id": 6644,
    "package_name": "RecordTest",
    "title": "Inference Tools in Time Series Based on Record Statistics",
    "description": "Statistical tools based on the probabilistic properties of the \n  record occurrence in a sequence of independent and identically distributed \n  continuous random variables. In particular, tools to prepare a time series \n  as well as distribution-free trend and change-point tests and graphical \n  tools to study the record occurrence. Details about the implemented tools \n  can be found in Castillo-Mateo et al. (2023a) <doi:10.18637/jss.v106.i05> \n  and Castillo-Mateo et al. (2023b) <doi:10.1016/j.atmosres.2023.106934>.",
    "version": "2.2.0",
    "maintainer": "Jorge Castillo-Mateo <jorgecastillomateo@gmail.com>",
    "author": "Jorge Castillo-Mateo [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3859-0248>),\n  Ana C. Cebri\u00e1n [ths] (ORCID: <https://orcid.org/0000-0002-9052-9674>),\n  Jes\u00fas As\u00edn [ths] (ORCID: <https://orcid.org/0000-0002-0174-789X>)",
    "url": "https://github.com/JorgeCastilloMateo/RecordTest",
    "bug_reports": "https://github.com/JorgeCastilloMateo/RecordTest/issues",
    "repository": "https://cran.r-project.org/package=RecordTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RecordTest Inference Tools in Time Series Based on Record Statistics Statistical tools based on the probabilistic properties of the \n  record occurrence in a sequence of independent and identically distributed \n  continuous random variables. In particular, tools to prepare a time series \n  as well as distribution-free trend and change-point tests and graphical \n  tools to study the record occurrence. Details about the implemented tools \n  can be found in Castillo-Mateo et al. (2023a) <doi:10.18637/jss.v106.i05> \n  and Castillo-Mateo et al. (2023b) <doi:10.1016/j.atmosres.2023.106934>.  "
  },
  {
    "id": 6732,
    "package_name": "Rlgt",
    "title": "Bayesian Exponential Smoothing Models with Trend Modifications",
    "description": "An implementation of a number of Global Trend models for time series forecasting \n    that are Bayesian generalizations and extensions of some Exponential Smoothing models. \n    The main differences/additions include 1) nonlinear global trend, 2) Student-t error \n    distribution, and 3) a function for the error size, so heteroscedasticity. The methods \n    are particularly useful for short time series. When tested on the well-known M3 dataset,\n    they are able to outperform all classical time series algorithms. The models are fitted \n    with MCMC using the 'rstan' package.",
    "version": "0.2-3",
    "maintainer": "Christoph Bergmeir <christoph.bergmeir@monash.edu>",
    "author": "Slawek Smyl [aut],\n  Christoph Bergmeir [aut, cre],\n  Erwin Wibowo [aut],\n  To Wang Ng [aut],\n  Xueying Long [aut],\n  Alexander Dokumentov [aut],\n  Daniel Schmidt [aut],\n  Trustees of Columbia University [cph] (tools/make_cpp.R,\n    R/stanmodels.R)",
    "url": "https://github.com/cbergmeir/Rlgt",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rlgt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rlgt Bayesian Exponential Smoothing Models with Trend Modifications An implementation of a number of Global Trend models for time series forecasting \n    that are Bayesian generalizations and extensions of some Exponential Smoothing models. \n    The main differences/additions include 1) nonlinear global trend, 2) Student-t error \n    distribution, and 3) a function for the error size, so heteroscedasticity. The methods \n    are particularly useful for short time series. When tested on the well-known M3 dataset,\n    they are able to outperform all classical time series algorithms. The models are fitted \n    with MCMC using the 'rstan' package.  "
  },
  {
    "id": 6734,
    "package_name": "Rlibkdv",
    "title": "A Versatile Kernel Density Visualization Library for Geospatial\nAnalytics (Heatmap)",
    "description": "Unlock the power of large-scale geospatial analysis, \n    quickly generate high-resolution kernel density visualizations, \n    supporting advanced analysis tasks such as bandwidth-tuning and spatiotemporal analysis. \n    Regardless of the size of your dataset, our library delivers efficient and accurate results.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu, Reynold Cheng (2023) <doi:10.1145/3555041.3589401>.\n    Tsz Nam Chan, Rui Zang, Pak Lon Ip, Leong Hou U, Jianliang Xu (2023) <doi:10.1145/3555041.3589711>.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.1145/3514221.3517823>.\n    Tsz Nam Chan, Pak Lon Ip, Kaiyan Zhao, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3554821.3554855>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3503585.3503591>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3494124.3494135>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Weng Hou Tong, Shivansh Mittal, Ye Li, Reynold Cheng (2021) <doi:10.14778/3476311.3476312>.\n    Tsz Nam Chan, Zhe Li, Leong Hou U, Jianliang Xu, Reynold Cheng (2021) <doi:10.14778/3461535.3461540>.\n    Tsz Nam Chan, Reynold Cheng, Man Lung Yiu (2020) <doi:10.1145/3318464.3380561>.\n    Tsz Nam Chan, Leong Hou U, Reynold Cheng, Man Lung Yiu, Shivansh Mittal (2020) <doi:10.1109/TKDE.2020.3018376>.\n    Tsz Nam Chan, Man Lung Yiu, Leong Hou U (2019) <doi:10.1109/ICDE.2019.00055>.",
    "version": "1.1",
    "maintainer": "Bojian Zhu <bjzhu999@gmail.com>",
    "author": "Bojian Zhu [cre, aut],\n  Tsz Nam Chan [aut],\n  Leong Hou U [aut],\n  Dingming Wu [aut],\n  Jianliang Xu [aut],\n  LibKDV Group [cph]",
    "url": "https://github.com/bojianzhu/Rlibkdv",
    "bug_reports": "https://github.com/bojianzhu/Rlibkdv/issues",
    "repository": "https://cran.r-project.org/package=Rlibkdv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rlibkdv A Versatile Kernel Density Visualization Library for Geospatial\nAnalytics (Heatmap) Unlock the power of large-scale geospatial analysis, \n    quickly generate high-resolution kernel density visualizations, \n    supporting advanced analysis tasks such as bandwidth-tuning and spatiotemporal analysis. \n    Regardless of the size of your dataset, our library delivers efficient and accurate results.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu, Reynold Cheng (2023) <doi:10.1145/3555041.3589401>.\n    Tsz Nam Chan, Rui Zang, Pak Lon Ip, Leong Hou U, Jianliang Xu (2023) <doi:10.1145/3555041.3589711>.\n    Tsz Nam Chan, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.1145/3514221.3517823>.\n    Tsz Nam Chan, Pak Lon Ip, Kaiyan Zhao, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3554821.3554855>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3503585.3503591>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Byron Choi, Jianliang Xu (2022) <doi:10.14778/3494124.3494135>.\n    Tsz Nam Chan, Pak Lon Ip, Leong Hou U, Weng Hou Tong, Shivansh Mittal, Ye Li, Reynold Cheng (2021) <doi:10.14778/3476311.3476312>.\n    Tsz Nam Chan, Zhe Li, Leong Hou U, Jianliang Xu, Reynold Cheng (2021) <doi:10.14778/3461535.3461540>.\n    Tsz Nam Chan, Reynold Cheng, Man Lung Yiu (2020) <doi:10.1145/3318464.3380561>.\n    Tsz Nam Chan, Leong Hou U, Reynold Cheng, Man Lung Yiu, Shivansh Mittal (2020) <doi:10.1109/TKDE.2020.3018376>.\n    Tsz Nam Chan, Man Lung Yiu, Leong Hou U (2019) <doi:10.1109/ICDE.2019.00055>.  "
  },
  {
    "id": 6741,
    "package_name": "Rmfrac",
    "title": "Simulation and Statistical Analysis of Multifractional Processes",
    "description": "Simulation of several fractional and multifractional processes. Includes Brownian and fractional Brownian motions, bridges and Gaussian Haar-based multifractional processes (GHBMP). Implements the methods from Ayache, Olenko and Samarakoon (2025) <doi:10.48550/arXiv.2503.07286> for simulation of GHBMP. Estimation of Hurst functions and local fractal dimension. Clustering realisations based on the Hurst functions. Several functions to estimate and plot geometric statistics of the processes and time series. Provides a 'shiny' application for interactive use of the functions from the package.",
    "version": "0.1.1",
    "maintainer": "Nemini Samarakoon <neminisamarakoon95@gmail.com>",
    "author": "Andriy Olenko [aut],\n  Nemini Samarakoon [aut, cre]",
    "url": "https://github.com/Nemini-S/Rmfrac",
    "bug_reports": "https://github.com/Nemini-S/Rmfrac/issues",
    "repository": "https://cran.r-project.org/package=Rmfrac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rmfrac Simulation and Statistical Analysis of Multifractional Processes Simulation of several fractional and multifractional processes. Includes Brownian and fractional Brownian motions, bridges and Gaussian Haar-based multifractional processes (GHBMP). Implements the methods from Ayache, Olenko and Samarakoon (2025) <doi:10.48550/arXiv.2503.07286> for simulation of GHBMP. Estimation of Hurst functions and local fractal dimension. Clustering realisations based on the Hurst functions. Several functions to estimate and plot geometric statistics of the processes and time series. Provides a 'shiny' application for interactive use of the functions from the package.  "
  },
  {
    "id": 6761,
    "package_name": "RobGARCHBoot",
    "title": "Robust Bootstrap Forecast Densities for GARCH Models",
    "description": "Bootstrap forecast densities for GARCH (Generalized Autoregressive Conditional Heteroskedastic) returns and volatilities using the robust residual-based bootstrap procedure of Trucios, Hotta and Ruiz (2017) <DOI:10.1080/00949655.2017.1359601>.",
    "version": "1.2.0",
    "maintainer": "Carlos Trucios <ctrucios@gmail.com>",
    "author": "Carlos Trucios",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RobGARCHBoot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RobGARCHBoot Robust Bootstrap Forecast Densities for GARCH Models Bootstrap forecast densities for GARCH (Generalized Autoregressive Conditional Heteroskedastic) returns and volatilities using the robust residual-based bootstrap procedure of Trucios, Hotta and Ruiz (2017) <DOI:10.1080/00949655.2017.1359601>.  "
  },
  {
    "id": 6764,
    "package_name": "RobPC",
    "title": "Robust Panel Clustering Algorithm",
    "description": "Performs both classical and robust panel clustering by applying Principal Component Analysis (PCA) for dimensionality reduction and clustering via standard K-Means or Trimmed K-Means. The method is designed to ensure stable and reliable clustering, even in the presence of outliers. Suitable for analyzing panel data in domains such as economic research, financial time-series, healthcare analytics, and social sciences. The package allows users to choose between classical K-Means for standard clustering and Trimmed K-Means for robust clustering, making it a flexible tool for various applications. For this package, we have benefited from the studies Rencher (2003), Wang and Lu (2021) <DOI:10.25236/AJBM.2021.031018>, Cuesta-Albertos et al. (1997) <https://www.jstor.org/stable/2242558?seq=1>.",
    "version": "1.4",
    "maintainer": "Hasan Bulut <hasan.bulut@omu.edu.tr>",
    "author": "Hasan Bulut [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RobPC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RobPC Robust Panel Clustering Algorithm Performs both classical and robust panel clustering by applying Principal Component Analysis (PCA) for dimensionality reduction and clustering via standard K-Means or Trimmed K-Means. The method is designed to ensure stable and reliable clustering, even in the presence of outliers. Suitable for analyzing panel data in domains such as economic research, financial time-series, healthcare analytics, and social sciences. The package allows users to choose between classical K-Means for standard clustering and Trimmed K-Means for robust clustering, making it a flexible tool for various applications. For this package, we have benefited from the studies Rencher (2003), Wang and Lu (2021) <DOI:10.25236/AJBM.2021.031018>, Cuesta-Albertos et al. (1997) <https://www.jstor.org/stable/2242558?seq=1>.  "
  },
  {
    "id": 6765,
    "package_name": "RobPer",
    "title": "Robust Periodogram and Periodicity Detection Methods",
    "description": "Calculates periodograms based on (robustly) fitting periodic functions to light curves (irregularly observed time series, possibly with measurement accuracies, occurring in astroparticle physics). Three main functions are included: RobPer() calculates the periodogram. Outlying periodogram bars (indicating a period) can be detected with betaCvMfit(). Artificial light curves can be generated using the function tsgen(). For more details see the corresponding article: Thieler, Fried and Rathjens (2016), Journal of Statistical Software 69(9), 1-36, <doi:10.18637/jss.v069.i09>.",
    "version": "1.2.3",
    "maintainer": "Jonathan Rathjens <jonathan.rathjens@tu-dortmund.de>",
    "author": "Anita M. Thieler [aut],\n  Jonathan Rathjens [aut, cre],\n  Roland Fried [aut],\n  Brenton R. Clarke [ctb] (function betaCvMfit()),\n  Uwe Ligges [ctb] (function TK95()),\n  Matias Salibian-Barrera [ctb] (functions FastS() and FastTau()),\n  Gert Willems [ctb] (function FastTau()),\n  Victor Yohai [ctb] (function FastS())",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RobPer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RobPer Robust Periodogram and Periodicity Detection Methods Calculates periodograms based on (robustly) fitting periodic functions to light curves (irregularly observed time series, possibly with measurement accuracies, occurring in astroparticle physics). Three main functions are included: RobPer() calculates the periodogram. Outlying periodogram bars (indicating a period) can be detected with betaCvMfit(). Artificial light curves can be generated using the function tsgen(). For more details see the corresponding article: Thieler, Fried and Rathjens (2016), Journal of Statistical Software 69(9), 1-36, <doi:10.18637/jss.v069.i09>.  "
  },
  {
    "id": 6774,
    "package_name": "RobustAdaptiveDecomposition",
    "title": "Decomposes a Univariate Time Series into Subcomponents",
    "description": "Provides a method to decompose a univariate time series into meaningful subcomponents for analysis and denoising.",
    "version": "0.1.0",
    "maintainer": "Laiba Sultan Dar <laibasultan@awkum.edu.pk>",
    "author": "Laiba Sultan Dar [aut, cre],\n  Muhammad Aamir [aut],\n  Muhammad Hamraz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RobustAdaptiveDecomposition",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RobustAdaptiveDecomposition Decomposes a Univariate Time Series into Subcomponents Provides a method to decompose a univariate time series into meaningful subcomponents for analysis and denoising.  "
  },
  {
    "id": 6787,
    "package_name": "RolWinMulCor",
    "title": "Subroutines to Estimate Rolling Window Multiple Correlation",
    "description": "Rolling Window Multiple Correlation ('RolWinMulCor') estimates the rolling (running) window correlation for the bi- and multi-variate cases between regular (sampled on identical time points) time series, with especial emphasis to ecological data although this can be applied to other kinds of data sets. 'RolWinMulCor' is based on the concept of rolling, running or sliding window and is useful to evaluate the evolution of correlation through time and time-scales. 'RolWinMulCor' contains six functions. The first two focus on the bi-variate case: (1) rolwincor_1win() and (2) rolwincor_heatmap(), which estimate the correlation coefficients and the their respective p-values for only one window-length (time-scale) and considering all possible window-lengths or a band of window-lengths, respectively. The second two functions: (3) rolwinmulcor_1win() and (4) rolwinmulcor_heatmap() are designed to analyze the multi-variate case, following the bi-variate case to visually display the results, but these two approaches are methodologically different. That is, the multi-variate case estimates the adjusted coefficients of determination instead of the correlation coefficients. The last two functions: (5) plot_1win() and (6) plot_heatmap() are used to represent graphically the outputs of the four aforementioned functions as simple plots or as heat maps. The functions contained in 'RolWinMulCor' are highly flexible since these contains several parameters to control the estimation of correlation and the features of the plot output, e.g. to remove the (linear) trend contained in the time series under analysis, to choose different p-value correction methods (which are used to address the multiple comparison problem) or to personalise the plot outputs. The 'RolWinMulCor' package also provides examples with synthetic and real-life ecological time series to exemplify its use. Methods derived from H. Abdi. (2007) <https://personal.utdallas.edu/~herve/Abdi-MCC2007-pretty.pdf>, R. Telford (2013) <https://quantpalaeo.wordpress.com/2013/01/04/, J. M. Polanco-Martinez (2019) <doi:10.1007/s11071-019-04974-y>, and J. M. Polanco-Martinez (2020) <doi:10.1016/j.ecoinf.2020.101163>. ",
    "version": "1.2.0",
    "maintainer": "Josue M. Polanco-Martinez <josue.m.polanco@gmail.com>",
    "author": "Josue M. Polanco-Martinez [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RolWinMulCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RolWinMulCor Subroutines to Estimate Rolling Window Multiple Correlation Rolling Window Multiple Correlation ('RolWinMulCor') estimates the rolling (running) window correlation for the bi- and multi-variate cases between regular (sampled on identical time points) time series, with especial emphasis to ecological data although this can be applied to other kinds of data sets. 'RolWinMulCor' is based on the concept of rolling, running or sliding window and is useful to evaluate the evolution of correlation through time and time-scales. 'RolWinMulCor' contains six functions. The first two focus on the bi-variate case: (1) rolwincor_1win() and (2) rolwincor_heatmap(), which estimate the correlation coefficients and the their respective p-values for only one window-length (time-scale) and considering all possible window-lengths or a band of window-lengths, respectively. The second two functions: (3) rolwinmulcor_1win() and (4) rolwinmulcor_heatmap() are designed to analyze the multi-variate case, following the bi-variate case to visually display the results, but these two approaches are methodologically different. That is, the multi-variate case estimates the adjusted coefficients of determination instead of the correlation coefficients. The last two functions: (5) plot_1win() and (6) plot_heatmap() are used to represent graphically the outputs of the four aforementioned functions as simple plots or as heat maps. The functions contained in 'RolWinMulCor' are highly flexible since these contains several parameters to control the estimation of correlation and the features of the plot output, e.g. to remove the (linear) trend contained in the time series under analysis, to choose different p-value correction methods (which are used to address the multiple comparison problem) or to personalise the plot outputs. The 'RolWinMulCor' package also provides examples with synthetic and real-life ecological time series to exemplify its use. Methods derived from H. Abdi. (2007) <https://personal.utdallas.edu/~herve/Abdi-MCC2007-pretty.pdf>, R. Telford (2013) <https://quantpalaeo.wordpress.com/2013/01/04/, J. M. Polanco-Martinez (2019) <doi:10.1007/s11071-019-04974-y>, and J. M. Polanco-Martinez (2020) <doi:10.1016/j.ecoinf.2020.101163>.   "
  },
  {
    "id": 6788,
    "package_name": "RolWinWavCor",
    "title": "Estimate Rolling Window Wavelet Correlation Between Two Time\nSeries",
    "description": "Estimates and plots as a heat map the rolling window wavelet correlation (RWWC) coefficients statistically significant (within the 95% CI) between two regular (evenly spaced) time series. 'RolWinWavCor' also plots at the same graphic the time series under study. The 'RolWinWavCor' was designed for financial time series, but this software can be used with other kinds of data (e.g., climatic, ecological, geological, etc). The functions contained in 'RolWinWavCor' are highly flexible since these contains some parameters to personalize the time series under analysis and the heat maps of the rolling window wavelet correlation coefficients. Moreover, we have also included a data set (named EU_stock_markets) that contains nine European stock market indices to exemplify the use of the functions contained in 'RolWinWavCor'. Methods derived from Polanco-Mart\u00ednez et al (2018) <doi:10.1016/j.physa.2017.08.065>). ",
    "version": "0.4.0",
    "maintainer": "Josu\u00e9 M. Polanco-Mart\u00ednez <josue.m.polanco@gmail.com>",
    "author": "Josu\u00e9 M. Polanco-Mart\u00ednez [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RolWinWavCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RolWinWavCor Estimate Rolling Window Wavelet Correlation Between Two Time\nSeries Estimates and plots as a heat map the rolling window wavelet correlation (RWWC) coefficients statistically significant (within the 95% CI) between two regular (evenly spaced) time series. 'RolWinWavCor' also plots at the same graphic the time series under study. The 'RolWinWavCor' was designed for financial time series, but this software can be used with other kinds of data (e.g., climatic, ecological, geological, etc). The functions contained in 'RolWinWavCor' are highly flexible since these contains some parameters to personalize the time series under analysis and the heat maps of the rolling window wavelet correlation coefficients. Moreover, we have also included a data set (named EU_stock_markets) that contains nine European stock market indices to exemplify the use of the functions contained in 'RolWinWavCor'. Methods derived from Polanco-Mart\u00ednez et al (2018) <doi:10.1016/j.physa.2017.08.065>).   "
  },
  {
    "id": 6820,
    "package_name": "Rsfar",
    "title": "Seasonal Functional Autoregressive Models",
    "description": "This is a collection of functions designed for simulating, estimating and forecasting seasonal functional autoregressive time series of order one. These methods are addressed in the manuscript: <https://www.monash.edu/business/ebs/research/publications/ebs/wp16-2019.pdf>.",
    "version": "0.0.1",
    "maintainer": "Hossein Haghbin <haghbinh@gmail.com>",
    "author": "Hossein Haghbin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8416-2354>),\n  Rob Hyndman [aut]",
    "url": "https://github.com/haghbinh/Rsfar",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rsfar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rsfar Seasonal Functional Autoregressive Models This is a collection of functions designed for simulating, estimating and forecasting seasonal functional autoregressive time series of order one. These methods are addressed in the manuscript: <https://www.monash.edu/business/ebs/research/publications/ebs/wp16-2019.pdf>.  "
  },
  {
    "id": 6825,
    "package_name": "Rspc",
    "title": "Nelson Rules for Control Charts",
    "description": "Implementation of Nelson rules for control charts in 'R'. The 'Rspc' implements some Statistical Process Control methods, namely Levey-Jennings type of I (individuals) chart, Shewhart C (count) chart and Nelson rules (as described in Montgomery, D. C. (2013) Introduction to statistical quality control. Hoboken, NJ: Wiley.). Typical workflow is taking the time series, specify the control limits, and list of Nelson rules you want to evaluate. There are several options how to modify the rules (one sided limits, numerical parameters of rules, etc.). Package is also capable of calculating the control limits from the data (so far only for i-chart and c-chart are implemented).",
    "version": "1.2.2",
    "maintainer": "Stanislav Matousek (MSD) <rspc@merck.com>",
    "author": "Martin Vagenknecht (MSD) [aut],\n  Jindrich Soukup (MSD) [aut],\n  Stanislav Matousek (MSD) [aut, cre],\n  Janet Alvarado (MSD) [ctb, rev],\n  Merck Sharp & Dohme Corp. a subsidiary of Merck & Co., Inc.,\n    Kenilworth, NJ, USA [cph]",
    "url": "",
    "bug_reports": "https://github.com/Merck/SPC_Package/issues",
    "repository": "https://cran.r-project.org/package=Rspc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rspc Nelson Rules for Control Charts Implementation of Nelson rules for control charts in 'R'. The 'Rspc' implements some Statistical Process Control methods, namely Levey-Jennings type of I (individuals) chart, Shewhart C (count) chart and Nelson rules (as described in Montgomery, D. C. (2013) Introduction to statistical quality control. Hoboken, NJ: Wiley.). Typical workflow is taking the time series, specify the control limits, and list of Nelson rules you want to evaluate. There are several options how to modify the rules (one sided limits, numerical parameters of rules, etc.). Package is also capable of calculating the control limits from the data (so far only for i-chart and c-chart are implemented).  "
  },
  {
    "id": 6828,
    "package_name": "Rssa",
    "title": "A Collection of Methods for Singular Spectrum Analysis",
    "description": "Methods and tools for Singular Spectrum Analysis including decomposition,\n             forecasting and gap-filling for univariate and multivariate time series.\n             General description of the methods with many examples can be found in the book\n             Golyandina (2018, <doi:10.1007/978-3-662-57380-8>).\n             See 'citation(\"Rssa\")' for details.",
    "version": "1.1",
    "maintainer": "Anton Korobeynikov <anton@korobeynikov.info>",
    "author": "Anton Korobeynikov [aut, cre],\n  Alex Shlemov [aut],\n  Konstantin Usevich [aut],\n  Nina Golyandina [aut]",
    "url": "https://github.com/asl/rssa",
    "bug_reports": "https://github.com/asl/rssa/issues",
    "repository": "https://cran.r-project.org/package=Rssa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rssa A Collection of Methods for Singular Spectrum Analysis Methods and tools for Singular Spectrum Analysis including decomposition,\n             forecasting and gap-filling for univariate and multivariate time series.\n             General description of the methods with many examples can be found in the book\n             Golyandina (2018, <doi:10.1007/978-3-662-57380-8>).\n             See 'citation(\"Rssa\")' for details.  "
  },
  {
    "id": 6838,
    "package_name": "RtsEva",
    "title": "Performs the Transformed-Stationary Extreme Values Analysis",
    "description": "Adaptation of the 'Matlab' 'tsEVA' toolbox developed by Lorenzo Mentaschi\n    available here:\n    <https://github.com/menta78/tsEva>. It contains an implementation of the\n    Transformed-Stationary (TS) methodology for non-stationary extreme \n    value Analysis (EVA) as described in Mentaschi et al. (2016) <doi:10.5194/hess-20-3527-2016>.  \n    In synthesis this approach consists in:\n    (i) transforming a non-stationary time series into a\n    stationary one to which the stationary extreme value theory can be applied; and\n    (ii) reverse-transforming the result into a non-stationary extreme\n    value distribution.\n    'RtsEva' offers several options for trend estimation (mean, extremes, seasonal)\n    and contains multiple plotting functions displaying different aspects\n    of the non-stationarity of extremes.",
    "version": "1.1.0",
    "maintainer": "Alois Tilloy <alois.tilloy@ec.europa.eu>",
    "author": "Alois Tilloy [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5881-0642>)",
    "url": "https://github.com/r-lib/devtools,\nhttps://github.com/Alowis/RtsEva",
    "bug_reports": "https://github.com/Alowis/RtsEva/issues",
    "repository": "https://cran.r-project.org/package=RtsEva",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RtsEva Performs the Transformed-Stationary Extreme Values Analysis Adaptation of the 'Matlab' 'tsEVA' toolbox developed by Lorenzo Mentaschi\n    available here:\n    <https://github.com/menta78/tsEva>. It contains an implementation of the\n    Transformed-Stationary (TS) methodology for non-stationary extreme \n    value Analysis (EVA) as described in Mentaschi et al. (2016) <doi:10.5194/hess-20-3527-2016>.  \n    In synthesis this approach consists in:\n    (i) transforming a non-stationary time series into a\n    stationary one to which the stationary extreme value theory can be applied; and\n    (ii) reverse-transforming the result into a non-stationary extreme\n    value distribution.\n    'RtsEva' offers several options for trend estimation (mean, extremes, seasonal)\n    and contains multiple plotting functions displaying different aspects\n    of the non-stationarity of extremes.  "
  },
  {
    "id": 6887,
    "package_name": "SAiVE",
    "title": "Functions Used for SAiVE Group Research, Collaborations, and\nPublications",
    "description": "Holds functions developed by the University of Ottawa's SAiVE\n    (Spatio-temporal Analysis of isotope Variations in the Environment)\n    research group with the intention of facilitating the re-use of code,\n    foster good code writing practices, and to allow others to benefit\n    from the work done by the SAiVE group. Contributions are welcome via\n    the 'GitHub' repository <https://github.com/UO-SAiVE/SAiVE> by group members as well as non-members.",
    "version": "1.0.6",
    "maintainer": "Ghislain de Laplante <ghislain.delaplante@yukon.ca>",
    "author": "Ghislain de Laplante [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5093-9185>)",
    "url": "https://github.com/UO-SAiVE/SAiVE",
    "bug_reports": "https://github.com/UO-SAiVE/SAiVE/issues",
    "repository": "https://cran.r-project.org/package=SAiVE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SAiVE Functions Used for SAiVE Group Research, Collaborations, and\nPublications Holds functions developed by the University of Ottawa's SAiVE\n    (Spatio-temporal Analysis of isotope Variations in the Environment)\n    research group with the intention of facilitating the re-use of code,\n    foster good code writing practices, and to allow others to benefit\n    from the work done by the SAiVE group. Contributions are welcome via\n    the 'GitHub' repository <https://github.com/UO-SAiVE/SAiVE> by group members as well as non-members.  "
  },
  {
    "id": 6889,
    "package_name": "SBAGM",
    "title": "Search Best ARIMA, GARCH, and MS-GARCH Model",
    "description": "Get the most appropriate autoregressive integrated moving average, generalized auto-regressive conditional heteroscedasticity and Markov switching GARCH model. For method details see Haas M, Mittnik S, Paolella MS (2004). <doi:10.1093/jjfinec/nbh020>, Bollerslev T (1986). <doi:10.1016/0304-4076(86)90063-1>.",
    "version": "0.1.0",
    "maintainer": "Rajeev Ranjan Kumar <rrk.uasd@gmail.com>",
    "author": "Rajeev Ranjan Kumar [aut, cre],\n  Girish Kumar Jha [aut, ths, ctb],\n  Dwijesh C. Mishra [ctb],\n  Neeraj Budhlakoti [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SBAGM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SBAGM Search Best ARIMA, GARCH, and MS-GARCH Model Get the most appropriate autoregressive integrated moving average, generalized auto-regressive conditional heteroscedasticity and Markov switching GARCH model. For method details see Haas M, Mittnik S, Paolella MS (2004). <doi:10.1093/jjfinec/nbh020>, Bollerslev T (1986). <doi:10.1016/0304-4076(86)90063-1>.  "
  },
  {
    "id": 6910,
    "package_name": "SCI",
    "title": "Standardized Climate Indices Such as SPI, SRI or SPEI",
    "description": "Functions for generating Standardized Climate Indices (SCI).\n  Functions for generating Standardized Climate Indices (SCI). \n  SCI is a transformation of (smoothed) climate (or environmental) time series \n  that removes seasonality and forces the data to take values of the standard \n  normal distribution. SCI was originally developed for precipitation. \n  In this case it is known as the Standardized Precipitation Index (SPI).",
    "version": "1.0-3",
    "maintainer": "Lukas Gudmundsson <lukas.gudmundsson@env.ethz.ch>",
    "author": "Lukas Gudmundsson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3539-8621>),\n  Jim Stagge [aut] (ORCID: <https://orcid.org/0000-0002-3667-2904>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SCI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SCI Standardized Climate Indices Such as SPI, SRI or SPEI Functions for generating Standardized Climate Indices (SCI).\n  Functions for generating Standardized Climate Indices (SCI). \n  SCI is a transformation of (smoothed) climate (or environmental) time series \n  that removes seasonality and forces the data to take values of the standard \n  normal distribution. SCI was originally developed for precipitation. \n  In this case it is known as the Standardized Precipitation Index (SPI).  "
  },
  {
    "id": 6932,
    "package_name": "SDLfilter",
    "title": "Filtering and Assessing the Sample Size of Tracking Data",
    "description": "Functions to filter GPS/Argos locations, as well as assessing the sample size for the analysis of animal distributions. The filters remove temporal and spatial duplicates, fixes located at a given height from estimated high tide line, and locations with high error as described in Shimada et al. (2012) <doi:10.3354/meps09747> and Shimada et al. (2016) <doi:10.1007/s00227-015-2771-0>. Sample size for the analysis of animal distributions can be assessed by the conventional area-based approach or the alternative probability-based approach as described in Shimada et al. (2021) <doi:10.1111/2041-210X.13506>. ",
    "version": "2.3.3",
    "maintainer": "Takahiro Shimada <taka.shimada@gmail.com>",
    "author": "Takahiro Shimada",
    "url": "https://github.com/TakahiroShimada/SDLfilter",
    "bug_reports": "https://github.com/TakahiroShimada/SDLfilter/issues",
    "repository": "https://cran.r-project.org/package=SDLfilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SDLfilter Filtering and Assessing the Sample Size of Tracking Data Functions to filter GPS/Argos locations, as well as assessing the sample size for the analysis of animal distributions. The filters remove temporal and spatial duplicates, fixes located at a given height from estimated high tide line, and locations with high error as described in Shimada et al. (2012) <doi:10.3354/meps09747> and Shimada et al. (2016) <doi:10.1007/s00227-015-2771-0>. Sample size for the analysis of animal distributions can be assessed by the conventional area-based approach or the alternative probability-based approach as described in Shimada et al. (2021) <doi:10.1111/2041-210X.13506>.   "
  },
  {
    "id": 6946,
    "package_name": "SEI",
    "title": "Calculating Standardised Indices",
    "description": "Convert a time series of observations to a time series of standardised indices that can be used to monitor variables on a common and probabilistically interpretable scale. The indices can be aggregated and rescaled to different time scales, visualised using plot capabilities, and calculated using a range of distributions. This includes flexible non-parametric and non-stationary methods.",
    "version": "0.2.0",
    "maintainer": "Sam Allen <sam.allen@stat.math.ethz.ch>",
    "author": "Sam Allen [aut, cre],\n  Noelia Otero [aut]",
    "url": "https://github.com/noeliaof/SEI, https://noeliaof.github.io/SEI/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SEI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SEI Calculating Standardised Indices Convert a time series of observations to a time series of standardised indices that can be used to monitor variables on a common and probabilistically interpretable scale. The indices can be aggregated and rescaled to different time scales, visualised using plot capabilities, and calculated using a range of distributions. This includes flexible non-parametric and non-stationary methods.  "
  },
  {
    "id": 6992,
    "package_name": "SIMle",
    "title": "Estimation and Inference for General Time Series Regression",
    "description": "We provide functions for estimation and inference of nonlinear and non-stationary time series regression using the sieve methods and bootstrapping procedure. ",
    "version": "0.1.0",
    "maintainer": "Xiucai Ding <xiucaiding89@gmail.com>",
    "author": "Xiucai Ding [aut, cre, cph],\n  Chen Qian [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SIMle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SIMle Estimation and Inference for General Time Series Regression We provide functions for estimation and inference of nonlinear and non-stationary time series regression using the sieve methods and bootstrapping procedure.   "
  },
  {
    "id": 7007,
    "package_name": "SKFCPD",
    "title": "Fast Online Changepoint Detection for Temporally Correlated Data",
    "description": "Sequential Kalman filter for scalable online changepoint detection by temporally correlated data. It enables fast single and multiple change points with missing values. See the reference: Hanmo Li, Yuedong Wang, Mengyang Gu (2023), <arXiv:2310.18611>.",
    "version": "0.2.4",
    "maintainer": "Hanmo Li <hanmo@pstat.ucsb.edu>",
    "author": "Hanmo Li [aut, cre],\n  Yuedong Wang [aut],\n  Mengyang Gu [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SKFCPD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SKFCPD Fast Online Changepoint Detection for Temporally Correlated Data Sequential Kalman filter for scalable online changepoint detection by temporally correlated data. It enables fast single and multiple change points with missing values. See the reference: Hanmo Li, Yuedong Wang, Mengyang Gu (2023), <arXiv:2310.18611>.  "
  },
  {
    "id": 7009,
    "package_name": "SLBDD",
    "title": "Statistical Learning for Big Dependent Data",
    "description": "Programs for analyzing large-scale time series data. They include functions for automatic specification and estimation of univariate time series, for clustering time series, for multivariate outlier detections, for quantile plotting of many time series, for dynamic factor models and for creating input data for deep learning programs. Examples of using the package can be found in the Wiley book 'Statistical Learning with Big Dependent Data' by Daniel Pe\u00f1a and Ruey S. Tsay (2021). ISBN 9781119417385.",
    "version": "0.0.4",
    "maintainer": "Antonio Elias <antonioefz91@gmail.com>",
    "author": "Angela Caro [aut],\n  Antonio Elias [aut, cre],\n  Daniel Pe\u00f1a [aut],\n  Ruey S. Tsay [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SLBDD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SLBDD Statistical Learning for Big Dependent Data Programs for analyzing large-scale time series data. They include functions for automatic specification and estimation of univariate time series, for clustering time series, for multivariate outlier detections, for quantile plotting of many time series, for dynamic factor models and for creating input data for deep learning programs. Examples of using the package can be found in the Wiley book 'Statistical Learning with Big Dependent Data' by Daniel Pe\u00f1a and Ruey S. Tsay (2021). ISBN 9781119417385.  "
  },
  {
    "id": 7056,
    "package_name": "SNSchart",
    "title": "Sequential Normal Scores in Statistical Process Management",
    "description": "The methods discussed in this package are new non-parametric methods\n    based on sequential normal scores 'SNS' (Conover et al (2017)\n    <doi:10.1080/07474946.2017.1360091>), designed for sequences of observations,\n    usually time series data, which may occur singly or in batches,\n    and may be univariate or multivariate. These methods are designed\n    to detect changes in the process, which may occur as changes in location\n    (mean or median), changes in scale (standard deviation, or variance), or\n    other changes of interest in the distribution of the observations,\n    over the time observed. They usually apply to large data sets,\n    so computations need to be simple enough to be done in a reasonable\n    time on a computer, and easily updated as each new observation\n    (or batch of observations) becomes available. Some examples and more detail\n    in 'SNS' is presented in the work by Conover et al (2019) <arXiv:1901.04443>.",
    "version": "1.4.0",
    "maintainer": "Luis Benavides <luisbv@tec.mx>",
    "author": "Victor Tercero [aut],\n  Luis Benavides [aut, cre],\n  Jorge Merlo [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SNSchart",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SNSchart Sequential Normal Scores in Statistical Process Management The methods discussed in this package are new non-parametric methods\n    based on sequential normal scores 'SNS' (Conover et al (2017)\n    <doi:10.1080/07474946.2017.1360091>), designed for sequences of observations,\n    usually time series data, which may occur singly or in batches,\n    and may be univariate or multivariate. These methods are designed\n    to detect changes in the process, which may occur as changes in location\n    (mean or median), changes in scale (standard deviation, or variance), or\n    other changes of interest in the distribution of the observations,\n    over the time observed. They usually apply to large data sets,\n    so computations need to be simple enough to be done in a reasonable\n    time on a computer, and easily updated as each new observation\n    (or batch of observations) becomes available. Some examples and more detail\n    in 'SNS' is presented in the work by Conover et al (2019) <arXiv:1901.04443>.  "
  },
  {
    "id": 7057,
    "package_name": "SNSeg",
    "title": "Self-Normalization(SN) Based Change-Point Estimation for Time\nSeries",
    "description": "Implementations self-normalization (SN) based algorithms for \n    change-points estimation in time series data. This comprises nested \n    local-window algorithms for detecting changes in both univariate and \n    multivariate time series developed in Zhao, Jiang and Shao (2022) \n    <doi:10.1111/rssb.12552>.",
    "version": "1.0.3",
    "maintainer": "Zifeng Zhao <zzhao2@nd.edu>",
    "author": "Shubo Sun [aut],\n  Zifeng Zhao [aut, cre],\n  Feiyu Jiang [aut],\n  Xiaofeng Shao [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SNSeg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SNSeg Self-Normalization(SN) Based Change-Point Estimation for Time\nSeries Implementations self-normalization (SN) based algorithms for \n    change-points estimation in time series data. This comprises nested \n    local-window algorithms for detecting changes in both univariate and \n    multivariate time series developed in Zhao, Jiang and Shao (2022) \n    <doi:10.1111/rssb.12552>.  "
  },
  {
    "id": 7078,
    "package_name": "SPAS",
    "title": "Stratified-Petersen Analysis System",
    "description": "The Stratified-Petersen Analysis System (SPAS) is designed\n    to estimate abundance in two-sample capture-recapture experiments \n    where the capture and recaptures are stratified. This is a generalization\n    of the simple Lincoln-Petersen estimator.\n    Strata may be defined in time or in space or both, \n    and the s strata in which marking takes place \n    may differ from the t strata in which recoveries take place.\n    When s=t, SPAS reduces to the method described by \n    Darroch (1961) <doi:10.2307/2332748>.\n    When s<t, SPAS implements the methods described in\n    Plante, Rivest, and Tremblay (1988) <doi:10.2307/2533994>.\n    Schwarz and Taylor (1998) <doi:10.1139/f97-238> describe\n    the use of SPAS in estimating return of salmon stratified by\n    time and geography. \n    A related package, BTSPAS, deals with temporal stratification where \n    a spline is used to model the distribution of the population \n    over time as it passes the second capture location.\n    This is the R-version of the (now obsolete) standalone Windows \n    program of the same name.",
    "version": "2025.2.1",
    "maintainer": "Carl James Schwarz <cschwarz.stat.sfu.ca@gmail.com>",
    "author": "Carl James Schwarz [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SPAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SPAS Stratified-Petersen Analysis System The Stratified-Petersen Analysis System (SPAS) is designed\n    to estimate abundance in two-sample capture-recapture experiments \n    where the capture and recaptures are stratified. This is a generalization\n    of the simple Lincoln-Petersen estimator.\n    Strata may be defined in time or in space or both, \n    and the s strata in which marking takes place \n    may differ from the t strata in which recoveries take place.\n    When s=t, SPAS reduces to the method described by \n    Darroch (1961) <doi:10.2307/2332748>.\n    When s<t, SPAS implements the methods described in\n    Plante, Rivest, and Tremblay (1988) <doi:10.2307/2533994>.\n    Schwarz and Taylor (1998) <doi:10.1139/f97-238> describe\n    the use of SPAS in estimating return of salmon stratified by\n    time and geography. \n    A related package, BTSPAS, deals with temporal stratification where \n    a spline is used to model the distribution of the population \n    over time as it passes the second capture location.\n    This is the R-version of the (now obsolete) standalone Windows \n    program of the same name.  "
  },
  {
    "id": 7094,
    "package_name": "SPORTSCausal",
    "title": "Spillover Time Series Causal Inference",
    "description": "A time series causal inference model for Randomized Controlled Trial (RCT) under spillover effect. 'SPORTSCausal' (Spillover Time Series Causal Inference) separates treatment effect and spillover effect from given responses of experiment group and control group by predicting the response without treatment. It reports both effects by fitting the Bayesian Structural Time Series (BSTS) model based on 'CausalImpact', as described in Brodersen et al. (2015) <doi:10.1214/14-AOAS788>. ",
    "version": "1.0",
    "maintainer": "Feiyu Yue <yuefyopals@gmail.com>",
    "author": "Zihao Zheng and Feiyu Yue",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SPORTSCausal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SPORTSCausal Spillover Time Series Causal Inference A time series causal inference model for Randomized Controlled Trial (RCT) under spillover effect. 'SPORTSCausal' (Spillover Time Series Causal Inference) separates treatment effect and spillover effect from given responses of experiment group and control group by predicting the response without treatment. It reports both effects by fitting the Bayesian Structural Time Series (BSTS) model based on 'CausalImpact', as described in Brodersen et al. (2015) <doi:10.1214/14-AOAS788>.   "
  },
  {
    "id": 7117,
    "package_name": "SSAforecast",
    "title": "SSA Based Decomposition and Forecasting",
    "description": "Singular spectrum analysis (SSA) decomposes a time series into interpretable components like trends, oscillations, and noise without strict distributional and structural assumptions. For method details see Golyandina N, Zhigljavsky A (2013). <doi:10.1007/978-3-642-34913-3>. ",
    "version": "0.1.1",
    "maintainer": "Rajeev Ranjan Kumar <rrk.uasd@gmail.com>",
    "author": "Prabhat Kumar [aut, ctb],\n  Girish Kumar Jha [aut, ths, ctb],\n  Rajeev Ranjan Kumar [aut, ctb, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SSAforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SSAforecast SSA Based Decomposition and Forecasting Singular spectrum analysis (SSA) decomposes a time series into interpretable components like trends, oscillations, and noise without strict distributional and structural assumptions. For method details see Golyandina N, Zhigljavsky A (2013). <doi:10.1007/978-3-642-34913-3>.   "
  },
  {
    "id": 7129,
    "package_name": "SSNbayes",
    "title": "Bayesian Spatio-Temporal Analysis in Stream Networks",
    "description": "Fits Bayesian spatio-temporal models and makes predictions on stream networks using the approach by Santos-Fernandez, Edgar, et al. (2022).\"Bayesian spatio-temporal models for stream networks\". <arXiv:2103.03538>. In these models, spatial dependence is captured using stream distance and flow connectivity, while temporal autocorrelation is modelled using vector autoregression methods. ",
    "version": "0.0.3",
    "maintainer": "Edgar Santos-Fernandez <santosfe@qut.edu.au>",
    "author": "Edgar Santos-Fernandez [aut, cre, cph]",
    "url": "https://github.com/EdgarSantos-Fernandez/SSNbayes",
    "bug_reports": "https://github.com/EdgarSantos-Fernandez/SSNbayes/issues",
    "repository": "https://cran.r-project.org/package=SSNbayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SSNbayes Bayesian Spatio-Temporal Analysis in Stream Networks Fits Bayesian spatio-temporal models and makes predictions on stream networks using the approach by Santos-Fernandez, Edgar, et al. (2022).\"Bayesian spatio-temporal models for stream networks\". <arXiv:2103.03538>. In these models, spatial dependence is captured using stream distance and flow connectivity, while temporal autocorrelation is modelled using vector autoregression methods.   "
  },
  {
    "id": 7147,
    "package_name": "STCCGEV",
    "title": "Conditional Copula Model for Crop Yield Forecasting",
    "description": "Provides functions to model and forecast crop yields using a spatial temporal conditional copula approach. \n    The package incorporates extreme weather covariates and Bayesian Structural Time Series models to analyze crop \n    yield dependencies across multiple regions. Includes tools for fitting, simulating, and visualizing results. \n    This method build upon established R packages, including 'Hofert' 'et' 'al'. (2025) <doi:10.32614/CRAN.package.copula>, \n    'Scott' (2024) <doi:10.32614/CRAN.package.bsts>, and 'Stephenson' 'et' 'al'. (2024) <doi:10.32614/CRAN.package.evd>.",
    "version": "1.0.0",
    "maintainer": "Yongkun Li <yongkun.li@concordia.ca>",
    "author": "Marie Michaelides [aut],\n  M\u00e9lina Mailhot [aut],\n  Yongkun Li [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=STCCGEV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STCCGEV Conditional Copula Model for Crop Yield Forecasting Provides functions to model and forecast crop yields using a spatial temporal conditional copula approach. \n    The package incorporates extreme weather covariates and Bayesian Structural Time Series models to analyze crop \n    yield dependencies across multiple regions. Includes tools for fitting, simulating, and visualizing results. \n    This method build upon established R packages, including 'Hofert' 'et' 'al'. (2025) <doi:10.32614/CRAN.package.copula>, \n    'Scott' (2024) <doi:10.32614/CRAN.package.bsts>, and 'Stephenson' 'et' 'al'. (2024) <doi:10.32614/CRAN.package.evd>.  "
  },
  {
    "id": 7148,
    "package_name": "STCYP",
    "title": "Spatio-Temporal Crop Yield Prediction",
    "description": "Provides crop yield and meteorological data for Ontario, Canada. \n  Includes functions for fitting and predicting data using spatio-temporal models, as well as\n  tools for visualizing the results. The package builds upon existing R packages, including\n  'copula' (Hofert et al., 2025) <doi:10.32614/CRAN.package.copula>, and\n  'bsts' (Scott, 2024) <doi:10.32614/CRAN.package.bsts>.",
    "version": "1.0.0",
    "maintainer": "Yongkun Li <yongkun.li@concordia.ca>",
    "author": "Marie Michaelides [aut],\n  M\u00e9lina Mailhot [aut],\n  Yongkun Li [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=STCYP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STCYP Spatio-Temporal Crop Yield Prediction Provides crop yield and meteorological data for Ontario, Canada. \n  Includes functions for fitting and predicting data using spatio-temporal models, as well as\n  tools for visualizing the results. The package builds upon existing R packages, including\n  'copula' (Hofert et al., 2025) <doi:10.32614/CRAN.package.copula>, and\n  'bsts' (Scott, 2024) <doi:10.32614/CRAN.package.bsts>.  "
  },
  {
    "id": 7151,
    "package_name": "STFTS",
    "title": "Statistical Tests for Functional Time Series",
    "description": "A collection of statistical hypothesis tests of functional time series. While it will include more tests when the related literature are enriched, this package contains the following key tests: functional stationarity test, functional trend stationarity test, functional unit root test, to name a few.",
    "version": "0.1.0",
    "maintainer": "Chi Seng Pun <cspun@ntu.edu.sg>",
    "author": "Yichao Chen [aut],\n  Chi Seng Pun [cre, aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=STFTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STFTS Statistical Tests for Functional Time Series A collection of statistical hypothesis tests of functional time series. While it will include more tests when the related literature are enriched, this package contains the following key tests: functional stationarity test, functional trend stationarity test, functional unit root test, to name a few.  "
  },
  {
    "id": 7153,
    "package_name": "STMotif",
    "title": "Discovery of Motifs in Spatial-Time Series",
    "description": "Allow to identify motifs in spatial-time series. A motif is a previously unknown subsequence of a (spatial) time series with relevant number of occurrences. For this purpose, the Combined Series Approach (CSA) is used.",
    "version": "2.0.2",
    "maintainer": "Heraldo Borges <stmotif@eic.cefet-rj.br>",
    "author": "Heraldo Borges [aut, cre] (CEFET/RJ),\n  Amin Bazaz [aut] (Polytech'Montpellier),\n  Esther Pacciti [aut] (INRIA/Polytech'Montpellier),\n  Eduardo Ogasawara [aut] (CEFET/RJ)",
    "url": "https://github.com/heraldoborges/STMotif/wiki",
    "bug_reports": "https://github.com/heraldoborges/STMotif/issues",
    "repository": "https://cran.r-project.org/package=STMotif",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STMotif Discovery of Motifs in Spatial-Time Series Allow to identify motifs in spatial-time series. A motif is a previously unknown subsequence of a (spatial) time series with relevant number of occurrences. For this purpose, the Combined Series Approach (CSA) is used.  "
  },
  {
    "id": 7160,
    "package_name": "SUMMER",
    "title": "Small-Area-Estimation Unit/Area Models and Methods for\nEstimation in R",
    "description": "Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>, Li et al. (2019) <doi:10.1371/journal.pone.0210645>, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) <doi:10.48550/arXiv.2007.05117>. ",
    "version": "2.0.0",
    "maintainer": "Zehang R Li <lizehang@gmail.com>",
    "author": "Zehang R Li [cre, aut],\n  Bryan D Martin [aut],\n  Yuan Hsiao [aut],\n  Jessica Godwin [aut],\n  John Paige [aut],\n  Peter Gao [aut],\n  Jon Wakefield [aut],\n  Samuel J Clark [aut],\n  Geir-Arne Fuglstad [aut],\n  Andrea Riebler [aut]",
    "url": "https://github.com/richardli/SUMMER,\nhttps://richardli.github.io/SUMMER/",
    "bug_reports": "https://github.com/richardli/SUMMER/issues",
    "repository": "https://cran.r-project.org/package=SUMMER",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SUMMER Small-Area-Estimation Unit/Area Models and Methods for\nEstimation in R Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>, Li et al. (2019) <doi:10.1371/journal.pone.0210645>, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) <doi:10.48550/arXiv.2007.05117>.   "
  },
  {
    "id": 7163,
    "package_name": "SUSY",
    "title": "Surrogate Synchrony",
    "description": "Computes synchrony as windowed cross-correlation based on two-dimensional time series in a text file you can upload. 'SUSY' works as described in Tschacher & Meier (2020) <doi:10.1080/10503307.2019.1612114>.",
    "version": "0.1.0",
    "maintainer": "Wolfgang Tschacher <wolfgang.tschacher@upd.unibe.ch>",
    "author": "Wolfgang Tschacher [aut, cre],\n  David Tschacher [ctb],\n  Jan Gorecki [ctb]",
    "url": "https://wtschacher.github.io/SUSY/",
    "bug_reports": "https://github.com/wtschacher/SUSY/issues",
    "repository": "https://cran.r-project.org/package=SUSY",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SUSY Surrogate Synchrony Computes synchrony as windowed cross-correlation based on two-dimensional time series in a text file you can upload. 'SUSY' works as described in Tschacher & Meier (2020) <doi:10.1080/10503307.2019.1612114>.  "
  },
  {
    "id": 7166,
    "package_name": "SVDNF",
    "title": "Discrete Nonlinear Filtering for Stochastic Volatility Models",
    "description": "Implements the discrete nonlinear filter (DNF) of Kitagawa (1987) <doi:10.1080/01621459.1987.10478534> to a wide class of stochastic volatility (SV) models with return and volatility jumps following the work of B\u00e9gin and Boudreault (2021) <doi:10.1080/10618600.2020.1840995> to obtain likelihood evaluations and maximum likelihood parameter estimates. Offers several built-in SV models and a flexible framework for users to create customized models by specifying drift and diffusion functions along with an arrival distribution for the return and volatility jumps. Allows for the estimation of factor models with stochastic volatility (e.g., heteroskedastic volatility CAPM) by incorporating expected return predictors. Also includes functions to compute filtering and prediction distribution estimates, to simulate data from built-in and custom SV models with jumps, and to forecast future returns and volatility values using Monte Carlo simulation from a given SV model. ",
    "version": "0.1.11",
    "maintainer": "Louis Arsenault-Mahjoubi <larsenau@sfu.ca>",
    "author": "Louis Arsenault-Mahjoubi [aut, cre],\n  Jean-Fran\u00e7ois B\u00e9gin [aut],\n  Mathieu Boudreault [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SVDNF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SVDNF Discrete Nonlinear Filtering for Stochastic Volatility Models Implements the discrete nonlinear filter (DNF) of Kitagawa (1987) <doi:10.1080/01621459.1987.10478534> to a wide class of stochastic volatility (SV) models with return and volatility jumps following the work of B\u00e9gin and Boudreault (2021) <doi:10.1080/10618600.2020.1840995> to obtain likelihood evaluations and maximum likelihood parameter estimates. Offers several built-in SV models and a flexible framework for users to create customized models by specifying drift and diffusion functions along with an arrival distribution for the return and volatility jumps. Allows for the estimation of factor models with stochastic volatility (e.g., heteroskedastic volatility CAPM) by incorporating expected return predictors. Also includes functions to compute filtering and prediction distribution estimates, to simulate data from built-in and custom SV models with jumps, and to forecast future returns and volatility values using Monte Carlo simulation from a given SV model.   "
  },
  {
    "id": 7172,
    "package_name": "SWMPr",
    "title": "Retrieving, Organizing, and Analyzing Estuary Monitoring Data",
    "description": "Tools for retrieving, organizing, and analyzing environmental\n    data from the System Wide Monitoring Program of the National Estuarine\n    Research Reserve System <https://cdmo.baruch.sc.edu/>. These tools\n    address common challenges associated with continuous time series data\n    for environmental decision making.",
    "version": "2.5.2",
    "maintainer": "Marcus W. Beck <mbeck@tbep.org>",
    "author": "Marcus W. Beck [aut, cre],\n  Kimberly Cressman [ctb]",
    "url": "http://fawda123.github.io/SWMPr/",
    "bug_reports": "https://github.com/fawda123/SWMPr/issues",
    "repository": "https://cran.r-project.org/package=SWMPr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SWMPr Retrieving, Organizing, and Analyzing Estuary Monitoring Data Tools for retrieving, organizing, and analyzing environmental\n    data from the System Wide Monitoring Program of the National Estuarine\n    Research Reserve System <https://cdmo.baruch.sc.edu/>. These tools\n    address common challenges associated with continuous time series data\n    for environmental decision making.  "
  },
  {
    "id": 7200,
    "package_name": "SeaVal",
    "title": "Validation of Seasonal Weather Forecasts",
    "description": "Provides tools for processing and evaluating seasonal weather forecasts, \n    with an emphasis on tercile forecasts. We follow the World Meteorological Organization's \n    \"Guidance on Verification of Operational Seasonal Climate Forecasts\", \n    S.J.Mason (2018, ISBN: 978-92-63-11220-0, URL: <https://library.wmo.int/idurl/4/56227>). \n    The development was supported by the European Union\u2019s Horizon 2020 research and innovation \n    programme under grant agreement no. 869730 (CONFER).\n    A comprehensive online tutorial is available at <https://seasonalforecastingengine.github.io/SeaValDoc/>.",
    "version": "1.2.0",
    "maintainer": "Claudio Heinrich-Mertsching <claudio.heinrich@hotmail.de>",
    "author": "Claudio Heinrich-Mertsching [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3581-6416>),\n  Celine Cunen [ctb],\n  Michael Scheuerer [ctb]",
    "url": "https://seasonalforecastingengine.github.io/SeaValDoc/,\nhttps://github.com/SeasonalForecastingEngine/SeaVal",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SeaVal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SeaVal Validation of Seasonal Weather Forecasts Provides tools for processing and evaluating seasonal weather forecasts, \n    with an emphasis on tercile forecasts. We follow the World Meteorological Organization's \n    \"Guidance on Verification of Operational Seasonal Climate Forecasts\", \n    S.J.Mason (2018, ISBN: 978-92-63-11220-0, URL: <https://library.wmo.int/idurl/4/56227>). \n    The development was supported by the European Union\u2019s Horizon 2020 research and innovation \n    programme under grant agreement no. 869730 (CONFER).\n    A comprehensive online tutorial is available at <https://seasonalforecastingengine.github.io/SeaValDoc/>.  "
  },
  {
    "id": 7202,
    "package_name": "SeasEpi",
    "title": "Spatiotemporal Modeling of Seasonal Infectious Disease",
    "description": "Spatiotemporal individual-level model of seasonal infectious disease transmission within the Susceptible-Exposed-Infectious-Recovered-Susceptible (SEIRS) framework are applied to model seasonal infectious disease transmission. This package employs a likelihood based Monte Carlo Expectation Conditional Maximization (MCECM) algorithm for estimating model parameters. In addition to model fitting and parameter estimation, the package offers functions for calculating AIC using real pandemic data and conducting simulation studies customized to user-specified model configurations.",
    "version": "0.0.3",
    "maintainer": "Amin Abed <abeda@myumanitoba.ca>",
    "author": "Amin Abed [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7381-4721>),\n  Mahmoud Torabi [ths],\n  Zeinab Mashreghi [ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SeasEpi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SeasEpi Spatiotemporal Modeling of Seasonal Infectious Disease Spatiotemporal individual-level model of seasonal infectious disease transmission within the Susceptible-Exposed-Infectious-Recovered-Susceptible (SEIRS) framework are applied to model seasonal infectious disease transmission. This package employs a likelihood based Monte Carlo Expectation Conditional Maximization (MCECM) algorithm for estimating model parameters. In addition to model fitting and parameter estimation, the package offers functions for calculating AIC using real pandemic data and conducting simulation studies customized to user-specified model configurations.  "
  },
  {
    "id": 7219,
    "package_name": "SemanticDistance",
    "title": "Compute Semantic Distance Between Text Constituents",
    "description": "Cleans and formats language transcripts guided by a series of transformation options (e.g., lemmatize words, omit stopwords, split strings across rows). 'SemanticDistance' computes two distinct metrics of cosine semantic distance (experiential and embedding). These values reflect pairwise cosine distance between different elements or chunks of a language sample. 'SemanticDistance' can process monologues (e.g., stories, ordered text), dialogues (e.g., conversation transcripts), word pairs arrayed in columns, and unordered word lists. Users specify options for how they wish to chunk distance calculations. These options include: rolling ngram-to-word distance (window of n-words to each new word), ngram-to-ngram distance (2-word chunk to the next 2-word chunk), pairwise distance between words arrayed in columns, matrix comparisons (i.e., all possible pairwise distances between words in an unordered list), turn-by-turn distance (talker to talker in a dialogue transcript). 'SemanticDistance' includes visualization options for analyzing distances as time series data and simple semantic network dynamics (e.g., clustering, undirected graph network).",
    "version": "0.1.1",
    "maintainer": "Jamie Reilly <jamie_reilly@temple.edu>",
    "author": "Jamie Reilly [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0891-438X>),\n  Emily B. Myers [aut],\n  Hannah R. Mechtenberg [aut],\n  Jonathan E. Peelle [aut]",
    "url": "https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance,\nhttps://reilly-conceptscognitionlab.github.io/SemanticDistance/",
    "bug_reports": "https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/issues",
    "repository": "https://cran.r-project.org/package=SemanticDistance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SemanticDistance Compute Semantic Distance Between Text Constituents Cleans and formats language transcripts guided by a series of transformation options (e.g., lemmatize words, omit stopwords, split strings across rows). 'SemanticDistance' computes two distinct metrics of cosine semantic distance (experiential and embedding). These values reflect pairwise cosine distance between different elements or chunks of a language sample. 'SemanticDistance' can process monologues (e.g., stories, ordered text), dialogues (e.g., conversation transcripts), word pairs arrayed in columns, and unordered word lists. Users specify options for how they wish to chunk distance calculations. These options include: rolling ngram-to-word distance (window of n-words to each new word), ngram-to-ngram distance (2-word chunk to the next 2-word chunk), pairwise distance between words arrayed in columns, matrix comparisons (i.e., all possible pairwise distances between words in an unordered list), turn-by-turn distance (talker to talker in a dialogue transcript). 'SemanticDistance' includes visualization options for analyzing distances as time series data and simple semantic network dynamics (e.g., clustering, undirected graph network).  "
  },
  {
    "id": 7249,
    "package_name": "ShapeSelectForest",
    "title": "Shape Selection for Landsat Time Series of Forest Dynamics",
    "description": "Landsat satellites collect important data about global forest conditions. Documentation about Landsat's role in forest disturbance estimation is available at the site <https://landsat.gsfc.nasa.gov/>. By constrained quadratic B-splines, this package delivers an optimal shape-restricted trajectory to a time series of Landsat imagery for the purpose of modeling annual forest disturbance dynamics to behave in an ecologically sensible manner assuming one of seven possible \"shapes\", namely, flat, decreasing, one-jump (decreasing, jump up, decreasing), inverted vee (increasing then decreasing), vee (decreasing then increasing), linear increasing, and double-jump (decreasing, jump up, decreasing, jump up, decreasing). The main routine selects the best shape according to the minimum Bayes information criterion (BIC) or the cone information criterion (CIC), which is defined as the log of the estimated predictive squared error. The package also provides parameters summarizing the temporal pattern including year(s) of inflection, magnitude of change, pre- and post-inflection rates of growth or recovery. In addition, it contains routines for converting a flat map of disturbance agents to time-series disturbance maps and a graphical routine displaying the fitted trajectory of Landsat imagery. ",
    "version": "1.7",
    "maintainer": "Xiyue Liao <xliao@sdsu.edu>",
    "author": "Xiyue Liao [aut, cre] (ORCID: <https://orcid.org/0000-0002-4508-9219>),\n  Mary Meyer [aut],\n  Elizabeth Freeman [aut],\n  Gretchen Moisen [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ShapeSelectForest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ShapeSelectForest Shape Selection for Landsat Time Series of Forest Dynamics Landsat satellites collect important data about global forest conditions. Documentation about Landsat's role in forest disturbance estimation is available at the site <https://landsat.gsfc.nasa.gov/>. By constrained quadratic B-splines, this package delivers an optimal shape-restricted trajectory to a time series of Landsat imagery for the purpose of modeling annual forest disturbance dynamics to behave in an ecologically sensible manner assuming one of seven possible \"shapes\", namely, flat, decreasing, one-jump (decreasing, jump up, decreasing), inverted vee (increasing then decreasing), vee (decreasing then increasing), linear increasing, and double-jump (decreasing, jump up, decreasing, jump up, decreasing). The main routine selects the best shape according to the minimum Bayes information criterion (BIC) or the cone information criterion (CIC), which is defined as the log of the estimated predictive squared error. The package also provides parameters summarizing the temporal pattern including year(s) of inflection, magnitude of change, pre- and post-inflection rates of growth or recovery. In addition, it contains routines for converting a flat map of disturbance agents to time-series disturbance maps and a graphical routine displaying the fitted trajectory of Landsat imagery.   "
  },
  {
    "id": 7255,
    "package_name": "ShellChron",
    "title": "Builds Chronologies from Oxygen Isotope Profiles in Shells",
    "description": "Takes as input a stable oxygen isotope (d18O) profile measured in growth direction (D)\n\tthrough a shell + uncertainties in both variables (d18O_err & D_err). It then models the seasonality\n\tin the d18O record by fitting a combination of a growth and temperature sine wave to year-length chunks of\n\tthe data (see Judd et al., (2018) <doi:10.1016/j.palaeo.2017.09.034>). This modeling is carried out along a sliding window through the data and yields estimates of\n\tthe day of the year (Julian Day) and local growth rate for each data point. Uncertainties in both modeling\n\troutine and the data itself are propagated and pooled to obtain a confidence envelope around the age of\n\teach data point in the shell. The end result is a shell chronology consisting of estimated ages of shell\n\tformation relative to the annual cycle with their uncertainties. All formulae in the package serve this\n\tpurpose, but the user can customize the model (e.g. number of days in a year and the mineralogy of the\n\tshell carbonate) through input parameters.",
    "version": "0.4.0",
    "maintainer": "Niels de Winter <niels_de_winter@live.nl>",
    "author": "Niels de Winter [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1453-5407>)",
    "url": "https://github.com/nielsjdewinter/ShellChron",
    "bug_reports": "https://github.com/nielsjdewinter/ShellChron/issues",
    "repository": "https://cran.r-project.org/package=ShellChron",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ShellChron Builds Chronologies from Oxygen Isotope Profiles in Shells Takes as input a stable oxygen isotope (d18O) profile measured in growth direction (D)\n\tthrough a shell + uncertainties in both variables (d18O_err & D_err). It then models the seasonality\n\tin the d18O record by fitting a combination of a growth and temperature sine wave to year-length chunks of\n\tthe data (see Judd et al., (2018) <doi:10.1016/j.palaeo.2017.09.034>). This modeling is carried out along a sliding window through the data and yields estimates of\n\tthe day of the year (Julian Day) and local growth rate for each data point. Uncertainties in both modeling\n\troutine and the data itself are propagated and pooled to obtain a confidence envelope around the age of\n\teach data point in the shell. The end result is a shell chronology consisting of estimated ages of shell\n\tformation relative to the annual cycle with their uncertainties. All formulae in the package serve this\n\tpurpose, but the user can customize the model (e.g. number of days in a year and the mineralogy of the\n\tshell carbonate) through input parameters.  "
  },
  {
    "id": 7272,
    "package_name": "Sie2nts",
    "title": "Sieve Methods for Non-Stationary Time Series",
    "description": "We provide functions for estimation and inference of locally-stationary time series using the sieve methods and bootstrapping procedure. In addition, it also contains functions to generate Daubechies and Coiflet wavelet by Cascade algorithm and to process data visualization.",
    "version": "0.1.0",
    "maintainer": "Xiucai Ding <xiucaiding89@gmail.com>",
    "author": "Xiucai Ding [aut, cre, cph],\n  Chen Qian [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Sie2nts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Sie2nts Sieve Methods for Non-Stationary Time Series We provide functions for estimation and inference of locally-stationary time series using the sieve methods and bootstrapping procedure. In addition, it also contains functions to generate Daubechies and Coiflet wavelet by Cascade algorithm and to process data visualization.  "
  },
  {
    "id": 7292,
    "package_name": "SimIndep",
    "title": "WISE: a Weighted Similarity Aggregation Test for Serial\nIndependence",
    "description": "A fast implementation of the weighted information similarity aggregation (WISE) \n    test for detecting serial dependence, particularly suited for high-dimensional and \n    non-Euclidean time series. Includes functions for constructing similarity matrices \n    and conducting hypothesis testing. Users can use different similarity \n    measures and define their own weighting schemes. For more details see Q Zhu, M Liu, \n    Y Han, D Zhou (2025) <doi:10.48550/arXiv.2509.05678>.",
    "version": "0.1.2",
    "maintainer": "Qihua Zhu <zhuqihua@u.nus.edu>",
    "author": "Qihua Zhu [aut, cre],\n  Mingshuo Liu [aut],\n  Yuefeng Han [aut],\n  Doudou Zhou [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SimIndep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimIndep WISE: a Weighted Similarity Aggregation Test for Serial\nIndependence A fast implementation of the weighted information similarity aggregation (WISE) \n    test for detecting serial dependence, particularly suited for high-dimensional and \n    non-Euclidean time series. Includes functions for constructing similarity matrices \n    and conducting hypothesis testing. Users can use different similarity \n    measures and define their own weighting schemes. For more details see Q Zhu, M Liu, \n    Y Han, D Zhou (2025) <doi:10.48550/arXiv.2509.05678>.  "
  },
  {
    "id": 7293,
    "package_name": "SimInf",
    "title": "A Framework for Data-Driven Stochastic Disease Spread\nSimulations",
    "description": "Provides an efficient and very flexible framework to\n    conduct data-driven epidemiological modeling in realistic large\n    scale disease spread simulations. The framework integrates\n    infection dynamics in subpopulations as continuous-time Markov\n    chains using the Gillespie stochastic simulation algorithm and\n    incorporates available data such as births, deaths and movements\n    as scheduled events at predefined time-points. Using C code for\n    the numerical solvers and 'OpenMP' (if available) to divide work\n    over multiple processors ensures high performance when simulating\n    a sample outcome. One of our design goals was to make the package\n    extendable and enable usage of the numerical solvers from other R\n    extension packages in order to facilitate complex epidemiological\n    research. The package contains template models and can be extended\n    with user-defined models. For more details see the paper by\n    Widgren, Bauer, Eriksson and Engblom (2019)\n    <doi:10.18637/jss.v091.i12>. The package also provides\n    functionality to fit models to time series data using the\n    Approximate Bayesian Computation Sequential Monte Carlo\n    ('ABC-SMC') algorithm of Toni and others (2009)\n    <doi:10.1098/rsif.2008.0172> or the Particle Markov Chain Monte\n    Carlo ('PMCMC') algorithm of 'Andrieu' and others (2010)\n    <doi:10.1111/j.1467-9868.2009.00736.x>.",
    "version": "10.1.0",
    "maintainer": "Stefan Widgren <stefan.widgren@gmail.com>",
    "author": "Stefan Widgren [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5745-2284>),\n  Robin Eriksson [aut] (ORCID: <https://orcid.org/0000-0002-4291-712X>),\n  Stefan Engblom [aut] (ORCID: <https://orcid.org/0000-0002-3614-1732>),\n  Pavol Bauer [aut] (ORCID: <https://orcid.org/0000-0003-4328-7171>),\n  Thomas Rosendal [ctb] (ORCID: <https://orcid.org/0000-0002-6576-9668>),\n  Ivana Rodriguez Ewerl\u00f6f [ctb] (ORCID:\n    <https://orcid.org/0000-0002-9678-9813>),\n  Attractive Chaos [cph] (Author of 'kvec.h'.)",
    "url": "https://github.com/stewid/SimInf, http://stewid.github.io/SimInf/",
    "bug_reports": "https://github.com/stewid/SimInf/issues",
    "repository": "https://cran.r-project.org/package=SimInf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimInf A Framework for Data-Driven Stochastic Disease Spread\nSimulations Provides an efficient and very flexible framework to\n    conduct data-driven epidemiological modeling in realistic large\n    scale disease spread simulations. The framework integrates\n    infection dynamics in subpopulations as continuous-time Markov\n    chains using the Gillespie stochastic simulation algorithm and\n    incorporates available data such as births, deaths and movements\n    as scheduled events at predefined time-points. Using C code for\n    the numerical solvers and 'OpenMP' (if available) to divide work\n    over multiple processors ensures high performance when simulating\n    a sample outcome. One of our design goals was to make the package\n    extendable and enable usage of the numerical solvers from other R\n    extension packages in order to facilitate complex epidemiological\n    research. The package contains template models and can be extended\n    with user-defined models. For more details see the paper by\n    Widgren, Bauer, Eriksson and Engblom (2019)\n    <doi:10.18637/jss.v091.i12>. The package also provides\n    functionality to fit models to time series data using the\n    Approximate Bayesian Computation Sequential Monte Carlo\n    ('ABC-SMC') algorithm of Toni and others (2009)\n    <doi:10.1098/rsif.2008.0172> or the Particle Markov Chain Monte\n    Carlo ('PMCMC') algorithm of 'Andrieu' and others (2010)\n    <doi:10.1111/j.1467-9868.2009.00736.x>.  "
  },
  {
    "id": 7323,
    "package_name": "SlidingWindows",
    "title": "Methods for Time Series Analysis",
    "description": "A collection of functions to perform Detrended Fluctuation Analysis (DFA exponent), GUEDES et al. (2019) <doi:10.1016/j.physa.2019.04.132> , Detrended cross-correlation coefficient (RHODCCA), GUEDES & ZEBENDE (2019) <doi:10.1016/j.physa.2019.121286>, DMCA cross-correlation coefficient and Detrended multiple cross-correlation coefficient (DMC), GUEDES & SILVA-FILHO & ZEBENDE (2018) <doi:10.1016/j.physa.2021.125990>, both with sliding windows approach. ",
    "version": "0.2.0",
    "maintainer": "Everaldo Freitas Guedes <efgestatistico@gmail.com>",
    "author": "Everaldo Freitas Guedes [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2986-7367>),\n  Ivan Costa da Cunha Lima [aut] (ORCID:\n    <https://orcid.org/0000-0002-4525-2346>),\n  Gilney Figueira Zebende [aut] (ORCID:\n    <https://orcid.org/0000-0003-2420-9805>),\n  Alo\u00edsio Machado Silva-Filho [aut] (ORCID:\n    <https://orcid.org/0000-0001-8250-1527>)",
    "url": "https://github.com/efguedes/SlidingWindows",
    "bug_reports": "https://github.com/efguedes/SlidingWindows",
    "repository": "https://cran.r-project.org/package=SlidingWindows",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SlidingWindows Methods for Time Series Analysis A collection of functions to perform Detrended Fluctuation Analysis (DFA exponent), GUEDES et al. (2019) <doi:10.1016/j.physa.2019.04.132> , Detrended cross-correlation coefficient (RHODCCA), GUEDES & ZEBENDE (2019) <doi:10.1016/j.physa.2019.121286>, DMCA cross-correlation coefficient and Detrended multiple cross-correlation coefficient (DMC), GUEDES & SILVA-FILHO & ZEBENDE (2018) <doi:10.1016/j.physa.2021.125990>, both with sliding windows approach.   "
  },
  {
    "id": 7366,
    "package_name": "SpTe2M",
    "title": "Nonparametric Modeling and Monitoring of Spatio-Temporal Data",
    "description": "Spatio-temporal data have become increasingly popular in many research fields. Such data often have complex structures that are difficult to describe and estimate. This package provides reliable tools for modeling complicated spatio-temporal data. It also includes tools of online process monitoring to detect possible change-points in a spatio-temporal process over time. More specifically, the package implements the spatio-temporal mean estimation procedure described in Yang and Qiu (2018) <doi:10.1002/sim.7622>, the spatio-temporal covariance estimation procedure discussed in Yang and Qiu (2019) <doi:10.1002/sim.8315>, the three-step method for the joint estimation of spatio-temporal mean and covariance functions suggested by Yang and Qiu (2022) <doi:10.1007/s10463-021-00787-2>, the spatio-temporal disease surveillance method discussed in Qiu and Yang (2021) <doi:10.1002/sim.9150> that can accommodate the covariate effect, the spatial-LASSO-based process monitoring method proposed by Qiu and Yang (2023) <doi:10.1080/00224065.2022.2081104>, and the online spatio-temporal disease surveillance method described in Yang and Qiu (2020) <doi:10.1080/24725854.2019.1696496>.",
    "version": "1.0.3",
    "maintainer": "Kai Yang <kayang@mcw.edu>",
    "author": "Kai Yang [aut, cre],\n  Peihua Qiu [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpTe2M",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpTe2M Nonparametric Modeling and Monitoring of Spatio-Temporal Data Spatio-temporal data have become increasingly popular in many research fields. Such data often have complex structures that are difficult to describe and estimate. This package provides reliable tools for modeling complicated spatio-temporal data. It also includes tools of online process monitoring to detect possible change-points in a spatio-temporal process over time. More specifically, the package implements the spatio-temporal mean estimation procedure described in Yang and Qiu (2018) <doi:10.1002/sim.7622>, the spatio-temporal covariance estimation procedure discussed in Yang and Qiu (2019) <doi:10.1002/sim.8315>, the three-step method for the joint estimation of spatio-temporal mean and covariance functions suggested by Yang and Qiu (2022) <doi:10.1007/s10463-021-00787-2>, the spatio-temporal disease surveillance method discussed in Qiu and Yang (2021) <doi:10.1002/sim.9150> that can accommodate the covariate effect, the spatial-LASSO-based process monitoring method proposed by Qiu and Yang (2023) <doi:10.1080/00224065.2022.2081104>, and the online spatio-temporal disease surveillance method described in Yang and Qiu (2020) <doi:10.1080/24725854.2019.1696496>.  "
  },
  {
    "id": 7370,
    "package_name": "SpaDES.core",
    "title": "Core Utilities for Developing and Running Spatially Explicit\nDiscrete Event Models",
    "description": "Provides the core framework for a discrete event system to \n    implement a complete data-to-decisions, reproducible workflow.\n    The core components facilitate the development of modular pieces, \n    and enable the user to include additional functionality by running user-built modules.\n    Includes conditional scheduling, restart after interruption, packaging of\n    reusable modules, tools for developing arbitrary automated workflows,\n    automated interweaving of modules of different temporal resolution,\n    and tools for visualizing and understanding the within-project dependencies. \n    The suggested package 'NLMR' can be installed from the repository \n    (<https://PredictiveEcology.r-universe.dev>).",
    "version": "2.1.8",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "author": "Alex M Chubaty [aut] (ORCID: <https://orcid.org/0000-0001-7146-8135>),\n  Eliot J B McIntire [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6914-8316>),\n  Yong Luo [ctb],\n  Steve Cumming [ctb],\n  Ceres Barros [ctb] (ORCID: <https://orcid.org/0000-0003-4036-977X>),\n  His Majesty the King in Right of Canada, as represented by the Minister\n    of Natural Resources Canada [cph]",
    "url": "https://spades-core.predictiveecology.org/,\nhttps://github.com/PredictiveEcology/SpaDES.core",
    "bug_reports": "https://github.com/PredictiveEcology/SpaDES.core/issues",
    "repository": "https://cran.r-project.org/package=SpaDES.core",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpaDES.core Core Utilities for Developing and Running Spatially Explicit\nDiscrete Event Models Provides the core framework for a discrete event system to \n    implement a complete data-to-decisions, reproducible workflow.\n    The core components facilitate the development of modular pieces, \n    and enable the user to include additional functionality by running user-built modules.\n    Includes conditional scheduling, restart after interruption, packaging of\n    reusable modules, tools for developing arbitrary automated workflows,\n    automated interweaving of modules of different temporal resolution,\n    and tools for visualizing and understanding the within-project dependencies. \n    The suggested package 'NLMR' can be installed from the repository \n    (<https://PredictiveEcology.r-universe.dev>).  "
  },
  {
    "id": 7373,
    "package_name": "SpaceTimeBSS",
    "title": "Blind Source Separation for Multivariate Spatio-Temporal Data",
    "description": "Simultaneous/joint diagonalization of local autocovariance matrices to estimate spatio-temporally uncorrelated random fields. ",
    "version": "0.4-0",
    "maintainer": "Klaus Nordhausen <klausnordhausenR@gmail.com>",
    "author": "Christoph Muehlmann [aut] (ORCID:\n    <https://orcid.org/0000-0001-7330-8434>),\n  Nikolaus Piccolotto [aut] (ORCID:\n    <https://orcid.org/0000-0001-6876-6502>),\n  Claudia Cappello [aut] (ORCID: <https://orcid.org/0000-0002-7905-5068>),\n  Sandra De Iaco [aut] (ORCID: <https://orcid.org/0000-0003-1820-2068>),\n  Klaus Nordhausen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3758-8501>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpaceTimeBSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpaceTimeBSS Blind Source Separation for Multivariate Spatio-Temporal Data Simultaneous/joint diagonalization of local autocovariance matrices to estimate spatio-temporally uncorrelated random fields.   "
  },
  {
    "id": 7408,
    "package_name": "SpatialVx",
    "title": "Spatial Forecast Verification",
    "description": "Spatial forecast verification refers to verifying weather forecasts when the verification set (forecast and observations) is on a spatial field, usually a high-resolution gridded spatial field.  Most of the functions here require the forecast and observed fields to be gridded and on the same grid. For a thorough review of most of the methods in this package, please see Gilleland et al. (2009) <doi: 10.1175/2009WAF2222269.1> and for a tutorial on some of the main functions available here, see Gilleland (2022) <doi: 10.5065/4px3-5a05>. ",
    "version": "1.0-3",
    "maintainer": "Eric Gilleland <eric.gilleland@colostate.edu>",
    "author": "Eric Gilleland [aut, cre],\n  Kim Elmore [ctb],\n  Caren Marzban [ctb],\n  Matt Pocernich [ctb],\n  Gregor Skok [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpatialVx",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpatialVx Spatial Forecast Verification Spatial forecast verification refers to verifying weather forecasts when the verification set (forecast and observations) is on a spatial field, usually a high-resolution gridded spatial field.  Most of the functions here require the forecast and observed fields to be gridded and on the same grid. For a thorough review of most of the methods in this package, please see Gilleland et al. (2009) <doi: 10.1175/2009WAF2222269.1> and for a tutorial on some of the main functions available here, see Gilleland (2022) <doi: 10.5065/4px3-5a05>.   "
  },
  {
    "id": 7413,
    "package_name": "SpecsVerification",
    "title": "Forecast Verification Routines for Ensemble Forecasts of Weather\nand Climate",
    "description": "A collection of forecast verification routines developed for the SPECS\n    FP7 project. The emphasis is on comparative verification of ensemble forecasts of weather and climate.",
    "version": "0.5-3",
    "maintainer": "Stefan Siegert <s.siegert@exeter.ac.uk>",
    "author": "Stefan Siegert [aut, cre],\n  Jonas Bhend [ctb],\n  Igor Kroener [ctb],\n  Matteo De Felice [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpecsVerification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpecsVerification Forecast Verification Routines for Ensemble Forecasts of Weather\nand Climate A collection of forecast verification routines developed for the SPECS\n    FP7 project. The emphasis is on comparative verification of ensemble forecasts of weather and climate.  "
  },
  {
    "id": 7421,
    "package_name": "Spillover",
    "title": "Spillover/Connectedness Index Based on VAR Modelling",
    "description": "A user-friendly tool for estimating both total and directional connectedness spillovers based on Diebold and Yilmaz (2009, 2012). It also provides the user with rolling estimation for total and net indices. User can find both orthogonalized and generalized versions for each kind of measures. See Diebold and Yilmaz (2009, 2012) find them at  <doi:10.1111/j.1468-0297.2008.02208.x> and <doi:10.1016/j.ijforecast.2011.02.006>.",
    "version": "0.1.1",
    "maintainer": "Jilber Urbina <JilberUrbina@gmail.com>",
    "author": "Jilber Urbina",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Spillover",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Spillover Spillover/Connectedness Index Based on VAR Modelling A user-friendly tool for estimating both total and directional connectedness spillovers based on Diebold and Yilmaz (2009, 2012). It also provides the user with rolling estimation for total and net indices. User can find both orthogonalized and generalized versions for each kind of measures. See Diebold and Yilmaz (2009, 2012) find them at  <doi:10.1111/j.1468-0297.2008.02208.x> and <doi:10.1016/j.ijforecast.2011.02.006>.  "
  },
  {
    "id": 7453,
    "package_name": "StatPerMeCo",
    "title": "Statistical Performance Measures to Evaluate Covariance Matrix\nEstimates",
    "description": "Statistical performance measures used in the econometric literature to evaluate conditional covariance/correlation matrix estimates (MSE, MAE, Euclidean distance, Frobenius distance, Stein distance, asymmetric loss function, eigenvalue loss function and the loss function defined in Eq. (4.6) of Engle et al. (2016) <doi:10.2139/ssrn.2814555>). Additionally, compute Eq. (3.1) and (4.2) of Li et al. (2016) <doi:10.1080/07350015.2015.1092975> to compare the factor loading matrix. The statistical performance measures implemented have been previously used in, for instance, Laurent et al. (2012) <doi:10.1002/jae.1248>,  Amendola et al. (2015) <doi:10.1002/for.2322> and  Becker et al. (2015) <doi:10.1016/j.ijforecast.2013.11.007>.",
    "version": "0.1.0",
    "maintainer": "Carlos Trucios <ctrucios@gmail.com>",
    "author": "Carlos Trucios",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StatPerMeCo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StatPerMeCo Statistical Performance Measures to Evaluate Covariance Matrix\nEstimates Statistical performance measures used in the econometric literature to evaluate conditional covariance/correlation matrix estimates (MSE, MAE, Euclidean distance, Frobenius distance, Stein distance, asymmetric loss function, eigenvalue loss function and the loss function defined in Eq. (4.6) of Engle et al. (2016) <doi:10.2139/ssrn.2814555>). Additionally, compute Eq. (3.1) and (4.2) of Li et al. (2016) <doi:10.1080/07350015.2015.1092975> to compare the factor loading matrix. The statistical performance measures implemented have been previously used in, for instance, Laurent et al. (2012) <doi:10.1002/jae.1248>,  Amendola et al. (2015) <doi:10.1002/for.2322> and  Becker et al. (2015) <doi:10.1016/j.ijforecast.2013.11.007>.  "
  },
  {
    "id": 7463,
    "package_name": "StempCens",
    "title": "Spatio-Temporal Estimation and Prediction for Censored/Missing\nResponses",
    "description": "It estimates the parameters of spatio-temporal models with censored or missing data using the SAEM algorithm (Delyon et al., 1999). This algorithm is a stochastic approximation of the widely used EM algorithm and is particularly valuable for models in which the E-step lacks a closed-form expression. It also provides a function to compute the observed information matrix using the method developed by Louis (1982). To assess the performance of the fitted model, case-deletion diagnostics are provided.",
    "version": "1.2.0",
    "maintainer": "Larissa A. Matos <larissa.amatos@gmail.com>",
    "author": "Larissa A. Matos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2635-0901>),\n  Katherine L. Valeriano [aut] (ORCID:\n    <https://orcid.org/0000-0001-6388-4753>),\n  Victor H. Lachos [ctb] (ORCID: <https://orcid.org/0000-0002-7239-2459>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StempCens",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StempCens Spatio-Temporal Estimation and Prediction for Censored/Missing\nResponses It estimates the parameters of spatio-temporal models with censored or missing data using the SAEM algorithm (Delyon et al., 1999). This algorithm is a stochastic approximation of the widely used EM algorithm and is particularly valuable for models in which the E-step lacks a closed-form expression. It also provides a function to compute the observed information matrix using the method developed by Louis (1982). To assess the performance of the fitted model, case-deletion diagnostics are provided.  "
  },
  {
    "id": 7473,
    "package_name": "StochBlock",
    "title": "Stochastic Blockmodeling of One-Mode and Linked Networks",
    "description": "Stochastic blockmodeling of one-mode and linked networks as presented in \u0160kulj and \u017diberna (2022) <doi:10.1016/j.socnet.2022.02.001>. The optimization is done via CEM (Classification Expectation Maximization) algorithm that can be initialized by random partitions or the results of k-means algorithm. The development of this package is financially supported by the Slovenian Research Agency (<https://www.arrs.si/>) within the research programs P5-0168 and the research projects J7-8279 (Blockmodeling multilevel and temporal networks) and J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).",
    "version": "0.1.5",
    "maintainer": "Ale\u0161 \u017diberna <ales.ziberna@fdv.uni-lj.si>",
    "author": "Ale\u0161 \u017diberna [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1534-6971>),\n  Fabio Ashtar Telarico [ctb] (ORCID:\n    <https://orcid.org/0000-0002-8740-7078>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StochBlock",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StochBlock Stochastic Blockmodeling of One-Mode and Linked Networks Stochastic blockmodeling of one-mode and linked networks as presented in \u0160kulj and \u017diberna (2022) <doi:10.1016/j.socnet.2022.02.001>. The optimization is done via CEM (Classification Expectation Maximization) algorithm that can be initialized by random partitions or the results of k-means algorithm. The development of this package is financially supported by the Slovenian Research Agency (<https://www.arrs.si/>) within the research programs P5-0168 and the research projects J7-8279 (Blockmodeling multilevel and temporal networks) and J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).  "
  },
  {
    "id": 7492,
    "package_name": "StructuralDecompose",
    "title": "Decomposes a Level Shifted Time Series",
    "description": "Explains the behavior of a time series by decomposing it into its trend, seasonality and residuals. \n             It is built to perform very well in the presence of significant level shifts. It is designed to play \n             well with any breakpoint algorithm and any smoothing algorithm. Currently defaults to 'lowess' for smoothing\n             and 'strucchange' for breakpoint identification. The package is useful in areas such as trend analysis, time series \n             decomposition, breakpoint identification and anomaly detection.",
    "version": "0.1.1",
    "maintainer": "Allen Sunny <allensunny1242@gmail.com>",
    "author": "Allen Sunny [aut, cre]",
    "url": "https://allen-1242.github.io/StructuralDecompose/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StructuralDecompose",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StructuralDecompose Decomposes a Level Shifted Time Series Explains the behavior of a time series by decomposing it into its trend, seasonality and residuals. \n             It is built to perform very well in the presence of significant level shifts. It is designed to play \n             well with any breakpoint algorithm and any smoothing algorithm. Currently defaults to 'lowess' for smoothing\n             and 'strucchange' for breakpoint identification. The package is useful in areas such as trend analysis, time series \n             decomposition, breakpoint identification and anomaly detection.  "
  },
  {
    "id": 7508,
    "package_name": "SunsVoc",
    "title": "Constructing Suns-Voc from Outdoor Time-Series I-V Curves",
    "description": "\n    Suns-Voc (or Isc-Voc) curves can provide the current-voltage (I-V) characteristics of the\n    diode of photovoltaic cells without the effect of series resistance.\n    Here, Suns-Voc curves can be constructed with outdoor time-series I-V\n    curves [1,2,3] of full-size photovoltaic (PV) modules instead of having to be measured in the lab.\n    Time series of four different power loss modes can be calculated based on obtained Isc-Voc curves.\n    This material is based upon work supported by the U.S. Department of\n    Energy's Office of Energy Efficiency and Renewable Energy (EERE) under\n    Solar Energy Technologies Office (SETO) Agreement Number DE-EE0008172. \n    Jennifer L. Braid is supported by the U.S. Department of Energy (DOE) Office of \n    Energy Efficiency and Renewable Energy administered by the Oak Ridge \n    Institute for Science and Education (ORISE) for the DOE. \n    ORISE is managed by Oak Ridge Associated Universities (ORAU) under DOE\n    contract number DE-SC0014664. \n    [1] Wang, M. et al, 2018. \n    <doi:10.1109/PVSC.2018.8547772>. \n    [2] Walters et al, 2018\n    <doi:10.1109/PVSC.2018.8548187>. \n    [3] Guo, S. et al, 2016. \n    <doi:10.1117/12.2236939>. ",
    "version": "0.1.2",
    "maintainer": "Tyler J. Burleyson <tjb152@case.edu>",
    "author": "Menghong Wang [aut] (ORCID: <https://orcid.org/0000-0001-7349-699X>),\n  Tyler J. Burleyson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6356-5354>),\n  Jiqi Liu [aut] (ORCID: <https://orcid.org/0000-0003-2016-4160>),\n  Alan J. Curran [aut] (ORCID: <https://orcid.org/0000-0002-4505-8359>),\n  Abdulkerim Gok [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-3433-7106>),\n  Eric J. Schneller [aut] (ORCID:\n    <https://orcid.org/0000-0002-2104-0066>),\n  Kristopher O. Davis [aut] (ORCID:\n    <https://orcid.org/0000-0002-5772-6254>),\n  Jennifer L. Braid [aut] (ORCID:\n    <https://orcid.org/0000-0002-0677-7756>),\n  Roger H. French [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-6162-0532>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SunsVoc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SunsVoc Constructing Suns-Voc from Outdoor Time-Series I-V Curves \n    Suns-Voc (or Isc-Voc) curves can provide the current-voltage (I-V) characteristics of the\n    diode of photovoltaic cells without the effect of series resistance.\n    Here, Suns-Voc curves can be constructed with outdoor time-series I-V\n    curves [1,2,3] of full-size photovoltaic (PV) modules instead of having to be measured in the lab.\n    Time series of four different power loss modes can be calculated based on obtained Isc-Voc curves.\n    This material is based upon work supported by the U.S. Department of\n    Energy's Office of Energy Efficiency and Renewable Energy (EERE) under\n    Solar Energy Technologies Office (SETO) Agreement Number DE-EE0008172. \n    Jennifer L. Braid is supported by the U.S. Department of Energy (DOE) Office of \n    Energy Efficiency and Renewable Energy administered by the Oak Ridge \n    Institute for Science and Education (ORISE) for the DOE. \n    ORISE is managed by Oak Ridge Associated Universities (ORAU) under DOE\n    contract number DE-SC0014664. \n    [1] Wang, M. et al, 2018. \n    <doi:10.1109/PVSC.2018.8547772>. \n    [2] Walters et al, 2018\n    <doi:10.1109/PVSC.2018.8548187>. \n    [3] Guo, S. et al, 2016. \n    <doi:10.1117/12.2236939>.   "
  },
  {
    "id": 7511,
    "package_name": "SuperGauss",
    "title": "Superfast Likelihood Inference for Stationary Gaussian Time\nSeries",
    "description": "Likelihood evaluations for stationary Gaussian time series are typically obtained via the Durbin-Levinson algorithm, which scales as O(n^2) in the number of time series observations.  This package provides a \"superfast\" O(n log^2 n) algorithm written in C++, crossing over with Durbin-Levinson around n = 300.  Efficient implementations of the score and Hessian functions are also provided, leading to superfast versions of inference algorithms such as Newton-Raphson and Hamiltonian Monte Carlo.  The C++ code provides a Toeplitz matrix class packaged as a header-only library, to simplify low-level usage in other packages and outside of R.",
    "version": "2.0.4",
    "maintainer": "Martin Lysy <mlysy@uwaterloo.ca>",
    "author": "Yun Ling [aut],\n  Martin Lysy [aut, cre]",
    "url": "https://github.com/mlysy/SuperGauss",
    "bug_reports": "https://github.com/mlysy/SuperGauss/issues",
    "repository": "https://cran.r-project.org/package=SuperGauss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SuperGauss Superfast Likelihood Inference for Stationary Gaussian Time\nSeries Likelihood evaluations for stationary Gaussian time series are typically obtained via the Durbin-Levinson algorithm, which scales as O(n^2) in the number of time series observations.  This package provides a \"superfast\" O(n log^2 n) algorithm written in C++, crossing over with Durbin-Levinson around n = 300.  Efficient implementations of the score and Hessian functions are also provided, leading to superfast versions of inference algorithms such as Newton-Raphson and Hamiltonian Monte Carlo.  The C++ code provides a Toeplitz matrix class packaged as a header-only library, to simplify low-level usage in other packages and outside of R.  "
  },
  {
    "id": 7556,
    "package_name": "SyncMove",
    "title": "Subsample Temporal Data to Synchronal Events and Compute the MCI",
    "description": "The function 'syncSubsample' subsamples temporal data of different entities so that the result only contains synchronal events. The function 'mci' calculates the Movement Coordination Index (MCI, see reference on help page for function 'mci') of a data set created with the function 'syncSubsample'.",
    "version": "0.1-0",
    "maintainer": "Martin Rimmler <martin.rimmler@gmail.com>",
    "author": "Martin Rimmler [aut, cre],\n  Thomas Mueller [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SyncMove",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SyncMove Subsample Temporal Data to Synchronal Events and Compute the MCI The function 'syncSubsample' subsamples temporal data of different entities so that the result only contains synchronal events. The function 'mci' calculates the Movement Coordination Index (MCI, see reference on help page for function 'mci') of a data set created with the function 'syncSubsample'.  "
  },
  {
    "id": 7576,
    "package_name": "TAR",
    "title": "Bayesian Modeling of Autoregressive Threshold Time Series Models",
    "description": "Identification and estimation of the autoregressive threshold models with Gaussian noise, as well as positive-valued time series. The package provides the identification of the number of regimes, the thresholds and the autoregressive orders, as well as the estimation of remain parameters. The package implements the methodology from the 2005 paper: Modeling Bivariate Threshold Autoregressive Processes in the Presence of Missing Data <DOI:10.1081/STA-200054435>.",
    "version": "1.0",
    "maintainer": "Hanwen Zhang <hanwengutierrez@gmail.com>",
    "author": "Hanwen Zhang, Fabio H. Nieto",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TAR Bayesian Modeling of Autoregressive Threshold Time Series Models Identification and estimation of the autoregressive threshold models with Gaussian noise, as well as positive-valued time series. The package provides the identification of the number of regimes, the thresholds and the autoregressive orders, as well as the estimation of remain parameters. The package implements the methodology from the 2005 paper: Modeling Bivariate Threshold Autoregressive Processes in the Presence of Missing Data <DOI:10.1081/STA-200054435>.  "
  },
  {
    "id": 7585,
    "package_name": "TCHazaRds",
    "title": "Tropical Cyclone (Hurricane, Typhoon) Spatial Hazard Modelling",
    "description": "Methods for generating modelled parametric Tropical Cyclone (TC) spatial hazard fields and time series output at point locations from TC tracks.  R's compatibility to simply use fast 'cpp' code via the 'Rcpp' package and the wide range spatial analysis tools via the 'terra' package makes it an attractive open source environment to study 'TCs'.  This package estimates TC vortex wind and pressure fields using parametric equations originally coded up in 'python' by 'TCRM' <https://github.com/GeoscienceAustralia/tcrm> and then coded up in 'Cuda' 'cpp' by 'TCwindgen' <https://github.com/CyprienBosserelle/TCwindgen>.",
    "version": "1.1.5",
    "maintainer": "Julian O'Grady <julian.ogrady@csiro.au>",
    "author": "Julian O'Grady [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3552-9193>)",
    "url": "https://github.com/AusClimateService/TCHazaRds",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TCHazaRds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TCHazaRds Tropical Cyclone (Hurricane, Typhoon) Spatial Hazard Modelling Methods for generating modelled parametric Tropical Cyclone (TC) spatial hazard fields and time series output at point locations from TC tracks.  R's compatibility to simply use fast 'cpp' code via the 'Rcpp' package and the wide range spatial analysis tools via the 'terra' package makes it an attractive open source environment to study 'TCs'.  This package estimates TC vortex wind and pressure fields using parametric equations originally coded up in 'python' by 'TCRM' <https://github.com/GeoscienceAustralia/tcrm> and then coded up in 'Cuda' 'cpp' by 'TCwindgen' <https://github.com/CyprienBosserelle/TCwindgen>.  "
  },
  {
    "id": 7587,
    "package_name": "TCIU",
    "title": "Spacekime Analytics, Time Complexity and Inferential Uncertainty",
    "description": "Provide the core functionality to transform longitudinal data to\n    complex-time (kime) data using analytic and numerical techniques, visualize the original \n    time-series and reconstructed kime-surfaces, perform model based (e.g., tensor-linear regression)\n    and model-free classification and clustering methods in the book Dinov, ID and Velev, MV. (2021)\n    \"Data Science: Time Complexity, Inferential Uncertainty, and Spacekime Analytics\", De Gruyter STEM Series,\n    ISBN 978-3-11-069780-3. <https://www.degruyter.com/view/title/576646>.\n    The package includes 18 core functions which can be separated into three groups.\n    1) draw longitudinal data, such as Functional magnetic resonance imaging(fMRI) time-series, and forecast or transform the time-series data.\n    2) simulate real-valued time-series data, e.g., fMRI time-courses, detect the activated areas,\n    report the corresponding p-values, and visualize the p-values in the 3D brain space.\n    3) Laplace transform and kimesurface reconstructions of the fMRI data.",
    "version": "1.2.7",
    "maintainer": "Yueyang Shen <petersyy@umich.edu>",
    "author": "Yongkai Qiu [aut],\n  Zhe Yin [aut],\n  Jinwen Cao [aut],\n  Yupeng Zhang [aut],\n  Yuyao Liu [aut],\n  Rongqian Zhang [aut],\n  Yueyang Shen [aut, cre],\n  Rouben Rostamian [ctb],\n  Ranjan Maitra [ctb],\n  Daniel Rowe [ctb],\n  Daniel Adrian [ctb] (gLRT method for complex-valued fMRI statistics),\n  Yunjie Guo [aut],\n  Ivo Dinov [aut]",
    "url": "https://github.com/SOCR/TCIU,\nhttps://www.socr.umich.edu/spacekime/,\nhttps://www.socr.umich.edu/TCIU/",
    "bug_reports": "https://github.com/SOCR/TCIU/issues",
    "repository": "https://cran.r-project.org/package=TCIU",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TCIU Spacekime Analytics, Time Complexity and Inferential Uncertainty Provide the core functionality to transform longitudinal data to\n    complex-time (kime) data using analytic and numerical techniques, visualize the original \n    time-series and reconstructed kime-surfaces, perform model based (e.g., tensor-linear regression)\n    and model-free classification and clustering methods in the book Dinov, ID and Velev, MV. (2021)\n    \"Data Science: Time Complexity, Inferential Uncertainty, and Spacekime Analytics\", De Gruyter STEM Series,\n    ISBN 978-3-11-069780-3. <https://www.degruyter.com/view/title/576646>.\n    The package includes 18 core functions which can be separated into three groups.\n    1) draw longitudinal data, such as Functional magnetic resonance imaging(fMRI) time-series, and forecast or transform the time-series data.\n    2) simulate real-valued time-series data, e.g., fMRI time-courses, detect the activated areas,\n    report the corresponding p-values, and visualize the p-values in the 3D brain space.\n    3) Laplace transform and kimesurface reconstructions of the fMRI data.  "
  },
  {
    "id": 7595,
    "package_name": "TDCor",
    "title": "Gene Network Inference from Time-Series Transcriptomic Data",
    "description": "The Time-Delay Correlation algorithm (TDCor) reconstructs the topology of a gene regulatory network (GRN) from time-series transcriptomic data.  The algorithm is described in details in Lavenus et al., Plant Cell, 2015.  It was initially developed to infer the topology of the GRN controlling lateral root formation in Arabidopsis thaliana.  The time-series transcriptomic dataset which was used in this study is included in the package to illustrate how to use it.",
    "version": "0.1-2",
    "maintainer": "Mikael Lucas <mikael.lucas@ird.fr>",
    "author": "Julien Lavenus",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TDCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TDCor Gene Network Inference from Time-Series Transcriptomic Data The Time-Delay Correlation algorithm (TDCor) reconstructs the topology of a gene regulatory network (GRN) from time-series transcriptomic data.  The algorithm is described in details in Lavenus et al., Plant Cell, 2015.  It was initially developed to infer the topology of the GRN controlling lateral root formation in Arabidopsis thaliana.  The time-series transcriptomic dataset which was used in this study is included in the package to illustrate how to use it.  "
  },
  {
    "id": 7599,
    "package_name": "TDSTNN",
    "title": "Time Delay Spatio Temporal Neural Network",
    "description": "STARMA (Space-Time Autoregressive Moving Average) models are commonly utilized in modeling and forecasting spatiotemporal time series data. However, the intricate nonlinear dynamics observed in many space-time rainfall patterns often exceed the capabilities of conventional STARMA models. This R package enables the fitting of Time Delay Spatio-Temporal Neural Networks, which are adept at handling such complex nonlinear dynamics efficiently. For detailed methodology, please refer to Saha et al. (2020) <doi:10.1007/s00704-020-03374-2>.",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Mrinmoy Ray [aut, cre],\n  Rajeev Ranjan Kumar [aut, ctb],\n  Kanchan Sinha [aut, ctb],\n  K. N. Singh [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TDSTNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TDSTNN Time Delay Spatio Temporal Neural Network STARMA (Space-Time Autoregressive Moving Average) models are commonly utilized in modeling and forecasting spatiotemporal time series data. However, the intricate nonlinear dynamics observed in many space-time rainfall patterns often exceed the capabilities of conventional STARMA models. This R package enables the fitting of Time Delay Spatio-Temporal Neural Networks, which are adept at handling such complex nonlinear dynamics efficiently. For detailed methodology, please refer to Saha et al. (2020) <doi:10.1007/s00704-020-03374-2>.  "
  },
  {
    "id": 7611,
    "package_name": "TGS",
    "title": "Rapid Reconstruction of Time-Varying Gene Regulatory Networks",
    "description": "Rapid advancements in high-throughput gene sequencing\n    technologies have resulted in genome-scale time-series datasets. \n    Uncovering the underlying temporal sequence of gene regulatory events \n    in the form of time-varying gene regulatory networks demands \n    accurate and computationally efficient algorithms. Such an\n    algorithm is 'TGS'. It is proposed in Saptarshi Pyne, Alok Ranjan \n    Kumar, and Ashish Anand. Rapid reconstruction of time-varying \n    gene regulatory networks. IEEE/ACM Transactions on Computational \n    Biology and Bioinformatics, 17(1):278{291, Jan-Feb 2020. The TGS \n    algorithm is shown to consume only 29 minutes for a microarray \n    dataset with 4028 genes. This package provides an implementation \n    of the TGS algorithm and its variants.",
    "version": "1.0.1",
    "maintainer": "Saptarshi Pyne <saptarshipyne01@gmail.com>",
    "author": "Saptarshi Pyne [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9710-6749>),\n  Manan Gupta [aut],\n  Alok Kumar [aut],\n  Ashish Anand [aut] (ORCID: <https://orcid.org/0000-0002-0024-3358>)",
    "url": "https://www.biorxiv.org/content/early/2018/06/14/272484,\nhttps://github.com/sap01/TGS",
    "bug_reports": "https://github.com/sap01/TGS/issues",
    "repository": "https://cran.r-project.org/package=TGS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TGS Rapid Reconstruction of Time-Varying Gene Regulatory Networks Rapid advancements in high-throughput gene sequencing\n    technologies have resulted in genome-scale time-series datasets. \n    Uncovering the underlying temporal sequence of gene regulatory events \n    in the form of time-varying gene regulatory networks demands \n    accurate and computationally efficient algorithms. Such an\n    algorithm is 'TGS'. It is proposed in Saptarshi Pyne, Alok Ranjan \n    Kumar, and Ashish Anand. Rapid reconstruction of time-varying \n    gene regulatory networks. IEEE/ACM Transactions on Computational \n    Biology and Bioinformatics, 17(1):278{291, Jan-Feb 2020. The TGS \n    algorithm is shown to consume only 29 minutes for a microarray \n    dataset with 4028 genes. This package provides an implementation \n    of the TGS algorithm and its variants.  "
  },
  {
    "id": 7614,
    "package_name": "THETASVM",
    "title": "Time Series Forecasting using THETA-SVM Hybrid Model",
    "description": "Testing, Implementation, and Forecasting of the THETA-SVM hybrid model. The THETA-SVM hybrid model combines the distinct strengths of the THETA model and the Support Vector Machine (SVM) model for time series forecasting.For method details see Bhattacharyya et al. (2022) <doi:10.1007/s11071-021-07099-3>.",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Fasila K. P. [aut, ctb],\n  Mrinmoy Ray [aut, cre],\n  Rajeev Ranjan Kumar [aut, ctb],\n  K. N. Singh [aut, ctb],\n  Amrender Kumar [aut, ctb],\n  Santosha Rathod [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=THETASVM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "THETASVM Time Series Forecasting using THETA-SVM Hybrid Model Testing, Implementation, and Forecasting of the THETA-SVM hybrid model. The THETA-SVM hybrid model combines the distinct strengths of the THETA model and the Support Vector Machine (SVM) model for time series forecasting.For method details see Bhattacharyya et al. (2022) <doi:10.1007/s11071-021-07099-3>.  "
  },
  {
    "id": 7627,
    "package_name": "TNC",
    "title": "Temporal Network Centrality (TNC) Measures",
    "description": "Node centrality measures for temporal networks. Available measures are temporal degree centrality, temporal closeness centrality and temporal betweenness centrality defined by Kim and Anderson (2012) <doi:10.1103/PhysRevE.85.026107>. Applying the REN algorithm by Hanke and Foraita (2017) <doi:10.1186/s12859-017-1677-x> when calculating the centrality measures keeps the computational running time linear in the number of graph snapshots. Further, all methods can run in parallel up to the number of nodes in the network.",
    "version": "0.1.0",
    "maintainer": "Moritz Hanke <hanke@leibniz-bips.de>",
    "author": "Moritz Hanke [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TNC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TNC Temporal Network Centrality (TNC) Measures Node centrality measures for temporal networks. Available measures are temporal degree centrality, temporal closeness centrality and temporal betweenness centrality defined by Kim and Anderson (2012) <doi:10.1103/PhysRevE.85.026107>. Applying the REN algorithm by Hanke and Foraita (2017) <doi:10.1186/s12859-017-1677-x> when calculating the centrality measures keeps the computational running time linear in the number of graph snapshots. Further, all methods can run in parallel up to the number of nodes in the network.  "
  },
  {
    "id": 7652,
    "package_name": "TSA",
    "title": "Time Series Analysis",
    "description": "Contains R functions and datasets detailed in the book\n        \"Time Series Analysis with Applications in R (second edition)\" by Jonathan Cryer and Kung-Sik Chan.",
    "version": "1.3.1",
    "maintainer": "Kung-Sik Chan <kungsik.chan@gmail.com>",
    "author": "Kung-Sik Chan, Brian Ripley ",
    "url": "https://stat.uiowa.edu/~kchan/TSA.htm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSA Time Series Analysis Contains R functions and datasets detailed in the book\n        \"Time Series Analysis with Applications in R (second edition)\" by Jonathan Cryer and Kung-Sik Chan.  "
  },
  {
    "id": 7653,
    "package_name": "TSANN",
    "title": "Time Series Artificial Neural Network",
    "description": "The best ANN structure for time series data analysis is a demanding need in the present era.\n    This package will find the best-fitted ANN model based on forecasting accuracy.\n    The optimum size of the hidden layers was also determined after determining the number of lags to be included.\n    This package has been developed using the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.",
    "version": "0.1.0",
    "maintainer": "Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Md Yeasin [aut, cre],\n  Ranjit Kumar Paul [aut],\n  Dipro Sinha [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSANN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSANN Time Series Artificial Neural Network The best ANN structure for time series data analysis is a demanding need in the present era.\n    This package will find the best-fitted ANN model based on forecasting accuracy.\n    The optimum size of the hidden layers was also determined after determining the number of lags to be included.\n    This package has been developed using the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.  "
  },
  {
    "id": 7655,
    "package_name": "TSCS",
    "title": "Time Series Cointegrated System",
    "description": "A set of functions to implement Time Series Cointegrated System (TSCS)\n    spatial interpolation and relevant data visualization.",
    "version": "0.1.1",
    "maintainer": "Tianjian Yang <yangtj5@mail2.sysu.edu.cn>",
    "author": "Tianjian Yang [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSCS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSCS Time Series Cointegrated System A set of functions to implement Time Series Cointegrated System (TSCS)\n    spatial interpolation and relevant data visualization.  "
  },
  {
    "id": 7659,
    "package_name": "TSEAL",
    "title": "Time Series Analysis Library",
    "description": "The library allows to perform a multivariate time series\n    classification based on the use of Discrete Wavelet Transform for\n    feature extraction, a step wise discriminant to select the most\n    relevant features and finally, the use of a linear or quadratic\n    discriminant for classification. Note that all these steps can be done\n    separately which allows to implement new steps.  Velasco, I., Sipols,\n    A., de Blas, C. S., Pastor, L., & Bayona, S. (2023)\n    <doi:10.1186/S12938-023-01079-X>.  Percival, D. B., & Walden, A. T.\n    (2000,ISBN:0521640687).  Maharaj, E. A., & Alonso, A. M. (2014)\n    <doi:10.1016/j.csda.2013.09.006>.",
    "version": "0.1.3",
    "maintainer": "Iv\u00e1n Velasco <ivan.velasco@urjc.es>",
    "author": "Iv\u00e1n Velasco [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2314-5670>)",
    "url": "https://github.com/vg-lab/TSEAL",
    "bug_reports": "https://github.com/vg-lab/TSEAL/issues",
    "repository": "https://cran.r-project.org/package=TSEAL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSEAL Time Series Analysis Library The library allows to perform a multivariate time series\n    classification based on the use of Discrete Wavelet Transform for\n    feature extraction, a step wise discriminant to select the most\n    relevant features and finally, the use of a linear or quadratic\n    discriminant for classification. Note that all these steps can be done\n    separately which allows to implement new steps.  Velasco, I., Sipols,\n    A., de Blas, C. S., Pastor, L., & Bayona, S. (2023)\n    <doi:10.1186/S12938-023-01079-X>.  Percival, D. B., & Walden, A. T.\n    (2000,ISBN:0521640687).  Maharaj, E. A., & Alonso, A. M. (2014)\n    <doi:10.1016/j.csda.2013.09.006>.  "
  },
  {
    "id": 7661,
    "package_name": "TSEntropies",
    "title": "Time Series Entropies",
    "description": "Computes various entropies of given time series. This is the initial version that includes ApEn() and SampEn() functions for calculating approximate entropy and sample entropy. Approximate entropy was proposed by S.M. Pincus in \"Approximate entropy as a measure of system complexity\", Proceedings of the National Academy of Sciences of the United States of America, 88, 2297-2301 (March 1991). Sample entropy was proposed by J. S. Richman and J. R. Moorman in \"Physiological time-series analysis using approximate entropy and sample entropy\", American Journal of Physiology, Heart and Circulatory Physiology, 278, 2039-2049 (June 2000). This package also contains FastApEn() and FastSampEn() functions for calculating fast approximate entropy and fast sample entropy. These are newly designed very fast algorithms, resulting from the modification of the original algorithms. The calculated values of these entropies are not the same as the original ones, but the entropy trend of the analyzed time series determines equally reliably. Their main advantage is their speed, which is up to a thousand times higher. A scientific article describing their properties has been submitted to The Journal of Supercomputing and in present time it is waiting for the acceptance.",
    "version": "0.9",
    "maintainer": "Jiri Tomcala <jiri.tomcala@vsb.cz>",
    "author": "Jiri Tomcala [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSEntropies",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSEntropies Time Series Entropies Computes various entropies of given time series. This is the initial version that includes ApEn() and SampEn() functions for calculating approximate entropy and sample entropy. Approximate entropy was proposed by S.M. Pincus in \"Approximate entropy as a measure of system complexity\", Proceedings of the National Academy of Sciences of the United States of America, 88, 2297-2301 (March 1991). Sample entropy was proposed by J. S. Richman and J. R. Moorman in \"Physiological time-series analysis using approximate entropy and sample entropy\", American Journal of Physiology, Heart and Circulatory Physiology, 278, 2039-2049 (June 2000). This package also contains FastApEn() and FastSampEn() functions for calculating fast approximate entropy and fast sample entropy. These are newly designed very fast algorithms, resulting from the modification of the original algorithms. The calculated values of these entropies are not the same as the original ones, but the entropy trend of the analyzed time series determines equally reliably. Their main advantage is their speed, which is up to a thousand times higher. A scientific article describing their properties has been submitted to The Journal of Supercomputing and in present time it is waiting for the acceptance.  "
  },
  {
    "id": 7664,
    "package_name": "TSF",
    "title": "Two Stage Forecasting (TSF) for Long Memory Time Series in\nPresence of Structural Break",
    "description": "Forecasting of long memory time series in presence of structural break by using TSF algorithm by Papailias and Dias (2015) <doi:10.1016/j.ijforecast.2015.01.006>. ",
    "version": "0.1.1",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Sandipan Samanta, Ranjit Kumar Paul and Dipankar Mitra",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSF Two Stage Forecasting (TSF) for Long Memory Time Series in\nPresence of Structural Break Forecasting of long memory time series in presence of structural break by using TSF algorithm by Papailias and Dias (2015) <doi:10.1016/j.ijforecast.2015.01.006>.   "
  },
  {
    "id": 7669,
    "package_name": "TSLSTM",
    "title": "Long Short Term Memory (LSTM) Model for Time Series Forecasting",
    "description": "The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Min-Max transformation has been used for data preparation. Here, we have used one LSTM layer as a simple LSTM model and a Dense layer is used as the output layer. Then, compile the model using the loss function, optimizer and metrics. This package is based on Keras and TensorFlow modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.",
    "version": "0.1.0",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut, cre],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSLSTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSLSTM Long Short Term Memory (LSTM) Model for Time Series Forecasting The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Min-Max transformation has been used for data preparation. Here, we have used one LSTM layer as a simple LSTM model and a Dense layer is used as the output layer. Then, compile the model using the loss function, optimizer and metrics. This package is based on Keras and TensorFlow modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.  "
  },
  {
    "id": 7670,
    "package_name": "TSLSTMplus",
    "title": "Long-Short Term Memory for Time-Series Forecasting, Enhanced",
    "description": "The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Customizable configurations for the model are allowed, improving the capabilities and usability of this model compared to other packages. This package is based on 'keras' and 'tensorflow' modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.",
    "version": "1.0.6",
    "maintainer": "Jaime Pizarroso Gonzalo <jpizarroso@comillas.edu>",
    "author": "Jaime Pizarroso Gonzalo [aut, ctb, cre],\n  Antonio Mu\u00f1oz San Roque [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSLSTMplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSLSTMplus Long-Short Term Memory for Time-Series Forecasting, Enhanced The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Customizable configurations for the model are allowed, improving the capabilities and usability of this model compared to other packages. This package is based on 'keras' and 'tensorflow' modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.  "
  },
  {
    "id": 7675,
    "package_name": "TSPred",
    "title": "Functions for Benchmarking Time Series Prediction",
    "description": "Functions for defining and conducting a time series prediction process including pre(post)processing, decomposition, modelling, prediction and accuracy assessment. The generated models and its yielded prediction errors can be used for benchmarking other time series prediction methods and for creating a demand for the refinement of such methods. For this purpose, benchmark data from prediction competitions may be used.",
    "version": "5.1.1",
    "maintainer": "Rebecca Pontes Salles <rebeccapsalles@acm.org>",
    "author": "Rebecca Pontes Salles [aut, cre, cph] (CEFET/RJ),\n  Eduardo Ogasawara [ths] (CEFET/RJ)",
    "url": "https://github.com/RebeccaSalles/TSPred/wiki",
    "bug_reports": "https://github.com/RebeccaSalles/TSPred/issues",
    "repository": "https://cran.r-project.org/package=TSPred",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSPred Functions for Benchmarking Time Series Prediction Functions for defining and conducting a time series prediction process including pre(post)processing, decomposition, modelling, prediction and accuracy assessment. The generated models and its yielded prediction errors can be used for benchmarking other time series prediction methods and for creating a demand for the refinement of such methods. For this purpose, benchmark data from prediction competitions may be used.  "
  },
  {
    "id": 7676,
    "package_name": "TSS.RESTREND",
    "title": "Time Series Segmentation of Residual Trends",
    "description": "Time Series Segmented Residual Trends is a method for the automated detection of land degradation from remotely sensed vegetation and climate datasets. TSS-RESTREND incorporates aspects of two existing degradation detection methods: RESTREND which is used to control for climate variability, and BFAST which is used to look for structural changes in the ecosystem. The full details of the testing and justification of the TSS-RESTREND method (version 0.1.02) are published in Burrell et al., (2017). <doi:10.1016/j.rse.2017.05.018>. The changes to the method introduced in version 0.2.03 focus on the inclusion  of temperature as an additional climate variable. This allows for land  degradation assessment in temperature limited drylands. A paper that details this work is currently under review. There are also a number of bug fixes and speed improvements. Version 0.3.0 introduces additional attribution for eCO2,  climate change and climate variability the details of which are in press in Burrell et al., (2020).  The version under active development and additional example scripts showing  how the package can be applied can be found at <https://github.com/ArdenB/TSSRESTREND>. ",
    "version": "0.3.1",
    "maintainer": "Arden Burrell <arden.burrell@gmail.com>",
    "author": "Arden Burrell [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSS.RESTREND",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSS.RESTREND Time Series Segmentation of Residual Trends Time Series Segmented Residual Trends is a method for the automated detection of land degradation from remotely sensed vegetation and climate datasets. TSS-RESTREND incorporates aspects of two existing degradation detection methods: RESTREND which is used to control for climate variability, and BFAST which is used to look for structural changes in the ecosystem. The full details of the testing and justification of the TSS-RESTREND method (version 0.1.02) are published in Burrell et al., (2017). <doi:10.1016/j.rse.2017.05.018>. The changes to the method introduced in version 0.2.03 focus on the inclusion  of temperature as an additional climate variable. This allows for land  degradation assessment in temperature limited drylands. A paper that details this work is currently under review. There are also a number of bug fixes and speed improvements. Version 0.3.0 introduces additional attribution for eCO2,  climate change and climate variability the details of which are in press in Burrell et al., (2020).  The version under active development and additional example scripts showing  how the package can be applied can be found at <https://github.com/ArdenB/TSSRESTREND>.   "
  },
  {
    "id": 7677,
    "package_name": "TSSS",
    "title": "Time Series Analysis with State Space Model",
    "description": "Functions for statistical analysis, modeling and simulation of time\n series with state space model, based on the methodology in Kitagawa\n (2020, ISBN: 978-0-367-18733-0).",
    "version": "1.3.4-5",
    "maintainer": "Masami Saga <msaga@mtb.biglobe.ne.jp>",
    "author": "The Institute of Statistical Mathematics, based on the program by\n Genshiro Kitagawa",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSSS Time Series Analysis with State Space Model Functions for statistical analysis, modeling and simulation of time\n series with state space model, based on the methodology in Kitagawa\n (2020, ISBN: 978-0-367-18733-0).  "
  },
  {
    "id": 7678,
    "package_name": "TSSVM",
    "title": "Time Series Forecasting using SVM Model",
    "description": "Implementation and forecasting univariate time series data using the Support Vector Machine model. Support Vector Machine is one of the prominent machine learning approach for non-linear time series forecasting. For method details see Kim, K. (2003) <doi:10.1016/S0925-2312(03)00372-2>.",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Mrinmoy Ray [aut, cre],\n  Samir Barman [aut, ctb],\n  Kanchan Sinha [aut, ctb],\n  K. N. Singh [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSSVM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSSVM Time Series Forecasting using SVM Model Implementation and forecasting univariate time series data using the Support Vector Machine model. Support Vector Machine is one of the prominent machine learning approach for non-linear time series forecasting. For method details see Kim, K. (2003) <doi:10.1016/S0925-2312(03)00372-2>.  "
  },
  {
    "id": 7679,
    "package_name": "TSTutorial",
    "title": "Fitting and Predict Time Series Interactive Laboratory",
    "description": "Interactive laboratory of Time Series based in Box-Jenkins methodology.",
    "version": "1.2.7",
    "maintainer": "Alberto Lopez Moreno <bertolomo@gmail.com>",
    "author": "Alberto Lopez Moreno",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSTutorial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSTutorial Fitting and Predict Time Series Interactive Laboratory Interactive laboratory of Time Series based in Box-Jenkins methodology.  "
  },
  {
    "id": 7681,
    "package_name": "TSclust",
    "title": "Time Series Clustering Utilities",
    "description": "A set of measures of dissimilarity between time series to perform time series clustering. Metrics based on raw data, on generating models and on the forecast behavior are implemented. Some additional utilities related to time series clustering are also provided, such as clustering algorithms and cluster evaluation metrics.",
    "version": "1.3.2",
    "maintainer": "Pablo Montero Manso <pmontm@gmail.com>",
    "author": "Pablo Montero Manso [cre],\n  Jose Vilar Fernandez [aut]",
    "url": "https://doi.org/10.18637/jss.v062.i01",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSclust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSclust Time Series Clustering Utilities A set of measures of dissimilarity between time series to perform time series clustering. Metrics based on raw data, on generating models and on the forecast behavior are implemented. Some additional utilities related to time series clustering are also provided, such as clustering algorithms and cluster evaluation metrics.  "
  },
  {
    "id": 7682,
    "package_name": "TSdisaggregation",
    "title": "High-Dimensional Temporal Disaggregation",
    "description": "First - Generates (potentially high-dimensional) high-frequency and low-frequency series for simulation studies in temporal disaggregation; Second - a toolkit utilizing temporal disaggregation and benchmarking techniques with a low-dimensional matrix of indicator series previously proposed in Dagum and Cholette (2006, ISBN:978-0-387-35439-2) ; and Third - novel techniques proposed by Mosley, Gibberd and Eckley (2021) <arXiv:2108.05783> for disaggregating low-frequency series in the presence of high-dimensional indicator matrices.",
    "version": "2.0.0",
    "maintainer": "Luke Mosley <l.mosley@lancaster.ac.uk>",
    "author": "Luke Mosley [aut, cre],\n  Kaveh S. Nobari [aut] (ORCID: <https://orcid.org/0000-0002-4053-0781>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSdisaggregation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSdisaggregation High-Dimensional Temporal Disaggregation First - Generates (potentially high-dimensional) high-frequency and low-frequency series for simulation studies in temporal disaggregation; Second - a toolkit utilizing temporal disaggregation and benchmarking techniques with a low-dimensional matrix of indicator series previously proposed in Dagum and Cholette (2006, ISBN:978-0-387-35439-2) ; and Third - novel techniques proposed by Mosley, Gibberd and Eckley (2021) <arXiv:2108.05783> for disaggregating low-frequency series in the presence of high-dimensional indicator matrices.  "
  },
  {
    "id": 7683,
    "package_name": "TSdist",
    "title": "Distance Measures for Time Series Data",
    "description": "A set of commonly used distance measures and some additional functions which, although initially not designed for this purpose, can be used to measure the dissimilarity between time series. These measures can be used to perform clustering, classification or other data mining tasks which require the definition of a distance measure between time series. U. Mori, A. Mendiburu and J.A. Lozano (2016), <doi:10.32614/RJ-2016-058>.",
    "version": "3.7.1",
    "maintainer": "Usue Mori <usue.mori@ehu.eus>",
    "author": "Usue Mori [aut, cre],\n  Alexander Mendiburu [aut],\n  Jose A. Lozano [aut],\n  Duarte Folgado [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSdist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSdist Distance Measures for Time Series Data A set of commonly used distance measures and some additional functions which, although initially not designed for this purpose, can be used to measure the dissimilarity between time series. These measures can be used to perform clustering, classification or other data mining tasks which require the definition of a distance measure between time series. U. Mori, A. Mendiburu and J.A. Lozano (2016), <doi:10.32614/RJ-2016-058>.  "
  },
  {
    "id": 7684,
    "package_name": "TSeriesMMA",
    "title": "Multiscale Multifractal Analysis of Time Series Data",
    "description": "Multiscale multifractal analysis (MMA) (Giera\u0142towski et al.,\n    2012)<DOI:10.1103/PhysRevE.85.021915> is a time series analysis method,\n    designed to describe scaling properties of fluctuations within the signal\n    analyzed. The main result of this procedure is the so called Hurst surface\n    h(q,s) , which is a dependence of the local Hurst exponent h (fluctuation\n    scaling exponent) on the multifractal parameter q and the scale of observation s\n    (data window width).",
    "version": "0.1.1",
    "maintainer": "Vishakh Padmakumar <vishakhpadmakumar@gmail.com>",
    "author": "Vishakh Padmakumar [aut, cre],\n  Rishab Ranga [aut],\n  Amogha Udupa [aut],\n  Param Hanji [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSeriesMMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSeriesMMA Multiscale Multifractal Analysis of Time Series Data Multiscale multifractal analysis (MMA) (Giera\u0142towski et al.,\n    2012)<DOI:10.1103/PhysRevE.85.021915> is a time series analysis method,\n    designed to describe scaling properties of fluctuations within the signal\n    analyzed. The main result of this procedure is the so called Hurst surface\n    h(q,s) , which is a dependence of the local Hurst exponent h (fluctuation\n    scaling exponent) on the multifractal parameter q and the scale of observation s\n    (data window width).  "
  },
  {
    "id": 7685,
    "package_name": "TSrepr",
    "title": "Time Series Representations",
    "description": "Methods for representations (i.e. dimensionality reduction, preprocessing, feature extraction) of time series to help more accurate and effective time series data mining.\n    Non-data adaptive, data adaptive, model-based and data dictated (clipped) representation methods are implemented. Also various normalisation methods (min-max, z-score, Box-Cox, Yeo-Johnson),\n    and forecasting accuracy measures are implemented.",
    "version": "1.1.0",
    "maintainer": "Peter Laurinec <tsreprpackage@gmail.com>",
    "author": "Peter Laurinec [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3501-8783>)",
    "url": "https://petolau.github.io/package/,\nhttps://github.com/PetoLau/TSrepr/",
    "bug_reports": "https://github.com/PetoLau/TSrepr/issues",
    "repository": "https://cran.r-project.org/package=TSrepr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSrepr Time Series Representations Methods for representations (i.e. dimensionality reduction, preprocessing, feature extraction) of time series to help more accurate and effective time series data mining.\n    Non-data adaptive, data adaptive, model-based and data dictated (clipped) representation methods are implemented. Also various normalisation methods (min-max, z-score, Box-Cox, Yeo-Johnson),\n    and forecasting accuracy measures are implemented.  "
  },
  {
    "id": 7686,
    "package_name": "TSsmoothing",
    "title": "Trend Estimation of Univariate and Bivariate Time Series with\nControlled Smoothness",
    "description": "It performs the smoothing approach provided by penalized least squares for univariate and bivariate time series, as proposed by Guerrero (2007) and Gerrero et al. (2017). \n          This allows to estimate the time series trend by controlling the amount of resulting (joint) smoothness.\n          ---\n          Guerrero, V.M (2007)  <DOI:10.1016/j.spl.2007.03.006>.\n          Guerrero, V.M; Islas-Camargo, A. and Ramirez-Ramirez, L.L. (2017) <DOI:10.1080/03610926.2015.1133826>.",
    "version": "0.1.0",
    "maintainer": "L. Leticia Ramirez-Ramirez <leticia.ramirez@cimat.mx>",
    "author": "L. Leticia Ramirez-Ramirez [aut, cre],\n  Alejandro Islas-Camargo [aut],\n  Victor M. Guerrero [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSsmoothing",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSsmoothing Trend Estimation of Univariate and Bivariate Time Series with\nControlled Smoothness It performs the smoothing approach provided by penalized least squares for univariate and bivariate time series, as proposed by Guerrero (2007) and Gerrero et al. (2017). \n          This allows to estimate the time series trend by controlling the amount of resulting (joint) smoothness.\n          ---\n          Guerrero, V.M (2007)  <DOI:10.1016/j.spl.2007.03.006>.\n          Guerrero, V.M; Islas-Camargo, A. and Ramirez-Ramirez, L.L. (2017) <DOI:10.1080/03610926.2015.1133826>.  "
  },
  {
    "id": 7687,
    "package_name": "TSstudio",
    "title": "Functions for Time Series Analysis and Forecasting",
    "description": "Provides a set of tools for descriptive and predictive analysis of time series data. That includes functions for interactive visualization of time series objects and as well utility functions for automation time series forecasting.",
    "version": "0.1.7",
    "maintainer": "Rami Krispin <rami.krispin@gmail.com>",
    "author": "Rami Krispin [aut, cre]",
    "url": "https://github.com/RamiKrispin/TSstudio",
    "bug_reports": "https://github.com/RamiKrispin/TSstudio/issues",
    "repository": "https://cran.r-project.org/package=TSstudio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSstudio Functions for Time Series Analysis and Forecasting Provides a set of tools for descriptive and predictive analysis of time series data. That includes functions for interactive visualization of time series objects and as well utility functions for automation time series forecasting.  "
  },
  {
    "id": 7688,
    "package_name": "TTAinterfaceTrendAnalysis",
    "title": "Temporal Trend Analysis Graphical Interface",
    "description": "This interface was created to develop a standard procedure \n to analyse temporal trend in the framework of the OSPAR convention.\n The analysis process run through 4 successive steps : 1) manipulate your data, 2)\n select the parameters you want to analyse, 3) build your regulated \n time series, 4) perform diagnosis and analysis and 5) read the results. \n Statistical analysis call other package function such as Kendall tests\n or cusum() function.",
    "version": "1.5.11",
    "maintainer": "David DEVREKER <David.Devreker@ifremer.fr>",
    "author": "David DEVREKER [aut, cre],\n  Alain LEFEBVRE [aut]",
    "url": "https://CRAN.R-project.org/package=TTAinterfaceTrendAnalysis",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TTAinterfaceTrendAnalysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TTAinterfaceTrendAnalysis Temporal Trend Analysis Graphical Interface This interface was created to develop a standard procedure \n to analyse temporal trend in the framework of the OSPAR convention.\n The analysis process run through 4 successive steps : 1) manipulate your data, 2)\n select the parameters you want to analyse, 3) build your regulated \n time series, 4) perform diagnosis and analysis and 5) read the results. \n Statistical analysis call other package function such as Kendall tests\n or cusum() function.  "
  },
  {
    "id": 7689,
    "package_name": "TTCA",
    "title": "Transcript Time Course Analysis",
    "description": "The analysis of microarray time series promises a deeper insight into the dynamics of the cellular response following stimulation. A common observation in this type of data is that some genes respond with quick, transient dynamics, while other genes change their expression slowly over time. The existing methods for detecting significant expression dynamics often fail when the expression dynamics show a large heterogeneity. Moreover, these methods often cannot cope with irregular and sparse measurements. The method proposed here is specifically designed for the analysis of perturbation responses. It combines different scores to capture fast and transient dynamics as well as slow expression changes, and performs well in the presence of low replicate numbers and irregular sampling times. The results are given in the form of tables including links to figures showing the expression dynamics of the respective transcript. These allow to quickly recognise the relevance of detection, to identify possible false positives and to discriminate early and late changes in gene expression. An extension of the method allows the analysis of the expression dynamics of functional groups of genes, providing a quick overview of the cellular response. The performance of this package was tested on microarray data derived from lung cancer cells stimulated with epidermal growth factor (EGF). Paper: Albrecht, Marco, et al. (2017)<DOI:10.1186/s12859-016-1440-8>.",
    "version": "0.1.1",
    "maintainer": "Marco Albrecht <marco.albrecht@posteo.de>",
    "author": "Marco Albrecht",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TTCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TTCA Transcript Time Course Analysis The analysis of microarray time series promises a deeper insight into the dynamics of the cellular response following stimulation. A common observation in this type of data is that some genes respond with quick, transient dynamics, while other genes change their expression slowly over time. The existing methods for detecting significant expression dynamics often fail when the expression dynamics show a large heterogeneity. Moreover, these methods often cannot cope with irregular and sparse measurements. The method proposed here is specifically designed for the analysis of perturbation responses. It combines different scores to capture fast and transient dynamics as well as slow expression changes, and performs well in the presence of low replicate numbers and irregular sampling times. The results are given in the form of tables including links to figures showing the expression dynamics of the respective transcript. These allow to quickly recognise the relevance of detection, to identify possible false positives and to discriminate early and late changes in gene expression. An extension of the method allows the analysis of the expression dynamics of functional groups of genes, providing a quick overview of the cellular response. The performance of this package was tested on microarray data derived from lung cancer cells stimulated with epidermal growth factor (EGF). Paper: Albrecht, Marco, et al. (2017)<DOI:10.1186/s12859-016-1440-8>.  "
  },
  {
    "id": 7717,
    "package_name": "Tcomp",
    "title": "Data from the 2010 Tourism Forecasting Competition",
    "description": "The 1311 time series from the tourism forecasting competition conducted in 2010 and described in Athanasopoulos et al. (2011) <DOI:10.1016/j.ijforecast.2010.04.009>.",
    "version": "1.0.1",
    "maintainer": "Peter Ellis <peter.ellis2013nz@gmail.com>",
    "author": "Peter Ellis [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/ellisp/Tcomp-r-package/issues",
    "repository": "https://cran.r-project.org/package=Tcomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Tcomp Data from the 2010 Tourism Forecasting Competition The 1311 time series from the tourism forecasting competition conducted in 2010 and described in Athanasopoulos et al. (2011) <DOI:10.1016/j.ijforecast.2010.04.009>.  "
  },
  {
    "id": 7723,
    "package_name": "TempCont",
    "title": "Temporal Contributions on Trends using Mixed Models",
    "description": "Method to estimate the effect of the trend in predictor variables on the observed trend\n of the response variable using mixed models with temporal autocorrelation. See Fern\u00e1ndez-Mart\u00ednez et\n al. (2017 and 2019) <doi:10.1038/s41598-017-08755-8> <doi:10.1038/s41558-018-0367-7>.",
    "version": "0.1.0",
    "maintainer": "Marcos Fern\u00e1ndez-Mart\u00ednez <marcos.fernandez-martinez@uantwerpen.be>",
    "author": "Marcos Fern\u00e1ndez-Mart\u00ednez, Joan Maspons",
    "url": "https://github.com/burriach/tempcont",
    "bug_reports": "https://github.com/burriach/tempcont/issues",
    "repository": "https://cran.r-project.org/package=TempCont",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TempCont Temporal Contributions on Trends using Mixed Models Method to estimate the effect of the trend in predictor variables on the observed trend\n of the response variable using mixed models with temporal autocorrelation. See Fern\u00e1ndez-Mart\u00ednez et\n al. (2017 and 2019) <doi:10.1038/s41598-017-08755-8> <doi:10.1038/s41558-018-0367-7>.  "
  },
  {
    "id": 7726,
    "package_name": "TemporalGSSA",
    "title": "Outputs Temporal Profile of Molecules from Stochastic Simulation\nAlgorithm Generated Datasets",
    "description": "The data that is generated from independent and consecutive 'GillespieSSA' runs for a generic biochemical network\n    is formatted as rows and constitutes an observation. The first column of each row is the computed timestep for each run. Subsequent \n    columns are used for the number of molecules of each participating molecular species or \"metabolite\" of a generic biochemical network. \n    In this way 'TemporalGSSA', is a wrapper for the R-package 'GillespieSSA'. The number of observations must be at least 30. \n    This will generate data that is statistically significant. 'TemporalGSSA', transforms this raw data into a simulation time-dependent and metabolite-specific\n    trial. Each such trial is defined as a set of linear models (n >= 30) between a timestep and number of molecules for a metabolite. Each linear model \n    is characterized by coefficients such as the slope, arbitrary constant, etc. The user must enter an integer from 1-4.\n    These specify the statistical modality utilized to compute a representative timestep (mean, median, random, all).\n    These arguments are mandatory and will be checked. Whilst, the numeric indicator \"0\" indicates suitability,\n    \"1\" prompts the user to revise and re-enter their data. An optional logical argument controls the output to the \n    console with the default being \"TRUE\" (curtailed) whilst \"FALSE\" (verbose). The coefficients of each linear model are averaged (mean slope, mean constant)\n    and are incorporated into a metabolite-specific linear regression model as the dependent variable. The independent variable is the representative timestep \n    chosen previously. The generated data is the imputed molecule number for an in silico experiment with (n >=30) \n    observations. These steps can be replicated with multiple set of observations. The generated \"technical \n    replicates\" can be statistically evaluated (mean, standard deviation) and will constitute simulation time-dependent molecules for each metabolite. \n    For SSA-generated datasets with varying simulation times 'TemporalGSSA' will generate a simulation time-dependent trajectory for each metabolite\n    of the biochemical network under study. The relevant publication with the mathematical derivation of the algorithm is \n    (2022, Journal of Bioinformatics and Computational Biology) <doi:10.1142/S0219720022500184>. The algorithm has been deployed in the following publications   \n    (2021, Heliyon) <doi:10.1016/j.heliyon.2021.e07466> and (2016, Journal of Theoretical Biology) <doi:10.1016/j.jtbi.2016.07.002>.",
    "version": "1.0.1",
    "maintainer": "Siddhartha Kundu <siddhartha_kundu@aiims.edu>",
    "author": "Siddhartha Kundu",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TemporalGSSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TemporalGSSA Outputs Temporal Profile of Molecules from Stochastic Simulation\nAlgorithm Generated Datasets The data that is generated from independent and consecutive 'GillespieSSA' runs for a generic biochemical network\n    is formatted as rows and constitutes an observation. The first column of each row is the computed timestep for each run. Subsequent \n    columns are used for the number of molecules of each participating molecular species or \"metabolite\" of a generic biochemical network. \n    In this way 'TemporalGSSA', is a wrapper for the R-package 'GillespieSSA'. The number of observations must be at least 30. \n    This will generate data that is statistically significant. 'TemporalGSSA', transforms this raw data into a simulation time-dependent and metabolite-specific\n    trial. Each such trial is defined as a set of linear models (n >= 30) between a timestep and number of molecules for a metabolite. Each linear model \n    is characterized by coefficients such as the slope, arbitrary constant, etc. The user must enter an integer from 1-4.\n    These specify the statistical modality utilized to compute a representative timestep (mean, median, random, all).\n    These arguments are mandatory and will be checked. Whilst, the numeric indicator \"0\" indicates suitability,\n    \"1\" prompts the user to revise and re-enter their data. An optional logical argument controls the output to the \n    console with the default being \"TRUE\" (curtailed) whilst \"FALSE\" (verbose). The coefficients of each linear model are averaged (mean slope, mean constant)\n    and are incorporated into a metabolite-specific linear regression model as the dependent variable. The independent variable is the representative timestep \n    chosen previously. The generated data is the imputed molecule number for an in silico experiment with (n >=30) \n    observations. These steps can be replicated with multiple set of observations. The generated \"technical \n    replicates\" can be statistically evaluated (mean, standard deviation) and will constitute simulation time-dependent molecules for each metabolite. \n    For SSA-generated datasets with varying simulation times 'TemporalGSSA' will generate a simulation time-dependent trajectory for each metabolite\n    of the biochemical network under study. The relevant publication with the mathematical derivation of the algorithm is \n    (2022, Journal of Bioinformatics and Computational Biology) <doi:10.1142/S0219720022500184>. The algorithm has been deployed in the following publications   \n    (2021, Heliyon) <doi:10.1016/j.heliyon.2021.e07466> and (2016, Journal of Theoretical Biology) <doi:10.1016/j.jtbi.2016.07.002>.  "
  },
  {
    "id": 7727,
    "package_name": "Tendril",
    "title": "Compute and Display Tendril Plots",
    "description": "Compute the coordinates to produce a tendril plot. \n    In the tendril plot, each tendril (branch) represents a type of events, \n    and the direction of the tendril is dictated by on which treatment arm the \n    event is occurring. If an event is occurring on the first of the two \n    specified treatment arms, the tendril bends in a clockwise direction. \n    If an event is occurring on the second of the treatment arms, the\n    tendril bends in an anti-clockwise direction. \n    Ref: Karpefors, M and Weatherall, J., \"The Tendril Plot - a novel visual summary \n    of the incidence, significance and temporal aspects of adverse events in \n    clinical trials\" - JAMIA 2018; 25(8): 1069-1073 <doi:10.1093/jamia/ocy016>.",
    "version": "2.0.4",
    "maintainer": "Stefano Borini <stefano.borini@astrazeneca.com>",
    "author": "Martin Karpefors [aut],\n  Stefano Borini [ctb, cre],\n  Mark Edmondson-Jones [ctb],\n  Hielke Bijlsma [ctb]",
    "url": "https://github.com/Karpefors/Tendril",
    "bug_reports": "https://github.com/Karpefors/Tendril/issues",
    "repository": "https://cran.r-project.org/package=Tendril",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Tendril Compute and Display Tendril Plots Compute the coordinates to produce a tendril plot. \n    In the tendril plot, each tendril (branch) represents a type of events, \n    and the direction of the tendril is dictated by on which treatment arm the \n    event is occurring. If an event is occurring on the first of the two \n    specified treatment arms, the tendril bends in a clockwise direction. \n    If an event is occurring on the second of the treatment arms, the\n    tendril bends in an anti-clockwise direction. \n    Ref: Karpefors, M and Weatherall, J., \"The Tendril Plot - a novel visual summary \n    of the incidence, significance and temporal aspects of adverse events in \n    clinical trials\" - JAMIA 2018; 25(8): 1069-1073 <doi:10.1093/jamia/ocy016>.  "
  },
  {
    "id": 7729,
    "package_name": "TensorPreAve",
    "title": "Rank and Factor Loadings Estimation in Time Series Tensor Factor\nModels",
    "description": "A set of functions to estimate rank and factor loadings of time series tensor factor models. A tensor is a multidimensional array. To analyze high-dimensional tensor time series, factor model is a major dimension reduction tool. 'TensorPreAve' provides functions to estimate the rank of core tensors and factor loading spaces of tensor time series. More specifically, a pre-averaging method that accumulates information from tensor fibres is used to estimate the factor loading spaces. The estimated directions corresponding to the strongest factors are then used for projecting the data for a potentially improved re-estimation of the factor loading spaces themselves. A new rank estimation method is also implemented to utilizes correlation information from the projected data. \n    See Chen and Lam (2023) <arXiv:2208.04012> for more details.",
    "version": "1.1.0",
    "maintainer": "Weilin Chen <w.chen56@lse.ac.uk>",
    "author": "Weilin Chen [aut, cre]",
    "url": "https://github.com/William-Chenwl/TensorPreAve",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TensorPreAve",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TensorPreAve Rank and Factor Loadings Estimation in Time Series Tensor Factor\nModels A set of functions to estimate rank and factor loadings of time series tensor factor models. A tensor is a multidimensional array. To analyze high-dimensional tensor time series, factor model is a major dimension reduction tool. 'TensorPreAve' provides functions to estimate the rank of core tensors and factor loading spaces of tensor time series. More specifically, a pre-averaging method that accumulates information from tensor fibres is used to estimate the factor loading spaces. The estimated directions corresponding to the strongest factors are then used for projecting the data for a potentially improved re-estimation of the factor loading spaces themselves. A new rank estimation method is also implemented to utilizes correlation information from the projected data. \n    See Chen and Lam (2023) <arXiv:2208.04012> for more details.  "
  },
  {
    "id": 7747,
    "package_name": "TextForecast",
    "title": "Regression Analysis and Forecasting Using Textual Data from a\nTime-Varying Dictionary",
    "description": "Provides functionalities based on the paper \"Time Varying Dictionary and the Predictive Power of FED Minutes\" (Lima, 2018) <doi:10.2139/ssrn.3312483>. It selects the most predictive terms, that we call time-varying dictionary using supervised machine learning techniques as lasso and elastic net.     ",
    "version": "0.1.3",
    "maintainer": "Lucas Godeiro <lucas.godeiro@hotmail.com>",
    "author": "Luiz Renato Lima [aut],\n  Lucas Godeiro [aut, cre]",
    "url": "https://github.com/lucasgodeiro/TextForecast",
    "bug_reports": "https://github.com/lucasgodeiro/TextForecast/issues",
    "repository": "https://cran.r-project.org/package=TextForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TextForecast Regression Analysis and Forecasting Using Textual Data from a\nTime-Varying Dictionary Provides functionalities based on the paper \"Time Varying Dictionary and the Predictive Power of FED Minutes\" (Lima, 2018) <doi:10.2139/ssrn.3312483>. It selects the most predictive terms, that we call time-varying dictionary using supervised machine learning techniques as lasso and elastic net.       "
  },
  {
    "id": 7764,
    "package_name": "TiPS",
    "title": "Trajectories and Phylogenies Simulator",
    "description": "Generates stochastic time series and genealogies associated with a population dynamics model. Times series are simulated using the Gillespie exact and approximate algorithms and a new algorithm we introduce that uses both approaches to optimize the time execution of the simulations. Genealogies are simulated from a trajectory using a backwards-in-time based approach. Methods are described in Danesh G et al (2022) <doi:10.1111/2041-210X.14038>.",
    "version": "1.3.0",
    "maintainer": "Gonche Danesh <gonche.danesh@gmail.com>",
    "author": "Gonche Danesh [aut, cre, cph],\n  Emma Saulnier [aut, cph],\n  Olivier Gascuel [aut, cph],\n  Marc Choisy [aut, cph, ths],\n  Samuel Alizon [aut, cph, ths]",
    "url": "https://gitlab.in2p3.fr/ete/tips/",
    "bug_reports": "https://gitlab.in2p3.fr/ete/tips/-/issues",
    "repository": "https://cran.r-project.org/package=TiPS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TiPS Trajectories and Phylogenies Simulator Generates stochastic time series and genealogies associated with a population dynamics model. Times series are simulated using the Gillespie exact and approximate algorithms and a new algorithm we introduce that uses both approaches to optimize the time execution of the simulations. Genealogies are simulated from a trajectory using a backwards-in-time based approach. Methods are described in Danesh G et al (2022) <doi:10.1111/2041-210X.14038>.  "
  },
  {
    "id": 7765,
    "package_name": "TideCurves",
    "title": "Analysis and Prediction of Tides",
    "description": "Tidal analysis of evenly spaced observed time series (time step 1 to 60 min) with or\n    without shorter gaps using the harmonic representation of inequalities.\n    The analysis should preferably cover an observation period of at least 19 years.\n    For shorter periods low frequency constituents are not taken into account, in accordance with the Rayleigh-Criterion.\n    The main objective of this package is to synthesize or predict a tidal time series.",
    "version": "0.0.5",
    "maintainer": "Moritz Mueller-Navarra <muellernavarra@gmail.com>",
    "author": "Moritz Mueller-Navarra [aut, cre],\n  Sylvin Mueller-Navarra [aut] ((2019)\n    <https://doi.org/10.5194/os-15-1363-2019>),\n  Andreas Boesch [ctb] ((2019) <https://doi.org/10.5194/os-15-1363-2019>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TideCurves",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TideCurves Analysis and Prediction of Tides Tidal analysis of evenly spaced observed time series (time step 1 to 60 min) with or\n    without shorter gaps using the harmonic representation of inequalities.\n    The analysis should preferably cover an observation period of at least 19 years.\n    For shorter periods low frequency constituents are not taken into account, in accordance with the Rayleigh-Criterion.\n    The main objective of this package is to synthesize or predict a tidal time series.  "
  },
  {
    "id": 7768,
    "package_name": "Tides",
    "title": "Quasi-Periodic Time Series Characteristics",
    "description": "Calculate Characteristics of Quasi-Periodic Time Series, e.g. Estuarine Water Levels.",
    "version": "2.1",
    "maintainer": "Tom Cox <tom.cox@uantwerp.be>",
    "author": "Tom Cox <tom.cox@uantwerp.be>, Lennert Schepers <lennert.schepers@uantwerp.be>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Tides",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Tides Quasi-Periodic Time Series Characteristics Calculate Characteristics of Quasi-Periodic Time Series, e.g. Estuarine Water Levels.  "
  },
  {
    "id": 7774,
    "package_name": "TimeVizPro",
    "title": "Dynamic Data Explorer: Visualize and Forecast with 'TimeVizPro'",
    "description": "Unleash the power of time-series data visualization with ease using our package. Designed with simplicity \n in mind, it offers three key features through the 'shiny' package output. The first tab shows time- series \n charts with forecasts, allowing users to visualize trends and changes effortlessly. The second one displays \n Averages per country presented in tables with accompanying sparklines, providing a quick and attractive \n overview of the data. The last tab presents A customizable world map colored based on user-defined \n variables for any chosen number of countries, offering an advanced visual approach to understanding \n geographical data distributions. This package operates with just a few simple arguments, enabling users \n to conduct sophisticated analyses without the need for complex programming skills. Transform your \n time-series data analysis experience with our user-friendly tool. ",
    "version": "1.0.1",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Fernando Cantu Bazaldua [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TimeVizPro",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TimeVizPro Dynamic Data Explorer: Visualize and Forecast with 'TimeVizPro' Unleash the power of time-series data visualization with ease using our package. Designed with simplicity \n in mind, it offers three key features through the 'shiny' package output. The first tab shows time- series \n charts with forecasts, allowing users to visualize trends and changes effortlessly. The second one displays \n Averages per country presented in tables with accompanying sparklines, providing a quick and attractive \n overview of the data. The last tab presents A customizable world map colored based on user-defined \n variables for any chosen number of countries, offering an advanced visual approach to understanding \n geographical data distributions. This package operates with just a few simple arguments, enabling users \n to conduct sophisticated analyses without the need for complex programming skills. Transform your \n time-series data analysis experience with our user-friendly tool.   "
  },
  {
    "id": 7776,
    "package_name": "TipDatingBeast",
    "title": "Using Tip Dates with Phylogenetic Trees in BEAST",
    "description": "Assists performing tip-dating of phylogenetic trees with BEAST \n    BEAST is a popular software for phylogenetic analysis.\n    The package assists the implementation of various phylogenetic tip-\n\tdating tests using BEAST. It contains two main functions.\n\tThe first one allows preparing date randomization analyses, \n\twhich assess the temporal signal of a data set. \n\tThe second function allows performing leave-one-out analyses,\n\twhich test for the consistency between independent calibration sequences\n\tand allow pinpointing those leading to potential bias.\n\tThe included tutorial provides detailed step-by-step instructions.\n\tAn expanded description of the package can be found in article:\n\tRieux, A. and Khatchikian, C.E. (2017), \n\tTIPDATINGBEAST: an R package to assist the implementation of phylogenetic\n\ttip-dating tests using BEAST. Molecular Ecology Resources, 17: 608-613.\n\t<onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12603>.",
    "version": "1.1-0",
    "maintainer": "Camilo Khatchikian <ckhatchikian@gmail.com>",
    "author": "Adrien Rieux, Camilo Khatchikian",
    "url": "https://www.r-project.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TipDatingBeast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TipDatingBeast Using Tip Dates with Phylogenetic Trees in BEAST Assists performing tip-dating of phylogenetic trees with BEAST \n    BEAST is a popular software for phylogenetic analysis.\n    The package assists the implementation of various phylogenetic tip-\n\tdating tests using BEAST. It contains two main functions.\n\tThe first one allows preparing date randomization analyses, \n\twhich assess the temporal signal of a data set. \n\tThe second function allows performing leave-one-out analyses,\n\twhich test for the consistency between independent calibration sequences\n\tand allow pinpointing those leading to potential bias.\n\tThe included tutorial provides detailed step-by-step instructions.\n\tAn expanded description of the package can be found in article:\n\tRieux, A. and Khatchikian, C.E. (2017), \n\tTIPDATINGBEAST: an R package to assist the implementation of phylogenetic\n\ttip-dating tests using BEAST. Molecular Ecology Resources, 17: 608-613.\n\t<onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12603>.  "
  },
  {
    "id": 7794,
    "package_name": "TractorTsbox",
    "title": "Wrangle and Modify Ts Object with Classic Frequencies and Exact\nDates",
    "description": "The ts objects in R are managed using a very specific date format (in the form c(2022, 9) for September 2022 or c(2021, 2) for the second quarter of 2021, depending on the frequency, for example). We focus solely on monthly and quarterly series to manage the dates of ts objects. The general idea is to offer a set of functions to manage this date format without it being too restrictive or too imprecise depending on the rounding. This is a compromise between simplicity, precision and use of the basic 'stats' functions for creating and managing time series (ts(), window()).\n    Les objets ts en R sont g\u00e9r\u00e9s par un format de date tr\u00e8s particulier (sous la forme c(2022, 9) pour septembre 2022 ou c(2021, 2) pour le deuxi\u00e8me trimestre 2021 selon la fr\u00e9quence par exemple). On se concentre uniquement sur les s\u00e9ries mensuelles et trimestrielles pour g\u00e9rer les dates des objets ts. Lid\u00e9e g\u00e9n\u00e9rale est de proposer un ensemble de fonctions pour g\u00e9rer ce format de date sans que ce soit trop contraignant ou trop impr\u00e9cis selon les arrondis. Cest un compromis entre simplicit\u00e9, pr\u00e9cision et utilisation des fonctions du package 'stats' de cr\u00e9ation et de gestion des s\u00e9ries temporelles (ts(), window()).",
    "version": "0.1.1",
    "maintainer": "Tanguy Barthelemy <tangbarth@hotmail.fr>",
    "author": "Tanguy Barthelemy [aut, cre]",
    "url": "https://github.com/TractorTom/TractorTsbox,\nhttps://tractortom.github.io/TractorTsbox/",
    "bug_reports": "https://github.com/TractorTom/TractorTsbox/issues",
    "repository": "https://cran.r-project.org/package=TractorTsbox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TractorTsbox Wrangle and Modify Ts Object with Classic Frequencies and Exact\nDates The ts objects in R are managed using a very specific date format (in the form c(2022, 9) for September 2022 or c(2021, 2) for the second quarter of 2021, depending on the frequency, for example). We focus solely on monthly and quarterly series to manage the dates of ts objects. The general idea is to offer a set of functions to manage this date format without it being too restrictive or too imprecise depending on the rounding. This is a compromise between simplicity, precision and use of the basic 'stats' functions for creating and managing time series (ts(), window()).\n    Les objets ts en R sont g\u00e9r\u00e9s par un format de date tr\u00e8s particulier (sous la forme c(2022, 9) pour septembre 2022 ou c(2021, 2) pour le deuxi\u00e8me trimestre 2021 selon la fr\u00e9quence par exemple). On se concentre uniquement sur les s\u00e9ries mensuelles et trimestrielles pour g\u00e9rer les dates des objets ts. Lid\u00e9e g\u00e9n\u00e9rale est de proposer un ensemble de fonctions pour g\u00e9rer ce format de date sans que ce soit trop contraignant ou trop impr\u00e9cis selon les arrondis. Cest un compromis entre simplicit\u00e9, pr\u00e9cision et utilisation des fonctions du package 'stats' de cr\u00e9ation et de gestion des s\u00e9ries temporelles (ts(), window()).  "
  },
  {
    "id": 7819,
    "package_name": "TrenchR",
    "title": "Tools for Microclimate and Biophysical Ecology",
    "description": "Tools for translating environmental change into organismal response. Microclimate models to vertically scale weather station data to organismal heights. The biophysical modeling tools include both general models for heat flows and specific models to predict body temperatures for a variety of ectothermic taxa. Additional functions model and temporally partition air and soil temperatures and solar radiation. Utility functions estimate the organismal and environmental parameters needed for biophysical ecology. 'TrenchR' focuses on relatively simple and modular functions so users can create transparent and flexible biophysical models. Many functions are derived from Gates (1980) <doi:10.1007/978-1-4612-6024-0> and Campbell and Norman (1988) <isbn:9780387949376>.",
    "version": "1.1.1",
    "maintainer": "Lauren Buckley <lbuckley@uw.edu>",
    "author": "Lauren Buckley [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1315-3818>),\n  Bryan Briones Ortiz [aut],\n  Isaac Caruso [aut],\n  Aji John [aut] (ORCID: <https://orcid.org/0000-0002-4401-1401>),\n  Ofir Levy [aut] (ORCID: <https://orcid.org/0000-0003-0920-1207>),\n  Abigail Meyer [aut],\n  Eric Riddell [aut] (ORCID: <https://orcid.org/0000-0002-4229-4911>),\n  Yutaro Sakairi [aut],\n  Juniper Simonis [aut] (ORCID: <https://orcid.org/0000-0001-9798-0460>),\n  Brian Helmuth [ctb] (ORCID: <https://orcid.org/0000-0003-0180-3414>)",
    "url": "https://trenchproject.github.io/TrenchR/,\nhttps://github.com/trenchproject/TrenchR",
    "bug_reports": "https://github.com/trenchproject/TrenchR/issues",
    "repository": "https://cran.r-project.org/package=TrenchR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TrenchR Tools for Microclimate and Biophysical Ecology Tools for translating environmental change into organismal response. Microclimate models to vertically scale weather station data to organismal heights. The biophysical modeling tools include both general models for heat flows and specific models to predict body temperatures for a variety of ectothermic taxa. Additional functions model and temporally partition air and soil temperatures and solar radiation. Utility functions estimate the organismal and environmental parameters needed for biophysical ecology. 'TrenchR' focuses on relatively simple and modular functions so users can create transparent and flexible biophysical models. Many functions are derived from Gates (1980) <doi:10.1007/978-1-4612-6024-0> and Campbell and Norman (1988) <isbn:9780387949376>.  "
  },
  {
    "id": 7821,
    "package_name": "TrendLSW",
    "title": "Wavelet Methods for Analysing Locally Stationary Time Series",
    "description": "Fitting models for, and simulation of, trend locally stationary \n    wavelet (TLSW) time series models, which take account of time-varying \n    trend and dependence structure in a univariate time series. The TLSW model, \n    and its estimation, is described in McGonigle, Killick and Nunes (2022a) \n    <doi:10.1111/jtsa.12643>, (2022b) <doi:10.1214/22-EJS2044>. New users will \n    likely want to start with the TLSW function.",
    "version": "1.0.4",
    "maintainer": "Euan T. McGonigle <e.t.mcgonigle@soton.ac.uk>",
    "author": "Euan T. McGonigle [aut, cre],\n  Rebecca Killick [aut],\n  Matthew Nunes [aut]",
    "url": "https://github.com/EuanMcGonigle/TrendLSW",
    "bug_reports": "https://github.com/EuanMcGonigle/TrendLSW/issues",
    "repository": "https://cran.r-project.org/package=TrendLSW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TrendLSW Wavelet Methods for Analysing Locally Stationary Time Series Fitting models for, and simulation of, trend locally stationary \n    wavelet (TLSW) time series models, which take account of time-varying \n    trend and dependence structure in a univariate time series. The TLSW model, \n    and its estimation, is described in McGonigle, Killick and Nunes (2022a) \n    <doi:10.1111/jtsa.12643>, (2022b) <doi:10.1214/22-EJS2044>. New users will \n    likely want to start with the TLSW function.  "
  },
  {
    "id": 7822,
    "package_name": "TrendTM",
    "title": "Trend of High-Dimensional Time Series Matrix Estimation",
    "description": "Matrix factorization for multivariate time series with both low rank and temporal structures. \n    The procedure is the one proposed by Alquier, P. and Marie, N. \n    \"Matrix factorization for multivariate time series analysis.\" \n    Electronic Journal of Statistics, 13(2), 4346-4366 (2019).",
    "version": "2.0.21",
    "maintainer": "Emilie Lebarbier <emilie.lebarbier@parisnanterre.fr>",
    "author": "Emilie Lebarbier [aut, cre],\n  Nicolas Marie [aut],\n  Am\u00e9lie Rosier [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TrendTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TrendTM Trend of High-Dimensional Time Series Matrix Estimation Matrix factorization for multivariate time series with both low rank and temporal structures. \n    The procedure is the one proposed by Alquier, P. and Marie, N. \n    \"Matrix factorization for multivariate time series analysis.\" \n    Electronic Journal of Statistics, 13(2), 4346-4366 (2019).  "
  },
  {
    "id": 7863,
    "package_name": "UComp",
    "title": "Automatic Univariate Time Series Modelling of many Kinds",
    "description": "Comprehensive analysis and forecasting \n             of univariate time series using automatic \n             time series models of many kinds.\n             Harvey AC (1989) <doi:10.1017/CBO9781107049994>.\n             Pedregal DJ and Young PC (2002) <doi:10.1002/9780470996430>.\n             Durbin J and Koopman SJ (2012) <doi:10.1093/acprof:oso/9780199641178.001.0001>.\n             Hyndman RJ, Koehler AB, Ord JK, and Snyder RD (2008) <doi:10.1007/978-3-540-71918-2>.\n             G\u00f3mez V, Maravall A (2000) <doi:10.1002/9781118032978>.\n             Pedregal DJ, Trapero JR and Holgado E (2024) <doi:10.1016/j.ijforecast.2023.09.004>.",
    "version": "5.1.5",
    "maintainer": "Diego J. Pedregal <diego.pedregal@uclm.es>",
    "author": "Diego J. Pedregal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4958-0969>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=UComp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "UComp Automatic Univariate Time Series Modelling of many Kinds Comprehensive analysis and forecasting \n             of univariate time series using automatic \n             time series models of many kinds.\n             Harvey AC (1989) <doi:10.1017/CBO9781107049994>.\n             Pedregal DJ and Young PC (2002) <doi:10.1002/9780470996430>.\n             Durbin J and Koopman SJ (2012) <doi:10.1093/acprof:oso/9780199641178.001.0001>.\n             Hyndman RJ, Koehler AB, Ord JK, and Snyder RD (2008) <doi:10.1007/978-3-540-71918-2>.\n             G\u00f3mez V, Maravall A (2000) <doi:10.1002/9781118032978>.\n             Pedregal DJ, Trapero JR and Holgado E (2024) <doi:10.1016/j.ijforecast.2023.09.004>.  "
  },
  {
    "id": 7865,
    "package_name": "UGarima",
    "title": "The Unit-Garima Distribution",
    "description": "Density, distribution function, quantile function, and random generating function of the Unit-Garima distribution\n    based on Ayuyuen, S., & Bodhisuwan, W. (2024)<doi:10.18187/pjsor.v20i1.4307>. ",
    "version": "0.1.0",
    "maintainer": "Atchanut Rattanalertnusorn <atchanut_r@rmutt.ac.th>",
    "author": "Atchanut Rattanalertnusorn [aut, cre],\n  Sirinapa Ayuyuen [aut],\n  Winai Bodhisuwan [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=UGarima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "UGarima The Unit-Garima Distribution Density, distribution function, quantile function, and random generating function of the Unit-Garima distribution\n    based on Ayuyuen, S., & Bodhisuwan, W. (2024)<doi:10.18187/pjsor.v20i1.4307>.   "
  },
  {
    "id": 7868,
    "package_name": "UKgrid",
    "title": "The UK National Electricity Transmission System Dataset",
    "description": "A time series of the national grid demand (high-voltage electric power transmission network) in the UK since 2011.",
    "version": "0.1.3",
    "maintainer": "Rami Krispin <rami.krispin@gmail.com>",
    "author": "Rami Krispin [aut, cre],\n  Lior Krispin [ctb]",
    "url": "https://github.com/RamiKrispin/UKgrid",
    "bug_reports": "https://github.com/RamiKrispin/UKgrid/issues",
    "repository": "https://cran.r-project.org/package=UKgrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "UKgrid The UK National Electricity Transmission System Dataset A time series of the national grid demand (high-voltage electric power transmission network) in the UK since 2011.  "
  },
  {
    "id": 7879,
    "package_name": "USgrid",
    "title": "The Demand and Supply for Electricity in the US",
    "description": "Provides a set of regular time-series datasets, describing the US electricity grid. That includes the total demand and supply, and as well as the demand by energy source (coal, solar, wind, etc.). Source: US Energy Information Administration (Dec 2019) <https://www.eia.gov/>.",
    "version": "0.1.2",
    "maintainer": "Rami Krispin <rami.krispin@gmail.com>",
    "author": "Rami Krispin [aut, cre]",
    "url": "https://github.com/RamiKrispin/USgrid",
    "bug_reports": "https://github.com/RamiKrispin/USgrid/issues",
    "repository": "https://cran.r-project.org/package=USgrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "USgrid The Demand and Supply for Electricity in the US Provides a set of regular time-series datasets, describing the US electricity grid. That includes the total demand and supply, and as well as the demand by energy source (coal, solar, wind, etc.). Source: US Energy Information Administration (Dec 2019) <https://www.eia.gov/>.  "
  },
  {
    "id": 7912,
    "package_name": "VAR.spec",
    "title": "Allows Specifying a Bivariate VAR (Vector Autoregression) with\nDesired Spectral Characteristics",
    "description": "The spectral characteristics of a bivariate series (Marginal Spectra, Coherency- and Phase-Spectrum) determine whether there is a strong presence of short-, medium-, or long-term fluctuations (components of certain frequencies in the spectral representation of the series) in each one of them.  These are induced by strong peaks of the marginal spectra of each series at the corresponding frequencies. The spectral characteristics also determine how strongly these short-, medium-, or long-term fluctuations of the two series are correlated between the two series. Information on this is provided by the Coherency spectrum at the corresponding frequencies. Finally, certain fluctuations of the two series may be lagged to each other. Information on this is provided by the Phase spectrum at the corresponding frequencies. The idea in this package is to define a VAR (Vector autoregression) model with desired spectral characteristics by specifying a number of polynomials, required to define the VAR. See Ioannidis(2007) <doi:10.1016/j.jspi.2005.12.013>. These are specified via their roots, instead of via their coefficients. This is an idea borrowed from the Time Series Library of R. Dahlhaus, where it is used for defining ARMA models for univariate time series. This way, one may e.g. specify a VAR inducing a strong presence of long-term fluctuations in series 1 and in series 2, which are weakly correlated, but lagged by a number of time units to each other, while short-term fluctuations in series 1 and in series 2, are strongly present only in one of the two series, while they are strongly correlated to each other between the two series. Simulation from such models allows studying the behavior of data-analysis tools, such as estimation of the spectra, under different circumstances, as e.g. peaks in the spectra, generating bias, induced by leakage.",
    "version": "1.0",
    "maintainer": "Evangelos Ioannidis <eioannid@aueb.gr>",
    "author": "Evangelos Ioannidis [cre, aut, cph],\n  Panagiotis Papastamoulis [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VAR.spec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VAR.spec Allows Specifying a Bivariate VAR (Vector Autoregression) with\nDesired Spectral Characteristics The spectral characteristics of a bivariate series (Marginal Spectra, Coherency- and Phase-Spectrum) determine whether there is a strong presence of short-, medium-, or long-term fluctuations (components of certain frequencies in the spectral representation of the series) in each one of them.  These are induced by strong peaks of the marginal spectra of each series at the corresponding frequencies. The spectral characteristics also determine how strongly these short-, medium-, or long-term fluctuations of the two series are correlated between the two series. Information on this is provided by the Coherency spectrum at the corresponding frequencies. Finally, certain fluctuations of the two series may be lagged to each other. Information on this is provided by the Phase spectrum at the corresponding frequencies. The idea in this package is to define a VAR (Vector autoregression) model with desired spectral characteristics by specifying a number of polynomials, required to define the VAR. See Ioannidis(2007) <doi:10.1016/j.jspi.2005.12.013>. These are specified via their roots, instead of via their coefficients. This is an idea borrowed from the Time Series Library of R. Dahlhaus, where it is used for defining ARMA models for univariate time series. This way, one may e.g. specify a VAR inducing a strong presence of long-term fluctuations in series 1 and in series 2, which are weakly correlated, but lagged by a number of time units to each other, while short-term fluctuations in series 1 and in series 2, are strongly present only in one of the two series, while they are strongly correlated to each other between the two series. Simulation from such models allows studying the behavior of data-analysis tools, such as estimation of the spectra, under different circumstances, as e.g. peaks in the spectra, generating bias, induced by leakage.  "
  },
  {
    "id": 7914,
    "package_name": "VARcpDetectOnline",
    "title": "Sequential Change Point Detection for High-Dimensional VAR\nModels",
    "description": "Implements the algorithm introduced in Tian, Y., and Safikhani, A. (2024)\n    <doi:10.5705/ss.202024.0182>, \"Sequential Change Point Detection in High-dimensional \n    Vector Auto-regressive Models\". This package provides tools for detecting change points \n    in the transition matrices of VAR models, effectively identifying shifts in temporal \n    and cross-correlations within high-dimensional time series data.",
    "version": "0.2.0",
    "maintainer": "Yuhan Tian <yuhan.tian@ufl.edu>",
    "author": "Yuhan Tian [aut, cre],\n  Abolfazl Safikhani [aut]",
    "url": "https://github.com/Helloworld9293/VARcpDetectOnline",
    "bug_reports": "https://github.com/Helloworld9293/VARcpDetectOnline/issues",
    "repository": "https://cran.r-project.org/package=VARcpDetectOnline",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VARcpDetectOnline Sequential Change Point Detection for High-Dimensional VAR\nModels Implements the algorithm introduced in Tian, Y., and Safikhani, A. (2024)\n    <doi:10.5705/ss.202024.0182>, \"Sequential Change Point Detection in High-dimensional \n    Vector Auto-regressive Models\". This package provides tools for detecting change points \n    in the transition matrices of VAR models, effectively identifying shifts in temporal \n    and cross-correlations within high-dimensional time series data.  "
  },
  {
    "id": 7915,
    "package_name": "VARshrink",
    "title": "Shrinkage Estimation Methods for Vector Autoregressive Models",
    "description": "\n    Vector autoregressive (VAR) model is a fundamental and effective approach\n    for multivariate time series analysis. Shrinkage estimation methods can be\n    applied to high-dimensional VAR models with dimensionality greater than\n    the number of observations, contrary to the standard ordinary least squares\n    method. This package is an integrative package delivering nonparametric,\n    parametric, and semiparametric methods in a unified and consistent manner,\n    such as the multivariate ridge regression in Golub, Heath, and Wahba (1979)\n    <doi:10.2307/1268518>, a James-Stein type nonparametric shrinkage method in\n    Opgen-Rhein and Strimmer (2007) <doi:10.1186/1471-2105-8-S2-S3>, and\n    Bayesian estimation methods using noninformative and informative priors\n    in Lee, Choi, and S.-H. Kim (2016) <doi:10.1016/j.csda.2016.03.007> and\n    Ni and Sun (2005) <doi:10.1198/073500104000000622>.",
    "version": "0.3.1",
    "maintainer": "Namgil Lee <namgil.lee@kangwon.ac.kr>",
    "author": "Namgil Lee [aut, cre] (ORCID: <https://orcid.org/0000-0003-0593-9028>),\n  Heon Young Yang [ctb],\n  Sung-Ho Kim [aut]",
    "url": "https://github.com/namgillee/VARshrink/",
    "bug_reports": "https://github.com/namgillee/VARshrink/issues/",
    "repository": "https://cran.r-project.org/package=VARshrink",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VARshrink Shrinkage Estimation Methods for Vector Autoregressive Models \n    Vector autoregressive (VAR) model is a fundamental and effective approach\n    for multivariate time series analysis. Shrinkage estimation methods can be\n    applied to high-dimensional VAR models with dimensionality greater than\n    the number of observations, contrary to the standard ordinary least squares\n    method. This package is an integrative package delivering nonparametric,\n    parametric, and semiparametric methods in a unified and consistent manner,\n    such as the multivariate ridge regression in Golub, Heath, and Wahba (1979)\n    <doi:10.2307/1268518>, a James-Stein type nonparametric shrinkage method in\n    Opgen-Rhein and Strimmer (2007) <doi:10.1186/1471-2105-8-S2-S3>, and\n    Bayesian estimation methods using noninformative and informative priors\n    in Lee, Choi, and S.-H. Kim (2016) <doi:10.1016/j.csda.2016.03.007> and\n    Ni and Sun (2005) <doi:10.1198/073500104000000622>.  "
  },
  {
    "id": 7921,
    "package_name": "VBV",
    "title": "The Generalized Berlin Method for Time Series Decomposition",
    "description": "Time series decomposition for univariate time series using the\n    \"Verallgemeinerte Berliner Verfahren\" (Generalized Berlin Method) as\n    described in 'Kontinuierliche Messgr\u00f6\u00dfen und Stichprobenstrategien in\n    Raum und Zeit mit Anwendungen in den Natur-, Umwelt-, Wirtschafts-\n    und Finanzwissenschaften', by\n    Hebbel and Steuer, Springer Berlin Heidelberg, 2022\n    <doi:10.1007/978-3-662-65638-9>, or\n    'Decomposition of Time Series using the Generalised Berlin \n    Method (VBV)' by Hebbel and Steuer, in Jan Beran, Yuanhua Feng, Hartmut\n    Hebbel (Eds.): Empirical Economic and Financial Research - Theory,\n    Methods and Practice, Festschrift in Honour of Prof. Siegfried Heiler.\n    Series: Advanced Studies in Theoretical and Applied Econometrics.\n    Springer 2014, p. 9-40.",
    "version": "0.6.2",
    "maintainer": "Detlef Steuer <steuer@hsu-hh.de>",
    "author": "Detlef Steuer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2676-5290>),\n  Hartmut Hebbel [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VBV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VBV The Generalized Berlin Method for Time Series Decomposition Time series decomposition for univariate time series using the\n    \"Verallgemeinerte Berliner Verfahren\" (Generalized Berlin Method) as\n    described in 'Kontinuierliche Messgr\u00f6\u00dfen und Stichprobenstrategien in\n    Raum und Zeit mit Anwendungen in den Natur-, Umwelt-, Wirtschafts-\n    und Finanzwissenschaften', by\n    Hebbel and Steuer, Springer Berlin Heidelberg, 2022\n    <doi:10.1007/978-3-662-65638-9>, or\n    'Decomposition of Time Series using the Generalised Berlin \n    Method (VBV)' by Hebbel and Steuer, in Jan Beran, Yuanhua Feng, Hartmut\n    Hebbel (Eds.): Empirical Economic and Financial Research - Theory,\n    Methods and Practice, Festschrift in Honour of Prof. Siegfried Heiler.\n    Series: Advanced Studies in Theoretical and Applied Econometrics.\n    Springer 2014, p. 9-40.  "
  },
  {
    "id": 7938,
    "package_name": "VGAMextra",
    "title": "Additions and Extensions of the 'VGAM' Package",
    "description": "Extending the functionalities of the 'VGAM' package with\n         additional functions and datasets. At present, 'VGAMextra'\n         comprises new family functions (ffs) to estimate several time\n         series models by maximum likelihood using Fisher scoring, \n         unlike popular packages in CRAN relying on optim(), including\n         ARMA-GARCH-like models, the Order-(p, d, q) ARIMAX model (non-\n         seasonal), the Order-(p) VAR model, error correction models\n         for cointegrated time series, and ARMA-structures with Student-t \n         errors. For independent data, new ffs to estimate the inverse-\n         Weibull, the inverse-gamma, the generalized beta of the second\n         kind and the general multivariate normal distributions are\n         available. In addition, 'VGAMextra' incorporates new VGLM-links\n         for the mean-function, and the quantile-function (as an alternative\n         to ordinary quantile modelling) of several 1-parameter distributions,\n         that are compatible with the class of VGLM/VGAM family functions.\n         Currently, only fixed-effects models are implemented. All functions\n         are subject to change; see the NEWS for further details on the\n         latest changes.",
    "version": "0.0-9",
    "maintainer": "Victor Miranda <victor.miranda@aut.ac.nz>",
    "author": "Victor Miranda [aut, cre, cph],\n  Thomas Yee [ctb, ths, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VGAMextra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VGAMextra Additions and Extensions of the 'VGAM' Package Extending the functionalities of the 'VGAM' package with\n         additional functions and datasets. At present, 'VGAMextra'\n         comprises new family functions (ffs) to estimate several time\n         series models by maximum likelihood using Fisher scoring, \n         unlike popular packages in CRAN relying on optim(), including\n         ARMA-GARCH-like models, the Order-(p, d, q) ARIMAX model (non-\n         seasonal), the Order-(p) VAR model, error correction models\n         for cointegrated time series, and ARMA-structures with Student-t \n         errors. For independent data, new ffs to estimate the inverse-\n         Weibull, the inverse-gamma, the generalized beta of the second\n         kind and the general multivariate normal distributions are\n         available. In addition, 'VGAMextra' incorporates new VGLM-links\n         for the mean-function, and the quantile-function (as an alternative\n         to ordinary quantile modelling) of several 1-parameter distributions,\n         that are compatible with the class of VGLM/VGAM family functions.\n         Currently, only fixed-effects models are implemented. All functions\n         are subject to change; see the NEWS for further details on the\n         latest changes.  "
  },
  {
    "id": 7946,
    "package_name": "VIRF",
    "title": "Computation of Volatility Impulse Response Function of\nMultivariate Time Series",
    "description": "Computation of volatility impulse response function for multivariate time series model using algorithm by Jin, Lin and Tamvakis (2012) <doi:10.1016/j.eneco.2012.03.003>.",
    "version": "0.1.1",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut, cre],\n  Dr. Md Yeasin [aut],\n  Mr. Ankit Tanwar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VIRF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VIRF Computation of Volatility Impulse Response Function of\nMultivariate Time Series Computation of volatility impulse response function for multivariate time series model using algorithm by Jin, Lin and Tamvakis (2012) <doi:10.1016/j.eneco.2012.03.003>.  "
  },
  {
    "id": 7949,
    "package_name": "VLMCX",
    "title": "Variable Length Markov Chain with Exogenous Covariates",
    "description": "Models categorical time series through a Markov Chain when a) covariates are predictors for transitioning into the next state/symbol and b) when the dependence in the past states has variable length. The probability of transitioning to the next state in the Markov Chain is defined by a multinomial regression whose parameters depend on the past states of the chain and, moreover, the number of states in the past needed to predict the next state also depends on the observed states themselves. See Zambom, Kim, and Garcia (2022) <doi:10.1111/jtsa.12615>.",
    "version": "1.0",
    "maintainer": "Adriano Zanin Zambom Developer <adriano.zambom@gmail.com>",
    "author": "Adriano Zanin Zambom Developer [aut, cre, cph],\n  Seonjin Kim Developer [aut],\n  Nancy Lopes Garcia Developer [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VLMCX",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VLMCX Variable Length Markov Chain with Exogenous Covariates Models categorical time series through a Markov Chain when a) covariates are predictors for transitioning into the next state/symbol and b) when the dependence in the past states has variable length. The probability of transitioning to the next state in the Markov Chain is defined by a multinomial regression whose parameters depend on the past states of the chain and, moreover, the number of states in the past needed to predict the next state also depends on the observed states themselves. See Zambom, Kim, and Garcia (2022) <doi:10.1111/jtsa.12615>.  "
  },
  {
    "id": 7950,
    "package_name": "VLTimeCausality",
    "title": "Variable-Lag Time Series Causality Inference Framework",
    "description": "A framework to infer causality on a pair of time series of real numbers based on variable-lag Granger causality and transfer entropy. Typically, Granger causality and transfer entropy have an assumption of a fixed and constant time delay between the cause and effect. However, for a non-stationary time series, this assumption is not true. For example, considering two time series of velocity of person A and person B where B follows A. At some time, B stops tying his shoes, then running to catch up A. The fixed-lag assumption is not true in this case. We propose a framework that allows variable-lags between cause and effect in Granger causality and transfer entropy to allow them to deal with variable-lag non-stationary time series. Please see Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf (2021) <doi:10.1145/3441452> when referring to this package in publications.  ",
    "version": "0.1.5",
    "maintainer": "Chainarong Amornbunchornvej <grandca@gmail.com>",
    "author": "Chainarong Amornbunchornvej [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3131-0370>)",
    "url": "https://github.com/DarkEyes/VLTimeSeriesCausality",
    "bug_reports": "https://github.com/DarkEyes/VLTimeSeriesCausality/issues",
    "repository": "https://cran.r-project.org/package=VLTimeCausality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VLTimeCausality Variable-Lag Time Series Causality Inference Framework A framework to infer causality on a pair of time series of real numbers based on variable-lag Granger causality and transfer entropy. Typically, Granger causality and transfer entropy have an assumption of a fixed and constant time delay between the cause and effect. However, for a non-stationary time series, this assumption is not true. For example, considering two time series of velocity of person A and person B where B follows A. At some time, B stops tying his shoes, then running to catch up A. The fixed-lag assumption is not true in this case. We propose a framework that allows variable-lags between cause and effect in Granger causality and transfer entropy to allow them to deal with variable-lag non-stationary time series. Please see Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf (2021) <doi:10.1145/3441452> when referring to this package in publications.    "
  },
  {
    "id": 7951,
    "package_name": "VMDML",
    "title": "Variational Mode Decomposition Based Machine Learning Models",
    "description": "Application of Variational Mode Decomposition based different Machine Learning models for univariate time series forecasting. For method details see (i) K. Dragomiretskiy and D. Zosso (2014) <doi:10.1109/TSP.2013.2288675>; (ii)  Pankaj Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/44138>.",
    "version": "0.1.1",
    "maintainer": "Pankaj Das <pankaj.das2@icar.gov.in>",
    "author": "Pankaj Das [aut, cre],\n  Girish Kumar Jha [aut],\n  Tauqueer Ahmad [aut],\n  Achal Lama [aut],\n  Lampros Mouselimis [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VMDML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VMDML Variational Mode Decomposition Based Machine Learning Models Application of Variational Mode Decomposition based different Machine Learning models for univariate time series forecasting. For method details see (i) K. Dragomiretskiy and D. Zosso (2014) <doi:10.1109/TSP.2013.2288675>; (ii)  Pankaj Das (2020) <http://krishi.icar.gov.in/jspui/handle/123456789/44138>.  "
  },
  {
    "id": 7970,
    "package_name": "VedicDateTime",
    "title": "Vedic Calendar System",
    "description": "Provides platform for Vedic calendar system having several\n    functionalities to facilitate conversion between Gregorian and Vedic\n    calendar systems, and helpful in examining its impact in the\n    time series analysis domain.",
    "version": "0.1.9",
    "maintainer": "Neeraj Dhanraj Bokde <neerajdhanraj@gmail.com>",
    "author": "Neeraj Dhanraj Bokde [aut, cre, cph],\n  Prajwal Kailasnath Patil [aut],\n  Saradindu Sengupta [aut],\n  Andr\u00e9s El\u00edas Feij\u00f3o Lorenzo [aut]",
    "url": "https://www.neerajbokde.in/viggnette/2022-09-05-VedicDateTime",
    "bug_reports": "https://github.com/prajwalkpatil/VedicDateTime/issues",
    "repository": "https://cran.r-project.org/package=VedicDateTime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VedicDateTime Vedic Calendar System Provides platform for Vedic calendar system having several\n    functionalities to facilitate conversion between Gregorian and Vedic\n    calendar systems, and helpful in examining its impact in the\n    time series analysis domain.  "
  },
  {
    "id": 7985,
    "package_name": "VisitorCounts",
    "title": "Modeling and Forecasting Visitor Counts Using Social Media",
    "description": "Performs modeling and forecasting of park visitor counts\n\tusing social media data and (partial) on-site visitor counts.\n\tSpecifically, the model is built based on an automatic decomposition\n\tof the trend and seasonal components of the social media-based park visitor counts,\n\tfrom which short-term forecasts of the visitor counts and percent changes\n\tin the visitor counts can be made. A reference for the underlying model that 'VisitorCounts' uses can be found at \n    Russell Goebel, Austin Schmaltz, Beth Ann Brackett, Spencer A. Wood, Kimihiro Noguchi (2023) <doi:10.1002/for.2965> .",
    "version": "2.0.3",
    "maintainer": "Robert Bowen <robertbowen.bham@gmail.com>",
    "author": "Robert Bowen [aut, cre],\n  Russell Goebel [aut],\n  Beth Ann Brackett [ctb],\n  Kimihiro Noguchi [aut],\n  Dylan Way [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VisitorCounts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VisitorCounts Modeling and Forecasting Visitor Counts Using Social Media Performs modeling and forecasting of park visitor counts\n\tusing social media data and (partial) on-site visitor counts.\n\tSpecifically, the model is built based on an automatic decomposition\n\tof the trend and seasonal components of the social media-based park visitor counts,\n\tfrom which short-term forecasts of the visitor counts and percent changes\n\tin the visitor counts can be made. A reference for the underlying model that 'VisitorCounts' uses can be found at \n    Russell Goebel, Austin Schmaltz, Beth Ann Brackett, Spencer A. Wood, Kimihiro Noguchi (2023) <doi:10.1002/for.2965> .  "
  },
  {
    "id": 7986,
    "package_name": "VisualDom",
    "title": "Visualize Dominant Variables in Wavelet Multiple Correlation",
    "description": "Estimates and plots as a heat map the correlation coefficients obtained via the wavelet local multiple correlation 'WLMC' (Fern\u00e1ndez-Macho 2018) and the 'dominant' variable/s, i.e., the variable/s that maximizes the multiple correlation through time and scale (Polanco-Mart\u00ednez et al. 2020, Polanco-Mart\u00ednez 2022). We improve the graphical outputs of WLMC proposing a didactic and useful way to visualize the 'dominant' variable(s) for a set of time series. The WLMC was designed for financial time series, but other kinds of data (e.g., climatic, ecological, etc.) can be used. The functions contained in 'VisualDom' are highly flexible since these contains several parameters to personalize the time series under analysis and the heat maps. In addition, we have also included two data sets (named 'rdata_climate' and 'rdata_Lorenz') to exemplify the use of the functions contained in 'VisualDom'. Methods derived from Fern\u00e1ndez-Macho (2018) <doi:10.1016/j.physa.2017.11.050>, Polanco-Mart\u00ednez et al. (2020) <doi:10.1038/s41598-020-77767-8> and Polanco-Mart\u00ednez (2023, in press). ",
    "version": "0.8.0",
    "maintainer": "Josu\u00e9 M. Polanco-Mart\u00ednez <josue.m.polanco@gmail.com>",
    "author": "Josu\u00e9 M. Polanco-Mart\u00ednez [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VisualDom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VisualDom Visualize Dominant Variables in Wavelet Multiple Correlation Estimates and plots as a heat map the correlation coefficients obtained via the wavelet local multiple correlation 'WLMC' (Fern\u00e1ndez-Macho 2018) and the 'dominant' variable/s, i.e., the variable/s that maximizes the multiple correlation through time and scale (Polanco-Mart\u00ednez et al. 2020, Polanco-Mart\u00ednez 2022). We improve the graphical outputs of WLMC proposing a didactic and useful way to visualize the 'dominant' variable(s) for a set of time series. The WLMC was designed for financial time series, but other kinds of data (e.g., climatic, ecological, etc.) can be used. The functions contained in 'VisualDom' are highly flexible since these contains several parameters to personalize the time series under analysis and the heat maps. In addition, we have also included two data sets (named 'rdata_climate' and 'rdata_Lorenz') to exemplify the use of the functions contained in 'VisualDom'. Methods derived from Fern\u00e1ndez-Macho (2018) <doi:10.1016/j.physa.2017.11.050>, Polanco-Mart\u00ednez et al. (2020) <doi:10.1038/s41598-020-77767-8> and Polanco-Mart\u00ednez (2023, in press).   "
  },
  {
    "id": 7993,
    "package_name": "VoxR",
    "title": "Trees Geometry and Morphology from Unstructured TLS Data",
    "description": "Tools for 3D point cloud voxelisation, projection, geometrical and morphological description of trees (DBH, height, volume, crown diameter), analyses of temporal changes between different measurement times, distance based clustering and visualisation of 3D voxel clouds and 2D projection. Most analyses and algorithms provided in the package are based on the concept of space exploration and are described in Lecigne et al. (2018, <doi:10.1093/aob/mcx095>).",
    "version": "1.0.0",
    "maintainer": "Bastien Lecigne <lecignebastien@gmail.com>",
    "author": "Bastien Lecigne [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1496-202X>)",
    "url": "https://github.com/Blecigne/VoxR",
    "bug_reports": "https://github.com/Blecigne/VoxR/issues",
    "repository": "https://cran.r-project.org/package=VoxR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VoxR Trees Geometry and Morphology from Unstructured TLS Data Tools for 3D point cloud voxelisation, projection, geometrical and morphological description of trees (DBH, height, volume, crown diameter), analyses of temporal changes between different measurement times, distance based clustering and visualisation of 3D voxel clouds and 2D projection. Most analyses and algorithms provided in the package are based on the concept of space exploration and are described in Lecigne et al. (2018, <doi:10.1093/aob/mcx095>).  "
  },
  {
    "id": 7996,
    "package_name": "W2CWM2C",
    "title": "A Graphical Tool for Wavelet (Cross) Correlation and Wavelet\nMultiple (Cross) Correlation Analysis",
    "description": "Set of functions that improves the graphical presentations of the functions: wave.correlation and spin.correlation (waveslim package, Whitcher 2012) and the wave.multiple.correlation and wave.multiple.cross.correlation (wavemulcor package, Fernandez-Macho 2012b). The plot outputs (heatmaps) can be displayed in the screen or can be saved as PNG or JPG images or as PDF or EPS formats. The W2CWM2C package also helps to handle the (input data) multivariate time series easily as a list of N elements (times series) and provides a multivariate data set (dataexample) to exemplify its use. A description of the package was published in a scientific paper: Polanco-Martinez and Fernandez-Macho (2014), <doi:10.1109/MCSE.2014.96>. ",
    "version": "2.2",
    "maintainer": "Josue M. Polanco-Martinez <josue.m.polanco@gmail.com>",
    "author": "Josue M. Polanco-Martinez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>)",
    "url": "https://github.com/jomopo/W2CWM2C",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=W2CWM2C",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "W2CWM2C A Graphical Tool for Wavelet (Cross) Correlation and Wavelet\nMultiple (Cross) Correlation Analysis Set of functions that improves the graphical presentations of the functions: wave.correlation and spin.correlation (waveslim package, Whitcher 2012) and the wave.multiple.correlation and wave.multiple.cross.correlation (wavemulcor package, Fernandez-Macho 2012b). The plot outputs (heatmaps) can be displayed in the screen or can be saved as PNG or JPG images or as PDF or EPS formats. The W2CWM2C package also helps to handle the (input data) multivariate time series easily as a list of N elements (times series) and provides a multivariate data set (dataexample) to exemplify its use. A description of the package was published in a scientific paper: Polanco-Martinez and Fernandez-Macho (2014), <doi:10.1109/MCSE.2014.96>.   "
  },
  {
    "id": 8022,
    "package_name": "WQM",
    "title": "Wavelet-Based Quantile Mapping for Postprocessing Numerical\nWeather Predictions",
    "description": "The wavelet-based quantile mapping (WQM) technique is designed to correct biases in spatio-temporal precipitation forecasts across multiple time scales. The WQM method effectively enhances forecast accuracy by generating an ensemble of precipitation forecasts that account for uncertainties in the prediction process. For a comprehensive overview of the methodologies employed in this package, please refer to Jiang, Z., and Johnson, F. (2023) <doi:10.1029/2022EF003350>. The package relies on two packages for continuous wavelet transforms: 'WaveletComp', which can be installed automatically, and 'wmtsa', which is optional and available from the CRAN archive <https://cran.r-project.org/src/contrib/Archive/wmtsa/>. Users need to manually install 'wmtsa' from this archive if they prefer to use 'wmtsa' based decomposition.",
    "version": "0.1.4",
    "maintainer": "Ze Jiang <ze.jiang@unsw.edu.au>",
    "author": "Ze Jiang [aut, cre] (ORCID: <https://orcid.org/0000-0002-3472-0829>),\n  Fiona Johnson [aut] (ORCID: <https://orcid.org/0000-0001-5708-1807>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WQM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WQM Wavelet-Based Quantile Mapping for Postprocessing Numerical\nWeather Predictions The wavelet-based quantile mapping (WQM) technique is designed to correct biases in spatio-temporal precipitation forecasts across multiple time scales. The WQM method effectively enhances forecast accuracy by generating an ensemble of precipitation forecasts that account for uncertainties in the prediction process. For a comprehensive overview of the methodologies employed in this package, please refer to Jiang, Z., and Johnson, F. (2023) <doi:10.1029/2022EF003350>. The package relies on two packages for continuous wavelet transforms: 'WaveletComp', which can be installed automatically, and 'wmtsa', which is optional and available from the CRAN archive <https://cran.r-project.org/src/contrib/Archive/wmtsa/>. Users need to manually install 'wmtsa' from this archive if they prefer to use 'wmtsa' based decomposition.  "
  },
  {
    "id": 8025,
    "package_name": "WRTDStidal",
    "title": "Weighted Regression for Water Quality Evaluation in Tidal Waters",
    "description": "An adaptation for estuaries (tidal waters) of weighted regression\n    on time, discharge, and season to evaluate trends in water quality time series. \n    Please see Beck and Hagy (2015) <doi:10.1007/s10666-015-9452-8> for \n    details.",
    "version": "1.1.4",
    "maintainer": "Marcus W. Beck <mbeck@tbep.org>",
    "author": "Marcus W. Beck [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/fawda123/WRTDStidal/issues",
    "repository": "https://cran.r-project.org/package=WRTDStidal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WRTDStidal Weighted Regression for Water Quality Evaluation in Tidal Waters An adaptation for estuaries (tidal waters) of weighted regression\n    on time, discharge, and season to evaluate trends in water quality time series. \n    Please see Beck and Hagy (2015) <doi:10.1007/s10666-015-9452-8> for \n    details.  "
  },
  {
    "id": 8032,
    "package_name": "WarnEpi",
    "title": "A Comprehensive Tool for Early Warning in Infectious Disease",
    "description": "\n    Infectious disease surveillance requires early outbreak detection. This\n    package provides statistical tools for analyzing time-series monitoring \n    data through three core methods: \n    a) EWMA (Exponentially Weighted Moving Average)\n    b) Modified-CUSUM (Modified Cumulative Sum)\n    c) Adjusted-Serfling models\n    Methodologies are based on:\n    - Wang et al. (2010) <doi:10.1016/j.jbi.2009.08.003>\n    - Wang et al. (2015) <doi:10.1371/journal.pone.0119923>\n    Designed for epidemiologists and public health researchers working with\n    disease surveillance systems.",
    "version": "1.0.1",
    "maintainer": "Mingyue Pan <panmyue18@163.com>",
    "author": "Xiaoli Wang [aut],\n  Mingyue Pan [aut, cre]",
    "url": "https://github.com/pan-mingyue/WarnEpi",
    "bug_reports": "https://github.com/pan-mingyue/WarnEpi/issues",
    "repository": "https://cran.r-project.org/package=WarnEpi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WarnEpi A Comprehensive Tool for Early Warning in Infectious Disease \n    Infectious disease surveillance requires early outbreak detection. This\n    package provides statistical tools for analyzing time-series monitoring \n    data through three core methods: \n    a) EWMA (Exponentially Weighted Moving Average)\n    b) Modified-CUSUM (Modified Cumulative Sum)\n    c) Adjusted-Serfling models\n    Methodologies are based on:\n    - Wang et al. (2010) <doi:10.1016/j.jbi.2009.08.003>\n    - Wang et al. (2015) <doi:10.1371/journal.pone.0119923>\n    Designed for epidemiologists and public health researchers working with\n    disease surveillance systems.  "
  },
  {
    "id": 8033,
    "package_name": "Wats",
    "title": "Wrap Around Time Series Graphics",
    "description": "Wrap-around Time Series (WATS) plots for interrupted time series\n    designs with seasonal patterns.\n    Longitudinal trajectories are shown in both Cartesian and polar coordinates.\n    In many scenarios, a WATS plot more clearly shows the existence and effect size of\n    of an intervention.\n    This package accompanies\n    \"Graphical Data Analysis on the Circle: Wrap-Around Time Series Plots for (Interrupted) Time Series Designs\"\n    by Rodgers, Beasley, & Schuelke (2014)\n    <doi:10.1080/00273171.2014.946589>;\n    see 'citation(\"Wats\")' for details.",
    "version": "1.0.1",
    "maintainer": "Will Beasley <wibeasley@hotmail.com>",
    "author": "Will Beasley [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5613-5006>),\n  Joe Rodgers [aut],\n  Matthew Schuelke [ctb],\n  Ronnie Coleman [ctb],\n  Mark Joseph Lachowicz [ctb],\n  Oklahoma Shared Clinical and Translational Resource (OSCTR) [fnd]",
    "url": "https://ouhscbbmc.github.io/Wats/,\nhttps://github.com/OuhscBbmc/Wats",
    "bug_reports": "https://github.com/OuhscBbmc/Wats/issues",
    "repository": "https://cran.r-project.org/package=Wats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Wats Wrap Around Time Series Graphics Wrap-around Time Series (WATS) plots for interrupted time series\n    designs with seasonal patterns.\n    Longitudinal trajectories are shown in both Cartesian and polar coordinates.\n    In many scenarios, a WATS plot more clearly shows the existence and effect size of\n    of an intervention.\n    This package accompanies\n    \"Graphical Data Analysis on the Circle: Wrap-Around Time Series Plots for (Interrupted) Time Series Designs\"\n    by Rodgers, Beasley, & Schuelke (2014)\n    <doi:10.1080/00273171.2014.946589>;\n    see 'citation(\"Wats\")' for details.  "
  },
  {
    "id": 8035,
    "package_name": "WaveletANN",
    "title": "Wavelet ANN Model",
    "description": "The wavelet and ANN technique have been combined to reduce the effect of data noise. This wavelet-ANN conjunction model is able to forecast time series data with better accuracy than the traditional time series model. This package fits hybrid Wavelet ANN model for time series forecasting using algorithm by Anjoy and Paul (2017) <DOI: 10.1007/s00521-017-3289-9>.",
    "version": "0.1.2",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut, cre],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletANN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletANN Wavelet ANN Model The wavelet and ANN technique have been combined to reduce the effect of data noise. This wavelet-ANN conjunction model is able to forecast time series data with better accuracy than the traditional time series model. This package fits hybrid Wavelet ANN model for time series forecasting using algorithm by Anjoy and Paul (2017) <DOI: 10.1007/s00521-017-3289-9>.  "
  },
  {
    "id": 8036,
    "package_name": "WaveletArima",
    "title": "Wavelet-ARIMA Model for Time Series Forecasting",
    "description": "Noise in the time-series data significantly affects the accuracy of the ARIMA model. Wavelet transformation decomposes the time series data into subcomponents to reduce the noise and help to improve the model performance. The wavelet-ARIMA model can achieve higher prediction accuracy than the traditional ARIMA model. This package provides Wavelet-ARIMA model for time series forecasting based on the algorithm by Aminghafari and Poggi (2012) and Paul and Anjoy (2018) <doi:10.1142/S0219691307002002> <doi:10.1007/s00704-017-2271-x>.",
    "version": "0.1.2",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut, cre],\n  Mr. Sandipan Samanta [aut],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletArima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletArima Wavelet-ARIMA Model for Time Series Forecasting Noise in the time-series data significantly affects the accuracy of the ARIMA model. Wavelet transformation decomposes the time series data into subcomponents to reduce the noise and help to improve the model performance. The wavelet-ARIMA model can achieve higher prediction accuracy than the traditional ARIMA model. This package provides Wavelet-ARIMA model for time series forecasting based on the algorithm by Aminghafari and Poggi (2012) and Paul and Anjoy (2018) <doi:10.1142/S0219691307002002> <doi:10.1007/s00704-017-2271-x>.  "
  },
  {
    "id": 8037,
    "package_name": "WaveletComp",
    "title": "Computational Wavelet Analysis",
    "description": "Wavelet analysis and reconstruction of time series, cross-wavelets and phase-difference (with filtering options), significance with simulation algorithms.",
    "version": "1.2",
    "maintainer": "Angi Roesch <angi@angi-stat.com>",
    "author": "Angi Roesch [aut, cre],\n  Harald Schmidbauer [aut]",
    "url": "http://www.hs-stat.com/projects/WaveletComp/WaveletComp_guided_tour.pdf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletComp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletComp Computational Wavelet Analysis Wavelet analysis and reconstruction of time series, cross-wavelets and phase-difference (with filtering options), significance with simulation algorithms.  "
  },
  {
    "id": 8038,
    "package_name": "WaveletETS",
    "title": "Wavelet Based Error Trend Seasonality Model",
    "description": "ETS stands for Error, Trend, and Seasonality, and it is a popular time series forecasting method. Wavelet decomposition can be used for denoising, compression, and feature extraction of signals. By removing the high-frequency components, wavelet decomposition can remove noise from the data while preserving important features. A hybrid Wavelet ETS  (Error Trend-Seasonality) model has been developed for time series forecasting using algorithm of Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.",
    "version": "0.1.0",
    "maintainer": "Dr. Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut],\n  Dr. Md Yeasin [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletETS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletETS Wavelet Based Error Trend Seasonality Model ETS stands for Error, Trend, and Seasonality, and it is a popular time series forecasting method. Wavelet decomposition can be used for denoising, compression, and feature extraction of signals. By removing the high-frequency components, wavelet decomposition can remove noise from the data while preserving important features. A hybrid Wavelet ETS  (Error Trend-Seasonality) model has been developed for time series forecasting using algorithm of Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.  "
  },
  {
    "id": 8039,
    "package_name": "WaveletGARCH",
    "title": "Fit the Wavelet-GARCH Model to Volatile Time Series Data",
    "description": "Fits the combination of Wavelet-GARCH model for time series forecasting using algorithm by Paul (2015) <doi:10.3233/MAS-150328>.",
    "version": "0.1.1",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul, Sandipan Samanta and Ankit Tanwar",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletGARCH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletGARCH Fit the Wavelet-GARCH Model to Volatile Time Series Data Fits the combination of Wavelet-GARCH model for time series forecasting using algorithm by Paul (2015) <doi:10.3233/MAS-150328>.  "
  },
  {
    "id": 8040,
    "package_name": "WaveletGBM",
    "title": "Wavelet Based Gradient Boosting Method",
    "description": "Wavelet decomposition method is very useful for modelling noisy time series data. Wavelet decomposition using 'haar' algorithm has been implemented to developed hybrid Wavelet GBM (Gradient Boosting Method) model for time series forecasting using algorithm by Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.",
    "version": "0.1.0",
    "maintainer": "Dr. Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut, cre],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletGBM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletGBM Wavelet Based Gradient Boosting Method Wavelet decomposition method is very useful for modelling noisy time series data. Wavelet decomposition using 'haar' algorithm has been implemented to developed hybrid Wavelet GBM (Gradient Boosting Method) model for time series forecasting using algorithm by Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.  "
  },
  {
    "id": 8041,
    "package_name": "WaveletKNN",
    "title": "Wavelet Based K-Nearest Neighbor Model",
    "description": "The employment of the Wavelet decomposition technique proves to be highly advantageous in the modelling of noisy time series data. Wavelet decomposition technique using the \"haar\" algorithm has been incorporated to formulate a hybrid Wavelet KNN (K-Nearest Neighbour) model for time series forecasting, as proposed by Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.",
    "version": "0.1.0",
    "maintainer": "Dr. Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut],\n  Dr. Md Yeasin [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletKNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletKNN Wavelet Based K-Nearest Neighbor Model The employment of the Wavelet decomposition technique proves to be highly advantageous in the modelling of noisy time series data. Wavelet decomposition technique using the \"haar\" algorithm has been incorporated to formulate a hybrid Wavelet KNN (K-Nearest Neighbour) model for time series forecasting, as proposed by Anjoy and Paul (2017) <DOI:10.1007/s00521-017-3289-9>.  "
  },
  {
    "id": 8045,
    "package_name": "WaveletRF",
    "title": "Wavelet-RF Hybrid Model for Time Series Forecasting",
    "description": "The Wavelet Decomposition followed by Random Forest Regression (RF) models have been applied for time series forecasting. The maximum overlap discrete wavelet transform (MODWT) algorithm was chosen as it works for any length of the series. The series is first divided into training and testing sets. In each of the wavelet decomposed series, the  supervised machine learning approach namely random forest was employed to train the model. This package also provides accuracy metrics in the form of Root Mean Square Error (RMSE) and Mean Absolute Prediction Error (MAPE). This package is based on the algorithm of Ding et al. (2021) <DOI: 10.1007/s11356-020-12298-3>.",
    "version": "0.1.0",
    "maintainer": "Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Ranjit Kumar Paul [aut, cre],\n  Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletRF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletRF Wavelet-RF Hybrid Model for Time Series Forecasting The Wavelet Decomposition followed by Random Forest Regression (RF) models have been applied for time series forecasting. The maximum overlap discrete wavelet transform (MODWT) algorithm was chosen as it works for any length of the series. The series is first divided into training and testing sets. In each of the wavelet decomposed series, the  supervised machine learning approach namely random forest was employed to train the model. This package also provides accuracy metrics in the form of Root Mean Square Error (RMSE) and Mean Absolute Prediction Error (MAPE). This package is based on the algorithm of Ding et al. (2021) <DOI: 10.1007/s11356-020-12298-3>.  "
  },
  {
    "id": 8046,
    "package_name": "WaveletSVR",
    "title": "Wavelet-SVR Hybrid Model for Time Series Forecasting",
    "description": "The main aim of this package is to combine the advantage of wavelet and support vector machine models for time series forecasting. This package also gives the accuracy measurements in terms of RMSE and MAPE. This package fits the hybrid Wavelet SVR model for time series forecasting The main aim of this package is to combine the advantage of wavelet and Support Vector Regression (SVR) models for time series forecasting. This package also gives the accuracy measurements in terms of Root Mean Square Error (RMSE) and Mean Absolute Prediction Error (MAPE). This package is based on the algorithm of Raimundo and Okamoto (2018) <DOI: 10.1109/INFOCT.2018.8356851>.",
    "version": "0.1.0",
    "maintainer": "Ranjit Kumar Paul <ranjitstat@gmail.com>",
    "author": "Ranjit Kumar Paul [aut, cre],\n  Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaveletSVR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaveletSVR Wavelet-SVR Hybrid Model for Time Series Forecasting The main aim of this package is to combine the advantage of wavelet and support vector machine models for time series forecasting. This package also gives the accuracy measurements in terms of RMSE and MAPE. This package fits the hybrid Wavelet SVR model for time series forecasting The main aim of this package is to combine the advantage of wavelet and Support Vector Regression (SVR) models for time series forecasting. This package also gives the accuracy measurements in terms of Root Mean Square Error (RMSE) and Mean Absolute Prediction Error (MAPE). This package is based on the algorithm of Raimundo and Okamoto (2018) <DOI: 10.1109/INFOCT.2018.8356851>.  "
  },
  {
    "id": 8048,
    "package_name": "WaverideR",
    "title": "Extracting Signals from Wavelet Spectra",
    "description": "The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.",
    "version": "0.4.1",
    "maintainer": "Michiel Arts <michiel.arts@stratigraphy.eu>",
    "author": "Michiel Arts [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3181-4608>)",
    "url": "https://github.com/stratigraphy/WaverideR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaverideR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaverideR Extracting Signals from Wavelet Spectra The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.  "
  },
  {
    "id": 8066,
    "package_name": "WeightedEnsemble",
    "title": "Weighted Ensemble for Hybrid Model",
    "description": "The weighted ensemble method is a valuable approach for combining forecasts. This algorithm employs several optimization techniques to generate optimized weights. This package has been developed using algorithm of Armstrong (1989) <doi:10.1016/0024-6301(90)90317-W>.",
    "version": "0.1.0",
    "maintainer": "Dr. Md Yeasin <yeasin.iasri@gmail.com>",
    "author": "Dr. Ranjit Kumar Paul [aut],\n  Dr. Md Yeasin [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WeightedEnsemble",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WeightedEnsemble Weighted Ensemble for Hybrid Model The weighted ensemble method is a valuable approach for combining forecasts. This algorithm employs several optimization techniques to generate optimized weights. This package has been developed using algorithm of Armstrong (1989) <doi:10.1016/0024-6301(90)90317-W>.  "
  },
  {
    "id": 8067,
    "package_name": "WeightedPortTest",
    "title": "Weighted Portmanteau Tests for Time Series Goodness-of-Fit",
    "description": "An implementation of the Weighted Portmanteau Tests described\n      in \"New Weighted Portmanteau Statistics for Time Series Goodness-of-Fit Testing\"\n      published by the Journal of the American Statistical Association, Volume 107, \n      Issue 498, pages 777-787, 2012.",
    "version": "1.1",
    "maintainer": "Thomas J. Fisher <fishert4@miamioh.edu>",
    "author": "Thomas J. Fisher [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5885-7646>),\n  Colin M. Gallagher [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WeightedPortTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WeightedPortTest Weighted Portmanteau Tests for Time Series Goodness-of-Fit An implementation of the Weighted Portmanteau Tests described\n      in \"New Weighted Portmanteau Statistics for Time Series Goodness-of-Fit Testing\"\n      published by the Journal of the American Statistical Association, Volume 107, \n      Issue 498, pages 777-787, 2012.  "
  },
  {
    "id": 8073,
    "package_name": "WhiteLabRt",
    "title": "Novel Methods for Reproduction Number Estimation,\nBack-Calculation, and Forecasting",
    "description": "A collection of functions related to novel methods for estimating R(t), \n  created by the lab of Professor Laura White. Currently implemented methods include \n  two-step Bayesian back-calculation and now-casting for line-list data with missing reporting delays, \n  adapted in 'STAN' from Li (2021) <doi:10.1371/journal.pcbi.1009210>, \n  and calculation of time-varying reproduction number assuming a flux between various adjacent states, adapted into 'STAN' from \n  Zhou (2021) <doi:10.1371/journal.pcbi.1010434>.",
    "version": "1.0.1",
    "maintainer": "Chad Milando <cmilando@bu.edu>",
    "author": "Chad Milando [aut, cre],\n  Tenglong Li [ctb],\n  Zhenwei Zhou [ctb],\n  Laura White [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WhiteLabRt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WhiteLabRt Novel Methods for Reproduction Number Estimation,\nBack-Calculation, and Forecasting A collection of functions related to novel methods for estimating R(t), \n  created by the lab of Professor Laura White. Currently implemented methods include \n  two-step Bayesian back-calculation and now-casting for line-list data with missing reporting delays, \n  adapted in 'STAN' from Li (2021) <doi:10.1371/journal.pcbi.1009210>, \n  and calculation of time-varying reproduction number assuming a flux between various adjacent states, adapted into 'STAN' from \n  Zhou (2021) <doi:10.1371/journal.pcbi.1010434>.  "
  },
  {
    "id": 8089,
    "package_name": "WormTensor",
    "title": "A Clustering Method for Time-Series Whole-Brain Activity Data of\n'C. elegans'",
    "description": "A toolkit to detect clusters from distance matrices. \n    The distance matrices are assumed to be calculated between the cells of \n    multiple animals ('Caenorhabditis elegans') from input time-series matrices. \n    Some functions for generating distance matrices, performing clustering, \n    evaluating the clustering, and visualizing the results of clustering and \n    evaluation are available. We're also providing the download function to \n    retrieve the calculated distance matrices from \n    'figshare' <https://figshare.com>.",
    "version": "0.1.2",
    "maintainer": "Kentaro Yamamoto <yamaken37.the.answer@gmail.com>",
    "author": "Kentaro Yamamoto [aut, cre],\n  Koki Tsuyuzaki [aut],\n  Itoshi Nikaido [aut]",
    "url": "https://github.com/rikenbit/WormTensor",
    "bug_reports": "https://github.com/rikenbit/WormTensor/issues",
    "repository": "https://cran.r-project.org/package=WormTensor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WormTensor A Clustering Method for Time-Series Whole-Brain Activity Data of\n'C. elegans' A toolkit to detect clusters from distance matrices. \n    The distance matrices are assumed to be calculated between the cells of \n    multiple animals ('Caenorhabditis elegans') from input time-series matrices. \n    Some functions for generating distance matrices, performing clustering, \n    evaluating the clustering, and visualizing the results of clustering and \n    evaluation are available. We're also providing the download function to \n    retrieve the calculated distance matrices from \n    'figshare' <https://figshare.com>.  "
  },
  {
    "id": 8116,
    "package_name": "YRmisc",
    "title": "Y&R Miscellaneous R Functions",
    "description": "Miscellaneous functions for data analysis, portfolio management, graphics, data manipulation, statistical investigation, including descriptive statistics, creating leading and lagging variables, portfolio return analysis, time series difference and percentage change calculation, stacking data for higher efficient analysis.",
    "version": "0.1.6",
    "maintainer": "Xuanhua (Peter) Yin <peteryin.sju@hotmail.com>",
    "author": "Manuel Russon <RUSSONM@stjohns.edu>, Xuanhua (Peter) Yin <peteryin.sju@hotmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=YRmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "YRmisc Y&R Miscellaneous R Functions Miscellaneous functions for data analysis, portfolio management, graphics, data manipulation, statistical investigation, including descriptive statistics, creating leading and lagging variables, portfolio return analysis, time series difference and percentage change calculation, stacking data for higher efficient analysis.  "
  },
  {
    "id": 8127,
    "package_name": "ZIHINAR1",
    "title": "Zero-Inflated and Hurdle INAR(1) Models",
    "description": "Provides tools for estimating Zero-Inflated INAR(1) \n    (ZI-INAR(1)) and Hurdle INAR(1) (H-INAR(1)) models using 'Stan'. \n    It allows users to simulate time series data for these models, \n    estimate parameters, and evaluate model fit using various criteria. \n    Functions include model estimation, simulation, and likelihood-based metrics.",
    "version": "0.1.0",
    "maintainer": "Fusheng Yang <fusheng.yang@uconn.edu>",
    "author": "Fusheng Yang [aut, cre],\n  Victor Hugo Lachos Davila [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ZIHINAR1",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ZIHINAR1 Zero-Inflated and Hurdle INAR(1) Models Provides tools for estimating Zero-Inflated INAR(1) \n    (ZI-INAR(1)) and Hurdle INAR(1) (H-INAR(1)) models using 'Stan'. \n    It allows users to simulate time series data for these models, \n    estimate parameters, and evaluate model fit using various criteria. \n    Functions include model estimation, simulation, and likelihood-based metrics.  "
  },
  {
    "id": 8128,
    "package_name": "ZIM",
    "title": "Zero-Inflated Models (ZIM) for Count Time Series with Excess\nZeros",
    "description": "Analyze count time series with excess zeros. \n    Two types of statistical models are supported: Markov regression by Yang et al.\n    (2013) <doi:10.1016/j.stamet.2013.02.001> and state-space models by Yang et al. \n    (2015) <doi:10.1177/1471082X14535530>. They are also known as observation-driven and \n    parameter-driven models respectively in the time series literature. The functions used for \n    Markov regression or observation-driven models can also be used to fit ordinary regression models \n    with independent data under the zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) \n    assumption. Besides, the package contains some miscellaneous functions to compute density, distribution, \n    quantile, and generate random numbers from ZIP and ZINB distributions.",
    "version": "1.1.0",
    "maintainer": "Ming Yang <mingyang@biostatstudio.com>",
    "author": "Ming Yang [aut, cre],\n  Gideon Zamba [aut],\n  Joseph Cavanaugh [aut]",
    "url": "https://github.com/biostatstudio/ZIM",
    "bug_reports": "https://github.com/biostatstudio/ZIM/issues",
    "repository": "https://cran.r-project.org/package=ZIM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ZIM Zero-Inflated Models (ZIM) for Count Time Series with Excess\nZeros Analyze count time series with excess zeros. \n    Two types of statistical models are supported: Markov regression by Yang et al.\n    (2013) <doi:10.1016/j.stamet.2013.02.001> and state-space models by Yang et al. \n    (2015) <doi:10.1177/1471082X14535530>. They are also known as observation-driven and \n    parameter-driven models respectively in the time series literature. The functions used for \n    Markov regression or observation-driven models can also be used to fit ordinary regression models \n    with independent data under the zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) \n    assumption. Besides, the package contains some miscellaneous functions to compute density, distribution, \n    quantile, and generate random numbers from ZIP and ZINB distributions.  "
  },
  {
    "id": 8137,
    "package_name": "ZRA",
    "title": "Dynamic Plots for Time Series Forecasting",
    "description": "Combines a forecast of a time series, using the function forecast(), with the dynamic plots from dygraphs.",
    "version": "0.2",
    "maintainer": "David Beiner <zra.r.package@gmail.com>",
    "author": "David Beiner",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ZRA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ZRA Dynamic Plots for Time Series Forecasting Combines a forecast of a time series, using the function forecast(), with the dynamic plots from dygraphs.  "
  },
  {
    "id": 8154,
    "package_name": "aTSA",
    "title": "Alternative Time Series Analysis",
    "description": "Contains some tools for testing, analyzing time series data and\n    fitting popular time series models such as ARIMA, Moving Average and Holt\n    Winters, etc. Most functions also provide nice and clear outputs like SAS\n    does, such as identify, estimate and forecast, which are the same statements\n    in PROC ARIMA in SAS.",
    "version": "3.1.2.1",
    "maintainer": "Debin Qiu <debinqiu@uga.edu>",
    "author": "Debin Qiu",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aTSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aTSA Alternative Time Series Analysis Contains some tools for testing, analyzing time series data and\n    fitting popular time series models such as ARIMA, Moving Average and Holt\n    Winters, etc. Most functions also provide nice and clear outputs like SAS\n    does, such as identify, estimate and forecast, which are the same statements\n    in PROC ARIMA in SAS.  "
  },
  {
    "id": 8191,
    "package_name": "accelerometry",
    "title": "Functions for Processing Accelerometer Data",
    "description": "A collection of functions that perform operations on time-series accelerometer data, such as identify non-wear time, flag minutes that are part of an activity bout, and find the maximum 10-minute average count value. The functions are generally very flexible, allowing for a variety of algorithms to be implemented. Most of the functions are written in C++ for efficiency.",
    "version": "3.1.2",
    "maintainer": "Dane R. Van Domelen <vandomed@gmail.com>",
    "author": "Dane R. Van Domelen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=accelerometry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "accelerometry Functions for Processing Accelerometer Data A collection of functions that perform operations on time-series accelerometer data, such as identify non-wear time, flag minutes that are part of an activity bout, and find the maximum 10-minute average count value. The functions are generally very flexible, allowing for a variety of algorithms to be implemented. Most of the functions are written in C++ for efficiency.  "
  },
  {
    "id": 8211,
    "package_name": "aclhs",
    "title": "Autocorrelated Conditioned Latin Hypercube Sampling",
    "description": "Implementation of the autocorrelated conditioned Latin\n    Hypercube Sampling (acLHS) algorithm for 1D (time-series) and 2D (spatial)\n    data. The acLHS algorithm is an extension of the conditioned Latin Hypercube \n    Sampling (cLHS) algorithm that allows sampled data to have similar \n    correlative and statistical features of the original data. Only a properly \n    formatted dataframe needs to be provided to yield subsample indices from \n    the primary function. For more details about the cLHS algorithm, see Minasny\n    and McBratney (2006), <doi:10.1016/j.cageo.2005.12.009>. For acLHS, see Le \n    and Vargas (2024) <doi:10.1016/j.cageo.2024.105539>.",
    "version": "1.0.1",
    "maintainer": "Gabriel Laboy <glaboy1@asu.edu>",
    "author": "Van Huong Le [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3700-9987>),\n  Rodrigo Vargas [aut] (ORCID: <https://orcid.org/0000-0001-6829-5333>),\n  Gabriel Laboy [ctb, cre] (ORCID:\n    <https://orcid.org/0009-0004-1538-5035>)",
    "url": "https://github.com/vargaslab/acLHS",
    "bug_reports": "https://github.com/vargaslab/acLHS/issues",
    "repository": "https://cran.r-project.org/package=aclhs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aclhs Autocorrelated Conditioned Latin Hypercube Sampling Implementation of the autocorrelated conditioned Latin\n    Hypercube Sampling (acLHS) algorithm for 1D (time-series) and 2D (spatial)\n    data. The acLHS algorithm is an extension of the conditioned Latin Hypercube \n    Sampling (cLHS) algorithm that allows sampled data to have similar \n    correlative and statistical features of the original data. Only a properly \n    formatted dataframe needs to be provided to yield subsample indices from \n    the primary function. For more details about the cLHS algorithm, see Minasny\n    and McBratney (2006), <doi:10.1016/j.cageo.2005.12.009>. For acLHS, see Le \n    and Vargas (2024) <doi:10.1016/j.cageo.2024.105539>.  "
  },
  {
    "id": 8224,
    "package_name": "actfts",
    "title": "Autocorrelation Tools Featured for Time Series",
    "description": "The 'actfts' package provides tools for performing autocorrelation analysis of time series data. It includes functions to compute and visualize the autocorrelation function (ACF) and the partial autocorrelation function (PACF). Additionally, it performs the Dickey-Fuller, KPSS, and Phillips-Perron unit root tests to assess the stationarity of time series. Theoretical foundations are based on Box and Cox (1964) <doi:10.1111/j.2517-6161.1964.tb00553.x>, Box and Jenkins (1976) <isbn:978-0-8162-1234-2>, and Box and Pierce (1970) <doi:10.1080/01621459.1970.10481180>. Statistical methods are also drawn from Kolmogorov (1933) <doi:10.1007/BF00993594>, Kwiatkowski et al. (1992) <doi:10.1016/0304-4076(92)90104-Y>, and Ljung and Box (1978) <doi:10.1093/biomet/65.2.297>. The package integrates functions from 'forecast' (Hyndman & Khandakar, 2008) <https://CRAN.R-project.org/package=forecast>, 'tseries' (Trapletti & Hornik, 2020) <https://CRAN.R-project.org/package=tseries>, 'xts' (Ryan & Ulrich, 2020) <https://CRAN.R-project.org/package=xts>, and 'stats' (R Core Team, 2023) <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/00Index.html>. Additionally, it provides visualization tools via 'plotly' (Sievert, 2020) <https://CRAN.R-project.org/package=plotly> and 'reactable' (Glaz, 2023) <https://CRAN.R-project.org/package=reactable>. The package also incorporates macroeconomic datasets from the U.S. Bureau of Economic Analysis: Disposable Personal Income (DPI) <https://fred.stlouisfed.org/series/DPI>, Gross Domestic Product (GDP) <https://fred.stlouisfed.org/series/GDP>, and Personal Consumption Expenditures (PCEC) <https://fred.stlouisfed.org/series/PCEC>.",
    "version": "0.3.0",
    "maintainer": "Sergio Sierra <sergiochess95@gmail.com>",
    "author": "David Rodr\u00edguez [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-5430-0787>),\n  Sergio Sierra [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4055-8810>)",
    "url": "https://github.com/SergioFinances/actfts,\nhttps://sergiofinances.github.io/actfts/",
    "bug_reports": "https://github.com/SergioFinances/actfts/issues",
    "repository": "https://cran.r-project.org/package=actfts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "actfts Autocorrelation Tools Featured for Time Series The 'actfts' package provides tools for performing autocorrelation analysis of time series data. It includes functions to compute and visualize the autocorrelation function (ACF) and the partial autocorrelation function (PACF). Additionally, it performs the Dickey-Fuller, KPSS, and Phillips-Perron unit root tests to assess the stationarity of time series. Theoretical foundations are based on Box and Cox (1964) <doi:10.1111/j.2517-6161.1964.tb00553.x>, Box and Jenkins (1976) <isbn:978-0-8162-1234-2>, and Box and Pierce (1970) <doi:10.1080/01621459.1970.10481180>. Statistical methods are also drawn from Kolmogorov (1933) <doi:10.1007/BF00993594>, Kwiatkowski et al. (1992) <doi:10.1016/0304-4076(92)90104-Y>, and Ljung and Box (1978) <doi:10.1093/biomet/65.2.297>. The package integrates functions from 'forecast' (Hyndman & Khandakar, 2008) <https://CRAN.R-project.org/package=forecast>, 'tseries' (Trapletti & Hornik, 2020) <https://CRAN.R-project.org/package=tseries>, 'xts' (Ryan & Ulrich, 2020) <https://CRAN.R-project.org/package=xts>, and 'stats' (R Core Team, 2023) <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/00Index.html>. Additionally, it provides visualization tools via 'plotly' (Sievert, 2020) <https://CRAN.R-project.org/package=plotly> and 'reactable' (Glaz, 2023) <https://CRAN.R-project.org/package=reactable>. The package also incorporates macroeconomic datasets from the U.S. Bureau of Economic Analysis: Disposable Personal Income (DPI) <https://fred.stlouisfed.org/series/DPI>, Gross Domestic Product (GDP) <https://fred.stlouisfed.org/series/GDP>, and Personal Consumption Expenditures (PCEC) <https://fred.stlouisfed.org/series/PCEC>.  "
  },
  {
    "id": 8295,
    "package_name": "adiv",
    "title": "Analysis of Diversity",
    "description": "Functions, data sets and examples for the calculation of various indices of biodiversity including species, functional and phylogenetic diversity. Part of the indices are expressed in terms of equivalent numbers of species. The package also provides ways to partition biodiversity across spatial or temporal scales (alpha, beta, gamma diversities). In addition to the quantification of biodiversity, ordination approaches are available which rely on diversity indices and allow the detailed identification of species, functional or phylogenetic differences between communities.",
    "version": "2.2.1",
    "maintainer": "Sandrine Pavoine <sandrine.pavoine@mnhn.fr>",
    "author": "Sandrine Pavoine ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=adiv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adiv Analysis of Diversity Functions, data sets and examples for the calculation of various indices of biodiversity including species, functional and phylogenetic diversity. Part of the indices are expressed in terms of equivalent numbers of species. The package also provides ways to partition biodiversity across spatial or temporal scales (alpha, beta, gamma diversities). In addition to the quantification of biodiversity, ordination approaches are available which rely on diversity indices and allow the detailed identification of species, functional or phylogenetic differences between communities.  "
  },
  {
    "id": 8334,
    "package_name": "aeddo",
    "title": "Automated and Early Detection of Disease Outbreaks",
    "description": "A powerful tool for automating the early detection of disease\n             outbreaks in time series data. 'aeddo' employs advanced statistical \n             methods, including hierarchical models, in an innovative manner to \n             effectively characterize outbreak signals. It is particularly useful \n             for epidemiologists, public health professionals, and researchers \n             seeking to identify and respond to disease outbreaks in a timely \n             fashion. For a detailed reference on hierarchical models, consult \n             Henrik Madsen and Poul Thyregod's book (2011), ISBN: 9781420091557.",
    "version": "0.1.1",
    "maintainer": "Lasse Engbo Christiansen <lsec@ssi.dk>",
    "author": "Kasper Schou Telkamp [aut] (ORCID:\n    <https://orcid.org/0009-0001-5126-0190>),\n  Lasse Engbo Christiansen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5019-1931>),\n  Statens Serum Institut, SSI [cph, fnd]",
    "url": "https://ssi-dk.github.io/aeddo/, https://github.com/ssi-dk/aeddo",
    "bug_reports": "https://github.com/ssi-dk/aeddo/issues",
    "repository": "https://cran.r-project.org/package=aeddo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aeddo Automated and Early Detection of Disease Outbreaks A powerful tool for automating the early detection of disease\n             outbreaks in time series data. 'aeddo' employs advanced statistical \n             methods, including hierarchical models, in an innovative manner to \n             effectively characterize outbreak signals. It is particularly useful \n             for epidemiologists, public health professionals, and researchers \n             seeking to identify and respond to disease outbreaks in a timely \n             fashion. For a detailed reference on hierarchical models, consult \n             Henrik Madsen and Poul Thyregod's book (2011), ISBN: 9781420091557.  "
  },
  {
    "id": 8335,
    "package_name": "aedseo",
    "title": "Automated and Early Detection of Seasonal Epidemic Onset and\nBurden Levels",
    "description": "A powerful tool for automating the early detection of seasonal epidemic\n             onsets in time series data. It offers the ability to estimate growth rates\n             across consecutive time intervals, calculate the sum of cases (SoC) within\n             those intervals, and estimate seasonal onsets within user defined seasons.\n             With use of a disease-specific threshold it also offers the possibility to\n             estimate seasonal onset of epidemics.\n             Additionally it offers the ability to estimate burden levels for seasons\n             based on historical data. It is aimed towards epidemiologists,\n             public health professionals, and researchers seeking to identify and respond\n             to seasonal epidemics in a timely fashion.",
    "version": "1.0.1",
    "maintainer": "Lasse Engbo Christiansen <lsec@ssi.dk>",
    "author": "Sofia Myrup Otero [aut] (ORCID:\n    <https://orcid.org/0009-0006-4953-614X>),\n  Kasper Schou Telkamp [aut] (ORCID:\n    <https://orcid.org/0009-0001-5126-0190>),\n  Lasse Engbo Christiansen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5019-1931>),\n  Rasmus Skytte Randl\u00f8v [rev] (ORCID:\n    <https://orcid.org/0000-0002-5860-3838>),\n  Statens Serum Institut, SSI [cph, fnd]",
    "url": "https://github.com/ssi-dk/aedseo, https://ssi-dk.github.io/aedseo/",
    "bug_reports": "https://github.com/ssi-dk/aedseo/issues",
    "repository": "https://cran.r-project.org/package=aedseo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aedseo Automated and Early Detection of Seasonal Epidemic Onset and\nBurden Levels A powerful tool for automating the early detection of seasonal epidemic\n             onsets in time series data. It offers the ability to estimate growth rates\n             across consecutive time intervals, calculate the sum of cases (SoC) within\n             those intervals, and estimate seasonal onsets within user defined seasons.\n             With use of a disease-specific threshold it also offers the possibility to\n             estimate seasonal onset of epidemics.\n             Additionally it offers the ability to estimate burden levels for seasons\n             based on historical data. It is aimed towards epidemiologists,\n             public health professionals, and researchers seeking to identify and respond\n             to seasonal epidemics in a timely fashion.  "
  },
  {
    "id": 8337,
    "package_name": "afc",
    "title": "Generalized Discrimination Score",
    "description": "This is an implementation of the Generalized Discrimination Score\n    (also known as Two Alternatives Forced Choice Score, 2AFC) for various \n    representations of forecasts and verifying observations. The Generalized \n    Discrimination Score is a generic forecast verification framework which \n    can be applied to any of the following verification contexts: dichotomous, \n    polychotomous (ordinal and nominal), continuous, probabilistic, and ensemble.\n    A comprehensive description of the Generalized Discrimination Score, including \n    all equations used in this package, is provided by Mason and Weigel (2009) \n    <doi:10.1175/MWR-D-10-05069.1>.",
    "version": "1.4.0",
    "maintainer": "Jonas Bhend <jonas.bhend@meteoswiss.ch>",
    "author": "Andreas Weigel [aut],\n  MeteoSwiss [cph],\n  Jonas Bhend [cre, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=afc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "afc Generalized Discrimination Score This is an implementation of the Generalized Discrimination Score\n    (also known as Two Alternatives Forced Choice Score, 2AFC) for various \n    representations of forecasts and verifying observations. The Generalized \n    Discrimination Score is a generic forecast verification framework which \n    can be applied to any of the following verification contexts: dichotomous, \n    polychotomous (ordinal and nominal), continuous, probabilistic, and ensemble.\n    A comprehensive description of the Generalized Discrimination Score, including \n    all equations used in this package, is provided by Mason and Weigel (2009) \n    <doi:10.1175/MWR-D-10-05069.1>.  "
  },
  {
    "id": 8348,
    "package_name": "africamonitor",
    "title": "Africa Macroeconomic Monitor Database API",
    "description": "An R API providing access to a relational database with macroeconomic data for Africa. \n             The database contains >700 macroeconomic time series from mostly international sources, \n             grouped into 50 macroeconomic and development-related topics. Series are carefully selected\n             on the basis of data coverage for Africa, frequency, and relevance to the macro-development context. \n             The project is part of the 'Kiel Institute Africa Initiative' \n             <https://www.ifw-kiel.de/institute/initiatives/kiel-institute-africa-initiative/>, \n             which, amongst other things, aims to develop a parsimonious database with highly relevant indicators \n             to monitor macroeconomic developments in Africa, accessible through a fast API and a web-based platform\n             at <https://africamonitor.ifw-kiel.de/>. \n             The database is maintained at the Kiel Institute for the World Economy <https://www.ifw-kiel.de/>. ",
    "version": "0.2.4",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre]",
    "url": "https://africamonitor.ifw-kiel.de/",
    "bug_reports": "https://github.com/kielinstitute/africamonitor/issues",
    "repository": "https://cran.r-project.org/package=africamonitor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "africamonitor Africa Macroeconomic Monitor Database API An R API providing access to a relational database with macroeconomic data for Africa. \n             The database contains >700 macroeconomic time series from mostly international sources, \n             grouped into 50 macroeconomic and development-related topics. Series are carefully selected\n             on the basis of data coverage for Africa, frequency, and relevance to the macro-development context. \n             The project is part of the 'Kiel Institute Africa Initiative' \n             <https://www.ifw-kiel.de/institute/initiatives/kiel-institute-africa-initiative/>, \n             which, amongst other things, aims to develop a parsimonious database with highly relevant indicators \n             to monitor macroeconomic developments in Africa, accessible through a fast API and a web-based platform\n             at <https://africamonitor.ifw-kiel.de/>. \n             The database is maintained at the Kiel Institute for the World Economy <https://www.ifw-kiel.de/>.   "
  },
  {
    "id": 8366,
    "package_name": "aggutils",
    "title": "Utilities for Aggregating Probabilistic Forecasts",
    "description": "Provides several methods for aggregating probabilistic forecasts. You have a group of\n    people who have made probabilistic forecasts for the same event. You want to take advantage of\n    the \"wisdom of the crowd\" and combine these forecasts in some sensible way. This package\n    provides implementations of several strategies, including geometric mean of odds, an extremized\n    aggregate (Neyman, Roughgarden (2021) <doi:10.1145/3490486.3538243>), and \"high-density trimmed\n    mean\" (Powell et al. (2022) <doi:10.1037/dec0000191>).",
    "version": "1.0.2",
    "maintainer": "Molly Hickman <molly@forecastingresearch.org>",
    "author": "Molly Hickman [aut, cre] (ORCID:\n    <https://orcid.org/0009-0007-5144-0080>),\n  Zach Jacobs [aut]",
    "url": "https://github.com/forecastingresearch/aggutils",
    "bug_reports": "https://github.com/forecastingresearch/aggutils/issues",
    "repository": "https://cran.r-project.org/package=aggutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aggutils Utilities for Aggregating Probabilistic Forecasts Provides several methods for aggregating probabilistic forecasts. You have a group of\n    people who have made probabilistic forecasts for the same event. You want to take advantage of\n    the \"wisdom of the crowd\" and combine these forecasts in some sensible way. This package\n    provides implementations of several strategies, including geometric mean of odds, an extremized\n    aggregate (Neyman, Roughgarden (2021) <doi:10.1145/3490486.3538243>), and \"high-density trimmed\n    mean\" (Powell et al. (2022) <doi:10.1037/dec0000191>).  "
  },
  {
    "id": 8380,
    "package_name": "ags",
    "title": "Crosswalk Municipality and District Statistics in Germany",
    "description": "Construct time series for Germany's municipalities (Gemeinden) and districts (Kreise) using a annual crosswalk constructed by the Federal Office for Building and Regional Planning (BBSR). ",
    "version": "1.0.1",
    "maintainer": "Moritz Marbach <m.marbach@ucl.ac.uk>",
    "author": "Moritz Marbach [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7101-2821>)",
    "url": "https://sumtxt.github.io/ags/",
    "bug_reports": "https://github.com/sumtxt/ags/issues",
    "repository": "https://cran.r-project.org/package=ags",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ags Crosswalk Municipality and District Statistics in Germany Construct time series for Germany's municipalities (Gemeinden) and districts (Kreise) using a annual crosswalk constructed by the Federal Office for Building and Regional Planning (BBSR).   "
  },
  {
    "id": 8389,
    "package_name": "aiRthermo",
    "title": "Atmospheric Thermodynamics and Visualization",
    "description": "Deals with many computations related to the thermodynamics of atmospheric processes. It includes many functions designed to consider the density of air with varying degrees of water vapour in it, saturation pressures and mixing ratios, conversion of moisture indices, computation of atmospheric states of parcels subject to dry or pseudoadiabatic vertical evolutions and atmospheric instability indices that are routinely used for operational weather forecasts or meteorological diagnostics.",
    "version": "1.2.2",
    "maintainer": "Santos J. Gonz\u00e1lez-Roj\u00ed <santosjose.gonzalez@ehu.eus>",
    "author": "Jon S\u00e1enz [aut, cph] (ORCID: <https://orcid.org/0000-0002-5920-7570>),\n  Santos J. Gonz\u00e1lez-Roj\u00ed [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4737-0984>),\n  Sheila Carreno-Madinabeitia [aut, cph] (ORCID:\n    <https://orcid.org/0000-0003-4625-6178>),\n  Gabriel Ibarra-Berastegi [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0001-8681-3755>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aiRthermo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aiRthermo Atmospheric Thermodynamics and Visualization Deals with many computations related to the thermodynamics of atmospheric processes. It includes many functions designed to consider the density of air with varying degrees of water vapour in it, saturation pressures and mixing ratios, conversion of moisture indices, computation of atmospheric states of parcels subject to dry or pseudoadiabatic vertical evolutions and atmospheric instability indices that are routinely used for operational weather forecasts or meteorological diagnostics.  "
  },
  {
    "id": 8394,
    "package_name": "aion",
    "title": "Archaeological Time Series",
    "description": "A toolkit for archaeological time series and time intervals.\n    This package provides a system of classes and methods to represent and\n    work with archaeological time series and time intervals. Dates are\n    represented as \"rata die\" and can be converted to (virtually) any\n    calendar defined by Reingold and Dershowitz (2018)\n    <doi:10.1017/9781107415058>. This packages offers a simple API that\n    can be used by other specialized packages.",
    "version": "1.6.0",
    "maintainer": "Nicolas Frerebeau <nicolas.frerebeau@u-bordeaux-montaigne.fr>",
    "author": "Nicolas Frerebeau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5759-4944>),\n  Joe Roe [aut] (ORCID: <https://orcid.org/0000-0002-1011-1244>),\n  Brice Lebrun [art] (ORCID: <https://orcid.org/0000-0001-7503-8685>,\n    Logo designer),\n  Universit\u00e9 Bordeaux Montaigne [fnd] (ROR: <https://ror.org/03pbgwk21>),\n  CNRS [fnd] (ROR: <https://ror.org/02feahw73>)",
    "url": "https://codeberg.org/tesselle/aion,\nhttps://tesselle.r-universe.dev/aion,\nhttps://packages.tesselle.org/aion/",
    "bug_reports": "https://codeberg.org/tesselle/aion/issues",
    "repository": "https://cran.r-project.org/package=aion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aion Archaeological Time Series A toolkit for archaeological time series and time intervals.\n    This package provides a system of classes and methods to represent and\n    work with archaeological time series and time intervals. Dates are\n    represented as \"rata die\" and can be converted to (virtually) any\n    calendar defined by Reingold and Dershowitz (2018)\n    <doi:10.1017/9781107415058>. This packages offers a simple API that\n    can be used by other specialized packages.  "
  },
  {
    "id": 8396,
    "package_name": "airGRdatasets",
    "title": "Hydro-Meteorological Catchments Datasets for the 'airGR'\nPackages",
    "description": "Sample of hydro-meteorological datasets extracted from the 'CAMELS-FR' French database <doi:10.57745/WH7FJR>. \n  It provides metadata and catchment-scale aggregated hydro-meteorological time series on a pool of French catchments for use by the 'airGR' packages. ",
    "version": "0.2.3",
    "maintainer": "Olivier Delaigue <airGR@inrae.fr>",
    "author": "Olivier Delaigue [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7668-8468>),\n  Pierre Brigode [aut] (ORCID: <https://orcid.org/0000-0001-8257-0741>),\n  Guillaume Thirel [aut] (ORCID: <https://orcid.org/0000-0002-1444-1830>),\n  Beno\u00eet G\u00e9not [ctb],\n  Guilherme Mendoza Guimar\u00e3es [ctb] (ORCID:\n    <https://orcid.org/0000-0002-4580-6089>)",
    "url": "https://gitlab.irstea.fr/HYCAR-Hydro/airgrgalaxy/airgrdatasets",
    "bug_reports": "https://gitlab.irstea.fr/HYCAR-Hydro/airgrgalaxy/airgrdatasets/-/issues",
    "repository": "https://cran.r-project.org/package=airGRdatasets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "airGRdatasets Hydro-Meteorological Catchments Datasets for the 'airGR'\nPackages Sample of hydro-meteorological datasets extracted from the 'CAMELS-FR' French database <doi:10.57745/WH7FJR>. \n  It provides metadata and catchment-scale aggregated hydro-meteorological time series on a pool of French catchments for use by the 'airGR' packages.   "
  },
  {
    "id": 8401,
    "package_name": "airnow",
    "title": "Retrieve 'AirNow' Air Quality Observations and Forecasts",
    "description": "Retrieve air quality data via the 'AirNow'\n    <https://www.airnow.gov/> API.",
    "version": "0.1.0",
    "maintainer": "Brian Connelly <bdc@bconnelly.net>",
    "author": "Brian Connelly [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9948-0379>)",
    "url": "https://github.com/briandconnelly/airnow",
    "bug_reports": "https://github.com/briandconnelly/airnow/issues",
    "repository": "https://cran.r-project.org/package=airnow",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "airnow Retrieve 'AirNow' Air Quality Observations and Forecasts Retrieve air quality data via the 'AirNow'\n    <https://www.airnow.gov/> API.  "
  },
  {
    "id": 8423,
    "package_name": "alfred",
    "title": "Downloading Time Series from ALFRED Database for Various\nVintages",
    "description": "Provides direct access to the ALFRED (<https://alfred.stlouisfed.org>) and FRED (<https://fred.stlouisfed.org>) databases.\n    Its functions return tidy data frames for different releases of the specified time series. \n    Note that this product uses the FRED\u00a9 API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.",
    "version": "0.2.1",
    "maintainer": "Onno Kleen <r@onnokleen.de>",
    "author": "Onno Kleen [aut, cre] (ORCID: <https://orcid.org/0000-0003-4731-4640>)",
    "url": "https://github.com/onnokleen/alfred/",
    "bug_reports": "https://github.com/onnokleen/alfred/issues",
    "repository": "https://cran.r-project.org/package=alfred",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "alfred Downloading Time Series from ALFRED Database for Various\nVintages Provides direct access to the ALFRED (<https://alfred.stlouisfed.org>) and FRED (<https://fred.stlouisfed.org>) databases.\n    Its functions return tidy data frames for different releases of the specified time series. \n    Note that this product uses the FRED\u00a9 API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.  "
  },
  {
    "id": 8429,
    "package_name": "align",
    "title": "A Modified DTW Algorithm for Stratigraphic Time Series Alignment",
    "description": "A dynamic time warping (DTW) algorithm for stratigraphic alignment,\n    translated into R from the original published 'MATLAB' code by Hay et al. (2019)\n    <doi:10.1130/G46019.1>. The DTW algorithm incorporates two geologically relevant\n    parameters (g and edge) for augmenting the typical DTW cost matrix, allowing\n    for a range of sedimentologic and chronologic conditions to be explored, as \n    well as the generation of an alignment library (as opposed to a single alignment\n    solution). The g parameter relates to the relative sediment accumulation rate\n    between the two time series records,  while the edge parameter relates to the \n    amount of total shared time between the records. Note that this algorithm is\n    used for all DTW alignments in the Align Shiny application, detailed in Hagen\n    et al. (in review).",
    "version": "0.1.0",
    "maintainer": "Cedric Hagen <ch0934@princeton.edu>",
    "author": "Cedric Hagen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=align",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "align A Modified DTW Algorithm for Stratigraphic Time Series Alignment A dynamic time warping (DTW) algorithm for stratigraphic alignment,\n    translated into R from the original published 'MATLAB' code by Hay et al. (2019)\n    <doi:10.1130/G46019.1>. The DTW algorithm incorporates two geologically relevant\n    parameters (g and edge) for augmenting the typical DTW cost matrix, allowing\n    for a range of sedimentologic and chronologic conditions to be explored, as \n    well as the generation of an alignment library (as opposed to a single alignment\n    solution). The g parameter relates to the relative sediment accumulation rate\n    between the two time series records,  while the edge parameter relates to the \n    amount of total shared time between the records. Note that this algorithm is\n    used for all DTW alignments in the Align Shiny application, detailed in Hagen\n    et al. (in review).  "
  },
  {
    "id": 8439,
    "package_name": "alluvial",
    "title": "Alluvial Diagrams",
    "description": "Creating alluvial diagrams (also known as parallel sets plots) for multivariate\n  and time series-like data.",
    "version": "0.1-2",
    "maintainer": "Michal Bojanowski <michal2992@gmail.com>",
    "author": "Michal Bojanowski [aut, cre],\n  Robin Edwards [aut]",
    "url": "https://github.com/mbojan/alluvial",
    "bug_reports": "https://github.com/mbojan/alluvial/issues",
    "repository": "https://cran.r-project.org/package=alluvial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "alluvial Alluvial Diagrams Creating alluvial diagrams (also known as parallel sets plots) for multivariate\n  and time series-like data.  "
  },
  {
    "id": 8463,
    "package_name": "amadeus",
    "title": "Accessing and Analyzing Large-Scale Environmental Data",
    "description": "Functions are designed to facilitate access to and utility with large scale, publicly available environmental data in R. The package contains functions for downloading raw data files from web URLs (download_data()), processing the raw data files into clean spatial objects (process_covariates()), and extracting values from the spatial data objects at point and polygon locations (calculate_covariates()). These functions call a series of source-specific functions which are tailored to each data sources/datasets particular URL structure, data format, and spatial/temporal resolution. The functions are tested, versioned, and open source and open access. For sum_edc() method details, see Messier, Akita, and Serre (2012) <doi:10.1021/es203152a>.",
    "version": "1.2.4.9",
    "maintainer": "Kyle Messier <kyle.messier@nih.gov>",
    "author": "Mitchell Manware [aut, ctb] (ORCID:\n    <https://orcid.org/0009-0003-6440-6106>),\n  Insang Song [aut, ctb] (ORCID: <https://orcid.org/0000-0001-8732-3256>),\n  Eva Marques [aut, ctb] (ORCID: <https://orcid.org/0000-0001-9817-6546>),\n  Mariana Alifa Kassien [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-2295-406X>),\n  Elizabeth Scholl [ctb] (ORCID: <https://orcid.org/0000-0003-2727-1954>),\n  Kyle Messier [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9508-9623>),\n  Spatiotemporal Exposures and Toxicology Group [cph]",
    "url": "https://niehs.github.io/amadeus/",
    "bug_reports": "https://github.com/NIEHS/amadeus/issues",
    "repository": "https://cran.r-project.org/package=amadeus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "amadeus Accessing and Analyzing Large-Scale Environmental Data Functions are designed to facilitate access to and utility with large scale, publicly available environmental data in R. The package contains functions for downloading raw data files from web URLs (download_data()), processing the raw data files into clean spatial objects (process_covariates()), and extracting values from the spatial data objects at point and polygon locations (calculate_covariates()). These functions call a series of source-specific functions which are tailored to each data sources/datasets particular URL structure, data format, and spatial/temporal resolution. The functions are tested, versioned, and open source and open access. For sum_edc() method details, see Messier, Akita, and Serre (2012) <doi:10.1021/es203152a>.  "
  },
  {
    "id": 8506,
    "package_name": "animation",
    "title": "A Gallery of Animations in Statistics and Utilities to Create\nAnimations",
    "description": "Provides functions for animations in statistics, covering topics\n    in probability theory, mathematical statistics, multivariate statistics,\n    non-parametric statistics, sampling survey, linear models, time series,\n    computational statistics, data mining and machine learning. These functions\n    may be helpful in teaching statistics and data analysis. Also provided in this\n    package are a series of functions to save animations to various formats, e.g.\n    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted\n    into 'Sweave' / 'knitr' easily.",
    "version": "2.8",
    "maintainer": "Yihui Xie <xie@yihui.name>",
    "author": "Yihui Xie [aut, cre] (ORCID: <https://orcid.org/0000-0003-0645-5666>,\n    URL: https://yihui.org),\n  Christian Mueller [ctb],\n  Lijia Yu [ctb],\n  Xinyuan Chu [ctb],\n  Weicheng Zhu [ctb]",
    "url": "https://yihui.org/animation/",
    "bug_reports": "https://github.com/yihui/animation/issues",
    "repository": "https://cran.r-project.org/package=animation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "animation A Gallery of Animations in Statistics and Utilities to Create\nAnimations Provides functions for animations in statistics, covering topics\n    in probability theory, mathematical statistics, multivariate statistics,\n    non-parametric statistics, sampling survey, linear models, time series,\n    computational statistics, data mining and machine learning. These functions\n    may be helpful in teaching statistics and data analysis. Also provided in this\n    package are a series of functions to save animations to various formats, e.g.\n    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted\n    into 'Sweave' / 'knitr' easily.  "
  },
  {
    "id": 8518,
    "package_name": "anomaly",
    "title": "Detecting Anomalies in Data",
    "description": "Implements Collective And Point Anomaly (CAPA) Fisch, Eckley, and Fearnhead (2022) <doi:10.1002/sam.11586>, Multi-Variate Collective And Point Anomaly (MVCAPA) Fisch, Eckley, and Fearnhead (2021) <doi:10.1080/10618600.2021.1987257>, Proportion Adaptive Segment Selection (PASS) Jeng, Cai, and Li (2012) <doi:10.1093/biomet/ass059>, and Bayesian Abnormal Region Detector (BARD) Bardwell and Fearnhead (2015) <doi:10.1214/16-BA998>. These methods are for the detection of anomalies in time series data. Further information regarding the use of this package along with detailed examples can be found in Fisch, Grose, Eckley, Fearnhead, and Bardwell (2024) <doi:10.18637/jss.v110.i01>.",
    "version": "4.3.3",
    "maintainer": "Daniel Grose <dan.grose@lancaster.ac.uk>",
    "author": "Alex Fisch [aut],\n  Daniel Grose [aut, cre],\n  Lawrence Bardwell [aut, ctb],\n  Idris Eckley [aut, ths],\n  Paul Fearnhead [aut, ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=anomaly",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "anomaly Detecting Anomalies in Data Implements Collective And Point Anomaly (CAPA) Fisch, Eckley, and Fearnhead (2022) <doi:10.1002/sam.11586>, Multi-Variate Collective And Point Anomaly (MVCAPA) Fisch, Eckley, and Fearnhead (2021) <doi:10.1080/10618600.2021.1987257>, Proportion Adaptive Segment Selection (PASS) Jeng, Cai, and Li (2012) <doi:10.1093/biomet/ass059>, and Bayesian Abnormal Region Detector (BARD) Bardwell and Fearnhead (2015) <doi:10.1214/16-BA998>. These methods are for the detection of anomalies in time series data. Further information regarding the use of this package along with detailed examples can be found in Fisch, Grose, Eckley, Fearnhead, and Bardwell (2024) <doi:10.18637/jss.v110.i01>.  "
  },
  {
    "id": 8537,
    "package_name": "aoristic",
    "title": "Generates Aoristic Probability Distributions",
    "description": "It can sometimes be difficult to ascertain when some events (such as property crime)\n    occur because the victim is not present when the crime happens. As a result, police databases often\n    record a 'start' (or 'from') date and time, and an 'end' (or 'to') date and time. The time span between\n    these date/times can be minutes, hours, or sometimes days, hence the term 'Aoristic'. \n    Aoristic is one of the past tenses in Greek and represents an uncertain occurrence in time. \n    For events with a location describes with either a latitude/longitude, or X,Y coordinate pair, \n    and a start and end date/time, this package generates an aoristic data frame with aoristic weighted\n    probability values for each hour of the week, for each observation. The coordinates are not \n    necessary for the program to calculate aoristic weights; however, they are part of this package \n    because a spatial component has been integral to aoristic analysis from the start. Dummy \n    coordinates can be introduced if the user only has temporal data. Outputs include an aoristic \n    data frame, as well as summary graphs and displays.   \n        For more information see:\n    Ratcliffe, JH (2002) Aoristic signatures and the temporal analysis of high volume crime patterns, \n    Journal of Quantitative Criminology. 18 (1): 23-43.\n    Note: This package replaces an original 'aoristic' package (version 0.6) by George Kikuchi that \n    has been discontinued with his permission. ",
    "version": "1.1.1",
    "maintainer": "Jerry Ratcliffe <jhr@temple.edu>",
    "author": "Jerry Ratcliffe",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aoristic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aoristic Generates Aoristic Probability Distributions It can sometimes be difficult to ascertain when some events (such as property crime)\n    occur because the victim is not present when the crime happens. As a result, police databases often\n    record a 'start' (or 'from') date and time, and an 'end' (or 'to') date and time. The time span between\n    these date/times can be minutes, hours, or sometimes days, hence the term 'Aoristic'. \n    Aoristic is one of the past tenses in Greek and represents an uncertain occurrence in time. \n    For events with a location describes with either a latitude/longitude, or X,Y coordinate pair, \n    and a start and end date/time, this package generates an aoristic data frame with aoristic weighted\n    probability values for each hour of the week, for each observation. The coordinates are not \n    necessary for the program to calculate aoristic weights; however, they are part of this package \n    because a spatial component has been integral to aoristic analysis from the start. Dummy \n    coordinates can be introduced if the user only has temporal data. Outputs include an aoristic \n    data frame, as well as summary graphs and displays.   \n        For more information see:\n    Ratcliffe, JH (2002) Aoristic signatures and the temporal analysis of high volume crime patterns, \n    Journal of Quantitative Criminology. 18 (1): 23-43.\n    Note: This package replaces an original 'aoristic' package (version 0.6) by George Kikuchi that \n    has been discontinued with his permission.   "
  },
  {
    "id": 8548,
    "package_name": "apdesign",
    "title": "An Implementation of the Additive Polynomial Design Matrix",
    "description": "An implementation of the additive polynomial (AP) design matrix. It\n    constructs and appends an AP design matrix to a data frame for use with\n    longitudinal data subject to seasonality.",
    "version": "1.0.0",
    "maintainer": "Tyler Matta <tyler.matta@gmail.com>",
    "author": "Tyler Matta [aut, cre],\n  Quinn Lathrop [ctb],\n  Yeow Meng Thum [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=apdesign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "apdesign An Implementation of the Additive Polynomial Design Matrix An implementation of the additive polynomial (AP) design matrix. It\n    constructs and appends an AP design matrix to a data frame for use with\n    longitudinal data subject to seasonality.  "
  },
  {
    "id": 8556,
    "package_name": "aplms",
    "title": "Additive Partial Linear Models with Symmetric Autoregressive\nErrors",
    "description": "Set of tools for fitting the additive partial linear models with symmetric autoregressive errors of order p, or APLMS-AR(p). This setup enables the modeling of a time series response variable using linear and nonlinear structures of a set of explanatory variables, with nonparametric components approximated by natural cubic splines or P-splines. It also accounts for autoregressive error terms with distributions that have lighter or heavier tails than the normal distribution. The package includes various error distributions, such as normal, generalized normal, Student's t, generalized Student's t, power-exponential, and Cauchy distributions. Chou-Chen, S.W., Oliveira, R.A., Raicher, I., Gilberto A. Paula (2024) <doi:10.1007/s00362-024-01590-w>.",
    "version": "0.1.0",
    "maintainer": "Shu Wei Chou-Chen <shuwei.chou@ucr.ac.cr>",
    "author": "Shu Wei Chou-Chen [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5495-2486>),\n  Rodrigo A. Oliveira [aut] (ORCID:\n    <https://orcid.org/0000-0003-3328-6669>),\n  Gilberto A. Paula [aut] (ORCID:\n    <https://orcid.org/0000-0002-9906-9942>),\n  Sebastian Sanchez Sandi [ctb]",
    "url": "https://github.com/shuwei325/aplms",
    "bug_reports": "https://github.com/shuwei325/aplms/issues",
    "repository": "https://cran.r-project.org/package=aplms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aplms Additive Partial Linear Models with Symmetric Autoregressive\nErrors Set of tools for fitting the additive partial linear models with symmetric autoregressive errors of order p, or APLMS-AR(p). This setup enables the modeling of a time series response variable using linear and nonlinear structures of a set of explanatory variables, with nonparametric components approximated by natural cubic splines or P-splines. It also accounts for autoregressive error terms with distributions that have lighter or heavier tails than the normal distribution. The package includes various error distributions, such as normal, generalized normal, Student's t, generalized Student's t, power-exponential, and Cauchy distributions. Chou-Chen, S.W., Oliveira, R.A., Raicher, I., Gilberto A. Paula (2024) <doi:10.1007/s00362-024-01590-w>.  "
  },
  {
    "id": 8579,
    "package_name": "apt",
    "title": "Asymmetric Price Transmission",
    "description": "The transmission between two time-series prices is assessed. It contains several functions for linear and nonlinear threshold co-integration, and furthermore, symmetric and asymmetric error correction models.",
    "version": "4.0",
    "maintainer": "Changyou Sun <edwinsun258@gmail.com>",
    "author": "Changyou Sun [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=apt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "apt Asymmetric Price Transmission The transmission between two time-series prices is assessed. It contains several functions for linear and nonlinear threshold co-integration, and furthermore, symmetric and asymmetric error correction models.  "
  },
  {
    "id": 8603,
    "package_name": "archiDART",
    "title": "Plant Root System Architecture Analysis Using DART and RSML\nFiles",
    "description": "Analysis of complex plant root system architectures (RSA) using the output files created by Data Analysis of Root Tracings (DART), an open-access software dedicated to the study of plant root architecture and development across time series (Le Bot et al (2010) \"DART: a software to analyse root system architecture and development from captured images\", Plant and Soil, <DOI:10.1007/s11104-009-0005-2>), and RSA data encoded with the Root System Markup Language (RSML) (Lobet et al (2015) \"Root System Markup Language: toward a unified root architecture description language\", Plant Physiology, <DOI:10.1104/pp.114.253625>). More information can be found in Delory et al (2016) \"archiDART: an R package for the automated computation of plant root architectural traits\", Plant and Soil, <DOI:10.1007/s11104-015-2673-4>.",
    "version": "3.4",
    "maintainer": "Benjamin M Delory <Benjamin.Delory@leuphana.de>",
    "author": "Benjamin M Delory, Caroline Baudson, Yves Brostaux, Guillaume Lobet, Patrick du Jardin, Loic Pages, Pierre Delaplace ",
    "url": "https://archidart.github.io/",
    "bug_reports": "https://github.com/archiDART/archidart/issues",
    "repository": "https://cran.r-project.org/package=archiDART",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "archiDART Plant Root System Architecture Analysis Using DART and RSML\nFiles Analysis of complex plant root system architectures (RSA) using the output files created by Data Analysis of Root Tracings (DART), an open-access software dedicated to the study of plant root architecture and development across time series (Le Bot et al (2010) \"DART: a software to analyse root system architecture and development from captured images\", Plant and Soil, <DOI:10.1007/s11104-009-0005-2>), and RSA data encoded with the Root System Markup Language (RSML) (Lobet et al (2015) \"Root System Markup Language: toward a unified root architecture description language\", Plant Physiology, <DOI:10.1104/pp.114.253625>). More information can be found in Delory et al (2016) \"archiDART: an R package for the automated computation of plant root architectural traits\", Plant and Soil, <DOI:10.1007/s11104-015-2673-4>.  "
  },
  {
    "id": 8614,
    "package_name": "arealDB",
    "title": "Harmonise and Integrate Heterogeneous Areal Data",
    "description": "Many relevant applications in the environmental and socioeconomic \n    sciences use areal data, such as biodiversity checklists, agricultural statistics, \n    or socioeconomic surveys. For applications that surpass the spatial, temporal or \n    thematic scope of any single data source, data must be integrated from several \n    heterogeneous sources. Inconsistent concepts, definitions, or messy data tables \n    make this a tedious and error-prone process. 'arealDB' tackles those problems and \n    helps the user to integrate a harmonised databases of areal data. Read the paper\n    at Ehrmann, Seppelt & Meyer (2020) <doi:10.1016/j.envsoft.2020.104799>.",
    "version": "0.9.4",
    "maintainer": "Steffen Ehrmann <steffen.ehrmann@posteo.de>",
    "author": "Steffen Ehrmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2958-0796>),\n  Arne R\u00fcmmler [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-8637-9071>),\n  Felipe Melges [ctb] (ORCID: <https://orcid.org/0000-0003-0833-8973>),\n  Carsten Meyer [aut] (ORCID: <https://orcid.org/0000-0003-3927-5856>)",
    "url": "https://github.com/luckinet/arealDB",
    "bug_reports": "https://github.com/luckinet/arealDB/issues",
    "repository": "https://cran.r-project.org/package=arealDB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arealDB Harmonise and Integrate Heterogeneous Areal Data Many relevant applications in the environmental and socioeconomic \n    sciences use areal data, such as biodiversity checklists, agricultural statistics, \n    or socioeconomic surveys. For applications that surpass the spatial, temporal or \n    thematic scope of any single data source, data must be integrated from several \n    heterogeneous sources. Inconsistent concepts, definitions, or messy data tables \n    make this a tedious and error-prone process. 'arealDB' tackles those problems and \n    helps the user to integrate a harmonised databases of areal data. Read the paper\n    at Ehrmann, Seppelt & Meyer (2020) <doi:10.1016/j.envsoft.2020.104799>.  "
  },
  {
    "id": 8619,
    "package_name": "arfima",
    "title": "Fractional ARIMA (and Other Long Memory) Time Series Modeling",
    "description": "Simulates, fits, and predicts long-memory and anti-persistent\n\ttime series, possibly mixed with ARMA, regression, transfer-function\n\tcomponents.\n\tExact methods (MLE, forecasting, simulation) are used.\n\tBug reports should be done via GitHub (at\n\t<https://github.com/JQVeenstra/arfima>), where the development version\n\tof this package lives; it can be installed using devtools.",
    "version": "1.8-2",
    "maintainer": "JQ Veenstra <jqveenstra@gmail.com>",
    "author": "JQ Veenstra [aut, cre] (Justin),\n  A.I. McLeod [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=arfima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arfima Fractional ARIMA (and Other Long Memory) Time Series Modeling Simulates, fits, and predicts long-memory and anti-persistent\n\ttime series, possibly mixed with ARMA, regression, transfer-function\n\tcomponents.\n\tExact methods (MLE, forecasting, simulation) are used.\n\tBug reports should be done via GitHub (at\n\t<https://github.com/JQVeenstra/arfima>), where the development version\n\tof this package lives; it can be installed using devtools.  "
  },
  {
    "id": 8631,
    "package_name": "arima2",
    "title": "Likelihood Based Inference for ARIMA Modeling",
    "description": "Estimating and analyzing auto regressive integrated moving average\n    (ARIMA) models. The primary function in this package is arima(), which fits \n    an ARIMA model to univariate time series data using a random restart\n    algorithm. This approach frequently leads to models that have model \n    likelihood greater than or equal to that of the likelihood obtained by \n    fitting the same model using the arima() function from the 'stats' package. \n    This package enables proper optimization of model likelihoods, which is a \n    necessary condition for performing likelihood ratio tests. This package \n    relies heavily on the source code of the arima() function of the 'stats' \n    package. For more information, please see Jesse Wheeler and Edward L. \n    Ionides (2025) <doi:10.1371/journal.pone.0333993>.",
    "version": "3.4.3",
    "maintainer": "Jesse Wheeler <jessewheeler@isu.edu>",
    "author": "Jesse Wheeler [aut, cre, cph],\n  Noel McAllister [aut],\n  Dhajanae Sylvertooth [aut],\n  Edward Ionides [ctb],\n  Brian Ripley [ctb] (Author of arima source code in stats package.),\n  R Core Team [cph] (Author of arima source code in stats package.)",
    "url": "",
    "bug_reports": "https://github.com/jeswheel/arima2/issues/",
    "repository": "https://cran.r-project.org/package=arima2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arima2 Likelihood Based Inference for ARIMA Modeling Estimating and analyzing auto regressive integrated moving average\n    (ARIMA) models. The primary function in this package is arima(), which fits \n    an ARIMA model to univariate time series data using a random restart\n    algorithm. This approach frequently leads to models that have model \n    likelihood greater than or equal to that of the likelihood obtained by \n    fitting the same model using the arima() function from the 'stats' package. \n    This package enables proper optimization of model likelihoods, which is a \n    necessary condition for performing likelihood ratio tests. This package \n    relies heavily on the source code of the arima() function of the 'stats' \n    package. For more information, please see Jesse Wheeler and Edward L. \n    Ionides (2025) <doi:10.1371/journal.pone.0333993>.  "
  },
  {
    "id": 8664,
    "package_name": "asciichartr",
    "title": "Lightweight ASCII Line Graphs",
    "description": "Create ASCII line graphs of a time series directly on\n    your terminal in an easy way. There are some configurations you\n    can add to make the plot the way you like. This project was\n    inspired by the original 'asciichart' package by Igor Kroitor.",
    "version": "0.1.0",
    "maintainer": "Brian <bleemayer@gmail.com>",
    "author": "Brian Lee Mayer",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=asciichartr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "asciichartr Lightweight ASCII Line Graphs Create ASCII line graphs of a time series directly on\n    your terminal in an easy way. There are some configurations you\n    can add to make the plot the way you like. This project was\n    inspired by the original 'asciichart' package by Igor Kroitor.  "
  },
  {
    "id": 8666,
    "package_name": "ascotraceR",
    "title": "Simulate the Spread of Ascochyta Blight in Chickpea",
    "description": "A spatiotemporal model that simulates the spread of Ascochyta\n    blight in chickpea fields based on location-specific weather conditions.\n    This model is adapted from a model developed by Diggle et al. (2002)\n   <doi:10.1094/PHYTO.2002.92.10.1110> for simulating the spread of anthracnose\n   in a lupin field.",
    "version": "0.0.1",
    "maintainer": "Paul Melloy <p.melloy@uq.edu.au>",
    "author": "Ihsanul Khaliq [aut] (ORCID: <https://orcid.org/0000-0003-4171-0917>),\n  Paul Melloy [aut, trl, cre] (ORCID:\n    <https://orcid.org/0000-0003-4253-7167>),\n  Adam H. Sparks [aut, ccp] (ORCID:\n    <https://orcid.org/0000-0002-0061-8359>),\n  Grains Research and Development Corporation (GRDC) Project\n    USQ1903-003RTX [fnd, cph],\n  University of Southern Queensland [cph],\n  Western Australia Agriculture Authority (WAAA) [cph] (Supported the\n    development of ascotraceR through Adam H.  Sparks' time.)",
    "url": "https://github.com/IhsanKhaliq/ascotraceR",
    "bug_reports": "https://github.com/IhsanKhaliq/ascotraceR/issues",
    "repository": "https://cran.r-project.org/package=ascotraceR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ascotraceR Simulate the Spread of Ascochyta Blight in Chickpea A spatiotemporal model that simulates the spread of Ascochyta\n    blight in chickpea fields based on location-specific weather conditions.\n    This model is adapted from a model developed by Diggle et al. (2002)\n   <doi:10.1094/PHYTO.2002.92.10.1110> for simulating the spread of anthracnose\n   in a lupin field.  "
  },
  {
    "id": 8698,
    "package_name": "astrochron",
    "title": "A Computational Tool for Astrochronology",
    "description": "Routines for astrochronologic testing, astronomical time scale construction, and time series analysis <doi:10.1016/j.earscirev.2018.11.015>. Also included are a range of statistical analysis and modeling routines that are relevant to time scale development and paleoclimate analysis.",
    "version": "1.5",
    "maintainer": "Stephen Meyers <smeyers@geology.wisc.edu>",
    "author": "Stephen Meyers [aut, cre],\n  Alberto Malinverno [ctb],\n  Linda Hinnov [ctb],\n  Christian Zeeden [ctb],\n  Huaran Liu [ctb],\n  Vincent Moron [ctb],\n  Michel Crucifix [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=astrochron",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "astrochron A Computational Tool for Astrochronology Routines for astrochronologic testing, astronomical time scale construction, and time series analysis <doi:10.1016/j.earscirev.2018.11.015>. Also included are a range of statistical analysis and modeling routines that are relevant to time scale development and paleoclimate analysis.  "
  },
  {
    "id": 8707,
    "package_name": "atRisk",
    "title": "At-Risk",
    "description": "The at-Risk (aR) approach is based on a two-step parametric estimation procedure that allows to forecast the full conditional distribution of an economic variable at a given horizon, as a function of a set of factors. These density forecasts are then be used to produce coherent forecasts for any downside risk measure, e.g., value-at-risk, expected shortfall, downside entropy. Initially introduced by Adrian et al. (2019) <doi:10.1257/aer.20161923> to reveal the vulnerability of economic growth to financial conditions, the aR approach is currently extensively used by international financial institutions to provide Value-at-Risk (VaR) type forecasts for GDP growth (Growth-at-Risk) or inflation (Inflation-at-Risk). This package provides methods for estimating these models. Datasets for the US and the Eurozone are available to allow testing of the Adrian et al. (2019) model. This package constitutes a useful toolbox (data and functions) for private practitioners, scholars as well as policymakers.",
    "version": "0.2.0",
    "maintainer": "Quentin Lajaunie <quentin_lajaunie@hotmail.fr>",
    "author": "Quentin Lajaunie [aut, cre],\n  Guillaume Flament [aut, ctb],\n  Christophe Hurlin [aut],\n  Souzan Kazemi [rev]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=atRisk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "atRisk At-Risk The at-Risk (aR) approach is based on a two-step parametric estimation procedure that allows to forecast the full conditional distribution of an economic variable at a given horizon, as a function of a set of factors. These density forecasts are then be used to produce coherent forecasts for any downside risk measure, e.g., value-at-risk, expected shortfall, downside entropy. Initially introduced by Adrian et al. (2019) <doi:10.1257/aer.20161923> to reveal the vulnerability of economic growth to financial conditions, the aR approach is currently extensively used by international financial institutions to provide Value-at-Risk (VaR) type forecasts for GDP growth (Growth-at-Risk) or inflation (Inflation-at-Risk). This package provides methods for estimating these models. Datasets for the US and the Eurozone are available to allow testing of the Adrian et al. (2019) model. This package constitutes a useful toolbox (data and functions) for private practitioners, scholars as well as policymakers.  "
  },
  {
    "id": 8712,
    "package_name": "atlas",
    "title": "Stanford 'ATLAS' Search Engine API",
    "description": "Stanford 'ATLAS' (Advanced Temporal Search Engine) is a powerful tool that allows constructing\n             cohorts of patients extremely quickly and efficiently. This package is designed to interface directly\n             with an instance of 'ATLAS' search engine and facilitates API queries and data dumps. Prerequisite\n             is a good knowledge of the temporal language to be able to efficiently construct a query.\n             More information available at <https://shahlab.stanford.edu/start>.",
    "version": "1.0.0",
    "maintainer": "Vladimir Polony <podalv@gmail.com>",
    "author": "Vladimir Polony",
    "url": "https://shahlab.stanford.edu/start",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=atlas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "atlas Stanford 'ATLAS' Search Engine API Stanford 'ATLAS' (Advanced Temporal Search Engine) is a powerful tool that allows constructing\n             cohorts of patients extremely quickly and efficiently. This package is designed to interface directly\n             with an instance of 'ATLAS' search engine and facilitates API queries and data dumps. Prerequisite\n             is a good knowledge of the temporal language to be able to efficiently construct a query.\n             More information available at <https://shahlab.stanford.edu/start>.  "
  },
  {
    "id": 8729,
    "package_name": "audrex",
    "title": "Automatic Dynamic Regression using Extreme Gradient Boosting",
    "description": "Dynamic regression for time series using Extreme Gradient Boosting with hyper-parameter tuning via Bayesian Optimization or Random Search.",
    "version": "2.0.1",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino",
    "url": "https://rpubs.com/giancarlo_vercellino/audrex",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=audrex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "audrex Automatic Dynamic Regression using Extreme Gradient Boosting Dynamic regression for time series using Extreme Gradient Boosting with hyper-parameter tuning via Bayesian Optimization or Random Search.  "
  },
  {
    "id": 8747,
    "package_name": "autoTS",
    "title": "Automatic Model Selection and Prediction for Univariate Time\nSeries",
    "description": "Offers a set of functions to easily make predictions for univariate time series. \n             'autoTS' is a wrapper of existing functions of the 'forecast' and 'prophet' packages, \n             harmonising their outputs in tidy dataframes and using default values for each.\n             The core function getBestModel() allows the user to effortlessly benchmark seven \n             algorithms along with a bagged estimator to identify which one performs the best \n             for a given time series.",
    "version": "0.9.11",
    "maintainer": "Vivien Roussez <vivien.roussez@gmail.com>",
    "author": "Vivien Roussez",
    "url": "https://github.com/vivienroussez/autoTS",
    "bug_reports": "https://github.com/vivienroussez/autots/issues",
    "repository": "https://cran.r-project.org/package=autoTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "autoTS Automatic Model Selection and Prediction for Univariate Time\nSeries Offers a set of functions to easily make predictions for univariate time series. \n             'autoTS' is a wrapper of existing functions of the 'forecast' and 'prophet' packages, \n             harmonising their outputs in tidy dataframes and using default values for each.\n             The core function getBestModel() allows the user to effortlessly benchmark seven \n             algorithms along with a bagged estimator to identify which one performs the best \n             for a given time series.  "
  },
  {
    "id": 8766,
    "package_name": "autostsm",
    "title": "Automatic Structural Time Series Models",
    "description": "Automatic model selection for structural time series decomposition into trend, cycle, and seasonal components, plus optionality for structural interpolation, using the Kalman filter. \n  Koopman, Siem Jan and Marius Ooms (2012) \"Forecasting Economic Time Series Using Unobserved Components Time Series Models\" <doi:10.1093/oxfordhb/9780195398649.013.0006>.\n  Kim, Chang-Jin and Charles R. Nelson (1999) \"State-Space Models with Regime Switching: Classical and Gibbs-Sampling Approaches with Applications\" <doi:10.7551/mitpress/6444.001.0001><http://econ.korea.ac.kr/~cjkim/>. ",
    "version": "3.1.5",
    "maintainer": "Alex Hubbard <hubbard.alex@gmail.com>",
    "author": "Alex Hubbard [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=autostsm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "autostsm Automatic Structural Time Series Models Automatic model selection for structural time series decomposition into trend, cycle, and seasonal components, plus optionality for structural interpolation, using the Kalman filter. \n  Koopman, Siem Jan and Marius Ooms (2012) \"Forecasting Economic Time Series Using Unobserved Components Time Series Models\" <doi:10.1093/oxfordhb/9780195398649.013.0006>.\n  Kim, Chang-Jin and Charles R. Nelson (1999) \"State-Space Models with Regime Switching: Classical and Gibbs-Sampling Approaches with Applications\" <doi:10.7551/mitpress/6444.001.0001><http://econ.korea.ac.kr/~cjkim/>.   "
  },
  {
    "id": 8772,
    "package_name": "avar",
    "title": "Allan Variance",
    "description": "Implements the allan variance and allan variance linear regression estimator for latent time series models. More details about the method can be found, for example, in Guerrier, S., Molinari, R., & Stebler, Y. (2016) <doi:10.1109/LSP.2016.2541867>. ",
    "version": "0.1.3",
    "maintainer": "St\u00e9phane Guerrier <stef.guerrier@gmail.com>",
    "author": "St\u00e9phane Guerrier [aut, cre],\n  James Balamuta [aut],\n  Gaetan Bakalli [aut],\n  Roberto Molinari [aut],\n  Justin Lee [aut],\n  Ahmed Radi [aut],\n  Haotian Xu [aut],\n  Yuming Zhang [aut],\n  Nathanael Claussen [aut],\n  Lionel Voirol [ctb]",
    "url": "https://github.com/SMAC-Group/avar",
    "bug_reports": "https://github.com/SMAC-Group/avar/issues",
    "repository": "https://cran.r-project.org/package=avar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "avar Allan Variance Implements the allan variance and allan variance linear regression estimator for latent time series models. More details about the method can be found, for example, in Guerrier, S., Molinari, R., & Stebler, Y. (2016) <doi:10.1109/LSP.2016.2541867>.   "
  },
  {
    "id": 8781,
    "package_name": "awdb",
    "title": "Query the USDA NWCC Air and Water Database REST API",
    "description": "Query the four endpoints of the 'Air and Water Database (AWDB) REST\n    API' maintained by the National Water and Climate Center (NWCC) at the \n    United States Department of Agriculture (USDA). Endpoints include data, \n    forecast, reference-data, and metadata. The package is extremely light \n    weight, with 'Rust' via 'extendr' doing most of the heavy lifting to \n    deserialize and flatten deeply nested 'JSON' responses. The AWDB can be \n    found at <https://wcc.sc.egov.usda.gov/awdbRestApi/swagger-ui/index.html>.",
    "version": "0.1.3",
    "maintainer": "Kenneth Blake Vernon <kenneth.b.vernon@gmail.com>",
    "author": "Kenneth Blake Vernon [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0098-5092>)",
    "url": "https://github.com/kbvernon/awdb, https://kbvernon.github.io/awdb/",
    "bug_reports": "https://github.com/kbvernon/awdb/issues",
    "repository": "https://cran.r-project.org/package=awdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "awdb Query the USDA NWCC Air and Water Database REST API Query the four endpoints of the 'Air and Water Database (AWDB) REST\n    API' maintained by the National Water and Climate Center (NWCC) at the \n    United States Department of Agriculture (USDA). Endpoints include data, \n    forecast, reference-data, and metadata. The package is extremely light \n    weight, with 'Rust' via 'extendr' doing most of the heavy lifting to \n    deserialize and flatten deeply nested 'JSON' responses. The AWDB can be \n    found at <https://wcc.sc.egov.usda.gov/awdbRestApi/swagger-ui/index.html>.  "
  },
  {
    "id": 8797,
    "package_name": "aws.wrfsmn",
    "title": "Data Processing of SMN Hi-Res Weather Forecast from 'AWS'",
    "description": "Exploration of Weather Research & Forecasting ('WRF') Model data\n    of Servicio Meteorologico Nacional (SMN) from Amazon Web Services\n    (<https://registry.opendata.aws/smn-ar-wrf-dataset/>) cloud. The package\n    provides the possibility of data downloading, processing and correction\n    methods. It also has map management and series exploration of available\n    meteorological variables of 'WRF' forecast.",
    "version": "0.1.0",
    "maintainer": "Gonzalo Diaz <gonzalomartindiaz22@gmail.com>",
    "author": "Gonzalo Diaz [cre, aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aws.wrfsmn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aws.wrfsmn Data Processing of SMN Hi-Res Weather Forecast from 'AWS' Exploration of Weather Research & Forecasting ('WRF') Model data\n    of Servicio Meteorologico Nacional (SMN) from Amazon Web Services\n    (<https://registry.opendata.aws/smn-ar-wrf-dataset/>) cloud. The package\n    provides the possibility of data downloading, processing and correction\n    methods. It also has map management and series exploration of available\n    meteorological variables of 'WRF' forecast.  "
  },
  {
    "id": 8826,
    "package_name": "baf",
    "title": "Block Assignment Files",
    "description": "Download and read US Census Bureau data relationship files. Provides \n    support for cleaning and using block assignment files since 2010, as described in \n    <https://www.census.gov/geographies/reference-files/time-series/geo/block-assignment-files.html>. \n    Also includes support for working with block equivalency files, used for years \n    outside of decennial census years.",
    "version": "0.0.4",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>),\n  Cory McCartan [ctb] (ORCID: <https://orcid.org/0000-0002-6251-669X>)",
    "url": "http://christophertkenny.com/baf/,\nhttps://github.com/christopherkenny/baf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=baf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "baf Block Assignment Files Download and read US Census Bureau data relationship files. Provides \n    support for cleaning and using block assignment files since 2010, as described in \n    <https://www.census.gov/geographies/reference-files/time-series/geo/block-assignment-files.html>. \n    Also includes support for working with block equivalency files, used for years \n    outside of decennial census years.  "
  },
  {
    "id": 8828,
    "package_name": "bage",
    "title": "Bayesian Estimation and Forecasting of Age-Specific Rates",
    "description": "Fast Bayesian estimation and forecasting of age-specific\n    rates, probabilities, and means, based on 'Template Model Builder'.",
    "version": "0.10.2",
    "maintainer": "John Bryant <john@bayesiandemography.com>",
    "author": "John Bryant [aut, cre],\n  Junni Zhang [aut],\n  Bayesian Demography Limited [cph]",
    "url": "https://bayesiandemography.github.io/bage/,\nhttps://github.com/bayesiandemography/bage",
    "bug_reports": "https://github.com/bayesiandemography/bage/issues",
    "repository": "https://cran.r-project.org/package=bage",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bage Bayesian Estimation and Forecasting of Age-Specific Rates Fast Bayesian estimation and forecasting of age-specific\n    rates, probabilities, and means, based on 'Template Model Builder'.  "
  },
  {
    "id": 8913,
    "package_name": "bayesDccGarch",
    "title": "Methods and Tools for Bayesian Dynamic Conditional Correlation\nGARCH(1,1) Model",
    "description": "Bayesian estimation of dynamic conditional correlation GARCH model for multivariate time series volatility (Fioruci, J.A., Ehlers, R.S. and Andrade-Filho, M.G., (2014). <doi:10.1080/02664763.2013.839635>.",
    "version": "3.0.4",
    "maintainer": "Jose Augusto Fiorucci <jafiorucci@gmail.com>",
    "author": "Jose Augusto Fiorucci [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1201-9089>),\n  Ricardo Sanders Ehlers [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-9034-5173>),\n  Francisco Louzada [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-7815-9554>)",
    "url": "https://ui.adsabs.harvard.edu/abs/2014arXiv1412.2967F/abstract",
    "bug_reports": "https://github.com/jafiorucci/bayesDccGarch/issues",
    "repository": "https://cran.r-project.org/package=bayesDccGarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesDccGarch Methods and Tools for Bayesian Dynamic Conditional Correlation\nGARCH(1,1) Model Bayesian estimation of dynamic conditional correlation GARCH model for multivariate time series volatility (Fioruci, J.A., Ehlers, R.S. and Andrade-Filho, M.G., (2014). <doi:10.1080/02664763.2013.839635>.  "
  },
  {
    "id": 8926,
    "package_name": "bayesRecon",
    "title": "Probabilistic Reconciliation via Conditioning",
    "description": "Provides methods for probabilistic reconciliation of hierarchical forecasts of time series. \n             The available methods include analytical Gaussian reconciliation (Corani et al., 2021) \n             <doi:10.1007/978-3-030-67664-3_13>, \n             MCMC reconciliation of count time series (Corani et al., 2024) \n             <doi:10.1016/j.ijforecast.2023.04.003>, \n             Bottom-Up Importance Sampling (Zambon et al., 2024) \n             <doi:10.1007/s11222-023-10343-y>,\n             methods for the reconciliation of mixed hierarchies (Mix-Cond and TD-cond)\n             (Zambon et al., 2024) <https://proceedings.mlr.press/v244/zambon24a.html>. ",
    "version": "0.3.3",
    "maintainer": "Dario Azzimonti <dario.azzimonti@gmail.com>",
    "author": "Dario Azzimonti [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5080-3061>),\n  Nicol\u00f2 Rubattu [aut] (ORCID: <https://orcid.org/0000-0002-2703-1005>),\n  Lorenzo Zambon [aut] (ORCID: <https://orcid.org/0000-0002-8939-993X>),\n  Giorgio Corani [aut] (ORCID: <https://orcid.org/0000-0002-1541-8384>)",
    "url": "https://github.com/IDSIA/bayesRecon,\nhttps://idsia.github.io/bayesRecon/",
    "bug_reports": "https://github.com/IDSIA/bayesRecon/issues",
    "repository": "https://cran.r-project.org/package=bayesRecon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesRecon Probabilistic Reconciliation via Conditioning Provides methods for probabilistic reconciliation of hierarchical forecasts of time series. \n             The available methods include analytical Gaussian reconciliation (Corani et al., 2021) \n             <doi:10.1007/978-3-030-67664-3_13>, \n             MCMC reconciliation of count time series (Corani et al., 2024) \n             <doi:10.1016/j.ijforecast.2023.04.003>, \n             Bottom-Up Importance Sampling (Zambon et al., 2024) \n             <doi:10.1007/s11222-023-10343-y>,\n             methods for the reconciliation of mixed hierarchies (Mix-Cond and TD-cond)\n             (Zambon et al., 2024) <https://proceedings.mlr.press/v244/zambon24a.html>.   "
  },
  {
    "id": 8938,
    "package_name": "bayesdfa",
    "title": "Bayesian Dynamic Factor Analysis (DFA) with 'Stan'",
    "description": "Implements Bayesian dynamic factor analysis with 'Stan'. Dynamic \n    factor analysis is a dimension reduction tool for multivariate time series.\n    'bayesdfa' extends conventional dynamic factor models in several ways. \n    First, extreme events may be estimated in the latent trend by modeling\n    process error with a student-t distribution. Second, alternative constraints\n    (including proportions are allowed). Third, the estimated\n    dynamic factors can be analyzed with hidden Markov models to evaluate\n    support for latent regimes.",
    "version": "1.3.4",
    "maintainer": "Eric J. Ward <eric.ward@noaa.gov>",
    "author": "Eric J. Ward [aut, cre],\n  Sean C. Anderson [aut],\n  Luis A. Damiano [aut],\n  Michael J. Malick [aut],\n  Philina A. English [aut],\n  Mary E. Hunsicker, [ctb],\n  Mike A. Litzow [ctb],\n  Mark D. Scheuerell [ctb],\n  Elizabeth E. Holmes [ctb],\n  Nick Tolimieri [ctb],\n  Trustees of Columbia University [cph]",
    "url": "https://fate-ewi.github.io/bayesdfa/",
    "bug_reports": "https://github.com/fate-ewi/bayesdfa/issues",
    "repository": "https://cran.r-project.org/package=bayesdfa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesdfa Bayesian Dynamic Factor Analysis (DFA) with 'Stan' Implements Bayesian dynamic factor analysis with 'Stan'. Dynamic \n    factor analysis is a dimension reduction tool for multivariate time series.\n    'bayesdfa' extends conventional dynamic factor models in several ways. \n    First, extreme events may be estimated in the latent trend by modeling\n    process error with a student-t distribution. Second, alternative constraints\n    (including proportions are allowed). Third, the estimated\n    dynamic factors can be analyzed with hidden Markov models to evaluate\n    support for latent regimes.  "
  },
  {
    "id": 8941,
    "package_name": "bayesforecast",
    "title": "Bayesian Time Series Modeling with Stan",
    "description": "Fit Bayesian time series models using 'Stan' for full Bayesian inference. A wide range \n  of distributions and models are supported, allowing users to fit Seasonal ARIMA, ARIMAX, Dynamic \n  Harmonic Regression, GARCH, t-student innovation GARCH models, asymmetric GARCH, Random Walks, stochastic \n  volatility models for univariate time series. Prior specifications are flexible and explicitly encourage \n  users to apply prior distributions that actually reflect their beliefs. Model fit can easily be assessed \n  and compared with typical visualization methods, information criteria such as loglik, AIC, BIC WAIC, Bayes \n  factor and leave-one-out cross-validation methods. References: Hyndman (2017)\n    <doi:10.18637/jss.v027.i03>; Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
    "version": "1.0.5",
    "maintainer": "Asael Alonzo Matamoros <asael.alonzo@gmail.com>",
    "author": "Asael Alonzo Matamoros [aut, cre],\n  Cristian Cruz Torres [aut],\n  Andres Dala [ctb],\n  Rob Hyndman [ctb],\n  Mitchell O'Hara-Wild [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bayesforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesforecast Bayesian Time Series Modeling with Stan Fit Bayesian time series models using 'Stan' for full Bayesian inference. A wide range \n  of distributions and models are supported, allowing users to fit Seasonal ARIMA, ARIMAX, Dynamic \n  Harmonic Regression, GARCH, t-student innovation GARCH models, asymmetric GARCH, Random Walks, stochastic \n  volatility models for univariate time series. Prior specifications are flexible and explicitly encourage \n  users to apply prior distributions that actually reflect their beliefs. Model fit can easily be assessed \n  and compared with typical visualization methods, information criteria such as loglik, AIC, BIC WAIC, Bayes \n  factor and leave-one-out cross-validation methods. References: Hyndman (2017)\n    <doi:10.18637/jss.v027.i03>; Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>.  "
  },
  {
    "id": 8943,
    "package_name": "bayesianETAS",
    "title": "Bayesian Estimation of the ETAS Model for Earthquake Occurrences",
    "description": "The Epidemic Type Aftershock Sequence  (ETAS) model is one of the best-performing methods for modeling and forecasting earthquake occurrences. This package implements Bayesian estimation routines to draw samples from the full posterior distribution of the model parameters, given an earthquake catalog. The paper on which this package is based is Gordon J. Ross - Bayesian Estimation of the ETAS Model for Earthquake Occurrences (2016), available from the below URL.",
    "version": "1.0.3",
    "maintainer": "Gordon J. Ross <gordon@gordonjross.co.uk>",
    "author": "Gordon J. Ross",
    "url": "http://www.gordonjross.co.uk/bayesianetas.pdf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bayesianETAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesianETAS Bayesian Estimation of the ETAS Model for Earthquake Occurrences The Epidemic Type Aftershock Sequence  (ETAS) model is one of the best-performing methods for modeling and forecasting earthquake occurrences. This package implements Bayesian estimation routines to draw samples from the full posterior distribution of the model parameters, given an earthquake catalog. The paper on which this package is based is Gordon J. Ross - Bayesian Estimation of the ETAS Model for Earthquake Occurrences (2016), available from the below URL.  "
  },
  {
    "id": 8961,
    "package_name": "bayfoxr",
    "title": "Global Bayesian Foraminifera Core Top Calibration",
    "description": "A Bayesian, global planktic foraminifera core top calibration to \n    modern sea-surface temperatures. Includes four calibration models, \n    considering species-specific calibration parameters and seasonality.",
    "version": "0.0.1",
    "maintainer": "Steven Malevich <malevich@email.arizona.edu>",
    "author": "Steven Malevich [aut, cre]",
    "url": "https://github.com/brews/bayfoxr/",
    "bug_reports": "https://github.com/brews/bayfoxr/issues",
    "repository": "https://cran.r-project.org/package=bayfoxr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayfoxr Global Bayesian Foraminifera Core Top Calibration A Bayesian, global planktic foraminifera core top calibration to \n    modern sea-surface temperatures. Includes four calibration models, \n    considering species-specific calibration parameters and seasonality.  "
  },
  {
    "id": 8965,
    "package_name": "baytrends",
    "title": "Long Term Water Quality Trend Analysis",
    "description": "Enable users to evaluate long-term trends using a Generalized \n    Additive Modeling (GAM) approach. The model development includes selecting a \n    GAM structure to describe nonlinear seasonally-varying changes over time, \n    incorporation of hydrologic variability via either a river flow or salinity, \n    the use of an intervention to deal with method or laboratory changes \n    suspected to impact data values, and representation of left- and \n    interval-censored data. The approach has been applied to water quality data \n    in the Chesapeake Bay, a major estuary on the east coast of the United \n    States to provide insights to a range of management- and research-focused \n    questions.  Methodology described in Murphy (2019) \n    <doi:10.1016/j.envsoft.2019.03.027>.",
    "version": "2.0.12",
    "maintainer": "Erik W Leppo <Erik.Leppo@tetratech.com>",
    "author": "Rebecca Murphy, Elgin Perry, Jennifer Keisman, Jon Harcum, Erik W Leppo",
    "url": "https://github.com/tetratech/baytrends,\nhttps://tetratech.github.io/baytrends/",
    "bug_reports": "https://github.com/tetratech/baytrends/issues",
    "repository": "https://cran.r-project.org/package=baytrends",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "baytrends Long Term Water Quality Trend Analysis Enable users to evaluate long-term trends using a Generalized \n    Additive Modeling (GAM) approach. The model development includes selecting a \n    GAM structure to describe nonlinear seasonally-varying changes over time, \n    incorporation of hydrologic variability via either a river flow or salinity, \n    the use of an intervention to deal with method or laboratory changes \n    suspected to impact data values, and representation of left- and \n    interval-censored data. The approach has been applied to water quality data \n    in the Chesapeake Bay, a major estuary on the east coast of the United \n    States to provide insights to a range of management- and research-focused \n    questions.  Methodology described in Murphy (2019) \n    <doi:10.1016/j.envsoft.2019.03.027>.  "
  },
  {
    "id": 8967,
    "package_name": "bbk",
    "title": "Client for Central Bank APIs",
    "description": "A client for retrieving data and metadata from major central\n    bank APIs. It supports access to the 'Bundesbank SDMX Web Service API'\n    (<https://www.bundesbank.de/en/statistics/time-series-databases/help-for-sdmx-web-service/web-service-interface-data>),\n    the 'Swiss National Bank Data Portal' (<https://data.snb.ch/en>), the\n    'European Central Bank Data Portal API'\n    (<https://data.ecb.europa.eu/help/api/overview>), the 'Bank of England\n    Interactive Statistical Database'\n    (<https://www.bankofengland.co.uk/boeapps/database>), the 'Banco de\n    Espa\u00f1a API'\n    (<https://www.bde.es/webbe/en/estadisticas/recursos/api-estadisticas-bde.html>),\n    the 'Banque de France Web Service'\n    (<https://webstat.banque-france.fr/en/pages/guide-migration-api/>),\n    and 'Bank of Canada Valet API'\n    (<https://www.bankofcanada.ca/valet/docs>).",
    "version": "0.8.0",
    "maintainer": "Maximilian M\u00fccke <muecke.maximilian@gmail.com>",
    "author": "Maximilian M\u00fccke [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9432-9795>)",
    "url": "https://m-muecke.github.io/bbk/, https://github.com/m-muecke/bbk",
    "bug_reports": "https://github.com/m-muecke/bbk/issues",
    "repository": "https://cran.r-project.org/package=bbk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bbk Client for Central Bank APIs A client for retrieving data and metadata from major central\n    bank APIs. It supports access to the 'Bundesbank SDMX Web Service API'\n    (<https://www.bundesbank.de/en/statistics/time-series-databases/help-for-sdmx-web-service/web-service-interface-data>),\n    the 'Swiss National Bank Data Portal' (<https://data.snb.ch/en>), the\n    'European Central Bank Data Portal API'\n    (<https://data.ecb.europa.eu/help/api/overview>), the 'Bank of England\n    Interactive Statistical Database'\n    (<https://www.bankofengland.co.uk/boeapps/database>), the 'Banco de\n    Espa\u00f1a API'\n    (<https://www.bde.es/webbe/en/estadisticas/recursos/api-estadisticas-bde.html>),\n    the 'Banque de France Web Service'\n    (<https://webstat.banque-france.fr/en/pages/guide-migration-api/>),\n    and 'Bank of Canada Valet API'\n    (<https://www.bankofcanada.ca/valet/docs>).  "
  },
  {
    "id": 8987,
    "package_name": "bcpa",
    "title": "Behavioral Change Point Analysis of Animal Movement",
    "description": "The Behavioral Change Point Analysis (BCPA) is a method of\n    identifying hidden shifts in the underlying parameters of a time series,\n    developed specifically to be applied to animal movement data which is\n    irregularly sampled.  The method is based on: E. Gurarie, R. Andrews and \n    K. Laidre A novel method for identifying behavioural changes in animal \n    movement data (2009) Ecology Letters 12:5 395-408. A development version is \n    on <https://github.com/EliGurarie/bcpa>. NOTE: the BCPA method may be useful \n    for any univariate, irregularly sampled Gaussian time-series, but animal \n    movement analysts are encouraged to apply correlated velocity change point \n    analysis as implemented in the smoove package, as of this writing on GitHub \n    at <https://github.com/EliGurarie/smoove>. An example of a univariate analysis\n    is provided in the UnivariateBCPA vignette. ",
    "version": "1.3.2",
    "maintainer": "Eliezer Gurarie <egurarie@esf.edu>",
    "author": "Eliezer Gurarie <egurarie@esf.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bcpa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bcpa Behavioral Change Point Analysis of Animal Movement The Behavioral Change Point Analysis (BCPA) is a method of\n    identifying hidden shifts in the underlying parameters of a time series,\n    developed specifically to be applied to animal movement data which is\n    irregularly sampled.  The method is based on: E. Gurarie, R. Andrews and \n    K. Laidre A novel method for identifying behavioural changes in animal \n    movement data (2009) Ecology Letters 12:5 395-408. A development version is \n    on <https://github.com/EliGurarie/bcpa>. NOTE: the BCPA method may be useful \n    for any univariate, irregularly sampled Gaussian time-series, but animal \n    movement analysts are encouraged to apply correlated velocity change point \n    analysis as implemented in the smoove package, as of this writing on GitHub \n    at <https://github.com/EliGurarie/smoove>. An example of a univariate analysis\n    is provided in the UnivariateBCPA vignette.   "
  },
  {
    "id": 9001,
    "package_name": "bdots",
    "title": "Bootstrapped Differences of Time Series",
    "description": "Analyze differences among time series curves with p-value\n        adjustment for multiple comparisons introduced in Oleson et al\n        (2015) <DOI:10.1177/0962280215607411>.",
    "version": "2.0.0",
    "maintainer": "Collin Nolte <noltecollin@grinnell.edu>",
    "author": "Collin Nolte [aut, cre],\n  Michael Seedorff [aut],\n  Jacob Oleson [aut],\n  Grant Brown [aut],\n  Joseph Cavanaugh [aut],\n  Bob McMurray [aut]",
    "url": "https://github.com/collinn/bdots",
    "bug_reports": "https://github.com/collinn/bdots/issues",
    "repository": "https://cran.r-project.org/package=bdots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bdots Bootstrapped Differences of Time Series Analyze differences among time series curves with p-value\n        adjustment for multiple comparisons introduced in Oleson et al\n        (2015) <DOI:10.1177/0962280215607411>.  "
  },
  {
    "id": 9017,
    "package_name": "beast",
    "title": "Bayesian Estimation of Change-Points in the Slope of\nMultivariate Time-Series",
    "description": "Assume that a temporal process is composed of contiguous segments with differing slopes and replicated noise-corrupted time series measurements are observed. The unknown mean of the data generating process is modelled as a piecewise linear function of time with an unknown number of change-points. The package infers the joint posterior distribution of the number and position of change-points as well as the unknown mean parameters per time-series by MCMC sampling. A-priori, the proposed model uses an overfitting number of mean parameters but, conditionally on a set of change-points, only a subset of them influences the likelihood. An exponentially decreasing prior distribution on the number of change-points gives rise to a posterior distribution concentrating on sparse representations of the underlying sequence, but also available is the Poisson distribution. See Papastamoulis et al (2017) <arXiv:1709.06111> for a detailed presentation of the method.",
    "version": "1.1",
    "maintainer": "Panagiotis Papastamoulis <papapast@yahoo.gr>",
    "author": "Panagiotis Papastamoulis",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=beast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "beast Bayesian Estimation of Change-Points in the Slope of\nMultivariate Time-Series Assume that a temporal process is composed of contiguous segments with differing slopes and replicated noise-corrupted time series measurements are observed. The unknown mean of the data generating process is modelled as a piecewise linear function of time with an unknown number of change-points. The package infers the joint posterior distribution of the number and position of change-points as well as the unknown mean parameters per time-series by MCMC sampling. A-priori, the proposed model uses an overfitting number of mean parameters but, conditionally on a set of change-points, only a subset of them influences the likelihood. An exponentially decreasing prior distribution on the number of change-points gives rise to a posterior distribution concentrating on sparse representations of the underlying sequence, but also available is the Poisson distribution. See Papastamoulis et al (2017) <arXiv:1709.06111> for a detailed presentation of the method.  "
  },
  {
    "id": 9039,
    "package_name": "bentcableAR",
    "title": "Bent-Cable Regression for Independent Data or Autoregressive\nTime Series",
    "description": "\n\tIncluded are two main interfaces, bentcable.ar() and\n\tbentcable.dev.plot(), for fitting and diagnosing bent-cable\n\tregressions for autoregressive time-series data (Chiu and\n\tLockhart 2010, <doi:10.1002/cjs.10070>) or independent data (time\n\tseries or otherwise - Chiu, Lockhart and Routledge 2006,\n\t<doi:10.1198/016214505000001177>). Some components in the package\n\tcan also be used as stand-alone functions. The bent cable\n\t(linear-quadratic-linear) generalizes the broken stick\n\t(linear-linear), which is also handled by this package. Version\n\t0.2 corrected a glitch in the computation of confidence intervals\n\tfor the CTP. References that were updated from Versions 0.2.1 and\n\t0.2.2 appear in Version 0.2.3 and up. Version 0.3.0 improved\n\trobustness of the error-message producing mechanism. Version 0.3.1\n\timproves the NAMESPACE file of the package. It is the author's\n\tintention to distribute any future updates via GitHub.",
    "version": "0.3.1",
    "maintainer": "Grace Chiu <bentcable@gmail.com>",
    "author": "\n\tGrace Chiu <bentcable@gmail.com>,\n\tVirginia Institute of Marine Science, William & Mary\n\tPO Box 1346, Gloucester Point, VA 23062, USA",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bentcableAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bentcableAR Bent-Cable Regression for Independent Data or Autoregressive\nTime Series \n\tIncluded are two main interfaces, bentcable.ar() and\n\tbentcable.dev.plot(), for fitting and diagnosing bent-cable\n\tregressions for autoregressive time-series data (Chiu and\n\tLockhart 2010, <doi:10.1002/cjs.10070>) or independent data (time\n\tseries or otherwise - Chiu, Lockhart and Routledge 2006,\n\t<doi:10.1198/016214505000001177>). Some components in the package\n\tcan also be used as stand-alone functions. The bent cable\n\t(linear-quadratic-linear) generalizes the broken stick\n\t(linear-linear), which is also handled by this package. Version\n\t0.2 corrected a glitch in the computation of confidence intervals\n\tfor the CTP. References that were updated from Versions 0.2.1 and\n\t0.2.2 appear in Version 0.2.3 and up. Version 0.3.0 improved\n\trobustness of the error-message producing mechanism. Version 0.3.1\n\timproves the NAMESPACE file of the package. It is the author's\n\tintention to distribute any future updates via GitHub.  "
  },
  {
    "id": 9060,
    "package_name": "betategarch",
    "title": "Simulation, Estimation and Forecasting of Beta-Skew-t-EGARCH\nModels",
    "description": "Simulation, estimation and forecasting of first-order Beta-Skew-t-EGARCH models with leverage (one-component, two-component, skewed versions).",
    "version": "3.4",
    "maintainer": "Genaro Sucarrat <genaro.sucarrat@bi.no>",
    "author": "Genaro Sucarrat [aut, cre]",
    "url": "https://www.sucarrat.net/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=betategarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "betategarch Simulation, Estimation and Forecasting of Beta-Skew-t-EGARCH\nModels Simulation, estimation and forecasting of first-order Beta-Skew-t-EGARCH models with leverage (one-component, two-component, skewed versions).  "
  },
  {
    "id": 9064,
    "package_name": "beyondWhittle",
    "title": "Bayesian Spectral Inference for Time Series",
    "description": "Implementations of Bayesian parametric, nonparametric and semiparametric procedures for univariate and multivariate time series. The package is based on the methods presented in C. Kirch et al (2018) <doi:10.1214/18-BA1126>, A. Meier (2018) <https://opendata.uni-halle.de//handle/1981185920/13470> and Y. Tang et al (2023) <doi:10.48550/arXiv.2303.11561>. It was supported by DFG grants KI 1443/3-1 and KI 1443/3-2.",
    "version": "1.3.0",
    "maintainer": "Renate Meyer <renate.meyer@auckland.ac.nz>",
    "author": "Alexander Meier [aut],\n  Claudia Kirch [aut],\n  Matthew C. Edwards [aut],\n  Renate Meyer [aut, cre],\n  Yifu Tang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=beyondWhittle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "beyondWhittle Bayesian Spectral Inference for Time Series Implementations of Bayesian parametric, nonparametric and semiparametric procedures for univariate and multivariate time series. The package is based on the methods presented in C. Kirch et al (2018) <doi:10.1214/18-BA1126>, A. Meier (2018) <https://opendata.uni-halle.de//handle/1981185920/13470> and Y. Tang et al (2023) <doi:10.48550/arXiv.2303.11561>. It was supported by DFG grants KI 1443/3-1 and KI 1443/3-2.  "
  },
  {
    "id": 9066,
    "package_name": "bfast",
    "title": "Breaks for Additive Season and Trend",
    "description": "Decomposition of time series into\n    trend, seasonal, and remainder components with methods for detecting and\n    characterizing abrupt changes within the trend and seasonal components. 'BFAST'\n    can be used to analyze different types of satellite image time series and can\n    be applied to other disciplines dealing with seasonal or non-seasonal time\n    series, such as hydrology, climatology, and econometrics. The algorithm can be\n    extended to label detected changes with information on the parameters of the\n    fitted piecewise linear models. 'BFAST' monitoring functionality is described\n    in Verbesselt et al. (2010) <doi:10.1016/j.rse.2009.08.014>. 'BFAST monitor'\n    provides functionality to detect disturbance in near real-time based on 'BFAST'-\n    type models, and is described in Verbesselt et al. (2012) <doi:10.1016/j.rse.2012.02.022>.\n    'BFAST Lite' approach is a flexible approach that handles missing data\n    without interpolation, and will be described in an upcoming paper.\n    Furthermore, different models can now be used to fit the\n    time series data and detect structural changes (breaks).",
    "version": "1.7.1",
    "maintainer": "Dainius Masili\u016bnas <pastas4@gmail.com>",
    "author": "Jan Verbesselt [aut],\n  Dainius Masili\u016bnas [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5654-1277>),\n  Achim Zeileis [aut],\n  Rob Hyndman [ctb],\n  Marius Appel [aut],\n  Martin Jung [ctb],\n  Andrei M\u00eer\u021b [ctb] (ORCID: <https://orcid.org/0000-0003-3654-2090>),\n  Paulo Negri Bernardino [ctb],\n  Dongdong Kong [ctb] (ORCID: <https://orcid.org/0000-0003-1836-8172>)",
    "url": "https://bfast2.github.io/",
    "bug_reports": "https://github.com/bfast2/bfast/issues",
    "repository": "https://cran.r-project.org/package=bfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bfast Breaks for Additive Season and Trend Decomposition of time series into\n    trend, seasonal, and remainder components with methods for detecting and\n    characterizing abrupt changes within the trend and seasonal components. 'BFAST'\n    can be used to analyze different types of satellite image time series and can\n    be applied to other disciplines dealing with seasonal or non-seasonal time\n    series, such as hydrology, climatology, and econometrics. The algorithm can be\n    extended to label detected changes with information on the parameters of the\n    fitted piecewise linear models. 'BFAST' monitoring functionality is described\n    in Verbesselt et al. (2010) <doi:10.1016/j.rse.2009.08.014>. 'BFAST monitor'\n    provides functionality to detect disturbance in near real-time based on 'BFAST'-\n    type models, and is described in Verbesselt et al. (2012) <doi:10.1016/j.rse.2012.02.022>.\n    'BFAST Lite' approach is a flexible approach that handles missing data\n    without interpolation, and will be described in an upcoming paper.\n    Furthermore, different models can now be used to fit the\n    time series data and detect structural changes (breaks).  "
  },
  {
    "id": 9092,
    "package_name": "bibliorefer",
    "title": "Generator of Main Scientific References",
    "description": "Generates a list, with a size defined by the user, containing the main scientific references and the frequency distribution of authors and journals in the list obtained.\n    The database is a dataframe with academic production metadata made available by bibliographic collections such as Scopus, Web of Science, etc.\n    The temporal evolution of scientific production on a given topic is presented and ordered lists of articles are constructed by number of citations and of authors and journals by level of productivity.\n    Massimo Aria, Corrado Cuccurullo. (2017) <doi:10.1016/j.joi.2017.08.007>.\n    Caibo Zhou, Wenyan Song. (2021) <doi:10.1016/j.jclepro.2021.126943>.",
    "version": "0.1.2",
    "maintainer": "M\u00e1rcio Eust\u00e1quio <marcioeustaquio@id.uff.br>",
    "author": "M\u00e1rcio Eust\u00e1quio [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bibliorefer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bibliorefer Generator of Main Scientific References Generates a list, with a size defined by the user, containing the main scientific references and the frequency distribution of authors and journals in the list obtained.\n    The database is a dataframe with academic production metadata made available by bibliographic collections such as Scopus, Web of Science, etc.\n    The temporal evolution of scientific production on a given topic is presented and ordered lists of articles are constructed by number of citations and of authors and journals by level of productivity.\n    Massimo Aria, Corrado Cuccurullo. (2017) <doi:10.1016/j.joi.2017.08.007>.\n    Caibo Zhou, Wenyan Song. (2021) <doi:10.1016/j.jclepro.2021.126943>.  "
  },
  {
    "id": 9102,
    "package_name": "bigDM",
    "title": "Scalable Bayesian Disease Mapping Models for High-Dimensional\nData",
    "description": "Implements several spatial and spatio-temporal scalable disease mapping models for high-dimensional count data using the INLA technique for approximate Bayesian inference in latent Gaussian models (Orozco-Acosta et al., 2021 <doi:10.1016/j.spasta.2021.100496>; Orozco-Acosta et al., 2023 <doi:10.1016/j.cmpb.2023.107403> and Vicente et al., 2023 <doi:10.1007/s11222-023-10263-x>). The creation and develpment of this package has been supported by Project MTM2017-82553-R (AEI/FEDER, UE) and Project PID2020-113125RB-I00/MCIN/AEI/10.13039/501100011033. It has also been partially funded by the Public University of Navarra (project PJUPNA2001).",
    "version": "0.5.7",
    "maintainer": "Aritz Adin <aritz.adin@unavarra.es>",
    "author": "Aritz Adin [aut, cre] (ORCID: <https://orcid.org/0000-0003-3232-6147>),\n  Erick Orozco-Acosta [aut] (ORCID:\n    <https://orcid.org/0000-0002-1170-667X>),\n  Maria Dolores Ugarte [aut] (ORCID:\n    <https://orcid.org/0000-0002-3505-8400>)",
    "url": "https://github.com/spatialstatisticsupna/bigDM",
    "bug_reports": "https://github.com/spatialstatisticsupna/bigDM/issues",
    "repository": "https://cran.r-project.org/package=bigDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bigDM Scalable Bayesian Disease Mapping Models for High-Dimensional\nData Implements several spatial and spatio-temporal scalable disease mapping models for high-dimensional count data using the INLA technique for approximate Bayesian inference in latent Gaussian models (Orozco-Acosta et al., 2021 <doi:10.1016/j.spasta.2021.100496>; Orozco-Acosta et al., 2023 <doi:10.1016/j.cmpb.2023.107403> and Vicente et al., 2023 <doi:10.1007/s11222-023-10263-x>). The creation and develpment of this package has been supported by Project MTM2017-82553-R (AEI/FEDER, UE) and Project PID2020-113125RB-I00/MCIN/AEI/10.13039/501100011033. It has also been partially funded by the Public University of Navarra (project PJUPNA2001).  "
  },
  {
    "id": 9137,
    "package_name": "bigtime",
    "title": "Sparse Estimation of Large Time Series Models",
    "description": "Estimation of large Vector AutoRegressive (VAR), Vector AutoRegressive with Exogenous Variables X (VARX) and Vector AutoRegressive Moving Average (VARMA) Models with Structured Lasso Penalties, see Nicholson, Wilms, Bien and Matteson (2020) <https://jmlr.org/papers/v21/19-777.html> and Wilms, Basu, Bien and Matteson (2021) <doi:10.1080/01621459.2021.1942013>.",
    "version": "0.2.3",
    "maintainer": "Ines Wilms <i.wilms@maastrichtuniversity.nl>",
    "author": "Ines Wilms [cre, aut],\n  David S. Matteson [aut],\n  Jacob Bien [aut],\n  Sumanta Basu [aut],\n  Will Nicholson [aut],\n  Enrico Wegner [aut]",
    "url": "https://github.com/ineswilms/bigtime",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bigtime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bigtime Sparse Estimation of Large Time Series Models Estimation of large Vector AutoRegressive (VAR), Vector AutoRegressive with Exogenous Variables X (VARX) and Vector AutoRegressive Moving Average (VARMA) Models with Structured Lasso Penalties, see Nicholson, Wilms, Bien and Matteson (2020) <https://jmlr.org/papers/v21/19-777.html> and Wilms, Basu, Bien and Matteson (2021) <doi:10.1080/01621459.2021.1942013>.  "
  },
  {
    "id": 9143,
    "package_name": "bimets",
    "title": "Time Series and Econometric Modeling",
    "description": "Time series analysis, (dis)aggregation and manipulation, e.g. time series extension, merge, projection, lag, lead, delta, moving and cumulative average and product, selection by index, date and year-period, conversion to daily, monthly, quarterly, (semi)annually. Simultaneous equation models definition, estimation, simulation and forecasting with coefficient restrictions, error autocorrelation, exogenization, add-factors, impact and interim multipliers analysis, conditional equation evaluation, rational expectations, endogenous targeting and model renormalization, structural stability, stochastic simulation and forecast, optimal control, by A. Luciani (2022) <doi:10.13140/RG.2.2.31160.83202>.",
    "version": "4.1.2",
    "maintainer": "Andrea Luciani <andrea.luciani@bancaditalia.it>",
    "author": "Andrea Luciani [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7372-358X>),\n  Roberto Stok [aut],\n  Bank of Italy [cph]",
    "url": "https://github.com/andrea-luciani/bimets",
    "bug_reports": "https://github.com/andrea-luciani/bimets/issues",
    "repository": "https://cran.r-project.org/package=bimets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bimets Time Series and Econometric Modeling Time series analysis, (dis)aggregation and manipulation, e.g. time series extension, merge, projection, lag, lead, delta, moving and cumulative average and product, selection by index, date and year-period, conversion to daily, monthly, quarterly, (semi)annually. Simultaneous equation models definition, estimation, simulation and forecasting with coefficient restrictions, error autocorrelation, exogenization, add-factors, impact and interim multipliers analysis, conditional equation evaluation, rational expectations, endogenous targeting and model renormalization, structural stability, stochastic simulation and forecast, optimal control, by A. Luciani (2022) <doi:10.13140/RG.2.2.31160.83202>.  "
  },
  {
    "id": 9149,
    "package_name": "binaryGP",
    "title": "Fit and Predict a Gaussian Process Model with (Time-Series)\nBinary Response",
    "description": "Allows the estimation and prediction for binary Gaussian process model. The mean function can be assumed to have time-series structure. The estimation methods for the unknown parameters are based on penalized quasi-likelihood/penalized quasi-partial likelihood and restricted maximum likelihood. The predicted probability and its confidence interval are computed by Metropolis-Hastings algorithm. More details can be seen in Sung et al (2017) <arXiv:1705.02511>.",
    "version": "0.2",
    "maintainer": "Chih-Li Sung <iamdfchile@gmail.com>",
    "author": "Chih-Li Sung",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=binaryGP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "binaryGP Fit and Predict a Gaussian Process Model with (Time-Series)\nBinary Response Allows the estimation and prediction for binary Gaussian process model. The mean function can be assumed to have time-series structure. The estimation methods for the unknown parameters are based on penalized quasi-likelihood/penalized quasi-partial likelihood and restricted maximum likelihood. The predicted probability and its confidence interval are computed by Metropolis-Hastings algorithm. More details can be seen in Sung et al (2017) <arXiv:1705.02511>.  "
  },
  {
    "id": 9194,
    "package_name": "biomod2",
    "title": "Ensemble Platform for Species Distribution Modeling",
    "description": "Functions for species distribution modeling, calibration and evaluation, \n  ensemble of models, ensemble forecasting and visualization. The package permits to run\n  consistently up to 10 single models on a presence/absences (resp presences/pseudo-absences)\n  dataset and to combine them in ensemble models and ensemble projections. Some bench of other \n  evaluation and visualization tools are also available within the package.",
    "version": "4.2-6-2",
    "maintainer": "Maya Gueguen <maya.gueguen@univ-grenoble-alpes.fr>",
    "author": "Wilfried Thuiller [aut],\n  Damien Georges [aut],\n  Maya Gueguen [aut, cre],\n  Robin Engler [aut],\n  Frank Breiner [aut],\n  Bruno Lafourcade [aut],\n  Remi Patin [aut],\n  Helene Blancheteau [aut]",
    "url": "https://biomodhub.github.io/biomod2/",
    "bug_reports": "https://github.com/biomodhub/biomod2/issues",
    "repository": "https://cran.r-project.org/package=biomod2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "biomod2 Ensemble Platform for Species Distribution Modeling Functions for species distribution modeling, calibration and evaluation, \n  ensemble of models, ensemble forecasting and visualization. The package permits to run\n  consistently up to 10 single models on a presence/absences (resp presences/pseudo-absences)\n  dataset and to combine them in ensemble models and ensemble projections. Some bench of other \n  evaluation and visualization tools are also available within the package.  "
  },
  {
    "id": 9223,
    "package_name": "bistablehistory",
    "title": "Cumulative History Analysis for Bistable Perception Time Series",
    "description": "Estimates cumulative history for time-series for continuously\n    viewed bistable perceptual rivalry displays. Computes cumulative history\n    via a homogeneous first order differential process. I.e., it assumes\n    exponential growth/decay of the history as a function time and perceptually\n    dominant state, Pastukhov & Braun (2011) <doi:10.1167/11.10.12>.\n    Supports Gamma, log normal, and normal distribution families.\n    Provides a method to compute history directly and example of using the\n    computation on a custom Stan code.",
    "version": "1.1.3",
    "maintainer": "Alexander Pastukhov <pastukhov.alexander@gmail.com>",
    "author": "Alexander Pastukhov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8738-8591>)",
    "url": "https://github.com/alexander-pastukhov/bistablehistory/,\nhttps://alexander-pastukhov.github.io/bistablehistory/",
    "bug_reports": "https://github.com/alexander-pastukhov/bistablehistory/issues/",
    "repository": "https://cran.r-project.org/package=bistablehistory",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bistablehistory Cumulative History Analysis for Bistable Perception Time Series Estimates cumulative history for time-series for continuously\n    viewed bistable perceptual rivalry displays. Computes cumulative history\n    via a homogeneous first order differential process. I.e., it assumes\n    exponential growth/decay of the history as a function time and perceptually\n    dominant state, Pastukhov & Braun (2011) <doi:10.1167/11.10.12>.\n    Supports Gamma, log normal, and normal distribution families.\n    Provides a method to compute history directly and example of using the\n    computation on a custom Stan code.  "
  },
  {
    "id": 9265,
    "package_name": "blockmatrix",
    "title": "blockmatrix: Tools to solve algebraic systems with partitioned\nmatrices",
    "description": "Some elementary matrix algebra tools are implemented to manage\n    block matrices or partitioned matrix, i.e. \"matrix of matrices\"\n    (http://en.wikipedia.org/wiki/Block_matrix). The block matrix is here\n    defined as a new S3 object. In this package, some methods for \"matrix\"\n    object are rewritten for \"blockmatrix\" object. New methods are implemented.\n    This package was created to solve equation systems with block matrices for\n    the analysis of environmental vector time series .\n    Bugs/comments/questions/collaboration of any kind are warmly welcomed.",
    "version": "1.0",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano",
    "url": "http://cri.gmpf.eu/Research/Sustainable-Agro-Ecosystems-and-Bioresources/Dynamics-in-the-agro-ecosystems/people/Emanuele-Cordano",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=blockmatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "blockmatrix blockmatrix: Tools to solve algebraic systems with partitioned\nmatrices Some elementary matrix algebra tools are implemented to manage\n    block matrices or partitioned matrix, i.e. \"matrix of matrices\"\n    (http://en.wikipedia.org/wiki/Block_matrix). The block matrix is here\n    defined as a new S3 object. In this package, some methods for \"matrix\"\n    object are rewritten for \"blockmatrix\" object. New methods are implemented.\n    This package was created to solve equation systems with block matrices for\n    the analysis of environmental vector time series .\n    Bugs/comments/questions/collaboration of any kind are warmly welcomed.  "
  },
  {
    "id": 9277,
    "package_name": "blsR",
    "title": "Make Requests from the Bureau of Labor Statistics API",
    "description": "Implements v2 of the B.L.S. API for requests of survey information\n  and time series data through 3-tiered API that allows users to interact with\n  the raw API directly, create queries through a functional interface, and\n  re-shape the data structures returned to fit common uses. The API definition \n  is located at: <https://www.bls.gov/developers/api_signature_v2.htm>.",
    "version": "0.5.0",
    "maintainer": "Guillermo Roditi Dominguez <guillermo@newriverinvestments.com>",
    "author": "Guillermo Roditi Dominguez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7127-8742>)",
    "url": "https://github.com/groditi/blsR",
    "bug_reports": "https://github.com/groditi/blsR/issues",
    "repository": "https://cran.r-project.org/package=blsR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "blsR Make Requests from the Bureau of Labor Statistics API Implements v2 of the B.L.S. API for requests of survey information\n  and time series data through 3-tiered API that allows users to interact with\n  the raw API directly, create queries through a functional interface, and\n  re-shape the data structures returned to fit common uses. The API definition \n  is located at: <https://www.bls.gov/developers/api_signature_v2.htm>.  "
  },
  {
    "id": 9287,
    "package_name": "bmgarch",
    "title": "Bayesian Multivariate GARCH Models",
    "description": "Fit Bayesian multivariate GARCH models using 'Stan' for full Bayesian inference. Generate (weighted) forecasts for means, variances (volatility) and correlations. Currently DCC(P,Q), CCC(P,Q), pdBEKK(P,Q), and BEKK(P,Q) parameterizations are implemented, based either on a multivariate gaussian normal or student-t distribution. DCC and CCC models are based on Engle (2002) <doi:10.1198/073500102288618487> and Bollerslev (1990). The BEKK parameterization follows Engle and Kroner (1995) <doi:10.1017/S0266466600009063> while the pdBEKK as well as the estimation approach for this package is described in Rast et al. (2020) <doi:10.31234/osf.io/j57pk>. The fitted models contain 'rstan' objects and can be examined with 'rstan' functions.  ",
    "version": "2.0.0",
    "maintainer": "Philippe Rast <rast.ph@gmail.com>",
    "author": "Philippe Rast [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3630-6629>),\n  Stephen Martin [aut] (ORCID: <https://orcid.org/0000-0001-8085-2390>)",
    "url": "",
    "bug_reports": "https://github.com/ph-rast/bmgarch/issues",
    "repository": "https://cran.r-project.org/package=bmgarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bmgarch Bayesian Multivariate GARCH Models Fit Bayesian multivariate GARCH models using 'Stan' for full Bayesian inference. Generate (weighted) forecasts for means, variances (volatility) and correlations. Currently DCC(P,Q), CCC(P,Q), pdBEKK(P,Q), and BEKK(P,Q) parameterizations are implemented, based either on a multivariate gaussian normal or student-t distribution. DCC and CCC models are based on Engle (2002) <doi:10.1198/073500102288618487> and Bollerslev (1990). The BEKK parameterization follows Engle and Kroner (1995) <doi:10.1017/S0266466600009063> while the pdBEKK as well as the estimation approach for this package is described in Rast et al. (2020) <doi:10.31234/osf.io/j57pk>. The fitted models contain 'rstan' objects and can be examined with 'rstan' functions.    "
  },
  {
    "id": 9294,
    "package_name": "bmstdr",
    "title": "Bayesian Modeling of Spatio-Temporal Data with R",
    "description": "Fits, validates and compares a number of Bayesian models for\n    spatial and space time point referenced and areal unit data. Model fitting\n    is done using several packages: 'rstan', 'INLA', 'spBayes', 'spTimer',\n    'spTDyn', 'CARBayes' and 'CARBayesST'. Model comparison is performed using\n    the DIC and WAIC,  and K-fold cross-validation where the user is free\n    to select their own subset of data rows for validation. Sahu (2022)\n    <doi:10.1201/9780429318443> describes the methods in detail.",
    "version": "0.8.2",
    "maintainer": "Sujit K. Sahu <S.K.Sahu@soton.ac.uk>",
    "author": "Sujit K. Sahu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2315-3598>),\n  Duncan P. Lee [aut],\n  K. Shuvo Bakar [aut]",
    "url": "https://www.sujitsahu.com",
    "bug_reports": "https://github.com/sujit-sahu/bmstdr/issues",
    "repository": "https://cran.r-project.org/package=bmstdr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bmstdr Bayesian Modeling of Spatio-Temporal Data with R Fits, validates and compares a number of Bayesian models for\n    spatial and space time point referenced and areal unit data. Model fitting\n    is done using several packages: 'rstan', 'INLA', 'spBayes', 'spTimer',\n    'spTDyn', 'CARBayes' and 'CARBayesST'. Model comparison is performed using\n    the DIC and WAIC,  and K-fold cross-validation where the user is free\n    to select their own subset of data rows for validation. Sahu (2022)\n    <doi:10.1201/9780429318443> describes the methods in detail.  "
  },
  {
    "id": 9343,
    "package_name": "bootUR",
    "title": "Bootstrap Unit Root Tests",
    "description": "Set of functions to perform various bootstrap unit root tests for both individual time series\n  (including augmented Dickey-Fuller test and union tests), multiple time series and panel data; see\n  Smeekes and Wilms (2023) <doi:10.18637/jss.v106.i12>,\n  Palm, Smeekes and Urbain (2008) <doi:10.1111/j.1467-9892.2007.00565.x>,\n  Palm, Smeekes and Urbain (2011) <doi:10.1016/j.jeconom.2010.11.010>, \n  Moon and Perron (2012) <doi:10.1016/j.jeconom.2012.01.008>, \n  Smeekes and Taylor (2012) <doi:10.1017/S0266466611000387> and \n  Smeekes (2015) <doi:10.1111/jtsa.12110> for key references. ",
    "version": "1.0.4",
    "maintainer": "Stephan Smeekes <s.smeekes@maastrichtuniversity.nl>",
    "author": "Stephan Smeekes [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0157-639X>),\n  Ines Wilms [aut]",
    "url": "https://github.com/smeekes/bootUR,\nhttps://smeekes.github.io/bootUR/",
    "bug_reports": "https://github.com/smeekes/bootUR/issues",
    "repository": "https://cran.r-project.org/package=bootUR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bootUR Bootstrap Unit Root Tests Set of functions to perform various bootstrap unit root tests for both individual time series\n  (including augmented Dickey-Fuller test and union tests), multiple time series and panel data; see\n  Smeekes and Wilms (2023) <doi:10.18637/jss.v106.i12>,\n  Palm, Smeekes and Urbain (2008) <doi:10.1111/j.1467-9892.2007.00565.x>,\n  Palm, Smeekes and Urbain (2011) <doi:10.1016/j.jeconom.2010.11.010>, \n  Moon and Perron (2012) <doi:10.1016/j.jeconom.2012.01.008>, \n  Smeekes and Taylor (2012) <doi:10.1017/S0266466611000387> and \n  Smeekes (2015) <doi:10.1111/jtsa.12110> for key references.   "
  },
  {
    "id": 9389,
    "package_name": "braggR",
    "title": "Calculate the Revealed Aggregator of Probability Predictions",
    "description": "\n    Forecasters predicting the chances of a future event may disagree due to\n    differing evidence or noise. To harness the collective evidence of the crowd, \n    Ville Satop\u00e4\u00e4 (2021) \"Regularized Aggregation of One-off Probability Predictions\"\n    <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3769945> proposes a Bayesian\n    aggregator that is regularized by analyzing the forecasters' disagreement and ascribing \n    over-dispersion to noise. This aggregator requires no user intervention and can be computed\n    efficiently even for a large numbers of predictions. The author evaluates\n    the aggregator on subjective probability predictions collected during\n    a four-year forecasting tournament sponsored by the US intelligence community.\n    The aggregator improves the accuracy of simple averaging by around 20% and\n    other state-of-the-art aggregators by 10-25%. The advantage stems almost\n    exclusively from improved calibration. This aggregator -- know as \"the revealed\n    aggregator\" -- inputs a) forecasters' probability predictions (p) of a future binary event\n    and b) the forecasters' common prior (p0) of the future event. In this R-package,\n    the function sample_aggregator(p,p0,...) allows the user to calculate the revealed\n    aggregator. Its use is illustrated with a simple example. ",
    "version": "0.1.1",
    "maintainer": "Ville Satop\u00e4\u00e4 <ville.satopaa@gmail.com>",
    "author": "Ville Satop\u00e4\u00e4 [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=braggR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "braggR Calculate the Revealed Aggregator of Probability Predictions \n    Forecasters predicting the chances of a future event may disagree due to\n    differing evidence or noise. To harness the collective evidence of the crowd, \n    Ville Satop\u00e4\u00e4 (2021) \"Regularized Aggregation of One-off Probability Predictions\"\n    <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3769945> proposes a Bayesian\n    aggregator that is regularized by analyzing the forecasters' disagreement and ascribing \n    over-dispersion to noise. This aggregator requires no user intervention and can be computed\n    efficiently even for a large numbers of predictions. The author evaluates\n    the aggregator on subjective probability predictions collected during\n    a four-year forecasting tournament sponsored by the US intelligence community.\n    The aggregator improves the accuracy of simple averaging by around 20% and\n    other state-of-the-art aggregators by 10-25%. The advantage stems almost\n    exclusively from improved calibration. This aggregator -- know as \"the revealed\n    aggregator\" -- inputs a) forecasters' probability predictions (p) of a future binary event\n    and b) the forecasters' common prior (p0) of the future event. In this R-package,\n    the function sample_aggregator(p,p0,...) allows the user to calculate the revealed\n    aggregator. Its use is illustrated with a simple example.   "
  },
  {
    "id": 9410,
    "package_name": "breathtestcore",
    "title": "Core Functions to Read and Fit 13c Time Series from Breath Tests",
    "description": "Reads several formats of 13C data (IRIS/Wagner,\n    BreathID) and CSV.  Creates artificial sample data for testing.  Fits\n    Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.\n    Methods to fit breath test curves with Bayesian Stan methods are\n    refactored to package 'breathteststan'. For a Shiny GUI, see package\n    'dmenne/breathtestshiny' on github.",
    "version": "0.8.10",
    "maintainer": "Dieter Menne <dieter.menne@menne-biomed.de>",
    "author": "Dieter Menne [aut, cre],\n  Menne Biomed Consulting Tuebingen [cph],\n  Benjamin Misselwitz [fnd],\n  Mark Fox [fnd],\n  Andreas Steingoetter [dtc],\n  University Hospital of Zurich, Dep. Gastroenterology [fnd, dtc]",
    "url": "https://github.com/dmenne/breathtestcore,",
    "bug_reports": "https://github.com/dmenne/breathtestcore/issues",
    "repository": "https://cran.r-project.org/package=breathtestcore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "breathtestcore Core Functions to Read and Fit 13c Time Series from Breath Tests Reads several formats of 13C data (IRIS/Wagner,\n    BreathID) and CSV.  Creates artificial sample data for testing.  Fits\n    Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.\n    Methods to fit breath test curves with Bayesian Stan methods are\n    refactored to package 'breathteststan'. For a Shiny GUI, see package\n    'dmenne/breathtestshiny' on github.  "
  },
  {
    "id": 9413,
    "package_name": "brfinance",
    "title": "Simplified Access to Brazilian Financial and Macroeconomic Data",
    "description": "It offers simplified access to Brazilian macroeconomic and financial indicators selected from official sources, such as the 'IBGE' (Brazilian Institute of Geography and Statistics) via the 'SIDRA' API and the 'Central Bank of Brazil' via the 'SGS' API. It allows users to quickly retrieve and visualize data series such as the unemployment rate and the Selic interest rate. This package was developed for data access and visualization purposes, without generating forecasts or statistical results. For more information, see the official APIs: <https://sidra.ibge.gov.br/> and <https://dadosabertos.bcb.gov.br/dataset/>.",
    "version": "0.2.2",
    "maintainer": "Jo\u00e3o Paulo dos Santos Pereira Barbosa <joao.31582129@gmail.com>",
    "author": "Jo\u00e3o Paulo dos Santos Pereira Barbosa [aut, cre]",
    "url": "https://github.com/efram2/brfinance",
    "bug_reports": "https://github.com/efram2/brfinance/issues",
    "repository": "https://cran.r-project.org/package=brfinance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "brfinance Simplified Access to Brazilian Financial and Macroeconomic Data It offers simplified access to Brazilian macroeconomic and financial indicators selected from official sources, such as the 'IBGE' (Brazilian Institute of Geography and Statistics) via the 'SIDRA' API and the 'Central Bank of Brazil' via the 'SGS' API. It allows users to quickly retrieve and visualize data series such as the unemployment rate and the Selic interest rate. This package was developed for data access and visualization purposes, without generating forecasts or statistical results. For more information, see the official APIs: <https://sidra.ibge.gov.br/> and <https://dadosabertos.bcb.gov.br/dataset/>.  "
  },
  {
    "id": 9421,
    "package_name": "bridgr",
    "title": "Bridging Data Frequencies for Timely Economic Forecasts",
    "description": "Implements bridge models for nowcasting and forecasting macroeconomic variables by linking high-frequency indicator variables (e.g., monthly data) to low-frequency target variables (e.g., quarterly GDP). Simplifies forecasting and aggregating indicator variables to match the target frequency, enabling timely predictions ahead of official data releases. For more on bridge models, see Baffigi, A., Golinelli, R., & Parigi, G. (2004) <doi:10.1016/S0169-2070(03)00067-0>, Burri (2023) <https://www5.unine.ch/RePEc/ftp/irn/pdfs/WP23-02.pdf> or Schumacher (2016) <doi:10.1016/j.ijforecast.2015.07.004>. ",
    "version": "0.1.1",
    "maintainer": "Marc Burri <marc.burri91@gmail.com>",
    "author": "Marc Burri [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-8974-9090>)",
    "url": "https://github.com/marcburri/bridgr,\nhttps://marcburri.github.io/bridgr/",
    "bug_reports": "https://github.com/marcburri/bridgr/issues",
    "repository": "https://cran.r-project.org/package=bridgr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bridgr Bridging Data Frequencies for Timely Economic Forecasts Implements bridge models for nowcasting and forecasting macroeconomic variables by linking high-frequency indicator variables (e.g., monthly data) to low-frequency target variables (e.g., quarterly GDP). Simplifies forecasting and aggregating indicator variables to match the target frequency, enabling timely predictions ahead of official data releases. For more on bridge models, see Baffigi, A., Golinelli, R., & Parigi, G. (2004) <doi:10.1016/S0169-2070(03)00067-0>, Burri (2023) <https://www5.unine.ch/RePEc/ftp/irn/pdfs/WP23-02.pdf> or Schumacher (2016) <doi:10.1016/j.ijforecast.2015.07.004>.   "
  },
  {
    "id": 9432,
    "package_name": "brolgar",
    "title": "Browse Over Longitudinal Data Graphically and Analytically in R",
    "description": "Provides a framework of tools to summarise, visualise, and explore \n  longitudinal data. It builds upon the tidy time series data frames used in the\n  'tsibble' package, and is designed to integrate within the 'tidyverse', and\n  'tidyverts' (for time series) ecosystems. The methods implemented include \n  calculating features for understanding longitudinal data, including \n  calculating summary statistics such as quantiles, medians, and numeric ranges,\n  sampling individual series, identifying individual series representative of a \n  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are\n  fully described in the paper \"brolgar: An R package to Browse Over \n  Longitudinal Data Graphically and Analytically in R\", Nicholas Tierney, \n  Dianne Cook, Tania Prvan (2020) <doi:10.32614/RJ-2022-023>.",
    "version": "1.0.2",
    "maintainer": "Nicholas Tierney <nicholas.tierney@gmail.com>",
    "author": "Nicholas Tierney [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1460-8722>),\n  Di Cook [aut] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Tania Prvan [aut],\n  Stuart Lee [ctb],\n  Earo Wang [ctb]",
    "url": "https://github.com/njtierney/brolgar,\nhttps://brolgar.njtierney.com/, http://brolgar.njtierney.com/",
    "bug_reports": "https://github.com/njtierney/brolgar/issues",
    "repository": "https://cran.r-project.org/package=brolgar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "brolgar Browse Over Longitudinal Data Graphically and Analytically in R Provides a framework of tools to summarise, visualise, and explore \n  longitudinal data. It builds upon the tidy time series data frames used in the\n  'tsibble' package, and is designed to integrate within the 'tidyverse', and\n  'tidyverts' (for time series) ecosystems. The methods implemented include \n  calculating features for understanding longitudinal data, including \n  calculating summary statistics such as quantiles, medians, and numeric ranges,\n  sampling individual series, identifying individual series representative of a \n  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are\n  fully described in the paper \"brolgar: An R package to Browse Over \n  Longitudinal Data Graphically and Analytically in R\", Nicholas Tierney, \n  Dianne Cook, Tania Prvan (2020) <doi:10.32614/RJ-2022-023>.  "
  },
  {
    "id": 9455,
    "package_name": "bspec",
    "title": "Bayesian Spectral Inference",
    "description": "Bayesian inference on the (discrete) power spectrum of time series.",
    "version": "1.6",
    "maintainer": "Christian Roever <christian.roever@med.uni-goettingen.de>",
    "author": "Christian Roever [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6911-698X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bspec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bspec Bayesian Spectral Inference Bayesian inference on the (discrete) power spectrum of time series.  "
  },
  {
    "id": 9465,
    "package_name": "bsts",
    "title": "Bayesian Structural Time Series",
    "description": "Time series regression using dynamic linear models fit using\n  MCMC. See Scott and Varian (2014) <DOI:10.1504/IJMMNO.2014.059942>, among many\n  other sources.",
    "version": "0.9.11",
    "maintainer": "Steven L. Scott <steve.the.bayesian@gmail.com>",
    "author": "Steven L. Scott [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bsts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsts Bayesian Structural Time Series Time series regression using dynamic linear models fit using\n  MCMC. See Scott and Varian (2014) <DOI:10.1504/IJMMNO.2014.059942>, among many\n  other sources.  "
  },
  {
    "id": 9467,
    "package_name": "bsvarSIGNs",
    "title": "Bayesian SVARs with Sign, Zero, and Narrative Restrictions",
    "description": "Implements state-of-the-art algorithms for the Bayesian analysis of Structural Vector Autoregressions (SVARs) identified by sign, zero, and narrative restrictions. The core model is based on a flexible Vector Autoregression with estimated hyper-parameters of the Minnesota prior and the dummy observation priors as in Giannone, Lenza, Primiceri (2015) <doi:10.1162/REST_a_00483>. The sign restrictions are implemented employing the methods proposed by Rubio-Ram\u00edrez, Waggoner & Zha (2010) <doi:10.1111/j.1467-937X.2009.00578.x>, while identification through sign and zero restrictions follows the approach developed by Arias, Rubio-Ram\u00edrez, & Waggoner (2018) <doi:10.3982/ECTA14468>. Furthermore, our tool provides algorithms for identification via sign and narrative restrictions, in line with the methods introduced by Antol\u00edn-D\u00edaz and Rubio-Ram\u00edrez (2018) <doi:10.1257/aer.20161852>. Users can also estimate a model with sign, zero, and narrative restrictions imposed at once. The package facilitates predictive and structural analyses using impulse responses, forecast error variance and historical decompositions, forecasting and conditional forecasting, as well as analyses of structural shocks and fitted values. All this is complemented by colourful plots, user-friendly summary functions, and comprehensive documentation including the vignette by Wang & Wo\u017aniak (2024) <doi:10.48550/arXiv.2501.16711>. The 'bsvarSIGNs' package is aligned regarding objects, workflows, and code structure with the R package 'bsvars' by Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars>, and they constitute an integrated toolset. It was granted the Di Cook Open-Source Statistical Software Award by the Statistical Society of Australia in 2024.",
    "version": "2.0",
    "maintainer": "Xiaolei Wang <adamwang15@gmail.com>",
    "author": "Xiaolei Wang [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-6192-9061>),\n  Tomasz Wo\u017aniak [aut] (ORCID: <https://orcid.org/0000-0003-2212-2378>)",
    "url": "https://bsvars.org/bsvarSIGNs/",
    "bug_reports": "https://github.com/bsvars/bsvarSIGNs/issues",
    "repository": "https://cran.r-project.org/package=bsvarSIGNs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsvarSIGNs Bayesian SVARs with Sign, Zero, and Narrative Restrictions Implements state-of-the-art algorithms for the Bayesian analysis of Structural Vector Autoregressions (SVARs) identified by sign, zero, and narrative restrictions. The core model is based on a flexible Vector Autoregression with estimated hyper-parameters of the Minnesota prior and the dummy observation priors as in Giannone, Lenza, Primiceri (2015) <doi:10.1162/REST_a_00483>. The sign restrictions are implemented employing the methods proposed by Rubio-Ram\u00edrez, Waggoner & Zha (2010) <doi:10.1111/j.1467-937X.2009.00578.x>, while identification through sign and zero restrictions follows the approach developed by Arias, Rubio-Ram\u00edrez, & Waggoner (2018) <doi:10.3982/ECTA14468>. Furthermore, our tool provides algorithms for identification via sign and narrative restrictions, in line with the methods introduced by Antol\u00edn-D\u00edaz and Rubio-Ram\u00edrez (2018) <doi:10.1257/aer.20161852>. Users can also estimate a model with sign, zero, and narrative restrictions imposed at once. The package facilitates predictive and structural analyses using impulse responses, forecast error variance and historical decompositions, forecasting and conditional forecasting, as well as analyses of structural shocks and fitted values. All this is complemented by colourful plots, user-friendly summary functions, and comprehensive documentation including the vignette by Wang & Wo\u017aniak (2024) <doi:10.48550/arXiv.2501.16711>. The 'bsvarSIGNs' package is aligned regarding objects, workflows, and code structure with the R package 'bsvars' by Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars>, and they constitute an integrated toolset. It was granted the Di Cook Open-Source Statistical Software Award by the Statistical Society of Australia in 2024.  "
  },
  {
    "id": 9468,
    "package_name": "bsvars",
    "title": "Bayesian Estimation of Structural Vector Autoregressive Models",
    "description": "Provides fast and efficient procedures for Bayesian analysis of Structural Vector Autoregressions. This package estimates a wide range of models, including homo-, heteroskedastic, and non-normal specifications. Structural models can be identified by adjustable exclusion restrictions, time-varying volatility, or non-normality. They all include a flexible three-level equation-specific local-global hierarchical prior distribution for the estimated level of shrinkage for autoregressive and structural parameters. Additionally, the package facilitates predictive and structural analyses such as impulse responses, forecast error variance and historical decompositions, forecasting, verification of heteroskedasticity, non-normality, and hypotheses on autoregressive parameters, as well as analyses of structural shocks, volatilities, and fitted values. Beautiful plots, informative summary functions, and extensive documentation including the vignette by Wo\u017aniak (2024) <doi:10.48550/arXiv.2410.15090> complement all this. The implemented techniques align closely with those presented in L\u00fctkepohl, Shang, Uzeda, & Wo\u017aniak (2024) <doi:10.48550/arXiv.2404.11057>, L\u00fctkepohl & Wo\u017aniak (2020) <doi:10.1016/j.jedc.2020.103862>, and Song & Wo\u017aniak (2021) <doi:10.1093/acrefore/9780190625979.013.174>. The 'bsvars' package is aligned regarding objects, workflows, and code structure with the R package 'bsvarSIGNs' by Wang & Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they constitute an integrated toolset.",
    "version": "3.2",
    "maintainer": "Tomasz Wo\u017aniak <wozniak.tom@pm.me>",
    "author": "Tomasz Wo\u017aniak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2212-2378>)",
    "url": "https://bsvars.org/bsvars/",
    "bug_reports": "https://github.com/bsvars/bsvars/issues",
    "repository": "https://cran.r-project.org/package=bsvars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsvars Bayesian Estimation of Structural Vector Autoregressive Models Provides fast and efficient procedures for Bayesian analysis of Structural Vector Autoregressions. This package estimates a wide range of models, including homo-, heteroskedastic, and non-normal specifications. Structural models can be identified by adjustable exclusion restrictions, time-varying volatility, or non-normality. They all include a flexible three-level equation-specific local-global hierarchical prior distribution for the estimated level of shrinkage for autoregressive and structural parameters. Additionally, the package facilitates predictive and structural analyses such as impulse responses, forecast error variance and historical decompositions, forecasting, verification of heteroskedasticity, non-normality, and hypotheses on autoregressive parameters, as well as analyses of structural shocks, volatilities, and fitted values. Beautiful plots, informative summary functions, and extensive documentation including the vignette by Wo\u017aniak (2024) <doi:10.48550/arXiv.2410.15090> complement all this. The implemented techniques align closely with those presented in L\u00fctkepohl, Shang, Uzeda, & Wo\u017aniak (2024) <doi:10.48550/arXiv.2404.11057>, L\u00fctkepohl & Wo\u017aniak (2020) <doi:10.1016/j.jedc.2020.103862>, and Song & Wo\u017aniak (2021) <doi:10.1093/acrefore/9780190625979.013.174>. The 'bsvars' package is aligned regarding objects, workflows, and code structure with the R package 'bsvarSIGNs' by Wang & Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they constitute an integrated toolset.  "
  },
  {
    "id": 9470,
    "package_name": "btb",
    "title": "Beyond the Border - Kernel Density Estimation for Urban\nGeography",
    "description": "The kernelSmoothing() function allows you to square and smooth geolocated data. It calculates a classical kernel smoothing (conservative) or a geographically weighted median. There are four major call modes of the function. \n        The first call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth) for a classical kernel smoothing and automatic grid.\n        The second call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles) for a geographically weighted median and automatic grid.\n        The third call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, centroids) for a classical kernel smoothing and user grid.\n        The fourth call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles, centroids) for a geographically weighted median and user grid.\n        Geographically weighted summary statistics : a framework for localised exploratory data analysis, C.Brunsdon & al., in Computers, Environment and Urban Systems C.Brunsdon & al. (2002) <doi:10.1016/S0198-9715(01)00009-6>, \n        Statistical Analysis of Spatial and Spatio-Temporal Point Patterns, Third Edition, Diggle, pp. 83-86, (2003) <doi:10.1080/13658816.2014.937718>.",
    "version": "0.2.1",
    "maintainer": "Sol\u00e8ne Colin <solene.colin@insee.fr>",
    "author": "Arlindo Dos Santos [aut],\n  Fran\u00e7ois S\u00e9m\u00e9curbe [aut],\n  Julien Pramil [aut],\n  Sol\u00e8ne Colin [cre, ctb],\n  Kim Antunez [ctb],\n  Auriane Renaud [ctb],\n  Farida Marouchi [ctb],\n  Joachim Timot\u00e9o [ctb],\n  Institut national de la statistique et des \u00e9tudes \u00e9conomiques [cph]",
    "url": "https://github.com/InseeFr/btb, https://inseefr.github.io/btb/",
    "bug_reports": "https://github.com/InseeFr/btb/issues",
    "repository": "https://cran.r-project.org/package=btb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "btb Beyond the Border - Kernel Density Estimation for Urban\nGeography The kernelSmoothing() function allows you to square and smooth geolocated data. It calculates a classical kernel smoothing (conservative) or a geographically weighted median. There are four major call modes of the function. \n        The first call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth) for a classical kernel smoothing and automatic grid.\n        The second call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles) for a geographically weighted median and automatic grid.\n        The third call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, centroids) for a classical kernel smoothing and user grid.\n        The fourth call mode is kernelSmoothing(obs, epsg, cellsize, bandwidth, quantiles, centroids) for a geographically weighted median and user grid.\n        Geographically weighted summary statistics : a framework for localised exploratory data analysis, C.Brunsdon & al., in Computers, Environment and Urban Systems C.Brunsdon & al. (2002) <doi:10.1016/S0198-9715(01)00009-6>, \n        Statistical Analysis of Spatial and Spatio-Temporal Point Patterns, Third Edition, Diggle, pp. 83-86, (2003) <doi:10.1080/13658816.2014.937718>.  "
  },
  {
    "id": 9471,
    "package_name": "btergm",
    "title": "Temporal Exponential Random Graph Models by Bootstrapped\nPseudolikelihood",
    "description": "Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs. The methods are described in Leifeld, Cranmer and Desmarais (2018), JStatSoft <doi:10.18637/jss.v083.i06>.",
    "version": "1.11.1",
    "maintainer": "Philip Leifeld <philip.leifeld@manchester.ac.uk>",
    "author": "Philip Leifeld [aut, cre],\n  Skyler J. Cranmer [ctb],\n  Bruce A. Desmarais [ctb]",
    "url": "https://github.com/leifeld/btergm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=btergm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "btergm Temporal Exponential Random Graph Models by Bootstrapped\nPseudolikelihood Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs. The methods are described in Leifeld, Cranmer and Desmarais (2018), JStatSoft <doi:10.18637/jss.v083.i06>.  "
  },
  {
    "id": 9491,
    "package_name": "bundesbank",
    "title": "Download Data from Bundesbank",
    "description": "Download data from the time-series\n  databases of the Bundesbank, the German central\n  bank. See the overview at the Bundesbank website\n  (<https://www.bundesbank.de/en/statistics/time-series-databases>)\n  for available series. The package provides only a\n  single function, getSeries(), which supports both\n  traditional and real-time datasets; it will also\n  download meta data if available. Downloaded data\n  can automatically be arranged in various formats,\n  such as data frames or 'zoo' series. The data\n  may optionally be cached, so as to avoid repeated\n  downloads of the same series.",
    "version": "0.1-12",
    "maintainer": "Enrico Schumann <es@enricoschumann.net>",
    "author": "Enrico Schumann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7601-6576>)",
    "url": "http://enricoschumann.net/R/packages/bundesbank/index.htm,\nhttps://github.com/enricoschumann/bundesbank",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bundesbank",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bundesbank Download Data from Bundesbank Download data from the time-series\n  databases of the Bundesbank, the German central\n  bank. See the overview at the Bundesbank website\n  (<https://www.bundesbank.de/en/statistics/time-series-databases>)\n  for available series. The package provides only a\n  single function, getSeries(), which supports both\n  traditional and real-time datasets; it will also\n  download meta data if available. Downloaded data\n  can automatically be arranged in various formats,\n  such as data frames or 'zoo' series. The data\n  may optionally be cached, so as to avoid repeated\n  downloads of the same series.  "
  },
  {
    "id": 9505,
    "package_name": "bvartools",
    "title": "Bayesian Inference of Vector Autoregressive and Error Correction\nModels",
    "description": "Assists in the set-up of algorithms for Bayesian inference of vector autoregressive (VAR) and error correction (VEC) models. Functions for posterior simulation, forecasting, impulse response analysis and forecast error variance decomposition are largely based on the introductory texts of Chan, Koop, Poirier and Tobias (2019, ISBN: 9781108437493), Koop and Korobilis (2010) <doi:10.1561/0800000013> and Luetkepohl (2006, ISBN: 9783540262398).",
    "version": "0.2.4",
    "maintainer": "Franz X. Mohr <franz.x.mohr@outlook.com>",
    "author": "Franz X. Mohr [aut, cre] (ORCiD: 0009-0003-8890-7781)",
    "url": "https://github.com/franzmohr/bvartools",
    "bug_reports": "https://github.com/franzmohr/bvartools/issues",
    "repository": "https://cran.r-project.org/package=bvartools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bvartools Bayesian Inference of Vector Autoregressive and Error Correction\nModels Assists in the set-up of algorithms for Bayesian inference of vector autoregressive (VAR) and error correction (VEC) models. Functions for posterior simulation, forecasting, impulse response analysis and forecast error variance decomposition are largely based on the introductory texts of Chan, Koop, Poirier and Tobias (2019, ISBN: 9781108437493), Koop and Korobilis (2010) <doi:10.1561/0800000013> and Luetkepohl (2006, ISBN: 9783540262398).  "
  },
  {
    "id": 9506,
    "package_name": "bvhar",
    "title": "Bayesian Vector Heterogeneous Autoregressive Modeling",
    "description": "Tools to model and forecast multivariate time series\n    including Bayesian Vector heterogeneous autoregressive (VHAR) model\n    by Kim & Baek (2023) (<doi:10.1080/00949655.2023.2281644>).\n    'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), and Bayesian VHAR (BVHAR) models.",
    "version": "2.3.0",
    "maintainer": "Young Geun Kim <ygeunkimstat@gmail.com>",
    "author": "Young Geun Kim [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-8651-1167>),\n  Changryong Baek [ctb]",
    "url": "https://ygeunkim.github.io/package/bvhar/,\nhttps://github.com/ygeunkim/bvhar",
    "bug_reports": "https://github.com/ygeunkim/bvhar/issues",
    "repository": "https://cran.r-project.org/package=bvhar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bvhar Bayesian Vector Heterogeneous Autoregressive Modeling Tools to model and forecast multivariate time series\n    including Bayesian Vector heterogeneous autoregressive (VHAR) model\n    by Kim & Baek (2023) (<doi:10.1080/00949655.2023.2281644>).\n    'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), and Bayesian VHAR (BVHAR) models.  "
  },
  {
    "id": 9614,
    "package_name": "caretForecast",
    "title": "Conformal Time Series Forecasting Using State of Art Machine\nLearning Algorithms",
    "description": "Conformal time series forecasting using the caret infrastructure. \n  It provides access to state-of-the-art machine learning models for forecasting\n  applications. The hyperparameter of each model is selected based on time \n  series cross-validation, and forecasting is done recursively.",
    "version": "0.1.1",
    "maintainer": "Resul Akay <resulakay1@gmail.com>",
    "author": "Resul Akay [aut, cre]",
    "url": "https://github.com/Akai01/caretForecast",
    "bug_reports": "https://github.com/Akai01/caretForecast/issues",
    "repository": "https://cran.r-project.org/package=caretForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "caretForecast Conformal Time Series Forecasting Using State of Art Machine\nLearning Algorithms Conformal time series forecasting using the caret infrastructure. \n  It provides access to state-of-the-art machine learning models for forecasting\n  applications. The hyperparameter of each model is selected based on time \n  series cross-validation, and forecasting is done recursively.  "
  },
  {
    "id": 9616,
    "package_name": "carfima",
    "title": "Continuous-Time Fractionally Integrated ARMA Process for\nIrregularly Spaced Long-Memory Time Series Data",
    "description": "We provide a toolbox to fit a continuous-time fractionally integrated ARMA process (CARFIMA) on univariate and irregularly spaced time series data via both frequentist and Bayesian machinery. A general-order CARFIMA(p, H, q) model for p>q is specified in Tsai and Chan (2005) <doi:10.1111/j.1467-9868.2005.00522.x> and it involves p+q+2 unknown model parameters, i.e., p AR parameters, q MA parameters, Hurst parameter H, and process uncertainty (standard deviation) sigma. Also, the model can account for heteroscedastic measurement errors, if the information about measurement error standard deviations is known. The package produces their maximum likelihood estimates and asymptotic uncertainties using a global optimizer called the differential evolution algorithm. It also produces posterior samples of the model parameters via Metropolis-Hastings within a Gibbs sampler equipped with adaptive Markov chain Monte Carlo. These fitting procedures, however, may produce numerical errors if p>2. The toolbox also contains a function to simulate discrete time series data from CARFIMA(p, H, q) process given the model parameters and observation times. ",
    "version": "2.0.2",
    "maintainer": "Hyungsuk Tak <hyungsuk.tak@gmail.com>",
    "author": "Hyungsuk Tak, Henghsiu Tsai, and Kisung You",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=carfima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "carfima Continuous-Time Fractionally Integrated ARMA Process for\nIrregularly Spaced Long-Memory Time Series Data We provide a toolbox to fit a continuous-time fractionally integrated ARMA process (CARFIMA) on univariate and irregularly spaced time series data via both frequentist and Bayesian machinery. A general-order CARFIMA(p, H, q) model for p>q is specified in Tsai and Chan (2005) <doi:10.1111/j.1467-9868.2005.00522.x> and it involves p+q+2 unknown model parameters, i.e., p AR parameters, q MA parameters, Hurst parameter H, and process uncertainty (standard deviation) sigma. Also, the model can account for heteroscedastic measurement errors, if the information about measurement error standard deviations is known. The package produces their maximum likelihood estimates and asymptotic uncertainties using a global optimizer called the differential evolution algorithm. It also produces posterior samples of the model parameters via Metropolis-Hastings within a Gibbs sampler equipped with adaptive Markov chain Monte Carlo. These fitting procedures, however, may produce numerical errors if p>2. The toolbox also contains a function to simulate discrete time series data from CARFIMA(p, H, q) process given the model parameters and observation times.   "
  },
  {
    "id": 9670,
    "package_name": "causalDisco",
    "title": "Tools for Causal Discovery on Observational Data",
    "description": "Various tools for inferring causal models from observational data. The package \n    includes an implementation of the temporal Peter-Clark (TPC) algorithm. Petersen, Osler \n    and Ekstr\u00f8m (2021) <doi:10.1093/aje/kwab087>. It also includes general tools\n    for evaluating differences in adjacency matrices, which can be used for evaluating\n    performance of causal discovery procedures. ",
    "version": "0.9.1",
    "maintainer": "Anne Helby Petersen <ahpe@sund.ku.dk>",
    "author": "Anne Helby Petersen [aut, cre]",
    "url": "https://github.com/annennenne/causalDisco",
    "bug_reports": "https://github.com/annennenne/causalDisco/issues",
    "repository": "https://cran.r-project.org/package=causalDisco",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "causalDisco Tools for Causal Discovery on Observational Data Various tools for inferring causal models from observational data. The package \n    includes an implementation of the temporal Peter-Clark (TPC) algorithm. Petersen, Osler \n    and Ekstr\u00f8m (2021) <doi:10.1093/aje/kwab087>. It also includes general tools\n    for evaluating differences in adjacency matrices, which can be used for evaluating\n    performance of causal discovery procedures.   "
  },
  {
    "id": 9696,
    "package_name": "cbsREPS",
    "title": "Hedonic and Multilateral Index Methods for Real Estate Price\nStatistics",
    "description": "Compute price indices using various Hedonic and\n    multilateral methods, including Laspeyres, Paasche, Fisher, and HMTS (Hedonic\n    Multilateral Time series re-estimation with splicing). The central function\n    calculate_price_index() offers a unified interface for running these methods\n    on structured datasets. This package is designed to support index construction\n    workflows for real estate and other domains where quality-adjusted price\n    comparisons over time are essential. The development of this package was funded\n    by Eurostat and Statistics Netherlands (CBS), and carried out by Statistics Netherlands.\n    The HMTS method implemented here is described in Ishaak, Ouwehand and Rem\u00f8y (2024)\n    <doi:10.1177/0282423X241246617>. For broader methodological context, see Eurostat\n    (2013, ISBN:978-92-79-25984-5, <doi:10.2785/34007>).",
    "version": "0.1.0",
    "maintainer": "Vivek Gajadhar <v.gajadhar@cbs.nl>",
    "author": "Farley Ishaak [aut],\n  Pim Ouwehand [aut],\n  David Pietersz [aut],\n  Liu Nuo Su [aut],\n  Cynthia Cao [aut],\n  Mohammed Kardal [aut],\n  Odens van der Zwan [aut],\n  Vivek Gajadhar [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cbsREPS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cbsREPS Hedonic and Multilateral Index Methods for Real Estate Price\nStatistics Compute price indices using various Hedonic and\n    multilateral methods, including Laspeyres, Paasche, Fisher, and HMTS (Hedonic\n    Multilateral Time series re-estimation with splicing). The central function\n    calculate_price_index() offers a unified interface for running these methods\n    on structured datasets. This package is designed to support index construction\n    workflows for real estate and other domains where quality-adjusted price\n    comparisons over time are essential. The development of this package was funded\n    by Eurostat and Statistics Netherlands (CBS), and carried out by Statistics Netherlands.\n    The HMTS method implemented here is described in Ishaak, Ouwehand and Rem\u00f8y (2024)\n    <doi:10.1177/0282423X241246617>. For broader methodological context, see Eurostat\n    (2013, ISBN:978-92-79-25984-5, <doi:10.2785/34007>).  "
  },
  {
    "id": 9710,
    "package_name": "ccid",
    "title": "Cross-Covariance Isolate Detect: a New Change-Point Method for\nEstimating Dynamic Functional Connectivity",
    "description": "Provides efficient implementation of the Cross-Covariance\n    Isolate Detect (CCID) methodology for the estimation of the number\n    and location of multiple change-points in the second-order\n    (cross-covariance or network) structure of multivariate, possibly\n    high-dimensional time series. The method is motivated by the detection\n    of change points in functional connectivity networks for functional\n    magnetic resonance imaging (fMRI), electroencephalography (EEG),\n    magentoencephalography (MEG) and electrocorticography (ECoG) data. The\n    main routines in the package have been extensively tested on fMRI data. \n    For details on the CCID methodology, please see Anastasiou et\n    al (2022), Cross-covariance isolate detect: A new change-point method for\n    estimating dynamic functional connectivity. Medical Image Analysis, Volume\n    75.",
    "version": "1.2.0",
    "maintainer": "Andreas Anastasiou <anastasiou.andreas@ucy.ac.cy>",
    "author": "Andreas Anastasiou [aut, cre],\n  Ivor Cribben [aut],\n  Piotr Fryzlewicz [aut]",
    "url": "https://github.com/Anastasiou-Andreas/ccid",
    "bug_reports": "https://github.com/Anastasiou-Andreas/ccid/issues",
    "repository": "https://cran.r-project.org/package=ccid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ccid Cross-Covariance Isolate Detect: a New Change-Point Method for\nEstimating Dynamic Functional Connectivity Provides efficient implementation of the Cross-Covariance\n    Isolate Detect (CCID) methodology for the estimation of the number\n    and location of multiple change-points in the second-order\n    (cross-covariance or network) structure of multivariate, possibly\n    high-dimensional time series. The method is motivated by the detection\n    of change points in functional connectivity networks for functional\n    magnetic resonance imaging (fMRI), electroencephalography (EEG),\n    magentoencephalography (MEG) and electrocorticography (ECoG) data. The\n    main routines in the package have been extensively tested on fMRI data. \n    For details on the CCID methodology, please see Anastasiou et\n    al (2022), Cross-covariance isolate detect: A new change-point method for\n    estimating dynamic functional connectivity. Medical Image Analysis, Volume\n    75.  "
  },
  {
    "id": 9795,
    "package_name": "cgmguru",
    "title": "Advanced Continuous Glucose Monitoring Analysis with\nHigh-Performance C++ Backend",
    "description": "Tools for advanced analysis of continuous glucose monitoring (CGM)\n    time-series, implementing GRID (Glucose Rate Increase Detector) and GRID-based\n    algorithms for postprandial peak detection, and detection of hypoglycemic and\n    hyperglycemic episodes (Levels 1/2/Extended) aligned with international consensus\n    CGM metrics. Core algorithms are implemented in optimized C++ using 'Rcpp' to\n    provide accurate and fast analysis on large datasets.",
    "version": "0.1.0",
    "maintainer": "Sang Ho Park <shstat1729@gmail.com>",
    "author": "Sang Ho Park [aut, cre],\n  Rosa Oh [aut, ctb],\n  Sang-Man Jin [aut, ctb]",
    "url": "https://github.com/shstat1729/cgmguru",
    "bug_reports": "https://github.com/shstat1729/cgmguru/issues",
    "repository": "https://cran.r-project.org/package=cgmguru",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cgmguru Advanced Continuous Glucose Monitoring Analysis with\nHigh-Performance C++ Backend Tools for advanced analysis of continuous glucose monitoring (CGM)\n    time-series, implementing GRID (Glucose Rate Increase Detector) and GRID-based\n    algorithms for postprandial peak detection, and detection of hypoglycemic and\n    hyperglycemic episodes (Levels 1/2/Extended) aligned with international consensus\n    CGM metrics. Core algorithms are implemented in optimized C++ using 'Rcpp' to\n    provide accurate and fast analysis on large datasets.  "
  },
  {
    "id": 9806,
    "package_name": "changepointGA",
    "title": "Changepoint Detection via Modified Genetic Algorithm",
    "description": "The Genetic Algorithm (GA) is used to perform changepoint analysis in time series data. The package also includes an extended island version of GA, as described in Lu, Lund, and Lee (2010, <doi:10.1214/09-AOAS289>). By mimicking the principles of natural selection and evolution, GA provides a powerful stochastic search technique for solving combinatorial optimization problems. In 'changepointGA', each chromosome represents a changepoint configuration, including the number and locations of changepoints, hyperparameters, and model parameters. The package employs genetic operators\u2014selection, crossover, and mutation\u2014to iteratively improve solutions based on the given fitness (objective) function. Key features of 'changepointGA' include encoding changepoint configurations in an integer format, enabling dynamic and simultaneous estimation of model hyperparameters, changepoint configurations, and associated parameters. The detailed algorithmic implementation can be found in the package vignettes and in the paper of Li (2024, <doi:10.48550/arXiv.2410.15571>).",
    "version": "0.1.3",
    "maintainer": "Mo Li <mo.li@louisiana.edu>",
    "author": "Mo Li [aut, cre],\n  QiQi Lu [aut]",
    "url": "https://github.com/mli171/changepointGA",
    "bug_reports": "https://github.com/mli171/changepointGA/issues",
    "repository": "https://cran.r-project.org/package=changepointGA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "changepointGA Changepoint Detection via Modified Genetic Algorithm The Genetic Algorithm (GA) is used to perform changepoint analysis in time series data. The package also includes an extended island version of GA, as described in Lu, Lund, and Lee (2010, <doi:10.1214/09-AOAS289>). By mimicking the principles of natural selection and evolution, GA provides a powerful stochastic search technique for solving combinatorial optimization problems. In 'changepointGA', each chromosome represents a changepoint configuration, including the number and locations of changepoints, hyperparameters, and model parameters. The package employs genetic operators\u2014selection, crossover, and mutation\u2014to iteratively improve solutions based on the given fitness (objective) function. Key features of 'changepointGA' include encoding changepoint configurations in an integer format, enabling dynamic and simultaneous estimation of model hyperparameters, changepoint configurations, and associated parameters. The detailed algorithmic implementation can be found in the package vignettes and in the paper of Li (2024, <doi:10.48550/arXiv.2410.15571>).  "
  },
  {
    "id": 9835,
    "package_name": "cheddar",
    "title": "Analysis and Visualisation of Ecological Communities",
    "description": "Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.",
    "version": "0.1-639",
    "maintainer": "Lawrence Hudson <quicklizard@googlemail.com>",
    "author": "Lawrence Hudson with contributions from Dan Reuman and Rob Emerson",
    "url": "https://github.com/quicklizard99/cheddar/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cheddar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cheddar Analysis and Visualisation of Ecological Communities Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.  "
  },
  {
    "id": 9872,
    "package_name": "chopper",
    "title": "Changepoint-Aware Ensemble for Probabilistic Modeling",
    "description": "Implements a changepoint-aware ensemble forecasting algorithm that combines Theta, TBATS (Trigonometric, Box-Cox transformation, ARMA errors, Trend, Seasonal components), and ARFIMA (AutoRegressive, Fractionally Integrated, Moving Average) using a product-of-experts approach for robust probabilistic prediction.",
    "version": "1.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/chopper",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=chopper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "chopper Changepoint-Aware Ensemble for Probabilistic Modeling Implements a changepoint-aware ensemble forecasting algorithm that combines Theta, TBATS (Trigonometric, Box-Cox transformation, ARMA errors, Trend, Seasonal components), and ARFIMA (AutoRegressive, Fractionally Integrated, Moving Average) using a product-of-experts approach for robust probabilistic prediction.  "
  },
  {
    "id": 9899,
    "package_name": "cif",
    "title": "Cointegrated ICU Forecasting",
    "description": "Set of forecasting tools to predict ICU beds using a Vector Error Correction model with a single cointegrating vector. Method described in  Berta, P. Lovaglio, P.G. Paruolo, P. Verzillo, S., 2020. \"Real Time Forecasting of Covid-19 Intensive Care Units demand\" Health, Econometrics and Data Group (HEDG) Working Papers 20/16, HEDG, Department of Economics, University of York, <https://www.york.ac.uk/media/economics/documents/hedg/workingpapers/2020/2016.pdf>. ",
    "version": "0.1.1",
    "maintainer": "Paolo Paruolo <Paolo.PARUOLO@ec.europa.eu>",
    "author": "Paolo Berta [aut],\n  Paolo Paruolo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3982-4889>),\n  Stefano Verzillo [ctb],\n  Pietro Giorgio Lovaglio [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cif",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cif Cointegrated ICU Forecasting Set of forecasting tools to predict ICU beds using a Vector Error Correction model with a single cointegrating vector. Method described in  Berta, P. Lovaglio, P.G. Paruolo, P. Verzillo, S., 2020. \"Real Time Forecasting of Covid-19 Intensive Care Units demand\" Health, Econometrics and Data Group (HEDG) Working Papers 20/16, HEDG, Department of Economics, University of York, <https://www.york.ac.uk/media/economics/documents/hedg/workingpapers/2020/2016.pdf>.   "
  },
  {
    "id": 9954,
    "package_name": "clda",
    "title": "Convolution-Based Linear Discriminant Analysis",
    "description": "Contains a time series classification method that obtains a set of filters that maximize the between-class and minimize the within-class distances.",
    "version": "0.1",
    "maintainer": "Grover E. Castro Guzman <grover@usp.br>",
    "author": "Grover E. Castro Guzman [cre, aut],\n  Andr\u00e9 Fujita [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=clda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clda Convolution-Based Linear Discriminant Analysis Contains a time series classification method that obtains a set of filters that maximize the between-class and minimize the within-class distances.  "
  },
  {
    "id": 9958,
    "package_name": "cleanTS",
    "title": "Testbench for Univariate Time Series Cleaning",
    "description": "A reliable and efficient tool for cleaning univariate time \n    series data. It implements reliable and efficient procedures for \n    automating the process of cleaning univariate time series data. \n    The package provides integration with already developed and deployed \n    tools for missing value imputation and outlier detection. It also \n    provides a way of visualizing large time-series data in different \n    resolutions.",
    "version": "0.1.2",
    "maintainer": "Mayur Shende <mayur.k.shende@gmail.com>",
    "author": "Mayur Shende [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1738-2573>),\n  Neeraj Bokde [aut] (ORCID: <https://orcid.org/0000-0002-3493-9302>),\n  Andr\u00e9s E. Feij\u00f3o-Lorenzo [aut] (ORCID:\n    <https://orcid.org/0000-0003-3172-7037>)",
    "url": "https://github.com/Mayur1009/cleanTS",
    "bug_reports": "https://github.com/Mayur1009/cleanTS/issues",
    "repository": "https://cran.r-project.org/package=cleanTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cleanTS Testbench for Univariate Time Series Cleaning A reliable and efficient tool for cleaning univariate time \n    series data. It implements reliable and efficient procedures for \n    automating the process of cleaning univariate time series data. \n    The package provides integration with already developed and deployed \n    tools for missing value imputation and outlier detection. It also \n    provides a way of visualizing large time-series data in different \n    resolutions.  "
  },
  {
    "id": 9975,
    "package_name": "climaemet",
    "title": "Climate AEMET Tools",
    "description": "Tools to download the climatic data of the Spanish\n    Meteorological Agency (AEMET) directly from R using their API and\n    create scientific graphs (climate charts, trend analysis of climate\n    time series, temperature and precipitation anomalies maps, warming\n    stripes graphics, climatograms, etc.).",
    "version": "1.4.2",
    "maintainer": "Diego Hernang\u00f3mez <diego.hernangomezherrero@gmail.com>",
    "author": "Manuel Pizarro [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-6981-0154>),\n  Diego Hernang\u00f3mez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8457-4658>),\n  Gema Fern\u00e1ndez-Avil\u00e9s [aut] (ORCID:\n    <https://orcid.org/0000-0001-5934-1916>)",
    "url": "https://ropenspain.github.io/climaemet/,\nhttps://github.com/rOpenSpain/climaemet",
    "bug_reports": "https://github.com/rOpenSpain/climaemet/issues",
    "repository": "https://cran.r-project.org/package=climaemet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "climaemet Climate AEMET Tools Tools to download the climatic data of the Spanish\n    Meteorological Agency (AEMET) directly from R using their API and\n    create scientific graphs (climate charts, trend analysis of climate\n    time series, temperature and precipitation anomalies maps, warming\n    stripes graphics, climatograms, etc.).  "
  },
  {
    "id": 9980,
    "package_name": "climetrics",
    "title": "Climate Change Metrics",
    "description": "A framework that facilitates spatio-temporal analysis of climate dynamics through exploring and measuring different dimensions of climate change in space and time.",
    "version": "1.0-15",
    "maintainer": "Shirin Taheri <taheri.shi@gmail.com>",
    "author": "Shirin Taheri [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0303-3145>),\n  Babak Naimi [aut] (ORCID: <https://orcid.org/0000-0001-5431-2729>),\n  Miguel Araujo [aut]",
    "url": "https://r-gis.net/",
    "bug_reports": "https://github.com/shirintaheri/climetrics/issues/",
    "repository": "https://cran.r-project.org/package=climetrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "climetrics Climate Change Metrics A framework that facilitates spatio-temporal analysis of climate dynamics through exploring and measuring different dimensions of climate change in space and time.  "
  },
  {
    "id": 10005,
    "package_name": "clockplot",
    "title": "Plot Event Times on a 24-Hour Clock",
    "description": "Provides a novel visualization technique for plotting timestamped events\n    on a 24-hour circular clock face. This is particularly useful for analyzing\n    daily patterns, event clustering, and gaps in temporal data. The package\n    also generalizes this approach to create cyclic charts for other periods,\n    including weekly and monthly cycles, enabling effective event planning and\n    pattern analysis across multiple time frames.",
    "version": "0.8.3",
    "maintainer": "Abdullah Al Mahmud <almahmud.sbi@gmail.com>",
    "author": "Abdullah Al Mahmud [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2814-8798>)",
    "url": "https://github.com/mahmudstat/clockplot/",
    "bug_reports": "https://github.com/mahmudstat/clockplot/issues",
    "repository": "https://cran.r-project.org/package=clockplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clockplot Plot Event Times on a 24-Hour Clock Provides a novel visualization technique for plotting timestamped events\n    on a 24-hour circular clock face. This is particularly useful for analyzing\n    daily patterns, event clustering, and gaps in temporal data. The package\n    also generalizes this approach to create cyclic charts for other periods,\n    including weekly and monthly cycles, enabling effective event planning and\n    pattern analysis across multiple time frames.  "
  },
  {
    "id": 10033,
    "package_name": "clustTMB",
    "title": "Spatio-Temporal Finite Mixture Model using 'TMB'",
    "description": "Fits a spatio-temporal finite mixture model using 'TMB'.\n    Covariate, spatial and temporal random effects can be incorporated\n    into the gating formula using multinomial logistic regression, the\n    expert formula using a generalized linear mixed model framework, or\n    both.",
    "version": "0.1.0",
    "maintainer": "Andrea M. Havron <andrea.havron@noaa.gov>",
    "author": "Andrea M. Havron [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4080-448X>)",
    "url": "https://github.com/Andrea-Havron/clustTMB,\nhttps://andrea-havron.github.io/clustTMB/",
    "bug_reports": "https://github.com/Andrea-Havron/clustTMB/issues",
    "repository": "https://cran.r-project.org/package=clustTMB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clustTMB Spatio-Temporal Finite Mixture Model using 'TMB' Fits a spatio-temporal finite mixture model using 'TMB'.\n    Covariate, spatial and temporal random effects can be incorporated\n    into the gating formula using multinomial logistic regression, the\n    expert formula using a generalized linear mixed model framework, or\n    both.  "
  },
  {
    "id": 10056,
    "package_name": "clustra",
    "title": "Clustering Longitudinal Trajectories",
    "description": "Clusters longitudinal trajectories over time (can be unequally \n    spaced, unequal length time series and/or partially overlapping series) on\n    a common time axis. Performs k-means clustering on a single continuous \n    variable measured over time, where each mean is defined by a thin plate \n    spline fit to all points in a cluster. Distance is MSE across trajectory \n    points to cluster spline. Provides graphs of derived cluster splines, \n    silhouette plots, and Adjusted Rand Index evaluations of the number\n    of clusters. Scales well to large data with multicore parallelism available\n    to speed computation.",
    "version": "0.2.1",
    "maintainer": "George Ostrouchov <go@tennessee.edu>",
    "author": "George Ostrouchov [aut, cre],\n  David Gagnon [aut],\n  Hanna Gerlovin [aut],\n  Chen Wei-Chen [ctb],\n  Schmidt Drew [ctb],\n  Oak Ridge National Laboratory [cph],\n  U.S. Department of Veteran's Affairs [fnd] (Project: Million Veteran\n    Program Data Core)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=clustra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clustra Clustering Longitudinal Trajectories Clusters longitudinal trajectories over time (can be unequally \n    spaced, unequal length time series and/or partially overlapping series) on\n    a common time axis. Performs k-means clustering on a single continuous \n    variable measured over time, where each mean is defined by a thin plate \n    spline fit to all points in a cluster. Distance is MSE across trajectory \n    points to cluster spline. Provides graphs of derived cluster splines, \n    silhouette plots, and Adjusted Rand Index evaluations of the number\n    of clusters. Scales well to large data with multicore parallelism available\n    to speed computation.  "
  },
  {
    "id": 10064,
    "package_name": "cmR",
    "title": "Analysis of Cardiac Magnetic Resonance Images",
    "description": "Computes maximum response from Cardiac Magnetic Resonance Images using spatial and voxel wise spline based Bayesian model. This is an implementation of the methods described in Schmid (2011) <doi:10.1109/TMI.2011.2109733> \"Voxel-Based Adaptive Spatio-Temporal Modelling of Perfusion Cardiovascular MRI\". IEEE TMI 30(7) p. 1305 - 1313.",
    "version": "1.1",
    "maintainer": "Volker Schmid <volker.schmid@lmu.de>",
    "author": "Volker Schmid [aut, cre]",
    "url": "https://bioimaginggroup.github.io/cmr/",
    "bug_reports": "https://github.com/bioimaginggroup/cmR/issues",
    "repository": "https://cran.r-project.org/package=cmR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cmR Analysis of Cardiac Magnetic Resonance Images Computes maximum response from Cardiac Magnetic Resonance Images using spatial and voxel wise spline based Bayesian model. This is an implementation of the methods described in Schmid (2011) <doi:10.1109/TMI.2011.2109733> \"Voxel-Based Adaptive Spatio-Temporal Modelling of Perfusion Cardiovascular MRI\". IEEE TMI 30(7) p. 1305 - 1313.  "
  },
  {
    "id": 10112,
    "package_name": "coconots",
    "title": "Convolution-Closed Models for Count Time Series",
    "description": "Useful tools for fitting, validating, and forecasting of practical convolution-closed time series models for low counts are provided. Marginal distributions of the data can be modelled via Poisson and Generalized Poisson innovations. Regression effects can be incorporated through time varying innovation rates. The models are described in Jung and Tremayne (2011) <doi:10.1111/j.1467-9892.2010.00697.x> and the model assessment tools are presented in Czado et al. (2009) <doi:10.1111/j.1541-0420.2009.01191.x> and, Tsay (1992) <doi:10.2307/2347612>.",
    "version": "2.0.2",
    "maintainer": "Manuel Huth <manuel.huth@yahoo.com>",
    "author": "Manuel Huth [aut, cre],\n  Robert C. Jung [aut],\n  Andy Tremayne [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=coconots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "coconots Convolution-Closed Models for Count Time Series Useful tools for fitting, validating, and forecasting of practical convolution-closed time series models for low counts are provided. Marginal distributions of the data can be modelled via Poisson and Generalized Poisson innovations. Regression effects can be incorporated through time varying innovation rates. The models are described in Jung and Tremayne (2011) <doi:10.1111/j.1467-9892.2010.00697.x> and the model assessment tools are presented in Czado et al. (2009) <doi:10.1111/j.1541-0420.2009.01191.x> and, Tsay (1992) <doi:10.2307/2347612>.  "
  },
  {
    "id": 10141,
    "package_name": "codyn",
    "title": "Community Dynamics Metrics",
    "description": "Univariate and multivariate temporal and spatial diversity indices, \n    rank abundance curves, and community stability measures. The functions \n    implement measures that are either explicitly temporal and include the \n    option to calculate them over multiple replicates, or spatial and include \n    the option to calculate them over multiple time points. Functions fall into \n    five categories: static diversity indices, temporal diversity indices, \n    spatial diversity indices, rank abundance curves, and community stability \n    measures. The diversity indices are temporal and spatial analogs to \n    traditional diversity indices. Specifically, the package includes functions \n    to calculate community richness, evenness and diversity at a given point in \n    space and time. In addition, it contains functions to calculate species \n    turnover, mean rank shifts, and lags in community similarity between two \n    time points. Details of the methods are available in\n    Hallett et al. (2016) <doi:10.1111/2041-210X.12569> and Avolio \n    et al. (2019) <doi:10.1002/ecs2.2881>.",
    "version": "2.0.5",
    "maintainer": "Matthew B. Jones <jones@nceas.ucsb.edu>",
    "author": "Lauren Hallett [aut] (ORCID: <https://orcid.org/0000-0002-0718-0257>),\n  Meghan L. Avolio [aut] (ORCID: <https://orcid.org/0000-0002-2649-9159>),\n  Ian T. Carroll [aut] (ORCID: <https://orcid.org/0000-0002-3616-810X>),\n  Sydney K. Jones [aut],\n  A. Andrew M. MacDonald [aut] (ORCID:\n    <https://orcid.org/0000-0003-1162-169X>),\n  Dan F. B. Flynn [aut] (ORCID: <https://orcid.org/0000-0002-2978-5257>),\n  Peter Slaughter [aut] (ORCID: <https://orcid.org/0000-0002-2192-403X>),\n  Julie Ripplinger [aut] (ORCID: <https://orcid.org/0000-0002-2771-6637>),\n  Scott L. Collins [aut] (ORCID: <https://orcid.org/0000-0002-0193-2892>),\n  Corinna Gries [aut] (ORCID: <https://orcid.org/0000-0002-9091-6543>),\n  Matthew B. Jones [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0077-4738>)",
    "url": "https://github.com/NCEAS/codyn/",
    "bug_reports": "https://github.com/NCEAS/codyn/issues",
    "repository": "https://cran.r-project.org/package=codyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "codyn Community Dynamics Metrics Univariate and multivariate temporal and spatial diversity indices, \n    rank abundance curves, and community stability measures. The functions \n    implement measures that are either explicitly temporal and include the \n    option to calculate them over multiple replicates, or spatial and include \n    the option to calculate them over multiple time points. Functions fall into \n    five categories: static diversity indices, temporal diversity indices, \n    spatial diversity indices, rank abundance curves, and community stability \n    measures. The diversity indices are temporal and spatial analogs to \n    traditional diversity indices. Specifically, the package includes functions \n    to calculate community richness, evenness and diversity at a given point in \n    space and time. In addition, it contains functions to calculate species \n    turnover, mean rank shifts, and lags in community similarity between two \n    time points. Details of the methods are available in\n    Hallett et al. (2016) <doi:10.1111/2041-210X.12569> and Avolio \n    et al. (2019) <doi:10.1002/ecs2.2881>.  "
  },
  {
    "id": 10166,
    "package_name": "collapse",
    "title": "Advanced and Fast Data Transformation",
    "description": "A large C/C++-based package for advanced data transformation and \n    statistical computing in R that is extremely fast, class-agnostic, robust, and \n    programmer friendly. Core functionality includes a rich set of S3 generic grouped \n    and weighted statistical functions for vectors, matrices and data frames, which \n    provide efficient low-level vectorizations, OpenMP multithreading, and skip missing \n    values by default. These are integrated with fast grouping and ordering algorithms \n    (also callable from C), and efficient data manipulation functions. The package also \n    provides a flexible and rigorous approach to time series and panel data in R, fast \n    functions for data transformation and common statistical procedures, detailed \n    (grouped, weighted) summary statistics, powerful tools to work with nested data, \n    fast data object conversions, functions for memory efficient R programming, and \n    helpers to effectively deal with variable labels, attributes, and missing data. It \n    seamlessly supports base R objects/classes as well as 'units', 'integer64', 'xts'/\n    'zoo', 'tibble', 'grouped_df', 'data.table', 'sf', and 'pseries'/'pdata.frame'.",
    "version": "2.1.5",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6212-5229>),\n  Matt Dowle [ctb],\n  Arun Srinivasan [ctb],\n  Morgan Jacob [ctb],\n  Dirk Eddelbuettel [ctb],\n  Laurent Berge [ctb],\n  Kevin Tappe [ctb],\n  Alina Cherkas [ctb],\n  R Core Team and contributors worldwide [ctb],\n  Martyn Plummer [cph],\n  1999-2016 The R Core Team [cph]",
    "url": "https://sebkrantz.github.io/collapse/,\nhttps://github.com/SebKrantz/collapse",
    "bug_reports": "https://github.com/SebKrantz/collapse/issues",
    "repository": "https://cran.r-project.org/package=collapse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "collapse Advanced and Fast Data Transformation A large C/C++-based package for advanced data transformation and \n    statistical computing in R that is extremely fast, class-agnostic, robust, and \n    programmer friendly. Core functionality includes a rich set of S3 generic grouped \n    and weighted statistical functions for vectors, matrices and data frames, which \n    provide efficient low-level vectorizations, OpenMP multithreading, and skip missing \n    values by default. These are integrated with fast grouping and ordering algorithms \n    (also callable from C), and efficient data manipulation functions. The package also \n    provides a flexible and rigorous approach to time series and panel data in R, fast \n    functions for data transformation and common statistical procedures, detailed \n    (grouped, weighted) summary statistics, powerful tools to work with nested data, \n    fast data object conversions, functions for memory efficient R programming, and \n    helpers to effectively deal with variable labels, attributes, and missing data. It \n    seamlessly supports base R objects/classes as well as 'units', 'integer64', 'xts'/\n    'zoo', 'tibble', 'grouped_df', 'data.table', 'sf', and 'pseries'/'pdata.frame'.  "
  },
  {
    "id": 10174,
    "package_name": "collin",
    "title": "Visualization the Effects of Collinearity in Distributed Lag\nModels and Other Linear Models",
    "description": "Tool to assessing whether the results of a study could be influenced by\n    collinearity. Simulations under a given hypothesized truth regarding effects of an\n    exposure on the outcome are used and the resulting curves of lagged effects are\n    visualized. A user's manual is provided, which includes detailed examples (e.g. a\n    cohort study looking for windows of vulnerability to air pollution, a time series\n    study examining the linear association of air pollution with hospital admissions,\n    and a time series study examining the non-linear association between temperature and\n    mortality). The methods are described in Basagana and Barrera-Gomez (2021) <doi:10.1093/ije/dyab179>.",
    "version": "0.0.4",
    "maintainer": "Jose Barrera-Gomez <jose.barrera@isglobal.org>",
    "author": "Jose Barrera-Gomez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2688-6036>),\n  Xavier Basagana [aut] (ORCID: <https://orcid.org/0000-0002-8457-1489>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=collin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "collin Visualization the Effects of Collinearity in Distributed Lag\nModels and Other Linear Models Tool to assessing whether the results of a study could be influenced by\n    collinearity. Simulations under a given hypothesized truth regarding effects of an\n    exposure on the outcome are used and the resulting curves of lagged effects are\n    visualized. A user's manual is provided, which includes detailed examples (e.g. a\n    cohort study looking for windows of vulnerability to air pollution, a time series\n    study examining the linear association of air pollution with hospital admissions,\n    and a time series study examining the non-linear association between temperature and\n    mortality). The methods are described in Basagana and Barrera-Gomez (2021) <doi:10.1093/ije/dyab179>.  "
  },
  {
    "id": 10190,
    "package_name": "colorednoise",
    "title": "Simulate Temporally Autocorrelated Populations",
    "description": "Temporally autocorrelated populations are correlated in their vital rates (growth, death, etc.) from year to year. It is very common for populations, whether they be bacteria, plants, or humans, to be temporally autocorrelated. This poses a challenge for stochastic population modeling, because a temporally correlated population will behave differently from an uncorrelated one.\n    This package provides tools for simulating populations with white noise (no temporal autocorrelation), red noise (positive temporal autocorrelation), and blue noise (negative temporal autocorrelation).  The algebraic formulation for autocorrelated noise comes from Ruokolainen et al. (2009) <doi:10.1016/j.tree.2009.04.009>. Models for unstructured populations and for structured populations (matrix models) are available.",
    "version": "1.1.2",
    "maintainer": "July Pilowsky <pilowskyj@caryinstitute.org>",
    "author": "July Pilowsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6376-2585>)",
    "url": "",
    "bug_reports": "https://github.com/japilo/colorednoise/issues",
    "repository": "https://cran.r-project.org/package=colorednoise",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "colorednoise Simulate Temporally Autocorrelated Populations Temporally autocorrelated populations are correlated in their vital rates (growth, death, etc.) from year to year. It is very common for populations, whether they be bacteria, plants, or humans, to be temporally autocorrelated. This poses a challenge for stochastic population modeling, because a temporally correlated population will behave differently from an uncorrelated one.\n    This package provides tools for simulating populations with white noise (no temporal autocorrelation), red noise (positive temporal autocorrelation), and blue noise (negative temporal autocorrelation).  The algebraic formulation for autocorrelated noise comes from Ruokolainen et al. (2009) <doi:10.1016/j.tree.2009.04.009>. Models for unstructured populations and for structured populations (matrix models) are available.  "
  },
  {
    "id": 10308,
    "package_name": "conformalForecast",
    "title": "Conformal Prediction Methods for Multistep-Ahead Time Series\nForecasting",
    "description": "Methods and tools for performing multistep-ahead time series\n    forecasting using conformal prediction methods including classical\n    conformal prediction, adaptive conformal prediction, conformal PID\n    (Proportional-Integral-Derivative) control, and autocorrelated\n    multistep-ahead conformal prediction.\n    The methods were described by Wang and Hyndman (2024) <doi:10.48550/arXiv.2410.13115>.",
    "version": "0.1.0",
    "maintainer": "Xiaoqian Wang <Xiaoqian.Wang@amss.ac.cn>",
    "author": "Xiaoqian Wang [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4827-496X>),\n  Rob Hyndman [aut] (ORCID: <https://orcid.org/0000-0002-2140-5352>)",
    "url": "https://github.com/xqnwang/conformalForecast,\nhttps://xqnwang.github.io/conformalForecast/",
    "bug_reports": "https://github.com/xqnwang/conformalForecast/issues",
    "repository": "https://cran.r-project.org/package=conformalForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "conformalForecast Conformal Prediction Methods for Multistep-Ahead Time Series\nForecasting Methods and tools for performing multistep-ahead time series\n    forecasting using conformal prediction methods including classical\n    conformal prediction, adaptive conformal prediction, conformal PID\n    (Proportional-Integral-Derivative) control, and autocorrelated\n    multistep-ahead conformal prediction.\n    The methods were described by Wang and Hyndman (2024) <doi:10.48550/arXiv.2410.13115>.  "
  },
  {
    "id": 10339,
    "package_name": "constellation",
    "title": "Identify Event Sequences Using Time Series Joins",
    "description": "Examine any number of time series data frames to identify \n    instances in which various criteria are met within specified time\n    frames. In clinical medicine, these types of events are often\n    called \"constellations of signs and symptoms\", because a single \n    condition depends on a series of events occurring within a certain \n    amount of time of each other. This package was written to work with\n    any number of time series data frames and is optimized for speed \n    to work well with data frames with millions of rows.",
    "version": "0.2.0",
    "maintainer": "Mark Sendak <mark.sendak@gmail.com>",
    "author": "Mark Sendak [aut, cre]",
    "url": "https://github.com/marksendak/constellation",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=constellation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "constellation Identify Event Sequences Using Time Series Joins Examine any number of time series data frames to identify \n    instances in which various criteria are met within specified time\n    frames. In clinical medicine, these types of events are often\n    called \"constellations of signs and symptoms\", because a single \n    condition depends on a series of events occurring within a certain \n    amount of time of each other. This package was written to work with\n    any number of time series data frames and is optimized for speed \n    to work well with data frames with millions of rows.  "
  },
  {
    "id": 10353,
    "package_name": "contoso",
    "title": "Dataset of the 'Contoso' Company",
    "description": "A collection of synthetic datasets simulating sales transactions from a fictional company. The dataset includes various related tables that contain essential business and operational data, useful for analyzing sales performance and other business insights. Key tables included in the package are:\n  - \"sales\": Contains data on individual sales transactions, including order details, pricing, quantities, and customer information.\n  - \"customer\": Stores customer-specific details such as demographics, geographic location, occupation, and birthday.\n  - \"store\": Provides information about stores, including location, size, status, and operational dates.\n  - \"orders\": Contains details about customer orders, including order and delivery dates, store, and customer data.\n  - \"product\": Contains data on products, including attributes such as product name, category, price, cost, and weight.\n  - \"date\": A time-based table that includes date-related attributes like year, month, quarter, day, and working day indicators.\n  This dataset is ideal for practicing data analysis, performing time-series analysis, creating reports, or simulating business intelligence scenarios.",
    "version": "1.2.1",
    "maintainer": "Alejandro Hagan <alejandro.hagan@outlook.com>",
    "author": "Alejandro Hagan [aut, cre]",
    "url": "https://usrbinr.github.io/contoso/,\nhttps://github.com/usrbinr/contoso",
    "bug_reports": "https://github.com/usrbinr/contoso/issues",
    "repository": "https://cran.r-project.org/package=contoso",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "contoso Dataset of the 'Contoso' Company A collection of synthetic datasets simulating sales transactions from a fictional company. The dataset includes various related tables that contain essential business and operational data, useful for analyzing sales performance and other business insights. Key tables included in the package are:\n  - \"sales\": Contains data on individual sales transactions, including order details, pricing, quantities, and customer information.\n  - \"customer\": Stores customer-specific details such as demographics, geographic location, occupation, and birthday.\n  - \"store\": Provides information about stores, including location, size, status, and operational dates.\n  - \"orders\": Contains details about customer orders, including order and delivery dates, store, and customer data.\n  - \"product\": Contains data on products, including attributes such as product name, category, price, cost, and weight.\n  - \"date\": A time-based table that includes date-related attributes like year, month, quarter, day, and working day indicators.\n  This dataset is ideal for practicing data analysis, performing time-series analysis, creating reports, or simulating business intelligence scenarios.  "
  },
  {
    "id": 10396,
    "package_name": "corbouli",
    "title": "Corbae-Ouliaris Frequency Domain Filtering",
    "description": "Corbae-Ouliaris frequency domain filtering. According to \n             Corbae and Ouliaris (2006) <doi:10.1017/CBO9781139164863.008>,\n             this is a solution for extracting cycles from time series, like\n             business cycles etc. when filtering. This method is valid for both\n             stationary and non-stationary time series.",
    "version": "0.1.5",
    "maintainer": "Christos Adam <econp266@econ.soc.uoc.gr>",
    "author": "Christos Adam [aut, cre] (ORCID:\n    <https://orcid.org/0009-0003-3244-7034>)",
    "url": "https://github.com/cadam00/corbouli,\nhttps://cadam00.github.io/corbouli/",
    "bug_reports": "https://github.com/cadam00/corbouli/issues",
    "repository": "https://cran.r-project.org/package=corbouli",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "corbouli Corbae-Ouliaris Frequency Domain Filtering Corbae-Ouliaris frequency domain filtering. According to \n             Corbae and Ouliaris (2006) <doi:10.1017/CBO9781139164863.008>,\n             this is a solution for extracting cycles from time series, like\n             business cycles etc. when filtering. This method is valid for both\n             stationary and non-stationary time series.  "
  },
  {
    "id": 10433,
    "package_name": "corset",
    "title": "Arbitrary Bounding of Series and Time Series Objects",
    "description": "Set of methods to constrain numerical series and time series within\n             arbitrary boundaries.",
    "version": "0.1-5",
    "maintainer": "Fran Urbano <viraltux@gmail.com>",
    "author": "Fran Urbano",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=corset",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "corset Arbitrary Bounding of Series and Time Series Objects Set of methods to constrain numerical series and time series within\n             arbitrary boundaries.  "
  },
  {
    "id": 10444,
    "package_name": "costat",
    "title": "Time Series Costationarity Determination",
    "description": "Contains functions that can determine whether a time series\n\tis second-order stationary or not (and hence evidence for\n\tlocally stationarity). Given two non-stationary series (i.e.\n\tlocally stationary series) this package can then discover\n\ttime-varying linear combinations that are second-order stationary.\n\tCardinali, A. and Nason, G.P. (2013)\n\t<doi:10.18637/jss.v055.i01>.",
    "version": "2.4.1",
    "maintainer": "Guy Nason <g.nason@imperial.ac.uk>",
    "author": "Guy Nason [aut, cre],\n  Alessandro Cardinali [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=costat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "costat Time Series Costationarity Determination Contains functions that can determine whether a time series\n\tis second-order stationary or not (and hence evidence for\n\tlocally stationarity). Given two non-stationary series (i.e.\n\tlocally stationary series) this package can then discover\n\ttime-varying linear combinations that are second-order stationary.\n\tCardinali, A. and Nason, G.P. (2013)\n\t<doi:10.18637/jss.v055.i01>.  "
  },
  {
    "id": 10448,
    "package_name": "countHMM",
    "title": "Penalized Estimation of Flexible Hidden Markov Models for Time\nSeries of Counts",
    "description": "Provides tools for penalized estimation of flexible hidden Markov models for time series of counts w/o the need to specify a (parametric) family of distributions. These include functions for model fitting, model checking, and state decoding. For details, see Adam, T., Langrock, R., and Wei\u00df, C.H. (2019): Penalized Estimation of Flexible Hidden Markov Models for Time Series of Counts. <arXiv:1901.03275>.",
    "version": "0.1.0",
    "maintainer": "Timo Adam <timo.adam@uni-bielefeld.de>",
    "author": "Timo Adam",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=countHMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "countHMM Penalized Estimation of Flexible Hidden Markov Models for Time\nSeries of Counts Provides tools for penalized estimation of flexible hidden Markov models for time series of counts w/o the need to specify a (parametric) family of distributions. These include functions for model fitting, model checking, and state decoding. For details, see Adam, T., Langrock, R., and Wei\u00df, C.H. (2019): Penalized Estimation of Flexible Hidden Markov Models for Time Series of Counts. <arXiv:1901.03275>.  "
  },
  {
    "id": 10449,
    "package_name": "countSTAR",
    "title": "Flexible Modeling of Count Data",
    "description": "For Bayesian and classical inference and prediction with count-valued data,\n    Simultaneous Transformation and Rounding (STAR) Models provide a flexible, interpretable,\n    and easy-to-use approach. STAR models the observed count data using a rounded \n    continuous data model and incorporates a transformation for greater flexibility.\n    Implicitly, STAR formalizes the commonly-applied yet incoherent procedure of \n    (i) transforming count-valued data and subsequently \n    (ii) modeling the transformed data using Gaussian models. \n    STAR is well-defined for count-valued data, which is reflected in predictive accuracy, \n    and is designed to account for zero-inflation, bounded or censored data, and over- or underdispersion. \n    Importantly, STAR is easy to combine with existing MCMC or point estimation\n    methods for continuous data, which allows seamless adaptation of continuous data\n    models (such as linear regressions, additive models, BART, random forests,\n    and gradient boosting machines) for count-valued data. The package also includes several\n    methods for modeling count time series data, namely via warped Dynamic Linear Models. \n    For more details and background on these methodologies, see the works of \n    Kowal and Canale (2020) <doi:10.1214/20-EJS1707>, \n    Kowal and Wu (2022) <doi:10.1111/biom.13617>, \n    King and Kowal (2022) <arXiv:2110.14790>, and \n    Kowal and Wu (2023) <arXiv:2110.12316>.",
    "version": "1.0.2",
    "maintainer": "Brian King <brianking387@gmail.com>",
    "author": "Brian King [aut, cre],\n  Dan Kowal [aut]",
    "url": "https://bking124.github.io/countSTAR/\nhttps://github.com/bking124/countSTAR",
    "bug_reports": "https://github.com/bking124/countSTAR/issues",
    "repository": "https://cran.r-project.org/package=countSTAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "countSTAR Flexible Modeling of Count Data For Bayesian and classical inference and prediction with count-valued data,\n    Simultaneous Transformation and Rounding (STAR) Models provide a flexible, interpretable,\n    and easy-to-use approach. STAR models the observed count data using a rounded \n    continuous data model and incorporates a transformation for greater flexibility.\n    Implicitly, STAR formalizes the commonly-applied yet incoherent procedure of \n    (i) transforming count-valued data and subsequently \n    (ii) modeling the transformed data using Gaussian models. \n    STAR is well-defined for count-valued data, which is reflected in predictive accuracy, \n    and is designed to account for zero-inflation, bounded or censored data, and over- or underdispersion. \n    Importantly, STAR is easy to combine with existing MCMC or point estimation\n    methods for continuous data, which allows seamless adaptation of continuous data\n    models (such as linear regressions, additive models, BART, random forests,\n    and gradient boosting machines) for count-valued data. The package also includes several\n    methods for modeling count time series data, namely via warped Dynamic Linear Models. \n    For more details and background on these methodologies, see the works of \n    Kowal and Canale (2020) <doi:10.1214/20-EJS1707>, \n    Kowal and Wu (2022) <doi:10.1111/biom.13617>, \n    King and Kowal (2022) <arXiv:2110.14790>, and \n    Kowal and Wu (2023) <arXiv:2110.12316>.  "
  },
  {
    "id": 10476,
    "package_name": "covid19.analytics",
    "title": "Load and Analyze Live Data from the COVID-19 Pandemic",
    "description": "Load and analyze updated time series worldwide data of reported cases for the Novel Coronavirus Disease (COVID-19) from different sources, including the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) data repository <https://github.com/CSSEGISandData/COVID-19>, \"Our World in Data\" <https://github.com/owid/> among several others. The datasets reporting the COVID-19 cases are available in two main modalities, as a time series sequences and aggregated data for the last day with greater spatial resolution. Several analysis, visualization and modelling functions are available in the package that will allow the user to compute and visualize total number of cases, total number of changes and growth rate globally or for an specific geographical location, while at the same time generating models using these trends; generate interactive visualizations and generate Susceptible-Infected-Recovered (SIR) model for the disease spread.",
    "version": "2.1.3.3",
    "maintainer": "Marcelo Ponce <m.ponce@utoronto.ca>",
    "author": "Marcelo Ponce [aut, cre], Amit Sandhel [ctb]",
    "url": "https://mponce0.github.io/covid19.analytics/",
    "bug_reports": "https://github.com/mponce0/covid19.analytics/issues",
    "repository": "https://cran.r-project.org/package=covid19.analytics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "covid19.analytics Load and Analyze Live Data from the COVID-19 Pandemic Load and analyze updated time series worldwide data of reported cases for the Novel Coronavirus Disease (COVID-19) from different sources, including the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) data repository <https://github.com/CSSEGISandData/COVID-19>, \"Our World in Data\" <https://github.com/owid/> among several others. The datasets reporting the COVID-19 cases are available in two main modalities, as a time series sequences and aggregated data for the last day with greater spatial resolution. Several analysis, visualization and modelling functions are available in the package that will allow the user to compute and visualize total number of cases, total number of changes and growth rate globally or for an specific geographical location, while at the same time generating models using these trends; generate interactive visualizations and generate Susceptible-Infected-Recovered (SIR) model for the disease spread.  "
  },
  {
    "id": 10480,
    "package_name": "covid19india",
    "title": "Pulling Clean Data from Covid19india.org",
    "description": "Pull raw and pre-cleaned versions of national and state-level \n    COVID-19 time-series data from covid19india.org <https://www.covid19india.org>. \n    Easily obtain and merge case count data, testing data, and vaccine data. \n    Also assists in calculating the time-varying effective reproduction number \n    with sensible parameters for COVID-19.",
    "version": "0.1.4",
    "maintainer": "Max Salvatore <mmsalva@umich.edu>",
    "author": "Max Salvatore [aut, cre],\n  Michael Kleinsasser [aut]",
    "url": "https://github.com/maxsal/covid19india",
    "bug_reports": "https://github.com/maxsal/covid19india/issues",
    "repository": "https://cran.r-project.org/package=covid19india",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "covid19india Pulling Clean Data from Covid19india.org Pull raw and pre-cleaned versions of national and state-level \n    COVID-19 time-series data from covid19india.org <https://www.covid19india.org>. \n    Easily obtain and merge case count data, testing data, and vaccine data. \n    Also assists in calculating the time-varying effective reproduction number \n    with sensible parameters for COVID-19.  "
  },
  {
    "id": 10486,
    "package_name": "covidcast",
    "title": "Client for Delphi's 'COVIDcast Epidata' API",
    "description": "Tools for Delphi's 'COVIDcast Epidata' API: data access, maps and\n    time series plotting, and basic signal processing. The API includes a\n    collection of numerous indicators relevant to the COVID-19 pandemic in the\n    United States, including official reports, de-identified aggregated medical\n    claims data, large-scale surveys of symptoms and public behavior, and\n    mobility data, typically updated daily and at the county level. All data\n    sources are documented at\n    <https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html>.",
    "version": "0.5.3",
    "maintainer": "Alex Reinhart <areinhar@stat.cmu.edu>",
    "author": "Taylor Arnold [aut],\n  Jacob Bien [aut],\n  Logan Brooks [aut],\n  Sarah Colquhoun [aut],\n  David Farrow [aut],\n  Jed Grabman [ctb],\n  Pedrito Maynard-Zhang [ctb],\n  Kathryn Mazaitis [aut],\n  Alex Reinhart [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6658-514X>),\n  Ryan Tibshirani [aut]",
    "url": "https://cmu-delphi.github.io/covidcast/covidcastR/,\nhttps://github.com/cmu-delphi/covidcast",
    "bug_reports": "https://github.com/cmu-delphi/covidcast/issues",
    "repository": "https://cran.r-project.org/package=covidcast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "covidcast Client for Delphi's 'COVIDcast Epidata' API Tools for Delphi's 'COVIDcast Epidata' API: data access, maps and\n    time series plotting, and basic signal processing. The API includes a\n    collection of numerous indicators relevant to the COVID-19 pandemic in the\n    United States, including official reports, de-identified aggregated medical\n    claims data, large-scale surveys of symptoms and public behavior, and\n    mobility data, typically updated daily and at the county level. All data\n    sources are documented at\n    <https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html>.  "
  },
  {
    "id": 10509,
    "package_name": "cpam",
    "title": "Changepoint Additive Models for Time Series Omics Data",
    "description": "Provides a comprehensive framework for time series omics analysis,\n  integrating changepoint detection, smooth and shape-constrained trends,\n  and uncertainty quantification. It supports gene- and transcript-level inferences,\n  p-value aggregation for improved power, and both case-only and case-control designs.\n  It includes an interactive 'shiny' interface. The methods are described in Yates et al. (2024) <doi:10.1101/2024.12.22.630003>.",
    "version": "0.1.3",
    "maintainer": "Luke Yates <luke.yates@utas.edu.au>",
    "author": "Luke Yates [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1685-3169>),\n  Michael Charleston [aut],\n  Jazmine Humphreys [aut],\n  Steven Smith [aut]",
    "url": "https://l-a-yates.github.io/cpam/,\nhttps://github.com/l-a-yates/cpam",
    "bug_reports": "https://github.com/l-a-yates/cpam/issues",
    "repository": "https://cran.r-project.org/package=cpam",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cpam Changepoint Additive Models for Time Series Omics Data Provides a comprehensive framework for time series omics analysis,\n  integrating changepoint detection, smooth and shape-constrained trends,\n  and uncertainty quantification. It supports gene- and transcript-level inferences,\n  p-value aggregation for improved power, and both case-only and case-control designs.\n  It includes an interactive 'shiny' interface. The methods are described in Yates et al. (2024) <doi:10.1101/2024.12.22.630003>.  "
  },
  {
    "id": 10518,
    "package_name": "cpop",
    "title": "Detection of Multiple Changes in Slope in Univariate Time-Series",
    "description": "Detects multiple changes in slope using the CPOP dynamic programming approach of Fearnhead, Maidstone, and Letchford (2019) <doi:10.1080/10618600.2018.1512868>. This method finds the best continuous piecewise linear fit to data under a criterion that measures fit to data using the residual sum of squares, but penalizes complexity based on an L0 penalty on changes in slope. Further information regarding the use of this package with detailed examples can be found in Fearnhead and Grose (2024) <doi:10.18637/jss.v109.i07>.  ",
    "version": "1.0.8",
    "maintainer": "Daniel Grose <dan.grose@lancaster.ac.uk>",
    "author": "Daniel Grose [aut, cre],\n  Paul Fearnhead [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cpop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cpop Detection of Multiple Changes in Slope in Univariate Time-Series Detects multiple changes in slope using the CPOP dynamic programming approach of Fearnhead, Maidstone, and Letchford (2019) <doi:10.1080/10618600.2018.1512868>. This method finds the best continuous piecewise linear fit to data under a criterion that measures fit to data using the residual sum of squares, but penalizes complexity based on an L0 penalty on changes in slope. Further information regarding the use of this package with detailed examples can be found in Fearnhead and Grose (2024) <doi:10.18637/jss.v109.i07>.    "
  },
  {
    "id": 10616,
    "package_name": "cruts",
    "title": "Interface to Climatic Research Unit Time-Series Version 3.21\nData",
    "description": "Functions for reading in and manipulating CRU TS3.21: Climatic\n    Research Unit (CRU) Time-Series (TS) Version 3.21 data.",
    "version": "1.1",
    "maintainer": "Benjamin M. Taylor <benjamin.taylor.software@gmail.com>",
    "author": "Benjamin M. Taylor\n        Additional contributions\n        Bikash Parida\n        Jacob Davies",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cruts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cruts Interface to Climatic Research Unit Time-Series Version 3.21\nData Functions for reading in and manipulating CRU TS3.21: Climatic\n    Research Unit (CRU) Time-Series (TS) Version 3.21 data.  "
  },
  {
    "id": 10627,
    "package_name": "csa",
    "title": "A Cross-Scale Analysis Tool for Model-Observation Visualization\nand Integration",
    "description": "Integration of Earth system data from various sources is a challenging task. Except for their qualitative heterogeneity, different data records exist for describing similar Earth system process at different spatio-temporal scales. Data inter-comparison and validation are usually performed at a single spatial or temporal scale, which could hamper the identification of potential discrepancies in other scales. 'csa' package offers a simple, yet efficient, graphical method for synthesizing and comparing observed and modelled data across a range of spatio-temporal scales. Instead of focusing at specific scales, such as annual means or original grid resolution, we examine how their statistical properties change across spatio-temporal continuum.  ",
    "version": "0.7.1",
    "maintainer": "Yannis Markonis <imarkonis@gmail.com>",
    "author": "Yannis Markonis [aut, cre],\n  Christoforos Pappas [aut],\n  Mijael Vargas [ctb],\n  Simon Papalexiou [ctb],\n  Martin Hanel [ctb]",
    "url": "https://github.com/imarkonis/csa",
    "bug_reports": "https://github.com/imarkonis/csa/issues",
    "repository": "https://cran.r-project.org/package=csa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "csa A Cross-Scale Analysis Tool for Model-Observation Visualization\nand Integration Integration of Earth system data from various sources is a challenging task. Except for their qualitative heterogeneity, different data records exist for describing similar Earth system process at different spatio-temporal scales. Data inter-comparison and validation are usually performed at a single spatial or temporal scale, which could hamper the identification of potential discrepancies in other scales. 'csa' package offers a simple, yet efficient, graphical method for synthesizing and comparing observed and modelled data across a range of spatio-temporal scales. Instead of focusing at specific scales, such as annual means or original grid resolution, we examine how their statistical properties change across spatio-temporal continuum.    "
  },
  {
    "id": 10638,
    "package_name": "cspec",
    "title": "Complete Discrete Fourier Transform (DFT) and Periodogram",
    "description": "Calculate the predictive discrete Fourier transform, complete discrete Fourier transform, complete periodogram, and tapered complete periodogram. This algorithm is based on the preprint \"Spectral methods for small sample time series: A complete periodogram approach\" (2020) by Sourav Das, Suhasini Subba Rao, and Junho Yang.",
    "version": "0.1.2",
    "maintainer": "Junho Yang <junhoyang@stat.tamu.edu>",
    "author": "Junho Yang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cspec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cspec Complete Discrete Fourier Transform (DFT) and Periodogram Calculate the predictive discrete Fourier transform, complete discrete Fourier transform, complete periodogram, and tapered complete periodogram. This algorithm is based on the preprint \"Spectral methods for small sample time series: A complete periodogram approach\" (2020) by Sourav Das, Suhasini Subba Rao, and Junho Yang.  "
  },
  {
    "id": 10641,
    "package_name": "csquares",
    "title": "Concise Spatial Query and Representation System (c-Squares)",
    "description": "Encode and decode c-squares, from and to simple feature (sf)\n    or spatiotemporal arrays (stars) objects. Use c-squares codes to quickly\n    join or query spatial data.",
    "version": "0.1.0",
    "maintainer": "Pepijn de Vries <pepijn.devries@outlook.com>",
    "author": "Pepijn de Vries [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7961-6646>)",
    "url": "https://pepijn-devries.github.io/csquares/,\nhttps://github.com/pepijn-devries/csquares/",
    "bug_reports": "https://github.com/pepijn-devries/csquares/issues",
    "repository": "https://cran.r-project.org/package=csquares",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "csquares Concise Spatial Query and Representation System (c-Squares) Encode and decode c-squares, from and to simple feature (sf)\n    or spatiotemporal arrays (stars) objects. Use c-squares codes to quickly\n    join or query spatial data.  "
  },
  {
    "id": 10654,
    "package_name": "ctbi",
    "title": "A Procedure to Clean, Decompose and Aggregate Timeseries",
    "description": "Clean, decompose and aggregate univariate time series following the procedure \"Cyclic/trend decomposition using bin interpolation\" and the Logbox method for flagging outliers, both detailed in Ritter, F.: Technical note: A procedure to clean, decompose, and aggregate time series, Hydrol. Earth Syst. Sci., 27, 349\u2013361, <doi:10.5194/hess-27-349-2023>, 2023.",
    "version": "2.0.5",
    "maintainer": "Francois Ritter <ritter.francois@gmail.com>",
    "author": "Francois Ritter [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-6123-2145>)",
    "url": "https://github.com/fritte2/ctbi",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ctbi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ctbi A Procedure to Clean, Decompose and Aggregate Timeseries Clean, decompose and aggregate univariate time series following the procedure \"Cyclic/trend decomposition using bin interpolation\" and the Logbox method for flagging outliers, both detailed in Ritter, F.: Technical note: A procedure to clean, decompose, and aggregate time series, Hydrol. Earth Syst. Sci., 27, 349\u2013361, <doi:10.5194/hess-27-349-2023>, 2023.  "
  },
  {
    "id": 10672,
    "package_name": "ctsfeatures",
    "title": "Analyzing Categorical Time Series",
    "description": "An implementation of several functions for feature extraction in \n    categorical time series datasets. Specifically, some features related to \n    marginal distributions and serial dependence patterns can be computed. These \n    features can be used to feed clustering and classification algorithms for\n    categorical time series, among others. The package also includes some\n    interesting datasets containing biological sequences. Practitioners from a \n    broad variety of fields could benefit from the general framework provided \n    by 'ctsfeatures'.",
    "version": "1.2.2",
    "maintainer": "Angel Lopez-Oriona <oriona38@hotmail.com>",
    "author": "Angel Lopez-Oriona [aut, cre],\n  Jose A. Vilar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ctsfeatures",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ctsfeatures Analyzing Categorical Time Series An implementation of several functions for feature extraction in \n    categorical time series datasets. Specifically, some features related to \n    marginal distributions and serial dependence patterns can be computed. These \n    features can be used to feed clustering and classification algorithms for\n    categorical time series, among others. The package also includes some\n    interesting datasets containing biological sequences. Practitioners from a \n    broad variety of fields could benefit from the general framework provided \n    by 'ctsfeatures'.  "
  },
  {
    "id": 10673,
    "package_name": "ctsmTMB",
    "title": "Continuous Time Stochastic Modelling using Template Model\nBuilder",
    "description": "Perform state and parameter inference, and forecasting, in\n    stochastic state-space systems using the 'ctsmTMB' class. This class,\n    built with the 'R6' package, provides a user-friendly interface for\n    defining and handling state-space models. Inference is based on\n    maximum likelihood estimation, with derivatives efficiently computed\n    through automatic differentiation enabled by the 'TMB'/'RTMB' packages\n    (Kristensen et al., 2016) <doi:10.18637/jss.v070.i05>. The available\n    inference methods include Kalman filters, in addition to a Laplace\n    approximation-based smoothing method. For further details of these\n    methods refer to the documentation of the 'CTSMR' package\n    <https://ctsm.info/ctsmr-reference.pdf> and Thygesen (2025)\n    <doi:10.48550/arXiv.2503.21358>. Forecasting capabilities include\n    moment predictions and stochastic path simulations, both implemented\n    in 'C++' using 'Rcpp' (Eddelbuettel et al., 2018)\n    <doi:10.1080/00031305.2017.1375990> for computational efficiency.",
    "version": "1.0.1",
    "maintainer": "Phillip Vetter <pbrve@dtu.dk>",
    "author": "Phillip Vetter [aut, cre, cph],\n  Jan M\u00f8ller [ctb],\n  Uffe Thygesen [ctb],\n  Peder Bacher [ctb],\n  Henrik Madsen [ctb]",
    "url": "https://github.com/phillipbvetter/ctsmTMB",
    "bug_reports": "https://github.com/phillipbvetter/ctsmTMB/issues",
    "repository": "https://cran.r-project.org/package=ctsmTMB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ctsmTMB Continuous Time Stochastic Modelling using Template Model\nBuilder Perform state and parameter inference, and forecasting, in\n    stochastic state-space systems using the 'ctsmTMB' class. This class,\n    built with the 'R6' package, provides a user-friendly interface for\n    defining and handling state-space models. Inference is based on\n    maximum likelihood estimation, with derivatives efficiently computed\n    through automatic differentiation enabled by the 'TMB'/'RTMB' packages\n    (Kristensen et al., 2016) <doi:10.18637/jss.v070.i05>. The available\n    inference methods include Kalman filters, in addition to a Laplace\n    approximation-based smoothing method. For further details of these\n    methods refer to the documentation of the 'CTSMR' package\n    <https://ctsm.info/ctsmr-reference.pdf> and Thygesen (2025)\n    <doi:10.48550/arXiv.2503.21358>. Forecasting capabilities include\n    moment predictions and stochastic path simulations, both implemented\n    in 'C++' using 'Rcpp' (Eddelbuettel et al., 2018)\n    <doi:10.1080/00031305.2017.1375990> for computational efficiency.  "
  },
  {
    "id": 10681,
    "package_name": "cubble",
    "title": "A Vector Spatio-Temporal Data Structure for Data Analysis",
    "description": "A spatiotemperal data object in a relational data structure to separate the recording of time variant/ invariant variables. See the Journal of Statistical Software reference: <doi:10.18637/jss.v110.i07>.",
    "version": "1.0.0",
    "maintainer": "H. Sherry Zhang <huizezhangsh@gmail.com>",
    "author": "H. Sherry Zhang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7122-1463>),\n  Dianne Cook [aut] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Ursula Laa [aut] (ORCID: <https://orcid.org/0000-0002-0249-6439>),\n  Nicolas Langren\u00e9 [aut] (ORCID: <https://orcid.org/0000-0001-7601-4618>),\n  Patricia Men\u00e9ndez [aut] (ORCID:\n    <https://orcid.org/0000-0003-0701-6315>)",
    "url": "https://github.com/huizezhang-sherry/cubble,\nhttps://huizezhang-sherry.github.io/cubble/",
    "bug_reports": "https://github.com/huizezhang-sherry/cubble/issues",
    "repository": "https://cran.r-project.org/package=cubble",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cubble A Vector Spatio-Temporal Data Structure for Data Analysis A spatiotemperal data object in a relational data structure to separate the recording of time variant/ invariant variables. See the Journal of Statistical Software reference: <doi:10.18637/jss.v110.i07>.  "
  },
  {
    "id": 10760,
    "package_name": "dCovTS",
    "title": "Distance Covariance and Correlation for Time Series Analysis",
    "description": "Computing and plotting the distance covariance and correlation function of a univariate or a multivariate time series. Both versions of biased and unbiased estimators of distance covariance and correlation are provided. Test statistics for testing pairwise independence are also implemented. Some data sets are also included. References include: \n\t\t\t       a) Edelmann Dominic, Fokianos Konstantinos and Pitsillou Maria (2019). 'An Updated Literature Review of Distance Correlation and Its Applications to Time Series'. International Statistical Review, 87(2): 237--262. <doi:10.1111/insr.12294>.\n             b) Fokianos Konstantinos and Pitsillou Maria (2018). 'Testing independence for multivariate time series via the auto-distance correlation matrix'. Biometrika, 105(2): 337--352. <doi:10.1093/biomet/asx082>.\n             c) Fokianos Konstantinos and Pitsillou Maria (2017). 'Consistent testing for pairwise dependence in time series'. Technometrics, 59(2): 262--270. <doi:10.1080/00401706.2016.1156024>.\n             d) Pitsillou Maria and Fokianos Konstantinos (2016). 'dCovTS: Distance Covariance/Correlation for Time Series'. R Journal, 8(2):324-340. <doi:10.32614/RJ-2016-049>.",
    "version": "1.4",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "author": "Michail Tsagris [aut, cre],\n  Maria Pitsillou [aut, cph],\n  Konstantinos Fokianos [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dCovTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dCovTS Distance Covariance and Correlation for Time Series Analysis Computing and plotting the distance covariance and correlation function of a univariate or a multivariate time series. Both versions of biased and unbiased estimators of distance covariance and correlation are provided. Test statistics for testing pairwise independence are also implemented. Some data sets are also included. References include: \n\t\t\t       a) Edelmann Dominic, Fokianos Konstantinos and Pitsillou Maria (2019). 'An Updated Literature Review of Distance Correlation and Its Applications to Time Series'. International Statistical Review, 87(2): 237--262. <doi:10.1111/insr.12294>.\n             b) Fokianos Konstantinos and Pitsillou Maria (2018). 'Testing independence for multivariate time series via the auto-distance correlation matrix'. Biometrika, 105(2): 337--352. <doi:10.1093/biomet/asx082>.\n             c) Fokianos Konstantinos and Pitsillou Maria (2017). 'Consistent testing for pairwise dependence in time series'. Technometrics, 59(2): 262--270. <doi:10.1080/00401706.2016.1156024>.\n             d) Pitsillou Maria and Fokianos Konstantinos (2016). 'dCovTS: Distance Covariance/Correlation for Time Series'. R Journal, 8(2):324-340. <doi:10.32614/RJ-2016-049>.  "
  },
  {
    "id": 10763,
    "package_name": "dLagM",
    "title": "Time Series Regression Models with Distributed Lag Models",
    "description": "Provides time series regression models with one predictor using finite distributed lag models, polynomial (Almon) distributed lag models, geometric distributed lag models with Koyck transformation, and autoregressive distributed lag models. It also consists of functions for computation of h-step ahead forecasts from these models. See Demirhan (2020)(<doi:10.1371/journal.pone.0228812>) and Baltagi (2011)(<doi:10.1007/978-3-642-20059-5>) for more information.",
    "version": "1.1.13",
    "maintainer": "Haydar Demirhan <haydar.demirhan@rmit.edu.au>",
    "author": "Haydar Demirhan [aut, cre, cph] (<https://orcid.org/0000-0002-8565-4710>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dLagM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dLagM Time Series Regression Models with Distributed Lag Models Provides time series regression models with one predictor using finite distributed lag models, polynomial (Almon) distributed lag models, geometric distributed lag models with Koyck transformation, and autoregressive distributed lag models. It also consists of functions for computation of h-step ahead forecasts from these models. See Demirhan (2020)(<doi:10.1371/journal.pone.0228812>) and Baltagi (2011)(<doi:10.1007/978-3-642-20059-5>) for more information.  "
  },
  {
    "id": 10791,
    "package_name": "daltoolbox",
    "title": "Leveraging Experiment Lines to Data Analytics",
    "description": "The natural increase in the complexity of current research experiments and data demands better tools to enhance productivity in Data Analytics. The package is a framework designed to address the modern challenges in data analytics workflows. The package is inspired by Experiment Line concepts. It aims to provide seamless support for users in developing their data mining workflows by offering a uniform data model and method API. It enables the integration of various data mining activities, including data preprocessing, classification, regression, clustering, and time series prediction. It also offers options for hyper-parameter tuning and supports integration with existing libraries and languages. Overall, the package provides researchers with a comprehensive set of functionalities for data science, promoting ease of use, extensibility, and integration with various tools and libraries. Information on Experiment Line is based on Ogasawara et al. (2009) <doi:10.1007/978-3-642-02279-1_20>.",
    "version": "1.2.747",
    "maintainer": "Eduardo Ogasawara <eogasawara@ieee.org>",
    "author": "Eduardo Ogasawara [aut, ths, cre] (ORCID:\n    <https://orcid.org/0000-0002-0466-0626>),\n  Ana Carolina S\u00e1 [aut],\n  Antonio Castro [aut],\n  Caio Santos [aut],\n  Diego Carvalho [ctb],\n  Diego Salles [aut],\n  Eduardo Bezerra [ctb],\n  Esther Pacitti [ctb],\n  Fabio Porto [ctb],\n  Janio Lima [aut],\n  Lucas Tavares [aut],\n  Rafaelli Coutinho [ctb],\n  Rebecca Salles [aut],\n  Vinicius Saidy [aut],\n  CEFET/RJ [cph]",
    "url": "https://cefet-rj-dal.github.io/daltoolbox/,\nhttps://github.com/cefet-rj-dal/daltoolbox",
    "bug_reports": "https://github.com/cefet-rj-dal/daltoolbox/issues",
    "repository": "https://cran.r-project.org/package=daltoolbox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "daltoolbox Leveraging Experiment Lines to Data Analytics The natural increase in the complexity of current research experiments and data demands better tools to enhance productivity in Data Analytics. The package is a framework designed to address the modern challenges in data analytics workflows. The package is inspired by Experiment Line concepts. It aims to provide seamless support for users in developing their data mining workflows by offering a uniform data model and method API. It enables the integration of various data mining activities, including data preprocessing, classification, regression, clustering, and time series prediction. It also offers options for hyper-parameter tuning and supports integration with existing libraries and languages. Overall, the package provides researchers with a comprehensive set of functionalities for data science, promoting ease of use, extensibility, and integration with various tools and libraries. Information on Experiment Line is based on Ogasawara et al. (2009) <doi:10.1007/978-3-642-02279-1_20>.  "
  },
  {
    "id": 10843,
    "package_name": "dataprep",
    "title": "Efficient and Flexible Data Preprocessing Tools",
    "description": "Efficiently and flexibly preprocess data using a set of data filtering, deletion, and interpolation tools.\n    These data preprocessing methods are developed based on the principles of completeness, accuracy, threshold method, and linear interpolation and through the setting of constraint conditions, time completion & recovery, and fast & efficient calculation and grouping.\n    Key preprocessing steps include deletions of variables and observations, outlier removal, and missing values (NA) interpolation, which are dependent on the incomplete and dispersed degrees of raw data.\n    They clean data more accurately, keep more samples, and add no outliers after interpolation, compared with ordinary methods.\n    Auto-identification of consecutive NA via run-length based grouping is used in observation deletion, outlier removal, and NA interpolation;\n    thus, new outliers are not generated in interpolation. Conditional extremum is proposed to realize point-by-point weighed outlier removal that saves non-outliers from being removed.\n    Plus, time series interpolation with values to refer to within short periods further ensures reliable interpolation.\n    These methods are based on and improved from the reference: Liang, C.-S., Wu, H., Li, H.-Y., Zhang, Q., Li, Z. & He, K.-B. (2020) <doi:10.1016/j.scitotenv.2020.140923>.",
    "version": "0.1.5",
    "maintainer": "Chun-Sheng Liang <liangchunsheng@lzu.edu.cn>",
    "author": "Chun-Sheng Liang <liangchunsheng@lzu.edu.cn>, Hao Wu, Hai-Yan Li, Qiang Zhang, Zhanqing Li, Ke-Bin He, Lanzhou University, Tsinghua University",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dataprep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dataprep Efficient and Flexible Data Preprocessing Tools Efficiently and flexibly preprocess data using a set of data filtering, deletion, and interpolation tools.\n    These data preprocessing methods are developed based on the principles of completeness, accuracy, threshold method, and linear interpolation and through the setting of constraint conditions, time completion & recovery, and fast & efficient calculation and grouping.\n    Key preprocessing steps include deletions of variables and observations, outlier removal, and missing values (NA) interpolation, which are dependent on the incomplete and dispersed degrees of raw data.\n    They clean data more accurately, keep more samples, and add no outliers after interpolation, compared with ordinary methods.\n    Auto-identification of consecutive NA via run-length based grouping is used in observation deletion, outlier removal, and NA interpolation;\n    thus, new outliers are not generated in interpolation. Conditional extremum is proposed to realize point-by-point weighed outlier removal that saves non-outliers from being removed.\n    Plus, time series interpolation with values to refer to within short periods further ensures reliable interpolation.\n    These methods are based on and improved from the reference: Liang, C.-S., Wu, H., Li, H.-Y., Zhang, Q., Li, Z. & He, K.-B. (2020) <doi:10.1016/j.scitotenv.2020.140923>.  "
  },
  {
    "id": 10851,
    "package_name": "dataseries",
    "title": "Switzerland's Data Series in One Place",
    "description": "Download and import time series from <http://www.dataseries.org>, a comprehensive and up-to-date collection of open data from Switzerland.",
    "version": "0.2.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax",
    "url": "http://www.dataseries.org",
    "bug_reports": "https://github.com/christophsax/dataseries",
    "repository": "https://cran.r-project.org/package=dataseries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dataseries Switzerland's Data Series in One Place Download and import time series from <http://www.dataseries.org>, a comprehensive and up-to-date collection of open data from Switzerland.  "
  },
  {
    "id": 10890,
    "package_name": "dbnR",
    "title": "Dynamic Bayesian Network Learning and Inference",
    "description": "Learning and inference over dynamic Bayesian networks of arbitrary \n    Markovian order. Extends some of the functionality offered by the 'bnlearn' \n    package to learn the networks from data and perform exact inference. \n    It offers three structure learning algorithms for dynamic Bayesian networks:\n    Trabelsi G. (2013) <doi:10.1007/978-3-642-41398-8_34>, Santos F.P. and Maciel C.D. (2014)\n    <doi:10.1109/BRC.2014.6880957>, Quesada D., Bielza C. and Larra\u00f1aga P. (2021)\n    <doi:10.1007/978-3-030-86271-8_14>. It also offers the possibility to perform \n    forecasts of arbitrary length. A tool for visualizing the structure of the \n    net is also provided via the 'visNetwork' package.",
    "version": "0.7.9",
    "maintainer": "David Quesada <dkesada@gmail.com>",
    "author": "David Quesada [aut, cre],\n  Gabriel Valverde [ctb]",
    "url": "https://github.com/dkesada/dbnR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dbnR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dbnR Dynamic Bayesian Network Learning and Inference Learning and inference over dynamic Bayesian networks of arbitrary \n    Markovian order. Extends some of the functionality offered by the 'bnlearn' \n    package to learn the networks from data and perform exact inference. \n    It offers three structure learning algorithms for dynamic Bayesian networks:\n    Trabelsi G. (2013) <doi:10.1007/978-3-642-41398-8_34>, Santos F.P. and Maciel C.D. (2014)\n    <doi:10.1109/BRC.2014.6880957>, Quesada D., Bielza C. and Larra\u00f1aga P. (2021)\n    <doi:10.1007/978-3-030-86271-8_14>. It also offers the possibility to perform \n    forecasts of arbitrary length. A tool for visualizing the structure of the \n    net is also provided via the 'visNetwork' package.  "
  },
  {
    "id": 10891,
    "package_name": "dbnlearn",
    "title": "Dynamic Bayesian Network Structure Learning, Parameter Learning\nand Forecasting",
    "description": "It allows to learn the structure of univariate time series, learning parameters and forecasting. \n             Implements a model of Dynamic Bayesian Networks with temporal windows, \n             with collections of linear regressors for Gaussian nodes, \n             based on the introductory texts of Korb and Nicholson (2010) <doi:10.1201/b10391> and \n             Nagarajan, Scutari and L\u00e8bre (2013) <doi:10.1007/978-1-4614-6446-4>.",
    "version": "0.1.0",
    "maintainer": "Robson Fernandes <robson.fernandes@usp.br>",
    "author": "Robson Fernandes [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dbnlearn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dbnlearn Dynamic Bayesian Network Structure Learning, Parameter Learning\nand Forecasting It allows to learn the structure of univariate time series, learning parameters and forecasting. \n             Implements a model of Dynamic Bayesian Networks with temporal windows, \n             with collections of linear regressors for Gaussian nodes, \n             based on the introductory texts of Korb and Nicholson (2010) <doi:10.1201/b10391> and \n             Nagarajan, Scutari and L\u00e8bre (2013) <doi:10.1007/978-1-4614-6446-4>.  "
  },
  {
    "id": 10932,
    "package_name": "deFit",
    "title": "Fitting Differential Equations to Time Series Data",
    "description": "Use numerical optimization to fit ordinary differential equations (ODEs) to time series data to examine the dynamic relationships between variables or the characteristics of a dynamical system. It can now be used to estimate the parameters of ODEs up to second order, and can also apply to multilevel systems. See <https://github.com/yueqinhu/defit> for details.",
    "version": "0.3.0",
    "maintainer": "Yueqin Hu <yueqinhu@bnu.edu.cn>",
    "author": "Yueqin Hu [aut, cre],\n  Qingshan Liu [aut],\n  Minglan Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=deFit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deFit Fitting Differential Equations to Time Series Data Use numerical optimization to fit ordinary differential equations (ODEs) to time series data to examine the dynamic relationships between variables or the characteristics of a dynamical system. It can now be used to estimate the parameters of ODEs up to second order, and can also apply to multilevel systems. See <https://github.com/yueqinhu/defit> for details.  "
  },
  {
    "id": 10949,
    "package_name": "decompML",
    "title": "Decomposition Based Machine Learning Model",
    "description": "The hybrid model is a highly effective forecasting approach that integrates decomposition techniques with machine learning to enhance time series prediction accuracy. Each decomposition technique breaks down a time series into multiple intrinsic mode functions (IMFs), which are then individually modeled and forecasted using machine learning algorithms. The final forecast is obtained by aggregating the predictions of all IMFs, producing an ensemble output for the time series. The performance of the developed models is evaluated using international monthly maize price data, assessed through metrics such as root mean squared error (RMSE), mean absolute percentage error (MAPE), and mean absolute error (MAE). For method details see Choudhary, K. et al. (2023). <https://ssca.org.in/media/14_SA44052022_R3_SA_21032023_Girish_Jha_FINAL_Finally.pdf>. ",
    "version": "0.1.1",
    "maintainer": "Kapil Choudhary <kapiliasri@gmail.com>",
    "author": "Girish Kumar Jha [aut, ctb],\n  Kapil Choudhary [aut, cre],\n  Rajender Parsad [ctb],\n  Ronit Jaiswal [ctb],\n  Rajeev Ranjan Kumar [ctb],\n  P Venkatesh [ctb],\n  Dwijesh Chandra Mishra [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=decompML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "decompML Decomposition Based Machine Learning Model The hybrid model is a highly effective forecasting approach that integrates decomposition techniques with machine learning to enhance time series prediction accuracy. Each decomposition technique breaks down a time series into multiple intrinsic mode functions (IMFs), which are then individually modeled and forecasted using machine learning algorithms. The final forecast is obtained by aggregating the predictions of all IMFs, producing an ensemble output for the time series. The performance of the developed models is evaluated using international monthly maize price data, assessed through metrics such as root mean squared error (RMSE), mean absolute percentage error (MAPE), and mean absolute error (MAE). For method details see Choudhary, K. et al. (2023). <https://ssca.org.in/media/14_SA44052022_R3_SA_21032023_Girish_Jha_FINAL_Finally.pdf>.   "
  },
  {
    "id": 10950,
    "package_name": "decomposedPSF",
    "title": "Time Series Prediction with PSF and Decomposition Methods (EMD\nand EEMD)",
    "description": "Predict future values with hybrid combinations of Pattern Sequence based\n        Forecasting (PSF), Autoregressive Integrated Moving Average (ARIMA), Empirical Mode\n        Decomposition (EMD) and Ensemble Empirical Mode Decomposition (EEMD) methods based\n        hybrid methods.",
    "version": "0.2",
    "maintainer": "Neeraj Bokde <neerajdhanraj@gmail.com>",
    "author": "Neeraj Bokde",
    "url": "https://www.neerajbokde.in/software/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=decomposedPSF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "decomposedPSF Time Series Prediction with PSF and Decomposition Methods (EMD\nand EEMD) Predict future values with hybrid combinations of Pattern Sequence based\n        Forecasting (PSF), Autoregressive Integrated Moving Average (ARIMA), Empirical Mode\n        Decomposition (EMD) and Ensemble Empirical Mode Decomposition (EEMD) methods based\n        hybrid methods.  "
  },
  {
    "id": 10956,
    "package_name": "decp",
    "title": "Complete Change Point Analysis",
    "description": "Provides a comprehensive approach for identifying and estimating change points in multivariate time series through various statistical methods. Implements the multiple change point detection methodology from Ryan & Killick (2023) <doi:10.1080/00401706.2023.2183261> and a novel estimation methodology from Fotopoulos et al. (2023) <doi:10.1007/s00362-023-01495-0> generalized to fit the detection methodologies. Performs both detection and estimation of change points, providing visualization and summary information of the estimation process for each detected change point.",
    "version": "0.1.2",
    "maintainer": "Vasileios Pavlopoulos <vasileios.pavlopoulos@uah.edu>",
    "author": "Vasileios Pavlopoulos [cre, aut],\n  Hieu Pham [aut, ctb],\n  Paras Bhatt [aut, ctb],\n  Yi Tan [aut, ctb],\n  Ravi Patnayakuni [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=decp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "decp Complete Change Point Analysis Provides a comprehensive approach for identifying and estimating change points in multivariate time series through various statistical methods. Implements the multiple change point detection methodology from Ryan & Killick (2023) <doi:10.1080/00401706.2023.2183261> and a novel estimation methodology from Fotopoulos et al. (2023) <doi:10.1007/s00362-023-01495-0> generalized to fit the detection methodologies. Performs both detection and estimation of change points, providing visualization and summary information of the estimation process for each detected change point.  "
  },
  {
    "id": 11002,
    "package_name": "demography",
    "title": "Forecasting Mortality, Fertility, Migration and Population Data",
    "description": "Functions for demographic analysis including lifetable\n        calculations; Lee-Carter modelling; functional data analysis of\n        mortality rates, fertility rates, net migration numbers; and\n        stochastic population forecasting.",
    "version": "2.0.1",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  Heather Booth [ctb] (ORCID: <https://orcid.org/0000-0002-8356-0534>),\n  Leonie Tickle [ctb] (ORCID: <https://orcid.org/0000-0002-6612-2401>),\n  John Maindonald [ctb],\n  Simon Wood [ctb],\n  R Core Team [ctb]",
    "url": "https://pkg.robjhyndman.com/demography/,\nhttps://github.com/robjhyndman/demography",
    "bug_reports": "https://github.com/robjhyndman/demography/issues",
    "repository": "https://cran.r-project.org/package=demography",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "demography Forecasting Mortality, Fertility, Migration and Population Data Functions for demographic analysis including lifetable\n        calculations; Lee-Carter modelling; functional data analysis of\n        mortality rates, fertility rates, net migration numbers; and\n        stochastic population forecasting.  "
  },
  {
    "id": 11004,
    "package_name": "dendRoAnalyst",
    "title": "A Tool for Processing and Analyzing Dendrometer Data",
    "description": "There are various functions for managing and cleaning data before the application of different approaches. This includes identifying and erasing sudden jumps in dendrometer data not related to environmental change, identifying the time gaps of recordings, and changing the temporal resolution of data to different frequencies. Furthermore, the package calculates daily statistics of dendrometer data, including the daily amplitude of tree growth. Various approaches can be applied to separate radial growth from daily cyclic shrinkage and expansion due to uptake and loss of stem water. In addition, it identifies periods of consecutive days with user-defined climatic conditions in daily meteorological data, then check what trees are doing during that period. ",
    "version": "0.1.5",
    "maintainer": "Sugam Aryal <sugam.aryal@fau.de>",
    "author": "Sugam Aryal [aut, cre, dtc],\n  Martin H\u00e4usser [aut],\n  Jussi Grie\u00dfinger [aut],\n  Ze-Xin Fan [aut],\n  Achim Br\u00e4uning [aut, dgs]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dendRoAnalyst",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dendRoAnalyst A Tool for Processing and Analyzing Dendrometer Data There are various functions for managing and cleaning data before the application of different approaches. This includes identifying and erasing sudden jumps in dendrometer data not related to environmental change, identifying the time gaps of recordings, and changing the temporal resolution of data to different frequencies. Furthermore, the package calculates daily statistics of dendrometer data, including the daily amplitude of tree growth. Various approaches can be applied to separate radial growth from daily cyclic shrinkage and expansion due to uptake and loss of stem water. In addition, it identifies periods of consecutive days with user-defined climatic conditions in daily meteorological data, then check what trees are doing during that period.   "
  },
  {
    "id": 11031,
    "package_name": "depmixS4",
    "title": "Dependent Mixture Models - Hidden Markov Models of GLMs and\nOther Distributions in S4",
    "description": "Fits latent (hidden) Markov models on mixed categorical and continuous (time series) data, otherwise known as dependent mixture models, see Visser & Speekenbrink (2010, <DOI:10.18637/jss.v036.i07>).",
    "version": "1.5-1",
    "maintainer": "Ingmar Visser <i.visser@uva.nl>",
    "author": "Ingmar Visser [aut, cre],\n  Maarten Speekenbrink [aut]",
    "url": "https://depmix.github.io/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=depmixS4",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "depmixS4 Dependent Mixture Models - Hidden Markov Models of GLMs and\nOther Distributions in S4 Fits latent (hidden) Markov models on mixed categorical and continuous (time series) data, otherwise known as dependent mixture models, see Visser & Speekenbrink (2010, <DOI:10.18637/jss.v036.i07>).  "
  },
  {
    "id": 11038,
    "package_name": "descomponer",
    "title": "Seasonal Adjustment by Frequency Analysis",
    "description": "Decompose a time series into seasonal, trend and irregular components using transformations to amplitude-frequency domain.",
    "version": "1.6",
    "maintainer": "Francisco Parra  <parra_fj@cantabria.es>",
    "author": "Francisco Parra  <parra_fj@cantabria.es>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=descomponer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "descomponer Seasonal Adjustment by Frequency Analysis Decompose a time series into seasonal, trend and irregular components using transformations to amplitude-frequency domain.  "
  },
  {
    "id": 11050,
    "package_name": "deseats",
    "title": "Data-Driven Locally Weighted Regression for Trend and\nSeasonality in TS",
    "description": "Various methods for the identification of trend and seasonal\n  components in time series (TS) are provided. Among them is a data-driven locally\n  weighted regression approach with automatically selected bandwidth for\n  equidistant short-memory time series. The approach is a\n  combination / extension of the algorithms by\n  Feng (2013) <doi:10.1080/02664763.2012.740626> and Feng, Y., Gries, T.,\n  and Fritz, M. (2020) <doi:10.1080/10485252.2020.1759598> and a brief\n  description of this new method is provided in the package documentation.\n  Furthermore, the package allows its users to apply the base model of the\n  Berlin procedure, version 4.1, as described in Speth (2004) <https://www.destatis.de/DE/Methoden/Saisonbereinigung/BV41-methodenbericht-Heft3_2004.pdf?__blob=publicationFile>.\n  Permission to include this procedure was kindly provided by the Federal\n  Statistical Office of Germany.",
    "version": "1.1.1",
    "maintainer": "Dominik Schulz <dominik.schulz@uni-paderborn.de>",
    "author": "Yuanhua Feng [aut] (Paderborn University, Germany),\n  Dominik Schulz [aut, cre] (Paderborn University, Germany)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=deseats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deseats Data-Driven Locally Weighted Regression for Trend and\nSeasonality in TS Various methods for the identification of trend and seasonal\n  components in time series (TS) are provided. Among them is a data-driven locally\n  weighted regression approach with automatically selected bandwidth for\n  equidistant short-memory time series. The approach is a\n  combination / extension of the algorithms by\n  Feng (2013) <doi:10.1080/02664763.2012.740626> and Feng, Y., Gries, T.,\n  and Fritz, M. (2020) <doi:10.1080/10485252.2020.1759598> and a brief\n  description of this new method is provided in the package documentation.\n  Furthermore, the package allows its users to apply the base model of the\n  Berlin procedure, version 4.1, as described in Speth (2004) <https://www.destatis.de/DE/Methoden/Saisonbereinigung/BV41-methodenbericht-Heft3_2004.pdf?__blob=publicationFile>.\n  Permission to include this procedure was kindly provided by the Federal\n  Statistical Office of Germany.  "
  },
  {
    "id": 11058,
    "package_name": "desla",
    "title": "Desparsified Lasso Inference for Time Series",
    "description": "Calculates the desparsified lasso as originally introduced in van de Geer et al. (2014) <doi:10.1214/14-AOS1221>, and provides inference suitable for high-dimensional time series, based on the long run covariance estimator in Adamek et al. (2020) <arXiv:2007.10952>. Also estimates high-dimensional local projections by the desparsified lasso, as described in Adamek et al. (2022) <arXiv:2209.03218>.",
    "version": "0.3.0",
    "maintainer": "Robert Adamek <robertadamek94@gmail.com>",
    "author": "Robert Adamek [cre, aut],\n  Stephan Smeekes [aut],\n  Ines Wilms [aut]",
    "url": "https://github.com/RobertAdamek/desla",
    "bug_reports": "https://github.com/RobertAdamek/desla/issues",
    "repository": "https://cran.r-project.org/package=desla",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "desla Desparsified Lasso Inference for Time Series Calculates the desparsified lasso as originally introduced in van de Geer et al. (2014) <doi:10.1214/14-AOS1221>, and provides inference suitable for high-dimensional time series, based on the long run covariance estimator in Adamek et al. (2020) <arXiv:2007.10952>. Also estimates high-dimensional local projections by the desparsified lasso, as described in Adamek et al. (2022) <arXiv:2209.03218>.  "
  },
  {
    "id": 11063,
    "package_name": "detectR",
    "title": "Change Point Detection",
    "description": "Time series analysis of network connectivity. Detects and visualizes change points between networks.\n    Methods included in the package are discussed in depth in Baek, C., Gates, K. M., Leinwand, B., Pipiras, V. (2021)\n    \"Two sample tests for high-dimensional auto-covariances\" <doi:10.1016/j.csda.2020.107067>\n    and Baek, C., Gampe, M., Leinwand B., Lindquist K., Hopfinger J. and Gates K. (2023)\n    \u201cDetecting functional connectivity changes in fMRI data\u201d <doi:10.1007/s11336-023-09908-7>.",
    "version": "0.3.0",
    "maintainer": "Changryong Baek <crbaek@skku.edu>",
    "author": "Changryong Baek [aut, cre],\n  Mattew Gampe [aut],\n  Kathleen M. Gates [aut],\n  Seok-Oh Jeong [aut],\n  Vladas Pipiras [aut]",
    "url": "https://github.com/crbaek/detectR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=detectR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "detectR Change Point Detection Time series analysis of network connectivity. Detects and visualizes change points between networks.\n    Methods included in the package are discussed in depth in Baek, C., Gates, K. M., Leinwand, B., Pipiras, V. (2021)\n    \"Two sample tests for high-dimensional auto-covariances\" <doi:10.1016/j.csda.2020.107067>\n    and Baek, C., Gampe, M., Leinwand B., Lindquist K., Hopfinger J. and Gates K. (2023)\n    \u201cDetecting functional connectivity changes in fMRI data\u201d <doi:10.1007/s11336-023-09908-7>.  "
  },
  {
    "id": 11072,
    "package_name": "detrendeR",
    "title": "A Graphical User Interface (GUI) to Visualize and Analyze\nDendrochronological Data",
    "description": "A Graphical User Interface (GUI) to import, save, detrend and \n    perform standard tree-ring analyses. The interactive detrending allows the user to check how\n    well the detrending curve fits each time-series and change it when needed.",
    "version": "1.0.5",
    "maintainer": "Filipe Campelo <fcampelo@ci.uc.pt>",
    "author": "Filipe Campelo",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=detrendeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "detrendeR A Graphical User Interface (GUI) to Visualize and Analyze\nDendrochronological Data A Graphical User Interface (GUI) to import, save, detrend and \n    perform standard tree-ring analyses. The interactive detrending allows the user to check how\n    well the detrending curve fits each time-series and change it when needed.  "
  },
  {
    "id": 11090,
    "package_name": "dfms",
    "title": "Dynamic Factor Models",
    "description": "Efficient estimation of Dynamic Factor Models using the Expectation Maximization (EM) algorithm \n  or Two-Step (2S) estimation, supporting datasets with missing data. Factors are assumed to follow a stationary VAR \n  process of order p. The estimation options follow advances in the econometric literature: either running the Kalman \n  Filter and Smoother once with initial values from PCA - 2S estimation as in Doz, Giannone and Reichlin (2011) \n  <doi:10.1016/j.jeconom.2011.02.012> - or via iterated Kalman Filtering and Smoothing until EM convergence - following \n  Doz, Giannone and Reichlin (2012) <doi:10.1162/REST_a_00225> - or using the adapted EM algorithm of Banbura and \n  Modugno (2014) <doi:10.1002/jae.2306>, allowing arbitrary patterns of missing data. The implementation makes heavy \n  use of the 'Armadillo' 'C++' library and the 'collapse' package, providing for particularly speedy estimation. \n  A comprehensive set of methods supports interpretation and visualization of the model as well as forecasting. \n  Information criteria to choose the number of factors are also provided - following Bai and Ng (2002) \n  <doi:10.1111/1468-0262.00273>.",
    "version": "0.3.2",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre],\n  Rytis Bagdziunas [aut],\n  Santtu Tikka [rev],\n  Eli Holmes [rev]",
    "url": "https://sebkrantz.github.io/dfms/,\nhttps://github.com/SebKrantz/dfms",
    "bug_reports": "https://github.com/SebKrantz/dfms/issues",
    "repository": "https://cran.r-project.org/package=dfms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dfms Dynamic Factor Models Efficient estimation of Dynamic Factor Models using the Expectation Maximization (EM) algorithm \n  or Two-Step (2S) estimation, supporting datasets with missing data. Factors are assumed to follow a stationary VAR \n  process of order p. The estimation options follow advances in the econometric literature: either running the Kalman \n  Filter and Smoother once with initial values from PCA - 2S estimation as in Doz, Giannone and Reichlin (2011) \n  <doi:10.1016/j.jeconom.2011.02.012> - or via iterated Kalman Filtering and Smoothing until EM convergence - following \n  Doz, Giannone and Reichlin (2012) <doi:10.1162/REST_a_00225> - or using the adapted EM algorithm of Banbura and \n  Modugno (2014) <doi:10.1002/jae.2306>, allowing arbitrary patterns of missing data. The implementation makes heavy \n  use of the 'Armadillo' 'C++' library and the 'collapse' package, providing for particularly speedy estimation. \n  A comprehensive set of methods supports interpretation and visualization of the model as well as forecasting. \n  Information criteria to choose the number of factors are also provided - following Bai and Ng (2002) \n  <doi:10.1111/1468-0262.00273>.  "
  },
  {
    "id": 11131,
    "package_name": "diegr",
    "title": "Dynamic and Interactive EEG Graphics",
    "description": "Allows to visualize high-density electroencephalography (HD-EEG) data through interactive plots and animations, enabling exploratory and communicative analysis of temporal-spatial brain signals. Funder: Masaryk University (Grant No. MUNI/A/1457/2023).",
    "version": "0.1.0",
    "maintainer": "Zde\u0148ka Ger\u0161lov\u00e1 <gerslovaz@math.muni.cz>",
    "author": "Zde\u0148ka Ger\u0161lov\u00e1 [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1973-0479>),\n  Stanislav Katina [rev] (ORCID: <https://orcid.org/0000-0002-3256-5482>,\n    Reviewer and Supervisor),\n  Martin Lamo\u0161 [ctb] (Provided anonymized data from the project AZV\n    NU21-04-0044)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=diegr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diegr Dynamic and Interactive EEG Graphics Allows to visualize high-density electroencephalography (HD-EEG) data through interactive plots and animations, enabling exploratory and communicative analysis of temporal-spatial brain signals. Funder: Masaryk University (Grant No. MUNI/A/1457/2023).  "
  },
  {
    "id": 11150,
    "package_name": "diffusion",
    "title": "Forecast the Diffusion of New Products",
    "description": "Various diffusion models to forecast new product growth. Currently\n    the package contains Bass, Gompertz, Gamma/Shifted Gompertz and Weibull curves. See\n    Meade and Islam (2006) <doi:10.1016/j.ijforecast.2006.01.005>.",
    "version": "0.4.0",
    "maintainer": "Oliver Schaer <info@oliverschaer.ch>",
    "author": "Oliver Schaer [aut, cre] (Assistant Professor, LeBow College of\n    Business, Drexel University, USA),\n  Nikolaos Kourentzes [aut] (Professor of Predictive Analytics, School of\n    Informatics, Skoevde University, Sweden),\n  Ivan Svetunkov [aut] (Lecturer at Centre for Marketing Analytics and\n    Forecasting, Lancaster University, UK)",
    "url": "https://github.com/mamut86/diffusion",
    "bug_reports": "https://github.com/mamut86/diffusion/issues",
    "repository": "https://cran.r-project.org/package=diffusion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diffusion Forecast the Diffusion of New Products Various diffusion models to forecast new product growth. Currently\n    the package contains Bass, Gompertz, Gamma/Shifted Gompertz and Weibull curves. See\n    Meade and Islam (2006) <doi:10.1016/j.ijforecast.2006.01.005>.  "
  },
  {
    "id": 11177,
    "package_name": "disagg2",
    "title": "Support Functions for Time Series Analysis Book",
    "description": "Contains the support functions for the Time Series Analysis book.\n\t     We present a function to calculate MSE and MAE for inputs\n\t     of actual and forecast values.  We also have the code for\n\t     disaggregation as found in Wei and Stram\n\t     (1990, <doi:10.1111/j.2517-6161.1990.tb01799.x>),\n\t     and Hodgess and Wei (1996, \"Temporal Disaggregation of Time\n\t     Series\").",
    "version": "0.1.0",
    "maintainer": "Erin Hodgess <erinm.hodgess@gmail.com>",
    "author": "Erin Hodgess [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=disagg2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "disagg2 Support Functions for Time Series Analysis Book Contains the support functions for the Time Series Analysis book.\n\t     We present a function to calculate MSE and MAE for inputs\n\t     of actual and forecast values.  We also have the code for\n\t     disaggregation as found in Wei and Stram\n\t     (1990, <doi:10.1111/j.2517-6161.1990.tb01799.x>),\n\t     and Hodgess and Wei (1996, \"Temporal Disaggregation of Time\n\t     Series\").  "
  },
  {
    "id": 11178,
    "package_name": "disaggR",
    "title": "Two-Steps Benchmarks for Time Series Disaggregation",
    "description": "The twoStepsBenchmark() and threeRuleSmooth() functions allow you to \n    disaggregate a low-frequency time series with higher frequency time series, \n    using the French National Accounts methodology. The aggregated sum of the \n    resulting time series is strictly equal to the low-frequency time series within the \n    benchmarking window. Typically, the low-frequency time series is an annual one, \n    unknown for the last year, and the high frequency one is either quarterly or \n    monthly. See \"Methodology of quarterly national accounts\", Insee M\u00e9thodes \n    N\u00b0126, by Insee (2012, ISBN:978-2-11-068613-8, <https://www.insee.fr/en/information/2579410>).",
    "version": "1.0.5.4",
    "maintainer": "Pauline Meinzel <pauline.meinzel@insee.fr>",
    "author": "Arnaud Feldmann [aut] (ORCID: <https://orcid.org/0000-0003-0109-7505>,\n    Author and maintener of the package until the version 1.0.1),\n  Pauline Meinzel [cre],\n  Thomas Laurent [ctb] (Maintener of the package from 1.0.2 to 1.0.5.2),\n  Franck Arnaud [ctb] (barplot base graphics method for the mts class),\n  Institut national de la statistique et des \u00e9tudes \u00e9conomiques [cph]\n    (https://www.insee.fr/)",
    "url": "https://inseefr.github.io/disaggR/",
    "bug_reports": "https://github.com/InseeFr/disaggR/issues",
    "repository": "https://cran.r-project.org/package=disaggR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "disaggR Two-Steps Benchmarks for Time Series Disaggregation The twoStepsBenchmark() and threeRuleSmooth() functions allow you to \n    disaggregate a low-frequency time series with higher frequency time series, \n    using the French National Accounts methodology. The aggregated sum of the \n    resulting time series is strictly equal to the low-frequency time series within the \n    benchmarking window. Typically, the low-frequency time series is an annual one, \n    unknown for the last year, and the high frequency one is either quarterly or \n    monthly. See \"Methodology of quarterly national accounts\", Insee M\u00e9thodes \n    N\u00b0126, by Insee (2012, ISBN:978-2-11-068613-8, <https://www.insee.fr/en/information/2579410>).  "
  },
  {
    "id": 11212,
    "package_name": "dispositionEffect",
    "title": "Analysis of Disposition Effect on Financial Portfolios",
    "description": "Evaluate the presence of disposition effect and others irrational\n    investor's behaviors based solely on investor's transactions and financial\n    market data. Experimental data can also be used to perform the analysis.  \n    Four different methodologies are implemented to account for the different\n    nature of human behaviors on financial markets.  \n    Novel analyses such as portfolio driven and time series disposition effect\n    are also allowed.",
    "version": "1.0.1",
    "maintainer": "Marco Zanotti <zanottimarco17@gmail.com>",
    "author": "Lorenzo Mazzucchelli [aut],\n  Marco Zanotti [aut, cre]",
    "url": "https://marcozanotti.github.io/dispositionEffect/,\nhttps://github.com/marcozanotti/dispositionEffect",
    "bug_reports": "https://github.com/marcozanotti/dispositionEffect/issues",
    "repository": "https://cran.r-project.org/package=dispositionEffect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dispositionEffect Analysis of Disposition Effect on Financial Portfolios Evaluate the presence of disposition effect and others irrational\n    investor's behaviors based solely on investor's transactions and financial\n    market data. Experimental data can also be used to perform the analysis.  \n    Four different methodologies are implemented to account for the different\n    nature of human behaviors on financial markets.  \n    Novel analyses such as portfolio driven and time series disposition effect\n    are also allowed.  "
  },
  {
    "id": 11221,
    "package_name": "distantia",
    "title": "Advanced Toolset for Efficient Time Series Dissimilarity\nAnalysis",
    "description": "Fast C++ implementation of Dynamic Time Warping for time series dissimilarity analysis, with applications in environmental monitoring and sensor data analysis, climate science, signal processing and pattern recognition, and financial data analysis. Built upon the ideas presented in Benito and Birks (2020) <doi:10.1111/ecog.04895>, provides tools for analyzing time series of varying lengths and structures, including irregular multivariate time series. Key features include individual variable contribution analysis, restricted permutation tests for statistical significance, and imputation of missing data via GAMs. Additionally, the package provides an ample set of tools to prepare and manage time series data.",
    "version": "2.0.2",
    "maintainer": "Blas M. Benito <blasbenito@gmail.com>",
    "author": "Blas M. Benito [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5105-7232>)",
    "url": "https://blasbenito.github.io/distantia/",
    "bug_reports": "https://github.com/BlasBenito/distantia/issues",
    "repository": "https://cran.r-project.org/package=distantia",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "distantia Advanced Toolset for Efficient Time Series Dissimilarity\nAnalysis Fast C++ implementation of Dynamic Time Warping for time series dissimilarity analysis, with applications in environmental monitoring and sensor data analysis, climate science, signal processing and pattern recognition, and financial data analysis. Built upon the ideas presented in Benito and Birks (2020) <doi:10.1111/ecog.04895>, provides tools for analyzing time series of varying lengths and structures, including irregular multivariate time series. Key features include individual variable contribution analysis, restricted permutation tests for statistical significance, and imputation of missing data via GAMs. Additionally, the package provides an ample set of tools to prepare and manage time series data.  "
  },
  {
    "id": 11243,
    "package_name": "divDyn",
    "title": "Diversity Dynamics using Fossil Sampling Data",
    "description": "Functions to describe sampling and diversity dynamics of fossil occurrence datasets (e.g. from the Paleobiology Database). The package includes methods to calculate range- and occurrence-based metrics of taxonomic richness, extinction and origination rates, along with traditional sampling measures. A powerful subsampling tool is also included that implements frequently used sampling standardization methods in a multiple bin-framework. The plotting of time series and the occurrence data can be simplified by the functions incorporated in the package, as well as other calculations, such as environmental affinities and extinction selectivity testing. Details can be found in: Kocsis, A.T.; Reddin, C.J.; Alroy, J. and Kiessling, W. (2019) <doi:10.1101/423780>.",
    "version": "0.8.3",
    "maintainer": "Adam T. Kocsis <adam.t.kocsis@gmail.com>",
    "author": "Adam T. Kocsis [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-9028-665X>),\n  John Alroy [aut] (ORCID: <https://orcid.org/0000-0002-9882-2111>),\n  Carl J. Reddin [aut] (ORCID: <https://orcid.org/0000-0001-5930-1164>),\n  Wolfgang Kiessling [aut] (ORCID:\n    <https://orcid.org/0000-0002-1088-2014>),\n  Deutsche Forschungsgemeinschaft [fnd],\n  FAU GeoZentrum Nordbayern [fnd]",
    "url": "",
    "bug_reports": "https://github.com/divDyn/r-package/issues",
    "repository": "https://cran.r-project.org/package=divDyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "divDyn Diversity Dynamics using Fossil Sampling Data Functions to describe sampling and diversity dynamics of fossil occurrence datasets (e.g. from the Paleobiology Database). The package includes methods to calculate range- and occurrence-based metrics of taxonomic richness, extinction and origination rates, along with traditional sampling measures. A powerful subsampling tool is also included that implements frequently used sampling standardization methods in a multiple bin-framework. The plotting of time series and the occurrence data can be simplified by the functions incorporated in the package, as well as other calculations, such as environmental affinities and extinction selectivity testing. Details can be found in: Kocsis, A.T.; Reddin, C.J.; Alroy, J. and Kiessling, W. (2019) <doi:10.1101/423780>.  "
  },
  {
    "id": 11253,
    "package_name": "divraster",
    "title": "Diversity Metrics Calculations for Rasterized Data",
    "description": "Alpha and beta diversity for taxonomic (TD), functional (FD),\n    and phylogenetic (PD) dimensions based on rasters. Spatial and\n    temporal beta diversity can be partitioned into replacement and\n    richness difference components. It also calculates standardized effect\n    size for FD and PD alpha diversity and the average individual traits\n    across multilayer rasters. The layers of the raster represent species,\n    while the cells represent communities. Methods details can be found at\n    Cardoso et al. 2022 <https://CRAN.R-project.org/package=BAT> and\n    Heming et al. 2023 <https://CRAN.R-project.org/package=SESraster>.",
    "version": "1.2.1",
    "maintainer": "Fl\u00e1vio M. M. Mota <flaviomoc@gmail.com>",
    "author": "Fl\u00e1vio M. M. Mota [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0308-7151>),\n  Neander Marcel Heming [aut] (ORCID:\n    <https://orcid.org/0000-0003-2461-5045>),\n  Gabriela Alves-Ferreira [aut] (ORCID:\n    <https://orcid.org/0000-0001-5661-3381>)",
    "url": "https://github.com/flaviomoc/divraster,\nhttps://flaviomoc.github.io/divraster/",
    "bug_reports": "https://github.com/flaviomoc/divraster/issues",
    "repository": "https://cran.r-project.org/package=divraster",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "divraster Diversity Metrics Calculations for Rasterized Data Alpha and beta diversity for taxonomic (TD), functional (FD),\n    and phylogenetic (PD) dimensions based on rasters. Spatial and\n    temporal beta diversity can be partitioned into replacement and\n    richness difference components. It also calculates standardized effect\n    size for FD and PD alpha diversity and the average individual traits\n    across multilayer rasters. The layers of the raster represent species,\n    while the cells represent communities. Methods details can be found at\n    Cardoso et al. 2022 <https://CRAN.R-project.org/package=BAT> and\n    Heming et al. 2023 <https://CRAN.R-project.org/package=SESraster>.  "
  },
  {
    "id": 11265,
    "package_name": "dlmwwbe",
    "title": "Dynamic Linear Model for Wastewater-Based Epidemiology",
    "description": "Implement dynamic linear models outlined in Shumway and Stoffer (2025) <doi:10.1007/978-3-031-70584-7>. Two model structures for data smoothing and forecasting are considered. The specific models proposed will be added once the manuscript is published. ",
    "version": "0.1.0",
    "maintainer": "Difan Ouyang <ouyan146@umn.edu>",
    "author": "Difan Ouyang [aut, cre],\n  Lappui Chung [aut],\n  Charles Doss [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dlmwwbe",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dlmwwbe Dynamic Linear Model for Wastewater-Based Epidemiology Implement dynamic linear models outlined in Shumway and Stoffer (2025) <doi:10.1007/978-3-031-70584-7>. Two model structures for data smoothing and forecasting are considered. The specific models proposed will be added once the manuscript is published.   "
  },
  {
    "id": 11269,
    "package_name": "dlsem",
    "title": "Distributed-Lag Linear Structural Equation Models",
    "description": "Inference functionalities for distributed-lag linear structural equation models (DLSEMs). DLSEMs are Markovian structural causal models where each factor of the joint probability distribution is a distributed-lag linear regression with constrained lag shapes (Magrini, 2018 <doi:10.2478/bile-2018-0012>; Magrini et al., 2019 <doi:10.1007/s11135-019-00855-z>). DLSEMs account for temporal delays in the dependence relationships among the variables through a single parameter per covariate, thus allowing to perform dynamic causal inference in a feasible fashion. Endpoint-constrained quadratic, quadratic decreasing, linearly decreasing and gamma lag shapes are available.",
    "version": "2.4.6",
    "maintainer": "Alessandro Magrini <alessandro.magrini@unifi.it>",
    "author": "Alessandro Magrini",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dlsem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dlsem Distributed-Lag Linear Structural Equation Models Inference functionalities for distributed-lag linear structural equation models (DLSEMs). DLSEMs are Markovian structural causal models where each factor of the joint probability distribution is a distributed-lag linear regression with constrained lag shapes (Magrini, 2018 <doi:10.2478/bile-2018-0012>; Magrini et al., 2019 <doi:10.1007/s11135-019-00855-z>). DLSEMs account for temporal delays in the dependence relationships among the variables through a single parameter per covariate, thus allowing to perform dynamic causal inference in a feasible fashion. Endpoint-constrained quadratic, quadratic decreasing, linearly decreasing and gamma lag shapes are available.  "
  },
  {
    "id": 11285,
    "package_name": "dnr",
    "title": "Simulate Dynamic Networks using Exponential Random Graph Models\n(ERGM) Family",
    "description": "Functions are provided to fit temporal lag models to dynamic\n    networks. The models are build on top of exponential random graph models (ERGM) framework. There are\n    functions for simulating or forecasting networks for future time points.\n    Abhirup Mallik & Zack W. Almquist (2019) Stable Multiple Time Step Simulation/Prediction From Lagged Dynamic Network Regression Models, Journal of Computational and Graphical Statistics, 28:4, 967-979, <DOI: 10.1080/10618600.2019.1594834>.",
    "version": "0.3.5",
    "maintainer": "Abhirup Mallik <abhirupkgp@gmail.com>",
    "author": "Abhirup Mallik [aut, cre],\n  Zack Almquist [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dnr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dnr Simulate Dynamic Networks using Exponential Random Graph Models\n(ERGM) Family Functions are provided to fit temporal lag models to dynamic\n    networks. The models are build on top of exponential random graph models (ERGM) framework. There are\n    functions for simulating or forecasting networks for future time points.\n    Abhirup Mallik & Zack W. Almquist (2019) Stable Multiple Time Step Simulation/Prediction From Lagged Dynamic Network Regression Models, Journal of Computational and Graphical Statistics, 28:4, 967-979, <DOI: 10.1080/10618600.2019.1594834>.  "
  },
  {
    "id": 11298,
    "package_name": "doblin",
    "title": "'doblin': Inferring Dominant Clonal Lineages from DNA Barcoding\nTime-Series",
    "description": "Provides functions to quantify dominant clonal lineages from DNA barcoding time-series data. The package implements clustering of barcode lineage trajectories, based on the assumption that similar temporal dynamics indicate comparable relative fitness. It also identifies persistent clonal lineages across time points. Input data can include lineage frequency tables derived from chromosomal barcoding, mutational libraries, or CRISPR/Cas screens. For more details, see Gagn\u00e9-Leroux et al. (2024) <doi:10.1101/2024.09.08.611892>.",
    "version": "0.1.1",
    "maintainer": "Adrian Serohijos <adrian.serohijos@umontreal.ca>",
    "author": "Adrian Serohijos [aut, cre],\n  David Gagn\u00e9-Leroux [ctb],\n  Melis Gencel [ctb],\n  Louis Gauthier [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=doblin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "doblin 'doblin': Inferring Dominant Clonal Lineages from DNA Barcoding\nTime-Series Provides functions to quantify dominant clonal lineages from DNA barcoding time-series data. The package implements clustering of barcode lineage trajectories, based on the assumption that similar temporal dynamics indicate comparable relative fitness. It also identifies persistent clonal lineages across time points. Input data can include lineage frequency tables derived from chromosomal barcoding, mutational libraries, or CRISPR/Cas screens. For more details, see Gagn\u00e9-Leroux et al. (2024) <doi:10.1101/2024.09.08.611892>.  "
  },
  {
    "id": 11401,
    "package_name": "drugDemand",
    "title": "Drug Demand Forecasting",
    "description": "Performs drug demand forecasting by modeling drug dispensing data while taking into account predicted enrollment and treatment discontinuation dates. The gap time between randomization and the first drug dispensing visit is modeled using interval-censored exponential, Weibull, log-logistic, or log-normal distributions (Anderson-Bergman (2017) <doi:10.18637/jss.v081.i12>). The number of skipped visits is modeled using Poisson, zero-inflated Poisson, or negative binomial distributions (Zeileis, Kleiber & Jackman (2008) <doi:10.18637/jss.v027.i08>). The gap time between two consecutive drug dispensing visits given the number of skipped visits is modeled using linear regression based on least squares or least absolute deviations (Birkes & Dodge (1993, ISBN:0-471-56881-3)). The number of dispensed doses is modeled using linear or linear mixed-effects models (McCulloch & Searle (2001, ISBN:0-471-19364-X)).",
    "version": "0.1.3",
    "maintainer": "Kaifeng Lu <kaifenglu@gmail.com>",
    "author": "Kaifeng Lu [aut, cre] (ORCID: <https://orcid.org/0000-0002-6160-7119>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=drugDemand",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "drugDemand Drug Demand Forecasting Performs drug demand forecasting by modeling drug dispensing data while taking into account predicted enrollment and treatment discontinuation dates. The gap time between randomization and the first drug dispensing visit is modeled using interval-censored exponential, Weibull, log-logistic, or log-normal distributions (Anderson-Bergman (2017) <doi:10.18637/jss.v081.i12>). The number of skipped visits is modeled using Poisson, zero-inflated Poisson, or negative binomial distributions (Zeileis, Kleiber & Jackman (2008) <doi:10.18637/jss.v027.i08>). The gap time between two consecutive drug dispensing visits given the number of skipped visits is modeled using linear regression based on least squares or least absolute deviations (Birkes & Dodge (1993, ISBN:0-471-56881-3)). The number of dispensed doses is modeled using linear or linear mixed-effects models (McCulloch & Searle (2001, ISBN:0-471-19364-X)).  "
  },
  {
    "id": 11408,
    "package_name": "dsa",
    "title": "Seasonal Adjustment of Daily Time Series",
    "description": "Seasonal- and calendar adjustment of time series\n    with daily frequency using the DSA approach developed by Ollech,\n    Daniel (2018): Seasonal adjustment of daily time series. Bundesbank\n    Discussion Paper 41/2018.",
    "version": "1.0.12",
    "maintainer": "Daniel Ollech <daniel.ollech@bundesbank.de>",
    "author": "Daniel Ollech [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dsa Seasonal Adjustment of Daily Time Series Seasonal- and calendar adjustment of time series\n    with daily frequency using the DSA approach developed by Ollech,\n    Daniel (2018): Seasonal adjustment of daily time series. Bundesbank\n    Discussion Paper 41/2018.  "
  },
  {
    "id": 11414,
    "package_name": "dsem",
    "title": "Dynamic Structural Equation Models",
    "description": "Applies dynamic structural equation models to time-series data\n\twith generic and simplified specification for simultaneous and lagged\n\teffects. Methods are described in Thorson et al. (2024)\n\t\"Dynamic structural equation models synthesize ecosystem dynamics \n\tconstrained by ecological mechanisms.\"  ",
    "version": "1.7.0",
    "maintainer": "James Thorson <James.Thorson@noaa.gov>",
    "author": "James Thorson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7415-1010>),\n  Maurice Goodman [ctb] (ORCID: <https://orcid.org/0000-0002-6874-2313>),\n  Wouter van der Bijl [ctb] (ORCID:\n    <https://orcid.org/0000-0002-7366-1868>, template for d-separation\n    test),\n  Giovanni M. Marchetti [ctr] (creator of ggm, from which functions are\n    copied to avoid dependency on package graph not on CRAN)",
    "url": "https://james-thorson-noaa.github.io/dsem/",
    "bug_reports": "https://github.com/James-Thorson-NOAA/dsem/issues",
    "repository": "https://cran.r-project.org/package=dsem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dsem Dynamic Structural Equation Models Applies dynamic structural equation models to time-series data\n\twith generic and simplified specification for simultaneous and lagged\n\teffects. Methods are described in Thorson et al. (2024)\n\t\"Dynamic structural equation models synthesize ecosystem dynamics \n\tconstrained by ecological mechanisms.\"    "
  },
  {
    "id": 11423,
    "package_name": "dsp",
    "title": "Dynamic Shrinkage Process and Change Point Detection",
    "description": "Provides efficient Markov chain Monte Carlo (MCMC) algorithms for \n    dynamic shrinkage processes, which extend global-local shrinkage priors to \n    the time series setting by allowing shrinkage to depend on its own past. \n    These priors yield locally adaptive estimates, useful for time series and \n    regression functions with irregular features. The package includes full MCMC \n    implementations for trend filtering using dynamic shrinkage on signal differences, \n    producing locally constant or linear fits with adaptive credible bands. \n    Also included are models with static shrinkage and normal-inverse-Gamma priors for comparison. \n    Additional tools cover dynamic regression with time-varying coefficients and \n    B-spline models with shrinkage on basis differences, allowing for flexible \n    curve-fitting with unequally spaced data. Some support for heteroscedastic errors, \n    outlier detection, and change point estimation.\n    Methods in this package are described in Kowal et al. (2019) <doi:10.1111/rssb.12325>, \n    Wu et al. (2024) <doi:10.1080/07350015.2024.2362269>, Schafer and Matteson (2024)\n    <doi:10.1080/00401706.2024.2407316>, and Cho and Matteson (2024) <doi:10.48550/arXiv.2408.11315>.",
    "version": "1.2.0",
    "maintainer": "Toryn Schafer <toryn27@gmail.com>",
    "author": "Daniel R. Kowal [aut, cph],\n  Haoxuan Wu [aut],\n  Toryn Schafer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5594-7697>),\n  Jason B. Cho [aut],\n  David S. Matteson [aut]",
    "url": "https://github.com/schafert/dsp",
    "bug_reports": "https://github.com/schafert/dsp/issues",
    "repository": "https://cran.r-project.org/package=dsp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dsp Dynamic Shrinkage Process and Change Point Detection Provides efficient Markov chain Monte Carlo (MCMC) algorithms for \n    dynamic shrinkage processes, which extend global-local shrinkage priors to \n    the time series setting by allowing shrinkage to depend on its own past. \n    These priors yield locally adaptive estimates, useful for time series and \n    regression functions with irregular features. The package includes full MCMC \n    implementations for trend filtering using dynamic shrinkage on signal differences, \n    producing locally constant or linear fits with adaptive credible bands. \n    Also included are models with static shrinkage and normal-inverse-Gamma priors for comparison. \n    Additional tools cover dynamic regression with time-varying coefficients and \n    B-spline models with shrinkage on basis differences, allowing for flexible \n    curve-fitting with unequally spaced data. Some support for heteroscedastic errors, \n    outlier detection, and change point estimation.\n    Methods in this package are described in Kowal et al. (2019) <doi:10.1111/rssb.12325>, \n    Wu et al. (2024) <doi:10.1080/07350015.2024.2362269>, Schafer and Matteson (2024)\n    <doi:10.1080/00401706.2024.2407316>, and Cho and Matteson (2024) <doi:10.48550/arXiv.2408.11315>.  "
  },
  {
    "id": 11445,
    "package_name": "dtts",
    "title": "'data.table' Time-Series",
    "description": "High-frequency time-series support via 'nanotime' and 'data.table'.",
    "version": "0.1.3",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel and Leonardo Silvestri",
    "url": "",
    "bug_reports": "https://github.com/eddelbuettel/dtts/issues",
    "repository": "https://cran.r-project.org/package=dtts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dtts 'data.table' Time-Series High-frequency time-series support via 'nanotime' and 'data.table'.  "
  },
  {
    "id": 11446,
    "package_name": "dtw",
    "title": "Dynamic Time Warping Algorithms",
    "description": "A comprehensive implementation of dynamic time warping\n    (DTW) algorithms in R.  DTW computes the optimal (least cumulative\n    distance) alignment between points of two time series.  Common DTW\n    variants covered include local (slope) and global (window)\n    constraints, subsequence matches, arbitrary distance definitions,\n    normalizations, minimum variance matching, and so on.  Provides\n    cumulative distances, alignments, specialized plot styles, etc.,\n    as described in Giorgino (2009) <doi:10.18637/jss.v031.i07>.",
    "version": "1.23-1",
    "maintainer": "Toni Giorgino <toni.giorgino@gmail.com>",
    "author": "Toni Giorgino [aut, cre]",
    "url": "https://dynamictimewarping.github.io/,\nhttp://dtw.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dtw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dtw Dynamic Time Warping Algorithms A comprehensive implementation of dynamic time warping\n    (DTW) algorithms in R.  DTW computes the optimal (least cumulative\n    distance) alignment between points of two time series.  Common DTW\n    variants covered include local (slope) and global (window)\n    constraints, subsequence matches, arbitrary distance definitions,\n    normalizations, minimum variance matching, and so on.  Provides\n    cumulative distances, alignments, specialized plot styles, etc.,\n    as described in Giorgino (2009) <doi:10.18637/jss.v031.i07>.  "
  },
  {
    "id": 11447,
    "package_name": "dtwclust",
    "title": "Time Series Clustering Along with Optimizations for the Dynamic\nTime Warping Distance",
    "description": "Time series clustering along with optimized techniques related\n    to the Dynamic Time Warping distance and its corresponding lower bounds.\n    Implementations of partitional, hierarchical, fuzzy, k-Shape and TADPole\n    clustering are available. Functionality can be easily extended with\n    custom distance measures and centroid definitions. Implementations of\n    DTW barycenter averaging, a distance based on global alignment kernels,\n    and the soft-DTW distance and centroid routines are also provided. \n    All included distance functions have custom loops optimized for the \n    calculation of cross-distance matrices, including parallelization support.\n    Several cluster validity indices are included.",
    "version": "6.0.0",
    "maintainer": "Alexis Sarda <alexis.sarda@gmail.com>",
    "author": "Alexis Sarda-Espinosa",
    "url": "https://github.com/asardaes/dtwclust",
    "bug_reports": "https://github.com/asardaes/dtwclust/issues",
    "repository": "https://cran.r-project.org/package=dtwclust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dtwclust Time Series Clustering Along with Optimizations for the Dynamic\nTime Warping Distance Time series clustering along with optimized techniques related\n    to the Dynamic Time Warping distance and its corresponding lower bounds.\n    Implementations of partitional, hierarchical, fuzzy, k-Shape and TADPole\n    clustering are available. Functionality can be easily extended with\n    custom distance measures and centroid definitions. Implementations of\n    DTW barycenter averaging, a distance based on global alignment kernels,\n    and the soft-DTW distance and centroid routines are also provided. \n    All included distance functions have custom loops optimized for the \n    calculation of cross-distance matrices, including parallelization support.\n    Several cluster validity indices are included.  "
  },
  {
    "id": 11474,
    "package_name": "dycdtools",
    "title": "Calibration Assistant and Post-Processing Tool for Aquatic\nEcosystem Model DYRESM-CAEDYM",
    "description": "Dynamic Reservoir Simulation Model (DYRESM) and Computational Aquatic Ecosystem Dynamics Model (CAEDYM) model development, including assisting with calibrating selected model parameters and visualising model output through time series plot, profile plot, contour plot, and scatter plot. For more details, see Yu et al. (2023) <https://journal.r-project.org/articles/RJ-2023-008/>.",
    "version": "0.4.4",
    "maintainer": "Songyan Yu <yusongyan1989@gmail.com>",
    "author": "Songyan Yu [aut, cre] (ORCID: <https://orcid.org/0000-0001-5765-7060>),\n  Christopher McBride [ctb],\n  Marieke Frassl [ctb]",
    "url": "https://github.com/SongyanYu/dycdtools",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dycdtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dycdtools Calibration Assistant and Post-Processing Tool for Aquatic\nEcosystem Model DYRESM-CAEDYM Dynamic Reservoir Simulation Model (DYRESM) and Computational Aquatic Ecosystem Dynamics Model (CAEDYM) model development, including assisting with calibrating selected model parameters and visualising model output through time series plot, profile plot, contour plot, and scatter plot. For more details, see Yu et al. (2023) <https://journal.r-project.org/articles/RJ-2023-008/>.  "
  },
  {
    "id": 11476,
    "package_name": "dymo",
    "title": "Dynamic Mode Decomposition Forecasting with Conformal Predictive\nSampling",
    "description": "The DYMO package provides tools for multi-feature time-series forecasting using a Dynamic Mode Decomposition (DMD) model combined with conformal predictive sampling for uncertainty quantification.",
    "version": "2.0.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/dymo",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dymo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dymo Dynamic Mode Decomposition Forecasting with Conformal Predictive\nSampling The DYMO package provides tools for multi-feature time-series forecasting using a Dynamic Mode Decomposition (DMD) model combined with conformal predictive sampling for uncertainty quantification.  "
  },
  {
    "id": 11477,
    "package_name": "dyn",
    "title": "Time Series Regression",
    "description": "Time series regression.  The dyn class interfaces ts,\n        irts(), zoo() and zooreg() time series classes to lm(), glm(),\n        loess(), quantreg::rq(), MASS::rlm(), MCMCpack::MCMCregress(),\n        quantreg::rq(), randomForest::randomForest() and other regression\n        functions allowing those functions to be used with time series\n        including specifications that may contain lags, diffs and\n        missing values.",
    "version": "0.2-9.6",
    "maintainer": "M. Leeds <markleeds2@gmail.com>",
    "author": "G. Grothendieck",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dyn Time Series Regression Time series regression.  The dyn class interfaces ts,\n        irts(), zoo() and zooreg() time series classes to lm(), glm(),\n        loess(), quantreg::rq(), MASS::rlm(), MCMCpack::MCMCregress(),\n        quantreg::rq(), randomForest::randomForest() and other regression\n        functions allowing those functions to be used with time series\n        including specifications that may contain lags, diffs and\n        missing values.  "
  },
  {
    "id": 11487,
    "package_name": "dynamicSDM",
    "title": "Species Distribution and Abundance Modelling at High\nSpatio-Temporal Resolution",
    "description": "A collection of novel tools for generating species distribution and abundance models (SDM) that are dynamic through both space and time. These highly flexible functions incorporate spatial and temporal aspects across key SDM stages; including when cleaning and filtering species occurrence data, generating pseudo-absence records, assessing and correcting sampling biases and autocorrelation, extracting explanatory variables and projecting distribution patterns. Throughout, functions utilise Google Earth Engine and Google Drive to minimise the computing power and storage demands associated with species distribution modelling at high spatio-temporal resolution.",
    "version": "1.3.4",
    "maintainer": "Rachel Dobson <eerdo@leeds.ac.uk>",
    "author": "Rachel Dobson [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0003-3990-267X>),\n  Andy J. Challinor [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-8551-6617>),\n  Robert A. Cheke [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-7437-1934>),\n  Stewart Jennings [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-1267-8623>),\n  Stephen G. Willis [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-8656-5808>),\n  Martin Dallimer [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-8120-3309>)",
    "url": "https://github.com/r-a-dobson/dynamicSDM",
    "bug_reports": "https://github.com/r-a-dobson/dynamicSDM/issues",
    "repository": "https://cran.r-project.org/package=dynamicSDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dynamicSDM Species Distribution and Abundance Modelling at High\nSpatio-Temporal Resolution A collection of novel tools for generating species distribution and abundance models (SDM) that are dynamic through both space and time. These highly flexible functions incorporate spatial and temporal aspects across key SDM stages; including when cleaning and filtering species occurrence data, generating pseudo-absence records, assessing and correcting sampling biases and autocorrelation, extracting explanatory variables and projecting distribution patterns. Throughout, functions utilise Google Earth Engine and Google Drive to minimise the computing power and storage demands associated with species distribution modelling at high spatio-temporal resolution.  "
  },
  {
    "id": 11491,
    "package_name": "dynemu",
    "title": "Emulation of Dynamic Simulators via One-Step-Ahead Approach",
    "description": "Performs emulation of dynamic simulators using Gaussian process via one-step ahead approach. The package implements a flexible framework for approximating time-dependent outputs from computationally expensive dynamic systems. It is specifically designed for nonlinear dynamic systems where full simulations may be costly. The underlying Gaussian process model accounts for temporal dependency through the one-step-ahead formulation, allowing for accurate emulation of complex dynamics. Hyperparameters are estimated via maximum likelihood. For methodological details, see Heo (2025, <doi:10.48550/arXiv.2503.20250>) for exact method, and Mohammadi, Challenor, and Goodfellow (2019, <doi:10.1016/j.csda.2019.05.006>) for Monte Carlo method. ",
    "version": "1.0.2",
    "maintainer": "Junoh Heo <heojunoh@msu.edu>",
    "author": "Junoh Heo [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dynemu",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dynemu Emulation of Dynamic Simulators via One-Step-Ahead Approach Performs emulation of dynamic simulators using Gaussian process via one-step ahead approach. The package implements a flexible framework for approximating time-dependent outputs from computationally expensive dynamic systems. It is specifically designed for nonlinear dynamic systems where full simulations may be costly. The underlying Gaussian process model accounts for temporal dependency through the one-step-ahead formulation, allowing for accurate emulation of complex dynamics. Hyperparameters are estimated via maximum likelihood. For methodological details, see Heo (2025, <doi:10.48550/arXiv.2503.20250>) for exact method, and Mohammadi, Challenor, and Goodfellow (2019, <doi:10.1016/j.csda.2019.05.006>) for Monte Carlo method.   "
  },
  {
    "id": 11494,
    "package_name": "dynlm",
    "title": "Dynamic Linear Regression",
    "description": "Dynamic linear models and time series regression.",
    "version": "0.3-6",
    "maintainer": "Achim Zeileis <Achim.Zeileis@R-project.org>",
    "author": "Achim Zeileis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0918-3766>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dynlm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dynlm Dynamic Linear Regression Dynamic linear models and time series regression.  "
  },
  {
    "id": 11524,
    "package_name": "eNchange",
    "title": "Ensemble Methods for Multiple Change-Point Detection",
    "description": "Implements a segmentation algorithm for multiple change-point detection in univariate time series using the Ensemble Binary Segmentation of Korkas (2022) <Journal of the Korean Statistical Society, 51(1), pp.65-86.>.",
    "version": "1.1",
    "maintainer": "Karolos K. Korkas <kkorkas@yahoo.co.uk>",
    "author": "Karolos K. Korkas [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=eNchange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eNchange Ensemble Methods for Multiple Change-Point Detection Implements a segmentation algorithm for multiple change-point detection in univariate time series using the Ensemble Binary Segmentation of Korkas (2022) <Journal of the Korean Statistical Society, 51(1), pp.65-86.>.  "
  },
  {
    "id": 11551,
    "package_name": "easyVerification",
    "title": "Ensemble Forecast Verification for Large Data Sets",
    "description": "Set of tools to simplify application of atomic forecast\n    verification metrics for (comparative) verification of ensemble forecasts\n    to large data sets. The forecast metrics are imported from the\n    'SpecsVerification' package, and additional forecast metrics are provided\n    with this package. Alternatively, new user-defined forecast scores can be\n    implemented using the example scores provided and applied using the\n    functionality of this package.",
    "version": "0.4.5",
    "maintainer": "Jonas Bhend <jonas.bhend@meteoswiss.ch>",
    "author": "MeteoSwiss [aut, cph],\n  Jonas Bhend [cre],\n  Jacopo Ripoldi [ctb],\n  Claudia Mignani [ctb],\n  Irina Mahlstein [ctb],\n  Rebecca Hiller [ctb],\n  Christoph Spirig [ctb],\n  Mark Liniger [ctb],\n  Andreas Weigel [ctb],\n  Joaqu'in Bedia Jimenez [ctb],\n  Matteo De Felice [ctb],\n  Stefan Siegert [ctb],\n  Katrin Sedlmeier [ctb]",
    "url": "https://www.meteoswiss.admin.ch,\nhttps://github.com/jonasbhend/easyVerification",
    "bug_reports": "https://github.com/jonasbhend/easyVerification/issues",
    "repository": "https://cran.r-project.org/package=easyVerification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "easyVerification Ensemble Forecast Verification for Large Data Sets Set of tools to simplify application of atomic forecast\n    verification metrics for (comparative) verification of ensemble forecasts\n    to large data sets. The forecast metrics are imported from the\n    'SpecsVerification' package, and additional forecast metrics are provided\n    with this package. Alternatively, new user-defined forecast scores can be\n    implemented using the example scores provided and applied using the\n    functionality of this package.  "
  },
  {
    "id": 11581,
    "package_name": "ebirdst",
    "title": "Access and Analyze eBird Status and Trends Data Products",
    "description": "Tools for accessing and analyzing eBird Status and\n    Trends Data Products\n    (<https://science.ebird.org/en/status-and-trends>). eBird\n    (<https://ebird.org/home>) is a global database of bird observations\n    collected by member of the public. eBird Status and Trends uses these\n    data to model global bird distributions, abundances, and population trends \n    at a high spatial and temporal resolution.",
    "version": "3.2023.1",
    "maintainer": "Matthew Strimas-Mackey <mes335@cornell.edu>",
    "author": "Matthew Strimas-Mackey [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8929-7776>),\n  Shawn Ligocki [aut],\n  Tom Auer [aut] (ORCID: <https://orcid.org/0000-0001-8619-7147>),\n  Daniel Fink [aut] (ORCID: <https://orcid.org/0000-0002-8368-1248>),\n  Cornell Lab of Ornithology [cph]",
    "url": "https://ebird.github.io/ebirdst/, https://github.com/ebird/ebirdst",
    "bug_reports": "https://github.com/ebird/ebirdst/issues",
    "repository": "https://cran.r-project.org/package=ebirdst",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ebirdst Access and Analyze eBird Status and Trends Data Products Tools for accessing and analyzing eBird Status and\n    Trends Data Products\n    (<https://science.ebird.org/en/status-and-trends>). eBird\n    (<https://ebird.org/home>) is a global database of bird observations\n    collected by member of the public. eBird Status and Trends uses these\n    data to model global bird distributions, abundances, and population trends \n    at a high spatial and temporal resolution.  "
  },
  {
    "id": 11602,
    "package_name": "echos",
    "title": "Echo State Networks for Time Series Modeling and Forecasting",
    "description": "Provides a lightweight implementation of functions and methods for\n    fast and fully automatic time series modeling and forecasting using Echo\n    State Networks (ESNs).",
    "version": "1.0.2",
    "maintainer": "Alexander H\u00e4u\u00dfer <alexander-haeusser@gmx.de>",
    "author": "Alexander H\u00e4u\u00dfer [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0000-5419-8479>)",
    "url": "https://github.com/ahaeusser/echos,\nhttps://ahaeusser.github.io/echos/",
    "bug_reports": "https://github.com/ahaeusser/echos/issues",
    "repository": "https://cran.r-project.org/package=echos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "echos Echo State Networks for Time Series Modeling and Forecasting Provides a lightweight implementation of functions and methods for\n    fast and fully automatic time series modeling and forecasting using Echo\n    State Networks (ESNs).  "
  },
  {
    "id": 11605,
    "package_name": "ecm",
    "title": "Build Error Correction Models",
    "description": "Functions for easy building of error correction models (ECM) for time series regression. ",
    "version": "7.2.0",
    "maintainer": "Gaurav Bansal <gaurbans@gmail.com>",
    "author": "Gaurav Bansal",
    "url": "https://github.com/gaurbans/ecm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ecm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecm Build Error Correction Models Functions for easy building of error correction models (ECM) for time series regression.   "
  },
  {
    "id": 11606,
    "package_name": "ecmwfr",
    "title": "Interface to 'ECMWF' and 'CDS' Data Web Services",
    "description": "Programmatic interface to the European Centre for Medium-Range\n    Weather Forecasts dataset web services (ECMWF; <https://www.ecmwf.int/>)\n    and Copernicus's Data Stores. Allows for easy downloads of weather \n    forecasts and climate reanalysis data in R. Data stores covered include the Climate Data Store (CDS; \n    <https://cds.climate.copernicus.eu>), Atmosphere Data Store (ADS; \n    <https://ads.atmosphere.copernicus.eu>) and Early Warning Data Store (CEMS; \n    <https://ewds.climate.copernicus.eu>).",
    "version": "2.0.3",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "author": "Koen Hufkens [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5070-8109>),\n  Reto Stauffer [ctb] (ORCID: <https://orcid.org/0000-0002-3798-5507>),\n  Elio Campitelli [ctb] (ORCID: <https://orcid.org/0000-0002-7742-9230>),\n  BlueGreen Labs [fnd]",
    "url": "https://github.com/bluegreen-labs/ecmwfr",
    "bug_reports": "https://github.com/bluegreen-labs/ecmwfr/issues",
    "repository": "https://cran.r-project.org/package=ecmwfr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecmwfr Interface to 'ECMWF' and 'CDS' Data Web Services Programmatic interface to the European Centre for Medium-Range\n    Weather Forecasts dataset web services (ECMWF; <https://www.ecmwf.int/>)\n    and Copernicus's Data Stores. Allows for easy downloads of weather \n    forecasts and climate reanalysis data in R. Data stores covered include the Climate Data Store (CDS; \n    <https://cds.climate.copernicus.eu>), Atmosphere Data Store (ADS; \n    <https://ads.atmosphere.copernicus.eu>) and Early Warning Data Store (CEMS; \n    <https://ewds.climate.copernicus.eu>).  "
  },
  {
    "id": 11635,
    "package_name": "ecostate",
    "title": "State-Space Mass-Balance Model for Marine Ecosystems",
    "description": "\n\tFits a state-space mass-balance model for marine ecosystems,\n\twhich implements dynamics derived from \n\t'Ecopath with Ecosim' ('EwE') <https://ecopath.org/>\n\twhile fitting to time-series of fishery catch, biomass indices,\n\tage-composition samples, and weight-at-age data.  \n\t'Ecostate' fits biological parameters (e.g., equilibrium mass)\n\tand measurement parameters (e.g., catchability coefficients)\n\tjointly with residual variation in process errors, and can include\n\tBayesian priors for parameters.  ",
    "version": "0.3.0",
    "maintainer": "James T. Thorson <James.Thorson@noaa.gov>",
    "author": "James T. Thorson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7415-1010>)",
    "url": "https://james-thorson-noaa.github.io/ecostate/",
    "bug_reports": "https://github.com/James-Thorson-NOAA/ecostate/issues",
    "repository": "https://cran.r-project.org/package=ecostate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecostate State-Space Mass-Balance Model for Marine Ecosystems \n\tFits a state-space mass-balance model for marine ecosystems,\n\twhich implements dynamics derived from \n\t'Ecopath with Ecosim' ('EwE') <https://ecopath.org/>\n\twhile fitting to time-series of fishery catch, biomass indices,\n\tage-composition samples, and weight-at-age data.  \n\t'Ecostate' fits biological parameters (e.g., equilibrium mass)\n\tand measurement parameters (e.g., catchability coefficients)\n\tjointly with residual variation in process errors, and can include\n\tBayesian priors for parameters.    "
  },
  {
    "id": 11637,
    "package_name": "ecostatscale",
    "title": "Statistical Scaling Functions for Ecological Systems",
    "description": "Implementation of the scaling functions presented in \"General statistical scaling laws for stability in ecological systems\" by Clark et al in Ecology Letters <DOI:10.1111/ele.13760>. Includes functions for extrapolating variability, resistance, and resilience across spatial and ecological scales, as well as a basic simulation function for producing time series, and a regression routine for generating unbiased parameter estimates. See the main text of the paper for more details.",
    "version": "1.1",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "author": "Adam Clark [aut, cre] (ORCID: <https://orcid.org/0000-0002-8843-3278>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ecostatscale",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecostatscale Statistical Scaling Functions for Ecological Systems Implementation of the scaling functions presented in \"General statistical scaling laws for stability in ecological systems\" by Clark et al in Ecology Letters <DOI:10.1111/ele.13760>. Includes functions for extrapolating variability, resistance, and resilience across spatial and ecological scales, as well as a basic simulation function for producing time series, and a regression routine for generating unbiased parameter estimates. See the main text of the paper for more details.  "
  },
  {
    "id": 11642,
    "package_name": "ecotraj",
    "title": "Ecological Trajectory Analysis",
    "description": "Analysis of temporal changes (i.e. dynamics) of ecological entities, defined as trajectories on a chosen multivariate space, by providing a set of \n    trajectory metrics and visual representations [De Caceres et al. (2019) <doi:10.1002/ecm.1350>; \n    and Sturbois et al. (2021) <doi:10.1016/j.ecolmodel.2020.109400>]. Includes functions\n    to estimate metrics for individual trajectories (length, directionality, angles, ...) as well as\n    metrics to relate pairs of trajectories (dissimilarity and convergence). Functions are also\n    provided to estimate the ecological quality of ecosystem with respect to reference conditions \n    [Sturbois et al. (2023)  <doi:10.1002/ecs2.4726>].",
    "version": "1.2.0",
    "maintainer": "Miquel De C\u00e1ceres <miquelcaceres@gmail.com>",
    "author": "Miquel De C\u00e1ceres [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7132-2080>),\n  Nicolas Djeghri [aut] (ORCID: <https://orcid.org/0000-0001-5740-3386>),\n  Anthony Sturbois [aut] (ORCID: <https://orcid.org/0000-0002-9219-4468>),\n  Javier De la Casa [ctb]",
    "url": "https://emf-creaf.github.io/ecotraj/",
    "bug_reports": "https://github.com/emf-creaf/ecotraj/issues",
    "repository": "https://cran.r-project.org/package=ecotraj",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecotraj Ecological Trajectory Analysis Analysis of temporal changes (i.e. dynamics) of ecological entities, defined as trajectories on a chosen multivariate space, by providing a set of \n    trajectory metrics and visual representations [De Caceres et al. (2019) <doi:10.1002/ecm.1350>; \n    and Sturbois et al. (2021) <doi:10.1016/j.ecolmodel.2020.109400>]. Includes functions\n    to estimate metrics for individual trajectories (length, directionality, angles, ...) as well as\n    metrics to relate pairs of trajectories (dissimilarity and convergence). Functions are also\n    provided to estimate the ecological quality of ecosystem with respect to reference conditions \n    [Sturbois et al. (2023)  <doi:10.1002/ecs2.4726>].  "
  },
  {
    "id": 11643,
    "package_name": "ecotrends",
    "title": "Temporal Trends in Ecological Niche Models",
    "description": "Computes temporal trends in environmental suitability obtained from ecological niche models, based on a set of species presence point coordinates and predictor variables.",
    "version": "1.2",
    "maintainer": "A. Marcia Barbosa <ana.marcia.barbosa@gmail.com>",
    "author": "A. Marcia Barbosa [aut, cre],\n  Jo\u00e3o Al\u00edrio [aut],\n  Nuno Garcia [aut],\n  Jo\u00e3o Campos [aut],\n  Ana Cl\u00e1udia Teodoro [aut],\n  Lia B\u00e1rbara Duarte [aut],\n  Isabel P\u00f4\u00e7as [aut],\n  Salvador Arenas-Castro [aut],\n  Neftal\u00ed Sillero [aut]",
    "url": "https://github.com/AMBarbosa/ecotrends",
    "bug_reports": "https://github.com/AMBarbosa/ecotrends/issues",
    "repository": "https://cran.r-project.org/package=ecotrends",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecotrends Temporal Trends in Ecological Niche Models Computes temporal trends in environmental suitability obtained from ecological niche models, based on a set of species presence point coordinates and predictor variables.  "
  },
  {
    "id": 11656,
    "package_name": "edecob",
    "title": "Event Detection Using Confidence Bounds",
    "description": "Detects sustained change in digital bio-marker data using\n    simultaneous confidence bands. Accounts for noise using an auto-regressive\n    model. Based on Buehlmann (1998) \"Sieve bootstrap for smoothing in\n    nonstationary time series\" <doi:10.1214/aos/1030563978>.",
    "version": "1.2.2",
    "maintainer": "Zheng Chen Man <zheng.chen.man@alumni.ethz.ch>",
    "author": "Zheng Chen Man [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=edecob",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "edecob Event Detection Using Confidence Bounds Detects sustained change in digital bio-marker data using\n    simultaneous confidence bands. Accounts for noise using an auto-regressive\n    model. Based on Buehlmann (1998) \"Sieve bootstrap for smoothing in\n    nonstationary time series\" <doi:10.1214/aos/1030563978>.  "
  },
  {
    "id": 11685,
    "package_name": "eemdARIMA",
    "title": "EEMD Based Auto Regressive Integrated Moving Average Model",
    "description": "Forecasting time series with different decomposition based ARIMA models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>. ",
    "version": "0.1.0",
    "maintainer": "Rajeev Ranjan Kumar <rrk.uasd@gmail.com>",
    "author": "Rajeev Ranjan Kumar [aut, cre],\n  Girish Kumar Jha [aut, ths, ctb],\n  Kapil Choudhary [aut, ctb],\n  Ronit Jaiswal [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=eemdARIMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eemdARIMA EEMD Based Auto Regressive Integrated Moving Average Model Forecasting time series with different decomposition based ARIMA models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>.   "
  },
  {
    "id": 11686,
    "package_name": "eemdTDNN",
    "title": "EEMD and Its Variant Based Time Delay Neural Network Model",
    "description": "Forecasting univariate time series with different decomposition based time delay neural network models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>. ",
    "version": "0.1.0",
    "maintainer": "Kapil Choudhary <choudharykapil832@gmail.com>",
    "author": "Kapil Choudhary [aut, cre],\n  Girish Kumar Jha [aut, ths, ctb],\n  Rajeev Ranjan Kumar [aut, ctb],\n  Ronit Jaiswal [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=eemdTDNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eemdTDNN EEMD and Its Variant Based Time Delay Neural Network Model Forecasting univariate time series with different decomposition based time delay neural network models. For method details see Yu L, Wang S, Lai KK (2008). <doi:10.1016/j.eneco.2008.05.003>.   "
  },
  {
    "id": 11688,
    "package_name": "eesim",
    "title": "Simulate and Evaluate Time Series for Environmental Epidemiology",
    "description": "Provides functions to create simulated time series of environmental\n    exposures (e.g., temperature, air pollution) and health outcomes for use in\n    power analysis and simulation studies in environmental epidemiology. This\n    package also provides functions to evaluate the results of simulation studies\n    based on these simulated time series. This work was supported by a grant\n    from the National Institute of Environmental Health Sciences (R00ES022631) and\n    a fellowship from the Colorado State University Programs for Research and\n    Scholarly Excellence.",
    "version": "0.1.0",
    "maintainer": "Brooke Anderson <brooke.anderson@colostate.edu>",
    "author": "Sarah Koehler [aut],\n  Brooke Anderson [aut, cre]",
    "url": "http://github.com/sakoehler7/eesim",
    "bug_reports": "http://github.com/sakoehler7/eesim/issues",
    "repository": "https://cran.r-project.org/package=eesim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eesim Simulate and Evaluate Time Series for Environmental Epidemiology Provides functions to create simulated time series of environmental\n    exposures (e.g., temperature, air pollution) and health outcomes for use in\n    power analysis and simulation studies in environmental epidemiology. This\n    package also provides functions to evaluate the results of simulation studies\n    based on these simulated time series. This work was supported by a grant\n    from the National Institute of Environmental Health Sciences (R00ES022631) and\n    a fellowship from the Colorado State University Programs for Research and\n    Scholarly Excellence.  "
  },
  {
    "id": 11723,
    "package_name": "eixport",
    "title": "Export Emissions to Atmospheric Models",
    "description": "Emissions are the mass of pollutants released into the atmosphere. Air quality models need emissions data, with spatial and temporal distribution, to represent air pollutant concentrations. This package, eixport, creates inputs for the air quality models 'WRF-Chem' Grell et al (2005) <doi:10.1016/j.atmosenv.2005.04.027>, 'MUNICH' Kim et al (2018) <doi:10.5194/gmd-11-611-2018> , 'BRAMS-SPM' Freitas et al (2005) <doi:10.1016/j.atmosenv.2005.07.017> and 'RLINE' Snyder et al (2013) <doi:10.1016/j.atmosenv.2013.05.074>. See the 'eixport' website (<https://atmoschem.github.io/eixport/>) for more information, documentations and examples. More details in Ibarra-Espinosa et al (2018) <doi:10.21105/joss.00607>.",
    "version": "0.6.2",
    "maintainer": "Sergio Ibarra-Espinosa <zergioibarra@gmail.com>",
    "author": "Sergio Ibarra-Espinosa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3162-1905>),\n  Daniel Schuch [aut] (ORCID: <https://orcid.org/0000-0001-5977-4519>),\n  Edmilson Freitas [ths] (ORCID: <https://orcid.org/0000-0001-8783-2747>)",
    "url": "https://atmoschem.github.io/eixport/",
    "bug_reports": "https://github.com/atmoschem/eixport/issues/",
    "repository": "https://cran.r-project.org/package=eixport",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eixport Export Emissions to Atmospheric Models Emissions are the mass of pollutants released into the atmosphere. Air quality models need emissions data, with spatial and temporal distribution, to represent air pollutant concentrations. This package, eixport, creates inputs for the air quality models 'WRF-Chem' Grell et al (2005) <doi:10.1016/j.atmosenv.2005.04.027>, 'MUNICH' Kim et al (2018) <doi:10.5194/gmd-11-611-2018> , 'BRAMS-SPM' Freitas et al (2005) <doi:10.1016/j.atmosenv.2005.07.017> and 'RLINE' Snyder et al (2013) <doi:10.1016/j.atmosenv.2013.05.074>. See the 'eixport' website (<https://atmoschem.github.io/eixport/>) for more information, documentations and examples. More details in Ibarra-Espinosa et al (2018) <doi:10.21105/joss.00607>.  "
  },
  {
    "id": 11801,
    "package_name": "enmSdmX",
    "title": "Species Distribution Modeling and Ecological Niche Modeling",
    "description": "Implements species distribution modeling and ecological niche\n\tmodeling, including: bias correction, spatial cross-validation, model\n\tevaluation, raster interpolation, biotic \"velocity\" (speed and\n\tdirection of movement of a \"mass\" represented by a raster), interpolating\n\tacross a time series of rasters, and use of spatially imprecise records.\n\tThe heart of the package is a set of \"training\" functions which\n\tautomatically optimize model complexity based number of available\n\toccurrences. These algorithms include MaxEnt, MaxNet, boosted regression\n\ttrees/gradient boosting machines, generalized additive models,\n\tgeneralized linear models, natural splines, and random forests. To enhance\n\tinteroperability with other modeling packages, no new classes are created.\n\tThe package works with 'PROJ6' geodetic objects and coordinate reference\n\tsystems.",
    "version": "1.2.12",
    "maintainer": "Adam B. Smith <adam.smith@mobot.org>",
    "author": "Adam B. Smith [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-6420-1659>)",
    "url": "https://github.com/adamlilith/enmSdmX",
    "bug_reports": "https://github.com/adamlilith/enmSdmX/issues",
    "repository": "https://cran.r-project.org/package=enmSdmX",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "enmSdmX Species Distribution Modeling and Ecological Niche Modeling Implements species distribution modeling and ecological niche\n\tmodeling, including: bias correction, spatial cross-validation, model\n\tevaluation, raster interpolation, biotic \"velocity\" (speed and\n\tdirection of movement of a \"mass\" represented by a raster), interpolating\n\tacross a time series of rasters, and use of spatially imprecise records.\n\tThe heart of the package is a set of \"training\" functions which\n\tautomatically optimize model complexity based number of available\n\toccurrences. These algorithms include MaxEnt, MaxNet, boosted regression\n\ttrees/gradient boosting machines, generalized additive models,\n\tgeneralized linear models, natural splines, and random forests. To enhance\n\tinteroperability with other modeling packages, no new classes are created.\n\tThe package works with 'PROJ6' geodetic objects and coordinate reference\n\tsystems.  "
  },
  {
    "id": 11805,
    "package_name": "ensembleBMA",
    "title": "Probabilistic Forecasting using Ensembles and Bayesian Model\nAveraging",
    "description": "Bayesian Model Averaging to create probabilistic forecasts\n        from ensemble forecasts and weather observations\n <https://stat.uw.edu/sites/default/files/files/reports/2007/tr516.pdf>.",
    "version": "5.1.8",
    "maintainer": "Chris Fraley <fraley@u.washington.edu>",
    "author": "Chris Fraley, Adrian E. Raftery, J. McLean Sloughter, Tilmann\n        Gneiting, University of Washington.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ensembleBMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ensembleBMA Probabilistic Forecasting using Ensembles and Bayesian Model\nAveraging Bayesian Model Averaging to create probabilistic forecasts\n        from ensemble forecasts and weather observations\n <https://stat.uw.edu/sites/default/files/files/reports/2007/tr516.pdf>.  "
  },
  {
    "id": 11806,
    "package_name": "ensembleMOS",
    "title": "Ensemble Model Output Statistics",
    "description": "Ensemble Model Output Statistics to create probabilistic\n        forecasts from ensemble forecasts and weather observations.",
    "version": "0.8.2",
    "maintainer": "Sandor Baran <baran.sandor@inf.unideb.hu>",
    "author": "RA Yuen, Sandor Baran, Chris Fraley, Tilmann Gneiting, Sebastian Lerch, Michael Scheuerer, Thordis Thorarinsdottir",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ensembleMOS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ensembleMOS Ensemble Model Output Statistics Ensemble Model Output Statistics to create probabilistic\n        forecasts from ensemble forecasts and weather observations.  "
  },
  {
    "id": 11808,
    "package_name": "ensemblepp",
    "title": "Ensemble Postprocessing Data Sets",
    "description": "Data sets for the chapter \"Ensemble Postprocessing with R\" of the book Stephane Vannitsem, Daniel S. Wilks, and Jakob W. Messner (2018) \"Statistical Postprocessing of Ensemble Forecasts\", Elsevier, 362pp. These data sets contain temperature and precipitation ensemble weather forecasts and corresponding observations at Innsbruck/Austria. Additionally, a demo with the full code of the book chapter is provided.",
    "version": "1.0-0",
    "maintainer": "Jakob Messner <jakob.messner@posteo.net>",
    "author": "Jakob Messner [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ensemblepp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ensemblepp Ensemble Postprocessing Data Sets Data sets for the chapter \"Ensemble Postprocessing with R\" of the book Stephane Vannitsem, Daniel S. Wilks, and Jakob W. Messner (2018) \"Statistical Postprocessing of Ensemble Forecasts\", Elsevier, 362pp. These data sets contain temperature and precipitation ensemble weather forecasts and corresponding observations at Innsbruck/Austria. Additionally, a demo with the full code of the book chapter is provided.  "
  },
  {
    "id": 11836,
    "package_name": "epe4md",
    "title": "EPE's 4MD Model to Forecast the Adoption of Distributed\nGeneration",
    "description": "EPE's (Empresa de Pesquisa Energ\u00e9tica) 4MD (Modelo de Mercado da Micro e Minigera\u00e7\u00e3o Distribu\u00edda - Micro and Mini Distributed Generation Market Model) model to forecast the adoption of Distributed Generation. Given the user's assumptions, it is possible to estimate how many consumer units will have distributed generation in Brazil over the next 10 years, for example. In addition, it is possible to estimate the installed capacity, the amount of investments that will be made in the country and the monthly energy contribution of this type of generation. <https://www.epe.gov.br/sites-pt/publicacoes-dados-abertos/publicacoes/PublicacoesArquivos/publicacao-689/topico-639/NT_Metodologia_4MD_PDE_2032_VF.pdf>.",
    "version": "0.1.4",
    "maintainer": "Gabriel Konzen <gabriel.konzen@epe.gov.br>",
    "author": "Gabriel Konzen [aut, cre],\n  Bruno Crotman [aut],\n  Jo\u00e3o Santos [aut],\n  Leticia Minini [aut],\n  Empresa de Pesquisa Energ\u00e9tica [cph, fnd]",
    "url": "https://epe-gov-br.github.io/epe4md/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=epe4md",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epe4md EPE's 4MD Model to Forecast the Adoption of Distributed\nGeneration EPE's (Empresa de Pesquisa Energ\u00e9tica) 4MD (Modelo de Mercado da Micro e Minigera\u00e7\u00e3o Distribu\u00edda - Micro and Mini Distributed Generation Market Model) model to forecast the adoption of Distributed Generation. Given the user's assumptions, it is possible to estimate how many consumer units will have distributed generation in Brazil over the next 10 years, for example. In addition, it is possible to estimate the installed capacity, the amount of investments that will be made in the country and the monthly energy contribution of this type of generation. <https://www.epe.gov.br/sites-pt/publicacoes-dados-abertos/publicacoes/PublicacoesArquivos/publicacao-689/topico-639/NT_Metodologia_4MD_PDE_2032_VF.pdf>.  "
  },
  {
    "id": 11839,
    "package_name": "epicasting",
    "title": "Ewnet: An Ensemble Wavelet Neural Network for Forecasting and\nEpicasting",
    "description": "Method and tool for generating time series forecasts using\n        an ensemble wavelet-based auto-regressive neural network architecture. This method provides\n        additional support of exogenous variables and also generates confidence interval. This \n        package provides EWNet model for time series forecasting based on the algorithm by\n        Panja, et al. (2022) and Panja, et al. (2023) <arXiv:2206.10696> <doi:10.1016/j.chaos.2023.113124>.          ",
    "version": "0.1.0",
    "maintainer": "Tanujit Chakraborty <tanujitisi@gmail.com>",
    "author": "Madhurima Panja [aut],\n  Tanujit Chakraborty [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=epicasting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epicasting Ewnet: An Ensemble Wavelet Neural Network for Forecasting and\nEpicasting Method and tool for generating time series forecasts using\n        an ensemble wavelet-based auto-regressive neural network architecture. This method provides\n        additional support of exogenous variables and also generates confidence interval. This \n        package provides EWNet model for time series forecasting based on the algorithm by\n        Panja, et al. (2022) and Panja, et al. (2023) <arXiv:2206.10696> <doi:10.1016/j.chaos.2023.113124>.            "
  },
  {
    "id": 11847,
    "package_name": "epigrowthfit",
    "title": "Nonlinear Mixed Effects Models of Epidemic Growth",
    "description": "\n\tMaximum likelihood estimation of nonlinear mixed effects models of\n\tepidemic growth using Template Model Builder ('TMB').  Enables\n\tjoint estimation for collections of disease incidence time series,\n\tincluding time series that describe multiple epidemic waves.\n\tSupports a set of widely used phenomenological models: exponential,\n\tlogistic, Richards (generalized logistic), subexponential,\n\tand Gompertz.  Provides methods for interrogating model objects\n\tand several auxiliary functions, including one for computing basic\n\treproduction numbers from fitted values of the initial exponential\n\tgrowth rate.\n\tPreliminary versions of this software were applied\n\tin Ma et al. (2014) <doi:10.1007/s11538-013-9918-2> and\n\tin Earn et al. (2020) <doi:10.1073/pnas.2004904117>.",
    "version": "0.15.4",
    "maintainer": "Mikael Jagan <jaganmn@mcmaster.ca>",
    "author": "Mikael Jagan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3542-2938>),\n  Ben Bolker [aut] (ORCID: <https://orcid.org/0000-0002-2127-0443>),\n  Jonathan Dushoff [ctb] (ORCID: <https://orcid.org/0000-0003-0506-4794>),\n  David Earn [ctb] (ORCID: <https://orcid.org/0000-0003-3597-617X>),\n  Junling Ma [ctb]",
    "url": "https://github.com/davidearn/epigrowthfit",
    "bug_reports": "https://github.com/davidearn/epigrowthfit/issues",
    "repository": "https://cran.r-project.org/package=epigrowthfit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epigrowthfit Nonlinear Mixed Effects Models of Epidemic Growth \n\tMaximum likelihood estimation of nonlinear mixed effects models of\n\tepidemic growth using Template Model Builder ('TMB').  Enables\n\tjoint estimation for collections of disease incidence time series,\n\tincluding time series that describe multiple epidemic waves.\n\tSupports a set of widely used phenomenological models: exponential,\n\tlogistic, Richards (generalized logistic), subexponential,\n\tand Gompertz.  Provides methods for interrogating model objects\n\tand several auxiliary functions, including one for computing basic\n\treproduction numbers from fitted values of the initial exponential\n\tgrowth rate.\n\tPreliminary versions of this software were applied\n\tin Ma et al. (2014) <doi:10.1007/s11538-013-9918-2> and\n\tin Earn et al. (2020) <doi:10.1073/pnas.2004904117>.  "
  },
  {
    "id": 11850,
    "package_name": "epimdr",
    "title": "Functions and Data for \"Epidemics: Models and Data in R\"",
    "description": "Functions, data sets and shiny apps for \"Epidemics: Models and Data in R\" by Ottar N. Bjornstad (ISBN 978-3-319-97487-3) <https://www.springer.com/gp/book/9783319974866>. The package contains functions to study the S(E)IR model, spatial and age-structured SIR models; time-series SIR and chain-binomial stochastic models; catalytic disease models; coupled map lattice models of spatial transmission and network models for social spread of infection. The package is also an advanced quantitative companion to the coursera Epidemics Massive Online Open Course <https://www.coursera.org/learn/epidemics>.",
    "version": "0.6-5",
    "maintainer": "Ottar N. Bjornstad <onb1@psu.edu>",
    "author": "Ottar N. Bjornstad [aut, cre]",
    "url": "https://github.com/objornstad/epimdr,\nhttps://www.springer.com/gp/book/9783319974866,\nhttp://ento.psu.edu/directory/onb1",
    "bug_reports": "https://github.com/objornstad/epimdr/issues",
    "repository": "https://cran.r-project.org/package=epimdr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epimdr Functions and Data for \"Epidemics: Models and Data in R\" Functions, data sets and shiny apps for \"Epidemics: Models and Data in R\" by Ottar N. Bjornstad (ISBN 978-3-319-97487-3) <https://www.springer.com/gp/book/9783319974866>. The package contains functions to study the S(E)IR model, spatial and age-structured SIR models; time-series SIR and chain-binomial stochastic models; catalytic disease models; coupled map lattice models of spatial transmission and network models for social spread of infection. The package is also an advanced quantitative companion to the coursera Epidemics Massive Online Open Course <https://www.coursera.org/learn/epidemics>.  "
  },
  {
    "id": 11863,
    "package_name": "epizootic",
    "title": "Spatially Explicit Population Models of Disease Transmission in\nWildlife",
    "description": "This extension of the pattern-oriented modeling framework of the \n    'poems' package provides a collection of modules and functions customized \n    for modeling disease transmission on a population scale in a spatiotemporally \n    explicit manner. This includes seasonal time steps, dispersal functions that \n    track disease state of dispersers, results objects that store disease states, \n    and a population simulator that includes disease dynamics.",
    "version": "2.0.0",
    "maintainer": "July Pilowsky <pilowskyj@caryinstitute.org>",
    "author": "July Pilowsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6376-2585>),\n  National Science Foundation Biology Integration Institute 2213854 [fnd]",
    "url": "https://github.com/viralemergence/epizootic",
    "bug_reports": "https://github.com/viralemergence/epizootic/issues",
    "repository": "https://cran.r-project.org/package=epizootic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epizootic Spatially Explicit Population Models of Disease Transmission in\nWildlife This extension of the pattern-oriented modeling framework of the \n    'poems' package provides a collection of modules and functions customized \n    for modeling disease transmission on a population scale in a spatiotemporally \n    explicit manner. This includes seasonal time steps, dispersal functions that \n    track disease state of dispersers, results objects that store disease states, \n    and a population simulator that includes disease dynamics.  "
  },
  {
    "id": 11919,
    "package_name": "esback",
    "title": "Expected Shortfall Backtesting",
    "description": "Implementations of the expected shortfall backtests of Bayer and Dimitriadis (2020) <doi:10.1093/jjfinec/nbaa013> \n    as well as other well known backtests from the literature. Can be used to assess the correctness of forecasts of the \n    expected shortfall risk measure which is e.g. used in the banking and finance industry for quantifying the market risk \n    of investments. A special feature of the backtests of  Bayer and Dimitriadis (2020) <doi:10.1093/jjfinec/nbaa013> \n    is that they only require forecasts of  the expected shortfall, which is in striking contrast to all other existing \n    backtests, making them particularly attractive for practitioners.",
    "version": "0.3.1",
    "maintainer": "Sebastian Bayer <sebastian.bayer@uni-konstanz.de>",
    "author": "Sebastian Bayer [aut, cre],\n  Timo Dimitriadis [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=esback",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "esback Expected Shortfall Backtesting Implementations of the expected shortfall backtests of Bayer and Dimitriadis (2020) <doi:10.1093/jjfinec/nbaa013> \n    as well as other well known backtests from the literature. Can be used to assess the correctness of forecasts of the \n    expected shortfall risk measure which is e.g. used in the banking and finance industry for quantifying the market risk \n    of investments. A special feature of the backtests of  Bayer and Dimitriadis (2020) <doi:10.1093/jjfinec/nbaa013> \n    is that they only require forecasts of  the expected shortfall, which is in striking contrast to all other existing \n    backtests, making them particularly attractive for practitioners.  "
  },
  {
    "id": 11926,
    "package_name": "esemifar",
    "title": "Smoothing Long-Memory Time Series",
    "description": "The nonparametric trend and its derivatives in equidistant time \n    series (TS) with long-memory errors can be estimated. The \n    estimation is conducted via local polynomial regression using an \n    automatically selected bandwidth obtained by a built-in iterative plug-in \n    algorithm or a bandwidth fixed by the user.\n    The smoothing methods of the package are described in Letmathe, S., Beran,\n    J. and Feng, Y., (2023) <doi:10.1080/03610926.2023.2276049>.",
    "version": "2.0.1",
    "maintainer": "Dominik Schulz <dominik.schulz@uni-paderborn.de>",
    "author": "Yuanhua Feng [aut] (Paderborn University, Germany),\n  Jan Beran [aut] (University of Konstanz, Germany),\n  Sebastian Letmathe [aut] (Paderborn University, Germany),\n  Dominik Schulz [aut, cre] (Paderborn University, Germany)",
    "url": "https://wiwi.uni-paderborn.de/en/dep4/feng/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=esemifar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "esemifar Smoothing Long-Memory Time Series The nonparametric trend and its derivatives in equidistant time \n    series (TS) with long-memory errors can be estimated. The \n    estimation is conducted via local polynomial regression using an \n    automatically selected bandwidth obtained by a built-in iterative plug-in \n    algorithm or a bandwidth fixed by the user.\n    The smoothing methods of the package are described in Letmathe, S., Beran,\n    J. and Feng, Y., (2023) <doi:10.1080/03610926.2023.2276049>.  "
  },
  {
    "id": 11936,
    "package_name": "estar",
    "title": "Ecological Stability Metrics",
    "description": "Standardises and facilitates the use of eleven established stability properties that have been used to assess systems\u2019 responses to press or pulse disturbances at different ecological levels (e.g. population, community). There are two sets of functions. The first set corresponds to functions that measure stability at any level of organisation, from individual to community and can be applied to a time series of a system\u2019s state variables (e.g., body mass, population abundance, or species diversity). The properties included in this set are: invariability, resistance, extent and rate of recovery, persistence, and overall ecological vulnerability. The second set of functions can be applied to Jacobian matrices. The functions in this set measure the stability of a community at short and long time scales. In the short term, the community\u2019s response is measured by maximal amplification, reactivity and initial resilience (i.e. initial rate of return to equilibrium). In the long term, stability can be measured as asymptotic resilience and intrinsic stochastic invariability. Figueiredo et al. (2025) <doi:10.32942/X2M053>.",
    "version": "1.0-1",
    "maintainer": "Ludmilla Figueiredo <ludmilla.figueiredo@protonmail.com>",
    "author": "Ludmilla Figueiredo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8217-7800>),\n  Viktoriia Radchuk [aut] (ORCID:\n    <https://orcid.org/0000-0003-3072-0095>),\n  C\u00e9dric Scherer [ctb] (ORCID: <https://orcid.org/0000-0003-0465-2543>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=estar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "estar Ecological Stability Metrics Standardises and facilitates the use of eleven established stability properties that have been used to assess systems\u2019 responses to press or pulse disturbances at different ecological levels (e.g. population, community). There are two sets of functions. The first set corresponds to functions that measure stability at any level of organisation, from individual to community and can be applied to a time series of a system\u2019s state variables (e.g., body mass, population abundance, or species diversity). The properties included in this set are: invariability, resistance, extent and rate of recovery, persistence, and overall ecological vulnerability. The second set of functions can be applied to Jacobian matrices. The functions in this set measure the stability of a community at short and long time scales. In the short term, the community\u2019s response is measured by maximal amplification, reactivity and initial resilience (i.e. initial rate of return to equilibrium). In the long term, stability can be measured as asymptotic resilience and intrinsic stochastic invariability. Figueiredo et al. (2025) <doi:10.32942/X2M053>.  "
  },
  {
    "id": 11976,
    "package_name": "evapoRe",
    "title": "Evapotranspiration R Recipes",
    "description": "An R-based application for exploratory data analysis of global EvapoTranspiration (ET) datasets. \n  'evapoRe' enables users to download, validate, visualize, and analyze multi-source ET data across various spatio-temporal scales.\n  Also, the package offers calculation methods for estimating potential ET (PET), including temperature-based, combined type, and radiation-based approaches described in : Oudin et al., (2005) <doi:10.1016/j.jhydrol.2004.08.026>.\n  'evapoRe' supports hydrological modeling, climate studies, agricultural research, and other data-driven fields by facilitating access to ET data and offering powerful analysis capabilities.\n  Users can seamlessly integrate the package into their research applications and explore diverse ET data at different resolutions.",
    "version": "1.0.1",
    "maintainer": "Akbar Rahmati Ziveh <rahmati_ziveh@fzp.czu.cz>",
    "author": "Akbar Rahmati Ziveh [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4854-451X>),\n  Mijael Rodrigo Vargas Godoy [aut] (ORCID:\n    <https://orcid.org/0000-0002-1828-9266>),\n  Vishal Thakur [ctb] (ORCID: <https://orcid.org/0000-0003-2864-9517>),\n  Yannis Markonis [aut, ths] (ORCID:\n    <https://orcid.org/0000-0003-0144-8969>)",
    "url": "https://github.com/AkbarR1184/evapoRe",
    "bug_reports": "https://github.com/AkbarR1184/evapoRe/issues",
    "repository": "https://cran.r-project.org/package=evapoRe",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "evapoRe Evapotranspiration R Recipes An R-based application for exploratory data analysis of global EvapoTranspiration (ET) datasets. \n  'evapoRe' enables users to download, validate, visualize, and analyze multi-source ET data across various spatio-temporal scales.\n  Also, the package offers calculation methods for estimating potential ET (PET), including temperature-based, combined type, and radiation-based approaches described in : Oudin et al., (2005) <doi:10.1016/j.jhydrol.2004.08.026>.\n  'evapoRe' supports hydrological modeling, climate studies, agricultural research, and other data-driven fields by facilitating access to ET data and offering powerful analysis capabilities.\n  Users can seamlessly integrate the package into their research applications and explore diverse ET data at different resolutions.  "
  },
  {
    "id": 12002,
    "package_name": "evoTS",
    "title": "Analyses of Evolutionary Time-Series",
    "description": "Facilitates univariate and multivariate analysis of evolutionary sequences of phenotypic change. The package extends the modeling framework available in the 'paleoTS' package. Please see <https://klvoje.github.io/evoTS/index.html> for information about the package and the implemented models. ",
    "version": "1.0.3",
    "maintainer": "Kjetil Lysne Voje <k.l.voje@nhm.uio.no>",
    "author": "Kjetil Lysne Voje [aut, cre]",
    "url": "https://klvoje.github.io/evoTS/index.html",
    "bug_reports": "https://github.com/klvoje/evoTS/issues",
    "repository": "https://cran.r-project.org/package=evoTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "evoTS Analyses of Evolutionary Time-Series Facilitates univariate and multivariate analysis of evolutionary sequences of phenotypic change. The package extends the modeling framework available in the 'paleoTS' package. Please see <https://klvoje.github.io/evoTS/index.html> for information about the package and the implemented models.   "
  },
  {
    "id": 12012,
    "package_name": "evsim",
    "title": "Electric Vehicle Charging Sessions Simulation",
    "description": "Simulation of Electric Vehicles charging sessions using Gaussian models, together with time-series power demand calculations.",
    "version": "1.7.0",
    "maintainer": "Marc Ca\u00f1igueral <marccanyigueral@gmail.com>",
    "author": "Marc Ca\u00f1igueral [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9724-5829>)",
    "url": "https://github.com/resourcefully-dev/evsim/,\nhttps://resourcefully-dev.github.io/evsim/",
    "bug_reports": "https://github.com/resourcefully-dev/evsim/issues",
    "repository": "https://cran.r-project.org/package=evsim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "evsim Electric Vehicle Charging Sessions Simulation Simulation of Electric Vehicles charging sessions using Gaussian models, together with time-series power demand calculations.  "
  },
  {
    "id": 12029,
    "package_name": "exams.forge",
    "title": "Support for Compiling Examination Tasks using the 'exams'\nPackage",
    "description": "The main aim is to further facilitate the creation of exercises based on the package 'exams' \n    by Gr\u00fcn, B., and Zeileis, A. (2009) <doi:10.18637/jss.v029.i10>. Creating effective student exercises \n    involves challenges such as creating appropriate data sets and ensuring access to intermediate values \n    for accurate explanation of solutions. The functionality includes the generation of univariate and \n    bivariate data including simple time series, functions for theoretical distributions and their approximation, \n    statistical and mathematical calculations for tasks in basic statistics courses as well as general tasks \n    such as string manipulation, LaTeX/HTML formatting and the editing of XML task files for 'Moodle'.",
    "version": "1.0.12",
    "maintainer": "Sigbert Klinke <sigbert@hu-berlin.de>",
    "author": "Sigbert Klinke [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3337-1863>),\n  Kleio Chrysopoulou Tseva [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=exams.forge",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exams.forge Support for Compiling Examination Tasks using the 'exams'\nPackage The main aim is to further facilitate the creation of exercises based on the package 'exams' \n    by Gr\u00fcn, B., and Zeileis, A. (2009) <doi:10.18637/jss.v029.i10>. Creating effective student exercises \n    involves challenges such as creating appropriate data sets and ensuring access to intermediate values \n    for accurate explanation of solutions. The functionality includes the generation of univariate and \n    bivariate data including simple time series, functions for theoretical distributions and their approximation, \n    statistical and mathematical calculations for tasks in basic statistics courses as well as general tasks \n    such as string manipulation, LaTeX/HTML formatting and the editing of XML task files for 'Moodle'.  "
  },
  {
    "id": 12041,
    "package_name": "exdex",
    "title": "Estimation of the Extremal Index",
    "description": "Performs frequentist inference for the extremal index of a \n    stationary time series.  Two types of methodology are used.  One type is\n    based on a model that relates the distribution of block maxima to the \n    marginal distribution of series and leads to the semiparametric maxima \n    estimators described in Northrop (2015) <doi:10.1007/s10687-015-0221-5> and \n    Berghaus and Bucher (2018) <doi:10.1214/17-AOS1621>.  Sliding block maxima\n    are used to increase precision of estimation. A graphical block size \n    diagnostic is provided.  The other type of methodology uses a model for the \n    distribution of threshold inter-exceedance times (Ferro and Segers (2003) \n    <doi:10.1111/1467-9868.00401>). Three versions of this type of approach are \n    provided: the iterated weight least squares approach of Suveges (2007) \n    <doi:10.1007/s10687-007-0034-2>, the K-gaps model of \n    Suveges and Davison (2010) <doi:10.1214/09-AOAS292> and a similar approach\n    of Holesovsky and Fusek (2020) <doi:10.1007/s10687-020-00374-3> \n    that we refer to as D-gaps. For the K-gaps and D-gaps models this package \n    allows missing values in the data, can accommodate independent subsets of \n    data, such as monthly or seasonal time series from different years, and can \n    incorporate information from right-censored inter-exceedance times.  \n    Graphical diagnostics for the threshold level and the respective tuning\n    parameters K and D are provided.",
    "version": "1.2.3",
    "maintainer": "Paul J. Northrop <p.northrop@ucl.ac.uk>",
    "author": "Paul J. Northrop [aut, cre, cph],\n  Constantinos Christodoulides [aut, cph]",
    "url": "https://github.com/paulnorthrop/exdex,\nhttps://paulnorthrop.github.io/exdex/",
    "bug_reports": "https://github.com/paulnorthrop/exdex/issues",
    "repository": "https://cran.r-project.org/package=exdex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exdex Estimation of the Extremal Index Performs frequentist inference for the extremal index of a \n    stationary time series.  Two types of methodology are used.  One type is\n    based on a model that relates the distribution of block maxima to the \n    marginal distribution of series and leads to the semiparametric maxima \n    estimators described in Northrop (2015) <doi:10.1007/s10687-015-0221-5> and \n    Berghaus and Bucher (2018) <doi:10.1214/17-AOS1621>.  Sliding block maxima\n    are used to increase precision of estimation. A graphical block size \n    diagnostic is provided.  The other type of methodology uses a model for the \n    distribution of threshold inter-exceedance times (Ferro and Segers (2003) \n    <doi:10.1111/1467-9868.00401>). Three versions of this type of approach are \n    provided: the iterated weight least squares approach of Suveges (2007) \n    <doi:10.1007/s10687-007-0034-2>, the K-gaps model of \n    Suveges and Davison (2010) <doi:10.1214/09-AOAS292> and a similar approach\n    of Holesovsky and Fusek (2020) <doi:10.1007/s10687-020-00374-3> \n    that we refer to as D-gaps. For the K-gaps and D-gaps models this package \n    allows missing values in the data, can accommodate independent subsets of \n    data, such as monthly or seasonal time series from different years, and can \n    incorporate information from right-censored inter-exceedance times.  \n    Graphical diagnostics for the threshold level and the respective tuning\n    parameters K and D are provided.  "
  },
  {
    "id": 12065,
    "package_name": "expsmooth",
    "title": "Data Sets from \"Forecasting with Exponential Smoothing\"",
    "description": "Data sets from the book \"Forecasting with exponential smoothing: the state space approach\" by \n\tHyndman, Koehler, Ord and Snyder (Springer, 2008).",
    "version": "2.3",
    "maintainer": "Rob J Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob J Hyndman <Rob.Hyndman@monash.edu>",
    "url": "https://github.com/robjhyndman/expsmooth",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=expsmooth",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "expsmooth Data Sets from \"Forecasting with Exponential Smoothing\" Data sets from the book \"Forecasting with exponential smoothing: the state space approach\" by \n\tHyndman, Koehler, Ord and Snyder (Springer, 2008).  "
  },
  {
    "id": 12076,
    "package_name": "extr",
    "title": "Extinction Risk Estimation",
    "description": "Estimates extinction risk from population time series under a\n    drifted Wiener process using the w-z method for accurate confidence\n    intervals.",
    "version": "1.0.0",
    "maintainer": "Hiroshi Hakoyama <hiroshi.hakoyama@gmail.com>",
    "author": "Hiroshi Hakoyama [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7464-0754>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=extr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "extr Extinction Risk Estimation Estimates extinction risk from population time series under a\n    drifted Wiener process using the w-z method for accurate confidence\n    intervals.  "
  },
  {
    "id": 12086,
    "package_name": "extremeIndex",
    "title": "Forecast Verification for Extreme Events",
    "description": "An index measuring the amount of information brought by forecasts for extreme events, subject to calibration, is computed. This index is originally designed for weather or climate forecasts, but it may be used in other forecasting contexts. This is the implementation of the index in Taillardat et al. (2019) <arXiv:1905.04022>.",
    "version": "0.0.3",
    "maintainer": "Maxime Taillardat <maxime.taillardat@meteo.fr>",
    "author": "Maxime Taillardat [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=extremeIndex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "extremeIndex Forecast Verification for Extreme Events An index measuring the amount of information brought by forecasts for extreme events, subject to calibration, is computed. This index is originally designed for weather or climate forecasts, but it may be used in other forecasting contexts. This is the implementation of the index in Taillardat et al. (2019) <arXiv:1905.04022>.  "
  },
  {
    "id": 12092,
    "package_name": "extremogram",
    "title": "Estimation of Extreme Value Dependence for Time Series Data",
    "description": "Estimation of the sample univariate, cross and return time extremograms. The package can also adds empirical confidence bands to each of the extremogram plots via a permutation procedure under the assumption that the data are independent. Finally, the stationary bootstrap allows us to construct credible confidence bands for the extremograms.  ",
    "version": "1.0.2",
    "maintainer": "Nadezda Frolova <nfrolova@ualberta.ca>",
    "author": "Nadezda Frolova, Ivor Cribben",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=extremogram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "extremogram Estimation of Extreme Value Dependence for Time Series Data Estimation of the sample univariate, cross and return time extremograms. The package can also adds empirical confidence bands to each of the extremogram plots via a permutation procedure under the assumption that the data are independent. Finally, the stationary bootstrap allows us to construct credible confidence bands for the extremograms.    "
  },
  {
    "id": 12093,
    "package_name": "exuber",
    "title": "Econometric Analysis of Explosive Time Series",
    "description": "Testing for and dating periods of explosive\n    dynamics (exuberance) in time series using the univariate and panel\n    recursive unit root tests proposed by Phillips et al. (2015)\n    <doi:10.1111/iere.12132> and Pavlidis et al. (2016)\n    <doi:10.1007/s11146-015-9531-2>.The recursive least-squares\n    algorithm utilizes the matrix inversion lemma to avoid matrix\n    inversion which results in significant speed improvements. Simulation\n    of a variety of periodically-collapsing bubble processes. Details can be \n    found in Vasilopoulos et al. (2022) <doi:10.18637/jss.v103.i10>.",
    "version": "1.1.0",
    "maintainer": "Kostas Vasilopoulos <k.vasilopoulo@gmail.com>",
    "author": "Kostas Vasilopoulos [cre, aut],\n  Efthymios Pavlidis [aut],\n  Enrique Mart\u00ednez-Garc\u00eda [aut],\n  Simon Spavound [aut]",
    "url": "https://kvasilopoulos.github.io/exuber/,\nhttps://github.com/kvasilopoulos/exuber",
    "bug_reports": "https://github.com/kvasilopoulos/exuber/issues",
    "repository": "https://cran.r-project.org/package=exuber",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exuber Econometric Analysis of Explosive Time Series Testing for and dating periods of explosive\n    dynamics (exuberance) in time series using the univariate and panel\n    recursive unit root tests proposed by Phillips et al. (2015)\n    <doi:10.1111/iere.12132> and Pavlidis et al. (2016)\n    <doi:10.1007/s11146-015-9531-2>.The recursive least-squares\n    algorithm utilizes the matrix inversion lemma to avoid matrix\n    inversion which results in significant speed improvements. Simulation\n    of a variety of periodically-collapsing bubble processes. Details can be \n    found in Vasilopoulos et al. (2022) <doi:10.18637/jss.v103.i10>.  "
  },
  {
    "id": 12121,
    "package_name": "fEGarch",
    "title": "SM/LM EGARCH & GARCH, VaR/ES Backtesting & Dual LM Extensions",
    "description": "Implement and fit a variety of short-memory (SM) and long-memory\n  (LM) models from a very broad family of exponential generalized autoregressive\n  conditional heteroskedasticity (EGARCH) models, such as a MEGARCH (modified\n  EGARCH), FIEGARCH (fractionally integrated EGARCH), FIMLog-GARCH (fractionally\n  integrated modulus Log-GARCH), and more. The FIMLog-GARCH as part of the\n  EGARCH family is discussed in Feng et al. (2023)\n  <https://econpapers.repec.org/paper/pdnciepap/156.htm>. For convenience and\n  the purpose of comparison, a variety of other popular SM and LM GARCH-type\n  models, like an APARCH model, a fractionally integrated\n  APARCH (FIAPARCH) model, standard GARCH and fractionally integrated GARCH\n  (FIGARCH) models, GJR-GARCH and FIGJR-GARCH models, TGARCH and FITGARCH\n  models, are implemented as well as dual models with simultaneous modelling of\n  the mean, including dual long-memory models with a fractionally integrated\n  autoregressive moving average (FARIMA) model in the mean and a long-memory\n  model in the variance, and semiparametric volatility model extensions.\n  Parametric models and parametric model parts are fitted through\n  quasi-maximum-likelihood estimation.\n  Furthermore, common forecasting and backtesting functions for value-at-risk\n  (VaR) and expected shortfall (ES) based on the package's models are provided.",
    "version": "1.0.3",
    "maintainer": "Dominik Schulz <dominik.schulz@uni-paderborn.de>",
    "author": "Dominik Schulz [aut, cre] (Paderborn University, Germany),\n  Yuanhua Feng [aut] (Paderborn University, Germany),\n  Christian Peitz [aut] (Financial Intelligence Unit (German Government)),\n  Oliver Kojo Ayensu [aut] (Paderborn University, Germany),\n  Thomas Gries [ctb] (Paderborn University, Germany),\n  Sikandar Siddiqui [ctb] (Deloitte Audit Analytics GmbH, Frankfurt,\n    Germany),\n  Shujie Li [ctb] (Paderborn University, Germany)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fEGarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fEGarch SM/LM EGARCH & GARCH, VaR/ES Backtesting & Dual LM Extensions Implement and fit a variety of short-memory (SM) and long-memory\n  (LM) models from a very broad family of exponential generalized autoregressive\n  conditional heteroskedasticity (EGARCH) models, such as a MEGARCH (modified\n  EGARCH), FIEGARCH (fractionally integrated EGARCH), FIMLog-GARCH (fractionally\n  integrated modulus Log-GARCH), and more. The FIMLog-GARCH as part of the\n  EGARCH family is discussed in Feng et al. (2023)\n  <https://econpapers.repec.org/paper/pdnciepap/156.htm>. For convenience and\n  the purpose of comparison, a variety of other popular SM and LM GARCH-type\n  models, like an APARCH model, a fractionally integrated\n  APARCH (FIAPARCH) model, standard GARCH and fractionally integrated GARCH\n  (FIGARCH) models, GJR-GARCH and FIGJR-GARCH models, TGARCH and FITGARCH\n  models, are implemented as well as dual models with simultaneous modelling of\n  the mean, including dual long-memory models with a fractionally integrated\n  autoregressive moving average (FARIMA) model in the mean and a long-memory\n  model in the variance, and semiparametric volatility model extensions.\n  Parametric models and parametric model parts are fitted through\n  quasi-maximum-likelihood estimation.\n  Furthermore, common forecasting and backtesting functions for value-at-risk\n  (VaR) and expected shortfall (ES) based on the package's models are provided.  "
  },
  {
    "id": 12122,
    "package_name": "fHMM",
    "title": "Fitting Hidden Markov Models to Financial Data",
    "description": "Fitting (hierarchical) hidden Markov models to financial data\n    via maximum likelihood estimation. See Oelschl\u00e4ger, L. and Adam, T.\n    \"Detecting Bearish and Bullish Markets in Financial Time Series Using \n    Hierarchical Hidden Markov Models\" (2021, Statistical Modelling) \n    <doi:10.1177/1471082X211034048> for a reference on the method. A user guide \n    is provided by the accompanying software paper \"fHMM: Hidden Markov Models \n    for Financial Time Series in R\", Oelschl\u00e4ger, L., Adam, T., and Michels, R.\n    (2024, Journal of Statistical Software)  <doi:10.18637/jss.v109.i09>.",
    "version": "1.4.2",
    "maintainer": "Lennart Oelschl\u00e4ger <oelschlaeger.lennart@gmail.com>",
    "author": "Lennart Oelschl\u00e4ger [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5421-9313>),\n  Timo Adam [aut] (ORCID: <https://orcid.org/0000-0001-9079-3259>),\n  Rouven Michels [aut] (ORCID: <https://orcid.org/0000-0002-5433-6197>)",
    "url": "https://loelschlaeger.de/fHMM/",
    "bug_reports": "https://github.com/loelschlaeger/fHMM/issues",
    "repository": "https://cran.r-project.org/package=fHMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fHMM Fitting Hidden Markov Models to Financial Data Fitting (hierarchical) hidden Markov models to financial data\n    via maximum likelihood estimation. See Oelschl\u00e4ger, L. and Adam, T.\n    \"Detecting Bearish and Bullish Markets in Financial Time Series Using \n    Hierarchical Hidden Markov Models\" (2021, Statistical Modelling) \n    <doi:10.1177/1471082X211034048> for a reference on the method. A user guide \n    is provided by the accompanying software paper \"fHMM: Hidden Markov Models \n    for Financial Time Series in R\", Oelschl\u00e4ger, L., Adam, T., and Michels, R.\n    (2024, Journal of Statistical Software)  <doi:10.18637/jss.v109.i09>.  "
  },
  {
    "id": 12125,
    "package_name": "fMRItools",
    "title": "Routines for Common fMRI Processing Tasks",
    "description": "Supports fMRI (functional magnetic resonance imaging) \n    analysis tasks including reading in 'CIFTI', 'GIFTI' and \n    'NIFTI' data, temporal filtering, nuisance regression, and \n    aCompCor (anatomical Components Correction) (Muschelli et al.\n    (2014) <doi:10.1016/j.neuroimage.2014.03.028>).",
    "version": "0.6.0",
    "maintainer": "Amanda Mejia <mandy.mejia@gmail.com>",
    "author": "Amanda Mejia [aut, cre],\n  Damon Pham [aut] (ORCID: <https://orcid.org/0000-0001-7563-4727>),\n  Mark Fiecas [ctb]",
    "url": "https://github.com/mandymejia/fMRItools",
    "bug_reports": "https://github.com/mandymejia/fMRItools/issues",
    "repository": "https://cran.r-project.org/package=fMRItools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fMRItools Routines for Common fMRI Processing Tasks Supports fMRI (functional magnetic resonance imaging) \n    analysis tasks including reading in 'CIFTI', 'GIFTI' and \n    'NIFTI' data, temporal filtering, nuisance regression, and \n    aCompCor (anatomical Components Correction) (Muschelli et al.\n    (2014) <doi:10.1016/j.neuroimage.2014.03.028>).  "
  },
  {
    "id": 12127,
    "package_name": "fNonlinear",
    "title": "Rmetrics - Nonlinear and Chaotic Time Series Modelling",
    "description": "Provides a collection of functions for testing various aspects of\n\tunivariate time series including independence and neglected\n\tnonlinearities. Further provides functions to investigate the chaotic\n\tbehavior of time series processes and to simulate different types of chaotic\n\ttime series maps.",
    "version": "4041.82",
    "maintainer": "Paul Smith <paul@waternumbers.co.uk>",
    "author": "Diethelm Wuertz [aut],\n  Tobias Setz [aut],\n  Yohan Chalabi [aut],\n  Paul Smith [cre]",
    "url": "https://www.rmetrics.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fNonlinear",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fNonlinear Rmetrics - Nonlinear and Chaotic Time Series Modelling Provides a collection of functions for testing various aspects of\n\tunivariate time series including independence and neglected\n\tnonlinearities. Further provides functions to investigate the chaotic\n\tbehavior of time series processes and to simulate different types of chaotic\n\ttime series maps.  "
  },
  {
    "id": 12131,
    "package_name": "fTrading",
    "title": "Rmetrics - Trading and Rebalancing Financial Instruments",
    "description": "A collection of functions for trading and rebalancing financial\n\tinstruments. It implements various technical indicators to analyse time series such\n\tas moving averages or stochastic oscillators.",
    "version": "3042.79",
    "maintainer": "Tobias Setz <tobias.setz@live.com>",
    "author": "Diethelm Wuertz [aut],\n\tTobias Setz [cre],\n\tYohan Chalabi [ctb]",
    "url": "http://www.rmetrics.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fTrading",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fTrading Rmetrics - Trading and Rebalancing Financial Instruments A collection of functions for trading and rebalancing financial\n\tinstruments. It implements various technical indicators to analyse time series such\n\tas moving averages or stochastic oscillators.  "
  },
  {
    "id": 12136,
    "package_name": "fabisearch",
    "title": "Change Point Detection in High-Dimensional Time Series Networks",
    "description": "Implementation of the Factorized Binary Search (FaBiSearch) methodology for the estimation of the number and the location of multiple change points in the network (or clustering) structure of multivariate high-dimensional time series. The method is motivated by the detection of change points in functional connectivity networks for functional magnetic resonance imaging (fMRI) data. FaBiSearch uses non-negative matrix factorization (NMF), an unsupervised dimension reduction technique, and a new binary search algorithm to identify multiple change points.  It requires minimal assumptions. Lastly, we provide interactive, 3-dimensional, brain-specific network visualization capability in a flexible, stand-alone function. This function can be conveniently used with any node coordinate atlas, and nodes can be color coded according to community membership, if applicable. The output is an elegantly displayed network laid over a cortical surface, which can be rotated in the 3-dimensional space. The main routines of the package are detect.cps(), for multiple change point detection, est.net(), for estimating a network between stationary multivariate time series, net.3dplot(), for plotting the estimated functional connectivity networks, and opt.rank(), for finding the optimal rank in NMF for a given data set. The functions have been extensively tested on simulated multivariate high-dimensional time series data and fMRI data. For details on the FaBiSearch methodology, please see Ondrus et al. (2021) <arXiv:2103.06347>. For a more detailed explanation and applied examples of the fabisearch package, please see Ondrus and Cribben (2022), preprint.",
    "version": "0.0.4.5",
    "maintainer": "Martin Ondrus <mondrus@ualberta.ca>",
    "author": "Martin Ondrus [aut, cre],\n  Ivor Cribben [aut]",
    "url": "https://github.com/mondrus96/FaBiSearch",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fabisearch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fabisearch Change Point Detection in High-Dimensional Time Series Networks Implementation of the Factorized Binary Search (FaBiSearch) methodology for the estimation of the number and the location of multiple change points in the network (or clustering) structure of multivariate high-dimensional time series. The method is motivated by the detection of change points in functional connectivity networks for functional magnetic resonance imaging (fMRI) data. FaBiSearch uses non-negative matrix factorization (NMF), an unsupervised dimension reduction technique, and a new binary search algorithm to identify multiple change points.  It requires minimal assumptions. Lastly, we provide interactive, 3-dimensional, brain-specific network visualization capability in a flexible, stand-alone function. This function can be conveniently used with any node coordinate atlas, and nodes can be color coded according to community membership, if applicable. The output is an elegantly displayed network laid over a cortical surface, which can be rotated in the 3-dimensional space. The main routines of the package are detect.cps(), for multiple change point detection, est.net(), for estimating a network between stationary multivariate time series, net.3dplot(), for plotting the estimated functional connectivity networks, and opt.rank(), for finding the optimal rank in NMF for a given data set. The functions have been extensively tested on simulated multivariate high-dimensional time series data and fMRI data. For details on the FaBiSearch methodology, please see Ondrus et al. (2021) <arXiv:2103.06347>. For a more detailed explanation and applied examples of the fabisearch package, please see Ondrus and Cribben (2022), preprint.  "
  },
  {
    "id": 12137,
    "package_name": "fable",
    "title": "Forecasting Models for Tidy Time Series",
    "description": "Provides a collection of commonly used univariate and multivariate\n    time series forecasting models including automatically selected exponential \n    smoothing (ETS) and autoregressive integrated moving average (ARIMA) models.\n    These models work within the 'fable' framework provided by the 'fabletools'\n    package, which provides the tools to evaluate, visualise, and combine models \n    in a workflow consistent with the tidyverse.",
    "version": "0.4.1",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre],\n  Rob Hyndman [aut],\n  Earo Wang [aut],\n  Gabriel Caceres [ctb] (NNETAR implementation),\n  Christoph Bergmeir [ctb] (ORCID:\n    <https://orcid.org/0000-0002-3665-9021>),\n  Tim-Gunnar Hensel [ctb],\n  Timothy Hyndman [ctb]",
    "url": "https://fable.tidyverts.org, https://github.com/tidyverts/fable",
    "bug_reports": "https://github.com/tidyverts/fable/issues",
    "repository": "https://cran.r-project.org/package=fable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fable Forecasting Models for Tidy Time Series Provides a collection of commonly used univariate and multivariate\n    time series forecasting models including automatically selected exponential \n    smoothing (ETS) and autoregressive integrated moving average (ARIMA) models.\n    These models work within the 'fable' framework provided by the 'fabletools'\n    package, which provides the tools to evaluate, visualise, and combine models \n    in a workflow consistent with the tidyverse.  "
  },
  {
    "id": 12138,
    "package_name": "fable.ata",
    "title": "'ATAforecasting' Modelling Interface for 'fable' Framework",
    "description": "Allows ATA (Automatic Time series analysis using the Ata method) models from the 'ATAforecasting' package to be used in a tidy workflow with the modeling interface of\n    'fabletools'. This extends 'ATAforecasting' to provide enhanced model specification and management, performance evaluation methods, and\n    model combination tools. The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016)\n    <doi:10.15672/HJMS.201614320580>, Yapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides\n    innovative solutions to issues faced during the initialization and optimization stages of existing forecasting methods.\n    Forecasting performance of the Ata method is superior to existing methods both in terms of easy implementation and accurate forecasting.\n    It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend and seasonal).",
    "version": "0.0.6",
    "maintainer": "Ali Sabri Taylan <alisabritaylan@gmail.com>",
    "author": "Ali Sabri Taylan [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9514-934X>),\n  Hanife Taylan Selamlar [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-4091-884X>),\n  Guckan Yapar [aut, ths, cph] (ORCID:\n    <https://orcid.org/0000-0002-0971-6676>)",
    "url": "https://alsabtay.github.io/fable.ata/",
    "bug_reports": "https://github.com/alsabtay/fable.ata/issues",
    "repository": "https://cran.r-project.org/package=fable.ata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fable.ata 'ATAforecasting' Modelling Interface for 'fable' Framework Allows ATA (Automatic Time series analysis using the Ata method) models from the 'ATAforecasting' package to be used in a tidy workflow with the modeling interface of\n    'fabletools'. This extends 'ATAforecasting' to provide enhanced model specification and management, performance evaluation methods, and\n    model combination tools. The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016)\n    <doi:10.15672/HJMS.201614320580>, Yapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides\n    innovative solutions to issues faced during the initialization and optimization stages of existing forecasting methods.\n    Forecasting performance of the Ata method is superior to existing methods both in terms of easy implementation and accurate forecasting.\n    It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend and seasonal).  "
  },
  {
    "id": 12139,
    "package_name": "fable.prophet",
    "title": "Prophet Modelling Interface for 'fable'",
    "description": "Allows prophet models from the 'prophet' package to be used in a tidy workflow with the modelling interface of 'fabletools'. This extends 'prophet' to provide enhanced model specification and management, performance evaluation methods, and model combination tools.",
    "version": "0.1.0",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre],\n  Sean Taylor [ctb] (Prophet library,\n    https://facebook.github.io/prophet/),\n  Ben Letham [ctb] (Prophet library, https://facebook.github.io/prophet/)",
    "url": "https://pkg.mitchelloharawild.com/fable.prophet/",
    "bug_reports": "https://github.com/mitchelloharawild/fable.prophet/issues",
    "repository": "https://cran.r-project.org/package=fable.prophet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fable.prophet Prophet Modelling Interface for 'fable' Allows prophet models from the 'prophet' package to be used in a tidy workflow with the modelling interface of 'fabletools'. This extends 'prophet' to provide enhanced model specification and management, performance evaluation methods, and model combination tools.  "
  },
  {
    "id": 12140,
    "package_name": "fableCount",
    "title": "INGARCH and GLARMA Models for Count Time Series in Fable\nFramework",
    "description": "Provides a tidy R interface for count time series analysis. It includes implementation of the INGARCH (Integer Generalized Autoregressive Conditional Heteroskedasticity) model from the 'tscount' package and the GLARMA (Generalized Linear Autoregressive Moving Averages) model from the 'glarma' package. Additionally, it offers automated parameter selection algorithms based on the minimization of a penalized likelihood.",
    "version": "0.1.0",
    "maintainer": "Gustavo Almeida <gustavoalmeidasilva@ice.ufjf.br>",
    "author": "Gustavo Almeida [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-7266-5866>),\n  Marcel Vieira [aut] (ORCID: <https://orcid.org/0000-0002-0456-380X>),\n  Conselho Nacional de Desenvolvimento Cient\u00edfico e Tecnol\u00f3gico - CNPq\n    [fnd],\n  JFSalvando Todos - Plataforma de An\u00e1lises Estat\u00edsticas [fnd, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fableCount",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fableCount INGARCH and GLARMA Models for Count Time Series in Fable\nFramework Provides a tidy R interface for count time series analysis. It includes implementation of the INGARCH (Integer Generalized Autoregressive Conditional Heteroskedasticity) model from the 'tscount' package and the GLARMA (Generalized Linear Autoregressive Moving Averages) model from the 'glarma' package. Additionally, it offers automated parameter selection algorithms based on the minimization of a penalized likelihood.  "
  },
  {
    "id": 12141,
    "package_name": "fabletools",
    "title": "Core Tools for Packages in the 'fable' Framework",
    "description": "Provides tools, helpers and data structures for\n    developing models and time series functions for 'fable' and extension\n    packages. These tools support a consistent and tidy interface for time\n    series modelling and analysis.",
    "version": "0.5.1",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Rob Hyndman [aut],\n  Earo Wang [aut] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Di Cook [ctb],\n  George Athanasopoulos [ctb],\n  David Holt [ctb]",
    "url": "https://fabletools.tidyverts.org/,\nhttps://github.com/tidyverts/fabletools",
    "bug_reports": "https://github.com/tidyverts/fabletools/issues",
    "repository": "https://cran.r-project.org/package=fabletools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fabletools Core Tools for Packages in the 'fable' Framework Provides tools, helpers and data structures for\n    developing models and time series functions for 'fable' and extension\n    packages. These tools support a consistent and tidy interface for time\n    series modelling and analysis.  "
  },
  {
    "id": 12152,
    "package_name": "facmodTS",
    "title": "Time Series Factor Models for Asset Returns",
    "description": "Supports teaching methods of estimating and testing time series\n    factor models for use in robust portfolio construction and analysis. Unique\n    in providing not only classical least squares, but also modern robust model\n    fitting methods which are not much influenced by outliers. Includes\n    returns and risk decompositions, with user choice of  standard deviation,\n    value-at-risk, and expected shortfall risk measures. \"Robust Statistics\n    Theory and Methods (with R)\", R. A. Maronna, R. D. Martin, V. J. Yohai, \n    M. Salibian-Barrera (2019) <doi:10.1002/9781119214656>.",
    "version": "1.0",
    "maintainer": "Doug Martin <martinrd3d@gmail.com>",
    "author": "Doug Martin [cre, aut],\n  Eric Zivot [aut],\n  Sangeetha Srinivasan [aut],\n  Avinash Acharya [ctb],\n  Yi-An Chen [ctb],\n  Kirk Li [ctb],\n  Lingjie Yi [ctb],\n  Justin Shea [ctb],\n  Mido Shammaa [ctb],\n  Jon Spinney [ctb]",
    "url": "https://github.com/robustport/facmodTS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=facmodTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "facmodTS Time Series Factor Models for Asset Returns Supports teaching methods of estimating and testing time series\n    factor models for use in robust portfolio construction and analysis. Unique\n    in providing not only classical least squares, but also modern robust model\n    fitting methods which are not much influenced by outliers. Includes\n    returns and risk decompositions, with user choice of  standard deviation,\n    value-at-risk, and expected shortfall risk measures. \"Robust Statistics\n    Theory and Methods (with R)\", R. A. Maronna, R. D. Martin, V. J. Yohai, \n    M. Salibian-Barrera (2019) <doi:10.1002/9781119214656>.  "
  },
  {
    "id": 12166,
    "package_name": "factree",
    "title": "Factor-Augmented Clustering Tree",
    "description": "Implements the Factor-Augmented Clustering Tree (FACT) algorithm\n    for clustering time series data. The method constructs a classification \n    tree where splits are determined by covariates, and the splitting criterion\n    is based on a group factor model representation of the time series within \n    each node. Both threshold-based and permutation-based tests are supported \n    for splitting decisions, with an option for parallel computation.\n    For methodological details, see Hu, Li, Luo, and Wang (2025, in preparation), \n    Factor-Augmented Clustering Tree for Time Series.",
    "version": "0.1.0",
    "maintainer": "Jiaqi Hu <hujiaqi@mail.ustc.edu.cn>",
    "author": "Jiaqi Hu [cre, aut],\n  Ting Li [ctb] (Assisted with methodology),\n  Zidan Luo [ctb] (Assisted with methodology),\n  Xueqin Wang [ctb] (Assisted with methodology)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=factree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "factree Factor-Augmented Clustering Tree Implements the Factor-Augmented Clustering Tree (FACT) algorithm\n    for clustering time series data. The method constructs a classification \n    tree where splits are determined by covariates, and the splitting criterion\n    is based on a group factor model representation of the time series within \n    each node. Both threshold-based and permutation-based tests are supported \n    for splitting decisions, with an option for parallel computation.\n    For methodological details, see Hu, Li, Luo, and Wang (2025, in preparation), \n    Factor-Augmented Clustering Tree for Time Series.  "
  },
  {
    "id": 12222,
    "package_name": "fastTS",
    "title": "Fast Time Series Modeling for Seasonal Series with Exogenous\nVariables",
    "description": "An implementation of sparsity-ranked lasso and related methods \n    for time series data. This methodology is especially useful for \n    large time series with exogenous features and/or complex \n    seasonality. Originally described in Peterson and Cavanaugh \n    (2022) <doi:10.1007/s10182-021-00431-7> in the context of variable \n    selection with interactions and/or polynomials, ranked sparsity is \n    a philosophy with methods useful for variable selection in the \n    presence of prior informational asymmetry. This situation exists for time \n    series data with complex seasonality, as shown in Peterson and Cavanaugh \n    (2024) <doi:10.1177/1471082X231225307>, which also describes this package\n    in greater detail. The sparsity-ranked penalization methods for time series\n    implemented in 'fastTS' can fit large/complex/high-frequency time series\n    quickly, even with a high-dimensional exogenous feature set. The method is\n    considerably faster than its competitors, while often producing more \n    accurate predictions. Also included is a long hourly series of arrivals \n    into the University of Iowa Emergency Department with concurrent local \n    temperature.",
    "version": "1.0.3",
    "maintainer": "Ryan Andrew Peterson <ryan-peterson@uiowa.edu>",
    "author": "Ryan Andrew Peterson [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4650-5798>)",
    "url": "https://petersonr.github.io/fastTS/,\nhttps://github.com/petersonR/fastTS/",
    "bug_reports": "https://github.com/petersonR/fastTS/issues",
    "repository": "https://cran.r-project.org/package=fastTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastTS Fast Time Series Modeling for Seasonal Series with Exogenous\nVariables An implementation of sparsity-ranked lasso and related methods \n    for time series data. This methodology is especially useful for \n    large time series with exogenous features and/or complex \n    seasonality. Originally described in Peterson and Cavanaugh \n    (2022) <doi:10.1007/s10182-021-00431-7> in the context of variable \n    selection with interactions and/or polynomials, ranked sparsity is \n    a philosophy with methods useful for variable selection in the \n    presence of prior informational asymmetry. This situation exists for time \n    series data with complex seasonality, as shown in Peterson and Cavanaugh \n    (2024) <doi:10.1177/1471082X231225307>, which also describes this package\n    in greater detail. The sparsity-ranked penalization methods for time series\n    implemented in 'fastTS' can fit large/complex/high-frequency time series\n    quickly, even with a high-dimensional exogenous feature set. The method is\n    considerably faster than its competitors, while often producing more \n    accurate predictions. Also included is a long hourly series of arrivals \n    into the University of Iowa Emergency Department with concurrent local \n    temperature.  "
  },
  {
    "id": 12226,
    "package_name": "fastWavelets",
    "title": "Compute Maximal Overlap Discrete Wavelet Transform (MODWT) and \u00c0\nTrous Discrete Wavelet Transform",
    "description": "A lightweight package to compute Maximal Overlap Discrete Wavelet \n    Transform (MODWT) and \u00c0 Trous Discrete Wavelet Transform by leveraging the \n    power of 'Rcpp' to make these operations fast. This package was designed for use in forecasting, and\n    allows users avoid the inclusion of future data when performing wavelet decomposition of time series.\n    See Quilty and Adamowski (2018) <doi:10.1016/j.jhydrol.2018.05.003>.",
    "version": "1.0.1",
    "maintainer": "John You <johnswyou@gmail.com>",
    "author": "John Quilty [aut] (ORCID: <https://orcid.org/0000-0002-0207-8077>),\n  John You [aut, cre] (ORCID: <https://orcid.org/0000-0002-3509-0312>)",
    "url": "https://github.com/johnswyou/fastWavelets",
    "bug_reports": "https://github.com/johnswyou/fastWavelets/issues",
    "repository": "https://cran.r-project.org/package=fastWavelets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastWavelets Compute Maximal Overlap Discrete Wavelet Transform (MODWT) and \u00c0\nTrous Discrete Wavelet Transform A lightweight package to compute Maximal Overlap Discrete Wavelet \n    Transform (MODWT) and \u00c0 Trous Discrete Wavelet Transform by leveraging the \n    power of 'Rcpp' to make these operations fast. This package was designed for use in forecasting, and\n    allows users avoid the inclusion of future data when performing wavelet decomposition of time series.\n    See Quilty and Adamowski (2018) <doi:10.1016/j.jhydrol.2018.05.003>.  "
  },
  {
    "id": 12229,
    "package_name": "fastai",
    "title": "Interface to 'fastai'",
    "description": "The 'fastai' <https://docs.fast.ai/index.html> library \n             simplifies training fast and accurate neural networks \n             using modern best practices. It is based on research \n             in to deep learning best practices undertaken \n             at 'fast.ai', including 'out of the box' support\n             for vision, text, tabular, audio, time series, and \n             collaborative filtering models. ",
    "version": "2.2.2",
    "maintainer": "Turgut Abdullayev <turqut.a.314@gmail.com>",
    "author": "Turgut Abdullayev [ctb, cre, cph, aut]",
    "url": "https://github.com/EagerAI/fastai",
    "bug_reports": "https://github.com/EagerAI/fastai/issues",
    "repository": "https://cran.r-project.org/package=fastai",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastai Interface to 'fastai' The 'fastai' <https://docs.fast.ai/index.html> library \n             simplifies training fast and accurate neural networks \n             using modern best practices. It is based on research \n             in to deep learning best practices undertaken \n             at 'fast.ai', including 'out of the box' support\n             for vision, text, tabular, audio, time series, and \n             collaborative filtering models.   "
  },
  {
    "id": 12231,
    "package_name": "fastbeta",
    "title": "Fast Approximation of Time-Varying Infectious Disease\nTransmission Rates",
    "description": "\n\tA fast method for approximating time-varying infectious disease\n\ttransmission rates from disease incidence time series and other\n\tdata, based on a discrete time approximation of an SEIR model, as\n\tanalyzed in Jagan et al. (2020) <doi:10.1371/journal.pcbi.1008124>.",
    "version": "0.5.1",
    "maintainer": "Mikael Jagan <jaganmn@mcmaster.ca>",
    "author": "Mikael Jagan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3542-2938>),\n  David Earn [ctb] (ORCID: <https://orcid.org/0000-0003-3597-617X>)",
    "url": "https://github.com/davidearn/fastbeta",
    "bug_reports": "https://github.com/davidearn/fastbeta/issues",
    "repository": "https://cran.r-project.org/package=fastbeta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastbeta Fast Approximation of Time-Varying Infectious Disease\nTransmission Rates \n\tA fast method for approximating time-varying infectious disease\n\ttransmission rates from disease incidence time series and other\n\tdata, based on a discrete time approximation of an SEIR model, as\n\tanalyzed in Jagan et al. (2020) <doi:10.1371/journal.pcbi.1008124>.  "
  },
  {
    "id": 12267,
    "package_name": "fastverse",
    "title": "A Suite of High-Performance Packages for Statistics and Data\nManipulation",
    "description": "Easy installation, loading and management, of high-performance packages \n             for statistical computing and data manipulation in R. \n             The core 'fastverse' consists of 4 packages: 'data.table', 'collapse', \n             'kit' and 'magrittr', that jointly only depend on 'Rcpp'. \n             The 'fastverse' can be freely and permanently extended with \n             additional packages, both globally or for individual projects. \n             Separate package verses can also be created. Fast packages \n             for many common tasks such as time series, dates and times, strings, \n             spatial data, statistics, data serialization, larger-than-memory \n             processing, and compilation of R code are listed in the README file: \n             <https://github.com/fastverse/fastverse#suggested-extensions>.",
    "version": "0.3.4",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre],\n  Hadley Wickham [ctb]",
    "url": "https://fastverse.github.io/fastverse/,\nhttps://fastverse.r-universe.dev/, https://github.com/fastverse",
    "bug_reports": "https://github.com/fastverse/fastverse/issues",
    "repository": "https://cran.r-project.org/package=fastverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastverse A Suite of High-Performance Packages for Statistics and Data\nManipulation Easy installation, loading and management, of high-performance packages \n             for statistical computing and data manipulation in R. \n             The core 'fastverse' consists of 4 packages: 'data.table', 'collapse', \n             'kit' and 'magrittr', that jointly only depend on 'Rcpp'. \n             The 'fastverse' can be freely and permanently extended with \n             additional packages, both globally or for individual projects. \n             Separate package verses can also be created. Fast packages \n             for many common tasks such as time series, dates and times, strings, \n             spatial data, statistics, data serialization, larger-than-memory \n             processing, and compilation of R code are listed in the README file: \n             <https://github.com/fastverse/fastverse#suggested-extensions>.  "
  },
  {
    "id": 12302,
    "package_name": "fdaACF",
    "title": "Autocorrelation Function for Functional Time Series",
    "description": "Quantify the serial correlation across lags of a given functional \n    time series using the autocorrelation function and a partial autocorrelation\n    function for functional time series proposed in \n    Mestre et al. (2021) <doi:10.1016/j.csda.2020.107108>.\n    The autocorrelation functions are based on the L2 norm of the lagged covariance \n    operators of the series. Functions are available for estimating the \n    distribution of the autocorrelation functions under the assumption \n    of strong functional white noise.",
    "version": "1.0.0",
    "maintainer": "Guillermo Mestre Marcos <guillermo.mestre@comillas.edu>",
    "author": "Guillermo Mestre Marcos [aut, cre],\n  Jos\u00e9 Portela Gonz\u00e1lez [aut],\n  Gregory Rice [aut],\n  Antonio Mu\u00f1oz San Roque [ctb],\n  Estrella Alonso P\u00e9rez [ctb]",
    "url": "https://github.com/GMestreM/fdaACF",
    "bug_reports": "https://github.com/GMestreM/fdaACF/issues",
    "repository": "https://cran.r-project.org/package=fdaACF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fdaACF Autocorrelation Function for Functional Time Series Quantify the serial correlation across lags of a given functional \n    time series using the autocorrelation function and a partial autocorrelation\n    function for functional time series proposed in \n    Mestre et al. (2021) <doi:10.1016/j.csda.2020.107108>.\n    The autocorrelation functions are based on the L2 norm of the lagged covariance \n    operators of the series. Functions are available for estimating the \n    distribution of the autocorrelation functions under the assumption \n    of strong functional white noise.  "
  },
  {
    "id": 12326,
    "package_name": "feasts",
    "title": "Feature Extraction and Statistics for Time Series",
    "description": "Provides a collection of features, decomposition methods, \n    statistical summaries and graphics functions for the analysing tidy time\n    series data. The package name 'feasts' is an acronym comprising of its key\n    features: Feature Extraction And Statistics for Time Series.",
    "version": "0.4.2",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre],\n  Rob Hyndman [aut],\n  Earo Wang [aut],\n  Di Cook [ctb],\n  Thiyanga Talagala [ctb] (Correlation features),\n  Leanne Chhay [ctb] (Guerrero's method)",
    "url": "http://feasts.tidyverts.org/, https://github.com/tidyverts/feasts/",
    "bug_reports": "https://github.com/tidyverts/feasts/issues",
    "repository": "https://cran.r-project.org/package=feasts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "feasts Feature Extraction and Statistics for Time Series Provides a collection of features, decomposition methods, \n    statistical summaries and graphics functions for the analysing tidy time\n    series data. The package name 'feasts' is an acronym comprising of its key\n    features: Feature Extraction And Statistics for Time Series.  "
  },
  {
    "id": 12361,
    "package_name": "fftab",
    "title": "Tidy Manipulation of Fourier Transformed Data",
    "description": "The 'fftab' package stores Fourier coefficients in a tibble and \n  allows their manipulation in various ways. Functions are available for converting \n  between complex, rectangular ('re', 'im'), and polar ('mod', 'arg') representations, \n  as well as for extracting components as vectors or matrices. Inputs can include \n  vectors, time series, and arrays of arbitrary dimensions, which are restored \n  to their original form when inverting the transform. Since 'fftab' stores Fourier \n  frequencies as columns in the tibble, many standard operations on spectral data \n  can be easily performed using tidy packages like 'dplyr'.",
    "version": "0.1.0",
    "maintainer": "Timothy Keitt <tkeitt@gmail.com>",
    "author": "Timothy Keitt [aut, cre]",
    "url": "https://github.com/thk686/fftab, https://thk686.github.io/fftab/",
    "bug_reports": "https://github.com/thk686/fftab/issues",
    "repository": "https://cran.r-project.org/package=fftab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fftab Tidy Manipulation of Fourier Transformed Data The 'fftab' package stores Fourier coefficients in a tibble and \n  allows their manipulation in various ways. Functions are available for converting \n  between complex, rectangular ('re', 'im'), and polar ('mod', 'arg') representations, \n  as well as for extracting components as vectors or matrices. Inputs can include \n  vectors, time series, and arrays of arbitrary dimensions, which are restored \n  to their original form when inverting the transform. Since 'fftab' stores Fourier \n  frequencies as columns in the tibble, many standard operations on spectral data \n  can be easily performed using tidy packages like 'dplyr'.  "
  },
  {
    "id": 12416,
    "package_name": "finnishgrid",
    "title": "'Fingrid Open Data API' R Client",
    "description": "R API client package for 'Fingrid Open Data' \n    <https://data.fingrid.fi/> on the electricity market and the power system. \n    get_data() function holds the main application logic to retrieve \n    time-series data. API calls require free user account registration.\n    Data is made available by Fingrid Oyj and distributed under\n    Creative Commons 4.0 <https://creativecommons.org/licenses/by/4.0/>.",
    "version": "0.2.0",
    "maintainer": "Markus Virtanen <markus.m.virtanen@gmail.com>",
    "author": "Markus Virtanen [aut, cre],\n  Kai Hippi [aut]",
    "url": "https://github.com/virmar/finnishgrid",
    "bug_reports": "https://github.com/virmar/finnishgrid/issues",
    "repository": "https://cran.r-project.org/package=finnishgrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "finnishgrid 'Fingrid Open Data API' R Client R API client package for 'Fingrid Open Data' \n    <https://data.fingrid.fi/> on the electricity market and the power system. \n    get_data() function holds the main application logic to retrieve \n    time-series data. API calls require free user account registration.\n    Data is made available by Fingrid Oyj and distributed under\n    Creative Commons 4.0 <https://creativecommons.org/licenses/by/4.0/>.  "
  },
  {
    "id": 12418,
    "package_name": "finnts",
    "title": "Microsoft Finance Time Series Forecasting Framework",
    "description": "Automated time series forecasting developed by Microsoft Finance. The Microsoft Finance Time \n    Series Forecasting Framework, aka Finn, can be used to forecast any component of the income \n    statement, balance sheet, or any other area of interest by finance. Any numerical quantity over time, \n    Finn can be used to forecast it. While it can be applied outside of the finance domain, Finn was built \n    to meet the needs of financial analysts to better forecast their businesses within a company, and has \n    a lot of built in features that are specific to the needs of financial forecasters. Happy forecasting!",
    "version": "0.6.0",
    "maintainer": "Mike Tokic <mftokic@gmail.com>",
    "author": "Mike Tokic [aut, cre] (ORCID: <https://orcid.org/0000-0002-7630-7055>),\n  Aadharsh Kannan [aut] (ORCID: <https://orcid.org/0000-0002-6475-8211>)",
    "url": "https://microsoft.github.io/finnts/,\nhttps://github.com/microsoft/finnts",
    "bug_reports": "https://github.com/microsoft/finnts/issues",
    "repository": "https://cran.r-project.org/package=finnts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "finnts Microsoft Finance Time Series Forecasting Framework Automated time series forecasting developed by Microsoft Finance. The Microsoft Finance Time \n    Series Forecasting Framework, aka Finn, can be used to forecast any component of the income \n    statement, balance sheet, or any other area of interest by finance. Any numerical quantity over time, \n    Finn can be used to forecast it. While it can be applied outside of the finance domain, Finn was built \n    to meet the needs of financial analysts to better forecast their businesses within a company, and has \n    a lot of built in features that are specific to the needs of financial forecasters. Happy forecasting!  "
  },
  {
    "id": 12474,
    "package_name": "flamingos",
    "title": "Functional Latent Data Models for Clustering Heterogeneous\nCurves ('FLaMingos')",
    "description": "Provides a variety of original and flexible user-friendly \n    statistical latent variable models for the simultaneous clustering and \n    segmentation of heterogeneous functional data (i.e time series, or more \n    generally longitudinal data, fitted by unsupervised algorithms, including \n    EM algorithms. Functional Latent Data Models for Clustering heterogeneous \n    curves ('FLaMingos') are originally introduced and written in 'Matlab' by\n    Faicel Chamroukhi \n    <https://github.com/fchamroukhi?utf8=?&tab=repositories&q=mix&type=public&language=matlab>. \n    The references are mainly the following ones.\n    Chamroukhi F. (2010) <https://chamroukhi.com/FChamroukhi-PhD.pdf>.\n    Chamroukhi F., Same A., Govaert, G. and Aknin P. (2010) <doi:10.1016/j.neucom.2009.12.023>.\n    Chamroukhi F., Same A., Aknin P. and Govaert G. (2011). <doi:10.1109/IJCNN.2011.6033590>.\n    Same A., Chamroukhi F., Govaert G. and Aknin, P. (2011) <doi:10.1007/s11634-011-0096-5>.\n    Chamroukhi F., and Glotin H. (2012) <doi:10.1109/IJCNN.2012.6252818>.\n    Chamroukhi F., Glotin H. and Same A. (2013) <doi:10.1016/j.neucom.2012.10.030>.\n    Chamroukhi F. (2015) <https://chamroukhi.com/FChamroukhi-HDR.pdf>.\n    Chamroukhi F. and Nguyen H-D. (2019) <doi:10.1002/widm.1298>.",
    "version": "0.1.0",
    "maintainer": "Florian Lecocq <florian.lecocq@outlook.com>",
    "author": "Faicel Chamroukhi [aut] (ORCID:\n    <https://orcid.org/0000-0002-5894-3103>),\n  Florian Lecocq [aut, trl, cre] (R port),\n  Marius Bartcus [aut, trl] (R port)",
    "url": "https://github.com/fchamroukhi/FLaMingos",
    "bug_reports": "https://github.com/fchamroukhi/FLaMingos/issues",
    "repository": "https://cran.r-project.org/package=flamingos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "flamingos Functional Latent Data Models for Clustering Heterogeneous\nCurves ('FLaMingos') Provides a variety of original and flexible user-friendly \n    statistical latent variable models for the simultaneous clustering and \n    segmentation of heterogeneous functional data (i.e time series, or more \n    generally longitudinal data, fitted by unsupervised algorithms, including \n    EM algorithms. Functional Latent Data Models for Clustering heterogeneous \n    curves ('FLaMingos') are originally introduced and written in 'Matlab' by\n    Faicel Chamroukhi \n    <https://github.com/fchamroukhi?utf8=?&tab=repositories&q=mix&type=public&language=matlab>. \n    The references are mainly the following ones.\n    Chamroukhi F. (2010) <https://chamroukhi.com/FChamroukhi-PhD.pdf>.\n    Chamroukhi F., Same A., Govaert, G. and Aknin P. (2010) <doi:10.1016/j.neucom.2009.12.023>.\n    Chamroukhi F., Same A., Aknin P. and Govaert G. (2011). <doi:10.1109/IJCNN.2011.6033590>.\n    Same A., Chamroukhi F., Govaert G. and Aknin, P. (2011) <doi:10.1007/s11634-011-0096-5>.\n    Chamroukhi F., and Glotin H. (2012) <doi:10.1109/IJCNN.2012.6252818>.\n    Chamroukhi F., Glotin H. and Same A. (2013) <doi:10.1016/j.neucom.2012.10.030>.\n    Chamroukhi F. (2015) <https://chamroukhi.com/FChamroukhi-HDR.pdf>.\n    Chamroukhi F. and Nguyen H-D. (2019) <doi:10.1002/widm.1298>.  "
  },
  {
    "id": 12477,
    "package_name": "flap",
    "title": "Forecast Linear Augmented Projection",
    "description": "The Forecast Linear Augmented Projection (flap) method reduces \n    forecast variance by adjusting the forecasts of multivariate time series to \n    be consistent with the forecasts of linear combinations (components) of the \n    series by projecting all forecasts onto the space where the linear \n    constraints are satisfied. The forecast variance can be reduced \n    monotonically by including more components. For a given number of \n    components, the flap method achieves maximum forecast variance reduction \n    among linear projections. ",
    "version": "0.2.0",
    "maintainer": "Yangzhuoran Fin Yang <yangyangzhuoran@gmail.com>",
    "author": "Yangzhuoran Fin Yang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1232-8017>)",
    "url": "https://github.com/FinYang/flap",
    "bug_reports": "https://github.com/FinYang/flap/issues/",
    "repository": "https://cran.r-project.org/package=flap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "flap Forecast Linear Augmented Projection The Forecast Linear Augmented Projection (flap) method reduces \n    forecast variance by adjusting the forecasts of multivariate time series to \n    be consistent with the forecasts of linear combinations (components) of the \n    series by projecting all forecasts onto the space where the linear \n    constraints are satisfied. The forecast variance can be reduced \n    monotonically by including more components. For a given number of \n    components, the flap method achieves maximum forecast variance reduction \n    among linear projections.   "
  },
  {
    "id": 12545,
    "package_name": "fma",
    "title": "Data Sets from \"Forecasting: Methods and Applications\" by\nMakridakis, Wheelwright & Hyndman (1998)",
    "description": "All data sets from \"Forecasting: methods and applications\" by Makridakis, Wheelwright & Hyndman (Wiley, 3rd ed., 1998) <https://robjhyndman.com/forecasting/>.",
    "version": "2.5",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  Justin Carmody [ctb]",
    "url": "https://pkg.robjhyndman.com/fma/,\nhttps://github.com/robjhyndman/fma",
    "bug_reports": "https://github.com/robjhyndman/fma/issues",
    "repository": "https://cran.r-project.org/package=fma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fma Data Sets from \"Forecasting: Methods and Applications\" by\nMakridakis, Wheelwright & Hyndman (1998) All data sets from \"Forecasting: methods and applications\" by Makridakis, Wheelwright & Hyndman (Wiley, 3rd ed., 1998) <https://robjhyndman.com/forecasting/>.  "
  },
  {
    "id": 12562,
    "package_name": "fnets",
    "title": "Factor-Adjusted Network Estimation and Forecasting for\nHigh-Dimensional Time Series",
    "description": "Implements methods for network estimation and forecasting of high-dimensional time series \n    exhibiting strong serial and cross-sectional correlations under a factor-adjusted vector autoregressive model.\n    See Barigozzi, Cho and Owens (2024+) <doi:10.1080/07350015.2023.2257270> for further descriptions of FNETS methodology and \n    Owens, Cho and Barigozzi (2024+) <arXiv:2301.11675> accompanying the R package.",
    "version": "0.1.6",
    "maintainer": "Haeran Cho <haeran.cho@bristol.ac.uk>",
    "author": "Matteo Barigozzi [aut],\n  Haeran Cho [cre, aut],\n  Dom Owens [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fnets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fnets Factor-Adjusted Network Estimation and Forecasting for\nHigh-Dimensional Time Series Implements methods for network estimation and forecasting of high-dimensional time series \n    exhibiting strong serial and cross-sectional correlations under a factor-adjusted vector autoregressive model.\n    See Barigozzi, Cho and Owens (2024+) <doi:10.1080/07350015.2023.2257270> for further descriptions of FNETS methodology and \n    Owens, Cho and Barigozzi (2024+) <arXiv:2301.11675> accompanying the R package.  "
  },
  {
    "id": 12580,
    "package_name": "foqat",
    "title": "Field Observation Quick Analysis Toolkit",
    "description": "Tools for quickly processing and analyzing \n\tfield observation data and air quality data. This \n\ttools contain functions that facilitate analysis \n\tin atmospheric chemistry (especially in ozone \n\tpollution). Some functions of time series are also \n\tapplicable to other fields. For detail please view \n\thomepage<https://github.com/tianshu129/foqat>.\n\tScientific Reference:\n\t1. The Hydroxyl Radical (OH) Reactivity: Roger Atkinson and Janet Arey (2003) <doi:10.1021/cr0206420>.\n\t2. Ozone Formation Potential (OFP): <http://ww2.arb.ca.gov/sites/default/files/barcu/regact/2009/mir2009/mir10.pdf>, Zhang et al.(2021) <doi:10.5194/acp-21-11053-2021>.\n\t3. Aerosol Formation Potential (AFP): Wenjing Wu et al. (2016) <doi:10.1016/j.jes.2016.03.025>.\n\t4. TUV model: <https://www2.acom.ucar.edu/modeling/tropospheric-ultraviolet-and-visible-tuv-radiation-model>.",
    "version": "2.0.8.2",
    "maintainer": "Tianshu Chen <tianshu129@163.com>",
    "author": "Tianshu Chen",
    "url": "https://github.com/tianshu129/foqat,\nhttps://tianshu129.github.io/foqat/",
    "bug_reports": "https://github.com/tianshu129/foqat/issues",
    "repository": "https://cran.r-project.org/package=foqat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "foqat Field Observation Quick Analysis Toolkit Tools for quickly processing and analyzing \n\tfield observation data and air quality data. This \n\ttools contain functions that facilitate analysis \n\tin atmospheric chemistry (especially in ozone \n\tpollution). Some functions of time series are also \n\tapplicable to other fields. For detail please view \n\thomepage<https://github.com/tianshu129/foqat>.\n\tScientific Reference:\n\t1. The Hydroxyl Radical (OH) Reactivity: Roger Atkinson and Janet Arey (2003) <doi:10.1021/cr0206420>.\n\t2. Ozone Formation Potential (OFP): <http://ww2.arb.ca.gov/sites/default/files/barcu/regact/2009/mir2009/mir10.pdf>, Zhang et al.(2021) <doi:10.5194/acp-21-11053-2021>.\n\t3. Aerosol Formation Potential (AFP): Wenjing Wu et al. (2016) <doi:10.1016/j.jes.2016.03.025>.\n\t4. TUV model: <https://www2.acom.ucar.edu/modeling/tropospheric-ultraviolet-and-visible-tuv-radiation-model>.  "
  },
  {
    "id": 12582,
    "package_name": "forceR",
    "title": "Force Measurement Analyses",
    "description": "For cleaning and analysis of graphs, such as animal closing force \n    measurements. \n    'forceR' was initially written and optimized to deal with insect bite force \n    measurements, but can be used for any time series. Includes a full workflow \n    to load, plot and crop data, correct amplifier and baseline drifts, \n    identify individual peak shapes (bites), rescale (normalize) peak curves, \n    and find best polynomial fits to describe and analyze force curve shapes.",
    "version": "1.0.20",
    "maintainer": "Peter T. R\u00fchr <peter.ruehr@gmail.com>",
    "author": "Peter T. R\u00fchr [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2776-6172>),\n  Alexander Blanke [ctb] (ORCID: <https://orcid.org/0000-0003-4385-6039>)",
    "url": "https://github.com/Peter-T-Ruehr/forceR",
    "bug_reports": "https://github.com/Peter-T-Ruehr/forceR/issues",
    "repository": "https://cran.r-project.org/package=forceR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forceR Force Measurement Analyses For cleaning and analysis of graphs, such as animal closing force \n    measurements. \n    'forceR' was initially written and optimized to deal with insect bite force \n    measurements, but can be used for any time series. Includes a full workflow \n    to load, plot and crop data, correct amplifier and baseline drifts, \n    identify individual peak shapes (bites), rescale (normalize) peak curves, \n    and find best polynomial fits to describe and analyze force curve shapes.  "
  },
  {
    "id": 12583,
    "package_name": "foreSIGHT",
    "title": "Systems Insights from Generation of Hydroclimatic Timeseries",
    "description": "A tool to create hydroclimate scenarios, stress test systems and visualize system performance in scenario-neutral climate change impact assessments. Scenario-neutral approaches 'stress-test' the performance of a modelled system by applying a wide range of plausible hydroclimate conditions (see Brown & Wilby (2012) <doi:10.1029/2012EO410001> and Prudhomme et al. (2010) <doi:10.1016/j.jhydrol.2010.06.043>). These approaches allow the identification of hydroclimatic variables that affect the vulnerability of a system to hydroclimate variation and change. This tool enables the generation of perturbed time series using a range of approaches including simple scaling of observed time series (e.g. Culley et al. (2016) <doi:10.1002/2015WR018253>) and stochastic simulation of perturbed time series via an inverse approach (see Guo et al. (2018) <doi:10.1016/j.jhydrol.2016.03.025>). It incorporates 'Richardson-type' weather generator model configurations documented in Richardson (1981) <doi:10.1029/WR017i001p00182>, Richardson and Wright (1984), as well as latent variable type model configurations documented in Bennett et al. (2018) <doi:10.1016/j.jhydrol.2016.12.043>, Rasmussen (2013) <doi:10.1002/wrcr.20164>, Bennett et al. (2019) <doi:10.5194/hess-23-4783-2019> to generate hydroclimate variables on a daily basis (e.g. precipitation, temperature, potential evapotranspiration) and allows a variety of different hydroclimate variable properties, herein called attributes, to be perturbed. Options are included for the easy integration of existing system models both internally in R and externally for seamless 'stress-testing'. A suite of visualization options for the results of a scenario-neutral analysis (e.g. plotting performance spaces and overlaying climate projection information) are also included. Version 1.0 of this package is described in Bennett et al. (2021) <doi:10.1016/j.envsoft.2021.104999>. As further developments in scenario-neutral approaches occur the tool will be updated to incorporate these advances.",
    "version": "2.0.0",
    "maintainer": "David McInerney <david.mcinerney@adelaide.edu.au>",
    "author": "Bree Bennett [aut] (ORCID: <https://orcid.org/0000-0002-2131-088X>),\n  David McInerney [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4876-8281>),\n  Sam Culley [aut] (ORCID: <https://orcid.org/0000-0003-4798-8522>),\n  Anjana Devanand [aut] (ORCID: <https://orcid.org/0000-0001-9422-3894>),\n  Seth Westra [aut] (ORCID: <https://orcid.org/0000-0003-4023-6061>),\n  Danlu Guo [ctb] (ORCID: <https://orcid.org/0000-0003-1083-1214>),\n  Holger Maier [ths] (ORCID: <https://orcid.org/0000-0002-0277-6887>)",
    "url": "",
    "bug_reports": "https://github.com/ClimateAnalytics/foreSIGHT/issues",
    "repository": "https://cran.r-project.org/package=foreSIGHT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "foreSIGHT Systems Insights from Generation of Hydroclimatic Timeseries A tool to create hydroclimate scenarios, stress test systems and visualize system performance in scenario-neutral climate change impact assessments. Scenario-neutral approaches 'stress-test' the performance of a modelled system by applying a wide range of plausible hydroclimate conditions (see Brown & Wilby (2012) <doi:10.1029/2012EO410001> and Prudhomme et al. (2010) <doi:10.1016/j.jhydrol.2010.06.043>). These approaches allow the identification of hydroclimatic variables that affect the vulnerability of a system to hydroclimate variation and change. This tool enables the generation of perturbed time series using a range of approaches including simple scaling of observed time series (e.g. Culley et al. (2016) <doi:10.1002/2015WR018253>) and stochastic simulation of perturbed time series via an inverse approach (see Guo et al. (2018) <doi:10.1016/j.jhydrol.2016.03.025>). It incorporates 'Richardson-type' weather generator model configurations documented in Richardson (1981) <doi:10.1029/WR017i001p00182>, Richardson and Wright (1984), as well as latent variable type model configurations documented in Bennett et al. (2018) <doi:10.1016/j.jhydrol.2016.12.043>, Rasmussen (2013) <doi:10.1002/wrcr.20164>, Bennett et al. (2019) <doi:10.5194/hess-23-4783-2019> to generate hydroclimate variables on a daily basis (e.g. precipitation, temperature, potential evapotranspiration) and allows a variety of different hydroclimate variable properties, herein called attributes, to be perturbed. Options are included for the easy integration of existing system models both internally in R and externally for seamless 'stress-testing'. A suite of visualization options for the results of a scenario-neutral analysis (e.g. plotting performance spaces and overlaying climate projection information) are also included. Version 1.0 of this package is described in Bennett et al. (2021) <doi:10.1016/j.envsoft.2021.104999>. As further developments in scenario-neutral approaches occur the tool will be updated to incorporate these advances.  "
  },
  {
    "id": 12585,
    "package_name": "forecTheta",
    "title": "Forecasting Time Series by Theta Models",
    "description": "Routines for forecasting univariate time series using Theta Models.",
    "version": "3.0",
    "maintainer": "Jose Augusto Fiorucci <jafiorucci@gmail.com>",
    "author": "Jose Augusto Fiorucci [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1201-9089>),\n  Francisco Louzada [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-7815-9554>),\n  Igor De Oliveira Barros Faluhelyi [aut, ctb] (ORCID:\n    <https://orcid.org/0009-0008-1637-4476>)",
    "url": "",
    "bug_reports": "https://github.com/jafiorucci/forecTheta/issues",
    "repository": "https://cran.r-project.org/package=forecTheta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecTheta Forecasting Time Series by Theta Models Routines for forecasting univariate time series using Theta Models.  "
  },
  {
    "id": 12586,
    "package_name": "forecast",
    "title": "Forecasting Functions for Time Series and Linear Models",
    "description": "Methods and tools for displaying and analysing\n             univariate time series forecasts including exponential smoothing\n             via state space models and automatic ARIMA modelling.",
    "version": "8.24.0",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  George Athanasopoulos [aut] (ORCID:\n    <https://orcid.org/0000-0002-5389-2802>),\n  Christoph Bergmeir [aut] (ORCID:\n    <https://orcid.org/0000-0002-3665-9021>),\n  Gabriel Caceres [aut] (ORCID: <https://orcid.org/0000-0002-2947-2023>),\n  Leanne Chhay [aut],\n  Kirill Kuroptev [aut],\n  Mitchell O'Hara-Wild [aut] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Fotios Petropoulos [aut] (ORCID:\n    <https://orcid.org/0000-0003-3039-4955>),\n  Slava Razbash [aut],\n  Earo Wang [aut] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Farah Yasmeen [aut] (ORCID: <https://orcid.org/0000-0002-1479-5401>),\n  Federico Garza [ctb],\n  Daniele Girolimetto [ctb],\n  Ross Ihaka [ctb, cph],\n  R Core Team [ctb, cph],\n  Daniel Reid [ctb],\n  David Shaub [ctb],\n  Yuan Tang [ctb] (ORCID: <https://orcid.org/0000-0001-5243-233X>),\n  Xiaoqian Wang [ctb],\n  Zhenyu Zhou [ctb]",
    "url": "https://pkg.robjhyndman.com/forecast/,\nhttps://github.com/robjhyndman/forecast",
    "bug_reports": "https://github.com/robjhyndman/forecast/issues",
    "repository": "https://cran.r-project.org/package=forecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecast Forecasting Functions for Time Series and Linear Models Methods and tools for displaying and analysing\n             univariate time series forecasts including exponential smoothing\n             via state space models and automatic ARIMA modelling.  "
  },
  {
    "id": 12587,
    "package_name": "forecastHybrid",
    "title": "Convenient Functions for Ensemble Time Series Forecasts",
    "description": "Convenient functions for ensemble forecasts in R combining\n    approaches from the 'forecast' package. Forecasts generated from auto.arima(), ets(),\n    thetaf(), nnetar(), stlm(), tbats(), snaive() and arfima() can be combined with equal weights, weights\n    based on in-sample errors (introduced by Bates & Granger (1969) <doi:10.1057/jors.1969.103>),\n    or cross-validated weights. Cross validation for time series data with user-supplied models\n    and forecasting functions is also supported to evaluate model accuracy.",
    "version": "5.1.20",
    "maintainer": "David Shaub <davidshaub@alumni.harvard.edu>",
    "author": "David Shaub [aut, cre],\n  Peter Ellis [aut]",
    "url": "https://gitlab.com/dashaub/forecastHybrid,\nhttps://github.com/ellisp/forecastHybrid",
    "bug_reports": "https://github.com/ellisp/forecastHybrid/issues",
    "repository": "https://cran.r-project.org/package=forecastHybrid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecastHybrid Convenient Functions for Ensemble Time Series Forecasts Convenient functions for ensemble forecasts in R combining\n    approaches from the 'forecast' package. Forecasts generated from auto.arima(), ets(),\n    thetaf(), nnetar(), stlm(), tbats(), snaive() and arfima() can be combined with equal weights, weights\n    based on in-sample errors (introduced by Bates & Granger (1969) <doi:10.1057/jors.1969.103>),\n    or cross-validated weights. Cross validation for time series data with user-supplied models\n    and forecasting functions is also supported to evaluate model accuracy.  "
  },
  {
    "id": 12588,
    "package_name": "forecastLSW",
    "title": "Forecasting Routines for Locally Stationary Wavelet Processes",
    "description": "Implementation to perform forecasting of locally stationary wavelet processes by examining the local second order structure of the time series. ",
    "version": "1.1.1",
    "maintainer": "Rebecca Killick <r.killick@lancs.ac.uk>",
    "author": "Rebecca Killick [aut, cre],\n  Matt Nunes [aut],\n  Guy Nason [aut],\n  Marina Knight [aut],\n  Idris Eckley [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=forecastLSW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecastLSW Forecasting Routines for Locally Stationary Wavelet Processes Implementation to perform forecasting of locally stationary wavelet processes by examining the local second order structure of the time series.   "
  },
  {
    "id": 12589,
    "package_name": "forecastML",
    "title": "Time Series Forecasting with Machine Learning Methods",
    "description": "The purpose of 'forecastML' is to simplify the process of multi-step-ahead forecasting with standard machine learning algorithms. 'forecastML' supports lagged, dynamic, static, and grouping features for modeling single and grouped numeric or factor/sequence time series. In addition, simple wrapper functions are used to support model-building with most R packages. This approach to forecasting is inspired by Bergmeir, Hyndman, and Koo's (2018) paper \"A note on the validity of cross-validation for evaluating autoregressive time series prediction\" <doi:10.1016/j.csda.2017.11.003>.",
    "version": "0.9.0",
    "maintainer": "Nickalus Redell <nickalusredell@gmail.com>",
    "author": "Nickalus Redell",
    "url": "https://github.com/nredell/forecastML/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=forecastML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecastML Time Series Forecasting with Machine Learning Methods The purpose of 'forecastML' is to simplify the process of multi-step-ahead forecasting with standard machine learning algorithms. 'forecastML' supports lagged, dynamic, static, and grouping features for modeling single and grouped numeric or factor/sequence time series. In addition, simple wrapper functions are used to support model-building with most R packages. This approach to forecasting is inspired by Bergmeir, Hyndman, and Koo's (2018) paper \"A note on the validity of cross-validation for evaluating autoregressive time series prediction\" <doi:10.1016/j.csda.2017.11.003>.  "
  },
  {
    "id": 12590,
    "package_name": "forecastSNSTS",
    "title": "Forecasting for Stationary and Non-Stationary Time Series",
    "description": "Methods to compute linear h-step ahead prediction coefficients based\n    on localised and iterated Yule-Walker estimates and empirical mean squared\n    and absolute prediction errors for the resulting predictors. Also, functions\n    to compute autocovariances for AR(p) processes, to simulate tvARMA(p,q) time\n    series, and to verify an assumption from Kley et al. (2019), Electronic of Statistics,\n    forthcoming. Preprint <arXiv:1611.04460>.",
    "version": "1.3-0",
    "maintainer": "Tobias Kley <tobias.kley@bristol.ac.uk>",
    "author": "Tobias Kley [aut, cre],\n  Philip Preuss [aut],\n  Piotr Fryzlewicz [aut]",
    "url": "http://github.com/tobiaskley/forecastSNSTS",
    "bug_reports": "http://github.com/tobiaskley/forecastSNSTS/issues",
    "repository": "https://cran.r-project.org/package=forecastSNSTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecastSNSTS Forecasting for Stationary and Non-Stationary Time Series Methods to compute linear h-step ahead prediction coefficients based\n    on localised and iterated Yule-Walker estimates and empirical mean squared\n    and absolute prediction errors for the resulting predictors. Also, functions\n    to compute autocovariances for AR(p) processes, to simulate tvARMA(p,q) time\n    series, and to verify an assumption from Kley et al. (2019), Electronic of Statistics,\n    forthcoming. Preprint <arXiv:1611.04460>.  "
  },
  {
    "id": 12591,
    "package_name": "forecasteR",
    "title": "Time Series Forecast System",
    "description": "A web application for displaying, analysing and forecasting univariate time series. Includes basic methods such as mean, na\u00efve, seasonal na\u00efve and drift, as well as more complex methods such as Holt-Winters Box,G and Jenkins, G (1976) <doi:10.1111/jtsa.12194> and ARIMA Brockwell, P.J. and R.A.Davis (1991) <doi:10.1007/978-1-4419-0320-4>.",
    "version": "3.0.2",
    "maintainer": "Oldemar Rodriguez <oldemar.rodriguez@ucr.ac.cr>",
    "author": "Oldemar Rodriguez [aut, cre],\n  Diego Jim\u00e9nez [aut]",
    "url": "https://promidat.website, https://github.com/PROMiDAT/forecasteR",
    "bug_reports": "https://github.com/PROMiDAT/forecasteR/issues",
    "repository": "https://cran.r-project.org/package=forecasteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecasteR Time Series Forecast System A web application for displaying, analysing and forecasting univariate time series. Includes basic methods such as mean, na\u00efve, seasonal na\u00efve and drift, as well as more complex methods such as Holt-Winters Box,G and Jenkins, G (1976) <doi:10.1111/jtsa.12194> and ARIMA Brockwell, P.J. and R.A.Davis (1991) <doi:10.1007/978-1-4419-0320-4>.  "
  },
  {
    "id": 12629,
    "package_name": "fortniteR",
    "title": "Access 'Fortnite Ecosystem' API",
    "description": "Interface for accessing the 'Fortnite Ecosystem' API, allowing users\n    to retrieve island metadata and engagement metrics. The package provides functions\n    to search for 'Fortnite Creative' islands, retrieve detailed metadata about specific\n    islands including titles, descriptions, and tags, and access engagement metrics\n    such as daily active users and play duration. It supports pagination for large\n    result sets and time-series analysis of island performance. The API endpoint is\n    <https://api.fortnite.com/ecosystem/v1>.",
    "version": "0.1.0",
    "maintainer": "Phillip Black <pblack@gameeconomistconsulting.com>",
    "author": "Phillip Black [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fortniteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fortniteR Access 'Fortnite Ecosystem' API Interface for accessing the 'Fortnite Ecosystem' API, allowing users\n    to retrieve island metadata and engagement metrics. The package provides functions\n    to search for 'Fortnite Creative' islands, retrieve detailed metadata about specific\n    islands including titles, descriptions, and tags, and access engagement metrics\n    such as daily active users and play duration. It supports pagination for large\n    result sets and time-series analysis of island performance. The API endpoint is\n    <https://api.fortnite.com/ecosystem/v1>.  "
  },
  {
    "id": 12642,
    "package_name": "fpa",
    "title": "Spatio-Temporal Fixation Pattern Analysis",
    "description": "Spatio-temporal Fixation Pattern Analysis (FPA) is a new method of analyzing eye \n  movement data, developed by Mr. Jinlu Cao under the supervision of Prof. Chen Hsuan-Chih at \n  The Chinese University of Hong Kong, and Prof. Wang Suiping at the South China Normal \n  Univeristy. The package \"fpa\" is a R implementation which makes FPA analysis much easier. \n  There are four major functions in the package: ft2fp(), get_pattern(), plot_pattern(), and \n  lineplot(). The function ft2fp() is the core function, which can complete all the preprocessing \n  within moments. The other three functions are supportive functions which visualize the eye \n  fixation patterns.",
    "version": "1.0",
    "maintainer": "Jinlu Cao <caojinlu@gmail.com>",
    "author": "Jinlu Cao",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fpa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fpa Spatio-Temporal Fixation Pattern Analysis Spatio-temporal Fixation Pattern Analysis (FPA) is a new method of analyzing eye \n  movement data, developed by Mr. Jinlu Cao under the supervision of Prof. Chen Hsuan-Chih at \n  The Chinese University of Hong Kong, and Prof. Wang Suiping at the South China Normal \n  Univeristy. The package \"fpa\" is a R implementation which makes FPA analysis much easier. \n  There are four major functions in the package: ft2fp(), get_pattern(), plot_pattern(), and \n  lineplot(). The function ft2fp() is the core function, which can complete all the preprocessing \n  within moments. The other three functions are supportive functions which visualize the eye \n  fixation patterns.  "
  },
  {
    "id": 12651,
    "package_name": "fpp2",
    "title": "Data for \"Forecasting: Principles and Practice\" (2nd Edition)",
    "description": "All data sets required for the examples and exercises\n  in the book \"Forecasting: principles and practice\" (2nd ed, 2018)\n  by Rob J Hyndman and George Athanasopoulos <https://otexts.com/fpp2/>.\n  All packages required to run the examples are also loaded.",
    "version": "2.5",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph],\n  RStudio [cph]",
    "url": "https://pkg.robjhyndman.com/fpp2-package/,\nhttps://github.com/robjhyndman/fpp2-package,\nhttps://otexts.com/fpp2/",
    "bug_reports": "https://github.com/robjhyndman/fpp2-package/issues",
    "repository": "https://cran.r-project.org/package=fpp2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fpp2 Data for \"Forecasting: Principles and Practice\" (2nd Edition) All data sets required for the examples and exercises\n  in the book \"Forecasting: principles and practice\" (2nd ed, 2018)\n  by Rob J Hyndman and George Athanasopoulos <https://otexts.com/fpp2/>.\n  All packages required to run the examples are also loaded.  "
  },
  {
    "id": 12652,
    "package_name": "fpp3",
    "title": "Data for \"Forecasting: Principles and Practice\" (3rd Edition)",
    "description": "\n    All data sets required for the examples and exercises in the book\n    \"Forecasting: principles and practice\" by Rob J Hyndman and George Athanasopoulos\n    <https://OTexts.com/fpp3/>. All packages required to run the examples are also\n    loaded. Additional data sets not used in the book are also included.",
    "version": "1.0.2",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  George Athanasopoulos [ctb],\n  Mitchell O'Hara-Wild [ctb],\n  Nuwani Palihawadana [ctb],\n  Shanika Wickramasuriya [ctb],\n  RStudio [cph]",
    "url": "https://pkg.robjhyndman.com/fpp3/,\nhttps://github.com/robjhyndman/fpp3, https://OTexts.com/fpp3/",
    "bug_reports": "https://github.com/robjhyndman/fpp3/issues",
    "repository": "https://cran.r-project.org/package=fpp3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fpp3 Data for \"Forecasting: Principles and Practice\" (3rd Edition) \n    All data sets required for the examples and exercises in the book\n    \"Forecasting: principles and practice\" by Rob J Hyndman and George Athanasopoulos\n    <https://OTexts.com/fpp3/>. All packages required to run the examples are also\n    loaded. Additional data sets not used in the book are also included.  "
  },
  {
    "id": 12660,
    "package_name": "fracARMA",
    "title": "Fractionally Integrated ARMA Model",
    "description": "Implements fractional differencing with Autoregressive Moving Average models to analyse long-memory \ttime series data. Traditional ARIMA models typically use integer values for differencing, which are \tsuitable for time series with short memory or anti-persistent behaviour. In contrast, the Fractional ARIMA \tmodel allows fractional differencing, enabling it to effectively capture long memory characteristics in \ttime series data. The \u2018fracARMA\u2019 package is user-friendly and allows users to manually input the \tfractional differencing parameter, which can be obtained using various estimators such as the GPH \testimator, Sperio method, or Wavelet method and many. Additionally, the package enables users to directly \tfeed the time series data, AR order, MA order, fractional differencing parameter, and the proportion of \ttraining data as a split ratio, all in a single command. The package is based on the reference from the \tpaper of Irshad and others (2024, <doi:10.22271/maths.2024.v9.i6b.1906>).",
    "version": "0.1.0",
    "maintainer": "Muhammed Irshad M <irshadmiitm@gmail.com>",
    "author": "Muhammed Irshad M [aut, cre],\n  Dr. Kader Ali Sarkar [aut],\n  Dr. Digvijay Singh Dhakre [aut],\n  Prof. Debasis Bhattacharaya [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fracARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fracARMA Fractionally Integrated ARMA Model Implements fractional differencing with Autoregressive Moving Average models to analyse long-memory \ttime series data. Traditional ARIMA models typically use integer values for differencing, which are \tsuitable for time series with short memory or anti-persistent behaviour. In contrast, the Fractional ARIMA \tmodel allows fractional differencing, enabling it to effectively capture long memory characteristics in \ttime series data. The \u2018fracARMA\u2019 package is user-friendly and allows users to manually input the \tfractional differencing parameter, which can be obtained using various estimators such as the GPH \testimator, Sperio method, or Wavelet method and many. Additionally, the package enables users to directly \tfeed the time series data, AR order, MA order, fractional differencing parameter, and the proportion of \ttraining data as a split ratio, all in a single command. The package is based on the reference from the \tpaper of Irshad and others (2024, <doi:10.22271/maths.2024.v9.i6b.1906>).  "
  },
  {
    "id": 12661,
    "package_name": "fracdiff",
    "title": "Fractionally Differenced ARIMA aka ARFIMA(P,d,q) Models",
    "description": "Maximum likelihood estimation of the parameters of a fractionally\n   differenced ARIMA(p,d,q) model (Haslett and Raftery, Appl.Statistics, 1989);\n   including inference and basic methods.  Some alternative algorithms to estimate \"H\".",
    "version": "1.5-3",
    "maintainer": "Martin Maechler <maechler@stat.math.ethz.ch>",
    "author": "Martin Maechler [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8685-9910>),\n  Chris Fraley [ctb, cph] (S original; Fortran code),\n  Friedrich Leisch [ctb] (R port, ORCID:\n    <https://orcid.org/0000-0001-7278-1983>),\n  Valderio Reisen [ctb] (fdGPH() & fdSperio()),\n  Artur Lemonte [ctb] (fdGPH() & fdSperio()),\n  Rob Hyndman [ctb] (residuals() & fitted(), ORCID:\n    <https://orcid.org/0000-0002-2140-5352>)",
    "url": "https://github.com/mmaechler/fracdiff",
    "bug_reports": "https://github.com/mmaechler/fracdiff/issues",
    "repository": "https://cran.r-project.org/package=fracdiff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fracdiff Fractionally Differenced ARIMA aka ARFIMA(P,d,q) Models Maximum likelihood estimation of the parameters of a fractionally\n   differenced ARIMA(p,d,q) model (Haslett and Raftery, Appl.Statistics, 1989);\n   including inference and basic methods.  Some alternative algorithms to estimate \"H\".  "
  },
  {
    "id": 12665,
    "package_name": "fractaldim",
    "title": "Estimation of Fractal Dimensions",
    "description": "Implements various methods for estimating fractal dimension of time series and 2-dimensional data <doi:10.1214/11-STS370>.",
    "version": "0.8-5",
    "maintainer": "Hana Sevcikova <hanas@uw.edu>",
    "author": "Hana Sevcikova <hanas@uw.edu>, \n\tDon Percival <dbp@apl.washington.edu>,\n        Tilmann Gneiting <tilmann@stat.washington.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fractaldim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fractaldim Estimation of Fractal Dimensions Implements various methods for estimating fractal dimension of time series and 2-dimensional data <doi:10.1214/11-STS370>.  "
  },
  {
    "id": 12683,
    "package_name": "fredr",
    "title": "An R Client for the 'FRED' API",
    "description": "An R client for the 'Federal Reserve Economic Data'\n    ('FRED') API <https://research.stlouisfed.org/docs/api/>.  Functions\n    to retrieve economic time series and other data from 'FRED'.",
    "version": "2.1.0",
    "maintainer": "Sam Boysel <sboysel@gmail.com>",
    "author": "Sam Boysel [aut, cre],\n  Davis Vaughan [aut]",
    "url": "https://github.com/sboysel/fredr",
    "bug_reports": "https://github.com/sboysel/fredr/issues",
    "repository": "https://cran.r-project.org/package=fredr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fredr An R Client for the 'FRED' API An R client for the 'Federal Reserve Economic Data'\n    ('FRED') API <https://research.stlouisfed.org/docs/api/>.  Functions\n    to retrieve economic time series and other data from 'FRED'.  "
  },
  {
    "id": 12691,
    "package_name": "freesurferformats",
    "title": "Read and Write 'FreeSurfer' Neuroimaging File Formats",
    "description": "Provides functions to read and write neuroimaging data in various file formats, with a focus on 'FreeSurfer' <http://freesurfer.net/> formats. This includes, but is not limited to, the following file formats: 1) MGH/MGZ format files, which can contain multi-dimensional images or other data. Typically they contain time-series of three-dimensional brain scans acquired by magnetic resonance imaging (MRI). They can also contain vertex-wise measures of surface morphometry data. The MGH format is named after the Massachusetts General Hospital, and the MGZ format is a compressed version of the same format. 2) 'FreeSurfer' morphometry data files in binary 'curv' format. These contain vertex-wise surface measures, i.e., one scalar value for each vertex of a brain surface mesh. These are typically values like the cortical thickness or brain surface area at each vertex. 3) Annotation file format. This contains a brain surface parcellation derived from a cortical atlas. 4) Surface file format. Contains a brain surface mesh, given by a list of vertices and a list of faces.",
    "version": "1.0.0",
    "maintainer": "Tim Sch\u00e4fer <ts+code@rcmd.org>",
    "author": "Tim Sch\u00e4fer [aut, cre] (ORCID: <https://orcid.org/0000-0002-3683-8070>)",
    "url": "https://github.com/dfsp-spirit/freesurferformats",
    "bug_reports": "https://github.com/dfsp-spirit/freesurferformats/issues",
    "repository": "https://cran.r-project.org/package=freesurferformats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "freesurferformats Read and Write 'FreeSurfer' Neuroimaging File Formats Provides functions to read and write neuroimaging data in various file formats, with a focus on 'FreeSurfer' <http://freesurfer.net/> formats. This includes, but is not limited to, the following file formats: 1) MGH/MGZ format files, which can contain multi-dimensional images or other data. Typically they contain time-series of three-dimensional brain scans acquired by magnetic resonance imaging (MRI). They can also contain vertex-wise measures of surface morphometry data. The MGH format is named after the Massachusetts General Hospital, and the MGZ format is a compressed version of the same format. 2) 'FreeSurfer' morphometry data files in binary 'curv' format. These contain vertex-wise surface measures, i.e., one scalar value for each vertex of a brain surface mesh. These are typically values like the cortical thickness or brain surface area at each vertex. 3) Annotation file format. This contains a brain surface parcellation derived from a cortical atlas. 4) Surface file format. Contains a brain surface mesh, given by a list of vertices and a list of faces.  "
  },
  {
    "id": 12697,
    "package_name": "freqdom",
    "title": "Frequency Domain Based Analysis: Dynamic PCA",
    "description": "Implementation of dynamic principal component\n    analysis (DPCA), simulation of VAR and VMA processes and frequency domain tools. \n    These frequency domain methods for dimensionality reduction of multivariate time series\n    were introduced by David Brillinger in his book Time Series (1974). We follow implementation\n    guidelines as described in Hormann, Kidzinski and Hallin (2016),\n    Dynamic Functional Principal Component <doi:10.1111/rssb.12076>.",
    "version": "2.0.5",
    "maintainer": "Kidzinski L. <lukasz.kidzinski@stanford.edu>",
    "author": "Hormann S., Kidzinski L.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=freqdom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "freqdom Frequency Domain Based Analysis: Dynamic PCA Implementation of dynamic principal component\n    analysis (DPCA), simulation of VAR and VMA processes and frequency domain tools. \n    These frequency domain methods for dimensionality reduction of multivariate time series\n    were introduced by David Brillinger in his book Time Series (1974). We follow implementation\n    guidelines as described in Hormann, Kidzinski and Hallin (2016),\n    Dynamic Functional Principal Component <doi:10.1111/rssb.12076>.  "
  },
  {
    "id": 12718,
    "package_name": "fruclimadapt",
    "title": "Evaluation Tools for Assessing Climate Adaptation of Fruit Tree\nSpecies",
    "description": "Climate is a critical component limiting growing range of plant species, which\n    also determines cultivar adaptation to a region. The evaluation of climate influence on\n    fruit production is critical for decision-making in the design stage of orchards and \n    vineyards and in the evaluation of the potential consequences of future climate. Bio-\n    climatic indices and plant phenology are commonly used to describe the suitability of \n    climate for growing quality fruit and to provide temporal and spatial information about \n    regarding ongoing and future changes. 'fruclimadapt' streamlines the assessment of \n    climate adaptation and the identification of potential risks for grapevines and fruit \n    trees. Procedures in the package allow to i) downscale daily meteorological variables\n    to hourly values (Forster et al (2016) <doi:10.5194/gmd-9-2315-2016>),\n    ii) estimate chilling and forcing heat accumulation (Miranda et al (2019)\n    <https://ec.europa.eu/eip/agriculture/sites/default/files/fg30_mp5_phenology_critical_temperatures.pdf>),\n    iii) estimate plant phenology (Schwartz (2012) <doi:10.1007/978-94-007-6925-0>), iv) \n    calculate bioclimatic indices to evaluate fruit tree and grapevine adaptation (e.g. Badr \n    et al (2017) <doi:10.3354/cr01532>), v) estimate the incidence of weather-related disorders \n    in fruits (e.g. Snyder and de Melo-Abreu (2005, ISBN:92-5-105328-6) and vi)\n    estimate plant water requirements (Allen et al (1998, ISBN:92-5-104219-5)). ",
    "version": "0.4.5",
    "maintainer": "Carlos Miranda <carlos.miranda@unavarra.es>",
    "author": "Carlos Miranda",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fruclimadapt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fruclimadapt Evaluation Tools for Assessing Climate Adaptation of Fruit Tree\nSpecies Climate is a critical component limiting growing range of plant species, which\n    also determines cultivar adaptation to a region. The evaluation of climate influence on\n    fruit production is critical for decision-making in the design stage of orchards and \n    vineyards and in the evaluation of the potential consequences of future climate. Bio-\n    climatic indices and plant phenology are commonly used to describe the suitability of \n    climate for growing quality fruit and to provide temporal and spatial information about \n    regarding ongoing and future changes. 'fruclimadapt' streamlines the assessment of \n    climate adaptation and the identification of potential risks for grapevines and fruit \n    trees. Procedures in the package allow to i) downscale daily meteorological variables\n    to hourly values (Forster et al (2016) <doi:10.5194/gmd-9-2315-2016>),\n    ii) estimate chilling and forcing heat accumulation (Miranda et al (2019)\n    <https://ec.europa.eu/eip/agriculture/sites/default/files/fg30_mp5_phenology_critical_temperatures.pdf>),\n    iii) estimate plant phenology (Schwartz (2012) <doi:10.1007/978-94-007-6925-0>), iv) \n    calculate bioclimatic indices to evaluate fruit tree and grapevine adaptation (e.g. Badr \n    et al (2017) <doi:10.3354/cr01532>), v) estimate the incidence of weather-related disorders \n    in fruits (e.g. Snyder and de Melo-Abreu (2005, ISBN:92-5-105328-6) and vi)\n    estimate plant water requirements (Allen et al (1998, ISBN:92-5-104219-5)).   "
  },
  {
    "id": 12738,
    "package_name": "ftsa",
    "title": "Functional Time Series Analysis",
    "description": "Functions for visualizing, modeling, forecasting and hypothesis testing of functional time series.",
    "version": "6.6",
    "maintainer": "Han Lin Shang <hanlin.shang@mq.edu.au>",
    "author": "Rob Hyndman [aut] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Han Lin Shang [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1769-6430>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ftsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ftsa Functional Time Series Analysis Functions for visualizing, modeling, forecasting and hypothesis testing of functional time series.  "
  },
  {
    "id": 12739,
    "package_name": "ftsspec",
    "title": "Spectral Density Estimation and Comparison for Functional Time\nSeries",
    "description": "Functions for estimating spectral density operator of functional\n    time series (FTS) and comparing the spectral density operator of two\n    functional time series, in a way that allows detection of differences of\n    the spectral density operator in frequencies and along the curve length.",
    "version": "1.0.0",
    "maintainer": "Shahin Tavakoli <s.tavakoli@statslab.cam.ac.uk>",
    "author": "Shahin Tavakoli [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ftsspec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ftsspec Spectral Density Estimation and Comparison for Functional Time\nSeries Functions for estimating spectral density operator of functional\n    time series (FTS) and comparing the spectral density operator of two\n    functional time series, in a way that allows detection of differences of\n    the spectral density operator in frequencies and along the curve length.  "
  },
  {
    "id": 12756,
    "package_name": "funbootband",
    "title": "Simultaneous Prediction and Confidence Bands for Time Series\nData",
    "description": "Provides methods to compute simultaneous prediction and confidence\n    bands for dense time series data. The implementation builds on the\n    functional bootstrap approach proposed by Lenhoff et al. (1999)\n    <doi:10.1016/S0966-6362(98)00043-5> and extended by Koska et al. (2023)\n    <doi:10.1016/j.jbiomech.2023.111506> to support both independent and\n    clustered (hierarchical) data. Includes a simple API (see band()) and an\n    'Rcpp' backend for performance.",
    "version": "0.2.0",
    "maintainer": "Daniel Koska <dkoska@proton.me>",
    "author": "Daniel Koska [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-8245-5222>)",
    "url": "https://github.com/koda86/funbootband-cran",
    "bug_reports": "https://github.com/koda86/funbootband-cran/issues",
    "repository": "https://cran.r-project.org/package=funbootband",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "funbootband Simultaneous Prediction and Confidence Bands for Time Series\nData Provides methods to compute simultaneous prediction and confidence\n    bands for dense time series data. The implementation builds on the\n    functional bootstrap approach proposed by Lenhoff et al. (1999)\n    <doi:10.1016/S0966-6362(98)00043-5> and extended by Koska et al. (2023)\n    <doi:10.1016/j.jbiomech.2023.111506> to support both independent and\n    clustered (hierarchical) data. Includes a simple API (see band()) and an\n    'Rcpp' backend for performance.  "
  },
  {
    "id": 12777,
    "package_name": "funtimes",
    "title": "Functions for Time Series Analysis",
    "description": "Nonparametric estimators and tests for time series analysis. The functions use bootstrap techniques and robust nonparametric difference-based estimators to test for the presence of possibly non-monotonic trends and for synchronicity of trends in multiple time series.",
    "version": "10.0",
    "maintainer": "Vyacheslav Lyubchich <lyubchich@umces.edu>",
    "author": "Vyacheslav Lyubchich [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7936-4285>),\n  Yulia R. Gel [aut],\n  Alexander Brenning [ctb],\n  Calvin Chu [ctb],\n  Xin Huang [ctb],\n  Umar Islambekov [ctb],\n  Palina Niamkova [ctb],\n  Dorcas Ofori-Boateng [ctb],\n  Ethan D. Schaeffer [ctb],\n  Srishti Vishwakarma [aut],\n  Xingyu Wang [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=funtimes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "funtimes Functions for Time Series Analysis Nonparametric estimators and tests for time series analysis. The functions use bootstrap techniques and robust nonparametric difference-based estimators to test for the presence of possibly non-monotonic trends and for synchronicity of trends in multiple time series.  "
  },
  {
    "id": 12898,
    "package_name": "garma",
    "title": "Fitting and Forecasting Gegenbauer ARMA Time Series Models",
    "description": "Methods for estimating univariate long memory-seasonal/cyclical\n             Gegenbauer time series processes. See for example (2022) <doi:10.1007/s00362-022-01290-3>.\n             Refer to the vignette for details of fitting these processes.",
    "version": "0.9.24",
    "maintainer": "Richard Hunt <maint@huntemail.id.au>",
    "author": "Richard Hunt [aut, cre]",
    "url": "https://github.com/rlph50/garma",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=garma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "garma Fitting and Forecasting Gegenbauer ARMA Time Series Models Methods for estimating univariate long memory-seasonal/cyclical\n             Gegenbauer time series processes. See for example (2022) <doi:10.1007/s00362-022-01290-3>.\n             Refer to the vignette for details of fitting these processes.  "
  },
  {
    "id": 12902,
    "package_name": "gasmodel",
    "title": "Generalized Autoregressive Score Models",
    "description": "Estimation, forecasting, and simulation of generalized\n    autoregressive score (GAS) models of Creal, Koopman, and Lucas (2013)\n    <doi:10.1002/jae.1279> and Harvey (2013) <doi:10.1017/cbo9781139540933>.\n    Model specification allows for various data types and distributions,\n    different parametrizations, exogenous variables, joint and separate modeling\n    of exogenous variables and dynamics, higher score and autoregressive orders,\n    custom and unconditional initial values of time-varying parameters, fixed\n    and bounded values of coefficients, and missing values. Model estimation is\n    performed by the maximum likelihood method.",
    "version": "0.6.2",
    "maintainer": "Vladim\u00edr Hol\u00fd <vladimir.holy@vse.cz>",
    "author": "Vladim\u00edr Hol\u00fd [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0416-0434>)",
    "url": "https://github.com/vladimirholy/gasmodel",
    "bug_reports": "https://github.com/vladimirholy/gasmodel/issues",
    "repository": "https://cran.r-project.org/package=gasmodel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gasmodel Generalized Autoregressive Score Models Estimation, forecasting, and simulation of generalized\n    autoregressive score (GAS) models of Creal, Koopman, and Lucas (2013)\n    <doi:10.1002/jae.1279> and Harvey (2013) <doi:10.1017/cbo9781139540933>.\n    Model specification allows for various data types and distributions,\n    different parametrizations, exogenous variables, joint and separate modeling\n    of exogenous variables and dynamics, higher score and autoregressive orders,\n    custom and unconditional initial values of time-varying parameters, fixed\n    and bounded values of coefficients, and missing values. Model estimation is\n    performed by the maximum likelihood method.  "
  },
  {
    "id": 12904,
    "package_name": "gastempt",
    "title": "Analyzing Gastric Emptying from MRI or Scintigraphy",
    "description": "Fits gastric emptying time series from MRI or 'scintigraphic' measurements\n   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with \n   Stan; computes derived parameters such as t50 and AUC.",
    "version": "0.7.0",
    "maintainer": "Dieter Menne <dieter.menne@menne-biomed.de>",
    "author": "Dieter Menne [aut, cre]",
    "url": "https://github.com/dmenne/gastempt,\nhttp://dmenne.github.io/gastempt/",
    "bug_reports": "https://github.com/dmenne/gastempt/issues",
    "repository": "https://cran.r-project.org/package=gastempt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gastempt Analyzing Gastric Emptying from MRI or Scintigraphy Fits gastric emptying time series from MRI or 'scintigraphic' measurements\n   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with \n   Stan; computes derived parameters such as t50 and AUC.  "
  },
  {
    "id": 12909,
    "package_name": "gauseR",
    "title": "Lotka-Volterra Models for Gause's 'Struggle for Existence'",
    "description": "A collection of tools and data for analyzing the Gause microcosm experiments, and for fitting Lotka-Volterra models to time series data. Includes methods for fitting single-species logistic growth, and multi-species interaction models, e.g. of competition, predator/prey relationships, or mutualism. See documentation for individual functions for examples. In general, see the lv_optim() function for examples of how to fit parameter values in multi-species systems. Note that the general methods applied here, as well as the form of the differential equations that we use, are described in detail in the Quantitative Ecology textbook by Lehman et al., available at <http://hdl.handle.net/11299/204551>, and in Lina K. M\u00fchlbauer, Maximilienne Schulze, W. Stanley Harpole, and Adam T. Clark. 'gauseR': Simple methods for fitting Lotka-Volterra models describing Gause's 'Struggle for Existence' in the journal Ecology and Evolution.",
    "version": "1.3",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "author": "Adam Clark [aut, cre] (ORCID: <https://orcid.org/0000-0002-8843-3278>),\n  Lina M\u00fchlbauer [aut],\n  Maximilienne Schulze [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gauseR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gauseR Lotka-Volterra Models for Gause's 'Struggle for Existence' A collection of tools and data for analyzing the Gause microcosm experiments, and for fitting Lotka-Volterra models to time series data. Includes methods for fitting single-species logistic growth, and multi-species interaction models, e.g. of competition, predator/prey relationships, or mutualism. See documentation for individual functions for examples. In general, see the lv_optim() function for examples of how to fit parameter values in multi-species systems. Note that the general methods applied here, as well as the form of the differential equations that we use, are described in detail in the Quantitative Ecology textbook by Lehman et al., available at <http://hdl.handle.net/11299/204551>, and in Lina K. M\u00fchlbauer, Maximilienne Schulze, W. Stanley Harpole, and Adam T. Clark. 'gauseR': Simple methods for fitting Lotka-Volterra models describing Gause's 'Struggle for Existence' in the journal Ecology and Evolution.  "
  },
  {
    "id": 12945,
    "package_name": "gdalcubes",
    "title": "Earth Observation Data Cubes from Satellite Image Collections",
    "description": "Processing collections of Earth observation images as on-demand multispectral, multitemporal raster data cubes. Users\n    define cubes by spatiotemporal extent, resolution, and spatial reference system and let 'gdalcubes' automatically apply cropping, reprojection, and \n    resampling using the 'Geospatial Data Abstraction Library' ('GDAL'). Implemented functions on data cubes include reduction over space and time, \n    applying arithmetic expressions on pixel band values, moving window aggregates over time, filtering by space, time, bands, and predicates on pixel values, \n    exporting data cubes as 'netCDF' or 'GeoTIFF' files, plotting, and extraction from spatial and or spatiotemporal features.  \n    All computational parts are implemented in C++, linking to the 'GDAL', 'netCDF', 'CURL', and 'SQLite' libraries. \n    See Appel and Pebesma (2019) <doi:10.3390/data4030092> for further details.",
    "version": "0.7.2",
    "maintainer": "Marius Appel <marius.appel@hs-bochum.de>",
    "author": "Marius Appel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5281-3896>),\n  Edzer Pebesma [ctb] (ORCID: <https://orcid.org/0000-0001-8049-7069>),\n  Roger Bivand [ctb],\n  Jeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Lewis Van Winkle [cph],\n  Ole Christian Eidheim [cph],\n  Howard Hinnant [cph],\n  Adrian Colomitchi [cph],\n  Florian Dang [cph],\n  Paul Thompson [cph],\n  Tomasz Kami\u0144ski [cph],\n  Dropbox, Inc. [cph]",
    "url": "https://github.com/appelmar/gdalcubes",
    "bug_reports": "https://github.com/appelmar/gdalcubes/issues/",
    "repository": "https://cran.r-project.org/package=gdalcubes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gdalcubes Earth Observation Data Cubes from Satellite Image Collections Processing collections of Earth observation images as on-demand multispectral, multitemporal raster data cubes. Users\n    define cubes by spatiotemporal extent, resolution, and spatial reference system and let 'gdalcubes' automatically apply cropping, reprojection, and \n    resampling using the 'Geospatial Data Abstraction Library' ('GDAL'). Implemented functions on data cubes include reduction over space and time, \n    applying arithmetic expressions on pixel band values, moving window aggregates over time, filtering by space, time, bands, and predicates on pixel values, \n    exporting data cubes as 'netCDF' or 'GeoTIFF' files, plotting, and extraction from spatial and or spatiotemporal features.  \n    All computational parts are implemented in C++, linking to the 'GDAL', 'netCDF', 'CURL', and 'SQLite' libraries. \n    See Appel and Pebesma (2019) <doi:10.3390/data4030092> for further details.  "
  },
  {
    "id": 12985,
    "package_name": "gen3sis",
    "title": "General Engine for Eco-Evolutionary Simulations",
    "description": "Contains an engine for spatially-explicit eco-evolutionary mechanistic models with a modular implementation and several support functions. It allows exploring the consequences of ecological and macroevolutionary processes across realistic or theoretical spatio-temporal landscapes on biodiversity patterns as a general term. Reference: Oskar Hagen, Benjamin Flueck, Fabian Fopp, Juliano S. Cabral, Florian Hartig, Mikael Pontarp, Thiago F. Rangel, Loic Pellissier (2021) \"gen3sis: A general engine for eco-evolutionary simulations of the processes that shape Earth's biodiversity\" <doi:10.1371/journal.pbio.3001340>.",
    "version": "1.6.0",
    "maintainer": "Oskar Hagen <oskar@hagen.bio>",
    "author": "ETH Z\u00fcrich [cph],\n  Oskar Hagen [aut, cre] (Landscape Ecology, WSL and ETH Z\u00fcrich,\n    Switzerland),\n  Benjamin Fl\u00fcck [aut] (Landscape Ecology, WSL and ETH Z\u00fcrich,\n    Switzerland),\n  Fabian Fopp [aut] (Landscape Ecology, WSL and ETH Z\u00fcrich, Switzerland),\n  Juliano S. Cabral [aut] (Ecosystem Modeling, Center for Computational\n    and Theoretical Biology, University of W\u00fcrzburg, W\u00fcrzburg, Germany),\n  Florian Hartig [aut] (Theoretical Ecology, University of Regensburg,\n    Regensburg, Germany),\n  Mikael Pontarp [aut] (Department of Biology, Lund University, Lund,\n    Sweden),\n  Charles Novaes de Santana [ctb] (Landscape Ecology, WSL and ETH Z\u00fcrich,\n    Switzerland),\n  Thiago F. Rangel [aut] (Department of Ecology, Universidade Federal de\n    Goi\u00e1s, Goi\u00e1s, Brazil),\n  Theo Gaboriau [ctb] (Depatment of Computational Biology, Lausanne\n    University, Switzerland),\n  Lo\u00efc Pellissier [aut, ths] (Landscape Ecology, WSL and ETH Z\u00fcrich,\n    Switzerland)",
    "url": "https://github.com/project-Gen3sis/R-package",
    "bug_reports": "https://github.com/project-Gen3sis/R-package/issues",
    "repository": "https://cran.r-project.org/package=gen3sis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gen3sis General Engine for Eco-Evolutionary Simulations Contains an engine for spatially-explicit eco-evolutionary mechanistic models with a modular implementation and several support functions. It allows exploring the consequences of ecological and macroevolutionary processes across realistic or theoretical spatio-temporal landscapes on biodiversity patterns as a general term. Reference: Oskar Hagen, Benjamin Flueck, Fabian Fopp, Juliano S. Cabral, Florian Hartig, Mikael Pontarp, Thiago F. Rangel, Loic Pellissier (2021) \"gen3sis: A general engine for eco-evolutionary simulations of the processes that shape Earth's biodiversity\" <doi:10.1371/journal.pbio.3001340>.  "
  },
  {
    "id": 13049,
    "package_name": "geoTS",
    "title": "Methods for Handling and Analyzing Time Series of Satellite\nImages",
    "description": "Provides functions and methods for: splitting large raster objects\n             into smaller chunks, transferring images from a binary format into raster \n             layers, transferring raster layers into an 'RData' file, calculating the \n             maximum gap (amount of consecutive missing values) of a numeric vector, \n             and fitting harmonic regression models to periodic time series. The homoscedastic\n             harmonic regression model is based on G. Roerink, M. Menenti and W. Verhoef (2000) <doi:10.1080/014311600209814>.",
    "version": "0.1.10",
    "maintainer": "Inder Tecuapetla-G\u00f3mez\n<itecuapetla@conabio.gob.mx>",
    "author": "Inder Tecuapetla-G\u00f3mez [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geoTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geoTS Methods for Handling and Analyzing Time Series of Satellite\nImages Provides functions and methods for: splitting large raster objects\n             into smaller chunks, transferring images from a binary format into raster \n             layers, transferring raster layers into an 'RData' file, calculating the \n             maximum gap (amount of consecutive missing values) of a numeric vector, \n             and fitting harmonic regression models to periodic time series. The homoscedastic\n             harmonic regression model is based on G. Roerink, M. Menenti and W. Verhoef (2000) <doi:10.1080/014311600209814>.  "
  },
  {
    "id": 13053,
    "package_name": "geocausal",
    "title": "Causal Inference with Spatio-Temporal Data",
    "description": "Spatio-temporal causal inference based on point process data. \n    You provide the raw data of locations and timings of treatment and \n    outcome events, specify counterfactual scenarios, and the package \n    estimates causal effects over specified spatial and temporal windows.\n    See Papadogeorgou, et  al. (2022) <doi:10.1111/rssb.12548> and\n    Mukaigawara, et al. (2024) <doi:10.31219/osf.io/5kc6f>.",
    "version": "0.3.4",
    "maintainer": "Mitsuru Mukaigawara <mitsuru_mukaigawara@g.harvard.edu>",
    "author": "Mitsuru Mukaigawara [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-6530-2083>),\n  Lingxiao Zhou [aut],\n  Georgia Papadogeorgou [aut] (ORCID:\n    <https://orcid.org/0000-0002-1982-2245>),\n  Jason Lyall [aut] (ORCID: <https://orcid.org/0000-0001-9117-7503>),\n  Kosuke Imai [aut] (ORCID: <https://orcid.org/0000-0002-2748-1022>)",
    "url": "https://github.com/mmukaigawara/geocausal",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geocausal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geocausal Causal Inference with Spatio-Temporal Data Spatio-temporal causal inference based on point process data. \n    You provide the raw data of locations and timings of treatment and \n    outcome events, specify counterfactual scenarios, and the package \n    estimates causal effects over specified spatial and temporal windows.\n    See Papadogeorgou, et  al. (2022) <doi:10.1111/rssb.12548> and\n    Mukaigawara, et al. (2024) <doi:10.31219/osf.io/5kc6f>.  "
  },
  {
    "id": 13066,
    "package_name": "geofi",
    "title": "Access Finnish Geospatial Data",
    "description": "Designed to simplify geospatial data access from the Statistics Finland Web Feature Service API <https://geo.stat.fi/geoserver/index.html>, the geofi package offers researchers and analysts a set of tools to obtain and harmonize administrative spatial data for a wide range of applications, from urban planning to environmental research. The package contains annually updated time series of municipality key datasets that can be used for data aggregation and language translations.",
    "version": "1.1.0",
    "maintainer": "Markus Kainu <markus.kainu@kapsi.fi>",
    "author": "Markus Kainu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1376-503X>),\n  Joona Lehtomaki [aut] (ORCID: <https://orcid.org/0000-0002-7891-0843>),\n  Juuso Parkkinen [ctb] (ORCID: <https://orcid.org/0000-0002-7818-5901>),\n  Jani Miettinen [ctb],\n  Pyry Kantanen [ctb],\n  Sampo Vesanen [ctb],\n  Leo Lahti [aut] (ORCID: <https://orcid.org/0000-0001-5537-637X>)",
    "url": "https://ropengov.github.io/geofi/,\nhttps://github.com/rOpenGov/geofi",
    "bug_reports": "https://github.com/rOpenGov/geofi/issues",
    "repository": "https://cran.r-project.org/package=geofi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geofi Access Finnish Geospatial Data Designed to simplify geospatial data access from the Statistics Finland Web Feature Service API <https://geo.stat.fi/geoserver/index.html>, the geofi package offers researchers and analysts a set of tools to obtain and harmonize administrative spatial data for a wide range of applications, from urban planning to environmental research. The package contains annually updated time series of municipality key datasets that can be used for data aggregation and language translations.  "
  },
  {
    "id": 13084,
    "package_name": "geomultistar",
    "title": "Multidimensional Queries Enriched with Geographic Data",
    "description": "Multidimensional systems allow complex queries to be carried\n    out in an easy way. The geographical dimension, together with the\n    temporal dimension, plays a fundamental role in multidimensional\n    systems. Through this package, vector geographic data layers can be\n    associated to the attributes of geographic dimensions, so that the\n    results of multidimensional queries can be obtained directly as vector\n    layers.  The multidimensional structures on which we can define the\n    queries can be created from a flat table or imported directly using\n    functions from this package.",
    "version": "1.2.2",
    "maintainer": "Jose Samos <jsamos@ugr.es>",
    "author": "Jose Samos [aut, cre] (ORCID: <https://orcid.org/0000-0002-4457-3439>),\n  Universidad de Granada [cph]",
    "url": "https://josesamos.github.io/geomultistar/,\nhttps://github.com/josesamos/geomultistar",
    "bug_reports": "https://github.com/josesamos/geomultistar/issues",
    "repository": "https://cran.r-project.org/package=geomultistar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geomultistar Multidimensional Queries Enriched with Geographic Data Multidimensional systems allow complex queries to be carried\n    out in an easy way. The geographical dimension, together with the\n    temporal dimension, plays a fundamental role in multidimensional\n    systems. Through this package, vector geographic data layers can be\n    associated to the attributes of geographic dimensions, so that the\n    results of multidimensional queries can be obtained directly as vector\n    layers.  The multidimensional structures on which we can define the\n    queries can be created from a flat table or imported directly using\n    functions from this package.  "
  },
  {
    "id": 13097,
    "package_name": "geospatialsuite",
    "title": "Comprehensive Geospatiotemporal Analysis and Multimodal\nIntegration Toolkit",
    "description": "A comprehensive toolkit for geospatiotemporal analysis\n    featuring 60+ vegetation indices, advanced raster visualization,\n    universal spatial mapping, water quality analysis, CDL crop analysis,\n    spatial interpolation, temporal analysis, and terrain analysis.\n    Designed for agricultural research, environmental monitoring, remote\n    sensing applications, and publication-quality mapping with support for\n    any geographic region and robust error handling. Methods include\n    vegetation indices calculations (Rouse et al. 1974), NDVI and enhanced\n    vegetation indices (Huete et al. 1997)\n    <doi:10.1016/S0034-4257(97)00104-1>, (Akanbi et al. 2024) \n    <doi:10.1007/s41651-023-00164-y>, spatial interpolation techniques\n    (Cressie 1993, ISBN:9780471002556), water quality indices (McFeeters\n    1996) <doi:10.1080/01431169608948714>, and crop data layer analysis\n    (USDA NASS 2024)\n    <https://www.nass.usda.gov/Research_and_Science/Cropland/>.  Funding:\n    This material is based upon financial support by the National Science\n    Foundation, EEC Division of Engineering Education and Centers, NSF\n    Engineering Research Center for Advancing Sustainable and Distributed\n    Fertilizer production (CASFER), NSF 20-553 Gen-4 Engineering Research\n    Centers award 2133576.",
    "version": "0.1.1",
    "maintainer": "Olatunde D. Akanbi <olatunde.akanbi@case.edu>",
    "author": "Olatunde D. Akanbi [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7719-2619>),\n  Vibha Mandayam [aut] (ORCID: <https://orcid.org/0009-0008-8628-9904>),\n  Yinghui Wu [aut] (ORCID: <https://orcid.org/0000-0003-3991-5155>),\n  Jeffrey Yarus [aut] (ORCID: <https://orcid.org/0000-0002-9331-9568>),\n  Erika I. Barcelos [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-9273-8488>),\n  Roger H. French [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-6162-0532>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geospatialsuite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geospatialsuite Comprehensive Geospatiotemporal Analysis and Multimodal\nIntegration Toolkit A comprehensive toolkit for geospatiotemporal analysis\n    featuring 60+ vegetation indices, advanced raster visualization,\n    universal spatial mapping, water quality analysis, CDL crop analysis,\n    spatial interpolation, temporal analysis, and terrain analysis.\n    Designed for agricultural research, environmental monitoring, remote\n    sensing applications, and publication-quality mapping with support for\n    any geographic region and robust error handling. Methods include\n    vegetation indices calculations (Rouse et al. 1974), NDVI and enhanced\n    vegetation indices (Huete et al. 1997)\n    <doi:10.1016/S0034-4257(97)00104-1>, (Akanbi et al. 2024) \n    <doi:10.1007/s41651-023-00164-y>, spatial interpolation techniques\n    (Cressie 1993, ISBN:9780471002556), water quality indices (McFeeters\n    1996) <doi:10.1080/01431169608948714>, and crop data layer analysis\n    (USDA NASS 2024)\n    <https://www.nass.usda.gov/Research_and_Science/Cropland/>.  Funding:\n    This material is based upon financial support by the National Science\n    Foundation, EEC Division of Engineering Education and Centers, NSF\n    Engineering Research Center for Advancing Sustainable and Distributed\n    Fertilizer production (CASFER), NSF 20-553 Gen-4 Engineering Research\n    Centers award 2133576.  "
  },
  {
    "id": 13099,
    "package_name": "geosptdb",
    "title": "Spatio-Temporal Radial Basis Functions with Distance-Based\nMethods (Optimization, Prediction and Cross Validation)",
    "description": "Spatio-temporal radial basis functions (optimization, prediction and cross-validation), summary statistics from cross-validation, Adjusting distance-based linear regression model and generation of the principal coordinates of a new individual from Gower's distance.",
    "version": "1.0-2",
    "maintainer": "Carlos Melo <cmelo@udistrital.edu.co>",
    "author": "Carlos Melo [aut, cre] (ORCID: <https://orcid.org/0000-0002-5598-1913>),\n  Oscar Melo [aut] (ORCID: <https://orcid.org/0000-0002-0296-4511>),\n  Sandra Melo [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geosptdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geosptdb Spatio-Temporal Radial Basis Functions with Distance-Based\nMethods (Optimization, Prediction and Cross Validation) Spatio-temporal radial basis functions (optimization, prediction and cross-validation), summary statistics from cross-validation, Adjusting distance-based linear regression model and generation of the principal coordinates of a new individual from Gower's distance.  "
  },
  {
    "id": 13158,
    "package_name": "ggTimeSeries",
    "title": "Time Series Visualisations Using the Grammar of Graphics",
    "description": "Provides additional display mediums for time series visualisations.",
    "version": "1.0.2",
    "maintainer": "Aditya Kothari <mail.thecomeonman@gmail.com>",
    "author": "Aditya Kothari [cre, aut],\n  Ather Energy [cph],\n  Jesse Vent [ctb]",
    "url": "https://github.com/thecomeonman/ggTimeSeries",
    "bug_reports": "https://github.com/thecomeonman/ggTimeSeries/issues",
    "repository": "https://cran.r-project.org/package=ggTimeSeries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggTimeSeries Time Series Visualisations Using the Grammar of Graphics Provides additional display mediums for time series visualisations.  "
  },
  {
    "id": 13206,
    "package_name": "ggfields",
    "title": "Add Vector Field Layers to Ggplots",
    "description": "Add vector field layers to ggplots. Ideal for visualising\n    wind speeds, water currents, electric/magnetic fields, etc.\n    Accepts data.frames, simple features (sf), and spatiotemporal arrays (stars)\n    objects as input. Vector fields are depicted as arrows starting at specified\n    locations, and with specified angles and radii.",
    "version": "0.0.7",
    "maintainer": "Pepijn de Vries <pepijn.devries@outlook.com>",
    "author": "Pepijn de Vries [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7961-6646>)",
    "url": "https://pepijn-devries.github.io/ggfields/,\nhttps://github.com/pepijn-devries/ggfields/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ggfields",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggfields Add Vector Field Layers to Ggplots Add vector field layers to ggplots. Ideal for visualising\n    wind speeds, water currents, electric/magnetic fields, etc.\n    Accepts data.frames, simple features (sf), and spatiotemporal arrays (stars)\n    objects as input. Vector fields are depicted as arrows starting at specified\n    locations, and with specified angles and radii.  "
  },
  {
    "id": 13214,
    "package_name": "ggfortify",
    "title": "Data Visualization Tools for Statistical Analysis Results",
    "description": "Unified plotting tools for statistics commonly used, such as GLM,\n    time series, PCA families, clustering and survival analysis. The package offers\n    a single plotting interface for these analysis results and plots in a unified\n    style using 'ggplot2'.",
    "version": "0.4.19",
    "maintainer": "Yuan Tang <terrytangyuan@gmail.com>",
    "author": "Masaaki Horikoshi [aut],\n  Yuan Tang [aut, cre] (ORCID: <https://orcid.org/0000-0001-5243-233X>),\n  Austin Dickey [ctb],\n  Matthias Greni\u00e9 [ctb],\n  Ryan Thompson [ctb],\n  Luciano Selzer [ctb],\n  Dario Strbenac [ctb],\n  Kirill Voronin [ctb],\n  Damir Pulatov [ctb]",
    "url": "https://github.com/sinhrks/ggfortify",
    "bug_reports": "https://github.com/sinhrks/ggfortify/issues",
    "repository": "https://cran.r-project.org/package=ggfortify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggfortify Data Visualization Tools for Statistical Analysis Results Unified plotting tools for statistics commonly used, such as GLM,\n    time series, PCA families, clustering and survival analysis. The package offers\n    a single plotting interface for these analysis results and plots in a unified\n    style using 'ggplot2'.  "
  },
  {
    "id": 13243,
    "package_name": "gglinedensity",
    "title": "Make DenseLines Heatmaps with 'ggplot2'",
    "description": "Visualise overlapping time series lines as a heatmap of line\n    density. Provides a 'ggplot2' statistic implementing the DenseLines\n    algorithm, which \"normalizes time series by the arc length to compute\n    accurate densities\"\n    (Moritz and Fisher, 2018) <doi:10.48550/arXiv.1808.06019>.",
    "version": "0.2.0",
    "maintainer": "Harry Thompson <harry@mayesfield.uk>",
    "author": "Harry Thompson [cre, aut, cph],\n  Dominik Moritz [aut] (Rust original,\n    <https://github.com/domoritz/line-density-rust>),\n  The authors of the dependency Rust crates [ctb] (see inst/AUTHORS file\n    for details),\n  Hiroaki Yutani [ctb] (ORCID: <https://orcid.org/0000-0002-3385-7233>,\n    Scripts where noted,\n    <https://yutannihilation.github.io/string2path>)",
    "url": "https://github.com/hrryt/gglinedensity,\nhttps://hrryt.github.io/gglinedensity/",
    "bug_reports": "https://github.com/hrryt/gglinedensity/issues",
    "repository": "https://cran.r-project.org/package=gglinedensity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gglinedensity Make DenseLines Heatmaps with 'ggplot2' Visualise overlapping time series lines as a heatmap of line\n    density. Provides a 'ggplot2' statistic implementing the DenseLines\n    algorithm, which \"normalizes time series by the arc length to compute\n    accurate densities\"\n    (Moritz and Fisher, 2018) <doi:10.48550/arXiv.1808.06019>.  "
  },
  {
    "id": 13319,
    "package_name": "ggsmc",
    "title": "Visualising Output from Sequential Monte Carlo and\nEnsemble-Based Methods",
    "description": "Functions for plotting, and animating, the output of importance samplers, sequential Monte Carlo samplers (SMC) and ensemble-based methods. The package can be used to plot and animate histograms, densities, scatter plots and time series, and to plot the genealogy of an SMC or ensemble-based algorithm. These functions all rely on algorithm output to be supplied in tidy format. A function is provided to transform algorithm output from matrix format (one Monte Carlo point per row) to the tidy format required by the plotting and animating functions.",
    "version": "0.2.0",
    "maintainer": "Richard G Everitt <richard.g.everitt@gmail.com>",
    "author": "Richard G Everitt [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0822-5648>)",
    "url": "https://github.com/richardgeveritt/ggsmc,\nhttps://richardgeveritt.github.io/ggsmc/",
    "bug_reports": "https://github.com/richardgeveritt/ggsmc/issues",
    "repository": "https://cran.r-project.org/package=ggsmc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggsmc Visualising Output from Sequential Monte Carlo and\nEnsemble-Based Methods Functions for plotting, and animating, the output of importance samplers, sequential Monte Carlo samplers (SMC) and ensemble-based methods. The package can be used to plot and animate histograms, densities, scatter plots and time series, and to plot the genealogy of an SMC or ensemble-based algorithm. These functions all rely on algorithm output to be supplied in tidy format. A function is provided to transform algorithm output from matrix format (one Monte Carlo point per row) to the tidy format required by the plotting and animating functions.  "
  },
  {
    "id": 13332,
    "package_name": "ggsurveillance",
    "title": "Tools for Outbreak Investigation/Infectious Disease Surveillance",
    "description": "Create epicurves, epigantt charts, and diverging bar charts\n    using 'ggplot2'. Prepare data for visualisation or other reporting for\n    infectious disease surveillance and outbreak investigation (time\n    series data).  Includes tidy functions to solve date based\n    transformations for common reporting tasks, like (A) seasonal date\n    alignment for respiratory disease surveillance, (B) date-based case\n    binning based on specified time intervals like isoweek, epiweek, month\n    and more, (C) automated detection and marking of the new year based on\n    the date/datetime axis of the 'ggplot2', (D) labelling of the last\n    value of a time-series.  An introduction on how to use epicurves can\n    be found on the US CDC website (2012,\n    <https://www.cdc.gov/training/quicklearns/epimode/index.html>).",
    "version": "0.5.2",
    "maintainer": "Alexander Bartel <alexander.bartel@fu-berlin.de>",
    "author": "Alexander Bartel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1280-6138>)",
    "url": "https://ggsurveillance.biostats.dev,\nhttps://github.com/biostats-dev/ggsurveillance",
    "bug_reports": "https://github.com/biostats-dev/ggsurveillance/issues",
    "repository": "https://cran.r-project.org/package=ggsurveillance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggsurveillance Tools for Outbreak Investigation/Infectious Disease Surveillance Create epicurves, epigantt charts, and diverging bar charts\n    using 'ggplot2'. Prepare data for visualisation or other reporting for\n    infectious disease surveillance and outbreak investigation (time\n    series data).  Includes tidy functions to solve date based\n    transformations for common reporting tasks, like (A) seasonal date\n    alignment for respiratory disease surveillance, (B) date-based case\n    binning based on specified time intervals like isoweek, epiweek, month\n    and more, (C) automated detection and marking of the new year based on\n    the date/datetime axis of the 'ggplot2', (D) labelling of the last\n    value of a time-series.  An introduction on how to use epicurves can\n    be found on the US CDC website (2012,\n    <https://www.cdc.gov/training/quicklearns/epimode/index.html>).  "
  },
  {
    "id": 13345,
    "package_name": "ggtime",
    "title": "Grammar of Graphics and Plot Helpers for Time Series\nVisualization",
    "description": "Extends the capabilities of 'ggplot2' by providing grammatical\n    elements and plot helpers designed for visualizing temporal patterns. The \n    package implements a grammar of temporal graphics, which leverages calendar\n    structures to highlight changes over time. The package also provides plot \n    helper functions to quickly produce commonly used time series graphics,\n    including time plots, season plots, and seasonal sub-series plots.",
    "version": "0.1.0",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Cynthia A. Huang [aut] (ORCID: <https://orcid.org/0000-0002-9218-987X>),\n  Matthew Kay [aut] (ORCID: <https://orcid.org/0000-0001-9446-0419>),\n  Rob Hyndman [aut] (ORCID: <https://orcid.org/0000-0002-2140-5352>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ggtime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggtime Grammar of Graphics and Plot Helpers for Time Series\nVisualization Extends the capabilities of 'ggplot2' by providing grammatical\n    elements and plot helpers designed for visualizing temporal patterns. The \n    package implements a grammar of temporal graphics, which leverages calendar\n    structures to highlight changes over time. The package also provides plot \n    helper functions to quickly produce commonly used time series graphics,\n    including time plots, season plots, and seasonal sub-series plots.  "
  },
  {
    "id": 13371,
    "package_name": "gifski",
    "title": "Highest Quality GIF Encoder",
    "description": "Multi-threaded GIF encoder written in Rust: <https://gif.ski/>. \n    Converts images to GIF animations using pngquant's efficient cross-frame \n    palettes and temporal dithering with thousands of colors per frame.",
    "version": "1.32.0-2",
    "maintainer": "Jeroen Ooms <jeroenooms@gmail.com>",
    "author": "Jeroen Ooms [aut, cre] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Kornel Lesi\u0144ski [aut] (Gifski Rust library),\n  Authors of the dependency Rust crates [aut] (see AUTHORS file)",
    "url": "https://r-rust.r-universe.dev/gifski",
    "bug_reports": "https://github.com/r-rust/gifski/issues",
    "repository": "https://cran.r-project.org/package=gifski",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gifski Highest Quality GIF Encoder Multi-threaded GIF encoder written in Rust: <https://gif.ski/>. \n    Converts images to GIF animations using pngquant's efficient cross-frame \n    palettes and temporal dithering with thousands of colors per frame.  "
  },
  {
    "id": 13376,
    "package_name": "gimme",
    "title": "Group Iterative Multiple Model Estimation",
    "description": "Data-driven approach for arriving at person-specific time series models. The method first identifies which relations replicate across the majority of individuals to detect signal from noise. These group-level relations are then used as a foundation for starting the search for person-specific (or individual-level) relations. See Gates & Molenaar (2012) <doi:10.1016/j.neuroimage.2012.06.026>. ",
    "version": "0.9.3",
    "maintainer": "Kathleen M Gates <gateskm@email.unc.edu>",
    "author": "Stephanie Lane [aut, trl],\n  Kathleen M Gates [aut, cre, ccp],\n  Zachary Fisher [aut],\n  Cara Arizmendi [aut],\n  Peter Molenaar [aut, ccp],\n  Edgar Merkle [ctb],\n  Michael Hallquist [ctb],\n  Hallie Pike [ctb],\n  Teague Henry [ctb],\n  Kelly Duffy [ctb],\n  Lan Luo [ctb],\n  Adriene Beltz [csp],\n  Aidan Wright [csp],\n  Jonathan Park [ctb],\n  Sebastian Castro Alvarez [ctb],\n  Bj\u00f6rn Siepe [ctb]",
    "url": "https://github.com/GatesLab/gimme/,\nhttps://tarheels.live/gimme/tutorials/",
    "bug_reports": "https://github.com/GatesLab/gimme/issues",
    "repository": "https://cran.r-project.org/package=gimme",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gimme Group Iterative Multiple Model Estimation Data-driven approach for arriving at person-specific time series models. The method first identifies which relations replicate across the majority of individuals to detect signal from noise. These group-level relations are then used as a foundation for starting the search for person-specific (or individual-level) relations. See Gates & Molenaar (2012) <doi:10.1016/j.neuroimage.2012.06.026>.   "
  },
  {
    "id": 13401,
    "package_name": "glarma",
    "title": "Generalized Linear Autoregressive Moving Average Models",
    "description": "Functions are provided for estimation, testing, diagnostic checking and forecasting of generalized linear autoregressive moving average (GLARMA) models for discrete valued time series with regression variables.  These are a class of observation driven non-linear non-Gaussian state space models. The state vector consists of a linear regression component plus an observation driven component consisting of an autoregressive-moving average (ARMA) filter of past predictive residuals. Currently three distributions (Poisson, negative binomial and binomial) can be used for the response series. Three options (Pearson, score-type and unscaled) for the residuals in the observation driven component are available. Estimation is via maximum likelihood (conditional on initializing values for the ARMA process) optimized using Fisher scoring or Newton Raphson iterative methods. Likelihood ratio and Wald tests for the observation driven component allow testing for serial dependence in generalized linear model settings. Graphical diagnostics including model fits, autocorrelation functions and probability integral transform residuals are included in the package. Several standard data sets are included in the package.",
    "version": "1.7-1",
    "maintainer": "William T.M. Dunsmuir <w.dunsmuir@unsw.edu.au>",
    "author": "William T.M. Dunsmuir [aut, cre],\n  Cenanning Li [aut],\n  David J. Scott [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glarma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glarma Generalized Linear Autoregressive Moving Average Models Functions are provided for estimation, testing, diagnostic checking and forecasting of generalized linear autoregressive moving average (GLARMA) models for discrete valued time series with regression variables.  These are a class of observation driven non-linear non-Gaussian state space models. The state vector consists of a linear regression component plus an observation driven component consisting of an autoregressive-moving average (ARMA) filter of past predictive residuals. Currently three distributions (Poisson, negative binomial and binomial) can be used for the response series. Three options (Pearson, score-type and unscaled) for the residuals in the observation driven component are available. Estimation is via maximum likelihood (conditional on initializing values for the ARMA process) optimized using Fisher scoring or Newton Raphson iterative methods. Likelihood ratio and Wald tests for the observation driven component allow testing for serial dependence in generalized linear model settings. Graphical diagnostics including model fits, autocorrelation functions and probability integral transform residuals are included in the package. Several standard data sets are included in the package.  "
  },
  {
    "id": 13433,
    "package_name": "glmmfields",
    "title": "Generalized Linear Mixed Models with Robust Random Fields for\nSpatiotemporal Modeling",
    "description": "Implements Bayesian spatial and spatiotemporal\n    models that optionally allow for extreme spatial deviations through\n    time. 'glmmfields' uses a predictive process approach with random\n    fields implemented through a multivariate-t distribution instead of\n    the usual multivariate normal.  Sampling is conducted with 'Stan'.\n    References: Anderson and Ward (2019) <doi:10.1002/ecy.2403>.",
    "version": "0.1.8",
    "maintainer": "Sean C. Anderson <sean@seananderson.ca>",
    "author": "Sean C. Anderson [aut, cre],\n  Eric J. Ward [aut],\n  Trustees of Columbia University [cph]",
    "url": "https://github.com/seananderson/glmmfields",
    "bug_reports": "https://github.com/seananderson/glmmfields/issues",
    "repository": "https://cran.r-project.org/package=glmmfields",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glmmfields Generalized Linear Mixed Models with Robust Random Fields for\nSpatiotemporal Modeling Implements Bayesian spatial and spatiotemporal\n    models that optionally allow for extreme spatial deviations through\n    time. 'glmmfields' uses a predictive process approach with random\n    fields implemented through a multivariate-t distribution instead of\n    the usual multivariate normal.  Sampling is conducted with 'Stan'.\n    References: Anderson and Ward (2019) <doi:10.1002/ecy.2403>.  "
  },
  {
    "id": 13435,
    "package_name": "glmmrOptim",
    "title": "Approximate Optimal Experimental Designs Using Generalised\nLinear Mixed Models",
    "description": "Optimal design analysis algorithms for any study design that can be represented or\n  modelled as a generalised linear mixed model including cluster randomised trials,\n  cohort studies, spatial and temporal epidemiological studies, and split-plot designs.\n  See <https://github.com/samuel-watson/glmmrBase/blob/master/README.md> for a\n  detailed manual on model specification. A detailed discussion of the methods in this\n  package can be found in Watson, Hemming, and Girling (2023) <doi:10.1177/09622802231202379>.",
    "version": "0.3.6",
    "maintainer": "Sam Watson <S.I.Watson@bham.ac.uk>",
    "author": "Sam Watson [aut, cre],\n  Yi Pan [aut]",
    "url": "https://github.com/samuel-watson/glmmrOptim",
    "bug_reports": "https://github.com/samuel-watson/glmmrOptim/issues",
    "repository": "https://cran.r-project.org/package=glmmrOptim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glmmrOptim Approximate Optimal Experimental Designs Using Generalised\nLinear Mixed Models Optimal design analysis algorithms for any study design that can be represented or\n  modelled as a generalised linear mixed model including cluster randomised trials,\n  cohort studies, spatial and temporal epidemiological studies, and split-plot designs.\n  See <https://github.com/samuel-watson/glmmrBase/blob/master/README.md> for a\n  detailed manual on model specification. A detailed discussion of the methods in this\n  package can be found in Watson, Hemming, and Girling (2023) <doi:10.1177/09622802231202379>.  "
  },
  {
    "id": 13462,
    "package_name": "glossa",
    "title": "User-Friendly 'shiny' App for Bayesian Species Distribution\nModels",
    "description": "A user-friendly 'shiny' application for Bayesian machine\n    learning analysis of marine species distributions. GLOSSA (Global\n    Ocean Species Spatio-temporal Analysis) uses Bayesian Additive\n    Regression Trees (BART; Chipman, George, and McCulloch (2010)\n    <doi:10.1214/09-AOAS285>) to model species distributions with\n    intuitive workflows for data upload, processing, model fitting, and\n    result visualization. It supports presence-absence and presence-only\n    data (with pseudo-absence generation), spatial thinning,\n    cross-validation, and scenario-based projections. GLOSSA is designed\n    to facilitate ecological research by providing easy-to-use tools for\n    analyzing and visualizing marine species distributions across\n    different spatial and temporal scales. Optionally, pseudo-absences can\n    be generated within the environmental space using the external package\n    'flexsdm' (not on CRAN), which can be downloaded from\n    <https://github.com/sjevelazco/flexsdm>; this functionality is used\n    conditionally when available and all core features work without it.",
    "version": "1.2.4",
    "maintainer": "Jorge Mestre-Tom\u00e1s <jorge.mestre.tomas@csic.es>",
    "author": "Jorge Mestre-Tom\u00e1s [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8983-3417>),\n  Alba Fuster-Alonso [aut] (ORCID:\n    <https://orcid.org/0000-0002-7283-291X>)",
    "url": "https://github.com/iMARES-group/glossa,\nhttps://iMARES-group.github.io/glossa/",
    "bug_reports": "https://github.com/iMARES-group/glossa/issues",
    "repository": "https://cran.r-project.org/package=glossa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glossa User-Friendly 'shiny' App for Bayesian Species Distribution\nModels A user-friendly 'shiny' application for Bayesian machine\n    learning analysis of marine species distributions. GLOSSA (Global\n    Ocean Species Spatio-temporal Analysis) uses Bayesian Additive\n    Regression Trees (BART; Chipman, George, and McCulloch (2010)\n    <doi:10.1214/09-AOAS285>) to model species distributions with\n    intuitive workflows for data upload, processing, model fitting, and\n    result visualization. It supports presence-absence and presence-only\n    data (with pseudo-absence generation), spatial thinning,\n    cross-validation, and scenario-based projections. GLOSSA is designed\n    to facilitate ecological research by providing easy-to-use tools for\n    analyzing and visualizing marine species distributions across\n    different spatial and temporal scales. Optionally, pseudo-absences can\n    be generated within the environmental space using the external package\n    'flexsdm' (not on CRAN), which can be downloaded from\n    <https://github.com/sjevelazco/flexsdm>; this functionality is used\n    conditionally when available and all core features work without it.  "
  },
  {
    "id": 13481,
    "package_name": "gmgm",
    "title": "Gaussian Mixture Graphical Model Learning and Inference",
    "description": "Gaussian mixture graphical models include Bayesian networks and\n    dynamic Bayesian networks (their temporal extension) whose local probability\n    distributions are described by Gaussian mixture models. They are powerful\n    tools for graphically and quantitatively representing nonlinear dependencies\n    between continuous variables. This package provides a complete framework to\n    create, manipulate, learn the structure and the parameters, and perform\n    inference in these models. Most of the algorithms are described in the PhD\n    thesis of Roos (2018) <https://tel.archives-ouvertes.fr/tel-01943718>.",
    "version": "1.1.2",
    "maintainer": "J\u00e9r\u00e9my Roos <jeremy.roos@gmail.com>",
    "author": "J\u00e9r\u00e9my Roos [aut, cre, cph],\n  RATP Group [fnd, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gmgm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gmgm Gaussian Mixture Graphical Model Learning and Inference Gaussian mixture graphical models include Bayesian networks and\n    dynamic Bayesian networks (their temporal extension) whose local probability\n    distributions are described by Gaussian mixture models. They are powerful\n    tools for graphically and quantitatively representing nonlinear dependencies\n    between continuous variables. This package provides a complete framework to\n    create, manipulate, learn the structure and the parameters, and perform\n    inference in these models. Most of the algorithms are described in the PhD\n    thesis of Roos (2018) <https://tel.archives-ouvertes.fr/tel-01943718>.  "
  },
  {
    "id": 13493,
    "package_name": "gmvarkit",
    "title": "Estimate Gaussian and Student's t Mixture Vector Autoregressive\nModels",
    "description": "Unconstrained and constrained maximum likelihood estimation of structural and reduced form \n    Gaussian mixture vector autoregressive, Student's t mixture vector autoregressive, and Gaussian and Student's t\n    mixture vector autoregressive models, quantile residual tests, graphical diagnostics,\n    simulations, forecasting, and estimation of generalized impulse response function and generalized \n    forecast error variance decomposition.\n    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2016) <doi:10.1016/j.jeconom.2016.02.012>,\n    Savi Virolainen (2025) <doi:10.1080/07350015.2024.2322090>,\n    Savi Virolainen (in press) <doi:10.1016/j.ecosta.2025.09.003>.",
    "version": "2.2.1",
    "maintainer": "Savi Virolainen <savi.virolainen@helsinki.fi>",
    "author": "Savi Virolainen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5075-6821>)",
    "url": "",
    "bug_reports": "https://github.com/saviviro/gmvarkit/issues",
    "repository": "https://cran.r-project.org/package=gmvarkit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gmvarkit Estimate Gaussian and Student's t Mixture Vector Autoregressive\nModels Unconstrained and constrained maximum likelihood estimation of structural and reduced form \n    Gaussian mixture vector autoregressive, Student's t mixture vector autoregressive, and Gaussian and Student's t\n    mixture vector autoregressive models, quantile residual tests, graphical diagnostics,\n    simulations, forecasting, and estimation of generalized impulse response function and generalized \n    forecast error variance decomposition.\n    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2016) <doi:10.1016/j.jeconom.2016.02.012>,\n    Savi Virolainen (2025) <doi:10.1080/07350015.2024.2322090>,\n    Savi Virolainen (in press) <doi:10.1016/j.ecosta.2025.09.003>.  "
  },
  {
    "id": 13590,
    "package_name": "grandR",
    "title": "Comprehensive Analysis of Nucleotide Conversion Sequencing Data",
    "description": "Nucleotide conversion sequencing experiments have been\n  developed to add a temporal dimension to RNA-seq and single-cell RNA-seq. Such \n  experiments require specialized tools for primary processing such as GRAND-SLAM,\n  (see 'J\u00fcrges et al' <doi:10.1093/bioinformatics/bty256>) and specialized tools for \n  downstream analyses. 'grandR' provides a comprehensive toolbox for quality control,\n  kinetic modeling, differential gene expression analysis and visualization of such data.",
    "version": "0.2.6",
    "maintainer": "Florian Erhard <Florian.Erhard@informatik.uni-regensburg.de>",
    "author": "Florian Erhard [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3574-6983>),\n  Teresa Rummel [ctb],\n  Lygeri Sakellaridi [ctb],\n  Kevin Berg [ctb]",
    "url": "https://github.com/erhard-lab/grandR",
    "bug_reports": "https://github.com/erhard-lab/grandR/issues",
    "repository": "https://cran.r-project.org/package=grandR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "grandR Comprehensive Analysis of Nucleotide Conversion Sequencing Data Nucleotide conversion sequencing experiments have been\n  developed to add a temporal dimension to RNA-seq and single-cell RNA-seq. Such \n  experiments require specialized tools for primary processing such as GRAND-SLAM,\n  (see 'J\u00fcrges et al' <doi:10.1093/bioinformatics/bty256>) and specialized tools for \n  downstream analyses. 'grandR' provides a comprehensive toolbox for quality control,\n  kinetic modeling, differential gene expression analysis and visualization of such data.  "
  },
  {
    "id": 13617,
    "package_name": "gratis",
    "title": "Generating Time Series with Diverse and Controllable\nCharacteristics",
    "description": "Generates synthetic time series based on various univariate\n    time series models including MAR and ARIMA processes. Kang, Y.,\n    Hyndman, R.J., Li, F.(2020) <doi:10.1002/sam.11461>.",
    "version": "1.0.7",
    "maintainer": "Feng Li <feng.li@cufe.edu.cn>",
    "author": "Yanfei Kang [aut] (ORCID: <https://orcid.org/0000-0001-8769-6650>),\n  Feng Li [aut, cre] (ORCID: <https://orcid.org/0000-0002-4248-9778>),\n  Rob Hyndman [aut] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Mitchell O'Hara-Wild [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Bocong Zhao [ctb] (ORCID: <https://orcid.org/0000-0001-8434-9047>)",
    "url": "https://github.com/ykang/gratis",
    "bug_reports": "https://github.com/ykang/gratis/issues/",
    "repository": "https://cran.r-project.org/package=gratis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gratis Generating Time Series with Diverse and Controllable\nCharacteristics Generates synthetic time series based on various univariate\n    time series models including MAR and ARIMA processes. Kang, Y.,\n    Hyndman, R.J., Li, F.(2020) <doi:10.1002/sam.11461>.  "
  },
  {
    "id": 13620,
    "package_name": "gravitas",
    "title": "Explore Probability Distributions for Bivariate Temporal\nGranularities",
    "description": "Provides tools for systematically exploring large quantities of \n             temporal data across cyclic temporal granularities\n             (deconstructions of time) by visualizing probability distributions.\n             Cyclic time granularities can be circular, quasi-circular or \n             aperiodic. 'gravitas' computes cyclic\n             single-order-up or multiple-order-up granularities, check the\n             feasibility of creating plots for any two cyclic granularities\n             and recommend probability distributions plots for exploring\n             periodicity in the data.",
    "version": "0.1.3",
    "maintainer": "Sayani Gupta <gupta.sayani@gmail.com>",
    "author": "Sayani Gupta [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0643-5358>),\n  Rob Hyndman [aut, ths] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Di Cook [aut, ths] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Antony Unwin [aut] (ORCID: <https://orcid.org/0000-0002-5841-5757>)",
    "url": "https://github.com/Sayani07/gravitas/",
    "bug_reports": "https://github.com/Sayani07/gravitas/issues",
    "repository": "https://cran.r-project.org/package=gravitas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gravitas Explore Probability Distributions for Bivariate Temporal\nGranularities Provides tools for systematically exploring large quantities of \n             temporal data across cyclic temporal granularities\n             (deconstructions of time) by visualizing probability distributions.\n             Cyclic time granularities can be circular, quasi-circular or \n             aperiodic. 'gravitas' computes cyclic\n             single-order-up or multiple-order-up granularities, check the\n             feasibility of creating plots for any two cyclic granularities\n             and recommend probability distributions plots for exploring\n             periodicity in the data.  "
  },
  {
    "id": 13629,
    "package_name": "greenSD",
    "title": "Access and Analyze Global GreenSpace Spatial Data",
    "description": "Access and analyze multi-band greenspace seasonality data cubes \n  (available for 1,028 major global cities), global Normalized Difference \n  Vegetation Index / land cover data from the European Space Agency \n  WorldCover 10m Dataset, and Sentinel-2-l2a images. Users can download data \n  using bounding boxes, city names, and filter by year or seasonal time window. \n  The package also supports calculating human exposure to greenspace using a \n  population-weighted greenspace exposure model introduced by \n  Chen et al. (2022) <doi:10.1038/s41467-022-32258-4> based on Global Human \n  Settlement Layer population data, and calculating a set of greenspace \n  morphology metrics at patch and landscape levels.",
    "version": "0.1.1",
    "maintainer": "Xiaohao Yang <xiaohaoy111@gmail.com>",
    "author": "Xiaohao Yang [aut, cre, cph]",
    "url": "https://github.com/billbillbilly/greenSD,\nhttps://billbillbilly.github.io/greenSD/",
    "bug_reports": "https://github.com/billbillbilly/greenSD/issues",
    "repository": "https://cran.r-project.org/package=greenSD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "greenSD Access and Analyze Global GreenSpace Spatial Data Access and analyze multi-band greenspace seasonality data cubes \n  (available for 1,028 major global cities), global Normalized Difference \n  Vegetation Index / land cover data from the European Space Agency \n  WorldCover 10m Dataset, and Sentinel-2-l2a images. Users can download data \n  using bounding boxes, city names, and filter by year or seasonal time window. \n  The package also supports calculating human exposure to greenspace using a \n  population-weighted greenspace exposure model introduced by \n  Chen et al. (2022) <doi:10.1038/s41467-022-32258-4> based on Global Human \n  Settlement Layer population data, and calculating a set of greenspace \n  morphology metrics at patch and landscape levels.  "
  },
  {
    "id": 13637,
    "package_name": "gretlR",
    "title": "A Seamless Integration of 'Gretl' and 'R'",
    "description": "It allows running 'gretl' (<http://gretl.sourceforge.net/index.html>) program from R, R Markdown and Quarto. 'gretl' ('Gnu' Regression, 'Econometrics', and Time-series Library) is a statistical software for Econometric analysis.  This package does not only integrate 'gretl' and 'R' but also serves  as a 'gretl' Knit-Engine for 'knitr' package. Write all your 'gretl' commands in 'R', R Markdown chunk.",
    "version": "0.1.4",
    "maintainer": "Sagiru Mati <smati@smati.com.ng>",
    "author": "Sagiru Mati [aut, cre] (ORCID: <https://orcid.org/0000-0003-1413-3974>)",
    "url": "https://CRAN.R-project.org/package=gretlR",
    "bug_reports": "https://github.com/sagirumati/gretlR/issues",
    "repository": "https://cran.r-project.org/package=gretlR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gretlR A Seamless Integration of 'Gretl' and 'R' It allows running 'gretl' (<http://gretl.sourceforge.net/index.html>) program from R, R Markdown and Quarto. 'gretl' ('Gnu' Regression, 'Econometrics', and Time-series Library) is a statistical software for Econometric analysis.  This package does not only integrate 'gretl' and 'R' but also serves  as a 'gretl' Knit-Engine for 'knitr' package. Write all your 'gretl' commands in 'R', R Markdown chunk.  "
  },
  {
    "id": 13639,
    "package_name": "greybox",
    "title": "Toolbox for Model Building and Forecasting",
    "description": "Implements functions and instruments for regression model building and its\n             application to forecasting. The main scope of the package is in variables selection\n             and models specification for cases of time series data. This includes promotional\n             modelling, selection between different dynamic regressions with non-standard\n             distributions of errors, selection based on cross validation, solutions to the fat\n             regression model problem and more. Models developed in the package are tailored\n             specifically for forecasting purposes. So as a results there are several methods\n             that allow producing forecasts from these models and visualising them.",
    "version": "2.0.6",
    "maintainer": "Ivan Svetunkov <ivan@svetunkov.com>",
    "author": "Ivan Svetunkov [aut, cre] (Senior Lecturer at Centre for Marketing\n    Analytics and Forecasting, Lancaster University, UK),\n  Yves R. Sagaert [ctb] (Visiting Research at Centre for Marketing\n    Analytics and Forecasting, Lancaster University, UK)",
    "url": "https://github.com/config-i1/greybox",
    "bug_reports": "https://github.com/config-i1/greybox/issues",
    "repository": "https://cran.r-project.org/package=greybox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "greybox Toolbox for Model Building and Forecasting Implements functions and instruments for regression model building and its\n             application to forecasting. The main scope of the package is in variables selection\n             and models specification for cases of time series data. This includes promotional\n             modelling, selection between different dynamic regressions with non-standard\n             distributions of errors, selection based on cross validation, solutions to the fat\n             regression model problem and more. Models developed in the package are tailored\n             specifically for forecasting purposes. So as a results there are several methods\n             that allow producing forecasts from these models and visualising them.  "
  },
  {
    "id": 13666,
    "package_name": "groupdata2",
    "title": "Creating Groups from Data",
    "description": "Methods for dividing data into groups. \n    Create balanced partitions and cross-validation folds. \n    Perform time series windowing and general grouping and splitting of data. \n    Balance existing groups with up- and downsampling or collapse them to fewer groups.",
    "version": "2.0.5",
    "maintainer": "Ludvig Renbo Olsen <r-pkgs@ludvigolsen.dk>",
    "author": "Ludvig Renbo Olsen [aut, cre] (ORCID:\n    <https://orcid.org/0009-0006-6798-7454>)",
    "url": "https://github.com/ludvigolsen/groupdata2",
    "bug_reports": "https://github.com/ludvigolsen/groupdata2/issues",
    "repository": "https://cran.r-project.org/package=groupdata2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "groupdata2 Creating Groups from Data Methods for dividing data into groups. \n    Create balanced partitions and cross-validation folds. \n    Perform time series windowing and general grouping and splitting of data. \n    Balance existing groups with up- and downsampling or collapse them to fewer groups.  "
  },
  {
    "id": 13676,
    "package_name": "growfunctions",
    "title": "Bayesian Non-Parametric Dependent Models for Time-Indexed\nFunctional Data",
    "description": "Estimates a collection of time-indexed functions under\n    either of Gaussian process (GP) or intrinsic Gaussian Markov\n    random field (iGMRF) prior formulations where a Dirichlet process\n    mixture allows sub-groupings of the functions to share the same\n    covariance or precision parameters.  The GP and iGMRF formulations\n    both support any number of additive covariance or precision terms,\n    respectively, expressing either or both of multiple trend and\n    seasonality.",
    "version": "0.17",
    "maintainer": "Terrance Savitsky <tds151@gmail.com>",
    "author": "Terrance Savitsky [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=growfunctions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "growfunctions Bayesian Non-Parametric Dependent Models for Time-Indexed\nFunctional Data Estimates a collection of time-indexed functions under\n    either of Gaussian process (GP) or intrinsic Gaussian Markov\n    random field (iGMRF) prior formulations where a Dirichlet process\n    mixture allows sub-groupings of the functions to share the same\n    covariance or precision parameters.  The GP and iGMRF formulations\n    both support any number of additive covariance or precision terms,\n    respectively, expressing either or both of multiple trend and\n    seasonality.  "
  },
  {
    "id": 13692,
    "package_name": "grwat",
    "title": "River Hydrograph Separation and Analysis",
    "description": "River hydrograph separation and daily runoff time series analysis. Provides\n  various filters to separate baseflow and quickflow. Implements advanced separation \n  technique by Rets et al. (2022) <doi:10.1134/S0097807822010146> which involves \n  meteorological data to reveal genetic components of the runoff: ground, rain, thaw \n  and spring (seasonal thaw). High-performance C++17 computation, annually aggregated \n  variables, statistical testing and numerous plotting functions for high-quality \n  visualization.",
    "version": "0.1",
    "maintainer": "Timofey Samsonov <tsamsonov@geogr.msu.ru>",
    "author": "Timofey Samsonov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5994-0302>),\n  Ekaterina Rets [ctb] (ORCID: <https://orcid.org/0000-0002-4505-1173>),\n  Maria Kireeva [ctb] (ORCID: <https://orcid.org/0000-0002-8285-9761>)",
    "url": "https://github.com/tsamsonov/grwat,\nhttps://tsamsonov.github.io/grwat/",
    "bug_reports": "https://github.com/tsamsonov/grwat/issues",
    "repository": "https://cran.r-project.org/package=grwat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "grwat River Hydrograph Separation and Analysis River hydrograph separation and daily runoff time series analysis. Provides\n  various filters to separate baseflow and quickflow. Implements advanced separation \n  technique by Rets et al. (2022) <doi:10.1134/S0097807822010146> which involves \n  meteorological data to reveal genetic components of the runoff: ground, rain, thaw \n  and spring (seasonal thaw). High-performance C++17 computation, annually aggregated \n  variables, statistical testing and numerous plotting functions for high-quality \n  visualization.  "
  },
  {
    "id": 13699,
    "package_name": "gsarima",
    "title": "Two Functions for Generalized SARIMA Time Series Simulation",
    "description": "Write SARIMA models in (finite) AR representation and simulate \n\tgeneralized multiplicative seasonal autoregressive moving average (time) series \n\twith Normal / Gaussian, Poisson or negative binomial distribution. \n\tThe methodology of this method is described in Briet OJT, Amerasinghe PH, and \n\tVounatsou P (2013) <doi:10.1371/journal.pone.0065761>.",
    "version": "0.1-5",
    "maintainer": "Olivier Briet <o.briet@gmail.com>",
    "author": "Olivier Briet <o.briet@gmail.com>",
    "url": "https://www.r-project.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gsarima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gsarima Two Functions for Generalized SARIMA Time Series Simulation Write SARIMA models in (finite) AR representation and simulate \n\tgeneralized multiplicative seasonal autoregressive moving average (time) series \n\twith Normal / Gaussian, Poisson or negative binomial distribution. \n\tThe methodology of this method is described in Briet OJT, Amerasinghe PH, and \n\tVounatsou P (2013) <doi:10.1371/journal.pone.0065761>.  "
  },
  {
    "id": 13705,
    "package_name": "gseries",
    "title": "Improve the Coherence of Your Time Series Data",
    "description": "\n    'R' version of 'G-Series', Statistics Canada's generalized system devoted\n    to the benchmarking and reconciliation of time series data. The methods\n    used in 'G-Series' essentially come from Dagum, E. B., and P. Cholette \n    (2006) <doi:10.1007/0-387-35439-5>.",
    "version": "3.0.2",
    "maintainer": "Michel Ferland <michel.ferland@statcan.gc.ca>",
    "author": "Michel Ferland [aut, cre],\n  Statistics Canada [cph, fnd]",
    "url": "https://StatCan.github.io/gensol-gseries/en/,\nhttps://StatCan.github.io/gensol-gseries/fr/",
    "bug_reports": "https://github.com/StatCan/gensol-gseries/issues/",
    "repository": "https://cran.r-project.org/package=gseries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gseries Improve the Coherence of Your Time Series Data \n    'R' version of 'G-Series', Statistics Canada's generalized system devoted\n    to the benchmarking and reconciliation of time series data. The methods\n    used in 'G-Series' essentially come from Dagum, E. B., and P. Cholette \n    (2006) <doi:10.1007/0-387-35439-5>.  "
  },
  {
    "id": 13717,
    "package_name": "gstar",
    "title": "Generalized Space-Time Autoregressive Model",
    "description": "Multivariate time series analysis based on Generalized Space-Time Autoregressive Model by Ruchjana et al.(2012) <doi:10.1063/1.4724118>.",
    "version": "0.1.0",
    "maintainer": "Ahmad Zaenal <ahmadzaenal125@gmail.com>",
    "author": "Ahmad Zaenal [aut, cre],\n  Fiqry Revadiansyah [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gstar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gstar Generalized Space-Time Autoregressive Model Multivariate time series analysis based on Generalized Space-Time Autoregressive Model by Ruchjana et al.(2012) <doi:10.1063/1.4724118>.  "
  },
  {
    "id": 13727,
    "package_name": "gtfs2emis",
    "title": "Estimating Public Transport Emissions from General Transit Feed\nSpecification (GTFS) Data",
    "description": "A bottom up model to estimate the emission levels of public transport systems based on General Transit Feed Specification (GTFS) data. The package requires two main inputs: i) Public transport data in the GTFS standard format; and ii) Some basic information on fleet characteristics such as fleet age, technology, fuel and Euro stage. As it stands, the package estimates several pollutants at high spatial and temporal resolutions. Pollution levels can be calculated for specific transport routes, trips, time of the day or for the transport system as a whole. The output with emission estimates can be extracted in different formats, supporting analysis on how emission levels vary across space, time and by fleet characteristics. A full description of the methods used in the 'gtfs2emis' model is presented in Vieira, J. P. B.; Pereira, R. H. M.; Andrade, P. R. (2022) <doi:10.31219/osf.io/8m2cy>. ",
    "version": "0.1.1",
    "maintainer": "Joao Bazzo <joao.bazzo@gmail.com>",
    "author": "Joao Bazzo [aut, cre] (ORCID: <https://orcid.org/0000-0003-4536-5006>),\n  Rafael H. M. Pereira [aut] (ORCID:\n    <https://orcid.org/0000-0003-2125-7465>),\n  Pedro R. Andrade [aut] (ORCID: <https://orcid.org/0000-0001-8675-4046>),\n  Sergio Ibarra-Espinosa [ctb] (ORCID:\n    <https://orcid.org/0000-0002-3162-1905>),\n  Ipea - Institute for Applied Economic Research [cph, fnd]",
    "url": "https://ipeagit.github.io/gtfs2emis/ ,\nhttps://github.com/ipeaGIT/gtfs2emis",
    "bug_reports": "https://github.com/ipeaGIT/gtfs2emis/issues",
    "repository": "https://cran.r-project.org/package=gtfs2emis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gtfs2emis Estimating Public Transport Emissions from General Transit Feed\nSpecification (GTFS) Data A bottom up model to estimate the emission levels of public transport systems based on General Transit Feed Specification (GTFS) data. The package requires two main inputs: i) Public transport data in the GTFS standard format; and ii) Some basic information on fleet characteristics such as fleet age, technology, fuel and Euro stage. As it stands, the package estimates several pollutants at high spatial and temporal resolutions. Pollution levels can be calculated for specific transport routes, trips, time of the day or for the transport system as a whole. The output with emission estimates can be extracted in different formats, supporting analysis on how emission levels vary across space, time and by fleet characteristics. A full description of the methods used in the 'gtfs2emis' model is presented in Vieira, J. P. B.; Pereira, R. H. M.; Andrade, P. R. (2022) <doi:10.31219/osf.io/8m2cy>.   "
  },
  {
    "id": 13794,
    "package_name": "ham",
    "title": "Healthcare Analysis Methods",
    "description": "Conducts analyses for healthcare program evaluations or intervention \n    studies. Calculates regression analyses for standard ordinary least squares \n    (OLS or linear) or logistic models. Performs regression models used for \n    causal modeling such as differences-in-differences (DID) and interrupted \n    time series (ITS) models. Provides limited interpretations of model \n    results and a ranking of variable importance in models. Performs \n    propensity score models, top-coding of model outcome variables, and \n    can return new data with the newly formed variables. Also performs Cronbach's \n    alpha for various scale items (e.g., survey questions). See Github URL for \n    examples in the README file. For more details on the statistical methods, see \n    Allen & Yen (1979, ISBN:0-8185-0283-5), \n    Angrist & Pischke (2009, ISBN:9780691120355), \n    Harrell (2016, ISBN:978-3-319-19424-0), \n    Kline (1999, ISBN:9780415211581),  \n    Linden (2015) <doi:10.1177/1536867X1501500208>,\n    Merlo (2006) <doi:10.1136/jech.2004.029454>\n    Muthen & Satorra (1995) <doi:10.2307/271070>, and\n    Rabe-Hesketh & Skrondal (2008, ISBN:978-1-59718-040-5).",
    "version": "1.1.0",
    "maintainer": "Stephen Zuniga <rms.shiny@gmail.com>",
    "author": "Stephen Zuniga [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1458-3924>)",
    "url": "https://github.com/szuniga07/ham",
    "bug_reports": "https://github.com/szuniga07/ham/issues",
    "repository": "https://cran.r-project.org/package=ham",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ham Healthcare Analysis Methods Conducts analyses for healthcare program evaluations or intervention \n    studies. Calculates regression analyses for standard ordinary least squares \n    (OLS or linear) or logistic models. Performs regression models used for \n    causal modeling such as differences-in-differences (DID) and interrupted \n    time series (ITS) models. Provides limited interpretations of model \n    results and a ranking of variable importance in models. Performs \n    propensity score models, top-coding of model outcome variables, and \n    can return new data with the newly formed variables. Also performs Cronbach's \n    alpha for various scale items (e.g., survey questions). See Github URL for \n    examples in the README file. For more details on the statistical methods, see \n    Allen & Yen (1979, ISBN:0-8185-0283-5), \n    Angrist & Pischke (2009, ISBN:9780691120355), \n    Harrell (2016, ISBN:978-3-319-19424-0), \n    Kline (1999, ISBN:9780415211581),  \n    Linden (2015) <doi:10.1177/1536867X1501500208>,\n    Merlo (2006) <doi:10.1136/jech.2004.029454>\n    Muthen & Satorra (1995) <doi:10.2307/271070>, and\n    Rabe-Hesketh & Skrondal (2008, ISBN:978-1-59718-040-5).  "
  },
  {
    "id": 13810,
    "package_name": "harbinger",
    "title": "A Unified Time Series Event Detection Framework",
    "description": "By analyzing time series, it is possible to observe significant changes in the behavior of observations that frequently characterize events. Events present themselves as anomalies, change points, or motifs. In the literature, there are several methods for detecting events. However, searching for a suitable time series method is a complex task, especially considering that the nature of events is often unknown. This work presents Harbinger, a framework for integrating and analyzing event detection methods. Harbinger contains several state-of-the-art methods described in Salles et al. (2020) <doi:10.5753/sbbd.2020.13626>.",
    "version": "1.2.747",
    "maintainer": "Eduardo Ogasawara <eogasawara@ieee.org>",
    "author": "Eduardo Ogasawara [aut, ths, cre] (ORCID:\n    <https://orcid.org/0000-0002-0466-0626>),\n  Antonio Castro [aut],\n  Antonio Mello [aut],\n  Diego Carvalho [ctb],\n  Eduardo Bezerra [ctb],\n  Ellen Paix\u00e3o [aut],\n  Fernando Fraga [aut],\n  Heraldo Borges [aut],\n  Janio Lima [aut],\n  Jessica Souza [aut],\n  Lais Baroni [aut],\n  Lucas Tavares [aut],\n  Michel Reis [aut],\n  Rebecca Salles [aut],\n  CEFET/RJ [cph]",
    "url": "https://cefet-rj-dal.github.io/harbinger/,\nhttps://github.com/cefet-rj-dal/harbinger",
    "bug_reports": "https://github.com/cefet-rj-dal/harbinger/issues",
    "repository": "https://cran.r-project.org/package=harbinger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "harbinger A Unified Time Series Event Detection Framework By analyzing time series, it is possible to observe significant changes in the behavior of observations that frequently characterize events. Events present themselves as anomalies, change points, or motifs. In the literature, there are several methods for detecting events. However, searching for a suitable time series method is a complex task, especially considering that the nature of events is often unknown. This work presents Harbinger, a framework for integrating and analyzing event detection methods. Harbinger contains several state-of-the-art methods described in Salles et al. (2020) <doi:10.5753/sbbd.2020.13626>.  "
  },
  {
    "id": 13849,
    "package_name": "hdbinseg",
    "title": "Change-Point Analysis of High-Dimensional Time Series via Binary\nSegmentation",
    "description": "Binary segmentation methods for detecting and estimating multiple change-points in the mean or second-order structure of high-dimensional time series as described in Cho and Fryzlewicz (2014) <doi:10.1111/rssb.12079> and Cho (2016) <doi:10.1214/16-EJS1155>.",
    "version": "1.0.3",
    "maintainer": "Haeran Cho <haeran.cho@bristol.ac.uk>",
    "author": "Haeran Cho [aut, cre],\n  Piotr Fryzlewicz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hdbinseg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hdbinseg Change-Point Analysis of High-Dimensional Time Series via Binary\nSegmentation Binary segmentation methods for detecting and estimating multiple change-points in the mean or second-order structure of high-dimensional time series as described in Cho and Fryzlewicz (2014) <doi:10.1111/rssb.12079> and Cho (2016) <doi:10.1214/16-EJS1155>.  "
  },
  {
    "id": 13855,
    "package_name": "hdflex",
    "title": "High-Dimensional Aggregate Density Forecasts",
    "description": "Provides a forecasting method that efficiently maps vast\n    numbers of (scalar-valued) signals into an aggregate density forecast\n    in a time-varying and computationally fast manner. The method proceeds\n    in two steps: First, it transforms a predictive signal into a density\n    forecast and, second, it combines the resulting candidate density\n    forecasts into an ultimate aggregate density forecast. For a detailed\n    explanation of the method, please refer to Adaemmer et al. (2025)\n    <doi:10.1080/07350015.2025.2526424>.",
    "version": "0.3.2",
    "maintainer": "Sven Lehmann <slehman5@uni-muenster.de>",
    "author": "Sven Lehmann [aut, cre, cph],\n  Philipp Ad\u00e4mmer [aut],\n  Rainer Sch\u00fcssler [aut]",
    "url": "https://github.com/lehmasve/hdflex",
    "bug_reports": "https://github.com/lehmasve/hdflex/issues",
    "repository": "https://cran.r-project.org/package=hdflex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hdflex High-Dimensional Aggregate Density Forecasts Provides a forecasting method that efficiently maps vast\n    numbers of (scalar-valued) signals into an aggregate density forecast\n    in a time-varying and computationally fast manner. The method proceeds\n    in two steps: First, it transforms a predictive signal into a density\n    forecast and, second, it combines the resulting candidate density\n    forecasts into an ultimate aggregate density forecast. For a detailed\n    explanation of the method, please refer to Adaemmer et al. (2025)\n    <doi:10.1080/07350015.2025.2526424>.  "
  },
  {
    "id": 13857,
    "package_name": "hdftsa",
    "title": "High-Dimensional Functional Time Series Analysis",
    "description": "Offers methods for visualizing, modelling, and forecasting high-dimensional functional time series, also known as functional panel data. Documentation about 'hdftsa' is provided via the paper by Cristian F. Jimenez-Varon, Ying Sun and Han Lin Shang (2024, <doi:10.1080/10618600.2024.2319166>).",
    "version": "1.0",
    "maintainer": "Han Lin Shang <hanlin.shang@mq.edu.au>",
    "author": "Han Lin Shang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1769-6430>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hdftsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hdftsa High-Dimensional Functional Time Series Analysis Offers methods for visualizing, modelling, and forecasting high-dimensional functional time series, also known as functional panel data. Documentation about 'hdftsa' is provided via the paper by Cristian F. Jimenez-Varon, Ying Sun and Han Lin Shang (2024, <doi:10.1080/10618600.2024.2319166>).  "
  },
  {
    "id": 13895,
    "package_name": "hedgedrf",
    "title": "An Implementation of the Hedged Random Forest Algorithm",
    "description": "This algorithm is described in detail in the paper \"Hedging Forecast Combinations With an Application to the Random Forest\" by Beck et al. (2024) <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5032102>. The package provides a function hedgedrf() that can be used to train a Hedged Random Forest model on a dataset, and a function predict.hedgedrf() that can be used to make predictions with the model.",
    "version": "1.0.1",
    "maintainer": "Elliot Beck <elliotleeroy.beck@uzh.ch>",
    "author": "Elliot Beck [aut, cre] (ORCID: <https://orcid.org/0000-0001-8707-1706>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hedgedrf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hedgedrf An Implementation of the Hedged Random Forest Algorithm This algorithm is described in detail in the paper \"Hedging Forecast Combinations With an Application to the Random Forest\" by Beck et al. (2024) <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5032102>. The package provides a function hedgedrf() that can be used to train a Hedged Random Forest model on a dataset, and a function predict.hedgedrf() that can be used to make predictions with the model.  "
  },
  {
    "id": 13911,
    "package_name": "hereR",
    "title": "'sf'-Based Interface to the 'HERE' REST APIs",
    "description": "Interface to the 'HERE' REST APIs <https://developer.here.com/develop/rest-apis>:\n  (1) geocode and autosuggest addresses or reverse geocode POIs using the 'Geocoder' API;\n  (2) route directions, travel distance or time matrices and isolines using the 'Routing', 'Matrix Routing' and 'Isoline Routing' APIs;\n  (3) request real-time traffic flow and incident information from the 'Traffic' API;\n  (4) find request public transport connections and nearby stations from the 'Public Transit' API;\n  (5) request intermodal routes using the 'Intermodal Routing' API;\n  (6) get weather forecasts, reports on current weather conditions, astronomical\n  information and alerts at a specific location from the 'Destination Weather' API.\n  Locations, routes and isolines are returned as 'sf' objects.",
    "version": "1.1.0",
    "maintainer": "Merlin Unterfinger <info@munterfinger.ch>",
    "author": "Merlin Unterfinger [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2020-2366>),\n  Daniel Possenriede [ctb] (ORCID:\n    <https://orcid.org/0000-0002-6738-9845>)",
    "url": "https://munterfi.github.io/hereR/,\nhttps://github.com/munterfi/hereR/",
    "bug_reports": "https://github.com/munterfi/hereR/issues/",
    "repository": "https://cran.r-project.org/package=hereR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hereR 'sf'-Based Interface to the 'HERE' REST APIs Interface to the 'HERE' REST APIs <https://developer.here.com/develop/rest-apis>:\n  (1) geocode and autosuggest addresses or reverse geocode POIs using the 'Geocoder' API;\n  (2) route directions, travel distance or time matrices and isolines using the 'Routing', 'Matrix Routing' and 'Isoline Routing' APIs;\n  (3) request real-time traffic flow and incident information from the 'Traffic' API;\n  (4) find request public transport connections and nearby stations from the 'Public Transit' API;\n  (5) request intermodal routes using the 'Intermodal Routing' API;\n  (6) get weather forecasts, reports on current weather conditions, astronomical\n  information and alerts at a specific location from the 'Destination Weather' API.\n  Locations, routes and isolines are returned as 'sf' objects.  "
  },
  {
    "id": 13915,
    "package_name": "hero",
    "title": "Spatio-Temporal (Hero) Sandwich Smoother",
    "description": "An implementation of the sandwich smoother proposed in Fast Bivariate Penalized Splines by Xiao et al. (2012) <doi:10.1111/rssb.12007>.    A hero is a specific type of sandwich.  Dictionary.com (2018) <https://www.dictionary.com> describes a hero as: a large sandwich, usually consisting of a small loaf of bread or long roll cut in half lengthwise and containing a variety of ingredients, as meat, cheese, lettuce, and tomatoes. Also implements the spatio-temporal sandwich smoother of French and Kokoszka (2021) <doi:10.1016/j.spasta.2020.100413>.",
    "version": "0.6",
    "maintainer": "Joshua French <joshua.french@ucdenver.edu>",
    "author": "Joshua French",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hero",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hero Spatio-Temporal (Hero) Sandwich Smoother An implementation of the sandwich smoother proposed in Fast Bivariate Penalized Splines by Xiao et al. (2012) <doi:10.1111/rssb.12007>.    A hero is a specific type of sandwich.  Dictionary.com (2018) <https://www.dictionary.com> describes a hero as: a large sandwich, usually consisting of a small loaf of bread or long roll cut in half lengthwise and containing a variety of ingredients, as meat, cheese, lettuce, and tomatoes. Also implements the spatio-temporal sandwich smoother of French and Kokoszka (2021) <doi:10.1016/j.spasta.2020.100413>.  "
  },
  {
    "id": 13948,
    "package_name": "hhh4contacts",
    "title": "Age-Structured Spatio-Temporal Models for Infectious Disease\nCounts",
    "description": "Meyer and Held (2017) <doi:10.1093/biostatistics/kxw051> present an\n    age-structured spatio-temporal model for infectious disease counts. The\n    approach is illustrated in a case study on norovirus gastroenteritis in\n    Berlin, 2011-2015, by age group, city district and week, using additional\n    contact data from the POLYMOD survey. This package contains the data and\n    code to reproduce the results from the paper, see 'demo(\"hhh4contacts\")'.",
    "version": "0.13.4",
    "maintainer": "Sebastian Meyer <seb.meyer@fau.de>",
    "author": "Sebastian Meyer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1791-9449>),\n  Leonhard Held [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0002-8686-5325>)",
    "url": "https://codeberg.org/EE-hub/hhh4contacts",
    "bug_reports": "https://codeberg.org/EE-hub/hhh4contacts/issues",
    "repository": "https://cran.r-project.org/package=hhh4contacts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hhh4contacts Age-Structured Spatio-Temporal Models for Infectious Disease\nCounts Meyer and Held (2017) <doi:10.1093/biostatistics/kxw051> present an\n    age-structured spatio-temporal model for infectious disease counts. The\n    approach is illustrated in a case study on norovirus gastroenteritis in\n    Berlin, 2011-2015, by age group, city district and week, using additional\n    contact data from the POLYMOD survey. This package contains the data and\n    code to reproduce the results from the paper, see 'demo(\"hhh4contacts\")'.  "
  },
  {
    "id": 13949,
    "package_name": "hhi",
    "title": "Calculate and Visualize the Herfindahl-Hirschman Index",
    "description": "Based on the aggregated shares retained by individual firms or actors within a market or space, the Herfindahl-Hirschman Index (HHI) measures the level of concentration in a space. This package allows for intuitive and straightforward computation of HHI scores, requiring placement of objects of interest directly into the function. The package also includes a plot function for quick visual display of an HHI time series using any measure of time (year, quarter, month, etc.). For usage, please cite the Journal of Open Source Software paper associated with the package: Waggoner, Philip D. (2018) <doi:10.21105/joss.00828>.",
    "version": "1.2.0",
    "maintainer": "Philip D. Waggoner <pdwaggoner@wm.edu>",
    "author": "Philip D. Waggoner <pdwaggoner@wm.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hhi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hhi Calculate and Visualize the Herfindahl-Hirschman Index Based on the aggregated shares retained by individual firms or actors within a market or space, the Herfindahl-Hirschman Index (HHI) measures the level of concentration in a space. This package allows for intuitive and straightforward computation of HHI scores, requiring placement of objects of interest directly into the function. The package also includes a plot function for quick visual display of an HHI time series using any measure of time (year, quarter, month, etc.). For usage, please cite the Journal of Open Source Software paper associated with the package: Waggoner, Philip D. (2018) <doi:10.21105/joss.00828>.  "
  },
  {
    "id": 13970,
    "package_name": "highfrequency",
    "title": "Tools for Highfrequency Data Analysis",
    "description": "Provide functionality to manage, clean and match highfrequency\n    trades and quotes data, calculate various liquidity measures, estimate and\n    forecast volatility, detect price jumps and investigate microstructure noise and intraday\n    periodicity. A detailed vignette can be found in the open-access paper \n    \"Analyzing Intraday Financial Data in R: The highfrequency Package\" \n    by Boudt, Kleen, and Sjoerup (2022, <doi:10.18637/jss.v104.i08>). ",
    "version": "1.0.2",
    "maintainer": "Kris Boudt <kris.boudt@ugent.be>",
    "author": "Kris Boudt [aut, cre] (ORCID: <https://orcid.org/0000-0002-1000-5142>),\n  Jonathan Cornelissen [aut],\n  Scott Payseur [aut],\n  Giang Nguyen [ctb],\n  Onno Kleen [aut] (ORCID: <https://orcid.org/0000-0003-4731-4640>),\n  Emil Sjoerup [aut]",
    "url": "https://github.com/jonathancornelissen/highfrequency",
    "bug_reports": "https://github.com/jonathancornelissen/highfrequency/issues",
    "repository": "https://cran.r-project.org/package=highfrequency",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "highfrequency Tools for Highfrequency Data Analysis Provide functionality to manage, clean and match highfrequency\n    trades and quotes data, calculate various liquidity measures, estimate and\n    forecast volatility, detect price jumps and investigate microstructure noise and intraday\n    periodicity. A detailed vignette can be found in the open-access paper \n    \"Analyzing Intraday Financial Data in R: The highfrequency Package\" \n    by Boudt, Kleen, and Sjoerup (2022, <doi:10.18637/jss.v104.i08>).   "
  },
  {
    "id": 13987,
    "package_name": "himach",
    "title": "Find Routes for Supersonic Aircraft",
    "description": "For supersonic aircraft, flying subsonic over land,\n    find the best route between airports. Allow for coastal buffer and\n    potentially closed regions. Use a minimal model of aircraft\n    performance: the focus is on time saved versus subsonic flight, rather\n    than on vertical flight profile. For modelling and forecasting, not for planning your\n    flight!",
    "version": "1.0.0",
    "maintainer": "David Marsh <david6marsh@gmail.com>",
    "author": "David Marsh [aut, cre],\n  Enrico Spinielli [ctb],\n  EUROCONTROL [fnd, cph]",
    "url": "https://github.com/david6marsh/himach,\nhttps://david6marsh.github.io/himach/",
    "bug_reports": "https://github.com/david6marsh/himach/issues",
    "repository": "https://cran.r-project.org/package=himach",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "himach Find Routes for Supersonic Aircraft For supersonic aircraft, flying subsonic over land,\n    find the best route between airports. Allow for coastal buffer and\n    potentially closed regions. Use a minimal model of aircraft\n    performance: the focus is on time saved versus subsonic flight, rather\n    than on vertical flight profile. For modelling and forecasting, not for planning your\n    flight!  "
  },
  {
    "id": 14013,
    "package_name": "hmix",
    "title": "Hidden Markov Model for Predicting Time Sequences with Mixture\nSampling",
    "description": "An algorithm for time series analysis that leverages hidden Markov models, cluster analysis, and mixture distributions to segment data, detect patterns and predict future sequences.",
    "version": "1.0.2",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/hmix",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hmix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hmix Hidden Markov Model for Predicting Time Sequences with Mixture\nSampling An algorithm for time series analysis that leverages hidden Markov models, cluster analysis, and mixture distributions to segment data, detect patterns and predict future sequences.  "
  },
  {
    "id": 14083,
    "package_name": "hts",
    "title": "Hierarchical and Grouped Time Series",
    "description": "Provides methods for analysing and forecasting hierarchical and \n    grouped time series. The available forecast methods include bottom-up,\n    top-down, optimal combination reconciliation (Hyndman et al. 2011) \n    <doi:10.1016/j.csda.2011.03.006>, and trace minimization reconciliation\n    (Wickramasuriya et al. 2018) <doi:10.1080/01621459.2018.1448825>.",
    "version": "6.0.3",
    "maintainer": "Earo Wang <earo.wang@gmail.com>",
    "author": "Rob Hyndman [aut] (Package creator),\n  Alan Lee [aut] (Fast computation using recursive methods),\n  Earo Wang [aut, cre],\n  Shanika Wickramasuriya [aut] (Reconciliation via trace minimization)",
    "url": "https://pkg.earo.me/hts/",
    "bug_reports": "https://github.com/earowang/hts/issues",
    "repository": "https://cran.r-project.org/package=hts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hts Hierarchical and Grouped Time Series Provides methods for analysing and forecasting hierarchical and \n    grouped time series. The available forecast methods include bottom-up,\n    top-down, optimal combination reconciliation (Hyndman et al. 2011) \n    <doi:10.1016/j.csda.2011.03.006>, and trace minimization reconciliation\n    (Wickramasuriya et al. 2018) <doi:10.1080/01621459.2018.1448825>.  "
  },
  {
    "id": 14084,
    "package_name": "htsDegenerateR",
    "title": "Degenerate Hierarchical Time Series Reconciliation",
    "description": "Takes the MinT implementation of the 'hts'<https://cran.r-project.org/package=hts> package and adapts it to allow degenerate hierarchical structures. Instead of the \"nodes\" argument, this function takes an S matrix which is more versatile in the structures it allows. For a demo, see Steinmeister and Pauly (2024)<doi:10.15488/17729>. The MinT algorithm is based on Wickramasuriya et al. (2019)<doi:10.1080/01621459.2018.1448825>.",
    "version": "0.1.0",
    "maintainer": "Louis Steinmeister <louis.steinmeister@udo.edu>",
    "author": "Louis Steinmeister [aut, cre],\n  Markus Pauly [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=htsDegenerateR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "htsDegenerateR Degenerate Hierarchical Time Series Reconciliation Takes the MinT implementation of the 'hts'<https://cran.r-project.org/package=hts> package and adapts it to allow degenerate hierarchical structures. Instead of the \"nodes\" argument, this function takes an S matrix which is more versatile in the structures it allows. For a demo, see Steinmeister and Pauly (2024)<doi:10.15488/17729>. The MinT algorithm is based on Wickramasuriya et al. (2019)<doi:10.1080/01621459.2018.1448825>.  "
  },
  {
    "id": 14085,
    "package_name": "htsr",
    "title": "Hydro-Meteorology Time-Series",
    "description": "Functions for the management and treatment of hydrology and \n  meteorology time-series stored in a 'Sqlite' data base.",
    "version": "2.1.6",
    "maintainer": "Pierre Chevallier <pierre.chevallier@mailo.com>",
    "author": "Pierre Chevallier [aut, cre]",
    "url": "https://github.com/p-chevallier/htsr",
    "bug_reports": "https://github.com/p-chevallier/htsr/issues",
    "repository": "https://cran.r-project.org/package=htsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "htsr Hydro-Meteorology Time-Series Functions for the management and treatment of hydrology and \n  meteorology time-series stored in a 'Sqlite' data base.  "
  },
  {
    "id": 14107,
    "package_name": "hurricaneexposure",
    "title": "Explore and Map County-Level Hurricane Exposure in the United\nStates",
    "description": "Allows users to create time series of tropical storm\n    exposure histories for chosen counties for a number of hazard metrics\n    (wind, rain, distance from the storm, etc.). This package interacts\n    with data available through the 'hurricaneexposuredata' package, which\n    is available in a 'drat' repository. To access this data package, see the \n    instructions at <https://github.com/geanders/hurricaneexposure>. \n    The size of the 'hurricaneexposuredata' package is\n    approximately 20 MB. This work was supported in part by grants from the National\n    Institute of Environmental Health Sciences (R00ES022631), the National Science\n    Foundation (1331399), and a NASA Applied Sciences Program/Public Health Program\n    Grant (NNX09AV81G).",
    "version": "0.1.1",
    "maintainer": "Brooke Anderson <brooke.anderson@colostate.edu>",
    "author": "Brooke Anderson [aut, cre],\n  Meilin Yan [aut],\n  Joshua Ferreri [aut],\n  William Crosson [ctb],\n  Mohammad Al-Hamdan [ctb],\n  Andrea Schumacher [ctb],\n  Dirk Eddelbuettel [ctb]",
    "url": "https://github.com/geanders/hurricaneexposure",
    "bug_reports": "https://github.com/geanders/hurricaneexposure/issues",
    "repository": "https://cran.r-project.org/package=hurricaneexposure",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hurricaneexposure Explore and Map County-Level Hurricane Exposure in the United\nStates Allows users to create time series of tropical storm\n    exposure histories for chosen counties for a number of hazard metrics\n    (wind, rain, distance from the storm, etc.). This package interacts\n    with data available through the 'hurricaneexposuredata' package, which\n    is available in a 'drat' repository. To access this data package, see the \n    instructions at <https://github.com/geanders/hurricaneexposure>. \n    The size of the 'hurricaneexposuredata' package is\n    approximately 20 MB. This work was supported in part by grants from the National\n    Institute of Environmental Health Sciences (R00ES022631), the National Science\n    Foundation (1331399), and a NASA Applied Sciences Program/Public Health Program\n    Grant (NNX09AV81G).  "
  },
  {
    "id": 14117,
    "package_name": "hwwntest",
    "title": "Tests of White Noise using Wavelets",
    "description": "Provides methods to test whether time series is consistent\n\twith white noise. Two new tests based on Haar wavelets and general\n\twavelets described by Nason and Savchev (2014)\n\t<doi:10.1002/sta4.69> are provided and, for comparison purposes\n\tthis package also implements the\n\tB test of Bartlett (1967) <doi:10.2307/2333850>. Functionality\n\tis provided to compute an approximation to the theoretical\n\tpower of the general wavelet test in the case of general\n\tARMA alternatives.",
    "version": "1.3.2",
    "maintainer": "Guy Nason <g.nason@imperial.ac.uk>",
    "author": "Delyan Savchev [aut],\n  Guy Nason [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hwwntest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hwwntest Tests of White Noise using Wavelets Provides methods to test whether time series is consistent\n\twith white noise. Two new tests based on Haar wavelets and general\n\twavelets described by Nason and Savchev (2014)\n\t<doi:10.1002/sta4.69> are provided and, for comparison purposes\n\tthis package also implements the\n\tB test of Bartlett (1967) <doi:10.2307/2333850>. Functionality\n\tis provided to compute an approximation to the theoretical\n\tpower of the general wavelet test in the case of general\n\tARMA alternatives.  "
  },
  {
    "id": 14122,
    "package_name": "hybridts",
    "title": "Hybrid Time Series Forecasting Using Error Remodeling Approach",
    "description": "Method and tool for generating hybrid time series forecasts using\n        an error remodeling approach. These forecasting approaches utilize a recursive \n        technique for modeling the linearity of the series using a linear method \n        (e.g., ARIMA, Theta, etc.) and then models (forecasts) the residuals of the linear forecaster\n        using non-linear neural networks (e.g., ANN, ARNN, etc.). The hybrid architectures comprise three steps: \n        firstly, the linear patterns of the series are forecasted which are followed by an error re-modeling step, \n        and finally, the forecasts from both the steps are combined to produce the final output. This method additionally \n        provides the confidence intervals as needed. Ten different models can be implemented using this package.\n        This package generates different types of hybrid error correction models for time series forecasting \n        based on the algorithms by Zhang. (2003), Chakraborty et al. (2019), Chakraborty et al. (2020), \n        Bhattacharyya et al. (2021), Chakraborty et al. (2022), and Bhattacharyya et al. (2022)\n        <doi:10.1016/S0925-2312(01)00702-0> <doi:10.1016/j.physa.2019.121266> \n        <doi:10.1016/j.chaos.2020.109850> <doi:10.1109/IJCNN52387.2021.9533747> \n        <doi:10.1007/978-3-030-72834-2_29> <doi:10.1007/s11071-021-07099-3>.",
    "version": "0.1.0",
    "maintainer": "Tanujit Chakraborty <tanujitisi@gmail.com>",
    "author": "Tanujit Chakraborty [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hybridts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hybridts Hybrid Time Series Forecasting Using Error Remodeling Approach Method and tool for generating hybrid time series forecasts using\n        an error remodeling approach. These forecasting approaches utilize a recursive \n        technique for modeling the linearity of the series using a linear method \n        (e.g., ARIMA, Theta, etc.) and then models (forecasts) the residuals of the linear forecaster\n        using non-linear neural networks (e.g., ANN, ARNN, etc.). The hybrid architectures comprise three steps: \n        firstly, the linear patterns of the series are forecasted which are followed by an error re-modeling step, \n        and finally, the forecasts from both the steps are combined to produce the final output. This method additionally \n        provides the confidence intervals as needed. Ten different models can be implemented using this package.\n        This package generates different types of hybrid error correction models for time series forecasting \n        based on the algorithms by Zhang. (2003), Chakraborty et al. (2019), Chakraborty et al. (2020), \n        Bhattacharyya et al. (2021), Chakraborty et al. (2022), and Bhattacharyya et al. (2022)\n        <doi:10.1016/S0925-2312(01)00702-0> <doi:10.1016/j.physa.2019.121266> \n        <doi:10.1016/j.chaos.2020.109850> <doi:10.1109/IJCNN52387.2021.9533747> \n        <doi:10.1007/978-3-030-72834-2_29> <doi:10.1007/s11071-021-07099-3>.  "
  },
  {
    "id": 14129,
    "package_name": "hydroGOF",
    "title": "Goodness-of-Fit Functions for Comparison of Simulated and\nObserved Hydrological Time Series",
    "description": "S3 functions implementing both statistical and graphical goodness-of-fit measures between observed and simulated values, mainly oriented to be used during the calibration, validation, and application of hydrological models. Missing values in observed and/or simulated values can be removed before computations. Comments / questions / collaboration of any kind are very welcomed.",
    "version": "0.6-0.1",
    "maintainer": "Mauricio Zambrano-Bigiarini <mzb.devel@gmail.com>",
    "author": "Mauricio Zambrano-Bigiarini [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9536-643X>)",
    "url": "https://github.com/hzambran/hydroGOF",
    "bug_reports": "https://github.com/hzambran/hydroGOF/issues",
    "repository": "https://cran.r-project.org/package=hydroGOF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydroGOF Goodness-of-Fit Functions for Comparison of Simulated and\nObserved Hydrological Time Series S3 functions implementing both statistical and graphical goodness-of-fit measures between observed and simulated values, mainly oriented to be used during the calibration, validation, and application of hydrological models. Missing values in observed and/or simulated values can be removed before computations. Comments / questions / collaboration of any kind are very welcomed.  "
  },
  {
    "id": 14132,
    "package_name": "hydroTSM",
    "title": "Time Series Management and Analysis for Hydrological Modelling",
    "description": "S3 functions for management, analysis, interpolation and plotting of time series used in hydrology and related environmental sciences. In particular, this package is highly oriented to hydrological modelling tasks. The focus of this package has been put in providing a collection of tools useful for the daily work of hydrologists (although an effort was made to optimise each function as much as possible, functionality has had priority over speed). Bugs / comments / questions / collaboration of any kind are very welcomed, and in particular, datasets that can be included in this package for academic purposes.",
    "version": "0.7-0.1",
    "maintainer": "Mauricio Zambrano-Bigiarini <mzb.devel@gmail.com>",
    "author": "Mauricio Zambrano-Bigiarini [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9536-643X>)",
    "url": "https://github.com/hzambran/hydroTSM,\nhttps://cran.r-project.org/package=hydroTSM",
    "bug_reports": "https://github.com/hzambran/hydroTSM/issues",
    "repository": "https://cran.r-project.org/package=hydroTSM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydroTSM Time Series Management and Analysis for Hydrological Modelling S3 functions for management, analysis, interpolation and plotting of time series used in hydrology and related environmental sciences. In particular, this package is highly oriented to hydrological modelling tasks. The focus of this package has been put in providing a collection of tools useful for the daily work of hydrologists (although an effort was made to optimise each function as much as possible, functionality has had priority over speed). Bugs / comments / questions / collaboration of any kind are very welcomed, and in particular, datasets that can be included in this package for academic purposes.  "
  },
  {
    "id": 14138,
    "package_name": "hydrostats",
    "title": "Hydrologic Indices for Daily Time Series Data",
    "description": "Calculates a suite of hydrologic indices for daily time series data that are widely used in hydrology and stream ecology.",
    "version": "0.2.9",
    "maintainer": "Nick Bond <n.bond@latrobe.edu.au>",
    "author": "Nick Bond",
    "url": "https://github.com/nickbond/hydrostats",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hydrostats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydrostats Hydrologic Indices for Daily Time Series Data Calculates a suite of hydrologic indices for daily time series data that are widely used in hydrology and stream ecology.  "
  },
  {
    "id": 14140,
    "package_name": "hyfo",
    "title": "Hydrology and Climate Forecasting",
    "description": "Focuses on data processing and visualization in hydrology and\n    climate forecasting. Main function includes data extraction, data downscaling,\n    data resampling, gap filler of precipitation, bias correction of forecasting\n    data, flexible time series plot, and spatial map generation. It is a good pre-\n    processing and post-processing tool for hydrological and hydraulic modellers.",
    "version": "1.4.6",
    "maintainer": "Yuanchao Xu <xuyuanchao37@gmail.com>",
    "author": "Yuanchao Xu [aut, cre]",
    "url": "https://yuanchao-xu.github.io/hyfo/",
    "bug_reports": "https://github.com/Yuanchao-Xu/hyfo/issues",
    "repository": "https://cran.r-project.org/package=hyfo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hyfo Hydrology and Climate Forecasting Focuses on data processing and visualization in hydrology and\n    climate forecasting. Main function includes data extraction, data downscaling,\n    data resampling, gap filler of precipitation, bias correction of forecasting\n    data, flexible time series plot, and spatial map generation. It is a good pre-\n    processing and post-processing tool for hydrological and hydraulic modellers.  "
  },
  {
    "id": 14158,
    "package_name": "hystar",
    "title": "Fit the Hysteretic Threshold Autoregressive Model",
    "description": "Estimate parameters of the hysteretic threshold autoregressive\n    (HysTAR) model, using conditional least squares.\n    In addition, you can generate time series data from the HysTAR model.\n    For details, see Li, Guan, Li and Yu (2015) <doi:10.1093/biomet/asv017>.",
    "version": "1.0.0",
    "maintainer": "Daan de Jong <daandejong94@gmail.com>",
    "author": "Daan de Jong [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-6034-0136>),\n  European Research Council [fnd]",
    "url": "https://github.com/daandejongen/hystar/",
    "bug_reports": "https://github.com/daandejongen/hystar/issues/",
    "repository": "https://cran.r-project.org/package=hystar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hystar Fit the Hysteretic Threshold Autoregressive Model Estimate parameters of the hysteretic threshold autoregressive\n    (HysTAR) model, using conditional least squares.\n    In addition, you can generate time series data from the HysTAR model.\n    For details, see Li, Guan, Li and Yu (2015) <doi:10.1093/biomet/asv017>.  "
  },
  {
    "id": 14163,
    "package_name": "iAR",
    "title": "Irregularly Observed Autoregressive Models",
    "description": "Data sets, functions and scripts with examples to implement autoregressive models for irregularly observed time series. The models available in this package are the irregular autoregressive model (Eyheramendy et al.(2018) <doi:10.1093/mnras/sty2487>), the complex irregular autoregressive model (Elorrieta et al.(2019) <doi:10.1051/0004-6361/201935560>) and the bivariate irregular autoregressive model (Elorrieta et al.(2021) <doi:10.1093/mnras/stab1216>).",
    "version": "1.3.2",
    "maintainer": "Elorrieta Felipe <felipe.elorrieta@usach.cl>",
    "author": "Elorrieta Felipe [aut, cre],\n  Ojeda Cesar [aut],\n  Eyheramendy Susana [aut],\n  Palma Wilfredo [aut]",
    "url": "https://github.com/felipeelorrieta",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iAR Irregularly Observed Autoregressive Models Data sets, functions and scripts with examples to implement autoregressive models for irregularly observed time series. The models available in this package are the irregular autoregressive model (Eyheramendy et al.(2018) <doi:10.1093/mnras/sty2487>), the complex irregular autoregressive model (Elorrieta et al.(2019) <doi:10.1051/0004-6361/201935560>) and the bivariate irregular autoregressive model (Elorrieta et al.(2021) <doi:10.1093/mnras/stab1216>).  "
  },
  {
    "id": 14178,
    "package_name": "iForecast",
    "title": "Machine Learning Time Series Forecasting",
    "description": "Compute onestep and multistep time series forecasts for machine learning models.",
    "version": "1.1.2",
    "maintainer": "Ho Tsung-wu <tsungwu@ntnu.edu.tw>",
    "author": "Ho Tsung-wu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iForecast Machine Learning Time Series Forecasting Compute onestep and multistep time series forecasts for machine learning models.  "
  },
  {
    "id": 14192,
    "package_name": "iNZightTS",
    "title": "Time Series for 'iNZight'",
    "description": "Provides a collection of functions for working with time series data, including functions for drawing, decomposing, and forecasting. Includes capabilities to compare multiple series and fit both additive and multiplicative models. Used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Holt (1957) <doi:10.1016/j.ijforecast.2003.09.015>, Winters (1960) <doi:10.1287/mnsc.6.3.324>, Cleveland, Cleveland, & Terpenning (1990) \"STL: A Seasonal-Trend Decomposition Procedure Based on Loess\".",
    "version": "2.0.2",
    "maintainer": "Tom Elliott <tom.elliott@auckland.ac.nz>",
    "author": "Tom Elliott [aut, cre] (ORCID: <https://orcid.org/0000-0002-7815-6318>),\n  Zhaoming Su [aut],\n  Junjie Zeng [ctb],\n  Simon Potter [ctb],\n  David Banks [ctb],\n  Marco Kuper [ctb],\n  Dongning Zhang [ctb]",
    "url": "https://inzight.nz",
    "bug_reports": "https://github.com/iNZightVIT/iNZightTS/issues",
    "repository": "https://cran.r-project.org/package=iNZightTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iNZightTS Time Series for 'iNZight' Provides a collection of functions for working with time series data, including functions for drawing, decomposing, and forecasting. Includes capabilities to compare multiple series and fit both additive and multiplicative models. Used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Holt (1957) <doi:10.1016/j.ijforecast.2003.09.015>, Winters (1960) <doi:10.1287/mnsc.6.3.324>, Cleveland, Cleveland, & Terpenning (1990) \"STL: A Seasonal-Trend Decomposition Procedure Based on Loess\".  "
  },
  {
    "id": 14202,
    "package_name": "iSTAY",
    "title": "Information-Based Stability and Synchrony Measures",
    "description": "Provides functions to to compute a continuum of information-based measures \n for quantifying the temporal stability of populations, communities, and ecosystems, \n as well as their associated synchrony, based on species (or species assemblage)\n biomass or other key variables. When biodiversity data are available, the package\n also enables the assessment of the corresponding diversity\u2013stability relationships.\n All measures are applicable in both temporal and spatial contexts. The theoretical\n and methodological background is detailed in Chao et al. (2025) \n <doi:10.1101/2025.08.20.671203>.",
    "version": "1.0.0",
    "maintainer": "Anne Chao <chao@stat.nthu.edu.tw>",
    "author": "Anne Chao [aut, cre],\n  Yu-Ting Huang [aut],\n  Johnny Shia [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iSTAY",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iSTAY Information-Based Stability and Synchrony Measures Provides functions to to compute a continuum of information-based measures \n for quantifying the temporal stability of populations, communities, and ecosystems, \n as well as their associated synchrony, based on species (or species assemblage)\n biomass or other key variables. When biodiversity data are available, the package\n also enables the assessment of the corresponding diversity\u2013stability relationships.\n All measures are applicable in both temporal and spatial contexts. The theoretical\n and methodological background is detailed in Chao et al. (2025) \n <doi:10.1101/2025.08.20.671203>.  "
  },
  {
    "id": 14270,
    "package_name": "ideamdb",
    "title": "Easy Manipulation of IDEAM's Climatological Data",
    "description": "Time series plain text conversion and data visualization. It allows\n    to transform IDEAM (Instituto de Hidrologia, Meteorologia y Estudios Ambientales)\n    daily series from plain text to CSV files or data frames in R. Additionally,\n    it is possible to obtain exploratory graphs from times series. IDEAM\u2019s data\n    is freely delivered under formal request through the official web page\n    <http://www.ideam.gov.co/solicitud-de-informacion>.",
    "version": "0.0.9",
    "maintainer": "Luz Maria Morales <lummoralesgo@unal.edu.co>",
    "author": "Luz Maria Morales [aut, cre],\n  Edwin Echeverri [aut],\n  Kenneth Roy Cabrera [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ideamdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ideamdb Easy Manipulation of IDEAM's Climatological Data Time series plain text conversion and data visualization. It allows\n    to transform IDEAM (Instituto de Hidrologia, Meteorologia y Estudios Ambientales)\n    daily series from plain text to CSV files or data frames in R. Additionally,\n    it is possible to obtain exploratory graphs from times series. IDEAM\u2019s data\n    is freely delivered under formal request through the official web page\n    <http://www.ideam.gov.co/solicitud-de-informacion>.  "
  },
  {
    "id": 14297,
    "package_name": "ifo",
    "title": "Client for the Ifo Institute Time Series",
    "description": "Download ifo business survey data and more time series from\n    ifo institute <https://www.ifo.de/en/ifo-time-series>.",
    "version": "0.2.2",
    "maintainer": "Maximilian M\u00fccke <muecke.maximilian@gmail.com>",
    "author": "Maximilian M\u00fccke [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9432-9795>)",
    "url": "https://m-muecke.github.io/ifo/, https://github.com/m-muecke/ifo",
    "bug_reports": "https://github.com/m-muecke/ifo/issues",
    "repository": "https://cran.r-project.org/package=ifo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ifo Client for the Ifo Institute Time Series Download ifo business survey data and more time series from\n    ifo institute <https://www.ifo.de/en/ifo-time-series>.  "
  },
  {
    "id": 14298,
    "package_name": "ifpd",
    "title": "Indonesia Food Prices Data",
    "description": "Imputation of missing values using the last observation carried forward technique on Indonesia food prices data that is time series data. Also, this technique applies imputation to data whose dates do not appear directly. So that the series assumptions in the time series data are met.",
    "version": "0.1.0",
    "maintainer": "Fadhlul Mubarak <mubarakfadhlul@gmail.com>",
    "author": "Fadhlul Mubarak [aut, cre],\n  Vinny Yuliani Sundara [aut],\n  Nurniswah [aut],\n  Fakhrur Razi [aut]",
    "url": "https://github.com/mubarakfadhlul/ifpd",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ifpd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ifpd Indonesia Food Prices Data Imputation of missing values using the last observation carried forward technique on Indonesia food prices data that is time series data. Also, this technique applies imputation to data whose dates do not appear directly. So that the series assumptions in the time series data are met.  "
  },
  {
    "id": 14303,
    "package_name": "igcop",
    "title": "Computational Tools for the IG and IGL Copula Families",
    "description": "Compute distributional quantities for an\n    Integrated Gamma (IG) or Integrated Gamma Limit (IGL) copula, such\n    as a cdf and density. Compute corresponding conditional quantities\n    such as the cdf and quantiles. Generate\n    data from an IG or IGL copula. See the vignette for formulas,\n    or for a derivation, see Coia, V (2017) \"Forecasting of Nonlinear \n    Extreme Quantiles Using Copula Models.\" PhD Dissertation, \n    The University of British Columbia.",
    "version": "1.0.2",
    "maintainer": "Vincenzo Coia <vincenzo.coia@gmail.com>",
    "author": "Vincenzo Coia [aut, cre],\n  Harry Joe [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=igcop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igcop Computational Tools for the IG and IGL Copula Families Compute distributional quantities for an\n    Integrated Gamma (IG) or Integrated Gamma Limit (IGL) copula, such\n    as a cdf and density. Compute corresponding conditional quantities\n    such as the cdf and quantiles. Generate\n    data from an IG or IGL copula. See the vignette for formulas,\n    or for a derivation, see Coia, V (2017) \"Forecasting of Nonlinear \n    Extreme Quantiles Using Copula Models.\" PhD Dissertation, \n    The University of British Columbia.  "
  },
  {
    "id": 14306,
    "package_name": "iglu",
    "title": "Interpreting Glucose Data from Continuous Glucose Monitors",
    "description": "Implements a wide range of metrics for measuring glucose control and glucose variability based on continuous glucose monitoring data. The list of implemented metrics is summarized in Rodbard (2009) <doi:10.1089/dia.2009.0015>. Additional visualization tools include time-series plots, lasagna plots and ambulatory glucose profile report. ",
    "version": "4.2.2",
    "maintainer": "Irina Gaynanova <irinagn@umich.edu>",
    "author": "Elizabeth Chun [aut],\n  Steve Broll [aut],\n  David Buchanan [aut],\n  John Muschelli [aut] (ORCID: <https://orcid.org/0000-0001-6469-1750>),\n  Nathaniel Fernandes [aut] (ORCID:\n    <https://orcid.org/0000-0003-0485-0726>),\n  Jung Hoon Seo [ctb],\n  Johnathan Shih [ctb],\n  Jacek Urbanek [ctb],\n  John Schwenck [ctb],\n  Marielle Hicban [ctb],\n  Mary Martin [ctb],\n  Pratik Patel [ctb],\n  Meyappan Ashok [ctb],\n  Nhan Nguyen [ctb],\n  Irina Gaynanova [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4116-0268>)",
    "url": "https://irinagain.github.io/iglu/",
    "bug_reports": "https://github.com/irinagain/iglu/issues",
    "repository": "https://cran.r-project.org/package=iglu",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iglu Interpreting Glucose Data from Continuous Glucose Monitors Implements a wide range of metrics for measuring glucose control and glucose variability based on continuous glucose monitoring data. The list of implemented metrics is summarized in Rodbard (2009) <doi:10.1089/dia.2009.0015>. Additional visualization tools include time-series plots, lasagna plots and ambulatory glucose profile report.   "
  },
  {
    "id": 14315,
    "package_name": "ihclust",
    "title": "Iterative Hierarchical Clustering (IHC)",
    "description": "Provides a set of tools to\n  i) identify geographic areas with significant change over time in drug utilization, and \n  ii) characterize common change over time patterns among the time series for multiple geographic areas.\n  For reference, see below:\n    1. Song, J., Carey, M., Zhu, H., Miao, H., Ram\u00b4\u0131rez, J. C., & Wu, H. (2018) <doi:10.1504/IJCBDD.2018.10011910>\n    2. Wu, S., Wu, H. (2013) <doi:10.1186/1471-2105-14-6>\n    3. Carey, M., Wu, S., Gan, G. & Wu, H. (2016) <doi:10.1016/j.idm.2016.07.001>.",
    "version": "0.1.0",
    "maintainer": "Elin Cho <elincho524@gmail.com>",
    "author": "Elin Cho [aut, cre],\n  Yuting Xu [aut],\n  Jaejoon Song [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ihclust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ihclust Iterative Hierarchical Clustering (IHC) Provides a set of tools to\n  i) identify geographic areas with significant change over time in drug utilization, and \n  ii) characterize common change over time patterns among the time series for multiple geographic areas.\n  For reference, see below:\n    1. Song, J., Carey, M., Zhu, H., Miao, H., Ram\u00b4\u0131rez, J. C., & Wu, H. (2018) <doi:10.1504/IJCBDD.2018.10011910>\n    2. Wu, S., Wu, H. (2013) <doi:10.1186/1471-2105-14-6>\n    3. Carey, M., Wu, S., Gan, G. & Wu, H. (2016) <doi:10.1016/j.idm.2016.07.001>.  "
  },
  {
    "id": 14333,
    "package_name": "imagefx",
    "title": "Extract Features from Images",
    "description": "Synthesize images into characteristic features for time-series analysis or machine learning applications.  The package was originally intended for monitoring volcanic eruptions in video data by highlighting and extracting regions above the vent associated with plume activity.  However, the functions within are general and have wide applications for image processing, analyzing, filtering, and plotting.       ",
    "version": "0.4.1",
    "maintainer": "Alex J.C. Witsil <alexjcwitsil@gmail.com>",
    "author": "Alex J.C. Witsil",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=imagefx",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imagefx Extract Features from Images Synthesize images into characteristic features for time-series analysis or machine learning applications.  The package was originally intended for monitoring volcanic eruptions in video data by highlighting and extracting regions above the vent associated with plume activity.  However, the functions within are general and have wide applications for image processing, analyzing, filtering, and plotting.         "
  },
  {
    "id": 14346,
    "package_name": "imf.data",
    "title": "An Interface to IMF (International Monetary Fund) Data JSON API",
    "description": "A straightforward interface for accessing the IMF \n    (International Monetary Fund) data JSON API, \n    available at <https://data.imf.org/>. This package offers direct access to \n    the primary API endpoints: Dataflow, DataStructure, and CompactData. \n    And, it provides an intuitive interface for exploring available \n    dimensions and attributes, as well as querying individual time-series datasets. \n    Additionally, the package implements a rate limit on API calls to reduce the \n    chances of exceeding service limits (limited to 10 calls every 5 seconds) \n    and encountering response errors.",
    "version": "0.1.7",
    "maintainer": "Pedro Baltazar <pedrobtz@gmail.com>",
    "author": "Pedro Baltazar [aut, cre]",
    "url": "https://pedrobtz.github.io/imf.data/",
    "bug_reports": "https://github.com/pedrobtz/imf.data/issues",
    "repository": "https://cran.r-project.org/package=imf.data",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imf.data An Interface to IMF (International Monetary Fund) Data JSON API A straightforward interface for accessing the IMF \n    (International Monetary Fund) data JSON API, \n    available at <https://data.imf.org/>. This package offers direct access to \n    the primary API endpoints: Dataflow, DataStructure, and CompactData. \n    And, it provides an intuitive interface for exploring available \n    dimensions and attributes, as well as querying individual time-series datasets. \n    Additionally, the package implements a rate limit on API calls to reduce the \n    chances of exceeding service limits (limited to 10 calls every 5 seconds) \n    and encountering response errors.  "
  },
  {
    "id": 14371,
    "package_name": "imputeFin",
    "title": "Imputation of Financial Time Series with Missing Values and/or\nOutliers",
    "description": "Missing values often occur in financial data due to a variety \n    of reasons (errors in the collection process or in the processing stage, \n    lack of asset liquidity, lack of reporting of funds, etc.). However, \n    most data analysis methods expect complete data and cannot be employed \n    with missing values. One convenient way to deal with this issue without \n    having to redesign the data analysis method is to impute the missing \n    values. This package provides an efficient way to impute the missing \n    values based on modeling the time series with a random walk or an \n    autoregressive (AR) model, convenient to model log-prices and log-volumes \n    in financial data. In the current version, the imputation is \n    univariate-based (so no asset correlation is used). In addition,\n    outliers can be detected and removed.\n    The package is based on the paper:\n    J. Liu, S. Kumar, and D. P. Palomar (2019). Parameter Estimation of \n    Heavy-Tailed AR Model With Missing Data Via Stochastic EM. IEEE Trans. on \n    Signal Processing, vol. 67, no. 8, pp. 2159-2172. <doi:10.1109/TSP.2019.2899816>.",
    "version": "0.1.2",
    "maintainer": "Daniel P. Palomar <daniel.p.palomar@gmail.com>",
    "author": "Daniel P. Palomar [cre, aut],\n  Junyan Liu [aut],\n  Rui Zhou [aut]",
    "url": "https://CRAN.R-project.org/package=imputeFin,\nhttps://github.com/dppalomar/imputeFin,\nhttps://www.danielppalomar.com,\nhttps://doi.org/10.1109/TSP.2019.2899816,\nhttps://doi.org/10.1109/TSP.2020.3033378",
    "bug_reports": "https://github.com/dppalomar/imputeFin/issues",
    "repository": "https://cran.r-project.org/package=imputeFin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imputeFin Imputation of Financial Time Series with Missing Values and/or\nOutliers Missing values often occur in financial data due to a variety \n    of reasons (errors in the collection process or in the processing stage, \n    lack of asset liquidity, lack of reporting of funds, etc.). However, \n    most data analysis methods expect complete data and cannot be employed \n    with missing values. One convenient way to deal with this issue without \n    having to redesign the data analysis method is to impute the missing \n    values. This package provides an efficient way to impute the missing \n    values based on modeling the time series with a random walk or an \n    autoregressive (AR) model, convenient to model log-prices and log-volumes \n    in financial data. In the current version, the imputation is \n    univariate-based (so no asset correlation is used). In addition,\n    outliers can be detected and removed.\n    The package is based on the paper:\n    J. Liu, S. Kumar, and D. P. Palomar (2019). Parameter Estimation of \n    Heavy-Tailed AR Model With Missing Data Via Stochastic EM. IEEE Trans. on \n    Signal Processing, vol. 67, no. 8, pp. 2159-2172. <doi:10.1109/TSP.2019.2899816>.  "
  },
  {
    "id": 14378,
    "package_name": "imputeTS",
    "title": "Time Series Missing Value Imputation",
    "description": "Imputation (replacement) of missing values \n             in univariate time series. \n             Offers several imputation functions\n             and missing data plots. \n             Available imputation algorithms include: \n            'Mean', 'LOCF', 'Interpolation', \n            'Moving Average', 'Seasonal Decomposition', \n            'Kalman Smoothing on Structural Time Series models',\n            'Kalman Smoothing on ARIMA models'. Published in Moritz and Bartz-Beielstein (2017) \n            <doi:10.32614/RJ-2017-009>.",
    "version": "3.4",
    "maintainer": "Steffen Moritz <steffen.moritz10@gmail.com>",
    "author": "Steffen Moritz [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0085-1804>),\n  Sebastian Gatscha [aut],\n  Earo Wang [ctb] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Ron Hause [ctb] (ORCID: <https://orcid.org/0000-0002-5229-7366>)",
    "url": "https://github.com/SteffenMoritz/imputeTS,\nhttps://steffenmoritz.github.io/imputeTS/",
    "bug_reports": "https://github.com/SteffenMoritz/imputeTS/issues",
    "repository": "https://cran.r-project.org/package=imputeTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imputeTS Time Series Missing Value Imputation Imputation (replacement) of missing values \n             in univariate time series. \n             Offers several imputation functions\n             and missing data plots. \n             Available imputation algorithms include: \n            'Mean', 'LOCF', 'Interpolation', \n            'Moving Average', 'Seasonal Decomposition', \n            'Kalman Smoothing on Structural Time Series models',\n            'Kalman Smoothing on ARIMA models'. Published in Moritz and Bartz-Beielstein (2017) \n            <doi:10.32614/RJ-2017-009>.  "
  },
  {
    "id": 14379,
    "package_name": "imputeTestbench",
    "title": "Test Bench for the Comparison of Imputation Methods",
    "description": "Provides a test bench for the comparison of missing data imputation \n    methods in uni-variate time series. Imputation methods are compared using \n    different error metrics. Proposed imputation methods and alternative error \n    metrics can be used.",
    "version": "3.0.3",
    "maintainer": "Marcus W. Beck <mbafs2012@gmail.com>",
    "author": "Neeraj Bokde [aut],\n  Marcus W. Beck [cre, aut]",
    "url": "",
    "bug_reports": "https://github.com/neerajdhanraj/imputeTestbench/issues",
    "repository": "https://cran.r-project.org/package=imputeTestbench",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imputeTestbench Test Bench for the Comparison of Imputation Methods Provides a test bench for the comparison of missing data imputation \n    methods in uni-variate time series. Imputation methods are compared using \n    different error metrics. Proposed imputation methods and alternative error \n    metrics can be used.  "
  },
  {
    "id": 14429,
    "package_name": "influxdbr",
    "title": "R Interface to InfluxDB",
    "description": "An R interface to the InfluxDB time series database <https://www.influxdata.com>. This package allows you to fetch and write time series data from/to an InfluxDB server. Additionally, handy wrappers for the Influx Query Language (IQL) to manage and explore a remote database are provided. ",
    "version": "0.14.2",
    "maintainer": "Dominik Leutnant <leutnant@fh-muenster.de>",
    "author": "Dominik Leutnant [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3293-2315>)",
    "url": "https://github.com/dleutnant/influxdbr",
    "bug_reports": "http://github.com/dleutnant/influxdbr/issues",
    "repository": "https://cran.r-project.org/package=influxdbr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "influxdbr R Interface to InfluxDB An R interface to the InfluxDB time series database <https://www.influxdata.com>. This package allows you to fetch and write time series data from/to an InfluxDB server. Additionally, handy wrappers for the Influx Query Language (IQL) to manage and explore a remote database are provided.   "
  },
  {
    "id": 14431,
    "package_name": "infocausality",
    "title": "Information-Theoretic Measure of Causality",
    "description": "Methods for quantifying temporal and spatial causality through information flow, and decomposing it into unique, redundant, and synergistic components, following the framework described in Martinez-Sanchez et al. (2024) <doi:10.1038/s41467-024-53373-4>.",
    "version": "1.0",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "author": "Wenbo Lv [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0002-6003-3800>)",
    "url": "https://stscl.github.io/infocausality/,\nhttps://github.com/stscl/infocausality",
    "bug_reports": "https://github.com/stscl/infocausality/issues",
    "repository": "https://cran.r-project.org/package=infocausality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "infocausality Information-Theoretic Measure of Causality Methods for quantifying temporal and spatial causality through information flow, and decomposing it into unique, redundant, and synergistic components, following the framework described in Martinez-Sanchez et al. (2024) <doi:10.1038/s41467-024-53373-4>.  "
  },
  {
    "id": 14511,
    "package_name": "intradayModel",
    "title": "Modeling and Forecasting Financial Intraday Signals",
    "description": "Models, analyzes, and forecasts financial intraday signals. This package\n    currently supports a univariate state-space model for intraday trading volume provided\n    by Chen (2016) <doi:10.2139/ssrn.3101695>.",
    "version": "0.0.1",
    "maintainer": "Daniel P. Palomar <daniel.p.palomar@gmail.com>",
    "author": "Shengjie Xiu [aut],\n  Yifan Yu [aut],\n  Daniel P. Palomar [cre, aut, cph]",
    "url": "https://github.com/convexfi/intradayModel,\nhttps://www.danielppalomar.com,\nhttps://dx.doi.org/10.2139/ssrn.3101695",
    "bug_reports": "https://github.com/convexfi/intradayModel/issues",
    "repository": "https://cran.r-project.org/package=intradayModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "intradayModel Modeling and Forecasting Financial Intraday Signals Models, analyzes, and forecasts financial intraday signals. This package\n    currently supports a univariate state-space model for intraday trading volume provided\n    by Chen (2016) <doi:10.2139/ssrn.3101695>.  "
  },
  {
    "id": 14522,
    "package_name": "inventorize",
    "title": "Inventory Analytics, Pricing and Markdowns",
    "description": "Simulate inventory policies with and without forecasting, facilitate inventory analysis calculations such as  stock levels and re-order points,pricing and promotions calculations. \n  The package includes calculations of inventory metrics, stock-out calculations and ABC analysis calculations.\n    The package includes revenue management techniques such as Multi-product optimization,logit and polynomial model optimization.\n  The functions are referenced from :\n  1-Harris, Ford W. (1913). \"How many parts to make at once\". Factory, The Magazine of Management. \n  2- Nahmias, S. Production and Operations Analysis. McGraw-Hill International Edition.\n  3-Silver, E.A., Pyke, D.F., Peterson, R. Inventory Management and Production Planning and Scheduling. \n  4-Ballou, R.H. Business Logistics Management. \n  5-MIT Micromasters Program. \n  6- Columbia University  course for supply and demand analysis.\n  8- Price Elasticity of Demand MATH 104,Mark Mac Lean (with assistance from Patrick Chan) 2011W\n  For further details or correspondence :<www.linkedin.com/in/haythamomar>, <www.rescaleanalytics.com>.",
    "version": "1.1.2",
    "maintainer": "Haytham Omar <haytham@rescaleanalytics.com>",
    "author": "Haytham Omar [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=inventorize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inventorize Inventory Analytics, Pricing and Markdowns Simulate inventory policies with and without forecasting, facilitate inventory analysis calculations such as  stock levels and re-order points,pricing and promotions calculations. \n  The package includes calculations of inventory metrics, stock-out calculations and ABC analysis calculations.\n    The package includes revenue management techniques such as Multi-product optimization,logit and polynomial model optimization.\n  The functions are referenced from :\n  1-Harris, Ford W. (1913). \"How many parts to make at once\". Factory, The Magazine of Management. \n  2- Nahmias, S. Production and Operations Analysis. McGraw-Hill International Edition.\n  3-Silver, E.A., Pyke, D.F., Peterson, R. Inventory Management and Production Planning and Scheduling. \n  4-Ballou, R.H. Business Logistics Management. \n  5-MIT Micromasters Program. \n  6- Columbia University  course for supply and demand analysis.\n  8- Price Elasticity of Demand MATH 104,Mark Mac Lean (with assistance from Patrick Chan) 2011W\n  For further details or correspondence :<www.linkedin.com/in/haythamomar>, <www.rescaleanalytics.com>.  "
  },
  {
    "id": 14555,
    "package_name": "iperform",
    "title": "Time Series Performance",
    "description": "A tool to calculate the performance of a time series in a specific date or period. It is more intended for data analysis in the fields of finance, banking, telecommunications or operational marketing.",
    "version": "0.0.3",
    "maintainer": "Patrick Ilunga <patrick.ilunga@unikin.ac.cd>",
    "author": "Patrick Ilunga [aut, cre],\n  Ilunga Buabua Patrick [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iperform",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iperform Time Series Performance A tool to calculate the performance of a time series in a specific date or period. It is more intended for data analysis in the fields of finance, banking, telecommunications or operational marketing.  "
  },
  {
    "id": 14564,
    "package_name": "ipolygrowth",
    "title": "Individual Growth Curve Parameter Calculation using Polynomial\nFunctions",
    "description": "Calculation of key bacterial growth curve parameters using fourth degree polynomial functions. \n    Six growth curve parameters are provided including peak growth rate, doubling time, lag time, maximum growth, and etc.\n    'ipolygrowth' takes time series data from individual biological samples (with technical replicates) or multiple samples.",
    "version": "1.0.0",
    "maintainer": "Jifan Wang <wjifan@hotmail.com>",
    "author": "Jifan Wang [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9720-8913>),\n  Kathryn Barger [aut, cph]",
    "url": "https://github.com/kivanvan/ipolygrowth",
    "bug_reports": "https://github.com/kivanvan/ipolygrowth/issues",
    "repository": "https://cran.r-project.org/package=ipolygrowth",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipolygrowth Individual Growth Curve Parameter Calculation using Polynomial\nFunctions Calculation of key bacterial growth curve parameters using fourth degree polynomial functions. \n    Six growth curve parameters are provided including peak growth rate, doubling time, lag time, maximum growth, and etc.\n    'ipolygrowth' takes time series data from individual biological samples (with technical replicates) or multiple samples.  "
  },
  {
    "id": 14581,
    "package_name": "irg",
    "title": "Instantaneous Rate of Green Up",
    "description": "Fits a double logistic function to NDVI time series and calculates \n             instantaneous rate of green (IRG) according to methods described\n             in Bischoff et al. (2012) <doi:10.1086/667590>. ",
    "version": "0.1.6",
    "maintainer": "Alec L. Robitaille <robit.alec@gmail.com>",
    "author": "Alec L. Robitaille [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4706-1762>)",
    "url": "https://github.com/robitalec/irg, https://robitalec.github.io/irg/",
    "bug_reports": "https://github.com/robitalec/irg/issues",
    "repository": "https://cran.r-project.org/package=irg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "irg Instantaneous Rate of Green Up Fits a double logistic function to NDVI time series and calculates \n             instantaneous rate of green (IRG) according to methods described\n             in Bischoff et al. (2012) <doi:10.1086/667590>.   "
  },
  {
    "id": 14649,
    "package_name": "its.analysis",
    "title": "Running Interrupted Time Series Analysis",
    "description": "Two functions for running and then post-estimating an Interrupted Time Series Analysis model. This is a solution for running time series analyses on temporally short data. See English (2019) 'The its.analysis R package - Modelling short time series data' <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3398189> for an overview of the method.",
    "version": "1.6.0",
    "maintainer": "Patrick English <p.english@exeter.ac.uk>",
    "author": "Patrick English",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=its.analysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "its.analysis Running Interrupted Time Series Analysis Two functions for running and then post-estimating an Interrupted Time Series Analysis model. This is a solution for running time series analyses on temporally short data. See English (2019) 'The its.analysis R package - Modelling short time series data' <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3398189> for an overview of the method.  "
  },
  {
    "id": 14652,
    "package_name": "itsmr",
    "title": "Time Series Analysis Using the Innovations Algorithm",
    "description": "Provides functions for modeling and forecasting time series data. Forecasting is based on the innovations algorithm. A description of the innovations algorithm can be found in the textbook \"Introduction to Time Series and Forecasting\" by Peter J. Brockwell and Richard A. Davis.",
    "version": "1.11",
    "maintainer": "George Weigt <9634295@gmail.com>",
    "author": "George Weigt [aut, cre]",
    "url": "https://georgeweigt.github.io/itsmr-refman.pdf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=itsmr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "itsmr Time Series Analysis Using the Innovations Algorithm Provides functions for modeling and forecasting time series data. Forecasting is based on the innovations algorithm. A description of the innovations algorithm can be found in the textbook \"Introduction to Time Series and Forecasting\" by Peter J. Brockwell and Richard A. Davis.  "
  },
  {
    "id": 14706,
    "package_name": "jellyfisher",
    "title": "Visualize Spatiotemporal Tumor Evolution with Jellyfish Plots",
    "description": "\n    Generates interactive Jellyfish plots to visualize spatiotemporal tumor\n    evolution by integrating sample and phylogenetic trees into a unified plot.\n    This approach provides an intuitive way to analyze tumor heterogeneity and\n    evolution over time and across anatomical locations. The Jellyfish plot\n    visualization design was first introduced by Lahtinen, Lavikka, et al.\n    (2023, <doi:10.1016/j.ccell.2023.04.017>).\n    This package also supports visualizing ClonEvol results, a tool developed\n    by Dang, et al. (2017, <doi:10.1093/annonc/mdx517>), for analyzing clonal\n    evolution from multi-sample sequencing data. The 'clonevol' package is not\n    available on CRAN but can be installed from its GitHub\n    repository (<https://github.com/hdng/clonevol>).",
    "version": "1.1.1",
    "maintainer": "Kari Lavikka <kari.lavikka@helsinki.fi>",
    "author": "Kari Lavikka [cph, aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4163-4945>)",
    "url": "https://github.com/HautaniemiLab/jellyfisher,\nhttps://hautaniemilab.github.io/jellyfisher/",
    "bug_reports": "https://github.com/HautaniemiLab/jellyfisher/issues",
    "repository": "https://cran.r-project.org/package=jellyfisher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jellyfisher Visualize Spatiotemporal Tumor Evolution with Jellyfish Plots \n    Generates interactive Jellyfish plots to visualize spatiotemporal tumor\n    evolution by integrating sample and phylogenetic trees into a unified plot.\n    This approach provides an intuitive way to analyze tumor heterogeneity and\n    evolution over time and across anatomical locations. The Jellyfish plot\n    visualization design was first introduced by Lahtinen, Lavikka, et al.\n    (2023, <doi:10.1016/j.ccell.2023.04.017>).\n    This package also supports visualizing ClonEvol results, a tool developed\n    by Dang, et al. (2017, <doi:10.1093/annonc/mdx517>), for analyzing clonal\n    evolution from multi-sample sequencing data. The 'clonevol' package is not\n    available on CRAN but can be installed from its GitHub\n    repository (<https://github.com/hdng/clonevol>).  "
  },
  {
    "id": 14724,
    "package_name": "jmotif",
    "title": "Time Series Analysis Toolkit Based on Symbolic Aggregate\nDiscretization, i.e. SAX",
    "description": "Implements time series z-normalization, SAX, HOT-SAX, VSM, SAX-VSM, RePair, and RRA\n    algorithms facilitating time series motif (i.e., recurrent pattern), discord (i.e., anomaly),\n    and characteristic pattern discovery along with interpretable time series classification.",
    "version": "1.2.0",
    "maintainer": "Pavel Senin <seninp@gmail.com>",
    "author": "Pavel Senin [aut, cre]",
    "url": "https://github.com/jMotif/jmotif-R",
    "bug_reports": "https://github.com/jMotif/jmotif-R/issues",
    "repository": "https://cran.r-project.org/package=jmotif",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jmotif Time Series Analysis Toolkit Based on Symbolic Aggregate\nDiscretization, i.e. SAX Implements time series z-normalization, SAX, HOT-SAX, VSM, SAX-VSM, RePair, and RRA\n    algorithms facilitating time series motif (i.e., recurrent pattern), discord (i.e., anomaly),\n    and characteristic pattern discovery along with interpretable time series classification.  "
  },
  {
    "id": 14784,
    "package_name": "jubilee",
    "title": "Forecasting Long-Term Growth of the U.S. Stock Market and\nBusiness Cycles",
    "description": "A long-term forecast model called \"Jubilee-Tectonic model\" is implemented to forecast future returns of the U.S. stock market, Treasury yield, and gold price. The five-factor model forecasts the 10-year and 20-year future equity returns with high R-squared above 80 percent. It is based on linear growth and mean reversion characteristics in the U.S. stock market. This model also enhances the CAPE model by introducing the hypothesis that there are fault lines in the historical CAPE, which can be calibrated and corrected through statistical learning. In addition, it contains a module for business cycles, optimal interest rate, and recession forecasts.",
    "version": "0.3.3",
    "maintainer": "Stephen H-T. Lihn <stevelihn@gmail.com>",
    "author": "Stephen H-T. Lihn [aut, cre]",
    "url": "https://ssrn.com/abstract=3156574\nhttps://ssrn.com/abstract=3422278\nhttps://ssrn.com/abstract=3435667",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=jubilee",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jubilee Forecasting Long-Term Growth of the U.S. Stock Market and\nBusiness Cycles A long-term forecast model called \"Jubilee-Tectonic model\" is implemented to forecast future returns of the U.S. stock market, Treasury yield, and gold price. The five-factor model forecasts the 10-year and 20-year future equity returns with high R-squared above 80 percent. It is based on linear growth and mean reversion characteristics in the U.S. stock market. This model also enhances the CAPE model by introducing the hypothesis that there are fault lines in the historical CAPE, which can be calibrated and corrected through statistical learning. In addition, it contains a module for business cycles, optimal interest rate, and recession forecasts.  "
  },
  {
    "id": 14787,
    "package_name": "jumps",
    "title": "Hodrick-Prescott Filter with Jumps",
    "description": "A set of functions to compute the Hodrick-Prescott (HP)\n    filter with automatically selected jumps. The original\n    HP filter extracts a smooth trend from a time series, and our version\n    allows for a small number of automatically identified jumps.\n    See Maranzano and Pelagatti (2024) <doi:10.2139/ssrn.4896170> for details.",
    "version": "1.0",
    "maintainer": "Matteo Pelagatti <matteo.pelagatti@unimib.it>",
    "author": "Matteo Pelagatti [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1860-7535>),\n  Paolo Maranzano [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-9228-2759>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=jumps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jumps Hodrick-Prescott Filter with Jumps A set of functions to compute the Hodrick-Prescott (HP)\n    filter with automatically selected jumps. The original\n    HP filter extracts a smooth trend from a time series, and our version\n    allows for a small number of automatically identified jumps.\n    See Maranzano and Pelagatti (2024) <doi:10.2139/ssrn.4896170> for details.  "
  },
  {
    "id": 14812,
    "package_name": "kardl",
    "title": "Make Symmetric and Asymmetric ARDL Estimations",
    "description": "Implements estimation procedures for Autoregressive Distributed Lag (ARDL) \n    and Nonlinear ARDL (NARDL) models, which allow researchers to investigate both \n    short- and long-run relationships in time series data under mixed orders of integration. \n    The package supports simultaneous modeling of symmetric and asymmetric regressors, \n    flexible treatment of short-run and long-run asymmetries, and automated equation handling. \n    It includes several cointegration testing approaches such as the Pesaran-Shin-Smith F \n    and t bounds tests, the Banerjee error correction test, and the restricted ECM test, \n    together with diagnostic tools including Wald tests for asymmetry, ARCH tests, and \n    stability procedures (CUSUM and CUSUMQ). Methodological foundations are provided in \n    Pesaran, Shin, and Smith (2001) <doi:10.1016/S0304-4076(01)00049-5> and Shin, Yu, and \n    Greenwood-Nimmo (2014, ISBN:9780123855079).",
    "version": "0.1.1",
    "maintainer": "Huseyin Karamelikli <hakperest@gmail.com>",
    "author": "Huseyin Karamelikli [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7622-0972>),\n  Huseyin Utku Demir [aut] (ORCID:\n    <https://orcid.org/0000-0002-9140-0362>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kardl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kardl Make Symmetric and Asymmetric ARDL Estimations Implements estimation procedures for Autoregressive Distributed Lag (ARDL) \n    and Nonlinear ARDL (NARDL) models, which allow researchers to investigate both \n    short- and long-run relationships in time series data under mixed orders of integration. \n    The package supports simultaneous modeling of symmetric and asymmetric regressors, \n    flexible treatment of short-run and long-run asymmetries, and automated equation handling. \n    It includes several cointegration testing approaches such as the Pesaran-Shin-Smith F \n    and t bounds tests, the Banerjee error correction test, and the restricted ECM test, \n    together with diagnostic tools including Wald tests for asymmetry, ARCH tests, and \n    stability procedures (CUSUM and CUSUMQ). Methodological foundations are provided in \n    Pesaran, Shin, and Smith (2001) <doi:10.1016/S0304-4076(01)00049-5> and Shin, Yu, and \n    Greenwood-Nimmo (2014, ISBN:9780123855079).  "
  },
  {
    "id": 14819,
    "package_name": "kcpRS",
    "title": "Kernel Change Point Detection on the Running Statistics",
    "description": "The running statistics of interest is first extracted using a time window which is slid across the time series, and in each window, the running statistics value is computed. KCP (Kernel Change Point) detection proposed by Arlot et al. (2012) <arXiv:1202.3878> is then implemented to flag the change points on the running statistics (Cabrieto et al., 2018, <doi:10.1016/j.ins.2018.03.010>). Change points are located by minimizing a variance criterion based on the pairwise similarities between running statistics which are computed via the Gaussian kernel. KCP can locate change points for a given k number of change points. To determine the optimal k, the KCP permutation test is first carried out by comparing the variance of the running statistics extracted from the original data to that of permuted data. If this test is significant, then there is sufficient evidence for at least one change point in the data. Model selection is then used to determine the optimal k>0.",
    "version": "1.1.1",
    "maintainer": "Kristof Meers <kristof.meers+cran@kuleuven.be>",
    "author": "Jedelyn Cabrieto [aut],\n  Kristof Meers [aut, cre],\n  Evelien Schat [ctb],\n  Janne Adolf [ctb],\n  Peter Kuppens [ctb],\n  Francis Tuerlinckx [ctb],\n  Eva Ceulemans [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kcpRS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kcpRS Kernel Change Point Detection on the Running Statistics The running statistics of interest is first extracted using a time window which is slid across the time series, and in each window, the running statistics value is computed. KCP (Kernel Change Point) detection proposed by Arlot et al. (2012) <arXiv:1202.3878> is then implemented to flag the change points on the running statistics (Cabrieto et al., 2018, <doi:10.1016/j.ins.2018.03.010>). Change points are located by minimizing a variance criterion based on the pairwise similarities between running statistics which are computed via the Gaussian kernel. KCP can locate change points for a given k number of change points. To determine the optimal k, the KCP permutation test is first carried out by comparing the variance of the running statistics extracted from the original data to that of permuted data. If this test is significant, then there is sufficient evidence for at least one change point in the data. Model selection is then used to determine the optimal k>0.  "
  },
  {
    "id": 14844,
    "package_name": "kernelPhil",
    "title": "Kernel Smoothing Tools for Philology and Historical Dialectology",
    "description": "Contains kernel smoothing tools designed for use by historical\n    dialectologists and philologists for exploring spatial and temporal patterns\n    in noisy historical language data, such as that obtained from historical texts.\n    The main way in which these might differ from other implementations of kernel\n    smoothing is that they assume that the function (linguistic variable) being\n    explored has the form of the relative frequency of a series of discrete\n    possibilities (linguistic variants). This package also offers a way of exploring\n    distributions in 2-dimensional space and in time with separate kernels, and\n    tools for identifying appropriate bandwidths for these.",
    "version": "0.2",
    "maintainer": "Tamsin Blaxter <tamsinblaxter@gmail.com>",
    "author": "Tamsin Blaxter [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1466-8306>)",
    "url": "http://www.icge.co.uk/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kernelPhil",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kernelPhil Kernel Smoothing Tools for Philology and Historical Dialectology Contains kernel smoothing tools designed for use by historical\n    dialectologists and philologists for exploring spatial and temporal patterns\n    in noisy historical language data, such as that obtained from historical texts.\n    The main way in which these might differ from other implementations of kernel\n    smoothing is that they assume that the function (linguistic variable) being\n    explored has the form of the relative frequency of a series of discrete\n    possibilities (linguistic variants). This package also offers a way of exploring\n    distributions in 2-dimensional space and in time with separate kernels, and\n    tools for identifying appropriate bandwidths for these.  "
  },
  {
    "id": 14852,
    "package_name": "kernstadapt",
    "title": "Adaptive Kernel Estimators for Point Process Intensities on\nLinear Networks",
    "description": "Adaptive estimation of the first-order intensity function of a spatio-temporal point process using kernels and variable bandwidths. The methodology used for estimation is presented in Gonz\u00e1lez and Moraga (2022). <doi:10.48550/arXiv.2208.12026>.",
    "version": "0.4.0",
    "maintainer": "Jonatan A Gonz\u00e1lez <jonathan.gonzalez@kaust.edu.sa>",
    "author": "Jonatan A Gonz\u00e1lez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2296-5271>),\n  Paula Moraga [aut] (ORCID: <https://orcid.org/0000-0001-5266-0201>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kernstadapt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kernstadapt Adaptive Kernel Estimators for Point Process Intensities on\nLinear Networks Adaptive estimation of the first-order intensity function of a spatio-temporal point process using kernels and variable bandwidths. The methodology used for estimation is presented in Gonz\u00e1lez and Moraga (2022). <doi:10.48550/arXiv.2208.12026>.  "
  },
  {
    "id": 14884,
    "package_name": "kinematics",
    "title": "Studying Sampled Trajectories",
    "description": "Allows analyzing time series representing two-dimensional movements.\n    It accepts a data frame with a time (t), horizontal (x) and vertical (y) coordinate as columns,\n    and returns several dynamical properties such as speed, acceleration or curvature.",
    "version": "1.0.0",
    "maintainer": "Pablo Rodriguez-Sanchez <pablo.rodriguez.sanchez@gmail.com>",
    "author": "Pablo Rodriguez-Sanchez (https://pabrod.github.io) and Sanne J. P. van den Berg (https://www.wur.nl/en/Persons/Sanne-dr.-SJP-Sanne-van-den-Berg.htm)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kinematics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kinematics Studying Sampled Trajectories Allows analyzing time series representing two-dimensional movements.\n    It accepts a data frame with a time (t), horizontal (x) and vertical (y) coordinate as columns,\n    and returns several dynamical properties such as speed, acceleration or curvature.  "
  },
  {
    "id": 14895,
    "package_name": "kiwisR",
    "title": "A Wrapper for Querying KISTERS 'WISKI' Databases via the 'KiWIS'\nAPI",
    "description": "A wrapper for querying 'WISKI' databases via the 'KiWIS' 'REST' API. 'WISKI' is an 'SQL' relational database \n  used for the collection and storage of water data developed by KISTERS and 'KiWIS' is a 'REST' service that provides\n  access to 'WISKI' databases via HTTP requests (<https://www.kisters.eu/water-weather-and-environment/>). \n  Contains a list of default databases (called 'hubs') and also allows users to provide their own 'KiWIS' URL. \n  Supports the entire query process- from metadata to specific time series values. All data is returned as tidy tibbles.",
    "version": "0.2.4",
    "maintainer": "Ryan Whaley <rdgwhaley@gmail.com>",
    "author": "Ryan Whaley [aut, cre],\n  Sam Albers [ctb]",
    "url": "https://github.com/rywhale/kiwisR",
    "bug_reports": "https://github.com/rywhale/kiwisR/issues",
    "repository": "https://cran.r-project.org/package=kiwisR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kiwisR A Wrapper for Querying KISTERS 'WISKI' Databases via the 'KiWIS'\nAPI A wrapper for querying 'WISKI' databases via the 'KiWIS' 'REST' API. 'WISKI' is an 'SQL' relational database \n  used for the collection and storage of water data developed by KISTERS and 'KiWIS' is a 'REST' service that provides\n  access to 'WISKI' databases via HTTP requests (<https://www.kisters.eu/water-weather-and-environment/>). \n  Contains a list of default databases (called 'hubs') and also allows users to provide their own 'KiWIS' URL. \n  Supports the entire query process- from metadata to specific time series values. All data is returned as tidy tibbles.  "
  },
  {
    "id": 14907,
    "package_name": "kmBlock",
    "title": "k-Means Like Blockmodeling of One-Mode and Linked Networks",
    "description": "Implements k-means like blockmodeling of one-mode and linked networks as presented in \u017diberna (2020) <doi:10.1016/j.socnet.2019.10.006>. The development of this package is financially supported by the Slovenian Research Agency (<https://www.arrs.si/>) within the research programs P5-0168 and the research projects J7-8279 (Blockmodeling multilevel and temporal networks) and J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).",
    "version": "0.1.4",
    "maintainer": "Ale\u0161 \u017diberna <ales.ziberna@fdv.uni-lj.si>",
    "author": "Ale\u0161 \u017diberna [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kmBlock",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kmBlock k-Means Like Blockmodeling of One-Mode and Linked Networks Implements k-means like blockmodeling of one-mode and linked networks as presented in \u017diberna (2020) <doi:10.1016/j.socnet.2019.10.006>. The development of this package is financially supported by the Slovenian Research Agency (<https://www.arrs.si/>) within the research programs P5-0168 and the research projects J7-8279 (Blockmodeling multilevel and temporal networks) and J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).  "
  },
  {
    "id": 14916,
    "package_name": "knfi",
    "title": "Analysis of Korean National Forest Inventory Database",
    "description": "Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.",
    "version": "1.0.1.9",
    "maintainer": "Sinyoung Park <youngsin0306@kookmin.ac.kr>",
    "author": "Sinyoung Park [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3658-0935>),\n  Wonhee Cho [aut, ctb] (ORCID: <https://orcid.org/0000-0002-9598-6188>),\n  Inyoo Kim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-7709-8224>),\n  Wontaek Lim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-5872-1121>),\n  Dongwook W. Ko [aut, ths] (ORCID:\n    <https://orcid.org/0000-0002-6944-0261>)",
    "url": "https://github.com/SYOUNG9836/knfi,\nhttps://syoung9836.github.io/knfi/",
    "bug_reports": "https://github.com/SYOUNG9836/knfi/issues",
    "repository": "https://cran.r-project.org/package=knfi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knfi Analysis of Korean National Forest Inventory Database Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.  "
  },
  {
    "id": 14925,
    "package_name": "knnp",
    "title": "Time Series Prediction using K-Nearest Neighbors Algorithm\n(Parallel)",
    "description": "Two main functionalities are provided. One of them is predicting values with \n    k-nearest neighbors algorithm and the other is optimizing the parameters k and d of the algorithm.\n    These are carried out in parallel using multiple threads.",
    "version": "2.0.0",
    "maintainer": "Daniel Bastarrica Lacalle <danibast@ucm.es>",
    "author": "Daniel Bastarrica Lacalle [aut, cre],\n  Javier Berdecio Trigueros [aut],\n  Javier Arroyo Gallardo [aut],\n  Albert Meco Alias [aut]",
    "url": "https://github.com/Grasia/knnp",
    "bug_reports": "https://github.com/Grasia/knnp/issues",
    "repository": "https://cran.r-project.org/package=knnp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knnp Time Series Prediction using K-Nearest Neighbors Algorithm\n(Parallel) Two main functionalities are provided. One of them is predicting values with \n    k-nearest neighbors algorithm and the other is optimizing the parameters k and d of the algorithm.\n    These are carried out in parallel using multiple threads.  "
  },
  {
    "id": 14926,
    "package_name": "knnwtsim",
    "title": "K Nearest Neighbor Forecasting with a Tailored Similarity Metric",
    "description": "Functions to implement K Nearest Neighbor forecasting using a weighted similarity metric tailored to the problem of forecasting univariate time series where recent observations, seasonal patterns, and exogenous predictors are all relevant in predicting future observations of the series in question. For more information on the formulation of this similarity metric please see Trupiano (2021) <arXiv:2112.06266>.",
    "version": "1.0.0",
    "maintainer": "Matthew Trupiano <matthew.trupiano.professional@gmail.com>",
    "author": "Matthew Trupiano",
    "url": "https://github.com/mtrupiano1/knnwtsim",
    "bug_reports": "https://github.com/mtrupiano1/knnwtsim/issues",
    "repository": "https://cran.r-project.org/package=knnwtsim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knnwtsim K Nearest Neighbor Forecasting with a Tailored Similarity Metric Functions to implement K Nearest Neighbor forecasting using a weighted similarity metric tailored to the problem of forecasting univariate time series where recent observations, seasonal patterns, and exogenous predictors are all relevant in predicting future observations of the series in question. For more information on the formulation of this similarity metric please see Trupiano (2021) <arXiv:2112.06266>.  "
  },
  {
    "id": 14927,
    "package_name": "knobi",
    "title": "Known-Biomass Production Model (KBPM)",
    "description": "Application of a Known Biomass Production Model (KBPM): (1) the fitting of KBPM to each stock; (2) the estimation of the effects of environmental variability; (3) the retrospective analysis to identify regime shifts; (4) the estimation of forecasts. For more details see Schaefer (1954) <https://www.iattc.org/GetAttachment/62d510ee-13d0-40f2-847b-0fde415476b8/Vol-1-No-2-1954-SCHAEFER,-MILNER-B-_Some-aspects-of-the-dynamics-of-populations-important-to-the-management-of-the-commercial-marine-fisheries.pdf>, Pella and Tomlinson (1969) <https://www.iattc.org/GetAttachment/9865079c-6ee7-40e2-9e30-c4523ff81ddf/Vol-13-No-3-1969-PELLA,-JEROME-J-,-and-PATRICK-K-TOMLINSON_A-generalized-stock-production-model.pdf> and MacCall (2002) <doi:10.1577/1548-8675(2002)022%3C0272:UOKBPM%3E2.0.CO;2>.",
    "version": "0.1.0",
    "maintainer": "Anxo Paz <anxo.paz@hotmail.com>",
    "author": "Anxo Paz [aut, cre],\n  Marta Cousido Rocha [aut, ths],\n  Santiago Cervino Lopez [aut, ths],\n  Maria Grazia Peninno [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=knobi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knobi Known-Biomass Production Model (KBPM) Application of a Known Biomass Production Model (KBPM): (1) the fitting of KBPM to each stock; (2) the estimation of the effects of environmental variability; (3) the retrospective analysis to identify regime shifts; (4) the estimation of forecasts. For more details see Schaefer (1954) <https://www.iattc.org/GetAttachment/62d510ee-13d0-40f2-847b-0fde415476b8/Vol-1-No-2-1954-SCHAEFER,-MILNER-B-_Some-aspects-of-the-dynamics-of-populations-important-to-the-management-of-the-commercial-marine-fisheries.pdf>, Pella and Tomlinson (1969) <https://www.iattc.org/GetAttachment/9865079c-6ee7-40e2-9e30-c4523ff81ddf/Vol-13-No-3-1969-PELLA,-JEROME-J-,-and-PATRICK-K-TOMLINSON_A-generalized-stock-production-model.pdf> and MacCall (2002) <doi:10.1577/1548-8675(2002)022%3C0272:UOKBPM%3E2.0.CO;2>.  "
  },
  {
    "id": 14933,
    "package_name": "kofdata",
    "title": "Get Data from the 'KOF Datenservice' API",
    "description": "Read Swiss time series data from the 'KOF Data' API, <https://datenservice.kof.ethz.ch>. The API provides macro economic time series data mostly about Switzerland. The package itself is a set of wrappers around the 'KOF Datenservice' API. The 'kofdata' package is able to consume public information as well as data that requires an API token. ",
    "version": "0.2.1",
    "maintainer": "Matthias Bannert <bannert@kof.ethz.ch>",
    "author": "Matthias Bannert [aut, cre],\n  Oliver M\u00fcller [aut],\n  Severin Thoeni [aut],\n  Diana Diaz [ctb]",
    "url": "https://github.com/KOF-ch/kofdata",
    "bug_reports": "https://github.com/KOF-ch/kofdata/issues",
    "repository": "https://cran.r-project.org/package=kofdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kofdata Get Data from the 'KOF Datenservice' API Read Swiss time series data from the 'KOF Data' API, <https://datenservice.kof.ethz.ch>. The API provides macro economic time series data mostly about Switzerland. The package itself is a set of wrappers around the 'KOF Datenservice' API. The 'kofdata' package is able to consume public information as well as data that requires an API token.   "
  },
  {
    "id": 14958,
    "package_name": "kssa",
    "title": "Known Sub-Sequence Algorithm",
    "description": "Implements the Known Sub-Sequence Algorithm <doi:10.1016/j.aaf.2021.12.013>, which helps to automatically identify and validate the best method for missing data imputation in a time series. Supports the comparison of multiple state-of-the-art algorithms.",
    "version": "0.0.5",
    "maintainer": "Iv\u00e1n Felipe Benavides <pipeben@gmail.com>",
    "author": "Iv\u00e1n Felipe Benavides [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1139-3909>),\n  Steffen Moritz [aut] (ORCID: <https://orcid.org/0000-0002-0085-1804>),\n  Brayan-David Aroca-Gonzalez [aut] (ORCID:\n    <https://orcid.org/0000-0002-7365-5740>),\n  Jhoana Romero [aut] (ORCID: <https://orcid.org/0000-0002-1834-3461>),\n  Marlon Santacruz [aut] (ORCID: <https://orcid.org/0000-0003-2242-742X>),\n  John-Josephraj Selvaraj [aut] (ORCID:\n    <https://orcid.org/0000-0002-9195-4883>)",
    "url": "https://github.com/steffenmoritz/kssa,\nhttps://steffenmoritz.github.io/kssa/",
    "bug_reports": "https://github.com/steffenmoritz/kssa/issues",
    "repository": "https://cran.r-project.org/package=kssa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kssa Known Sub-Sequence Algorithm Implements the Known Sub-Sequence Algorithm <doi:10.1016/j.aaf.2021.12.013>, which helps to automatically identify and validate the best method for missing data imputation in a time series. Supports the comparison of multiple state-of-the-art algorithms.  "
  },
  {
    "id": 14971,
    "package_name": "kza",
    "title": "Kolmogorov-Zurbenko Adaptive Filters",
    "description": "Time Series Analysis including break detection, spectral analysis, KZ Fourier Transforms.",
    "version": "4.1.0.1",
    "maintainer": "Brian Close <brian.close@gmail.com>",
    "author": "Brian Close <brian.close@gmail.com>, Igor Zurbenko <IZurbenko@albany.edu> and Mingzeng Sun <msun@albany.edu>\t",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kza",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kza Kolmogorov-Zurbenko Adaptive Filters Time Series Analysis including break detection, spectral analysis, KZ Fourier Transforms.  "
  },
  {
    "id": 15008,
    "package_name": "lambdaTS",
    "title": "Variational Seq2Seq Model with Lambda Transformer for Time\nSeries Analysis",
    "description": "Time series analysis based on lambda transformer and variational seq2seq, built on 'Torch'.",
    "version": "1.1",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lambdaTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lambdaTS Variational Seq2Seq Model with Lambda Transformer for Time\nSeries Analysis Time series analysis based on lambda transformer and variational seq2seq, built on 'Torch'.  "
  },
  {
    "id": 15067,
    "package_name": "lazybar",
    "title": "Progress Bar with Remaining Time Forecast Method",
    "description": "A simple progress bar showing estimated remaining time. \n    Multiple forecast methods and user defined forecast method for \n    the remaining time are supported.",
    "version": "0.1.0",
    "maintainer": "Yangzhuoran Yang <Fin.Yang@monash.edu>",
    "author": "Yangzhuoran Yang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1232-8017>)",
    "url": "https://pkg.yangzhuoranyang.com/lazybar/,\nhttps://github.com/FinYang/lazybar/",
    "bug_reports": "https://github.com/FinYang/lazybar/issues/",
    "repository": "https://cran.r-project.org/package=lazybar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lazybar Progress Bar with Remaining Time Forecast Method A simple progress bar showing estimated remaining time. \n    Multiple forecast methods and user defined forecast method for \n    the remaining time are supported.  "
  },
  {
    "id": 15096,
    "package_name": "ldhmm",
    "title": "Hidden Markov Model for Financial Time-Series Based on Lambda\nDistribution",
    "description": "Hidden Markov Model (HMM) based on symmetric lambda distribution\n    framework is implemented for the study of return time-series in the financial\n    market. Major features in the S&P500 index, such as regime identification,\n    volatility clustering, and anti-correlation between return and volatility,\n    can be extracted from HMM cleanly. Univariate symmetric lambda distribution\n    is essentially a location-scale family of exponential power distribution.\n    Such distribution is suitable for describing highly leptokurtic time series\n    obtained from the financial market. It provides a theoretically solid foundation\n    to explore such data where the normal distribution is not adequate. The HMM\n    implementation follows closely the book: \"Hidden Markov Models for Time Series\",\n    by Zucchini, MacDonald, Langrock (2016).",
    "version": "0.6.1",
    "maintainer": "Stephen H-T. Lihn <stevelihn@gmail.com>",
    "author": "Stephen H-T. Lihn [aut, cre]",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2979516\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=3435667",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ldhmm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ldhmm Hidden Markov Model for Financial Time-Series Based on Lambda\nDistribution Hidden Markov Model (HMM) based on symmetric lambda distribution\n    framework is implemented for the study of return time-series in the financial\n    market. Major features in the S&P500 index, such as regime identification,\n    volatility clustering, and anti-correlation between return and volatility,\n    can be extracted from HMM cleanly. Univariate symmetric lambda distribution\n    is essentially a location-scale family of exponential power distribution.\n    Such distribution is suitable for describing highly leptokurtic time series\n    obtained from the financial market. It provides a theoretically solid foundation\n    to explore such data where the normal distribution is not adequate. The HMM\n    implementation follows closely the book: \"Hidden Markov Models for Time Series\",\n    by Zucchini, MacDonald, Langrock (2016).  "
  },
  {
    "id": 15100,
    "package_name": "ldt",
    "title": "Automated Uncertainty Analysis",
    "description": "Methods and tools for model selection and multi-model inference (Burnham and Anderson (2002) <doi:10.1007/b97636>, among others). \n             'SUR' (for parameter estimation), 'logit'/'probit' (for binary classification), and 'VARMA' (for time-series forecasting) are implemented.\n             Evaluations are both in-sample and out-of-sample. \n             It is designed to be efficient in terms of CPU usage and memory consumption.",
    "version": "0.5.3",
    "maintainer": "Ramin Mojab <rmojab63@gmail.com>",
    "author": "Ramin Mojab [aut, cre],\n  Stephen Becker [cph] (BSD 3-clause license. Original code for L-BFGS-B\n    algorithm. The L-BFGS-B algorithm was written in the 1990s (mainly\n    1994, some revisions 1996) by Ciyou Zhu (in collaboration with R.H.\n    Byrd, P. Lu-Chen and J. Nocedal). L-BFGS-B Version 3.0 is an\n    algorithmic update from 2011, with coding changes by J. L. Morales)",
    "url": "https://github.com/rmojab63/LDT",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ldt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ldt Automated Uncertainty Analysis Methods and tools for model selection and multi-model inference (Burnham and Anderson (2002) <doi:10.1007/b97636>, among others). \n             'SUR' (for parameter estimation), 'logit'/'probit' (for binary classification), and 'VARMA' (for time-series forecasting) are implemented.\n             Evaluations are both in-sample and out-of-sample. \n             It is designed to be efficient in terms of CPU usage and memory consumption.  "
  },
  {
    "id": 15110,
    "package_name": "leaftime",
    "title": "'Leaflet-timeline' Plugin for Leaflet",
    "description": "Use the 'leaflet-timeline' plugin with a leaflet widget to add an\n    interactive slider with play, pause, and step buttons to explore temporal\n    geographic spatial data changes.",
    "version": "0.2.0",
    "maintainer": "Kent Russell <kent.russell@timelyportfolio.com>",
    "author": "Jonathan Skeate [aut] (leaflet-timeline library,\n    https://github.com/skeate/Leaflet.timeline),\n  Kent Russell [aut, cre] (R interface)",
    "url": "https://github.com/timelyportfolio/leaftime",
    "bug_reports": "https://github.com/timelyportfolio/leaftime/issues",
    "repository": "https://cran.r-project.org/package=leaftime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "leaftime 'Leaflet-timeline' Plugin for Leaflet Use the 'leaflet-timeline' plugin with a leaflet widget to add an\n    interactive slider with play, pause, and step buttons to explore temporal\n    geographic spatial data changes.  "
  },
  {
    "id": 15111,
    "package_name": "leakr",
    "title": "Data Leakage Detection Tools for Machine Learning",
    "description": "Provides utilities to detect common data leakage patterns including train/test\n           contamination, temporal leakage, and data duplication, enhancing model reliability and\n           reproducibility in machine learning workflows. Generates diagnostic reports and visual\n           summaries to support data validation. Methods based on best practices from Hastie,\n           Tibshirani, and Friedman (2009, ISBN:978-0387848570).",
    "version": "0.1.0",
    "maintainer": "Cheryl Isabella Lim <cheryl.academic@gmail.com>",
    "author": "Cheryl Isabella Lim [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=leakr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "leakr Data Leakage Detection Tools for Machine Learning Provides utilities to detect common data leakage patterns including train/test\n           contamination, temporal leakage, and data duplication, enhancing model reliability and\n           reproducibility in machine learning workflows. Generates diagnostic reports and visual\n           summaries to support data validation. Methods based on best practices from Hastie,\n           Tibshirani, and Friedman (2009, ISBN:978-0387848570).  "
  },
  {
    "id": 15127,
    "package_name": "legion",
    "title": "Forecasting Using Multivariate Models",
    "description": "Functions implementing multivariate state space models for purposes of time series analysis and forecasting.\n             The focus of the package is on multivariate models, such as Vector Exponential Smoothing,\n             Vector ETS (Error-Trend-Seasonal model) etc. It currently includes Vector Exponential\n             Smoothing (VES, de Silva et al., 2010, <doi:10.1177/1471082X0901000401>), Vector ETS (Svetunkov et al., 2023,\n             <doi:10.1016/j.ejor.2022.04.040>) and simulation function for VES.",
    "version": "0.2.1",
    "maintainer": "Ivan Svetunkov <ivan@svetunkov.com>",
    "author": "Ivan Svetunkov [aut, cre] (Senior Lecturer, Centre for Marketing\n    Analytics and Forecasting, Lancaster University, UK),\n  Kandrika Fadhlan Pritularga [aut] (Lecturer, Centre for Marketing\n    Analytics and Forecasting, Lancaster University, UK)",
    "url": "https://github.com/config-i1/legion",
    "bug_reports": "https://github.com/config-i1/legion/issues",
    "repository": "https://cran.r-project.org/package=legion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "legion Forecasting Using Multivariate Models Functions implementing multivariate state space models for purposes of time series analysis and forecasting.\n             The focus of the package is on multivariate models, such as Vector Exponential Smoothing,\n             Vector ETS (Error-Trend-Seasonal model) etc. It currently includes Vector Exponential\n             Smoothing (VES, de Silva et al., 2010, <doi:10.1177/1471082X0901000401>), Vector ETS (Svetunkov et al., 2023,\n             <doi:10.1016/j.ejor.2022.04.040>) and simulation function for VES.  "
  },
  {
    "id": 15162,
    "package_name": "lg",
    "title": "Locally Gaussian Distributions: Estimation and Methods",
    "description": "An implementation of locally Gaussian distributions. It provides methods for\n    implementing locally Gaussian multivariate density estimation, conditional density \n    estimation, various independence tests for iid and time series data, a test for conditional \n    independence and a test for financial contagion.",
    "version": "0.4.1",
    "maintainer": "H\u00e5kon Otneim <hakon.otneim@nhh.no>",
    "author": "H\u00e5kon Otneim [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lg Locally Gaussian Distributions: Estimation and Methods An implementation of locally Gaussian distributions. It provides methods for\n    implementing locally Gaussian multivariate density estimation, conditional density \n    estimation, various independence tests for iid and time series data, a test for conditional \n    independence and a test for financial contagion.  "
  },
  {
    "id": 15164,
    "package_name": "lgcp",
    "title": "Log-Gaussian Cox Process",
    "description": "Spatial and spatio-temporal modelling of point patterns using the\n    log-Gaussian Cox process. Bayesian inference for spatial, spatiotemporal,\n    multivariate and aggregated point processes using Markov chain Monte Carlo. See Benjamin M. Taylor, Tilman M. Davies, Barry S. Rowlingson, Peter J. Diggle (2015) <doi:10.18637/jss.v063.i07>.",
    "version": "2.0-1",
    "maintainer": "Benjamin M. Taylor <benjamin.taylor.software@gmail.com>",
    "author": "Benjamin M. Taylor [aut, cre],\n  Tilman M. Davies [aut],\n  Barry S. Rowlingson [aut],\n  Peter J. Diggle [aut],\n  Edzer Pebesma [ctb],\n  Dominic Schumacher. [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lgcp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lgcp Log-Gaussian Cox Process Spatial and spatio-temporal modelling of point patterns using the\n    log-Gaussian Cox process. Bayesian inference for spatial, spatiotemporal,\n    multivariate and aggregated point processes using Markov chain Monte Carlo. See Benjamin M. Taylor, Tilman M. Davies, Barry S. Rowlingson, Peter J. Diggle (2015) <doi:10.18637/jss.v063.i07>.  "
  },
  {
    "id": 15166,
    "package_name": "lgpr",
    "title": "Longitudinal Gaussian Process Regression",
    "description": "Interpretable nonparametric modeling of longitudinal data\n    using additive Gaussian process regression. Contains functionality\n    for inferring covariate effects and assessing covariate relevances.\n    Models are specified using a convenient formula syntax, and can include\n    shared, group-specific, non-stationary, heterogeneous and temporally\n    uncertain effects. Bayesian inference for model parameters is performed\n    using 'Stan'. The modeling approach and methods are described in detail in\n    Timonen et al. (2021) <doi:10.1093/bioinformatics/btab021>.",
    "version": "1.2.5",
    "maintainer": "Juho Timonen <juho.timonen@iki.fi>",
    "author": "Juho Timonen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2341-6765>),\n  Andrew Johnson [ctb]",
    "url": "https://github.com/jtimonen/lgpr",
    "bug_reports": "https://github.com/jtimonen/lgpr/issues",
    "repository": "https://cran.r-project.org/package=lgpr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lgpr Longitudinal Gaussian Process Regression Interpretable nonparametric modeling of longitudinal data\n    using additive Gaussian process regression. Contains functionality\n    for inferring covariate effects and assessing covariate relevances.\n    Models are specified using a convenient formula syntax, and can include\n    shared, group-specific, non-stationary, heterogeneous and temporally\n    uncertain effects. Bayesian inference for model parameters is performed\n    using 'Stan'. The modeling approach and methods are described in detail in\n    Timonen et al. (2021) <doi:10.1093/bioinformatics/btab021>.  "
  },
  {
    "id": 15192,
    "package_name": "liftLRD",
    "title": "Wavelet Lifting Estimators of the Hurst Exponent for Regularly\nand Irregularly Sampled Time Series",
    "description": "Implementations of Hurst exponent estimators based on the relationship between wavelet lifting scales and wavelet energy of Knight et al (2017) <doi:10.1007/s11222-016-9698-2>. ",
    "version": "1.0-9",
    "maintainer": "Matt Nunes <nunesrpackages@gmail.com>",
    "author": "Marina Knight [aut],\n  Guy Nason [ctb],\n  Matt Nunes [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=liftLRD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "liftLRD Wavelet Lifting Estimators of the Hurst Exponent for Regularly\nand Irregularly Sampled Time Series Implementations of Hurst exponent estimators based on the relationship between wavelet lifting scales and wavelet energy of Knight et al (2017) <doi:10.1007/s11222-016-9698-2>.   "
  },
  {
    "id": 15218,
    "package_name": "lineartestr",
    "title": "Linear Specification Testing",
    "description": "Tests whether the linear hypothesis of a model\n    is correct specified using Dominguez-Lobato test. Also Ramsey's RESET (Regression Equation \n    Specification Error Test) test is implemented and Wald tests can be carried out. \n    Although RESET test is widely used to \n    test the linear hypothesis of a model, Dominguez and Lobato (2019) proposed a novel \n    approach that generalizes well known specification tests such as Ramsey's. This test \n    relies on wild-bootstrap; this package implements this approach to be \n    usable with any function that fits linear models and is compatible with \n    the update() function such as 'stats'::lm(), 'lfe'::felm() and 'forecast'::Arima(), \n    for ARMA (autoregressive\u2013moving-average) models. \n    Also the package can handle custom statistics such as Cramer von Mises and Kolmogorov \n    Smirnov, described by the authors, and custom distributions such as Mammen (discrete \n    and continuous) and Rademacher.\n    Manuel A. Dominguez & Ignacio N. Lobato (2019) <doi:10.1080/07474938.2019.1687116>.",
    "version": "1.0.0",
    "maintainer": "Federico Garza <fede.garza.ramirez@gmail.com>",
    "author": "Federico Garza [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7015-8186>)",
    "url": "https://github.com/FedericoGarza/lineartestr",
    "bug_reports": "https://github.com/FedericoGarza/lineartestr/issues",
    "repository": "https://cran.r-project.org/package=lineartestr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lineartestr Linear Specification Testing Tests whether the linear hypothesis of a model\n    is correct specified using Dominguez-Lobato test. Also Ramsey's RESET (Regression Equation \n    Specification Error Test) test is implemented and Wald tests can be carried out. \n    Although RESET test is widely used to \n    test the linear hypothesis of a model, Dominguez and Lobato (2019) proposed a novel \n    approach that generalizes well known specification tests such as Ramsey's. This test \n    relies on wild-bootstrap; this package implements this approach to be \n    usable with any function that fits linear models and is compatible with \n    the update() function such as 'stats'::lm(), 'lfe'::felm() and 'forecast'::Arima(), \n    for ARMA (autoregressive\u2013moving-average) models. \n    Also the package can handle custom statistics such as Cramer von Mises and Kolmogorov \n    Smirnov, described by the authors, and custom distributions such as Mammen (discrete \n    and continuous) and Rademacher.\n    Manuel A. Dominguez & Ignacio N. Lobato (2019) <doi:10.1080/07474938.2019.1687116>.  "
  },
  {
    "id": 15224,
    "package_name": "linevis",
    "title": "Interactive Time Series Visualizations",
    "description": "Create interactive time series visualizations.\n    'linevis' includes an extensive API to manipulate time series after creation,\n    and supports getting data out of the visualization. Based on the\n    'timevis' package and the 'vis.js' Timeline 'JavaScript' library <https://visjs.github.io/vis-timeline/docs/graph2d/>.",
    "version": "1.0.0",
    "maintainer": "Thomas Charlon <charlon@protonmail.com>",
    "author": "Thomas Charlon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7497-0470>),\n  Dean Attali [aut, cph],\n  Almende B.V. [aut, cph] (vis.js Timeline library,\n    https://visjs.github.io/vis-timeline/docs/graph2d/)",
    "url": "https://gitlab.com/thomaschln/linevis",
    "bug_reports": "https://gitlab.com/thomaschln/linevis/-/issues",
    "repository": "https://cran.r-project.org/package=linevis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "linevis Interactive Time Series Visualizations Create interactive time series visualizations.\n    'linevis' includes an extensive API to manipulate time series after creation,\n    and supports getting data out of the visualization. Based on the\n    'timevis' package and the 'vis.js' Timeline 'JavaScript' library <https://visjs.github.io/vis-timeline/docs/graph2d/>.  "
  },
  {
    "id": 15242,
    "package_name": "lira",
    "title": "LInear Regression in Astronomy",
    "description": "Performs Bayesian linear regression and forecasting in astronomy. The method accounts for heteroscedastic errors in both the independent and the dependent variables, intrinsic scatters (in both variables) and scatter correlation, time evolution of slopes, normalization, scatters, Malmquist and Eddington bias, upper limits and break of linearity. The posterior distribution of the regression parameters is sampled with a Gibbs method exploiting the JAGS library.",
    "version": "2.0.1",
    "maintainer": "Mauro Sereno <mauro.sereno@unibo.it>",
    "author": "Mauro Sereno",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lira",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lira LInear Regression in Astronomy Performs Bayesian linear regression and forecasting in astronomy. The method accounts for heteroscedastic errors in both the independent and the dependent variables, intrinsic scatters (in both variables) and scatter correlation, time evolution of slopes, normalization, scatters, Malmquist and Eddington bias, upper limits and break of linearity. The posterior distribution of the regression parameters is sampled with a Gibbs method exploiting the JAGS library.  "
  },
  {
    "id": 15256,
    "package_name": "lite",
    "title": "Likelihood-Based Inference for Time Series Extremes",
    "description": "Performs likelihood-based inference for stationary time series \n    extremes.  The general approach follows Fawcett and Walshaw (2012)\n    <doi:10.1002/env.2133>.  Marginal extreme value inferences are adjusted for \n    cluster dependence in the data using the methodology in Chandler and Bate \n    (2007) <doi:10.1093/biomet/asm015>, producing an adjusted log-likelihood \n    for the model parameters.  A log-likelihood for the extremal index is \n    produced using the K-gaps model of Suveges and Davison (2010) \n    <doi:10.1214/09-AOAS292>. These log-likelihoods are combined to make \n    inferences about extreme values. Both maximum likelihood and Bayesian \n    approaches are available.",
    "version": "1.1.1",
    "maintainer": "Paul J. Northrop <p.northrop@ucl.ac.uk>",
    "author": "Paul J. Northrop [aut, cre, cph]",
    "url": "https://paulnorthrop.github.io/lite/,\nhttps://github.com/paulnorthrop/lite",
    "bug_reports": "https://github.com/paulnorthrop/lite/issues",
    "repository": "https://cran.r-project.org/package=lite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lite Likelihood-Based Inference for Time Series Extremes Performs likelihood-based inference for stationary time series \n    extremes.  The general approach follows Fawcett and Walshaw (2012)\n    <doi:10.1002/env.2133>.  Marginal extreme value inferences are adjusted for \n    cluster dependence in the data using the methodology in Chandler and Bate \n    (2007) <doi:10.1093/biomet/asm015>, producing an adjusted log-likelihood \n    for the model parameters.  A log-likelihood for the extremal index is \n    produced using the K-gaps model of Suveges and Davison (2010) \n    <doi:10.1214/09-AOAS292>. These log-likelihoods are combined to make \n    inferences about extreme values. Both maximum likelihood and Bayesian \n    approaches are available.  "
  },
  {
    "id": 15259,
    "package_name": "litteR",
    "title": "Litter Analysis",
    "description": "Data sets on various litter types like beach litter, riverain\n    litter, floating litter, and seafloor litter are rapidly growing. This \n    package offers a simple user interface to analyse these litter data in\n    a consistent and reproducible way. It also provides functions to \n    facilitate several kinds of litter analysis, e.g., trend analysis, \n    power analysis, and baseline analysis. Under the hood, these functions \n    are also used by the user interface. See Schulz et al. (2019)\n    <doi:10.1016/j.envpol.2019.02.030> for details. MS-Windows users are\n    advised to run 'litteR' in 'RStudio'. See our vignette: Installation manual \n    for 'RStudio' and 'litteR'.",
    "version": "1.0.2",
    "maintainer": "Dennis Walvoort <dennis.Walvoort@wur.nl>",
    "author": "Dennis Walvoort [aut, cre, cph],\n  Willem van Loon [aut, cph],\n  Rijkswaterstaat - The Netherlands [cph, fnd, dtc]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=litteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "litteR Litter Analysis Data sets on various litter types like beach litter, riverain\n    litter, floating litter, and seafloor litter are rapidly growing. This \n    package offers a simple user interface to analyse these litter data in\n    a consistent and reproducible way. It also provides functions to \n    facilitate several kinds of litter analysis, e.g., trend analysis, \n    power analysis, and baseline analysis. Under the hood, these functions \n    are also used by the user interface. See Schulz et al. (2019)\n    <doi:10.1016/j.envpol.2019.02.030> for details. MS-Windows users are\n    advised to run 'litteR' in 'RStudio'. See our vignette: Installation manual \n    for 'RStudio' and 'litteR'.  "
  },
  {
    "id": 15272,
    "package_name": "lmForc",
    "title": "Linear Model Forecasting",
    "description": "Introduces in-sample, out-of-sample, pseudo out-of-sample, and\n    benchmark model forecast tests and a new class for working with forecast data, Forecast.",
    "version": "1.0.0",
    "maintainer": "Nelson Rayl <nelsonrayl14@gmail.com>",
    "author": "Nelson Rayl [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lmForc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lmForc Linear Model Forecasting Introduces in-sample, out-of-sample, pseudo out-of-sample, and\n    benchmark model forecast tests and a new class for working with forecast data, Forecast.  "
  },
  {
    "id": 15296,
    "package_name": "lmomPi",
    "title": "(Precipitation) Frequency Analysis and Variability with\nL-Moments from 'lmom'",
    "description": "It is an extension of 'lmom' R package: 'pel...()','cdf...()',qua...()' function\n    families are lumped and called from one function per each family respectively in order to\n    create robust automatic tools to fit data  with different probability\n    distributions and then to estimate probability values and return periods.  The implemented functions are able to manage time series with constant and/or missing values without stopping\n    the execution with error messages. The package also contains tools to  calculate several  indices based on variability (e.g. 'SPI' , Standardized\n    Precipitation Index, see <https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi> and <http://spei.csic.es/>) for multiple time series or spatially gridded values. ",
    "version": "0.6.7",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lmomPi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lmomPi (Precipitation) Frequency Analysis and Variability with\nL-Moments from 'lmom' It is an extension of 'lmom' R package: 'pel...()','cdf...()',qua...()' function\n    families are lumped and called from one function per each family respectively in order to\n    create robust automatic tools to fit data  with different probability\n    distributions and then to estimate probability values and return periods.  The implemented functions are able to manage time series with constant and/or missing values without stopping\n    the execution with error messages. The package also contains tools to  calculate several  indices based on variability (e.g. 'SPI' , Standardized\n    Precipitation Index, see <https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi> and <http://spei.csic.es/>) for multiple time series or spatially gridded values.   "
  },
  {
    "id": 15311,
    "package_name": "loadshaper",
    "title": "Producing Load Shape with Target Peak and Load Factor",
    "description": "Modifying a load shape to match specific peak and \n  load factor is a fundamental component for various power system \n  planning and operation studies. This package is an efficient tool \n  to modify a reference load shape while matching the desired peak\n  and load factor. The package offers both linear and non-linear method,\n  described in <https://rpubs.com/riazakhan94/load_shape_match_peak_energy>. \n  The user can control the shape of the final load shape by regulating \n  certain parameters. The package provides validation metrics for \n  assessing the derived load shape in terms of preserving time series \n  properties. It also offers powerful graphics, that allows the user to\n  visually assess the derived load shape.",
    "version": "1.1.1",
    "maintainer": "Md Riaz Ahmed Khan <mdriazahmed.khan@jacks.sdstate.edu>",
    "author": "Md Riaz Ahmed Khan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=loadshaper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "loadshaper Producing Load Shape with Target Peak and Load Factor Modifying a load shape to match specific peak and \n  load factor is a fundamental component for various power system \n  planning and operation studies. This package is an efficient tool \n  to modify a reference load shape while matching the desired peak\n  and load factor. The package offers both linear and non-linear method,\n  described in <https://rpubs.com/riazakhan94/load_shape_match_peak_energy>. \n  The user can control the shape of the final load shape by regulating \n  certain parameters. The package provides validation metrics for \n  assessing the derived load shape in terms of preserving time series \n  properties. It also offers powerful graphics, that allows the user to\n  visually assess the derived load shape.  "
  },
  {
    "id": 15328,
    "package_name": "locits",
    "title": "Test of Stationarity and Localized Autocovariance",
    "description": "Provides test of second-order stationarity for time\n\tseries (for dyadic and arbitrary-n length data). Provides\n\tlocalized autocovariance, with confidence intervals,\n\tfor locally stationary (nonstationary) time series.\n\tSee Nason, G P (2013) \"A test for second-order stationarity and\n\tapproximate confidence intervals for localized autocovariance\n\tfor locally stationary time series.\" Journal of the Royal Statistical\n\tSociety, Series B, 75, 879-904.  <doi:10.1111/rssb.12015>.",
    "version": "1.7.8",
    "maintainer": "Guy Nason <g.nason@imperial.ac.uk>",
    "author": "Guy Nason [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=locits",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "locits Test of Stationarity and Localized Autocovariance Provides test of second-order stationarity for time\n\tseries (for dyadic and arbitrary-n length data). Provides\n\tlocalized autocovariance, with confidence intervals,\n\tfor locally stationary (nonstationary) time series.\n\tSee Nason, G P (2013) \"A test for second-order stationarity and\n\tapproximate confidence intervals for localized autocovariance\n\tfor locally stationary time series.\" Journal of the Royal Statistical\n\tSociety, Series B, 75, 879-904.  <doi:10.1111/rssb.12015>.  "
  },
  {
    "id": 15373,
    "package_name": "lomb",
    "title": "Lomb-Scargle Periodogram",
    "description": "Computes the Lomb-Scargle Periodogram and actogram for evenly or unevenly sampled time series. Includes a randomization procedure to obtain exact p-values. Partially based on C original by Press et al. (Numerical Recipes) and the Python module Astropy. For more information see Ruf, T. (1999). The Lomb-Scargle periodogram in biological rhythm research: analysis of incomplete and unequally spaced time-series. Biological Rhythm Research, 30(2), 178-201.",
    "version": "2.5.0",
    "maintainer": "Thomas Ruf <Thomas.P.Ruf@me.com>",
    "author": "Thomas Ruf [aut, cre] (ORCID: <https://orcid.org/0000-0002-9235-7079>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lomb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lomb Lomb-Scargle Periodogram Computes the Lomb-Scargle Periodogram and actogram for evenly or unevenly sampled time series. Includes a randomization procedure to obtain exact p-values. Partially based on C original by Press et al. (Numerical Recipes) and the Python module Astropy. For more information see Ruf, T. (1999). The Lomb-Scargle periodogram in biological rhythm research: analysis of incomplete and unequally spaced time-series. Biological Rhythm Research, 30(2), 178-201.  "
  },
  {
    "id": 15385,
    "package_name": "longmemo",
    "title": "Statistics for Long-Memory Processes (Book Jan Beran), and\nRelated Functionality",
    "description": "Datasets and Functionality from\n  'Jan Beran' (1994). Statistics for Long-Memory Processes; Chapman & Hall.\n  Estimation of Hurst (and more) parameters for fractional Gaussian noise,\n  'fARIMA' and 'FEXP' models.",
    "version": "1.1-4",
    "maintainer": "Martin Maechler <maechler@stat.math.ethz.ch>",
    "author": "Jan Beran [aut] (original S functions and scripts),\n  Martin Maechler [cre, aut] (Toplevel R functions and much more, ORCID:\n    <https://orcid.org/0000-0002-8685-9910>),\n  Brandon Whitcher [ctb] (Datasets)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=longmemo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "longmemo Statistics for Long-Memory Processes (Book Jan Beran), and\nRelated Functionality Datasets and Functionality from\n  'Jan Beran' (1994). Statistics for Long-Memory Processes; Chapman & Hall.\n  Estimation of Hurst (and more) parameters for fractional Gaussian noise,\n  'fARIMA' and 'FEXP' models.  "
  },
  {
    "id": 15412,
    "package_name": "lpacf",
    "title": "Local Partial Autocorrelation Function Estimation for Locally\nStationary Wavelet Processes",
    "description": "Provides the method for computing the local partial autocorrelation function for locally stationary wavelet time series from Killick, Knight, Nason, Eckley (2020) <doi:10.1214/20-EJS1748>.",
    "version": "1.0.2",
    "maintainer": "Rebecca Killick <r.killick@lancs.ac.uk>",
    "author": "Rebecca Killick [aut, cre],\n  Guy Nason [aut],\n  Marina Knight [aut],\n  Matt Nunes [aut],\n  Idris Eckley [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lpacf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lpacf Local Partial Autocorrelation Function Estimation for Locally\nStationary Wavelet Processes Provides the method for computing the local partial autocorrelation function for locally stationary wavelet time series from Killick, Knight, Nason, Eckley (2020) <doi:10.1214/20-EJS1748>.  "
  },
  {
    "id": 15452,
    "package_name": "ltsa",
    "title": "Linear Time Series Analysis",
    "description": "Methods of developing linear time series modelling.\n Methods are given for loglikelihood computation, forecasting\n  and simulation.",
    "version": "1.4.6.1",
    "maintainer": "A.I. McLeod <aimcleod@uwo.ca>",
    "author": "A.I. McLeod [aut, cre],\n  Hao Yu [aut],\n  Zinovi Krougly [aut]",
    "url": "http://www.stats.uwo.ca/faculty/aim",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ltsa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ltsa Linear Time Series Analysis Methods of developing linear time series modelling.\n Methods are given for loglikelihood computation, forecasting\n  and simulation.  "
  },
  {
    "id": 15453,
    "package_name": "ltsk",
    "title": "Local Time Space Kriging",
    "description": "Implements local spatial and local spatiotemporal Kriging based on local spatial and local spatiotemporal variograms, respectively. The method is documented in Kumar et al (2013) <https://www.nature.com/articles/jes201352)>.",
    "version": "1.1.2",
    "maintainer": "Dong Liang <dliang@umces.edu>",
    "author": "Naresh Kumar, Dong Liang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ltsk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ltsk Local Time Space Kriging Implements local spatial and local spatiotemporal Kriging based on local spatial and local spatiotemporal variograms, respectively. The method is documented in Kumar et al (2013) <https://www.nature.com/articles/jes201352)>.  "
  },
  {
    "id": 15455,
    "package_name": "ltxsparklines",
    "title": "Lightweight Sparklines for a LaTeX Document",
    "description": "Sparklines are small plots (about one line of text high),\n  made popular by Edward Tufte.  This package is the interface from R\n  to the LaTeX package sparklines by Andreas Loeffer and Dan Luecking\n  (<http://www.ctan.org/pkg/sparklines>).  It can work with Sweave or\n  knitr or other engines that produce TeX.  The package can be used to\n  plot vectors, matrices, data frames, time series (in ts or zoo format).",
    "version": "1.1.3",
    "maintainer": "Boris Veytsman <borisv@lk.net>",
    "author": "Boris Veytsman [aut, cre]",
    "url": "https://github.com/borisveytsman/ltxsparklines",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ltxsparklines",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ltxsparklines Lightweight Sparklines for a LaTeX Document Sparklines are small plots (about one line of text high),\n  made popular by Edward Tufte.  This package is the interface from R\n  to the LaTeX package sparklines by Andreas Loeffer and Dan Luecking\n  (<http://www.ctan.org/pkg/sparklines>).  It can work with Sweave or\n  knitr or other engines that produce TeX.  The package can be used to\n  plot vectors, matrices, data frames, time series (in ts or zoo format).  "
  },
  {
    "id": 15477,
    "package_name": "m2b",
    "title": "Movement to Behaviour Inference using Random Forest",
    "description": "Prediction of behaviour from movement \n\tcharacteristics using observation and random forest for the analyses of movement\n\tdata in ecology.\n\tFrom movement information (speed, bearing...) the model predicts the\n\tobserved behaviour (movement, foraging...) using random forest. The\n\tmodel can then extrapolate behavioural information to movement data\n\twithout direct observation of behaviours.\n\tThe specificity of this method relies on the derivation of multiple predictor variables from the\n\tmovement data over a range of temporal windows. This procedure allows to capture\n\tas much information as possible on the changes and variations of movement and\n\tensures the use of the random forest algorithm to its best capacity. The method\n\tis very generic, applicable to any set of data providing movement data together with\n\tobservation of behaviour.",
    "version": "1.1.0",
    "maintainer": "Laurent Dubroca <laurent.dubroca@gmail.com>",
    "author": "Laurent Dubroca [aut, cre],\n  Andr\u00e9a Thiebault [aut]",
    "url": "https://github.com/ldbk/m2b",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=m2b",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "m2b Movement to Behaviour Inference using Random Forest Prediction of behaviour from movement \n\tcharacteristics using observation and random forest for the analyses of movement\n\tdata in ecology.\n\tFrom movement information (speed, bearing...) the model predicts the\n\tobserved behaviour (movement, foraging...) using random forest. The\n\tmodel can then extrapolate behavioural information to movement data\n\twithout direct observation of behaviours.\n\tThe specificity of this method relies on the derivation of multiple predictor variables from the\n\tmovement data over a range of temporal windows. This procedure allows to capture\n\tas much information as possible on the changes and variations of movement and\n\tensures the use of the random forest algorithm to its best capacity. The method\n\tis very generic, applicable to any set of data providing movement data together with\n\tobservation of behaviour.  "
  },
  {
    "id": 15486,
    "package_name": "mFLICA",
    "title": "Leadership-Inference Framework for Multivariate Time Series",
    "description": "A leadership-inference framework for multivariate time series. The framework for multiple-faction-leadership inference from coordinated activities or 'mFLICA' uses a notion of a leader as an individual who initiates collective patterns that everyone in a group follows. Given a set of time series of individual activities, our goal is to identify periods of coordinated activity, find factions of coordination if more than one exist, as well as identify leaders of each faction. For each time step, the framework infers following relations between individual time series, then identifying a leader of each faction whom many individuals follow but it follows no one. A faction is defined as a group of individuals that everyone follows the same leader. 'mFLICA' reports following relations, leaders of factions, and members of each faction for each time step. Please see Chainarong Amornbunchornvej and Tanya Berger-Wolf (2018) <doi:10.1137/1.9781611975321.62> for methodology and Chainarong Amornbunchornvej (2021) <doi:10.1016/j.softx.2021.100781> for software when referring to this package in publications.",
    "version": "0.1.7",
    "maintainer": "Chainarong Amornbunchornvej <grandca@gmail.com>",
    "author": "Chainarong Amornbunchornvej [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3131-0370>),\n  Namrata Banerji [ctb]",
    "url": "https://github.com/DarkEyes/mFLICA",
    "bug_reports": "https://github.com/DarkEyes/mFLICA/issues",
    "repository": "https://cran.r-project.org/package=mFLICA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mFLICA Leadership-Inference Framework for Multivariate Time Series A leadership-inference framework for multivariate time series. The framework for multiple-faction-leadership inference from coordinated activities or 'mFLICA' uses a notion of a leader as an individual who initiates collective patterns that everyone in a group follows. Given a set of time series of individual activities, our goal is to identify periods of coordinated activity, find factions of coordination if more than one exist, as well as identify leaders of each faction. For each time step, the framework infers following relations between individual time series, then identifying a leader of each faction whom many individuals follow but it follows no one. A faction is defined as a group of individuals that everyone follows the same leader. 'mFLICA' reports following relations, leaders of factions, and members of each faction for each time step. Please see Chainarong Amornbunchornvej and Tanya Berger-Wolf (2018) <doi:10.1137/1.9781611975321.62> for methodology and Chainarong Amornbunchornvej (2021) <doi:10.1016/j.softx.2021.100781> for software when referring to this package in publications.  "
  },
  {
    "id": 15487,
    "package_name": "mFilter",
    "title": "Miscellaneous Time Series Filters",
    "description": "The mFilter package implements several time series filters useful\n        for smoothing and extracting trend and cyclical components of a\n        time series. The routines are commonly used in economics and\n        finance, however they should also be interest to other areas.\n        Currently, Christiano-Fitzgerald, Baxter-King,\n        Hodrick-Prescott, Butterworth, and trigonometric regression\n        filters are included in the package.",
    "version": "0.1-5",
    "maintainer": "Mehmet Balcilar <mehmet@mbalcilar.net>",
    "author": "Mehmet Balcilar <mehmet@mbalcilar.net>",
    "url": "http://www.mbalcilar.net",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mFilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mFilter Miscellaneous Time Series Filters The mFilter package implements several time series filters useful\n        for smoothing and extracting trend and cyclical components of a\n        time series. The routines are commonly used in economics and\n        finance, however they should also be interest to other areas.\n        Currently, Christiano-Fitzgerald, Baxter-King,\n        Hodrick-Prescott, Butterworth, and trigonometric regression\n        filters are included in the package.  "
  },
  {
    "id": 15492,
    "package_name": "mMARCH.AC",
    "title": "Processing of Accelerometry Data with 'GGIR' in mMARCH",
    "description": "Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.",
    "version": "3.2.0.1",
    "maintainer": "Wei Guo <wei.guo3@nih.gov>",
    "author": "Wei Guo [aut, cre],\n  Andrew Leroux [aut],\n  Vadim Zipunnikov [aut],\n  Kathleen Merikangas [aut]",
    "url": "https://github.com/WeiGuoNIMH/mMARCH.AC",
    "bug_reports": "https://github.com/WeiGuoNIMH/mMARCH.AC/issues",
    "repository": "https://cran.r-project.org/package=mMARCH.AC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mMARCH.AC Processing of Accelerometry Data with 'GGIR' in mMARCH Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.  "
  },
  {
    "id": 15509,
    "package_name": "macroBiome",
    "title": "A Tool for Mapping the Distribution of the Biomes and Bioclimate",
    "description": "Procedures for simulating biomes by equilibrium vegetation \n  models, with a special focus on paleoenvironmental applications.\n  Three widely used equilibrium biome models are currently implemented in \n  the package: the Holdridge Life Zone (HLZ) system (Holdridge 1947, \n  <doi:10.1126/science.105.2727.367>), the K\u00f6ppen-Geiger classification \n  (KGC) system (K\u00f6ppen 1936, \n  <https://koeppen-geiger.vu-wien.ac.at/pdf/Koppen_1936.pdf>) and the \n  BIOME model (Prentice et al. 1992, <doi:10.2307/2845499>). Three \n  climatic forest-steppe models are also implemented.\n  An approach for estimating monthly time series of relative sunshine \n  duration from temperature and precipitation data (Yin 1999, \n  <doi:10.1007/s007040050111>) is also adapted, allowing \n  process-based biome models to be combined with high-resolution \n  paleoclimate simulation datasets (e.g., CHELSA-TraCE21k v1.0 dataset: \n  <https://chelsa-climate.org/chelsa-trace21k/>).",
    "version": "0.4.0",
    "maintainer": "Zolt\u00e1n Szelepcs\u00e9nyi <szelepcsenyi.zoltan@gmail.com>",
    "author": "Zolt\u00e1n Szelepcs\u00e9nyi [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9844-4958>)",
    "url": "https://github.com/szelepcsenyi/macroBiome",
    "bug_reports": "https://github.com/szelepcsenyi/macroBiome/issues/",
    "repository": "https://cran.r-project.org/package=macroBiome",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "macroBiome A Tool for Mapping the Distribution of the Biomes and Bioclimate Procedures for simulating biomes by equilibrium vegetation \n  models, with a special focus on paleoenvironmental applications.\n  Three widely used equilibrium biome models are currently implemented in \n  the package: the Holdridge Life Zone (HLZ) system (Holdridge 1947, \n  <doi:10.1126/science.105.2727.367>), the K\u00f6ppen-Geiger classification \n  (KGC) system (K\u00f6ppen 1936, \n  <https://koeppen-geiger.vu-wien.ac.at/pdf/Koppen_1936.pdf>) and the \n  BIOME model (Prentice et al. 1992, <doi:10.2307/2845499>). Three \n  climatic forest-steppe models are also implemented.\n  An approach for estimating monthly time series of relative sunshine \n  duration from temperature and precipitation data (Yin 1999, \n  <doi:10.1007/s007040050111>) is also adapted, allowing \n  process-based biome models to be combined with high-resolution \n  paleoclimate simulation datasets (e.g., CHELSA-TraCE21k v1.0 dataset: \n  <https://chelsa-climate.org/chelsa-trace21k/>).  "
  },
  {
    "id": 15510,
    "package_name": "macrocol",
    "title": "Colombian Macro-Financial Time Series Generator",
    "description": "This repository aims to contribute to the econometric models' production\n\twith Colombian data, by providing a set of web-scrapping functions \n\tof some of the main macro-financial indicators. All the sources are public and\n\tfree, but the advantage of these functions is that they directly download \n\tand harmonize the information in R's environment. No need to import or download\n\tadditional files. You only need an internet connection!",
    "version": "0.1.0",
    "maintainer": "Pedro Alejandro Cabra-Acela <jando2797@gmail.com>",
    "author": "Pedro Alejandro Cabra-Acela [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4788-5910>)",
    "url": "<https://github.com/pedroCabraAcela/Scrapping-Colombian-Macrodata>",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=macrocol",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "macrocol Colombian Macro-Financial Time Series Generator This repository aims to contribute to the econometric models' production\n\twith Colombian data, by providing a set of web-scrapping functions \n\tof some of the main macro-financial indicators. All the sources are public and\n\tfree, but the advantage of these functions is that they directly download \n\tand harmonize the information in R's environment. No need to import or download\n\tadditional files. You only need an internet connection!  "
  },
  {
    "id": 15524,
    "package_name": "magclass",
    "title": "Data Class and Tools for Handling Spatial-Temporal Data",
    "description": "Data class for increased interoperability working with\n    spatial-temporal data together with corresponding functions and\n    methods (conversions, basic calculations and basic data manipulation).\n    The class distinguishes between spatial, temporal and other dimensions\n    to facilitate the development and interoperability of tools build for\n    it. Additional features are name-based addressing of data and internal\n    consistency checks (e.g. checking for the right data order in\n    calculations).",
    "version": "6.13.2",
    "maintainer": "Jan Philipp Dietrich <dietrich@pik-potsdam.de>",
    "author": "Jan Philipp Dietrich [aut, cre],\n  Benjamin Leon Bodirsky [aut],\n  Markus Bonsch [aut],\n  Florian Humpenoeder [aut],\n  Stephen Bi [aut],\n  Kristine Karstens [aut],\n  Debbora Leip [aut],\n  Pascal Sauer [aut],\n  Lavinia Baumstark [ctb],\n  Christoph Bertram [ctb],\n  Anastasis Giannousakis [ctb],\n  David Klein [ctb],\n  Ina Neher [ctb],\n  Michaja Pehl [ctb],\n  Anselm Schultes [ctb],\n  Miodrag Stevanovic [ctb],\n  Xiaoxi Wang [ctb],\n  Felicitas Beier [ctb],\n  Mika Pfl\u00fcger [ctb],\n  Oliver Richters [ctb]",
    "url": "https://github.com/pik-piam/magclass,\nhttps://doi.org/10.5281/zenodo.1158580",
    "bug_reports": "https://github.com/pik-piam/magclass/issues",
    "repository": "https://cran.r-project.org/package=magclass",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "magclass Data Class and Tools for Handling Spatial-Temporal Data Data class for increased interoperability working with\n    spatial-temporal data together with corresponding functions and\n    methods (conversions, basic calculations and basic data manipulation).\n    The class distinguishes between spatial, temporal and other dimensions\n    to facilitate the development and interoperability of tools build for\n    it. Additional features are name-based addressing of data and internal\n    consistency checks (e.g. checking for the right data order in\n    calculations).  "
  },
  {
    "id": 15596,
    "package_name": "mappestRisk",
    "title": "Create Maps Forecasting Risk of Pest Occurrence",
    "description": "There are three different modules: (1) model fitting and selection \n    using a set of the most commonly used equations describing developmental \n    responses to temperature helped by already existing R packages ('rTPC') \n    and nonlinear regression model functions from 'nls.multstart' \n    (Padfield et al. 2021, <doi:10.1111/2041-210X.13585>), with visualization \n    of model predictions to guide ecological criteria for model selection; \n    (2) calculation of suitability thermal limits, which consist on a \n    temperature interval delimiting the optimal performance zone or suitability; \n    and (3) climatic data extraction and visualization inspired on previous \n    research (Taylor et al. 2019, <doi:10.1111/1365-2664.13455>), with either \n    exportable rasters, static map images or html, interactive maps.",
    "version": "0.1.2",
    "maintainer": "Dar\u00edo San-Segundo Molina <dario.ssm2@gmail.com>",
    "author": "Dar\u00edo San-Segundo Molina [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7831-9623>),\n  A. M\u00e1rcia Barbosa [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-8972-7713>),\n  Antonio Jes\u00fas P\u00e9rez-Luque [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-1747-0469>),\n  Francisco Rodr\u00edguez-S\u00e1nchez [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7981-1599>)",
    "url": "https://github.com/EcologyR/mappestRisk,\nhttps://ecologyr.github.io/mappestRisk/",
    "bug_reports": "https://github.com/EcologyR/mappestRisk/issues",
    "repository": "https://cran.r-project.org/package=mappestRisk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mappestRisk Create Maps Forecasting Risk of Pest Occurrence There are three different modules: (1) model fitting and selection \n    using a set of the most commonly used equations describing developmental \n    responses to temperature helped by already existing R packages ('rTPC') \n    and nonlinear regression model functions from 'nls.multstart' \n    (Padfield et al. 2021, <doi:10.1111/2041-210X.13585>), with visualization \n    of model predictions to guide ecological criteria for model selection; \n    (2) calculation of suitability thermal limits, which consist on a \n    temperature interval delimiting the optimal performance zone or suitability; \n    and (3) climatic data extraction and visualization inspired on previous \n    research (Taylor et al. 2019, <doi:10.1111/1365-2664.13455>), with either \n    exportable rasters, static map images or html, interactive maps.  "
  },
  {
    "id": 15622,
    "package_name": "marima",
    "title": "Multivariate ARIMA and ARIMA-X Analysis",
    "description": "Multivariate ARIMA and ARIMA-X estimation using Spliid's \n    algorithm (marima()) and simulation (marima.sim()).",
    "version": "2.2",
    "maintainer": "Henrik Spliid <hspl@dtu.dk>",
    "author": "Henrik Spliid",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=marima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "marima Multivariate ARIMA and ARIMA-X Analysis Multivariate ARIMA and ARIMA-X estimation using Spliid's \n    algorithm (marima()) and simulation (marima.sim()).  "
  },
  {
    "id": 15648,
    "package_name": "mastif",
    "title": "Mast Inference and Forecasting",
    "description": "Analyzes production and dispersal of seeds dispersed from trees and recovered in seed traps.  Motivated by long-term inventory plots where seed collections are used to infer seed production by each individual plant. ",
    "version": "2.3",
    "maintainer": "James S. Clark <jimclark@duke.edu>",
    "author": "James S. Clark",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mastif",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mastif Mast Inference and Forecasting Analyzes production and dispersal of seeds dispersed from trees and recovered in seed traps.  Motivated by long-term inventory plots where seed collections are used to infer seed production by each individual plant.   "
  },
  {
    "id": 15659,
    "package_name": "mateable",
    "title": "Assess Mating Potential in Space and Time",
    "description": "Simulate, manage, visualize, and analyze spatially and temporally \n    explicit datasets of mating potential. Implements methods to calculate \n    synchrony, proximity, and compatibility.Synchrony calculations are based on \n    methods described in Augspurger (1983) <doi:10.2307/2387650>, \n    Kempenaers (1993) <doi:10.2307/3676415>, Ison et al. (2014) \n    <doi:10.3732/ajb.1300065>, and variations on these, as described.",
    "version": "0.3.3",
    "maintainer": "Stuart Wagenius <stuart.wagenius@gmail.com>",
    "author": "Stuart Wagenius [cre, aut],\n  Danny Hanson [aut],\n  Amy Waananen [aut]",
    "url": "https://github.com/stuartWagenius/mateable",
    "bug_reports": "https://github.com/stuartWagenius/mateable/issues",
    "repository": "https://cran.r-project.org/package=mateable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mateable Assess Mating Potential in Space and Time Simulate, manage, visualize, and analyze spatially and temporally \n    explicit datasets of mating potential. Implements methods to calculate \n    synchrony, proximity, and compatibility.Synchrony calculations are based on \n    methods described in Augspurger (1983) <doi:10.2307/2387650>, \n    Kempenaers (1993) <doi:10.2307/3676415>, Ison et al. (2014) \n    <doi:10.3732/ajb.1300065>, and variations on these, as described.  "
  },
  {
    "id": 15669,
    "package_name": "matman",
    "title": "Material Management",
    "description": "A set of functions, classes and methods for performing ABC and ABC/XYZ analyses, identifying overperforming, underperforming and constantly performing items, and plotting, analyzing as well as predicting the temporal development of items.",
    "version": "1.1.3",
    "maintainer": "Leon Binder <leon.binder@th-deg.de>",
    "author": "Leon Binder [cre, aut],\n  Bernhard Bauer [aut],\n  Michael Scholz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=matman",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "matman Material Management A set of functions, classes and methods for performing ABC and ABC/XYZ analyses, identifying overperforming, underperforming and constantly performing items, and plotting, analyzing as well as predicting the temporal development of items.  "
  },
  {
    "id": 15673,
    "package_name": "matrisk",
    "title": "Macroeconomic-at-Risk",
    "description": "The Macroeconomics-at-Risk (MaR) approach is based on a two-step semi-parametric estimation procedure that allows to forecast the full conditional distribution of an economic variable at a given horizon, as a function of a set of factors. These density forecasts are then be used to produce coherent forecasts for any downside risk measure, e.g., value-at-risk, expected shortfall, downside entropy. Initially introduced by Adrian et al. (2019) <doi:10.1257/aer.20161923> to reveal the vulnerability of economic growth to financial conditions, the MaR approach is currently extensively used by international financial institutions to provide Value-at-Risk (VaR) type forecasts for GDP growth (Growth-at-Risk) or inflation (Inflation-at-Risk). This package provides methods for estimating these models. Datasets for the US and the Eurozone are available to allow testing of the Adrian et al (2019) model. This package constitutes a useful toolbox (data and functions) for private practitioners, scholars as well as policymakers.",
    "version": "0.1.0",
    "maintainer": "Quentin Lajaunie <quentin_lajaunie@hotmail.fr>",
    "author": "Quentin Lajaunie [aut, cre],\n  Guillaume Flament [aut],\n  Christophe Hurlin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=matrisk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "matrisk Macroeconomic-at-Risk The Macroeconomics-at-Risk (MaR) approach is based on a two-step semi-parametric estimation procedure that allows to forecast the full conditional distribution of an economic variable at a given horizon, as a function of a set of factors. These density forecasts are then be used to produce coherent forecasts for any downside risk measure, e.g., value-at-risk, expected shortfall, downside entropy. Initially introduced by Adrian et al. (2019) <doi:10.1257/aer.20161923> to reveal the vulnerability of economic growth to financial conditions, the MaR approach is currently extensively used by international financial institutions to provide Value-at-Risk (VaR) type forecasts for GDP growth (Growth-at-Risk) or inflation (Inflation-at-Risk). This package provides methods for estimating these models. Datasets for the US and the Eurozone are available to allow testing of the Adrian et al (2019) model. This package constitutes a useful toolbox (data and functions) for private practitioners, scholars as well as policymakers.  "
  },
  {
    "id": 15677,
    "package_name": "matrixProfile",
    "title": "Matrix Profile",
    "description": "A simple and the early stage package for matrix profile based on the paper of Chin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh (2016) <DOI:10.1109/ICDM.2016.0179>. This package calculates all-pairs-similarity for a given window size for time series data.",
    "version": "0.5.0",
    "maintainer": "Donghwan Kim <donhkim9714@korea.ac.kr>",
    "author": "Donghwan Kim",
    "url": "https://github.com/ainsuotain/matrixprofile",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=matrixProfile",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "matrixProfile Matrix Profile A simple and the early stage package for matrix profile based on the paper of Chin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh (2016) <DOI:10.1109/ICDM.2016.0179>. This package calculates all-pairs-similarity for a given window size for time series data.  "
  },
  {
    "id": 15697,
    "package_name": "maxbootR",
    "title": "Efficient Bootstrap Methods for Block Maxima",
    "description": "Implements state-of-the-art block bootstrap methods for extreme value \n  statistics based on block maxima. Includes disjoint blocks, sliding blocks, \n  relying on a circular transformation of blocks. \n  Fast C++ backends (via 'Rcpp') ensure scalability for large time series.",
    "version": "1.0.0",
    "maintainer": "Torben Staud <torben.staud@gmail.com>",
    "author": "Torben Staud [aut, cre, cph]",
    "url": "https://torbenstaud.github.io/maxbootR/,\nhttps://github.com/torbenstaud/maxbootR",
    "bug_reports": "https://github.com/torbenstaud/maxbootR/issues",
    "repository": "https://cran.r-project.org/package=maxbootR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "maxbootR Efficient Bootstrap Methods for Block Maxima Implements state-of-the-art block bootstrap methods for extreme value \n  statistics based on block maxima. Includes disjoint blocks, sliding blocks, \n  relying on a circular transformation of blocks. \n  Fast C++ backends (via 'Rcpp') ensure scalability for large time series.  "
  },
  {
    "id": 15725,
    "package_name": "mbsts",
    "title": "Multivariate Bayesian Structural Time Series",
    "description": "Tools for data analysis with multivariate Bayesian structural time series (MBSTS) models.  Specifically, the package provides facilities for implementing general structural time series models, flexibly adding on different time series components (trend, season, cycle, and regression), simulating them, fitting them to multivariate correlated time series data, conducting feature selection on the regression component.",
    "version": "3.0",
    "maintainer": "Ning Ning <patricianing@gmail.com>",
    "author": "Jinwen Qiu <qjwsnow_ctw@hotmail.com>, Ning Ning <patricianing@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mbsts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mbsts Multivariate Bayesian Structural Time Series Tools for data analysis with multivariate Bayesian structural time series (MBSTS) models.  Specifically, the package provides facilities for implementing general structural time series models, flexibly adding on different time series components (trend, season, cycle, and regression), simulating them, fitting them to multivariate correlated time series data, conducting feature selection on the regression component.  "
  },
  {
    "id": 15745,
    "package_name": "mcgf",
    "title": "Markov Chain Gaussian Fields Simulation and Parameter Estimation",
    "description": "Simulating and estimating (regime-switching) Markov chain Gaussian \n    fields with covariance functions of the Gneiting class (Gneiting 2002) \n    <doi:10.1198/016214502760047113>. It supports parameter estimation by \n    weighted least squares and maximum likelihood methods, and produces Kriging \n    forecasts and intervals for existing and new locations.",
    "version": "1.1.1",
    "maintainer": "Tianxia Jia <tianxia.jia@ucalgary.ca>",
    "author": "Tianxia Jia [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5430-5019>)",
    "url": "https://github.com/tianxia-jia/mcgf,\nhttps://tianxia-jia.github.io/mcgf/",
    "bug_reports": "https://github.com/tianxia-jia/mcgf/issues",
    "repository": "https://cran.r-project.org/package=mcgf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcgf Markov Chain Gaussian Fields Simulation and Parameter Estimation Simulating and estimating (regime-switching) Markov chain Gaussian \n    fields with covariance functions of the Gneiting class (Gneiting 2002) \n    <doi:10.1198/016214502760047113>. It supports parameter estimation by \n    weighted least squares and maximum likelihood methods, and produces Kriging \n    forecasts and intervals for existing and new locations.  "
  },
  {
    "id": 15762,
    "package_name": "mcompanion",
    "title": "Objects and Methods for Multi-Companion Matrices",
    "description": "\n    Provides a class for multi-companion matrices with methods for\n    arithmetic and factorization.  A method for generation of\n    multi-companion matrices with prespecified spectral properties is\n    provided, as well as some utilities for periodically correlated and\n    multivariate time series models. See Boshnakov (2002)\n    <doi:10.1016/S0024-3795(01)00475-X> and Boshnakov & Iqelan (2009)\n    <doi:10.1111/j.1467-9892.2009.00617.x>.",
    "version": "0.6",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Georgi N. Boshnakov [aut, cre]",
    "url": "https://geobosh.github.io/mcompanion/ (doc),\nhttps://github.com/GeoBosh/mcompanion (devel)",
    "bug_reports": "https://github.com/GeoBosh/mcompanion/issues",
    "repository": "https://cran.r-project.org/package=mcompanion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcompanion Objects and Methods for Multi-Companion Matrices \n    Provides a class for multi-companion matrices with methods for\n    arithmetic and factorization.  A method for generation of\n    multi-companion matrices with prespecified spectral properties is\n    provided, as well as some utilities for periodically correlated and\n    multivariate time series models. See Boshnakov (2002)\n    <doi:10.1016/S0024-3795(01)00475-X> and Boshnakov & Iqelan (2009)\n    <doi:10.1111/j.1467-9892.2009.00617.x>.  "
  },
  {
    "id": 15795,
    "package_name": "mds",
    "title": "Medical Devices Surveillance",
    "description": "A set of core functions for handling medical device event data in\n    the context of post-market surveillance, pharmacovigilance, signal detection\n    and trending, and regulatory reporting. Primary inputs are data on events by\n    device and data on exposures by device. Outputs include: standardized\n    device-event and exposure datasets, defined analyses, and time series.",
    "version": "0.3.2",
    "maintainer": "Gary Chung <gchung05@gmail.com>",
    "author": "Gary Chung [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mds Medical Devices Surveillance A set of core functions for handling medical device event data in\n    the context of post-market surveillance, pharmacovigilance, signal detection\n    and trending, and regulatory reporting. Primary inputs are data on events by\n    device and data on exposures by device. Outputs include: standardized\n    device-event and exposure datasets, defined analyses, and time series.  "
  },
  {
    "id": 15804,
    "package_name": "measuRing",
    "title": "Detection and Control of Tree-Ring Widths on Scanned Image\nSections",
    "description": "Identification of ring borders on scanned image sections from dendrochronological samples. Processing of image reflectances to produce gray matrices and time series of smoothed gray values. Luminance data is plotted on segmented images for users to perform both: visual identification of ring borders or control of automatic detection. Routines to visually include/exclude ring borders on the R graphical devices, or automatically detect ring borders using a linear detection algorithm. This algorithm detects ring borders according to positive/negative extreme values in the smoothed time-series of gray values. Most of the in-package routines can be recursively implemented using the multiDetect() function.",
    "version": "0.5.2",
    "maintainer": "Wilson Lara <wilarhen@gmail.com>",
    "author": "Wilson Lara [aut, cre] (ORCID: <https://orcid.org/0000-0003-3527-1380>),\n  Carlos Sierra [aut] (ORCID: <https://orcid.org/0000-0003-0009-4169>),\n  Felipe Bravo [aut] (ORCID: <https://orcid.org/0000-0001-7348-6695>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=measuRing",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "measuRing Detection and Control of Tree-Ring Widths on Scanned Image\nSections Identification of ring borders on scanned image sections from dendrochronological samples. Processing of image reflectances to produce gray matrices and time series of smoothed gray values. Luminance data is plotted on segmented images for users to perform both: visual identification of ring borders or control of automatic detection. Routines to visually include/exclude ring borders on the R graphical devices, or automatically detect ring borders using a linear detection algorithm. This algorithm detects ring borders according to positive/negative extreme values in the smoothed time-series of gray values. Most of the in-package routines can be recursively implemented using the multiDetect() function.  "
  },
  {
    "id": 15808,
    "package_name": "meboot",
    "title": "Maximum Entropy Bootstrap for Time Series",
    "description": "Maximum entropy density based dependent data bootstrap. \n  An algorithm is provided to create a population of time series (ensemble) \n  without assuming stationarity. The reference paper (Vinod, H.D., 2004 <DOI: 10.1016/j.jempfin.2003.06.002>) explains\n  how the algorithm satisfies the ergodic theorem and the central limit theorem.",
    "version": "1.4-9.4",
    "maintainer": "Fred Viole <fviole@fordham.edu>",
    "author": "Hrishikesh D. Vinod <Vinod@fordham.edu>, Javier\n        L\u00f3pez-de-Lacalle <javlacalle@yahoo.es>, and Fred Viole",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=meboot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "meboot Maximum Entropy Bootstrap for Time Series Maximum entropy density based dependent data bootstrap. \n  An algorithm is provided to create a population of time series (ensemble) \n  without assuming stationarity. The reference paper (Vinod, H.D., 2004 <DOI: 10.1016/j.jempfin.2003.06.002>) explains\n  how the algorithm satisfies the ergodic theorem and the central limit theorem.  "
  },
  {
    "id": 15833,
    "package_name": "meltt",
    "title": "Matching Event Data by Location, Time and Type",
    "description": "Framework for merging and disambiguating event data based on spatiotemporal co-occurrence and secondary event characteristics. It can account for intrinsic \"fuzziness\" in the coding of events, varying event taxonomies and different geo-precision codes.",
    "version": "0.4.3",
    "maintainer": "Karsten Donnay <kdonnay@gmx.net>",
    "author": "Karsten Donnay and Eric Dunford",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=meltt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "meltt Matching Event Data by Location, Time and Type Framework for merging and disambiguating event data based on spatiotemporal co-occurrence and secondary event characteristics. It can account for intrinsic \"fuzziness\" in the coding of events, varying event taxonomies and different geo-precision codes.  "
  },
  {
    "id": 15845,
    "package_name": "memoria",
    "title": "Quantifying Ecological Memory in Palaeoecological Datasets and\nOther Long Time-Series",
    "description": "Tools to quantify ecological memory in long time-series with Random Forest models (Breiman 2001 <doi:10.1023/A:1010933404324>) fitted with the 'ranger' library (Wright and Ziegler 2017 <doi:10.18637/jss.v077.i01>). Particularly oriented to palaeoecological datasets and simulated pollen curves produced by the 'virtualPollen' package, but also applicable to other long time-series involving a set of environmental drivers and a biotic response.",
    "version": "1.0.0",
    "maintainer": "Blas M. Benito <blasbenito@gmail.com>",
    "author": "Blas M. Benito",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=memoria",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "memoria Quantifying Ecological Memory in Palaeoecological Datasets and\nOther Long Time-Series Tools to quantify ecological memory in long time-series with Random Forest models (Breiman 2001 <doi:10.1023/A:1010933404324>) fitted with the 'ranger' library (Wright and Ziegler 2017 <doi:10.18637/jss.v077.i01>). Particularly oriented to palaeoecological datasets and simulated pollen curves produced by the 'virtualPollen' package, but also applicable to other long time-series involving a set of environmental drivers and a biotic response.  "
  },
  {
    "id": 15861,
    "package_name": "messydates",
    "title": "A Flexible Class for Messy Dates",
    "description": "Contains a set of tools for constructing and coercing\n  into and from the \"mdate\" class. \n  This date class implements ISO 8601-2:2019(E) and\n  allows regular dates to be annotated \n  to express unspecified date components,\n  approximate or uncertain date components, \n  date ranges, and sets of dates. \n  This is useful for describing and analysing temporal information,\n  whether historical or recent, where date precision may vary.",
    "version": "0.5.4",
    "maintainer": "James Hollway <james.hollway@graduateinstitute.ch>",
    "author": "James Hollway [cre, aut, ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0002-8361-9647>),\n  Henrique Sposito [ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0003-3420-6085>),\n  Jael Tan [ctb] (IHEID, ORCID: <https://orcid.org/0000-0002-6234-9764>),\n  Nathan Werth [ctb]",
    "url": "https://globalgov.github.io/messydates/",
    "bug_reports": "https://github.com/globalgov/messydates/issues",
    "repository": "https://cran.r-project.org/package=messydates",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "messydates A Flexible Class for Messy Dates Contains a set of tools for constructing and coercing\n  into and from the \"mdate\" class. \n  This date class implements ISO 8601-2:2019(E) and\n  allows regular dates to be annotated \n  to express unspecified date components,\n  approximate or uncertain date components, \n  date ranges, and sets of dates. \n  This is useful for describing and analysing temporal information,\n  whether historical or recent, where date precision may vary.  "
  },
  {
    "id": 15878,
    "package_name": "metaRange",
    "title": "Framework to Build Mechanistic and Metabolic Constrained Species\nDistribution Models",
    "description": "Build spatially and temporally explicit\n    process-based species distribution models, that can include an arbitrary\n    number of environmental factors, species and processes including metabolic\n    constraints and species interactions. The focus of the package is simulating\n    populations of one or multiple species in a grid-based landscape and studying\n    the meta-population dynamics and emergent patterns that arise from the\n    interaction of species under complex environmental conditions. It\n    provides functions for common ecological processes such as\n    negative exponential, kernel-based dispersal (see\n    Nathan et al. (2012) <doi:10.1093/acprof:oso/9780199608898.003.0015>),\n    calculation of the environmental suitability based on cardinal values (\n    Yin et al. (1995) <doi:10.1016/0168-1923(95)02236-Q>, simplified by\n    Yan and Hunt (1999) <doi:10.1006/anbo.1999.0955> see eq: 4), reproduction in\n    form of an Ricker model (see Ricker (1954) <doi:10.1139/f54-039> and\n    Cabral and Schurr (2010) <doi:10.1111/j.1466-8238.2009.00492.x>),\n    as well as metabolic scaling based on the metabolic theory of ecology\n    (see Brown et al. (2004) <doi:10.1890/03-9000> and\n    Brown, Sibly and Kodric-Brown (2012)\n    <doi:10.1002/9781119968535.ch>).",
    "version": "1.1.4",
    "maintainer": "Stefan Fallert <srfallert@gmail.com>",
    "author": "Stefan Fallert [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9939-4219>),\n  Lea Li [aut, cph] (Implemented the first version of the metabolic\n    scaling),\n  Juliano Sarmento Cabral [aut, cph, ths] (ORCID:\n    <https://orcid.org/0000-0002-0116-220X>),\n  Tyler Morgan-Wall [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0002-3131-3814>),\n  Bavarian Ministry of Science and Arts (bayklif) [fnd],\n  Deutsche Bundesstiftung Umwelt (DBU) [fnd]",
    "url": "https://metaRange.github.io/metaRange/",
    "bug_reports": "https://github.com/metaRange/metaRange/issues",
    "repository": "https://cran.r-project.org/package=metaRange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metaRange Framework to Build Mechanistic and Metabolic Constrained Species\nDistribution Models Build spatially and temporally explicit\n    process-based species distribution models, that can include an arbitrary\n    number of environmental factors, species and processes including metabolic\n    constraints and species interactions. The focus of the package is simulating\n    populations of one or multiple species in a grid-based landscape and studying\n    the meta-population dynamics and emergent patterns that arise from the\n    interaction of species under complex environmental conditions. It\n    provides functions for common ecological processes such as\n    negative exponential, kernel-based dispersal (see\n    Nathan et al. (2012) <doi:10.1093/acprof:oso/9780199608898.003.0015>),\n    calculation of the environmental suitability based on cardinal values (\n    Yin et al. (1995) <doi:10.1016/0168-1923(95)02236-Q>, simplified by\n    Yan and Hunt (1999) <doi:10.1006/anbo.1999.0955> see eq: 4), reproduction in\n    form of an Ricker model (see Ricker (1954) <doi:10.1139/f54-039> and\n    Cabral and Schurr (2010) <doi:10.1111/j.1466-8238.2009.00492.x>),\n    as well as metabolic scaling based on the metabolic theory of ecology\n    (see Brown et al. (2004) <doi:10.1890/03-9000> and\n    Brown, Sibly and Kodric-Brown (2012)\n    <doi:10.1002/9781119968535.ch>).  "
  },
  {
    "id": 15881,
    "package_name": "metaSVR",
    "title": "Support Vector Regression with Metaheuristic Algorithms\nOptimization",
    "description": "Provides a hybrid modeling framework combining Support Vector Regression (SVR) with metaheuristic optimization algorithms, including the Archimedes Optimization Algorithm (AO) (Hashim et al. (2021) <doi:10.1007/s10489-020-01893-z>), Coot Bird Optimization (CBO) (Naruei & Keynia (2021) <doi:10.1016/j.eswa.2021.115352>), and their hybrid (AOCBO), as well as several others such as Harris Hawks Optimization (HHO) (Heidari et al. (2019) <doi:10.1016/j.future.2019.02.028>), Gray Wolf Optimizer (GWO) (Mirjalili et al. (2014) <doi:10.1016/j.advengsoft.2013.12.007>), Ant Lion Optimization (ALO) (Mirjalili (2015) <doi:10.1016/j.advengsoft.2015.01.010>), and Enhanced Harris Hawk Optimization with Coot Bird Optimization (EHHOCBO) (Cui et al. (2023) <doi:10.32604/cmes.2023.026019>). The package enables automatic tuning of SVR hyperparameters (cost, gamma, and epsilon) to enhance prediction performance. Suitable for regression tasks in domains such as renewable energy forecasting and hourly data prediction. For more details about implementation and parameter bounds see: Setiawan et al. (2021) <doi:10.1016/j.procs.2020.12.003> and Liu et al. (2018) <doi:10.1155/2018/6076475>.  ",
    "version": "0.1.0",
    "maintainer": "Rechtiana Putri Arini <rparini17@gmail.com>",
    "author": "Rechtiana Putri Arini [aut, cre],\n  Robert Kurniawan [aut],\n  I Nyoman Setiawan [aut],\n  Zulhan Andika Asyraf [aut]",
    "url": "https://github.com/rechtianaputri/metaSVR",
    "bug_reports": "https://github.com/rechtianaputri/metaSVR/issues",
    "repository": "https://cran.r-project.org/package=metaSVR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metaSVR Support Vector Regression with Metaheuristic Algorithms\nOptimization Provides a hybrid modeling framework combining Support Vector Regression (SVR) with metaheuristic optimization algorithms, including the Archimedes Optimization Algorithm (AO) (Hashim et al. (2021) <doi:10.1007/s10489-020-01893-z>), Coot Bird Optimization (CBO) (Naruei & Keynia (2021) <doi:10.1016/j.eswa.2021.115352>), and their hybrid (AOCBO), as well as several others such as Harris Hawks Optimization (HHO) (Heidari et al. (2019) <doi:10.1016/j.future.2019.02.028>), Gray Wolf Optimizer (GWO) (Mirjalili et al. (2014) <doi:10.1016/j.advengsoft.2013.12.007>), Ant Lion Optimization (ALO) (Mirjalili (2015) <doi:10.1016/j.advengsoft.2015.01.010>), and Enhanced Harris Hawk Optimization with Coot Bird Optimization (EHHOCBO) (Cui et al. (2023) <doi:10.32604/cmes.2023.026019>). The package enables automatic tuning of SVR hyperparameters (cost, gamma, and epsilon) to enhance prediction performance. Suitable for regression tasks in domains such as renewable energy forecasting and hourly data prediction. For more details about implementation and parameter bounds see: Setiawan et al. (2021) <doi:10.1016/j.procs.2020.12.003> and Liu et al. (2018) <doi:10.1155/2018/6076475>.    "
  },
  {
    "id": 15940,
    "package_name": "meteo",
    "title": "RFSI & STRK Interpolation for Meteo and Environmental Variables",
    "description": "Random Forest Spatial Interpolation (RFSI, Sekuli\u0107 et al. (2020) <doi:10.3390/rs12101687>) and spatio-temporal geostatistical (spatio-temporal regression Kriging (STRK)) interpolation for meteorological (Kilibarda et al. (2014) <doi:10.1002/2013JD020803>, Sekuli\u0107 et al. (2020) <doi:10.1007/s00704-019-03077-3>) and other environmental variables. Contains global spatio-temporal models calculated using publicly available data.",
    "version": "2.0-3",
    "maintainer": "Aleksandar Sekuli\u0107 <asekulic@grf.bg.ac.rs>",
    "author": "Milan Kilibarda [aut] (ORCID: <https://orcid.org/0000-0002-2930-3596>),\n  Aleksandar Sekuli\u0107 [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5515-2779>),\n  Tomislav Hengl [ctb],\n  Edzer Pebesma [ctb],\n  Benedikt Graeler [ctb]",
    "url": "https://www.r-pkg.org/pkg/meteo,\nhttps://r-forge.r-project.org/projects/meteo/,\nhttps://github.com/AleksandarSekulic/Rmeteo",
    "bug_reports": "https://github.com/AleksandarSekulic/Rmeteo/issues",
    "repository": "https://cran.r-project.org/package=meteo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "meteo RFSI & STRK Interpolation for Meteo and Environmental Variables Random Forest Spatial Interpolation (RFSI, Sekuli\u0107 et al. (2020) <doi:10.3390/rs12101687>) and spatio-temporal geostatistical (spatio-temporal regression Kriging (STRK)) interpolation for meteorological (Kilibarda et al. (2014) <doi:10.1002/2013JD020803>, Sekuli\u0107 et al. (2020) <doi:10.1007/s00704-019-03077-3>) and other environmental variables. Contains global spatio-temporal models calculated using publicly available data.  "
  },
  {
    "id": 15942,
    "package_name": "meteoForecast",
    "title": "Numerical Weather Predictions",
    "description": "Access to several Numerical Weather Prediction services both in raster format and as a time series for a location. Currently it works with GFS <https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast>, MeteoGalicia <https://www.meteogalicia.gal/web/modelos/threddsIndex.action>, NAM <https://www.ncei.noaa.gov/products/weather-climate-models/north-american-mesoscale>, and RAP <https://www.ncei.noaa.gov/products/weather-climate-models/rapid-refresh-update>.",
    "version": "0.57",
    "maintainer": "Oscar Perpinan Lamigueiro <oscar.perpinan@upm.es>",
    "author": "Oscar Perpinan Lamigueiro [cre, aut],\n  Marcelo Pinho Almeida [ctb]",
    "url": "https://codeberg.org/oscarperpinan/meteoForecast",
    "bug_reports": "https://codeberg.org/oscarperpinan/meteoForecast/issues",
    "repository": "https://cran.r-project.org/package=meteoForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "meteoForecast Numerical Weather Predictions Access to several Numerical Weather Prediction services both in raster format and as a time series for a location. Currently it works with GFS <https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast>, MeteoGalicia <https://www.meteogalicia.gal/web/modelos/threddsIndex.action>, NAM <https://www.ncei.noaa.gov/products/weather-climate-models/north-american-mesoscale>, and RAP <https://www.ncei.noaa.gov/products/weather-climate-models/rapid-refresh-update>.  "
  },
  {
    "id": 15947,
    "package_name": "metools",
    "title": "Macroeconomics Tools",
    "description": "Provides a number of functions to facilitate the handling and production of reports using time series data.\n    The package was developed to be understandable for beginners, so some functions aim to transform processes that would be\n    complex into functions with a few lines. The main advantage of using the 'metools' package is the ease of producing reports and\n    working with time series using a few lines of code, so the code is clean and easy to understand/maintain. \n    Learn more about the 'metools' at <https://metoolsr.wordpress.com>.",
    "version": "1.0.0",
    "maintainer": "Jo\u00e3o Victor Gomes de Araujo Santana <jvg.santana@gmail.com>",
    "author": "Jo\u00e3o Victor Gomes de Araujo Santana [aut, cre]",
    "url": "https://metoolsr.wordpress.com,https://github.com/jvg0mes/metools,https://jvg0mes.github.io/metoolsr",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=metools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metools Macroeconomics Tools Provides a number of functions to facilitate the handling and production of reports using time series data.\n    The package was developed to be understandable for beginners, so some functions aim to transform processes that would be\n    complex into functions with a few lines. The main advantage of using the 'metools' package is the ease of producing reports and\n    working with time series using a few lines of code, so the code is clean and easy to understand/maintain. \n    Learn more about the 'metools' at <https://metoolsr.wordpress.com>.  "
  },
  {
    "id": 15948,
    "package_name": "metrica",
    "title": "Prediction Performance Metrics",
    "description": "A compilation of more than 80 functions designed to quantitatively and visually evaluate prediction performance of regression (continuous variables) and classification (categorical variables) of point-forecast models (e.g. APSIM, DSSAT, DNDC, supervised Machine Learning). For regression, it includes functions to generate plots (scatter, tiles, density, & Bland-Altman plot), and to estimate error metrics (e.g. MBE, MAE, RMSE), error decomposition (e.g. lack of accuracy-precision), model efficiency (e.g. NSE, E1, KGE), indices of agreement (e.g. d, RAC), goodness of fit (e.g. r, R2), adjusted correlation coefficients (e.g. CCC, dcorr), symmetric regression coefficients (intercept, slope), and mean absolute scaled error (MASE) for time series predictions. For classification (binomial and multinomial), it offers functions to generate and plot confusion matrices, and to estimate performance metrics such as accuracy, precision, recall, specificity, F-score, Cohen's Kappa, G-mean, and many more. For more details visit the vignettes <https://adriancorrendo.github.io/metrica/>.",
    "version": "2.1.0",
    "maintainer": "Adrian A. Correndo <acorrend@uoguelph.ca>",
    "author": "Adrian A. Correndo [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4172-289X>),\n  Luiz H. Moro Rosso [aut] (ORCID:\n    <https://orcid.org/0000-0002-8642-911X>),\n  Rai Schwalbert [aut] (ORCID: <https://orcid.org/0000-0001-8488-7507>),\n  Carlos Hernandez [aut] (ORCID: <https://orcid.org/0000-0001-5171-2516>),\n  Leonardo M. Bastos [aut] (ORCID:\n    <https://orcid.org/0000-0001-8958-6527>),\n  Luciana Nieto [aut] (ORCID: <https://orcid.org/0000-0002-7172-0799>),\n  Dean Holzworth [aut],\n  Ignacio A. Ciampitti [aut] (ORCID:\n    <https://orcid.org/0000-0001-9619-5129>)",
    "url": "https://adriancorrendo.github.io/metrica/",
    "bug_reports": "https://github.com/adriancorrendo/metrica/issues",
    "repository": "https://cran.r-project.org/package=metrica",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metrica Prediction Performance Metrics A compilation of more than 80 functions designed to quantitatively and visually evaluate prediction performance of regression (continuous variables) and classification (categorical variables) of point-forecast models (e.g. APSIM, DSSAT, DNDC, supervised Machine Learning). For regression, it includes functions to generate plots (scatter, tiles, density, & Bland-Altman plot), and to estimate error metrics (e.g. MBE, MAE, RMSE), error decomposition (e.g. lack of accuracy-precision), model efficiency (e.g. NSE, E1, KGE), indices of agreement (e.g. d, RAC), goodness of fit (e.g. r, R2), adjusted correlation coefficients (e.g. CCC, dcorr), symmetric regression coefficients (intercept, slope), and mean absolute scaled error (MASE) for time series predictions. For classification (binomial and multinomial), it offers functions to generate and plot confusion matrices, and to estimate performance metrics such as accuracy, precision, recall, specificity, F-score, Cohen's Kappa, G-mean, and many more. For more details visit the vignettes <https://adriancorrendo.github.io/metrica/>.  "
  },
  {
    "id": 15955,
    "package_name": "mevr",
    "title": "Fitting the Metastatistical Extreme Value Distribution MEVD",
    "description": "Extreme value analysis with the metastatistical extreme value distribution MEVD (Marani and Ignaccolo, 2015, <doi:10.1016/j.advwatres.2015.03.001>) and some of its variants. In particular, analysis can be performed with the simplified metastatistical extreme value distribution SMEV (Marra et al., 2019, <doi:10.1016/j.advwatres.2019.04.002>) and the temporal metastatistical extreme value distribution TMEV (Falkensteiner et al., 2023, <doi:10.1016/j.wace.2023.100601>). Parameters can be estimated with probability weighted moments, maximum likelihood and least squares. The data can also be left-censored prior to a fit. Density, distribution function, quantile function and random generation for the MEVD, SMEV and TMEV are included. In addition, functions for the calculation of return levels including confidence intervals are provided. For a description of use cases please see the provided references.",
    "version": "1.1.1",
    "maintainer": "Harald Schellander <harald.schellander@geosphere.at>",
    "author": "Harald Schellander [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7661-287X>, Package creator and\n    maintainer),\n  Alexander Lieb [ctb] (Coded first versions of MEVD and SMEV),\n  Marc-Andre Falkensteiner [ctb] (Developed the TMEV)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mevr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mevr Fitting the Metastatistical Extreme Value Distribution MEVD Extreme value analysis with the metastatistical extreme value distribution MEVD (Marani and Ignaccolo, 2015, <doi:10.1016/j.advwatres.2015.03.001>) and some of its variants. In particular, analysis can be performed with the simplified metastatistical extreme value distribution SMEV (Marra et al., 2019, <doi:10.1016/j.advwatres.2019.04.002>) and the temporal metastatistical extreme value distribution TMEV (Falkensteiner et al., 2023, <doi:10.1016/j.wace.2023.100601>). Parameters can be estimated with probability weighted moments, maximum likelihood and least squares. The data can also be left-censored prior to a fit. Density, distribution function, quantile function and random generation for the MEVD, SMEV and TMEV are included. In addition, functions for the calculation of return levels including confidence intervals are provided. For a description of use cases please see the provided references.  "
  },
  {
    "id": 15959,
    "package_name": "mfGARCH",
    "title": "Mixed-Frequency GARCH Models",
    "description": "Estimating GARCH-MIDAS (MIxed-DAta-Sampling) models (Engle, Ghysels, Sohn, 2013, <doi:10.1162/REST_a_00300>) and related statistical inference, accompanying the paper \"Two are better than one: Volatility forecasting using multiplicative component GARCH models\" by Conrad and Kleen (2020, <doi:10.1002/jae.2742>). The GARCH-MIDAS model decomposes the conditional variance of (daily) stock returns into a short- and long-term component, where the latter may depend on an exogenous covariate sampled at a lower frequency. ",
    "version": "0.2.1",
    "maintainer": "Onno Kleen <r@onnokleen.de>",
    "author": "Onno Kleen [aut, cre] (ORCID: <https://orcid.org/0000-0003-4731-4640>)",
    "url": "https://github.com/onnokleen/mfGARCH/",
    "bug_reports": "https://github.com/onnokleen/mfGARCH/issues",
    "repository": "https://cran.r-project.org/package=mfGARCH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mfGARCH Mixed-Frequency GARCH Models Estimating GARCH-MIDAS (MIxed-DAta-Sampling) models (Engle, Ghysels, Sohn, 2013, <doi:10.1162/REST_a_00300>) and related statistical inference, accompanying the paper \"Two are better than one: Volatility forecasting using multiplicative component GARCH models\" by Conrad and Kleen (2020, <doi:10.1002/jae.2742>). The GARCH-MIDAS model decomposes the conditional variance of (daily) stock returns into a short- and long-term component, where the latter may depend on an exogenous covariate sampled at a lower frequency.   "
  },
  {
    "id": 15983,
    "package_name": "mhsmm",
    "title": "Inference for Hidden Markov and Semi-Markov Models",
    "description": "Parameter estimation and prediction for hidden Markov and semi-Markov models for data with multiple observation sequences.  Suitable for equidistant time series data, with multivariate and/or missing data. Allows user defined emission distributions.",
    "version": "0.4.21",
    "maintainer": "Jared O'Connell <jaredoconnell@gmail.com>",
    "author": "Jared O'Connell <jaredoconnell@gmail.com>, S\u00f8ren H\u00f8jsgaard\n        <sorenh@math.aau.dk>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mhsmm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mhsmm Inference for Hidden Markov and Semi-Markov Models Parameter estimation and prediction for hidden Markov and semi-Markov models for data with multiple observation sequences.  Suitable for equidistant time series data, with multivariate and/or missing data. Allows user defined emission distributions.  "
  },
  {
    "id": 16011,
    "package_name": "micompr",
    "title": "Multivariate Independent Comparison of Observations",
    "description": "A procedure for comparing multivariate samples associated with\n    different groups. It uses principal component analysis to convert\n    multivariate observations into a set of linearly uncorrelated statistical\n    measures, which are then compared using a number of statistical methods. The\n    procedure is independent of the distributional properties of samples and\n    automatically selects features that best explain their differences, avoiding\n    manual selection of specific points or summary statistics. It is appropriate\n    for comparing samples of time series, images, spectrometric measures or\n    similar multivariate observations. This package is described in Fachada et\n    al. (2016) <doi:10.32614/RJ-2016-055>.",
    "version": "1.3.0",
    "maintainer": "Nuno Fachada <faken@fakenmc.com>",
    "author": "Nuno Fachada [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8487-5837>)",
    "url": "https://github.com/nunofachada/micompr",
    "bug_reports": "https://github.com/nunofachada/micompr/issues",
    "repository": "https://cran.r-project.org/package=micompr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "micompr Multivariate Independent Comparison of Observations A procedure for comparing multivariate samples associated with\n    different groups. It uses principal component analysis to convert\n    multivariate observations into a set of linearly uncorrelated statistical\n    measures, which are then compared using a number of statistical methods. The\n    procedure is independent of the distributional properties of samples and\n    automatically selects features that best explain their differences, avoiding\n    manual selection of specific points or summary statistics. It is appropriate\n    for comparing samples of time series, images, spectrometric measures or\n    similar multivariate observations. This package is described in Fachada et\n    al. (2016) <doi:10.32614/RJ-2016-055>.  "
  },
  {
    "id": 16032,
    "package_name": "micss",
    "title": "Modified Iterative Cumulative Sum of Squares Algorithm",
    "description": "Companion package of Carrion-i-Silvestre & Sans\u00f3 (2023): \n  \"Generalized Extreme Value Approximation to the CUMSUMQ Test for Constant \n  Unconditional Variance in Heavy-Tailed Time Series\". It implements the Modified \n  Iterative Cumulative Sum of Squares Algorithm, which is an extension of \n  the Iterative Cumulative Sum of Squares (ICSS) Algorithm of Inclan and Tiao (1994), and it checks for changes in the \n  unconditional variance of a time series controlling for the tail index of \n  the underlying distribution. The fourth order moment is estimated non-parametrically\n  to avoid the size problems when the innovations are non-Gaussian (see, Sans\u00f3 et al., 2004). \n  Critical values and p-values are generated using a Generalized Extreme Value distribution approach.\n  References\n  Carrion-i-Silvestre J.J & Sans\u00f3 A (2023) <https://www.ub.edu/irea/working_papers/2023/202309.pdf>.\n  Inclan C & Tiao G.C (1994) <doi:10.1080/01621459.1994.10476824>,\n  Sans\u00f3 A & Arag\u00f3 V & Carrion-i-Silvestre J.L (2004) <https://dspace.uib.es/xmlui/bitstream/handle/11201/152078/524035.pdf>.",
    "version": "0.2.0",
    "maintainer": "Andreu Sans\u00f3 <andreu.sanso@uib.eu>",
    "author": "Josep Llu\u00eds Carrion-i-Silvestre [aut],\n  Andreu Sans\u00f3 [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=micss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "micss Modified Iterative Cumulative Sum of Squares Algorithm Companion package of Carrion-i-Silvestre & Sans\u00f3 (2023): \n  \"Generalized Extreme Value Approximation to the CUMSUMQ Test for Constant \n  Unconditional Variance in Heavy-Tailed Time Series\". It implements the Modified \n  Iterative Cumulative Sum of Squares Algorithm, which is an extension of \n  the Iterative Cumulative Sum of Squares (ICSS) Algorithm of Inclan and Tiao (1994), and it checks for changes in the \n  unconditional variance of a time series controlling for the tail index of \n  the underlying distribution. The fourth order moment is estimated non-parametrically\n  to avoid the size problems when the innovations are non-Gaussian (see, Sans\u00f3 et al., 2004). \n  Critical values and p-values are generated using a Generalized Extreme Value distribution approach.\n  References\n  Carrion-i-Silvestre J.J & Sans\u00f3 A (2023) <https://www.ub.edu/irea/working_papers/2023/202309.pdf>.\n  Inclan C & Tiao G.C (1994) <doi:10.1080/01621459.1994.10476824>,\n  Sans\u00f3 A & Arag\u00f3 V & Carrion-i-Silvestre J.L (2004) <https://dspace.uib.es/xmlui/bitstream/handle/11201/152078/524035.pdf>.  "
  },
  {
    "id": 16036,
    "package_name": "midasml",
    "title": "Estimation and Prediction Methods for High-Dimensional Mixed\nFrequency Time Series Data",
    "description": "The 'midasml' package implements estimation and prediction methods for high-dimensional mixed-frequency (MIDAS) time-series and panel data regression models. The regularized MIDAS models are estimated using orthogonal (e.g. Legendre) polynomials and sparse-group LASSO (sg-LASSO) estimator. For more information on the 'midasml' approach see Babii, Ghysels, and Striaukas (2021, JBES forthcoming) <doi:10.1080/07350015.2021.1899933>. The package is equipped with the fast implementation of the sg-LASSO estimator by means of proximal block coordinate descent. High-dimensional mixed frequency time-series data can also be easily manipulated with functions provided in the package.",
    "version": "0.1.11",
    "maintainer": "Jonas Striaukas <jonas.striaukas@gmail.com>",
    "author": "Jonas Striaukas [cre, aut],\n  Andrii Babii [aut],\n  Jad Beyhum [aut],\n  Eric Ghysels [aut],\n  Alex Kostrov [ctb] (Contributions to analytical gradients for\n    non-linear low-dimensional MIDAS estimation code)",
    "url": "",
    "bug_reports": "https://github.com/jstriaukas/midasml/issues",
    "repository": "https://cran.r-project.org/package=midasml",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "midasml Estimation and Prediction Methods for High-Dimensional Mixed\nFrequency Time Series Data The 'midasml' package implements estimation and prediction methods for high-dimensional mixed-frequency (MIDAS) time-series and panel data regression models. The regularized MIDAS models are estimated using orthogonal (e.g. Legendre) polynomials and sparse-group LASSO (sg-LASSO) estimator. For more information on the 'midasml' approach see Babii, Ghysels, and Striaukas (2021, JBES forthcoming) <doi:10.1080/07350015.2021.1899933>. The package is equipped with the fast implementation of the sg-LASSO estimator by means of proximal block coordinate descent. High-dimensional mixed frequency time-series data can also be easily manipulated with functions provided in the package.  "
  },
  {
    "id": 16037,
    "package_name": "midasr",
    "title": "Mixed Data Sampling Regression",
    "description": "Methods and tools for mixed frequency time series data analysis.\n    Allows estimation, model selection and forecasting for MIDAS regressions.",
    "version": "0.9",
    "maintainer": "Vaidotas Zemlys-Balevi\u010dius <zemlys@gmail.com>",
    "author": "Vaidotas Zemlys-Balevi\u010dius [cre],\n  Virmantas Kvedaras [aut],\n  Vaidotas Zemlys-Balevi\u010dius [aut]",
    "url": "http://mpiktas.github.io/midasr/",
    "bug_reports": "https://github.com/mpiktas/midasr/issues",
    "repository": "https://cran.r-project.org/package=midasr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "midasr Mixed Data Sampling Regression Methods and tools for mixed frequency time series data analysis.\n    Allows estimation, model selection and forecasting for MIDAS regressions.  "
  },
  {
    "id": 16053,
    "package_name": "miic",
    "title": "Learning Causal or Non-Causal Graphical Models Using Information\nTheory",
    "description": "Multivariate Information-based Inductive Causation, better known \n    by its acronym MIIC, is a causal discovery method, based on information \n    theory principles, which learns a large class of causal or non-causal \n    graphical models from purely observational data, while including the effects \n    of unobserved latent variables. Starting from a complete graph, the method \n    iteratively removes dispensable edges, by uncovering significant information \n    contributions from indirect paths, and assesses edge-specific confidences \n    from randomization of available data. The remaining edges are then oriented \n    based on the signature of causality in observational data. The recent more \n    interpretable MIIC extension (iMIIC) further distinguishes genuine causes \n    from putative and latent causal effects, while scaling to very large \n    datasets (hundreds of thousands of samples). Since the version 2.0, MIIC \n    also includes a temporal mode (tMIIC) to learn temporal causal graphs from \n    stationary time series data. MIIC has been applied to a wide range of \n    biological and biomedical data, such as single cell gene expression data, \n    genomic alterations in tumors, live-cell time-lapse imaging data \n    (CausalXtract), as well as medical records of patients. MIIC brings unique \n    insights based on causal interpretation and could be used in a broad range \n    of other data science domains (technology, climatology, economy, ...). \n    For more information, you can refer to: \n    Simon et al., eLife 2024, <doi:10.1101/2024.02.06.579177>, \n    Ribeiro-Dantas et al., iScience 2024, <doi:10.1016/j.isci.2024.109736>, \n    Cabeli et al., NeurIPS 2021, <https://why21.causalai.net/papers/WHY21_24.pdf>, \n    Cabeli et al., Comput. Biol. 2020, <doi:10.1371/journal.pcbi.1007866>, \n    Li et al., NeurIPS 2019, <https://papers.nips.cc/paper/9573-constraint-based-causal-structure-learning-with-consistent-separating-sets>, \n    Verny et al., PLoS Comput. Biol. 2017, <doi:10.1371/journal.pcbi.1005662>, \n    Affeldt et al., UAI 2015, <https://auai.org/uai2015/proceedings/papers/293.pdf>. \n    Changes from the previous 1.5.3 release on CRAN are available at \n    <https://github.com/miicTeam/miic_R_package/blob/master/NEWS.md>.",
    "version": "2.0.3",
    "maintainer": "Franck Simon <franck.simon@curie.fr>",
    "author": "Franck Simon [aut, cre],\n  Tiziana Tocci [aut],\n  Nikita Lagrange [aut],\n  Orianne Debeaupuis [aut],\n  Louise Dupuis [aut],\n  Vincent Cabeli [aut],\n  Honghao Li [aut],\n  Marcel Ribeiro Dantas [aut],\n  Nadir Sella [aut],\n  Louis Verny [aut],\n  Severine Affeldt [aut],\n  Herv\u00e9 Isambert [aut]",
    "url": "https://github.com/miicTeam/miic_R_package",
    "bug_reports": "https://github.com/miicTeam/miic_R_package/issues",
    "repository": "https://cran.r-project.org/package=miic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "miic Learning Causal or Non-Causal Graphical Models Using Information\nTheory Multivariate Information-based Inductive Causation, better known \n    by its acronym MIIC, is a causal discovery method, based on information \n    theory principles, which learns a large class of causal or non-causal \n    graphical models from purely observational data, while including the effects \n    of unobserved latent variables. Starting from a complete graph, the method \n    iteratively removes dispensable edges, by uncovering significant information \n    contributions from indirect paths, and assesses edge-specific confidences \n    from randomization of available data. The remaining edges are then oriented \n    based on the signature of causality in observational data. The recent more \n    interpretable MIIC extension (iMIIC) further distinguishes genuine causes \n    from putative and latent causal effects, while scaling to very large \n    datasets (hundreds of thousands of samples). Since the version 2.0, MIIC \n    also includes a temporal mode (tMIIC) to learn temporal causal graphs from \n    stationary time series data. MIIC has been applied to a wide range of \n    biological and biomedical data, such as single cell gene expression data, \n    genomic alterations in tumors, live-cell time-lapse imaging data \n    (CausalXtract), as well as medical records of patients. MIIC brings unique \n    insights based on causal interpretation and could be used in a broad range \n    of other data science domains (technology, climatology, economy, ...). \n    For more information, you can refer to: \n    Simon et al., eLife 2024, <doi:10.1101/2024.02.06.579177>, \n    Ribeiro-Dantas et al., iScience 2024, <doi:10.1016/j.isci.2024.109736>, \n    Cabeli et al., NeurIPS 2021, <https://why21.causalai.net/papers/WHY21_24.pdf>, \n    Cabeli et al., Comput. Biol. 2020, <doi:10.1371/journal.pcbi.1007866>, \n    Li et al., NeurIPS 2019, <https://papers.nips.cc/paper/9573-constraint-based-causal-structure-learning-with-consistent-separating-sets>, \n    Verny et al., PLoS Comput. Biol. 2017, <doi:10.1371/journal.pcbi.1005662>, \n    Affeldt et al., UAI 2015, <https://auai.org/uai2015/proceedings/papers/293.pdf>. \n    Changes from the previous 1.5.3 release on CRAN are available at \n    <https://github.com/miicTeam/miic_R_package/blob/master/NEWS.md>.  "
  },
  {
    "id": 16110,
    "package_name": "miscFuncs",
    "title": "Miscellaneous Useful Functions Including LaTeX Tables, Kalman\nFiltering, QQplots with Simulation-Based Confidence Intervals,\nLinear Regression Diagnostics and Development Tools",
    "description": "Implementing various things including functions for LaTeX tables,\n    the Kalman filter, QQ-plots with simulation-based confidence intervals, linear regression diagnostics, web scraping, development tools, relative risk and odds\n    rati, GARCH(1,1) Forecasting.",
    "version": "1.5-10",
    "maintainer": "Benjamin M. Taylor <benjamin.taylor.software@gmail.com>",
    "author": "Benjamin M. Taylor [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=miscFuncs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "miscFuncs Miscellaneous Useful Functions Including LaTeX Tables, Kalman\nFiltering, QQplots with Simulation-Based Confidence Intervals,\nLinear Regression Diagnostics and Development Tools Implementing various things including functions for LaTeX tables,\n    the Kalman filter, QQ-plots with simulation-based confidence intervals, linear regression diagnostics, web scraping, development tools, relative risk and odds\n    rati, GARCH(1,1) Forecasting.  "
  },
  {
    "id": 16185,
    "package_name": "mlVAR",
    "title": "Multi-Level Vector Autoregression",
    "description": "Estimates the multi-level vector autoregression model on time-series data.\n             Three network structures are obtained: temporal networks, contemporaneous\n             networks and between-subjects networks.",
    "version": "0.5.2",
    "maintainer": "Sacha Epskamp <mail@sachaepskamp.com>",
    "author": "Sacha Epskamp [aut, cre],\n  Marie K. Deserno [aut],\n  Laura F. Bringmann [aut],\n  Myrthe Veenman [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mlVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlVAR Multi-Level Vector Autoregression Estimates the multi-level vector autoregression model on time-series data.\n             Three network structures are obtained: temporal networks, contemporaneous\n             networks and between-subjects networks.  "
  },
  {
    "id": 16212,
    "package_name": "mlmts",
    "title": "Machine Learning Algorithms for Multivariate Time Series",
    "description": "An implementation of several machine learning algorithms for \n    multivariate time series. The package includes functions allowing the\n    execution of clustering, classification or outlier detection methods,\n    among others. It also incorporates a collection of multivariate time\n    series datasets which can be used to analyse the performance of new\n    proposed algorithms. Some of these datasets are stored in GitHub data\n    packages 'ueadata1' to 'ueadata8'. To access these data packages, run\n    'install.packages(c('ueadata1', 'ueadata2', 'ueadata3', 'ueadata4', 'ueadata5', 'ueadata6', 'ueadata7', 'ueadata8'), repos='<https://anloor7.github.io/drat/>')'.\n    The installation takes a couple of minutes but we strongly encourage the\n    users to do it if they want to have available all datasets of mlmts.\n    Practitioners from a broad variety of fields could\n    benefit from the general framework provided by 'mlmts'.",
    "version": "1.1.2",
    "maintainer": "Angel Lopez-Oriona <oriona38@hotmail.com>",
    "author": "Angel Lopez-Oriona [aut, cre],\n  Jose A. Vilar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mlmts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlmts Machine Learning Algorithms for Multivariate Time Series An implementation of several machine learning algorithms for \n    multivariate time series. The package includes functions allowing the\n    execution of clustering, classification or outlier detection methods,\n    among others. It also incorporates a collection of multivariate time\n    series datasets which can be used to analyse the performance of new\n    proposed algorithms. Some of these datasets are stored in GitHub data\n    packages 'ueadata1' to 'ueadata8'. To access these data packages, run\n    'install.packages(c('ueadata1', 'ueadata2', 'ueadata3', 'ueadata4', 'ueadata5', 'ueadata6', 'ueadata7', 'ueadata8'), repos='<https://anloor7.github.io/drat/>')'.\n    The installation takes a couple of minutes but we strongly encourage the\n    users to do it if they want to have available all datasets of mlmts.\n    Practitioners from a broad variety of fields could\n    benefit from the general framework provided by 'mlmts'.  "
  },
  {
    "id": 16239,
    "package_name": "mlr3spatiotempcv",
    "title": "Spatiotemporal Resampling Methods for 'mlr3'",
    "description": "Extends the mlr3 machine learning framework with\n    spatio-temporal resampling methods to account for the presence of\n    spatiotemporal autocorrelation (STAC) in predictor variables. STAC may\n    cause highly biased performance estimates in cross-validation if\n    ignored. A JSS article is available at <doi:10.18637/jss.v111.i07>.",
    "version": "2.3.4",
    "maintainer": "Patrick Schratz <patrick.schratz@gmail.com>",
    "author": "Patrick Schratz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0748-6624>),\n  Marc Becker [aut] (ORCID: <https://orcid.org/0000-0002-8115-0400>),\n  Jannes Muenchow [ctb] (ORCID: <https://orcid.org/0000-0001-7834-4717>),\n  Michel Lang [ctb] (ORCID: <https://orcid.org/0000-0001-9754-0393>)",
    "url": "https://mlr3spatiotempcv.mlr-org.com/,\nhttps://github.com/mlr-org/mlr3spatiotempcv,\nhttps://mlr3book.mlr-org.com",
    "bug_reports": "https://github.com/mlr-org/mlr3spatiotempcv/issues",
    "repository": "https://cran.r-project.org/package=mlr3spatiotempcv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlr3spatiotempcv Spatiotemporal Resampling Methods for 'mlr3' Extends the mlr3 machine learning framework with\n    spatio-temporal resampling methods to account for the presence of\n    spatiotemporal autocorrelation (STAC) in predictor variables. STAC may\n    cause highly biased performance estimates in cross-validation if\n    ignored. A JSS article is available at <doi:10.18637/jss.v111.i07>.  "
  },
  {
    "id": 16250,
    "package_name": "mlrv",
    "title": "Long-Run Variance Estimation in Time Series Regression",
    "description": "Plug-in and difference-based long-run covariance matrix estimation for time series regression. Two applications of hypothesis testing are also provided. The first one is for testing for structural stability in coefficient functions. The second one is aimed at detecting long memory in time series regression. Lujia Bai and Weichi Wu (2024)<doi:10.3150/23-BEJ1680> Zhou Zhou and Wei Biao Wu(2010)<doi:10.1111/j.1467-9868.2010.00743.x> Jianqing Fan and Wenyang Zhang<doi:10.1214/aos/1017939139> Lujia Bai and Weichi Wu(2024)<doi:10.1093/biomet/asae013> Dimitris N. Politis, Joseph P. Romano, Michael Wolf(1999)<doi:10.1007/978-1-4612-1554-7> Weichi Wu and Zhou Zhou(2018)<doi:10.1214/17-AOS1582>.",
    "version": "0.1.2",
    "maintainer": "Lujia Bai <bailujia98@gmail.com>",
    "author": "Lujia Bai [aut, cre],\n  Weichi Wu [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mlrv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlrv Long-Run Variance Estimation in Time Series Regression Plug-in and difference-based long-run covariance matrix estimation for time series regression. Two applications of hypothesis testing are also provided. The first one is for testing for structural stability in coefficient functions. The second one is aimed at detecting long memory in time series regression. Lujia Bai and Weichi Wu (2024)<doi:10.3150/23-BEJ1680> Zhou Zhou and Wei Biao Wu(2010)<doi:10.1111/j.1467-9868.2010.00743.x> Jianqing Fan and Wenyang Zhang<doi:10.1214/aos/1017939139> Lujia Bai and Weichi Wu(2024)<doi:10.1093/biomet/asae013> Dimitris N. Politis, Joseph P. Romano, Michael Wolf(1999)<doi:10.1007/978-1-4612-1554-7> Weichi Wu and Zhou Zhou(2018)<doi:10.1214/17-AOS1582>.  "
  },
  {
    "id": 16258,
    "package_name": "mlts",
    "title": "Multilevel Latent Time Series Models with 'R' and 'Stan'",
    "description": "Fit multilevel manifest or latent time-series models, including popular Dynamic Structural Equation Models (DSEM).\n  The models can be set up and modified with user-friendly functions and are fit to the data using 'Stan' for Bayesian inference.\n  Path models and formulas for user-defined models can be easily created with functions using 'knitr'. \n  Asparouhov, Hamaker, & Muthen (2018) <doi:10.1080/10705511.2017.1406803>.",
    "version": "2.0.1",
    "maintainer": "Kenneth Koslowski <kenneth.koslowski@uni-leipzig.de>",
    "author": "Kenneth Koslowski [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5296-5267>),\n  Fabian M\u00fcnch [aut] (ORCID: <https://orcid.org/0000-0001-5591-9901>),\n  Tobias Koch [aut] (ORCID: <https://orcid.org/0000-0002-8143-3566>),\n  Jana Holtmann [aut] (ORCID: <https://orcid.org/0000-0002-7949-0772>)",
    "url": "https://github.com/munchfab/mlts",
    "bug_reports": "https://github.com/munchfab/mlts/issues",
    "repository": "https://cran.r-project.org/package=mlts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlts Multilevel Latent Time Series Models with 'R' and 'Stan' Fit multilevel manifest or latent time-series models, including popular Dynamic Structural Equation Models (DSEM).\n  The models can be set up and modified with user-friendly functions and are fit to the data using 'Stan' for Bayesian inference.\n  Path models and formulas for user-defined models can be easily created with functions using 'knitr'. \n  Asparouhov, Hamaker, & Muthen (2018) <doi:10.1080/10705511.2017.1406803>.  "
  },
  {
    "id": 16260,
    "package_name": "mma",
    "title": "Multiple Mediation Analysis",
    "description": "Used for general multiple mediation analysis. \n\tThe analysis method is described in Yu and Li (2022) (ISBN: 9780367365479) \"Statistical Methods for Mediation, Confounding and Moderation Analysis Using R and SAS\", published by Chapman and Hall/CRC; and Yu et al.(2017) <DOI:10.1016/j.sste.2017.02.001> \"Exploring racial disparity in obesity: a mediation analysis considering geo-coded environmental factors\", published on Spatial and Spatio-temporal Epidemiology, 21, 13-23.  ",
    "version": "10.8-1",
    "maintainer": "Qingzhao Yu <qyu@lsuhsc.edu>",
    "author": "Qingzhao Yu [aut, cre],\n  Bin Li [aut]",
    "url": "https://www.r-project.org,\nhttps://publichealth.lsuhsc.edu/Faculty_pages/qyu/index.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mma Multiple Mediation Analysis Used for general multiple mediation analysis. \n\tThe analysis method is described in Yu and Li (2022) (ISBN: 9780367365479) \"Statistical Methods for Mediation, Confounding and Moderation Analysis Using R and SAS\", published by Chapman and Hall/CRC; and Yu et al.(2017) <DOI:10.1016/j.sste.2017.02.001> \"Exploring racial disparity in obesity: a mediation analysis considering geo-coded environmental factors\", published on Spatial and Spatio-temporal Epidemiology, 21, 13-23.    "
  },
  {
    "id": 16330,
    "package_name": "modernVA",
    "title": "An Implementation of Two Modern Education-Based Value-Added\nModels",
    "description": "Provides functions that fit two modern education-based value-added models.  \n                 One of these models is the quantile value-added model.  This model \n                 permits estimating a school's value-added based on specific quantiles of \n                 the post-test distribution.  Estimating value-added based on quantiles \n                 of the post-test distribution provides a more complete picture of an \n                 education institution's contribution to learning for students of all \n                 abilities. See Page, G.L.; San Mart\u00edn, E.; Orellana, J.; Gonzalez, J. (2017)\n                 <doi:10.1111/rssa.12195> for more details.  The second model is a temporally \n                 dependent value-added model. This model takes into account the temporal \n                 dependence that may exist in school performance  between two cohorts in one \n                 of two ways.  The first is by modeling school  random effects with a \n                 non-stationary AR(1) process.  The second is by  modeling school effects \n                 based on previous cohort's post-test performance. In addition to more \n                 efficiently estimating value-added, this model permits making statements \n                 about the persistence of a schools effectiveness. The standard  value-added \n                 model is also an option.",
    "version": "0.1.3",
    "maintainer": "Garritt L. Page <page@stat.byu.edu>",
    "author": "Garritt L. Page [aut, cre, cph],\n  S. McKay Curtis [ctb, cph],\n  Radford M. Neal [ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=modernVA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modernVA An Implementation of Two Modern Education-Based Value-Added\nModels Provides functions that fit two modern education-based value-added models.  \n                 One of these models is the quantile value-added model.  This model \n                 permits estimating a school's value-added based on specific quantiles of \n                 the post-test distribution.  Estimating value-added based on quantiles \n                 of the post-test distribution provides a more complete picture of an \n                 education institution's contribution to learning for students of all \n                 abilities. See Page, G.L.; San Mart\u00edn, E.; Orellana, J.; Gonzalez, J. (2017)\n                 <doi:10.1111/rssa.12195> for more details.  The second model is a temporally \n                 dependent value-added model. This model takes into account the temporal \n                 dependence that may exist in school performance  between two cohorts in one \n                 of two ways.  The first is by modeling school  random effects with a \n                 non-stationary AR(1) process.  The second is by  modeling school effects \n                 based on previous cohort's post-test performance. In addition to more \n                 efficiently estimating value-added, this model permits making statements \n                 about the persistence of a schools effectiveness. The standard  value-added \n                 model is also an option.  "
  },
  {
    "id": 16337,
    "package_name": "modifiedmk",
    "title": "Modified Versions of Mann Kendall and Spearman's Rho Trend Tests",
    "description": "Power of non-parametric Mann-Kendall test and Spearman\u2019s Rho test is highly influenced by serially correlated data. To address this issue, trend tests may be applied on the modified versions of the time series data by  Block Bootstrapping (BBS), Prewhitening (PW) , Trend Free Prewhitening (TFPW), Bias Corrected Prewhitening and Variance Correction Approach by calculating effective sample size.\n    Mann, H. B. (1945).<doi:10.1017/CBO9781107415324.004>.\n    Kendall, M. (1975). Multivariate analysis. Charles Griffin&Company Ltd,. \n    sen, P. K. (1968).<doi:10.2307/2285891>.\n    \u00d6n\u00f6z, B., & Bayazit, M. (2012) <doi:10.1002/hyp.8438>.\n    Hamed, K. H. (2009).<doi:10.1016/j.jhydrol.2009.01.040>.\n    Yue, S., & Wang, C. Y. (2002) <doi:10.1029/2001WR000861>.\n    Yue, S., Pilon, P., Phinney, B., & Cavadias, G. (2002) <doi:10.1002/hyp.1095>.\n    Hamed, K. H., & Ramachandra Rao, A. (1998) <doi:10.1016/S0022-1694(97)00125-X>.\n    Yue, S., & Wang, C. Y. (2004) <doi:10.1023/B:WARM.0000043140.61082.60>.",
    "version": "1.6",
    "maintainer": "Sandeep Kumar Patakamuri <sandeep.patakamuri@gmail.com>",
    "author": "Sandeep Kumar Patakamuri [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8965-8287>),\n  Nicole O'Brien [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=modifiedmk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modifiedmk Modified Versions of Mann Kendall and Spearman's Rho Trend Tests Power of non-parametric Mann-Kendall test and Spearman\u2019s Rho test is highly influenced by serially correlated data. To address this issue, trend tests may be applied on the modified versions of the time series data by  Block Bootstrapping (BBS), Prewhitening (PW) , Trend Free Prewhitening (TFPW), Bias Corrected Prewhitening and Variance Correction Approach by calculating effective sample size.\n    Mann, H. B. (1945).<doi:10.1017/CBO9781107415324.004>.\n    Kendall, M. (1975). Multivariate analysis. Charles Griffin&Company Ltd,. \n    sen, P. K. (1968).<doi:10.2307/2285891>.\n    \u00d6n\u00f6z, B., & Bayazit, M. (2012) <doi:10.1002/hyp.8438>.\n    Hamed, K. H. (2009).<doi:10.1016/j.jhydrol.2009.01.040>.\n    Yue, S., & Wang, C. Y. (2002) <doi:10.1029/2001WR000861>.\n    Yue, S., Pilon, P., Phinney, B., & Cavadias, G. (2002) <doi:10.1002/hyp.1095>.\n    Hamed, K. H., & Ramachandra Rao, A. (1998) <doi:10.1016/S0022-1694(97)00125-X>.\n    Yue, S., & Wang, C. Y. (2004) <doi:10.1023/B:WARM.0000043140.61082.60>.  "
  },
  {
    "id": 16338,
    "package_name": "modisfast",
    "title": "Fast and Efficient Access to MODIS Earth Observation Data",
    "description": "Programmatic interface to several NASA Earth Observation 'OPeNDAP' servers (Open-source Project for a Network Data Access Protocol) (<https://www.opendap.org/>). Allows for easy downloads of MODIS subsets, as well as other Earth Observation datacubes, in a time-saving and efficient way : by sampling it at the very downloading phase (spatially, temporally and dimensionally).",
    "version": "1.0.2",
    "maintainer": "Paul Taconet <paul.taconet@gmail.com>",
    "author": "Paul Taconet [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7429-7204>),\n  Nicolas Moiroux [fnd] (ORCID: <https://orcid.org/0000-0001-6755-6167>),\n  French National Research Institute for Sustainable Development, IRD\n    [fnd]",
    "url": "https://github.com/ptaconet/modisfast",
    "bug_reports": "https://github.com/ptaconet/modisfast/issues",
    "repository": "https://cran.r-project.org/package=modisfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modisfast Fast and Efficient Access to MODIS Earth Observation Data Programmatic interface to several NASA Earth Observation 'OPeNDAP' servers (Open-source Project for a Network Data Access Protocol) (<https://www.opendap.org/>). Allows for easy downloads of MODIS subsets, as well as other Earth Observation datacubes, in a time-saving and efficient way : by sampling it at the very downloading phase (spatially, temporally and dimensionally).  "
  },
  {
    "id": 16340,
    "package_name": "modnets",
    "title": "Modeling Moderated Networks",
    "description": "Methods for modeling moderator variables in cross-sectional, temporal, and multi-level networks. Includes model selection techniques and a variety of plotting functions. Implements the methods described by Swanson (2020) <https://www.proquest.com/openview/d151ab6b93ad47e3f0d5e59d7b6fd3d3>.",
    "version": "0.9.0",
    "maintainer": "Trevor Swanson <trevorswanson222@gmail.com>",
    "author": "Trevor Swanson [aut, cre]",
    "url": "https://github.com/tswanson222/modnets",
    "bug_reports": "https://github.com/tswanson222/modnets/issues",
    "repository": "https://cran.r-project.org/package=modnets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modnets Modeling Moderated Networks Methods for modeling moderator variables in cross-sectional, temporal, and multi-level networks. Includes model selection techniques and a variety of plotting functions. Implements the methods described by Swanson (2020) <https://www.proquest.com/openview/d151ab6b93ad47e3f0d5e59d7b6fd3d3>.  "
  },
  {
    "id": 16385,
    "package_name": "mopac",
    "title": "Collection of Datasets Pertaining to Loop 1 \"Mopac\"",
    "description": "Provides real & simulated datasets containing time-series traffic observations\n    and additional information pertaining to Loop 1 \"Mopac\" located in Austin, Texas.",
    "version": "0.1.0",
    "maintainer": "Scott McKenzie <sccmckenzie@gmail.com>",
    "author": "Scott McKenzie [aut, cre]",
    "url": "https://github.com/sccmckenzie/mopac",
    "bug_reports": "https://github.com/sccmckenzie/mopac/issues",
    "repository": "https://cran.r-project.org/package=mopac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mopac Collection of Datasets Pertaining to Loop 1 \"Mopac\" Provides real & simulated datasets containing time-series traffic observations\n    and additional information pertaining to Loop 1 \"Mopac\" located in Austin, Texas.  "
  },
  {
    "id": 16411,
    "package_name": "motoRneuron",
    "title": "Analyzing Paired Neuron Discharge Times for Time-Domain\nSynchronization",
    "description": "The temporal relationship between motor neurons can offer \n    explanations for neural strategies. We combined functions to reduce neuron \n    action potential discharge data and analyze it for short-term, time-domain \n    synchronization. Even more so, motoRneuron combines most available methods \n    for the determining cross correlation histogram peaks and most available \n    indices for calculating synchronization into simple functions. See \n    Nordstrom, Fuglevand, and Enoka (1992) <doi:10.1113/jphysiol.1992.sp019244> \n    for a more thorough introduction.",
    "version": "1.0.0",
    "maintainer": "Andrew Tweedell <atweedell315@gmail.com>",
    "author": "Andrew Tweedell [aut, cre],\n  Matthew Tenan [aut]",
    "url": "http://github.com/tweedell/motoRneuron",
    "bug_reports": "http://github.com/tweedell/motoRneuron/issues",
    "repository": "https://cran.r-project.org/package=motoRneuron",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "motoRneuron Analyzing Paired Neuron Discharge Times for Time-Domain\nSynchronization The temporal relationship between motor neurons can offer \n    explanations for neural strategies. We combined functions to reduce neuron \n    action potential discharge data and analyze it for short-term, time-domain \n    synchronization. Even more so, motoRneuron combines most available methods \n    for the determining cross correlation histogram peaks and most available \n    indices for calculating synchronization into simple functions. See \n    Nordstrom, Fuglevand, and Enoka (1992) <doi:10.1113/jphysiol.1992.sp019244> \n    for a more thorough introduction.  "
  },
  {
    "id": 16419,
    "package_name": "moveEZ",
    "title": "Animated Biplots",
    "description": "Create animated biplots that enables dynamic visualisation of temporal or sequential changes in multivariate data by animating a single biplot across the levels of a time variable. It builds on objects from the 'biplotEZ' package, Lubbe S, le Roux N, Nienkemper-Swanepoel J, Ganey R, Buys R, Adams Z, Manefeldt P (2024) <doi:10.32614/CRAN.package.biplotEZ>, allowing users to create animated biplots that reveal how both samples and variables evolve over time.",
    "version": "1.1.1",
    "maintainer": "Raeesa Ganey <raeesa.ganey@wits.ac.za>",
    "author": "Raeesa Ganey [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0008-6973-0999>),\n  Johan\u00e9 Nienkemper-Swanepoel [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-6086-8272>)",
    "url": "https://muvisu.github.io/moveEZ/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=moveEZ",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "moveEZ Animated Biplots Create animated biplots that enables dynamic visualisation of temporal or sequential changes in multivariate data by animating a single biplot across the levels of a time variable. It builds on objects from the 'biplotEZ' package, Lubbe S, le Roux N, Nienkemper-Swanepoel J, Ganey R, Buys R, Adams Z, Manefeldt P (2024) <doi:10.32614/CRAN.package.biplotEZ>, allowing users to create animated biplots that reveal how both samples and variables evolve over time.  "
  },
  {
    "id": 16434,
    "package_name": "mpitbR",
    "title": "Calculate Alkire-Foster Multidimensional Poverty Measures",
    "description": "\n    Estimate Multidimensional Poverty Indices disaggregated by population subgroups based on the Alkire and Foster method (2011) <doi:10.1016/j.jpubeco.2010.11.006>. This includes the calculation of standard errors and confidence intervals. Other partial indices such as incidence, intensity and indicator-specific measures as well as intertemporal changes analysis can also be estimated. The standard errors and confidence intervals are calculated considering the complex survey design. ",
    "version": "1.0.1",
    "maintainer": "Ignacio Girela <ignacio.girela@unc.edu.ar>",
    "author": "Ignacio Girela [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3297-3854>),\n  CONICET [fnd]",
    "url": "https://github.com/girelaignacio/mpitbR",
    "bug_reports": "https://github.com/girelaignacio/mpitbR/issues",
    "repository": "https://cran.r-project.org/package=mpitbR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mpitbR Calculate Alkire-Foster Multidimensional Poverty Measures \n    Estimate Multidimensional Poverty Indices disaggregated by population subgroups based on the Alkire and Foster method (2011) <doi:10.1016/j.jpubeco.2010.11.006>. This includes the calculation of standard errors and confidence intervals. Other partial indices such as incidence, intensity and indicator-specific measures as well as intertemporal changes analysis can also be estimated. The standard errors and confidence intervals are calculated considering the complex survey design.   "
  },
  {
    "id": 16490,
    "package_name": "msltrend",
    "title": "Improved Techniques to Estimate Trend, Velocity and Acceleration\nfrom Sea Level Records",
    "description": "Analysis of annual average ocean water level time series\n    from long (minimum length 80 years) individual records, providing improved\n    estimates of trend (mean sea level) and associated real-time velocities and\n    accelerations. Improved trend estimates are based on Singular Spectrum Analysis\n    methods. Various gap-filling options are included to accommodate incomplete time\n    series records. The package also contains a forecasting module to consider the\n    implication of user defined quantum of sea level rise between the end of the\n    available historical record and the year 2100. A wide range of screen and pdf\n    plotting options are available in the package.",
    "version": "1.0",
    "maintainer": "Phil J Watson <philwatson.slr@gmail.com>",
    "author": "Phil J Watson <philwatson.slr@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=msltrend",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "msltrend Improved Techniques to Estimate Trend, Velocity and Acceleration\nfrom Sea Level Records Analysis of annual average ocean water level time series\n    from long (minimum length 80 years) individual records, providing improved\n    estimates of trend (mean sea level) and associated real-time velocities and\n    accelerations. Improved trend estimates are based on Singular Spectrum Analysis\n    methods. Various gap-filling options are included to accommodate incomplete time\n    series records. The package also contains a forecasting module to consider the\n    implication of user defined quantum of sea level rise between the end of the\n    available historical record and the year 2100. A wide range of screen and pdf\n    plotting options are available in the package.  "
  },
  {
    "id": 16506,
    "package_name": "mtarm",
    "title": "Bayesian Estimation of Multivariate Threshold Autoregressive\nModels",
    "description": "Estimation, inference and forecasting using the Bayesian approach for multivariate threshold autoregressive (TAR) models in which the distribution used to describe the noise process belongs to the class of Gaussian variance mixtures.",
    "version": "0.1.7",
    "maintainer": "Luis Hernando Vanegas <lhvanegasp@unal.edu.co>",
    "author": "Luis Hernando Vanegas [aut, cre],\n  Sergio Alejandro Calder\u00f3n [aut],\n  Luz Marina Rond\u00f3n [aut]",
    "url": "",
    "bug_reports": "https://github.com/lhvanegasp/mtar/issues",
    "repository": "https://cran.r-project.org/package=mtarm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mtarm Bayesian Estimation of Multivariate Threshold Autoregressive\nModels Estimation, inference and forecasting using the Bayesian approach for multivariate threshold autoregressive (TAR) models in which the distribution used to describe the noise process belongs to the class of Gaussian variance mixtures.  "
  },
  {
    "id": 16513,
    "package_name": "mtsdi",
    "title": "Multivariate Time Series Data Imputation",
    "description": "This is an EM algorithm based method for imputation of missing values in multivariate normal time series. The imputation algorithm accounts for both spatial and temporal correlation structures. Temporal patterns can be modeled using an ARIMA(p,d,q), optionally with seasonal components, a non-parametric cubic spline or generalized additive models with exogenous covariates. This algorithm is specially tailored for climate data with missing measurements from several monitors along a given region.",
    "version": "0.3.7",
    "maintainer": "Washington Junger <wjunger@ims.uerj.br>",
    "author": "Washington Junger [aut, cre],\n  Antonio Ponce de Leon [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mtsdi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mtsdi Multivariate Time Series Data Imputation This is an EM algorithm based method for imputation of missing values in multivariate normal time series. The imputation algorithm accounts for both spatial and temporal correlation structures. Temporal patterns can be modeled using an ARIMA(p,d,q), optionally with seasonal components, a non-parametric cubic spline or generalized additive models with exogenous covariates. This algorithm is specially tailored for climate data with missing measurements from several monitors along a given region.  "
  },
  {
    "id": 16529,
    "package_name": "multDM",
    "title": "Multivariate Version of the Diebold-Mariano Test",
    "description": "Allows to perform the multivariate version of the Diebold-Mariano test for equal predictive ability of multiple forecast comparison. Main reference: Mariano, R.S., Preve, D. (2012) <doi:10.1016/j.jeconom.2012.01.014>. ",
    "version": "1.1.5",
    "maintainer": "Krzysztof Drachal <kdrachal@wne.uw.edu.pl>",
    "author": "Krzysztof Drachal [aut, cre] (Faculty of Economic Sciences, University\n    of Warsaw, Poland)",
    "url": "https://CRAN.R-project.org/package=multDM",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multDM Multivariate Version of the Diebold-Mariano Test Allows to perform the multivariate version of the Diebold-Mariano test for equal predictive ability of multiple forecast comparison. Main reference: Mariano, R.S., Preve, D. (2012) <doi:10.1016/j.jeconom.2012.01.014>.   "
  },
  {
    "id": 16554,
    "package_name": "multibreakeR",
    "title": "Tests for a Structural Change in Multivariate Time Series",
    "description": "Flexible implementation of a structural change point detection algorithm for multivariate time series.\n    It authorizes inclusion of trends, exogenous variables, and break test on the intercept or on the full vector autoregression system.\n    Bai, Lumsdaine, and Stock (1998) <doi:10.1111/1467-937X.00051>.",
    "version": "0.1.0",
    "maintainer": "Loic Marechal <loic.marechal@unil.ch>",
    "author": "Loic Marechal [cre, aut]",
    "url": "https://github.com/loicym/multibreakeR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multibreakeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multibreakeR Tests for a Structural Change in Multivariate Time Series Flexible implementation of a structural change point detection algorithm for multivariate time series.\n    It authorizes inclusion of trends, exogenous variables, and break test on the intercept or on the full vector autoregression system.\n    Bai, Lumsdaine, and Stock (1998) <doi:10.1111/1467-937X.00051>.  "
  },
  {
    "id": 16575,
    "package_name": "multilevelcoda",
    "title": "Estimate Bayesian Multilevel Models for Compositional Data",
    "description": "Implement Bayesian multilevel modelling for compositional data. \n             Compute multilevel compositional data and \n             perform log-ratio transforms at between and within-person levels, \n             fit Bayesian multilevel models for compositional predictors and outcomes, \n             and run post-hoc analyses such as isotemporal substitution models.\n             References: \n             Le, Stanford, Dumuid, and Wiley (2025) <doi:10.1037/met0000750>,\n             Le, Dumuid, Stanford, and Wiley (2025) <doi:10.1080/00273171.2025.2565598>.",
    "version": "1.3.3",
    "maintainer": "Flora Le <floralebui@gmail.com>",
    "author": "Flora Le [aut, cre] (ORCID: <https://orcid.org/0000-0003-0089-8167>),\n  Joshua F. Wiley [aut] (ORCID: <https://orcid.org/0000-0002-0271-6702>)",
    "url": "https://florale.github.io/multilevelcoda/,\nhttps://github.com/florale/multilevelcoda",
    "bug_reports": "https://github.com/florale/multilevelcoda/issues",
    "repository": "https://cran.r-project.org/package=multilevelcoda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multilevelcoda Estimate Bayesian Multilevel Models for Compositional Data Implement Bayesian multilevel modelling for compositional data. \n             Compute multilevel compositional data and \n             perform log-ratio transforms at between and within-person levels, \n             fit Bayesian multilevel models for compositional predictors and outcomes, \n             and run post-hoc analyses such as isotemporal substitution models.\n             References: \n             Le, Stanford, Dumuid, and Wiley (2025) <doi:10.1037/met0000750>,\n             Le, Dumuid, Stanford, and Wiley (2025) <doi:10.1080/00273171.2025.2565598>.  "
  },
  {
    "id": 16592,
    "package_name": "multiocc",
    "title": "Fits Multivariate Spatio-Temporal Occupancy Model",
    "description": "Spatio-temporal multivariate occupancy models can handle multiple species in occupancy models.  This method for fitting such models is described in Hepler and Erhardt (2021) \"A spatiotemporal model for multivariate occupancy data\".",
    "version": "0.2.3",
    "maintainer": "Staci Hepler <heplersa@wfu.edu>",
    "author": "Staci Hepler [aut, cre],\n  Rob Erhardt [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multiocc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multiocc Fits Multivariate Spatio-Temporal Occupancy Model Spatio-temporal multivariate occupancy models can handle multiple species in occupancy models.  This method for fitting such models is described in Hepler and Erhardt (2021) \"A spatiotemporal model for multivariate occupancy data\".  "
  },
  {
    "id": 16606,
    "package_name": "multispatialCCM",
    "title": "Multispatial Convergent Cross Mapping",
    "description": "The multispatial convergent cross mapping algorithm can be used as a test for causal associations between pairs of processes represented by time series. This is a combination of convergent cross mapping (CCM), described in Sugihara et al., 2012, Science, 338, 496-500, and dew-drop regression, described in Hsieh et al., 2008, American Naturalist, 171, 71\u201380. The algorithm allows CCM to be implemented on data that are not from a single long time series. Instead, data can come from many short time series, which are stitched together using bootstrapping.",
    "version": "1.3",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "author": "Adam Clark",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multispatialCCM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multispatialCCM Multispatial Convergent Cross Mapping The multispatial convergent cross mapping algorithm can be used as a test for causal associations between pairs of processes represented by time series. This is a combination of convergent cross mapping (CCM), described in Sugihara et al., 2012, Science, 338, 496-500, and dew-drop regression, described in Hsieh et al., 2008, American Naturalist, 171, 71\u201380. The algorithm allows CCM to be implemented on data that are not from a single long time series. Instead, data can come from many short time series, which are stitched together using bootstrapping.  "
  },
  {
    "id": 16609,
    "package_name": "multivar",
    "title": "Penalized Estimation of Multiple-Subject Vector Autoregressive\n(multi-VAR) Models",
    "description": "Functions for simulating, estimating and forecasting stationary Vector Autoregressive (VAR) models for multiple subject data using the penalized multi-VAR framework in Fisher, Kim and Pipiras (2020) <arXiv:2007.05052>. ",
    "version": "1.1.0",
    "maintainer": "Zachary Fisher <fish.zachary@gmail.com>",
    "author": "Zachary Fisher [aut, cre],\n  Younghoon Kim [ctb],\n  Vladas Pipiras [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multivar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multivar Penalized Estimation of Multiple-Subject Vector Autoregressive\n(multi-VAR) Models Functions for simulating, estimating and forecasting stationary Vector Autoregressive (VAR) models for multiple subject data using the penalized multi-VAR framework in Fisher, Kim and Pipiras (2020) <arXiv:2007.05052>.   "
  },
  {
    "id": 16625,
    "package_name": "murphydiagram",
    "title": "Murphy Diagrams for Forecast Comparisons",
    "description": "Data and code for the paper by Ehm, Gneiting, Jordan and\n    Krueger ('Of Quantiles and Expectiles: Consistent Scoring Functions, Choquet\n    Representations, and Forecast Rankings', JRSS-B, 2016 <DOI:10.1111/rssb.12154>).",
    "version": "0.12.2",
    "maintainer": "Fabian Krueger <Fabian.Krueger83@gmail.com>",
    "author": "Alexander Jordan, Fabian Krueger",
    "url": "https://sites.google.com/site/fk83research/code",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=murphydiagram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "murphydiagram Murphy Diagrams for Forecast Comparisons Data and code for the paper by Ehm, Gneiting, Jordan and\n    Krueger ('Of Quantiles and Expectiles: Consistent Scoring Functions, Choquet\n    Representations, and Forecast Rankings', JRSS-B, 2016 <DOI:10.1111/rssb.12154>).  "
  },
  {
    "id": 16636,
    "package_name": "mvDFA",
    "title": "Multivariate Detrended Fluctuation Analysis",
    "description": "This R package provides an implementation of multivariate extensions of a well-known fractal analysis technique, Detrended Fluctuations Analysis (DFA; Peng et al., 1995<doi:10.1063/1.166141>), for multivariate time series: multivariate DFA (mvDFA). Several coefficients are implemented that take into account the correlation structure of the multivariate time series to varying degrees. These coefficients may be used to analyze long memory and changes in the dynamic structure that would by univariate DFA. Therefore, this R package aims to extend and complement the original univariate DFA (Peng et al., 1995) for estimating the scaling properties of nonstationary time series.",
    "version": "0.0.4",
    "maintainer": "Julien Patrick Irmer <jirmer@psych.uni-frankfurt.de>",
    "author": "Julien Patrick Irmer [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7544-6483>),\n  Sebastian Wallot [aut, ctb]",
    "url": "https://github.com/jpirmer/mvDFA",
    "bug_reports": "https://github.com/jpirmer/mvDFA/issues",
    "repository": "https://cran.r-project.org/package=mvDFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvDFA Multivariate Detrended Fluctuation Analysis This R package provides an implementation of multivariate extensions of a well-known fractal analysis technique, Detrended Fluctuations Analysis (DFA; Peng et al., 1995<doi:10.1063/1.166141>), for multivariate time series: multivariate DFA (mvDFA). Several coefficients are implemented that take into account the correlation structure of the multivariate time series to varying degrees. These coefficients may be used to analyze long memory and changes in the dynamic structure that would by univariate DFA. Therefore, this R package aims to extend and complement the original univariate DFA (Peng et al., 1995) for estimating the scaling properties of nonstationary time series.  "
  },
  {
    "id": 16638,
    "package_name": "mvLSW",
    "title": "Multivariate, Locally Stationary Wavelet Process Estimation",
    "description": "Tools for analysing multivariate time series with wavelets. This includes: simulation of a multivariate locally stationary wavelet (mvLSW) process from a multivariate evolutionary wavelet spectrum (mvEWS); estimation of the mvEWS, local coherence and local partial coherence. See Park, Eckley and Ombao (2014) <doi:10.1109/TSP.2014.2343937> for details.",
    "version": "1.2.5",
    "maintainer": "Daniel Grose <dan.grose@lancaster.ac.uk>",
    "author": "Simon Taylor [aut],\n  Tim Park [aut],\n  Idris Eckley [ths],\n  Rebecca Killick [ctb],\n  Daniel Grose [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mvLSW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvLSW Multivariate, Locally Stationary Wavelet Process Estimation Tools for analysing multivariate time series with wavelets. This includes: simulation of a multivariate locally stationary wavelet (mvLSW) process from a multivariate evolutionary wavelet spectrum (mvEWS); estimation of the mvEWS, local coherence and local partial coherence. See Park, Eckley and Ombao (2014) <doi:10.1109/TSP.2014.2343937> for details.  "
  },
  {
    "id": 16639,
    "package_name": "mvLSWimpute",
    "title": "Imputation Methods for Multivariate Locally Stationary Time\nSeries",
    "description": "Implementation of imputation techniques based on locally stationary wavelet time series forecasting methods from Wilson, R. E. et al. (2021) <doi:10.1007/s11222-021-09998-2>.",
    "version": "0.1.1",
    "maintainer": "Matt Nunes <nunesrpackages@gmail.com>",
    "author": "Rebecca Wilson [aut],\n  Matt Nunes [aut, cre],\n  Idris Eckley [ctb, ths],\n  Tim Park [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mvLSWimpute",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvLSWimpute Imputation Methods for Multivariate Locally Stationary Time\nSeries Implementation of imputation techniques based on locally stationary wavelet time series forecasting methods from Wilson, R. E. et al. (2021) <doi:10.1007/s11222-021-09998-2>.  "
  },
  {
    "id": 16642,
    "package_name": "mvMORPH",
    "title": "Multivariate Comparative Tools for Fitting Evolutionary Models\nto Morphometric Data",
    "description": "Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares and multivariate tests) based on penalized likelihood.  See\n    Clavel et al. (2015) <DOI:10.1111/2041-210X.12420>, Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>, and Clavel & Morlon (2020) <DOI:10.1093/sysbio/syaa010>.",
    "version": "1.2.1",
    "maintainer": "Julien Clavel <julien.clavel@hotmail.fr>",
    "author": "Julien Clavel [aut, cre],\n  with contributions from Aaron King [aut],\n  Emmanuel Paradis [aut]",
    "url": "https://github.com/JClavel/mvMORPH",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mvMORPH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvMORPH Multivariate Comparative Tools for Fitting Evolutionary Models\nto Morphometric Data Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares and multivariate tests) based on penalized likelihood.  See\n    Clavel et al. (2015) <DOI:10.1111/2041-210X.12420>, Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>, and Clavel & Morlon (2020) <DOI:10.1093/sysbio/syaa010>.  "
  },
  {
    "id": 16648,
    "package_name": "mvSUSY",
    "title": "Multivariate Surrogate Synchrony",
    "description": "Multivariate Surrogate Synchrony ('mvSUSY') estimates the synchrony within datasets that contain more than two time series. 'mvSUSY' was developed from Surrogate Synchrony ('SUSY') with respect to implementing surrogate controls, and extends synchrony estimation to multivariate data. 'mvSUSY' works as described in Meier & Tschacher (2021).",
    "version": "0.1.0",
    "maintainer": "Wolfgang Tschacher <wolfgang.tschacher@unibe.ch>",
    "author": "Wolfgang Tschacher [aut, cre],\n  Deborah Meier [aut],\n  Jan Gorecki [ctb]",
    "url": "https://wtschacher.github.io/mvSUSY/",
    "bug_reports": "https://github.com/wtschacher/mvSUSY/issues",
    "repository": "https://cran.r-project.org/package=mvSUSY",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvSUSY Multivariate Surrogate Synchrony Multivariate Surrogate Synchrony ('mvSUSY') estimates the synchrony within datasets that contain more than two time series. 'mvSUSY' was developed from Surrogate Synchrony ('SUSY') with respect to implementing surrogate controls, and extends synchrony estimation to multivariate data. 'mvSUSY' works as described in Meier & Tschacher (2021).  "
  },
  {
    "id": 16683,
    "package_name": "mvtsplot",
    "title": "Multivariate Time Series Plot",
    "description": "A function for plotting multivariate time series data.",
    "version": "1.0-5",
    "maintainer": "Roger D. Peng <roger.peng@austin.utexas.edu>",
    "author": "Roger D. Peng <roger.peng@austin.utexas.edu>",
    "url": "https://github.com/rdpeng/mvtsplot",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mvtsplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvtsplot Multivariate Time Series Plot A function for plotting multivariate time series data.  "
  },
  {
    "id": 16686,
    "package_name": "mwa",
    "title": "Causal Inference in Spatiotemporal Event Data",
    "description": "Implementation of Matched Wake Analysis (mwa) for studying causal relationships in spatiotemporal event data, introduced by Schutte and Donnay (2014) <doi:10.1016/j.polgeo.2014.03.001>. ",
    "version": "0.5.0",
    "maintainer": "Karsten Donnay <kdonnay@gmx.net>",
    "author": "Sebastian Schutte [aut],\n  Karsten Donnay [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mwa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mwa Causal Inference in Spatiotemporal Event Data Implementation of Matched Wake Analysis (mwa) for studying causal relationships in spatiotemporal event data, introduced by Schutte and Donnay (2014) <doi:10.1016/j.polgeo.2014.03.001>.   "
  },
  {
    "id": 16731,
    "package_name": "narfima",
    "title": "Neural AutoRegressive Fractionally Integrated Moving Average\nModel",
    "description": "Methods and tools for forecasting univariate time series using the NARFIMA (Neural AutoRegressive Fractionally Integrated Moving Average) model. It combines neural networks with fractional differencing to capture both nonlinear patterns and long-term dependencies. The NARFIMA model supports seasonal adjustment, Box-Cox transformations, optional exogenous variables, and the computation of prediction intervals. In addition to the NARFIMA model, this package provides alternative forecasting models including NARIMA (Neural ARIMA), NBSTS (Neural Bayesian Structural Time Series), and NNaive (Neural Naive) for performance comparison across different modeling approaches. The methods are based on algorithms introduced by Chakraborty et al. (2025) <doi:10.48550/arXiv.2509.06697>.",
    "version": "0.1.0",
    "maintainer": "Donia Besher <donia.a.besher@gmail.com>",
    "author": "Tanujit Chakraborty [aut] (ORCID:\n    <https://orcid.org/0000-0002-3479-2187>),\n  Donia Besher [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0008-8314-1576>),\n  Madhurima Panja [aut] (ORCID: <https://orcid.org/0009-0004-7467-2456>),\n  Shovon Sengupta [aut] (ORCID: <https://orcid.org/0000-0003-2169-7364>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=narfima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "narfima Neural AutoRegressive Fractionally Integrated Moving Average\nModel Methods and tools for forecasting univariate time series using the NARFIMA (Neural AutoRegressive Fractionally Integrated Moving Average) model. It combines neural networks with fractional differencing to capture both nonlinear patterns and long-term dependencies. The NARFIMA model supports seasonal adjustment, Box-Cox transformations, optional exogenous variables, and the computation of prediction intervals. In addition to the NARFIMA model, this package provides alternative forecasting models including NARIMA (Neural ARIMA), NBSTS (Neural Bayesian Structural Time Series), and NNaive (Neural Naive) for performance comparison across different modeling approaches. The methods are based on algorithms introduced by Chakraborty et al. (2025) <doi:10.48550/arXiv.2509.06697>.  "
  },
  {
    "id": 16767,
    "package_name": "ncdfCF",
    "title": "Easy Access to NetCDF Files with CF Metadata Conventions",
    "description": "Network Common Data Form ('netCDF') files are widely used for \n    scientific data. Library-level access in R is provided through packages \n    'RNetCDF' and 'ncdf4'. Package 'ncdfCF' is built on top of 'RNetCDF' and \n    makes the data and its attributes available as a set of R6 classes that are \n    informed by the Climate and Forecasting Metadata Conventions. Access to the \n    data uses standard R subsetting operators and common function forms.",
    "version": "0.7.0",
    "maintainer": "Patrick Van Laake <patrick@vanlaake.net>",
    "author": "Patrick Van Laake [aut, cre, cph]",
    "url": "https://github.com/R-CF/ncdfCF",
    "bug_reports": "https://github.com/R-CF/ncdfCF/issues",
    "repository": "https://cran.r-project.org/package=ncdfCF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ncdfCF Easy Access to NetCDF Files with CF Metadata Conventions Network Common Data Form ('netCDF') files are widely used for \n    scientific data. Library-level access in R is provided through packages \n    'RNetCDF' and 'ncdf4'. Package 'ncdfCF' is built on top of 'RNetCDF' and \n    makes the data and its attributes available as a set of R6 classes that are \n    informed by the Climate and Forecasting Metadata Conventions. Access to the \n    data uses standard R subsetting operators and common function forms.  "
  },
  {
    "id": 16768,
    "package_name": "ncdfgeom",
    "title": "'NetCDF' Geometry and Time Series",
    "description": "Tools to create time series and geometry 'NetCDF' files.",
    "version": "1.1.6",
    "maintainer": "David Blodgett <dblodgett@usgs.gov>",
    "author": "David Blodgett [aut, cre],\n  Luke Winslow [ctb]",
    "url": "https://code.usgs.gov/water/ncdfgeom",
    "bug_reports": "https://github.com/DOI-USGS/ncdfgeom/issues",
    "repository": "https://cran.r-project.org/package=ncdfgeom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ncdfgeom 'NetCDF' Geometry and Time Series Tools to create time series and geometry 'NetCDF' files.  "
  },
  {
    "id": 16779,
    "package_name": "ndtv",
    "title": "Network Dynamic Temporal Visualizations",
    "description": "Renders dynamic network data from 'networkDynamic' objects as movies, interactive animations, or other representations of changing relational structures and attributes.",
    "version": "0.13.4",
    "maintainer": "Skye Bender-deMoll <skyebend@uw.edu>",
    "author": "Skye Bender-deMoll [cre, aut],\n  Martina Morris [ctb]",
    "url": "https://github.com/statnet/ndtv",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ndtv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ndtv Network Dynamic Temporal Visualizations Renders dynamic network data from 'networkDynamic' objects as movies, interactive animations, or other representations of changing relational structures and attributes.  "
  },
  {
    "id": 16793,
    "package_name": "nemBM",
    "title": "Using Network Evolution Models to Generate Networks with\nSelected Blockmodel Type",
    "description": "To study network evolution models and different blockmodeling approaches. Various functions enable generating (temporal) networks with a selected blockmodel type, taking into account selected local network mechanisms. The development of this package is financially supported the Slovenian Research Agency (www.arrs.gov.si) within the research program P5<96>0168 and the research project J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).",
    "version": "1.00.01",
    "maintainer": "Marjan Cugmas <marjan.cugmas@fdv.uni-lj.si>",
    "author": "Marjan Cugmas [aut, cre],\n  Ale\u0161 \u017diberna [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nemBM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nemBM Using Network Evolution Models to Generate Networks with\nSelected Blockmodel Type To study network evolution models and different blockmodeling approaches. Various functions enable generating (temporal) networks with a selected blockmodel type, taking into account selected local network mechanisms. The development of this package is financially supported the Slovenian Research Agency (www.arrs.gov.si) within the research program P5<96>0168 and the research project J5-2557 (Comparison and evaluation of different approaches to blockmodeling dynamic networks by simulations with application to Slovenian co-authorship networks).  "
  },
  {
    "id": 16836,
    "package_name": "nets",
    "title": "Network Estimation for Time Series",
    "description": "Sparse VAR estimation based on LASSO.",
    "version": "0.9.1",
    "maintainer": "Christian Brownlees <christian.brownlees@upf.edu>",
    "author": "Christian Brownlees",
    "url": "https://github.com/ctbrownlees/R-Package-nets",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nets Network Estimation for Time Series Sparse VAR estimation based on LASSO.  "
  },
  {
    "id": 16837,
    "package_name": "netseer",
    "title": "Graph Prediction from a Graph Time Series",
    "description": "Predicting the structure of a graph including new nodes and edges using\n    a time series of graphs. Flux balance analysis, a linear and integer programming \n    technique used in biochemistry is used with time series prediction methods to \n    predict the graph structure at a future time point \n    Kandanaarachchi (2025) <doi:10.48550/arXiv.2507.05806>.",
    "version": "0.1.2",
    "maintainer": "Sevvandi Kandanaarachchi <sevvandik@gmail.com>",
    "author": "Sevvandi Kandanaarachchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0337-0395>),\n  Stefan Westerlund [aut]",
    "url": "https://sevvandi.github.io/netseer/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=netseer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netseer Graph Prediction from a Graph Time Series Predicting the structure of a graph including new nodes and edges using\n    a time series of graphs. Flux balance analysis, a linear and integer programming \n    technique used in biochemistry is used with time series prediction methods to \n    predict the graph structure at a future time point \n    Kandanaarachchi (2025) <doi:10.48550/arXiv.2507.05806>.  "
  },
  {
    "id": 16845,
    "package_name": "networkDynamic",
    "title": "Dynamic Extensions for Network Objects",
    "description": "Simple interface routines to facilitate the handling of network objects with complex intertemporal data. This is a part of the \"statnet\" suite of packages for network analysis.",
    "version": "0.11.5",
    "maintainer": "Skye Bender-deMoll <skyebend@uw.edu>",
    "author": "Carter T. Butts [aut],\n  Ayn Leslie-Cook [aut],\n  Pavel N. Krivitsky [aut],\n  Skye Bender-deMoll [aut, cre],\n  Zack Almquist [ctb],\n  David R. Hunter [ctb],\n  Li Wang [ctb],\n  Kirk Li [ctb],\n  Steven M. Goodreau [ctb],\n  Jeffrey Horner [ctb],\n  Martina Morris [ctb]",
    "url": "https://statnet.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=networkDynamic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "networkDynamic Dynamic Extensions for Network Objects Simple interface routines to facilitate the handling of network objects with complex intertemporal data. This is a part of the \"statnet\" suite of packages for network analysis.  "
  },
  {
    "id": 16854,
    "package_name": "neuRosim",
    "title": "Simulate fMRI Data",
    "description": "Generates functional Magnetic Resonance Imaging (fMRI) \n             time series or 4D data. Some high-level \n             functions are created for fast data generation with only \n             a few arguments and a diversity of functions to define \n             activation and noise. For more advanced users it is possible \n             to use the low-level functions and manipulate the arguments.\n             See Welvaert et al. (2011) <doi:10.18637/jss.v044.i10>.",
    "version": "0.2-14",
    "maintainer": "Karsten Tabelow <karsten.tabelow@wias-berlin.de>",
    "author": "Marijke Welvaert [aut],\n  Joke Durnez [ctb],\n  Beatrijs Moerkerke [ctb],\n  Yves Rosseel [ctb],\n  Karsten Tabelow [ctb, cre],\n  Geert Verdoolaege [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=neuRosim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "neuRosim Simulate fMRI Data Generates functional Magnetic Resonance Imaging (fMRI) \n             time series or 4D data. Some high-level \n             functions are created for fast data generation with only \n             a few arguments and a diversity of functions to define \n             activation and noise. For more advanced users it is possible \n             to use the low-level functions and manipulate the arguments.\n             See Welvaert et al. (2011) <doi:10.18637/jss.v044.i10>.  "
  },
  {
    "id": 16871,
    "package_name": "neverhpfilter",
    "title": "An Alternative to the Hodrick-Prescott Filter",
    "description": "In the working paper titled \"Why You Should Never Use the Hodrick-Prescott Filter\", James D. Hamilton proposes a new alternative to economic time series filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.",
    "version": "0.5-0",
    "maintainer": "Justin M. Shea <jshea01@uic.edu>",
    "author": "Justin M. Shea [aut, cre]",
    "url": "https://justinmshea.github.io/neverhpfilter/",
    "bug_reports": "https://github.com/JustinMShea/neverhpfilter/issues",
    "repository": "https://cran.r-project.org/package=neverhpfilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "neverhpfilter An Alternative to the Hodrick-Prescott Filter In the working paper titled \"Why You Should Never Use the Hodrick-Prescott Filter\", James D. Hamilton proposes a new alternative to economic time series filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.  "
  },
  {
    "id": 16882,
    "package_name": "nfer",
    "title": "Event Stream Abstraction using Interval Logic",
    "description": "This is the R API for the 'nfer' formalism (<http://nfer.io/>).\n    'nfer' was developed to specify event stream abstractions for spacecraft \n    telemetry such as the Mars Science Laboratory.  Users write rules using \n    a syntax that borrows heavily from Allen's Temporal Logic that, when \n    applied to an event stream, construct a hierarchy of temporal intervals \n    with data.  The R API supports loading rules from a file or mining them \n    from historical data.  Traces of events or pools of intervals are \n    provided as data frames.",
    "version": "1.1.3",
    "maintainer": "Sean Kauffman <seank@cs.aau.dk>",
    "author": "Sean Kauffman [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6341-3898>)",
    "url": "http://nfer.io/",
    "bug_reports": "https://bitbucket.org/seanmk/nfer/issues",
    "repository": "https://cran.r-project.org/package=nfer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nfer Event Stream Abstraction using Interval Logic This is the R API for the 'nfer' formalism (<http://nfer.io/>).\n    'nfer' was developed to specify event stream abstractions for spacecraft \n    telemetry such as the Mars Science Laboratory.  Users write rules using \n    a syntax that borrows heavily from Allen's Temporal Logic that, when \n    applied to an event stream, construct a hierarchy of temporal intervals \n    with data.  The R API supports loading rules from a file or mining them \n    from historical data.  Traces of events or pools of intervals are \n    provided as data frames.  "
  },
  {
    "id": 16890,
    "package_name": "ngboostForecast",
    "title": "Probabilistic Time Series Forecasting",
    "description": "Probabilistic time series forecasting via Natural Gradient Boosting for Probabilistic Prediction.",
    "version": "0.1.1",
    "maintainer": "Resul Akay <resulakay1@gmail.com>",
    "author": "Resul Akay [aut, cre]",
    "url": "https://github.com/Akai01/ngboostForecast",
    "bug_reports": "https://github.com/Akai01/ngboostForecast/issues",
    "repository": "https://cran.r-project.org/package=ngboostForecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ngboostForecast Probabilistic Time Series Forecasting Probabilistic time series forecasting via Natural Gradient Boosting for Probabilistic Prediction.  "
  },
  {
    "id": 16930,
    "package_name": "nixtlar",
    "title": "A Software Development Kit for 'Nixtla''s 'TimeGPT'",
    "description": "A Software Development Kit for working with 'Nixtla''s 'TimeGPT', a foundation\n    model for time series forecasting. 'API' is an acronym for 'application\n    programming interface'; this package allows users to interact with\n    'TimeGPT' via the 'API'. You can set and validate 'API' keys and generate forecasts\n    via 'API' calls. It is compatible with 'tsibble' and base R. For more details \n    visit <https://docs.nixtla.io/>.",
    "version": "0.6.2",
    "maintainer": "Mariana Menchero <mariana@nixtla.io>",
    "author": "Mariana Menchero [aut, cre] (First author and maintainer),\n  Nixtla [cph] (Copyright held by 'Nixtla')",
    "url": "https://nixtla.github.io/nixtlar/, https://docs.nixtla.io/,\nhttps://github.com/Nixtla/nixtlar",
    "bug_reports": "https://github.com/Nixtla/nixtlar/issues",
    "repository": "https://cran.r-project.org/package=nixtlar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nixtlar A Software Development Kit for 'Nixtla''s 'TimeGPT' A Software Development Kit for working with 'Nixtla''s 'TimeGPT', a foundation\n    model for time series forecasting. 'API' is an acronym for 'application\n    programming interface'; this package allows users to interact with\n    'TimeGPT' via the 'API'. You can set and validate 'API' keys and generate forecasts\n    via 'API' calls. It is compatible with 'tsibble' and base R. For more details \n    visit <https://docs.nixtla.io/>.  "
  },
  {
    "id": 16972,
    "package_name": "nlts",
    "title": "Nonlinear Time Series Analysis",
    "description": "R functions for (non)linear time series analysis with an emphasis on nonparametric autoregression and order estimation, and tests for linearity / additivity.",
    "version": "1.0-2",
    "maintainer": "Ottar N. Bjornstad <onb1@psu.edu>",
    "author": "Ottar N. Bjornstad [aut, cre]",
    "url": "http://ento.psu.edu/directory/onb1",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nlts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nlts Nonlinear Time Series Analysis R functions for (non)linear time series analysis with an emphasis on nonparametric autoregression and order estimation, and tests for linearity / additivity.  "
  },
  {
    "id": 16989,
    "package_name": "nnfor",
    "title": "Time Series Forecasting with Neural Networks",
    "description": "Automatic time series modelling with neural networks. \n    Allows fully automatic, semi-manual or fully manual specification of networks. For details of the\n\tspecification methodology see: (i) Crone and Kourentzes (2010) <doi:10.1016/j.neucom.2010.01.017>;\n\tand (ii) Kourentzes et al. (2014) <doi:10.1016/j.eswa.2013.12.011>.",
    "version": "0.9.9",
    "maintainer": "Nikolaos Kourentzes <nikolaos@kourentzes.com>",
    "author": "Nikolaos Kourentzes [aut, cre]",
    "url": "https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/",
    "bug_reports": "https://github.com/trnnick/nnfor/issues",
    "repository": "https://cran.r-project.org/package=nnfor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nnfor Time Series Forecasting with Neural Networks Automatic time series modelling with neural networks. \n    Allows fully automatic, semi-manual or fully manual specification of networks. For details of the\n\tspecification methodology see: (i) Crone and Kourentzes (2010) <doi:10.1016/j.neucom.2010.01.017>;\n\tand (ii) Kourentzes et al. (2014) <doi:10.1016/j.eswa.2013.12.011>.  "
  },
  {
    "id": 17025,
    "package_name": "nonlinearTseries",
    "title": "Nonlinear Time Series Analysis",
    "description": "Functions for nonlinear time series analysis. This package permits\n    the computation of the  most-used nonlinear statistics/algorithms\n    including generalized correlation dimension, information dimension,\n    largest Lyapunov exponent, sample entropy and Recurrence\n    Quantification Analysis (RQA), among others. Basic routines\n    for surrogate data testing are also included. Part of this work\n    was based on the  book \"Nonlinear time series analysis\" by\n    Holger Kantz and Thomas Schreiber (ISBN: 9780521529020).",
    "version": "0.3.1",
    "maintainer": "Constantino A. Garcia <constantino.garciama@ceu.es>",
    "author": "Constantino A. Garcia [aut, cre],\n  Gunther Sawitzki [ctb]",
    "url": "https://github.com/constantino-garcia/nonlinearTseries",
    "bug_reports": "https://github.com/constantino-garcia/nonlinearTseries/issues",
    "repository": "https://cran.r-project.org/package=nonlinearTseries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nonlinearTseries Nonlinear Time Series Analysis Functions for nonlinear time series analysis. This package permits\n    the computation of the  most-used nonlinear statistics/algorithms\n    including generalized correlation dimension, information dimension,\n    largest Lyapunov exponent, sample entropy and Recurrence\n    Quantification Analysis (RQA), among others. Basic routines\n    for surrogate data testing are also included. Part of this work\n    was based on the  book \"Nonlinear time series analysis\" by\n    Holger Kantz and Thomas Schreiber (ISBN: 9780521529020).  "
  },
  {
    "id": 17037,
    "package_name": "nonstat",
    "title": "Detecting Nonstationarity in Time Series",
    "description": "Provides a nonvisual procedure for screening time series for nonstationarity in the context of intensive longitudinal designs, such as ecological momentary assessments. The method combines two diagnostics: one for detecting trends (based on the split R-hat statistic from Bayesian convergence diagnostics) and one for detecting changes in variance (a novel extension inspired by Levene's test). This approach allows researchers to efficiently and reproducibly detect violations of the stationarity assumption, especially when visual inspection of many individual time series is impractical. The procedure is suitable for use in all areas of research where time series analysis is central. For a detailed description of the method and its validation through simulations and empirical application, see Zitzmann, S., Lindner, C., Lohmann, J. F., & Hecht, M. (2024) \"A Novel Nonvisual Procedure for Screening for Nonstationarity in Time Series as Obtained from Intensive Longitudinal Designs\" <https://www.researchgate.net/publication/384354932_A_Novel_Nonvisual_Procedure_for_Screening_for_Nonstationarity_in_Time_Series_as_Obtained_from_Intensive_Longitudinal_Designs>.",
    "version": "0.0.6",
    "maintainer": "Martin Hecht <martin.hecht@hsu-hh.de>",
    "author": "Martin Hecht [aut, cre],\n  Steffen Zitzmann [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nonstat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nonstat Detecting Nonstationarity in Time Series Provides a nonvisual procedure for screening time series for nonstationarity in the context of intensive longitudinal designs, such as ecological momentary assessments. The method combines two diagnostics: one for detecting trends (based on the split R-hat statistic from Bayesian convergence diagnostics) and one for detecting changes in variance (a novel extension inspired by Levene's test). This approach allows researchers to efficiently and reproducibly detect violations of the stationarity assumption, especially when visual inspection of many individual time series is impractical. The procedure is suitable for use in all areas of research where time series analysis is central. For a detailed description of the method and its validation through simulations and empirical application, see Zitzmann, S., Lindner, C., Lohmann, J. F., & Hecht, M. (2024) \"A Novel Nonvisual Procedure for Screening for Nonstationarity in Time Series as Obtained from Intensive Longitudinal Designs\" <https://www.researchgate.net/publication/384354932_A_Novel_Nonvisual_Procedure_for_Screening_for_Nonstationarity_in_Time_Series_as_Obtained_from_Intensive_Longitudinal_Designs>.  "
  },
  {
    "id": 17044,
    "package_name": "normaliseR",
    "title": "Re-Scale Vectors and Time-Series Features",
    "description": "Provides standardized access to a range of re-scaling methods for numerical vectors\n    and time-series features calculated within the 'theft' ecosystem.",
    "version": "0.1.2",
    "maintainer": "Trent Henderson <then6675@uni.sydney.edu.au>",
    "author": "Trent Henderson [cre, aut]",
    "url": "https://hendersontrent.github.io/normaliseR/",
    "bug_reports": "https://github.com/hendersontrent/normaliseR/issues",
    "repository": "https://cran.r-project.org/package=normaliseR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "normaliseR Re-Scale Vectors and Time-Series Features Provides standardized access to a range of re-scaling methods for numerical vectors\n    and time-series features calculated within the 'theft' ecosystem.  "
  },
  {
    "id": 17053,
    "package_name": "nortsTest",
    "title": "Assessing Normality of Stationary Process",
    "description": "Despite that several tests for normality in stationary processes have been proposed in the literature, consistent implementations of these tests in programming languages are limited. Seven normality test are implemented. The asymptotic Lobato & Velasco's, asymptotic Epps, Psaradakis and  V\u00e1vra, Lobato & Velasco's and Epps sieve bootstrap approximations, El bouch et al., and the random projections tests for univariate stationary process. Some other diagnostics such as, unit root test for  stationarity, seasonal tests for seasonality, and arch effect test for volatility; are also performed. Additionally, the El bouch test performs normality tests for bivariate time series. The package also offers residual diagnostic for linear time series models developed in several packages.",
    "version": "1.1.3",
    "maintainer": "Asael Alonzo Matamoros <asael.alonzo@gmail.com>",
    "author": "Asael Alonzo Matamoros [aut, cre],\n  Alicia Nieto-Reyes [aut],\n  Rob Hyndman [ctb],\n  Mitchell O'Hara-Wild [ctb],\n  Trapletti A. [ctb]",
    "url": "https://github.com/asael697/nortsTest",
    "bug_reports": "https://github.com/asael697/nortsTest/issues",
    "repository": "https://cran.r-project.org/package=nortsTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nortsTest Assessing Normality of Stationary Process Despite that several tests for normality in stationary processes have been proposed in the literature, consistent implementations of these tests in programming languages are limited. Seven normality test are implemented. The asymptotic Lobato & Velasco's, asymptotic Epps, Psaradakis and  V\u00e1vra, Lobato & Velasco's and Epps sieve bootstrap approximations, El bouch et al., and the random projections tests for univariate stationary process. Some other diagnostics such as, unit root test for  stationarity, seasonal tests for seasonality, and arch effect test for volatility; are also performed. Additionally, the El bouch test performs normality tests for bivariate time series. The package also offers residual diagnostic for linear time series models developed in several packages.  "
  },
  {
    "id": 17098,
    "package_name": "npphen",
    "title": "Vegetation Phenological Cycle and Anomaly Detection using Remote\nSensing Data",
    "description": "Calculates phenological cycle and anomalies using a non-parametric\n    approach applied to time series of vegetation indices derived from remote sensing data \n    or field measurements. The package implements basic and high-level functions for \n    manipulating vector data (numerical series) and raster data (satellite derived products).\n    Processing of very large raster files is supported. For more information, please check \n    the following paper:\n    Ch\u00e1vez et al. (2023) <doi:10.3390/rs15010073>.",
    "version": "2.0.1",
    "maintainer": "Jos\u00e9 A. Lastra <jose.lastra@pucv.cl>",
    "author": "Roberto O. Ch\u00e1vez [aut] (ORCID:\n    <https://orcid.org/0000-0001-6782-3579>),\n  Sergio A. Estay [aut] (ORCID: <https://orcid.org/0000-0002-3797-8964>),\n  Jos\u00e9 A. Lastra [cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-6159-2201>),\n  Carlos G. Riquelme [ctb] (ORCID:\n    <https://orcid.org/0000-0003-4861-8355>)",
    "url": "https://github.com/labGRS/npphen, https://labgrs.github.io/npphen/",
    "bug_reports": "https://github.com/labGRS/npphen/issues",
    "repository": "https://cran.r-project.org/package=npphen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "npphen Vegetation Phenological Cycle and Anomaly Detection using Remote\nSensing Data Calculates phenological cycle and anomalies using a non-parametric\n    approach applied to time series of vegetation indices derived from remote sensing data \n    or field measurements. The package implements basic and high-level functions for \n    manipulating vector data (numerical series) and raster data (satellite derived products).\n    Processing of very large raster files is supported. For more information, please check \n    the following paper:\n    Ch\u00e1vez et al. (2023) <doi:10.3390/rs15010073>.  "
  },
  {
    "id": 17107,
    "package_name": "npsp",
    "title": "Nonparametric Spatial Statistics",
    "description": "Multidimensional nonparametric spatial (spatio-temporal) geostatistics.\n    S3 classes and methods for multidimensional: linear binning,\n    local polynomial kernel regression (spatial trend estimation), density and variogram estimation.\n    Nonparametric methods for simultaneous inference on both spatial trend\n    and variogram functions (for spatial processes).\n    Nonparametric residual kriging (spatial prediction).\n    For details on these methods see, for example, Fernandez-Casal and Francisco-Fernandez (2014) \n    <doi:10.1007/s00477-013-0817-8> or Castillo-Paez et al. (2019) <doi:10.1016/j.csda.2019.01.017>.",
    "version": "0.7-13",
    "maintainer": "Ruben Fernandez-Casal <rubenfcasal@gmail.com>",
    "author": "Ruben Fernandez-Casal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5785-3739>)",
    "url": "https://rubenfcasal.github.io/npsp/,\nhttps://github.com/rubenfcasal/npsp/",
    "bug_reports": "https://github.com/rubenfcasal/npsp/issues/",
    "repository": "https://cran.r-project.org/package=npsp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "npsp Nonparametric Spatial Statistics Multidimensional nonparametric spatial (spatio-temporal) geostatistics.\n    S3 classes and methods for multidimensional: linear binning,\n    local polynomial kernel regression (spatial trend estimation), density and variogram estimation.\n    Nonparametric methods for simultaneous inference on both spatial trend\n    and variogram functions (for spatial processes).\n    Nonparametric residual kriging (spatial prediction).\n    For details on these methods see, for example, Fernandez-Casal and Francisco-Fernandez (2014) \n    <doi:10.1007/s00477-013-0817-8> or Castillo-Paez et al. (2019) <doi:10.1016/j.csda.2019.01.017>.  "
  },
  {
    "id": 17154,
    "package_name": "oHMMed",
    "title": "HMMs with Ordered Hidden States and Emission Densities",
    "description": "Inference using a class of Hidden Markov models\n    (HMMs) called 'oHMMed'(ordered HMM with emission densities \n    <doi:10.1186/s12859-024-05751-4>): The 'oHMMed' algorithms identify \n    the number of comparably homogeneous regions within observed sequences\n    with autocorrelation patterns. These are modelled as discrete hidden\n    states; the observed data points are then realisations of continuous\n    probability distributions with state-specific means that enable\n    ordering of these distributions. The observed sequence is labelled\n    according to the hidden states, permitting only neighbouring states\n    that are also neighbours within the ordering of their associated\n    distributions. The parameters that characterise these state-specific\n    distributions are then inferred. Relevant for application to genomic\n    sequences, time series, or any other sequence data with serial\n    autocorrelation.",
    "version": "1.0.2",
    "maintainer": "Michal Majka <michalmajka@hotmail.com>",
    "author": "Michal Majka [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7524-8014>),\n  Lynette Caitlin Mikula [aut] (ORCID:\n    <https://orcid.org/0000-0002-0252-4014>),\n  Claus Vogl [aut] (ORCID: <https://orcid.org/0000-0002-3996-7863>)",
    "url": "https://github.com/LynetteCaitlin/oHMMed,\nhttps://lynettecaitlin.github.io/oHMMed/",
    "bug_reports": "https://github.com/LynetteCaitlin/oHMMed/issues",
    "repository": "https://cran.r-project.org/package=oHMMed",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oHMMed HMMs with Ordered Hidden States and Emission Densities Inference using a class of Hidden Markov models\n    (HMMs) called 'oHMMed'(ordered HMM with emission densities \n    <doi:10.1186/s12859-024-05751-4>): The 'oHMMed' algorithms identify \n    the number of comparably homogeneous regions within observed sequences\n    with autocorrelation patterns. These are modelled as discrete hidden\n    states; the observed data points are then realisations of continuous\n    probability distributions with state-specific means that enable\n    ordering of these distributions. The observed sequence is labelled\n    according to the hidden states, permitting only neighbouring states\n    that are also neighbours within the ordering of their associated\n    distributions. The parameters that characterise these state-specific\n    distributions are then inferred. Relevant for application to genomic\n    sequences, time series, or any other sequence data with serial\n    autocorrelation.  "
  },
  {
    "id": 17155,
    "package_name": "oRaklE",
    "title": "Multi-Horizon Electricity Demand Forecasting in High Resolution",
    "description": "Advanced forecasting algorithms for long-term energy demand at the \n  national or regional level. The methodology is based on Grand\u00f3n et al. (2024) \n  <doi:10.1016/j.apenergy.2023.122249>; Zimmermann & Ziel (2024) \n  <doi:10.1016/j.apenergy.2025.125444>. Real-time data, including power demand, weather conditions, and macroeconomic indicators, are provided through automated API integration with various institutions. The modular approach maintains transparency on the various model selection processes and encompasses the ability to be adapted to individual needs. 'oRaklE' tries to help facilitating robust decision-making in energy management and planning.",
    "version": "1.0.2",
    "maintainer": "Johannes Schwenzer <schwenzer@europa-uni.de>",
    "author": "Johannes Schwenzer [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0006-9618-8889>),\n  Simone Maxand [aut] (ORCID: <https://orcid.org/0000-0002-3153-7922>),\n  Tatiana Gonzalez Grand\u00f3n [aut] (ORCID:\n    <https://orcid.org/0000-0001-6587-0144>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=oRaklE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oRaklE Multi-Horizon Electricity Demand Forecasting in High Resolution Advanced forecasting algorithms for long-term energy demand at the \n  national or regional level. The methodology is based on Grand\u00f3n et al. (2024) \n  <doi:10.1016/j.apenergy.2023.122249>; Zimmermann & Ziel (2024) \n  <doi:10.1016/j.apenergy.2025.125444>. Real-time data, including power demand, weather conditions, and macroeconomic indicators, are provided through automated API integration with various institutions. The modular approach maintains transparency on the various model selection processes and encompasses the ability to be adapted to individual needs. 'oRaklE' tries to help facilitating robust decision-making in energy management and planning.  "
  },
  {
    "id": 17177,
    "package_name": "oce",
    "title": "Analysis of Oceanographic Data",
    "description": "Supports the analysis of Oceanographic data, including 'ADCP'\n    measurements, measurements made with 'argo' floats, 'CTD' measurements,\n    sectional data, sea-level time series, coastline and topographic data, etc.\n    Provides specialized functions for calculating seawater properties such as\n    potential temperature in either the 'UNESCO' or 'TEOS-10' equation of state.\n    Produces graphical displays that conform to the conventions of the\n    Oceanographic literature. This package is discussed extensively by\n    Kelley (2018) \"Oceanographic Analysis with R\" <doi:10.1007/978-1-4939-8844-0>.",
    "version": "1.8-3",
    "maintainer": "Dan Kelley <Dan.Kelley@Dal.Ca>",
    "author": "Dan Kelley [aut, cre] (ORCID: <https://orcid.org/0000-0001-7808-5911>),\n  Clark Richards [aut] (ORCID: <https://orcid.org/0000-0002-7833-206X>),\n  Chantelle Layton [ctb] (ORCID: <https://orcid.org/0000-0002-3199-5763>,\n    curl() coauthor),\n  British Geological Survey [ctb, cph] (magnetic-field subroutine)",
    "url": "https://dankelley.github.io/oce/",
    "bug_reports": "https://github.com/dankelley/oce/issues",
    "repository": "https://cran.r-project.org/package=oce",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oce Analysis of Oceanographic Data Supports the analysis of Oceanographic data, including 'ADCP'\n    measurements, measurements made with 'argo' floats, 'CTD' measurements,\n    sectional data, sea-level time series, coastline and topographic data, etc.\n    Provides specialized functions for calculating seawater properties such as\n    potential temperature in either the 'UNESCO' or 'TEOS-10' equation of state.\n    Produces graphical displays that conform to the conventions of the\n    Oceanographic literature. This package is discussed extensively by\n    Kelley (2018) \"Oceanographic Analysis with R\" <doi:10.1007/978-1-4939-8844-0>.  "
  },
  {
    "id": 17197,
    "package_name": "oddnet",
    "title": "Anomaly Detection in Temporal Networks",
    "description": "Anomaly detection in dynamic, temporal networks. The package \n    'oddnet' uses a feature-based method to identify anomalies. First, it computes \n    many features for each network. Then it models the features using time series \n    methods. Using time series residuals it detects anomalies. This way, the \n    temporal dependencies are accounted for when identifying anomalies \n    (Kandanaarachchi, Hyndman 2022) <arXiv:2210.07407>.",
    "version": "0.1.1",
    "maintainer": "Sevvandi Kandanaarachchi <sevvandik@gmail.com>",
    "author": "Sevvandi Kandanaarachchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0337-0395>),\n  Rob Hyndman [aut] (ORCID: <https://orcid.org/0000-0002-2140-5352>)",
    "url": "https://sevvandi.github.io/oddnet/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=oddnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oddnet Anomaly Detection in Temporal Networks Anomaly detection in dynamic, temporal networks. The package \n    'oddnet' uses a feature-based method to identify anomalies. First, it computes \n    many features for each network. Then it models the features using time series \n    methods. Using time series residuals it detects anomalies. This way, the \n    temporal dependencies are accounted for when identifying anomalies \n    (Kandanaarachchi, Hyndman 2022) <arXiv:2210.07407>.  "
  },
  {
    "id": 17202,
    "package_name": "oddstream",
    "title": "Outlier Detection in Data Streams",
    "description": "We proposes a framework that provides real time support for early detection of\n    anomalous series within a large collection of streaming time series data. By definition, anomalies\n    are rare in comparison to a system's typical behaviour. We define an anomaly as an observation that\n    is very unlikely given the forecast distribution. The algorithm first forecasts a boundary for the\n    system's typical behaviour using a representative sample of the typical behaviour of the system. An\n    approach based on extreme value theory is used for this boundary prediction process. Then a sliding\n    window is used to test for anomalous series within the newly arrived collection of series. Feature\n    based representation of time series is used as the input to the model. To cope with concept drift,\n    the forecast boundary for the system's typical behaviour is updated periodically.  More details\n    regarding the algorithm can be found in Talagala, P. D., Hyndman, R. J., Smith-Miles, K., et al.\n    (2019) <doi:10.1080/10618600.2019.1617160>.",
    "version": "0.5.0",
    "maintainer": "Priyanga Dilini Talagala <pritalagala@gmail.com>",
    "author": "Priyanga Dilini Talagala [aut, cre],\n  Rob J. Hyndman [ths],\n  Kate Smith-Miles [ths]",
    "url": "",
    "bug_reports": "https://github.com/pridiltal/oddstream/issues",
    "repository": "https://cran.r-project.org/package=oddstream",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oddstream Outlier Detection in Data Streams We proposes a framework that provides real time support for early detection of\n    anomalous series within a large collection of streaming time series data. By definition, anomalies\n    are rare in comparison to a system's typical behaviour. We define an anomaly as an observation that\n    is very unlikely given the forecast distribution. The algorithm first forecasts a boundary for the\n    system's typical behaviour using a representative sample of the typical behaviour of the system. An\n    approach based on extreme value theory is used for this boundary prediction process. Then a sliding\n    window is used to test for anomalous series within the newly arrived collection of series. Feature\n    based representation of time series is used as the input to the model. To cope with concept drift,\n    the forecast boundary for the system's typical behaviour is updated periodically.  More details\n    regarding the algorithm can be found in Talagala, P. D., Hyndman, R. J., Smith-Miles, K., et al.\n    (2019) <doi:10.1080/10618600.2019.1617160>.  "
  },
  {
    "id": 17217,
    "package_name": "offlineChange",
    "title": "Detect Multiple Change Points from Time Series",
    "description": "Detect the number and locations of change points. The locations can be either exact or in terms of ranges, \n            depending on the available computational resource. The method is based on Jie Ding, Yu Xiang, Lu Shen, Vahid Tarokh (2017) <doi:10.1109/TSP.2017.2711558>.",
    "version": "0.0.4",
    "maintainer": "Jiahuan Ye <jiahuanye431@gmail.com>",
    "author": "Jiahuan Ye [aut, trl, cre],\n  Jie Ding [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=offlineChange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "offlineChange Detect Multiple Change Points from Time Series Detect the number and locations of change points. The locations can be either exact or in terms of ranges, \n            depending on the available computational resource. The method is based on Jie Ding, Yu Xiang, Lu Shen, Vahid Tarokh (2017) <doi:10.1109/TSP.2017.2711558>.  "
  },
  {
    "id": 17224,
    "package_name": "ohsome",
    "title": "An 'ohsome API' Client",
    "description": "A client that grants access to the power of the 'ohsome API'\n    from R. It lets you analyze the rich data source of the \n    'OpenStreetMap (OSM)' history. You can retrieve the geometry of 'OSM' \n    data at specific points in time, and you can get aggregated statistics \n    on the evolution of 'OSM' elements and specify your own temporal, \n    spatial and/or thematic filters.",
    "version": "0.2.2",
    "maintainer": "Oliver Fritz <oliver.fritz@heigit.org>",
    "author": "Heidelberg Institute for Geoinformation Technology (HeiGIT) gGmbH [cph],\n  Oliver Fritz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6324-7295>)",
    "url": "https://github.com/GIScience/ohsome-r,https://docs.ohsome.org/ohsome-api/stable/",
    "bug_reports": "https://github.com/GIScience/ohsome-r/issues",
    "repository": "https://cran.r-project.org/package=ohsome",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ohsome An 'ohsome API' Client A client that grants access to the power of the 'ohsome API'\n    from R. It lets you analyze the rich data source of the \n    'OpenStreetMap (OSM)' history. You can retrieve the geometry of 'OSM' \n    data at specific points in time, and you can get aggregated statistics \n    on the evolution of 'OSM' elements and specify your own temporal, \n    spatial and/or thematic filters.  "
  },
  {
    "id": 17262,
    "package_name": "onlineCOV",
    "title": "Online Change Point Detection in High-Dimensional Covariance\nStructure",
    "description": "Implement a new stopping rule to detect anomaly in the covariance structure of high-dimensional online data. The detection procedure can be applied to Gaussian or non-Gaussian data with a large number of components. Moreover, it allows both spatial and temporal dependence in data. The dependence can be estimated by a data-driven procedure. The level of threshold in the stopping rule can be determined at a pre-selected average run length. More detail can be seen in Li, L. and Li, J. (2020) \"Online Change-Point Detection in High-Dimensional Covariance Structure with Application to Dynamic Networks.\" <arXiv:1911.07762>.",
    "version": "1.3",
    "maintainer": "Jun Li <jli49@kent.edu>",
    "author": "Lingjun Li and Jun Li",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=onlineCOV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "onlineCOV Online Change Point Detection in High-Dimensional Covariance\nStructure Implement a new stopping rule to detect anomaly in the covariance structure of high-dimensional online data. The detection procedure can be applied to Gaussian or non-Gaussian data with a large number of components. Moreover, it allows both spatial and temporal dependence in data. The dependence can be estimated by a data-driven procedure. The level of threshold in the stopping rule can be determined at a pre-selected average run length. More detail can be seen in Li, L. and Li, J. (2020) \"Online Change-Point Detection in High-Dimensional Covariance Structure with Application to Dynamic Networks.\" <arXiv:1911.07762>.  "
  },
  {
    "id": 17264,
    "package_name": "onlineforecast",
    "title": "Forecast Modelling for Online Applications",
    "description": "A framework for fitting adaptive forecasting models. Provides a way to use forecasts as input to models, e.g. weather forecasts for energy related forecasting. The models can be fitted recursively and can easily be setup for updating parameters when new data arrives. See the included vignettes, the website <https://onlineforecasting.org> and the paper \"onlineforecast: An R package for adaptive and recursive forecasting\" <https://journal.r-project.org/articles/RJ-2023-031/>.",
    "version": "1.0.2",
    "maintainer": "Peder Bacher <pbac@dtu.dk>",
    "author": "Peder Bacher [cre],\n  Hjorleifur G Bergsteinsson [aut]",
    "url": "https://onlineforecasting.org",
    "bug_reports": "https://lab.compute.dtu.dk/packages/onlineforecast/-/issues",
    "repository": "https://cran.r-project.org/package=onlineforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "onlineforecast Forecast Modelling for Online Applications A framework for fitting adaptive forecasting models. Provides a way to use forecasts as input to models, e.g. weather forecasts for energy related forecasting. The models can be fitted recursively and can easily be setup for updating parameters when new data arrives. See the included vignettes, the website <https://onlineforecasting.org> and the paper \"onlineforecast: An R package for adaptive and recursive forecasting\" <https://journal.r-project.org/articles/RJ-2023-031/>.  "
  },
  {
    "id": 17297,
    "package_name": "openair",
    "title": "Tools for the Analysis of Air Pollution Data",
    "description": "Tools to analyse, interpret and understand air pollution\n    data. Data are typically regular time series and air quality\n    measurement, meteorological data and dispersion model output can be\n    analysed. The package is described in Carslaw and Ropkins (2012,\n    <doi:10.1016/j.envsoft.2011.09.008>) and subsequent papers.",
    "version": "2.19.0",
    "maintainer": "David Carslaw <david.carslaw@york.ac.uk>",
    "author": "David Carslaw [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0991-950X>),\n  Jack Davison [aut] (ORCID: <https://orcid.org/0000-0003-2653-6615>),\n  Karl Ropkins [aut] (ORCID: <https://orcid.org/0000-0002-0294-6997>)",
    "url": "https://openair-project.github.io/openair/,\nhttps://github.com/openair-project/openair",
    "bug_reports": "https://github.com/openair-project/openair/issues",
    "repository": "https://cran.r-project.org/package=openair",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "openair Tools for the Analysis of Air Pollution Data Tools to analyse, interpret and understand air pollution\n    data. Data are typically regular time series and air quality\n    measurement, meteorological data and dispersion model output can be\n    analysed. The package is described in Carslaw and Ropkins (2012,\n    <doi:10.1016/j.envsoft.2011.09.008>) and subsequent papers.  "
  },
  {
    "id": 17391,
    "package_name": "ordinalpattern",
    "title": "Tests Based on Ordinal Patterns",
    "description": "Ordinal patterns describe the dynamics of a time series by looking at the ranks of subsequent observations. By comparing ordinal patterns of two times series, Schnurr (2014) <doi:10.1007/s00362-013-0536-8> defines a robust and non-parametric dependence measure: the ordinal pattern coefficient. Functions to calculate this and a method to detect a change in the pattern coefficient proposed in Schnurr and Dehling (2017) <doi:10.1080/01621459.2016.1164706> are provided. Furthermore, the package contains a function for calculating the ordinal pattern frequencies. Generalized ordinal patterns as proposed by Schnurr and Fischer (2022) <doi:10.1016/j.csda.2022.107472> are also considered.",
    "version": "0.2.7",
    "maintainer": "Angelika Silbernagel <silbernagel@hsu-hh.de>",
    "author": "Alexander Duerre [aut],\n  Svenja Fischer [ctb],\n  Alexander Schnurr [aut],\n  Angelika Silbernagel [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ordinalpattern",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ordinalpattern Tests Based on Ordinal Patterns Ordinal patterns describe the dynamics of a time series by looking at the ranks of subsequent observations. By comparing ordinal patterns of two times series, Schnurr (2014) <doi:10.1007/s00362-013-0536-8> defines a robust and non-parametric dependence measure: the ordinal pattern coefficient. Functions to calculate this and a method to detect a change in the pattern coefficient proposed in Schnurr and Dehling (2017) <doi:10.1080/01621459.2016.1164706> are provided. Furthermore, the package contains a function for calculating the ordinal pattern frequencies. Generalized ordinal patterns as proposed by Schnurr and Fischer (2022) <doi:10.1016/j.csda.2022.107472> are also considered.  "
  },
  {
    "id": 17399,
    "package_name": "organik",
    "title": "Multi-Horizon Probabilistic Ensemble with Copulas for Time\nSeries Forecasting",
    "description": "Trains per-horizon probabilistic ensembles from a univariate time series. It supports 'rpart', 'glmnet', and 'kNN' engines with flexible residual distributions and heteroscedastic scale models, weighting variants by calibration-aware scores. A Gaussian/t copula couples the marginals to simulate joint forecast paths, returning quantiles, means, and step increments across horizons.",
    "version": "1.0.1",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/organik",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=organik",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "organik Multi-Horizon Probabilistic Ensemble with Copulas for Time\nSeries Forecasting Trains per-horizon probabilistic ensembles from a univariate time series. It supports 'rpart', 'glmnet', and 'kNN' engines with flexible residual distributions and heteroscedastic scale models, weighting variants by calibration-aware scores. A Gaussian/t copula couples the marginals to simulate joint forecast paths, returning quantiles, means, and step increments across horizons.  "
  },
  {
    "id": 17435,
    "package_name": "otsfeatures",
    "title": "Ordinal Time Series Analysis",
    "description": "An implementation of several functions for feature extraction in \n    ordinal time series datasets. Specifically, some of the features proposed by\n    Weiss (2019) <doi:10.1080/01621459.2019.1604370> can be computed.  \n    These features can be used to perform inferential tasks or to feed machine\n    learning algorithms for ordinal time series, among others. The package also includes some\n    interesting datasets containing financial time series. Practitioners from a \n    broad variety of fields could benefit from the general framework provided \n    by 'otsfeatures'.",
    "version": "1.0.0",
    "maintainer": "Angel Lopez-Oriona <oriona38@hotmail.com>",
    "author": "Angel Lopez-Oriona [aut, cre],\n  Jose A. Vilar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=otsfeatures",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "otsfeatures Ordinal Time Series Analysis An implementation of several functions for feature extraction in \n    ordinal time series datasets. Specifically, some of the features proposed by\n    Weiss (2019) <doi:10.1080/01621459.2019.1604370> can be computed.  \n    These features can be used to perform inferential tasks or to feed machine\n    learning algorithms for ordinal time series, among others. The package also includes some\n    interesting datasets containing financial time series. Practitioners from a \n    broad variety of fields could benefit from the general framework provided \n    by 'otsfeatures'.  "
  },
  {
    "id": 17445,
    "package_name": "outliers.ts.oga",
    "title": "Efficient Outlier Detection for Large Time Series Databases",
    "description": "Programs for detecting and cleaning outliers in single time series and in time series from homogeneous and heterogeneous databases using an Orthogonal Greedy Algorithm (OGA) for saturated linear regression models. The programs implement the procedures presented in the paper entitled \"Efficient Outlier Detection for Large Time Series Databases\" by Pedro Galeano, Daniel Pe\u00f1a and Ruey S. Tsay (2025), working paper, Universidad Carlos III de Madrid. Version 1.1.1 contains some improvements in parallelization with respect to version 1.0.1.",
    "version": "1.1.1",
    "maintainer": "Pedro Galeano <pedro.galeano@uc3m.es>",
    "author": "Pedro Galeano [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2577-2747>),\n  Daniel Pe\u00f1a [aut] (ORCID: <https://orcid.org/0000-0002-9137-1557>),\n  Ruey S. Tsay [aut] (ORCID: <https://orcid.org/0000-0002-4949-4035>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=outliers.ts.oga",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "outliers.ts.oga Efficient Outlier Detection for Large Time Series Databases Programs for detecting and cleaning outliers in single time series and in time series from homogeneous and heterogeneous databases using an Orthogonal Greedy Algorithm (OGA) for saturated linear regression models. The programs implement the procedures presented in the paper entitled \"Efficient Outlier Detection for Large Time Series Databases\" by Pedro Galeano, Daniel Pe\u00f1a and Ruey S. Tsay (2025), working paper, Universidad Carlos III de Madrid. Version 1.1.1 contains some improvements in parallelization with respect to version 1.0.1.  "
  },
  {
    "id": 17450,
    "package_name": "overlap",
    "title": "Estimates of Coefficient of Overlapping for Animal Activity\nPatterns",
    "description": "Provides functions to fit kernel density functions to\n    data on temporal activity patterns of animals; estimate coefficients\n    of overlapping of densities for two species; and calculate bootstrap\n    estimates of confidence intervals. As in Ridout and Linkie (2009) <doi:10.1198/jabes.2009.08038>.",
    "version": "0.3.9",
    "maintainer": "Liz A.D. Campbell <lizadcampbell@gmail.com>",
    "author": "Mike Meredith [aut],\n  Martin Ridout [aut],\n  Liz A.D. Campbell [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8302-7430>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=overlap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "overlap Estimates of Coefficient of Overlapping for Animal Activity\nPatterns Provides functions to fit kernel density functions to\n    data on temporal activity patterns of animals; estimate coefficients\n    of overlapping of densities for two species; and calculate bootstrap\n    estimates of confidence intervals. As in Ridout and Linkie (2009) <doi:10.1198/jabes.2009.08038>.  "
  },
  {
    "id": 17474,
    "package_name": "pEPA",
    "title": "Tests of Equal Predictive Accuracy for Panels of Forecasts",
    "description": "Allows to perform the tests of equal predictive accuracy for panels of forecasts. Main references: Qu et al. (2024) <doi:10.1016/j.ijforecast.2023.08.001> and Akgun et al. (2024) <doi:10.1016/j.ijforecast.2023.02.001>. ",
    "version": "1.2",
    "maintainer": "Krzysztof Drachal <kdrachal@wne.uw.edu.pl>",
    "author": "Krzysztof Drachal [aut, cre] (Faculty of Economic Sciences, University\n    of Warsaw, Poland)",
    "url": "https://CRAN.R-project.org/package=pEPA",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pEPA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pEPA Tests of Equal Predictive Accuracy for Panels of Forecasts Allows to perform the tests of equal predictive accuracy for panels of forecasts. Main references: Qu et al. (2024) <doi:10.1016/j.ijforecast.2023.08.001> and Akgun et al. (2024) <doi:10.1016/j.ijforecast.2023.02.001>.   "
  },
  {
    "id": 17483,
    "package_name": "pRSR",
    "title": "Test of Periodicity using Response Surface Regression",
    "description": "Tests periodicity in short time series using response surface regression.",
    "version": "3.1.1",
    "maintainer": "M. S. Islam <shahed-sta@sust.edu>",
    "author": "M. S. Islam",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pRSR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pRSR Test of Periodicity using Response Surface Regression Tests periodicity in short time series using response surface regression.  "
  },
  {
    "id": 17526,
    "package_name": "paleoDiv",
    "title": "Extracting and Visualizing Paleobiodiversity",
    "description": "Contains various tools for conveniently downloading and editing taxon-specific datasets from the Paleobiology Database <https://paleobiodb.org>, extracting information on abundance, temporal distribution of subtaxa and taxonomic diversity through deep time, and visualizing these data in relation to phylogeny and stratigraphy.",
    "version": "0.4.6",
    "maintainer": "Darius Nau <dariusnau@gmx.at>",
    "author": "Darius Nau [aut, cre] (ORCID: <https://orcid.org/0009-0000-4343-6830>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=paleoDiv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paleoDiv Extracting and Visualizing Paleobiodiversity Contains various tools for conveniently downloading and editing taxon-specific datasets from the Paleobiology Database <https://paleobiodb.org>, extracting information on abundance, temporal distribution of subtaxa and taxonomic diversity through deep time, and visualizing these data in relation to phylogeny and stratigraphy.  "
  },
  {
    "id": 17527,
    "package_name": "paleoTS",
    "title": "Analyze Paleontological Time-Series",
    "description": "Facilitates analysis of paleontological sequences of trait values.  \n    Functions are provided to fit, using maximum likelihood, simple \n    evolutionary models (including unbiased random walks, directional \n    evolution,stasis, Ornstein-Uhlenbeck, covariate-tracking) and \n    complex models (punctuation, mode shifts).",
    "version": "0.6.2",
    "maintainer": "Gene Hunt <hunte@si.edu>",
    "author": "Gene Hunt [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-6430-5020>),\n  John Fricks [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=paleoTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paleoTS Analyze Paleontological Time-Series Facilitates analysis of paleontological sequences of trait values.  \n    Functions are provided to fit, using maximum likelihood, simple \n    evolutionary models (including unbiased random walks, directional \n    evolution,stasis, Ornstein-Uhlenbeck, covariate-tracking) and \n    complex models (punctuation, mode shifts).  "
  },
  {
    "id": 17549,
    "package_name": "pandemics",
    "title": "Monitoring a Developing Pandemic with Available Data",
    "description": "Full dynamic system to describe and forecast the spread and the severity\n    of a developing pandemic, based on available data. These data are number of infections, \n    hospitalizations, deaths and recoveries notified each day. The system consists of three \n    transitions, infection-infection, infection-hospital and hospital-death/recovery. \n    The intensities of these transitions are dynamic and estimated using non-parametric local\n    linear estimators. The package can be used to provide forecasts and survival indicators \n    such as the median time spent in hospital and the probability that a patient who has been\n    in hospital for a number of days can leave it alive. Methods are described in G\u00e1miz, \n    Mammen, Mart\u00ednez-Miranda, and Nielsen (2024) <doi:10.48550/arXiv.2308.09918> and \n    <doi:10.48550/arXiv.2308.09919>. ",
    "version": "0.1.0",
    "maintainer": "Mar\u00eda Dolores Mart\u00ednez-Miranda <mmiranda@ugr.es>",
    "author": "Mar\u00eda Luz G\u00e1miz [aut, cph],\n  Enno Mammen [aut, cph],\n  Mar\u00eda Dolores Mart\u00ednez-Miranda [aut, cre, cph],\n  Jens Perch Nielsen [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pandemics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pandemics Monitoring a Developing Pandemic with Available Data Full dynamic system to describe and forecast the spread and the severity\n    of a developing pandemic, based on available data. These data are number of infections, \n    hospitalizations, deaths and recoveries notified each day. The system consists of three \n    transitions, infection-infection, infection-hospital and hospital-death/recovery. \n    The intensities of these transitions are dynamic and estimated using non-parametric local\n    linear estimators. The package can be used to provide forecasts and survival indicators \n    such as the median time spent in hospital and the probability that a patient who has been\n    in hospital for a number of days can leave it alive. Methods are described in G\u00e1miz, \n    Mammen, Mart\u00ednez-Miranda, and Nielsen (2024) <doi:10.48550/arXiv.2308.09918> and \n    <doi:10.48550/arXiv.2308.09919>.   "
  },
  {
    "id": 17554,
    "package_name": "panelPomp",
    "title": "Inference for Panel Partially Observed Markov Processes",
    "description": "Data analysis based on panel partially-observed Markov process (PanelPOMP) models. To implement such models, simulate them and fit them to panel data, 'panelPomp' extends some of the facilities provided for time series data by the 'pomp' package. Implemented methods include filtering (panel particle filtering) and maximum likelihood estimation (Panel Iterated Filtering) as proposed in Breto, Ionides and King (2020) \"Panel Data Analysis via Mechanistic Models\" <doi:10.1080/01621459.2019.1604367>.",
    "version": "1.7.0.0",
    "maintainer": "Jesse Wheeler <jeswheel@umich.edu>",
    "author": "Carles Breto [aut] (ORCID: <https://orcid.org/0000-0003-4695-4902>),\n  Edward L. Ionides [aut] (ORCID:\n    <https://orcid.org/0000-0002-4190-0174>),\n  Aaron A. King [aut] (ORCID: <https://orcid.org/0000-0001-6159-3207>),\n  Jesse Wheeler [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3941-3884>),\n  Aaron Abkemeier [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=panelPomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "panelPomp Inference for Panel Partially Observed Markov Processes Data analysis based on panel partially-observed Markov process (PanelPOMP) models. To implement such models, simulate them and fit them to panel data, 'panelPomp' extends some of the facilities provided for time series data by the 'pomp' package. Implemented methods include filtering (panel particle filtering) and maximum likelihood estimation (Panel Iterated Filtering) as proposed in Breto, Ionides and King (2020) \"Panel Data Analysis via Mechanistic Models\" <doi:10.1080/01621459.2019.1604367>.  "
  },
  {
    "id": 17556,
    "package_name": "panelView",
    "title": "Visualizing Panel Data",
    "description": "Visualizes panel data. It has three main functionalities: (1) it plots the treatment status and missing values in a panel dataset; (2) it visualizes the temporal dynamics of a main variable of interest; (3) it depicts the bivariate relationships between a treatment variable and an outcome variable either by unit or in aggregate. For details, see <doi:10.18637/jss.v107.i07>.",
    "version": "1.1.18",
    "maintainer": "Yiqing Xu <yiqingxu@stanford.edu>",
    "author": "Hongyu Mou [aut],\n  Licheng Liu [aut],\n  Yiqing Xu [aut, cre] (ORCID: <https://orcid.org/0000-0003-2041-6671>)",
    "url": "https://yiqingxu.org/packages/panelview/index.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=panelView",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "panelView Visualizing Panel Data Visualizes panel data. It has three main functionalities: (1) it plots the treatment status and missing values in a panel dataset; (2) it visualizes the temporal dynamics of a main variable of interest; (3) it depicts the bivariate relationships between a treatment variable and an outcome variable either by unit or in aggregate. For details, see <doi:10.18637/jss.v107.i07>.  "
  },
  {
    "id": 17561,
    "package_name": "panelvar",
    "title": "Panel Vector Autoregression",
    "description": "We extend two general methods of moment estimators to panel vector \n    autoregression models (PVAR) with p lags of endogenous variables, predetermined \n    and strictly exogenous variables. This general PVAR model contains the first \n    difference GMM estimator by Holtz-Eakin et al. (1988) <doi:10.2307/1913103>, \n    Arellano and Bond (1991) <doi:10.2307/2297968> and the system GMM estimator \n    by Blundell and Bond (1998) <doi:10.1016/S0304-4076(98)00009-8>. We also \n    provide specification tests (Hansen overidentification test, lag selection \n    criterion and stability test of the PVAR polynomial) and classical structural \n    analysis for PVAR models such as orthogonal and generalized impulse response \n    functions, bootstrapped confidence intervals for impulse response analysis and \n    forecast error variance decompositions.",
    "version": "0.5.6",
    "maintainer": "Robert Ferstl <robert.ferstl@ur.de>",
    "author": "Michael Sigmund [aut],\n  Robert Ferstl [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=panelvar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "panelvar Panel Vector Autoregression We extend two general methods of moment estimators to panel vector \n    autoregression models (PVAR) with p lags of endogenous variables, predetermined \n    and strictly exogenous variables. This general PVAR model contains the first \n    difference GMM estimator by Holtz-Eakin et al. (1988) <doi:10.2307/1913103>, \n    Arellano and Bond (1991) <doi:10.2307/2297968> and the system GMM estimator \n    by Blundell and Bond (1998) <doi:10.1016/S0304-4076(98)00009-8>. We also \n    provide specification tests (Hansen overidentification test, lag selection \n    criterion and stability test of the PVAR polynomial) and classical structural \n    analysis for PVAR models such as orthogonal and generalized impulse response \n    functions, bootstrapped confidence intervals for impulse response analysis and \n    forecast error variance decompositions.  "
  },
  {
    "id": 17585,
    "package_name": "paramsim",
    "title": "Parameterized Simulation",
    "description": "This function obtains a Random Number Generator (RNG) or collection of RNGs that replicate the required parameter(s) of a distribution for a time series of data. Consider the case of reproducing a time series data set of size 20 that uses an autoregressive (AR) model with phi = 0.8 and standard deviation equal to 1. When one checks the arima.sin() function's estimated parameters, it's possible that after a single trial or a few more, one won't find the precise parameters. This enables one to look for the ideal RNG setting for a simulation that will accurately duplicate the desired parameters.",
    "version": "0.1.0",
    "maintainer": "Daniel James <futathesis@gmail.com>",
    "author": "Daniel James [cre, aut],\n  Ayinde Kayode [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=paramsim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paramsim Parameterized Simulation This function obtains a Random Number Generator (RNG) or collection of RNGs that replicate the required parameter(s) of a distribution for a time series of data. Consider the case of reproducing a time series data set of size 20 that uses an autoregressive (AR) model with phi = 0.8 and standard deviation equal to 1. When one checks the arima.sin() function's estimated parameters, it's possible that after a single trial or a few more, one won't find the precise parameters. This enables one to look for the ideal RNG setting for a simulation that will accurately duplicate the desired parameters.  "
  },
  {
    "id": 17615,
    "package_name": "partsm",
    "title": "Periodic Autoregressive Time Series Models",
    "description": "Basic functions to fit and predict periodic autoregressive time series models. These models are discussed in the book P.H. Franses (1996) \"Periodicity and Stochastic Trends in Economic Time Series\", Oxford University Press. Data set analyzed in that book is also provided. NOTE: the package was orphaned during several years. It is now only maintained, but no major enhancements are expected, and the maintainer cannot provide any support. ",
    "version": "1.1-4",
    "maintainer": "Matthieu Stigler <Matthieu.Stigler@gmail.com>",
    "author": "Javier Lopez-de-Lacalle [aut, cph],\n  Matthieu Stigler [cre] (ORCID: <https://orcid.org/0000-0002-6802-4290>)",
    "url": "https://github.com/MatthieuStigler/partsm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=partsm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "partsm Periodic Autoregressive Time Series Models Basic functions to fit and predict periodic autoregressive time series models. These models are discussed in the book P.H. Franses (1996) \"Periodicity and Stochastic Trends in Economic Time Series\", Oxford University Press. Data set analyzed in that book is also provided. NOTE: the package was orphaned during several years. It is now only maintained, but no major enhancements are expected, and the maintainer cannot provide any support.   "
  },
  {
    "id": 17625,
    "package_name": "pastclim",
    "title": "Manipulate Time Series of Climate Reconstructions",
    "description": "Methods to easily extract and manipulate climate\n  reconstructions for ecological and anthropological analyses, as described\n  in Leonardi et al. (2023) <doi:10.1111/ecog.06481>. The package includes datasets\n  of palaeoclimate reconstructions, present observations, and future projections \n  from multiple climate models.",
    "version": "2.2.0",
    "maintainer": "Andrea Manica <am315@cam.ac.uk>",
    "author": "Michela Leonardi [aut],\n  Emily Y. Hallet [ctb],\n  Robert Beyer [ctb],\n  Mario Krapp [ctb],\n  Andrea V. Pozzi [ctb],\n  Andrea Manica [aut, cre, cph]",
    "url": "https://github.com/EvolEcolGroup/pastclim,\nhttps://evolecolgroup.github.io/pastclim/",
    "bug_reports": "https://github.com/EvolEcolGroup/pastclim/issues",
    "repository": "https://cran.r-project.org/package=pastclim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pastclim Manipulate Time Series of Climate Reconstructions Methods to easily extract and manipulate climate\n  reconstructions for ecological and anthropological analyses, as described\n  in Leonardi et al. (2023) <doi:10.1111/ecog.06481>. The package includes datasets\n  of palaeoclimate reconstructions, present observations, and future projections \n  from multiple climate models.  "
  },
  {
    "id": 17627,
    "package_name": "pastecs",
    "title": "Package for Analysis of Space-Time Ecological Series",
    "description": "Regularisation, decomposition and analysis of space-time series.\n  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff\n  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.",
    "version": "1.4.2",
    "maintainer": "Philippe Grosjean <phgrosjean@sciviews.org>",
    "author": "Philippe Grosjean [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2694-9471>),\n  Frederic Ibanez [aut],\n  Michele Etienne [ctb]",
    "url": "https://github.com/SciViews/pastecs",
    "bug_reports": "https://github.com/SciViews/pastecs/issues",
    "repository": "https://cran.r-project.org/package=pastecs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pastecs Package for Analysis of Space-Time Ecological Series Regularisation, decomposition and analysis of space-time series.\n  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff\n  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.  "
  },
  {
    "id": 17710,
    "package_name": "pcts",
    "title": "Periodically Correlated and Periodically Integrated Time Series",
    "description": "Classes and methods for modelling and simulation of\n    periodically correlated (PC) and periodically integrated time\n    series.  Compute theoretical periodic autocovariances and related\n    properties of PC autoregressive moving average models. Some original\n    methods including Boshnakov & Iqelan (2009)\n    <doi:10.1111/j.1467-9892.2009.00617.x>, Boshnakov (1996)\n    <doi:10.1111/j.1467-9892.1996.tb00281.x>.",
    "version": "0.15.8",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Georgi N. Boshnakov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>)",
    "url": "https://geobosh.github.io/pcts/ (doc)\nhttps://github.com/GeoBosh/pcts/ (devel)",
    "bug_reports": "https://github.com/GeoBosh/pcts/issues",
    "repository": "https://cran.r-project.org/package=pcts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pcts Periodically Correlated and Periodically Integrated Time Series Classes and methods for modelling and simulation of\n    periodically correlated (PC) and periodically integrated time\n    series.  Compute theoretical periodic autocovariances and related\n    properties of PC autoregressive moving average models. Some original\n    methods including Boshnakov & Iqelan (2009)\n    <doi:10.1111/j.1467-9892.2009.00617.x>, Boshnakov (1996)\n    <doi:10.1111/j.1467-9892.1996.tb00281.x>.  "
  },
  {
    "id": 17717,
    "package_name": "pdc",
    "title": "Permutation Distribution Clustering",
    "description": "Permutation Distribution Clustering is a clustering method for time series. Dissimilarity of time series is formalized as the divergence between their permutation distributions. The permutation distribution was proposed as measure of the complexity of a time series.",
    "version": "1.0.3",
    "maintainer": "Andreas M. Brandmaier <brandmaier@mpib-berlin.mpg.de>",
    "author": "Andreas M. Brandmaier",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pdc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pdc Permutation Distribution Clustering Permutation Distribution Clustering is a clustering method for time series. Dissimilarity of time series is formalized as the divergence between their permutation distributions. The permutation distribution was proposed as measure of the complexity of a time series.  "
  },
  {
    "id": 17722,
    "package_name": "pdfetch",
    "title": "Fetch Economic and Financial Time Series Data from Public\nSources",
    "description": "Download economic and financial time series from public sources, \n  including the St Louis Fed's FRED system, Yahoo Finance, the US Bureau of Labor Statistics, \n  the US Energy Information Administration, the World Bank, Eurostat, the European Central Bank,\n  the Bank of England, the UK's Office of National Statistics, Deutsche Bundesbank, and INSEE.",
    "version": "0.3.3",
    "maintainer": "Abiel Reinhart <abielr@gmail.com>",
    "author": "Abiel Reinhart [aut, cre]",
    "url": "https://github.com/abielr/pdfetch",
    "bug_reports": "https://github.com/abielr/pdfetch/issues",
    "repository": "https://cran.r-project.org/package=pdfetch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pdfetch Fetch Economic and Financial Time Series Data from Public\nSources Download economic and financial time series from public sources, \n  including the St Louis Fed's FRED system, Yahoo Finance, the US Bureau of Labor Statistics, \n  the US Energy Information Administration, the World Bank, Eurostat, the European Central Bank,\n  the Bank of England, the UK's Office of National Statistics, Deutsche Bundesbank, and INSEE.  "
  },
  {
    "id": 17730,
    "package_name": "pdt",
    "title": "Permutation Distancing Test",
    "description": "Permutation (randomisation) test for single-case phase design data with \n    two phases (e.g., pre- and post-treatment). Correction for dependency of observations \n    is done through stepwise resampling the time series while varying \n    the distance between observations. The required distance 0,1,2,3.. is determined \n    based on repeated dependency testing while stepwise increasing the distance.\n    In preparation: Vroegindeweij et al. \"A Permutation distancing test \n    for single-case observational AB phase design data: A Monte Carlo simulation study\".",
    "version": "0.0.2",
    "maintainer": "Jan Houtveen <janhoutveen@gmail.com>",
    "author": "Jan Houtveen [aut, cre],\n  Anouk Vroegindeweij [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pdt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pdt Permutation Distancing Test Permutation (randomisation) test for single-case phase design data with \n    two phases (e.g., pre- and post-treatment). Correction for dependency of observations \n    is done through stepwise resampling the time series while varying \n    the distance between observations. The required distance 0,1,2,3.. is determined \n    based on repeated dependency testing while stepwise increasing the distance.\n    In preparation: Vroegindeweij et al. \"A Permutation distancing test \n    for single-case observational AB phase design data: A Monte Carlo simulation study\".  "
  },
  {
    "id": 17732,
    "package_name": "peRiodiCS",
    "title": "Functions for Generating Periodic Curves",
    "description": "\n    Functions for generating variants of curves:\n    restricted cubic spline, periodic restricted cubic spline,\n    periodic cubic spline. Periodic splines can be used to model data\n    that has periodic nature / seasonality.",
    "version": "0.5.0",
    "maintainer": "Crt Ahlin <crt.ahlin@gmail.com>",
    "author": "Crt Ahlin [aut, cre],\n  Lara Lusa [aut]",
    "url": "",
    "bug_reports": "https://github.com/crtahlin/peRiodiCS/issues",
    "repository": "https://cran.r-project.org/package=peRiodiCS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "peRiodiCS Functions for Generating Periodic Curves \n    Functions for generating variants of curves:\n    restricted cubic spline, periodic restricted cubic spline,\n    periodic cubic spline. Periodic splines can be used to model data\n    that has periodic nature / seasonality.  "
  },
  {
    "id": 17734,
    "package_name": "peacots",
    "title": "Periodogram Peaks in Correlated Time Series",
    "description": "Calculates the periodogram of a time series, maximum-likelihood fits an Ornstein-Uhlenbeck state space (OUSS) null model and evaluates the statistical significance of periodogram peaks against the OUSS null hypothesis. The OUSS is a parsimonious model for stochastically fluctuating variables with linear stabilizing forces, subject to uncorrelated measurement errors. Contrary to the classical white noise null model for detecting cyclicity, the OUSS model can account for temporal correlations typically occurring in ecological and geological time series. Citation: Louca, Stilianos and Doebeli, Michael (2015) <doi:10.1890/14-0126.1>.",
    "version": "1.3.2",
    "maintainer": "Stilianos Louca <louca.research@gmail.com>",
    "author": "Stilianos Louca [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=peacots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "peacots Periodogram Peaks in Correlated Time Series Calculates the periodogram of a time series, maximum-likelihood fits an Ornstein-Uhlenbeck state space (OUSS) null model and evaluates the statistical significance of periodogram peaks against the OUSS null hypothesis. The OUSS is a parsimonious model for stochastically fluctuating variables with linear stabilizing forces, subject to uncorrelated measurement errors. Contrary to the classical white noise null model for detecting cyclicity, the OUSS model can account for temporal correlations typically occurring in ecological and geological time series. Citation: Louca, Stilianos and Doebeli, Michael (2015) <doi:10.1890/14-0126.1>.  "
  },
  {
    "id": 17751,
    "package_name": "pedometrics",
    "title": "Miscellaneous Pedometric Tools",
    "description": "An R implementation of methods employed in the field of pedometrics, soil science\n    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil\n    using statistical and computational methods. The methods found here include the calibration of\n    linear regression models using covariate selection strategies, computation of summary validation\n    statistics for predictions, generation of summary plots, evaluation of the local quality of a\n    geostatistical model of uncertainty, and so on. Other functions simply extend the\n    functionalities of or facilitate the usage of functions from other packages that are commonly\n    used for the analysis of soil data. Formerly available versions of suggested packages no longer\n    available from CRAN can be obtained from the CRAN archive\n    <https://cran.r-project.org/src/contrib/Archive/>.",
    "version": "0.12.1",
    "maintainer": "Alessandro Samuel-Rosa <alessandrosamuelrosa@gmail.com>",
    "author": "Alessandro Samuel-Rosa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0877-1320>),\n  Lucia Helena Cunha dos Anjos [ths] (ORCID:\n    <https://orcid.org/0000-0003-0063-3521>),\n  Gustavo Vasques [ths] (ORCID: <https://orcid.org/0000-0001-9463-1898>),\n  Gerard B M Heuvelink [ths] (ORCID:\n    <https://orcid.org/0000-0003-0959-9358>),\n  Juan Carlos Ruiz Cuetos [ctb],\n  Maria Eugenia Polo Garcia [ctb],\n  Pablo Garcia Rodriguez [ctb],\n  Joshua French [ctb],\n  Ken Kleinman [ctb],\n  Dick Brus [ctb] (ORCID: <https://orcid.org/0000-0003-2194-4783>),\n  Frank Harrell Jr [ctb],\n  Ruo Xu [ctb]",
    "url": "https://github.com/Laboratorio-de-Pedometria/pedometrics-package",
    "bug_reports": "https://github.com/Laboratorio-de-Pedometria/pedometrics-package/issues",
    "repository": "https://cran.r-project.org/package=pedometrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pedometrics Miscellaneous Pedometric Tools An R implementation of methods employed in the field of pedometrics, soil science\n    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil\n    using statistical and computational methods. The methods found here include the calibration of\n    linear regression models using covariate selection strategies, computation of summary validation\n    statistics for predictions, generation of summary plots, evaluation of the local quality of a\n    geostatistical model of uncertainty, and so on. Other functions simply extend the\n    functionalities of or facilitate the usage of functions from other packages that are commonly\n    used for the analysis of soil data. Formerly available versions of suggested packages no longer\n    available from CRAN can be obtained from the CRAN archive\n    <https://cran.r-project.org/src/contrib/Archive/>.  "
  },
  {
    "id": 17787,
    "package_name": "perARMA",
    "title": "Periodic Time Series Analysis",
    "description": "Identification, model fitting and estimation for time series with periodic structure.\n    Additionally, procedures for simulation of periodic processes\n    and real data sets are included.\n    Hurd, H. L., Miamee, A. G. (2007) <doi:10.1002/9780470182833>\n    Box, G. E. P., Jenkins, G. M., Reinsel, G. (1994)  <doi:10.1111/jtsa.12194>\n    Brockwell, P. J., Davis, R. A. (1991, ISBN:978-1-4419-0319-8) \n    Bretz, F., Hothorn, T., Westfall, P. (2010, ISBN: 9780429139543) \n    Westfall, P. H., Young, S. S. (1993, ISBN:978-0-471-55761-6)\n    Bloomfield, P., Hurd, H. L.,Lund, R. (1994) \n    <doi:10.1111/j.1467-9892.1994.tb00181.x>\n    Dehay, D., Hurd, H. L. (1994, ISBN:0-7803-1023-3)\n    Vecchia, A. (1985) <doi:10.1080/00401706.1985.10488076>\n    Vecchia, A. (1985) <doi:10.1111/j.1752-1688.1985.tb00167.x>\n    Jones, R., Brelsford, W. (1967) <doi:10.1093/biomet/54.3-4.403>\n    Makagon, A. (1999)\n    <https://www.math.uni.wroc.pl/~pms/files/19.2/Article/19.2.5.pdf>\n    Sakai, H. (1989) <doi:10.1111/j.1467-9892.1991.tb00069.x>\n    Gladyshev, E. G. (1961) \n    <https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=dan&paperid=24851>\n    Ansley (1979) <doi:10.1093/biomet/66.1.59>\n    Hurd, H. L., Gerr, N. L. (1991) <doi:10.1111/j.1467-9892.1991.tb00088.x>.",
    "version": "1.7",
    "maintainer": "Karolina Marek <karolina.marek10@gmail.com>",
    "author": "Anna Dudek [aut],\n  Harry Hurd [aut],\n  Wioletta Wojtowicz [aut],\n  Karolina Marek [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=perARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "perARMA Periodic Time Series Analysis Identification, model fitting and estimation for time series with periodic structure.\n    Additionally, procedures for simulation of periodic processes\n    and real data sets are included.\n    Hurd, H. L., Miamee, A. G. (2007) <doi:10.1002/9780470182833>\n    Box, G. E. P., Jenkins, G. M., Reinsel, G. (1994)  <doi:10.1111/jtsa.12194>\n    Brockwell, P. J., Davis, R. A. (1991, ISBN:978-1-4419-0319-8) \n    Bretz, F., Hothorn, T., Westfall, P. (2010, ISBN: 9780429139543) \n    Westfall, P. H., Young, S. S. (1993, ISBN:978-0-471-55761-6)\n    Bloomfield, P., Hurd, H. L.,Lund, R. (1994) \n    <doi:10.1111/j.1467-9892.1994.tb00181.x>\n    Dehay, D., Hurd, H. L. (1994, ISBN:0-7803-1023-3)\n    Vecchia, A. (1985) <doi:10.1080/00401706.1985.10488076>\n    Vecchia, A. (1985) <doi:10.1111/j.1752-1688.1985.tb00167.x>\n    Jones, R., Brelsford, W. (1967) <doi:10.1093/biomet/54.3-4.403>\n    Makagon, A. (1999)\n    <https://www.math.uni.wroc.pl/~pms/files/19.2/Article/19.2.5.pdf>\n    Sakai, H. (1989) <doi:10.1111/j.1467-9892.1991.tb00069.x>\n    Gladyshev, E. G. (1961) \n    <https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=dan&paperid=24851>\n    Ansley (1979) <doi:10.1093/biomet/66.1.59>\n    Hurd, H. L., Gerr, N. L. (1991) <doi:10.1111/j.1467-9892.1991.tb00088.x>.  "
  },
  {
    "id": 17801,
    "package_name": "permute",
    "title": "Functions for Generating Restricted Permutations of Data",
    "description": "A set of restricted permutation designs for freely exchangeable, line transects (time series), and spatial grid designs plus permutation of blocks (groups of samples) is provided. 'permute' also allows split-plot designs, in which the whole-plots or split-plots or both can be freely-exchangeable or one of the restricted designs. The 'permute' package is modelled after the permutation schemes of 'Canoco 3.1' (and later) by Cajo ter Braak.",
    "version": "0.9-8",
    "maintainer": "Gavin L. Simpson <ucfagls@gmail.com>",
    "author": "Gavin L. Simpson [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0002-9084-8413>),\n  R Core Team [cph],\n  Douglas M. Bates [ctb],\n  Jari Oksanen [ctb]",
    "url": "https://github.com/gavinsimpson/permute",
    "bug_reports": "https://github.com/gavinsimpson/permute/issues",
    "repository": "https://cran.r-project.org/package=permute",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "permute Functions for Generating Restricted Permutations of Data A set of restricted permutation designs for freely exchangeable, line transects (time series), and spatial grid designs plus permutation of blocks (groups of samples) is provided. 'permute' also allows split-plot designs, in which the whole-plots or split-plots or both can be freely-exchangeable or one of the restricted designs. The 'permute' package is modelled after the permutation schemes of 'Canoco 3.1' (and later) by Cajo ter Braak.  "
  },
  {
    "id": 17802,
    "package_name": "permutes",
    "title": "Permutation Tests for Time Series Data",
    "description": "Helps you determine the analysis window to use when analyzing densely-sampled\n    time-series data, such as EEG data, using permutation testing (Maris & Oostenveld, 2007)\n    <doi:10.1016/j.jneumeth.2007.03.024>. These permutation tests can help identify the timepoints\n    where significance of an effect begins and ends, and the results can be plotted in various\n    types of heatmap for reporting. Mixed-effects models are supported using an implementation of\n    the approach by Lee & Braun (2012) <doi:10.1111/j.1541-0420.2011.01675.x>.",
    "version": "2.8",
    "maintainer": "Cesko C. Voeten <cvoeten@gmail.com>",
    "author": "Cesko C. Voeten [aut, cre]",
    "url": "",
    "bug_reports": "https://gitlab.com/cvoeten/permutes/-/issues",
    "repository": "https://cran.r-project.org/package=permutes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "permutes Permutation Tests for Time Series Data Helps you determine the analysis window to use when analyzing densely-sampled\n    time-series data, such as EEG data, using permutation testing (Maris & Oostenveld, 2007)\n    <doi:10.1016/j.jneumeth.2007.03.024>. These permutation tests can help identify the timepoints\n    where significance of an effect begins and ends, and the results can be plotted in various\n    types of heatmap for reporting. Mixed-effects models are supported using an implementation of\n    the approach by Lee & Braun (2012) <doi:10.1111/j.1541-0420.2011.01675.x>.  "
  },
  {
    "id": 17847,
    "package_name": "phantSEM",
    "title": "Create Phantom Variables in Structural Equation Models for\nSensitivity Analyses",
    "description": "Create phantom variables, which are variables that were not observed, for the purpose of sensitivity analyses for structural equation models. The package makes it easier for a user to test different combinations of covariances between the phantom variable(s) and observed variables. The package may be used to assess a model's or effect's sensitivity to temporal bias (e.g., if cross-sectional data were collected) or confounding bias. ",
    "version": "1.0.0.0",
    "maintainer": "Alexis Georgeson <georgeson.alexis@gmail.com>",
    "author": "Alexis Georgeson [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-6426-9258>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=phantSEM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phantSEM Create Phantom Variables in Structural Equation Models for\nSensitivity Analyses Create phantom variables, which are variables that were not observed, for the purpose of sensitivity analyses for structural equation models. The package makes it easier for a user to test different combinations of covariances between the phantom variable(s) and observed variables. The package may be used to assess a model's or effect's sensitivity to temporal bias (e.g., if cross-sectional data were collected) or confounding bias.   "
  },
  {
    "id": 17856,
    "package_name": "phase",
    "title": "Analyse Biological Time-Series Data",
    "description": "Compiles functions to trim, bin, visualise, and analyse activity/sleep time-series data collected from the Drosophila Activity Monitor (DAM) system (Trikinetics, USA). The following methods were used to compute periodograms - Chi-square periodogram: Sokolove and Bushell (1978) <doi:10.1016/0022-5193(78)90022-X>, Lomb-Scargle periodogram: Lomb (1976) <doi:10.1007/BF00648343>, Scargle (1982) <doi:10.1086/160554> and Ruf (1999) <doi:10.1076/brhm.30.2.178.1422>, and Autocorrelation: Eijzenbach et al. (1986) <doi:10.1111/j.1440-1681.1986.tb00943.x>. Identification of activity peaks is done after using a Savitzky-Golay filter (Savitzky and Golay (1964) <doi:10.1021/ac60214a047>) to smooth raw activity data. Three methods to estimate anticipation of activity are used based on the following papers - Slope method: Fernandez et al. (2020) <doi:10.1016/j.cub.2020.04.025>, Harrisingh method: Harrisingh et al. (2007) <doi:10.1523/JNEUROSCI.3680-07.2007>, and Stoleru method: Stoleru et al. (2004) <doi:10.1038/nature02926>. Rose plots and circular analysis are based on methods from - Batschelet (1981) <ISBN:0120810506> and Zar (2010) <ISBN:0321656865>.",
    "version": "1.2.9",
    "maintainer": "Lakshman Abhilash <labhilash@gc.cuny.edu>",
    "author": "Lakshman Abhilash [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9933-8989>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=phase",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phase Analyse Biological Time-Series Data Compiles functions to trim, bin, visualise, and analyse activity/sleep time-series data collected from the Drosophila Activity Monitor (DAM) system (Trikinetics, USA). The following methods were used to compute periodograms - Chi-square periodogram: Sokolove and Bushell (1978) <doi:10.1016/0022-5193(78)90022-X>, Lomb-Scargle periodogram: Lomb (1976) <doi:10.1007/BF00648343>, Scargle (1982) <doi:10.1086/160554> and Ruf (1999) <doi:10.1076/brhm.30.2.178.1422>, and Autocorrelation: Eijzenbach et al. (1986) <doi:10.1111/j.1440-1681.1986.tb00943.x>. Identification of activity peaks is done after using a Savitzky-Golay filter (Savitzky and Golay (1964) <doi:10.1021/ac60214a047>) to smooth raw activity data. Three methods to estimate anticipation of activity are used based on the following papers - Slope method: Fernandez et al. (2020) <doi:10.1016/j.cub.2020.04.025>, Harrisingh method: Harrisingh et al. (2007) <doi:10.1523/JNEUROSCI.3680-07.2007>, and Stoleru method: Stoleru et al. (2004) <doi:10.1038/nature02926>. Rose plots and circular analysis are based on methods from - Batschelet (1981) <ISBN:0120810506> and Zar (2010) <ISBN:0321656865>.  "
  },
  {
    "id": 17869,
    "package_name": "pheno",
    "title": "Auxiliary Functions for Phenological Data Analysis",
    "description": "Provides some easy-to-use functions for time series\n        analyses of (plant-) phenological data sets. These functions\n        mainly deal with the estimation of combined phenological time\n        series and are usually wrappers for functions that are already\n        implemented in other R packages adapted to the special\n        structure of phenological data and the needs of phenologists.\n        Some date conversion functions to handle Julian dates are also\n        provided.",
    "version": "1.7-0",
    "maintainer": "Maximilian Lange <maximilian.lange@ufz.de>",
    "author": "Joerg Schaber",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pheno",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pheno Auxiliary Functions for Phenological Data Analysis Provides some easy-to-use functions for time series\n        analyses of (plant-) phenological data sets. These functions\n        mainly deal with the estimation of combined phenological time\n        series and are usually wrappers for functions that are already\n        implemented in other R packages adapted to the special\n        structure of phenological data and the needs of phenologists.\n        Some date conversion functions to handle Julian dates are also\n        provided.  "
  },
  {
    "id": 17870,
    "package_name": "phenoCDM",
    "title": "Continuous Development Models for Incremental Time-Series\nAnalysis",
    "description": "Using the Bayesian state-space approach, we developed a continuous development model to quantify dynamic incremental changes in the response variable. While the model was originally developed for daily changes in forest green-up, the model can be used to predict any similar process. The CDM can capture both timing and rate of nonlinear processes. Unlike statics methods, which aggregate variations into a single metric, our dynamic model tracks the changing impacts over time. The CDM accommodates nonlinear responses to variation in predictors, which changes throughout development. ",
    "version": "0.1.3",
    "maintainer": "Bijan Seyednasrollah <bijan.s.nasr@gmail.com>",
    "author": "Bijan Seyednasrollah, Jennifer J. Swenson, Jean-Christophe Domec, James S. Clark",
    "url": "",
    "bug_reports": "https://github.com/bnasr/phenoCDM/issues",
    "repository": "https://cran.r-project.org/package=phenoCDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phenoCDM Continuous Development Models for Incremental Time-Series\nAnalysis Using the Bayesian state-space approach, we developed a continuous development model to quantify dynamic incremental changes in the response variable. While the model was originally developed for daily changes in forest green-up, the model can be used to predict any similar process. The CDM can capture both timing and rate of nonlinear processes. Unlike statics methods, which aggregate variations into a single metric, our dynamic model tracks the changing impacts over time. The CDM accommodates nonlinear responses to variation in predictors, which changes throughout development.   "
  },
  {
    "id": 17871,
    "package_name": "phenocamr",
    "title": "Facilitates 'PhenoCam' Data Access and Time Series\nPost-Processing",
    "description": "\n    Programmatic interface to the 'PhenoCam' web services (<https://phenocam.nau.edu/webcam>).\n    Allows for easy downloading of 'PhenoCam' data directly to your R workspace\n    or your computer and provides post-processing routines for consistent and easy\n    timeseries outlier detection, smoothing and estimation of phenological transition dates.\n    Methods for this package are described in detail in Hufkens et. al (2018) <doi:10.1111/2041-210X.12970>.",
    "version": "1.1.5",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "author": "Koen Hufkens [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5070-8109>),\n  BlueGreen Labs [cph, fnd]",
    "url": "https://github.com/bluegreen-labs/phenocamr",
    "bug_reports": "https://github.com/bluegreen-labs/phenocamr/issues",
    "repository": "https://cran.r-project.org/package=phenocamr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phenocamr Facilitates 'PhenoCam' Data Access and Time Series\nPost-Processing \n    Programmatic interface to the 'PhenoCam' web services (<https://phenocam.nau.edu/webcam>).\n    Allows for easy downloading of 'PhenoCam' data directly to your R workspace\n    or your computer and provides post-processing routines for consistent and easy\n    timeseries outlier detection, smoothing and estimation of phenological transition dates.\n    Methods for this package are described in detail in Hufkens et. al (2018) <doi:10.1111/2041-210X.12970>.  "
  },
  {
    "id": 17872,
    "package_name": "phenolocrop",
    "title": "Time-Series Models to the Crop Phenology",
    "description": "Fit a time-series model \n    to a crop phenology data, such as time-series rice canopy height.\n    This package returns the model parameters as the summary statistics of crop phenology,\n    and these parameters will be useful to characterize the growth pattern of each cultivar and \n    predict manually-measured traits, such as days to heading and biomass.\n    Please see Taniguchi et al. (2022) <doi:10.3389/fpls.2022.998803> and \n    Taniguchi et al. (2025) <doi: 10.3389/frai.2024.1477637> for detail.\n    This package has been designed for scientific use.  \n    Use for commercial purposes shall not be allowed.",
    "version": "0.0.4",
    "maintainer": "Shoji Taniguchi <taniguchi.shoji938@naro.go.jp>",
    "author": "Shoji Taniguchi [aut, cre],\n  The National Agriculture and Food Research Organization (NARO) [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=phenolocrop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phenolocrop Time-Series Models to the Crop Phenology Fit a time-series model \n    to a crop phenology data, such as time-series rice canopy height.\n    This package returns the model parameters as the summary statistics of crop phenology,\n    and these parameters will be useful to characterize the growth pattern of each cultivar and \n    predict manually-measured traits, such as days to heading and biomass.\n    Please see Taniguchi et al. (2022) <doi:10.3389/fpls.2022.998803> and \n    Taniguchi et al. (2025) <doi: 10.3389/frai.2024.1477637> for detail.\n    This package has been designed for scientific use.  \n    Use for commercial purposes shall not be allowed.  "
  },
  {
    "id": 17895,
    "package_name": "photobiologySun",
    "title": "Data for Sunlight Spectra",
    "description": "Data for the extraterrestrial solar spectral irradiance and ground \n    level solar spectral irradiance and irradiance. In addition data for \n    shade light under vegetation and irradiance time series from different\n    broadband sensors.  Part of the \n    'r4photobiology' suite, Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",
    "version": "0.5.1",
    "maintainer": "Pedro J. Aphalo <pedro.aphalo@helsinki.fi>",
    "author": "Pedro J. Aphalo [aut, trl, cre] (ORCID:\n    <https://orcid.org/0000-0003-3385-972X>),\n  T. Matthew Robson [ctb] (ORCID:\n    <https://orcid.org/0000-0002-8631-796X>),\n  Saara M. Hartiakinen [ctb] (ORCID:\n    <https://orcid.org/0000-0002-8430-6861>),\n  Anders Lindfors [ctb],\n  Titta K. Kotilainen [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2822-9734>)",
    "url": "https://docs.r4photobiology.info/photobiologySun/,\nhttps://github.com/aphalo/photobiologySun",
    "bug_reports": "https://github.com/aphalo/photobiologySun/issues",
    "repository": "https://cran.r-project.org/package=photobiologySun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "photobiologySun Data for Sunlight Spectra Data for the extraterrestrial solar spectral irradiance and ground \n    level solar spectral irradiance and irradiance. In addition data for \n    shade light under vegetation and irradiance time series from different\n    broadband sensors.  Part of the \n    'r4photobiology' suite, Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.  "
  },
  {
    "id": 17931,
    "package_name": "piar",
    "title": "Price Index Aggregation",
    "description": "Most price indexes are made with a two-step procedure, where\n    period-over-period elementary indexes are first calculated for a collection\n    of elementary aggregates at each point in time, and then aggregated according\n    to a price index aggregation structure. These indexes can then be chained\n    together to form a time series that gives the evolution of prices with\n    respect to a fixed base period. This package contains a collection of\n    functions that revolve around this work flow, making it easy to build\n    standard price indexes, and implement the methods described by\n    Balk (2008, <doi:10.1017/CBO9780511720758>), von der Lippe (2007,\n    <doi:10.3726/978-3-653-01120-3>), and the CPI manual (2020,\n    <doi:10.5089/9781484354841.069>) for bilateral price indexes.",
    "version": "0.8.3",
    "maintainer": "Steve Martin <marberts@protonmail.com>",
    "author": "Steve Martin [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2544-9480>)",
    "url": "https://marberts.github.io/piar/, https://github.com/marberts/piar",
    "bug_reports": "https://github.com/marberts/piar/issues",
    "repository": "https://cran.r-project.org/package=piar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "piar Price Index Aggregation Most price indexes are made with a two-step procedure, where\n    period-over-period elementary indexes are first calculated for a collection\n    of elementary aggregates at each point in time, and then aggregated according\n    to a price index aggregation structure. These indexes can then be chained\n    together to form a time series that gives the evolution of prices with\n    respect to a fixed base period. This package contains a collection of\n    functions that revolve around this work flow, making it easy to build\n    standard price indexes, and implement the methods described by\n    Balk (2008, <doi:10.1017/CBO9780511720758>), von der Lippe (2007,\n    <doi:10.3726/978-3-653-01120-3>), and the CPI manual (2020,\n    <doi:10.5089/9781484354841.069>) for bilateral price indexes.  "
  },
  {
    "id": 18117,
    "package_name": "pointRes",
    "title": "Analyzing Pointer Years and Components of Resilience",
    "description": "Functions to calculate and plot event and pointer years as well as resilience indices. Designed for dendroecological applications, but also suitable to analyze patterns in other ecological time series.",
    "version": "2.0.2",
    "maintainer": "Marieke van der Maaten-Theunissen <marieke.theunissen@tu-dresden.de>",
    "author": "Marieke van der Maaten-Theunissen [aut, cph, cre, trl], Ernst van der Maaten [aut, trl], Gottfried Jetsckhe [aut, trl], Mario Trouillier [aut, trl]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pointRes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pointRes Analyzing Pointer Years and Components of Resilience Functions to calculate and plot event and pointer years as well as resilience indices. Designed for dendroecological applications, but also suitable to analyze patterns in other ecological time series.  "
  },
  {
    "id": 18118,
    "package_name": "pointdensityP",
    "title": "Point Density for Geospatial Data",
    "description": "The function pointdensity returns a density count and the temporal average for\n    every point in the original list. The dataframe returned includes four\n    columns: lat, lon, count, and date_avg. The \"lat\" column is the original\n    latitude data; the \"lon\" column is the original longitude data; the \"count\"\n    is the density count of the number of points within a radius of\n    radius*grid_size (the neighborhood); and the date_avg column includes the\n    average date of each point in the neighborhood.",
    "version": "0.3.5",
    "maintainer": "Paul Evangelista <paul.evangelista@westpoint.edu>",
    "author": "\"Paul Evangelista <paul.evangelista@westpoint.edu> and Dave Beskow\n    <david.beskow@westpoint.edu>\"",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pointdensityP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pointdensityP Point Density for Geospatial Data The function pointdensity returns a density count and the temporal average for\n    every point in the original list. The dataframe returned includes four\n    columns: lat, lon, count, and date_avg. The \"lat\" column is the original\n    latitude data; the \"lon\" column is the original longitude data; the \"count\"\n    is the density count of the number of points within a radius of\n    radius*grid_size (the neighborhood); and the date_avg column includes the\n    average date of each point in the neighborhood.  "
  },
  {
    "id": 18168,
    "package_name": "pomp",
    "title": "Statistical Inference for Partially Observed Markov Processes",
    "description": "Tools for data analysis with partially observed Markov process (POMP) models (also known as stochastic dynamical systems, hidden Markov models, and nonlinear, non-Gaussian, state-space models).  The package provides facilities for implementing POMP models, simulating them, and fitting them to time series data by a variety of frequentist and Bayesian methods.  It is also a versatile platform for implementation of inference methods for general POMP models.",
    "version": "6.4",
    "maintainer": "Aaron A. King <kingaa@umich.edu>",
    "author": "Aaron A. King [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6159-3207>),\n  Edward L. Ionides [aut] (ORCID:\n    <https://orcid.org/0000-0002-4190-0174>),\n  Carles Bret\u00f3 [aut] (ORCID: <https://orcid.org/0000-0003-4695-4902>),\n  Stephen P. Ellner [ctb] (ORCID:\n    <https://orcid.org/0000-0002-8351-9734>),\n  Matthew J. Ferrari [ctb] (ORCID:\n    <https://orcid.org/0000-0001-5251-8168>),\n  Sebastian Funk [ctb] (ORCID: <https://orcid.org/0000-0002-2842-3406>),\n  Steven G. Johnson [ctb],\n  Bruce E. Kendall [ctb] (ORCID: <https://orcid.org/0000-0003-1782-8106>),\n  Michael Lavine [ctb],\n  Dao Nguyen [ctb] (ORCID: <https://orcid.org/0000-0003-2215-613X>),\n  Eamon B. O'Dea [ctb] (ORCID: <https://orcid.org/0000-0003-4748-683X>),\n  Daniel C. Reuman [ctb],\n  Helen Wearing [ctb] (ORCID: <https://orcid.org/0000-0002-9837-9797>),\n  Simon N. Wood [ctb] (ORCID: <https://orcid.org/0000-0002-2034-7453>)",
    "url": "https://kingaa.github.io/pomp/",
    "bug_reports": "https://github.com/kingaa/pomp/issues/",
    "repository": "https://cran.r-project.org/package=pomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pomp Statistical Inference for Partially Observed Markov Processes Tools for data analysis with partially observed Markov process (POMP) models (also known as stochastic dynamical systems, hidden Markov models, and nonlinear, non-Gaussian, state-space models).  The package provides facilities for implementing POMP models, simulating them, and fitting them to time series data by a variety of frequentist and Bayesian methods.  It is also a versatile platform for implementation of inference methods for general POMP models.  "
  },
  {
    "id": 18193,
    "package_name": "popstudy",
    "title": "Applied Techniques to Demographic and Time Series Analysis",
    "description": "The use of overparameterization is proposed with combinatorial analysis to test a broader spectrum of possible ARIMA models.\n    In the selection of ARIMA models, the most traditional methods such as correlograms or others, do not usually cover many alternatives to define the number of coefficients to be estimated in the model, which represents an estimation method that is not the best.\n    The popstudy package contains several tools for statistical analysis in demography and time series based in Shryock research (Shryock et. al. (1980) <https://books.google.co.cr/books?id=8Oo6AQAAMAAJ>).",
    "version": "1.0.2",
    "maintainer": "Cesar Gamboa-Sanabria <info@cesargamboasanabria.com>",
    "author": "Cesar Gamboa-Sanabria [aut, mdc, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-6733-4759>)",
    "url": "https://www.cesargamboasanabria.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=popstudy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "popstudy Applied Techniques to Demographic and Time Series Analysis The use of overparameterization is proposed with combinatorial analysis to test a broader spectrum of possible ARIMA models.\n    In the selection of ARIMA models, the most traditional methods such as correlograms or others, do not usually cover many alternatives to define the number of coefficients to be estimated in the model, which represents an estimation method that is not the best.\n    The popstudy package contains several tools for statistical analysis in demography and time series based in Shryock research (Shryock et. al. (1980) <https://books.google.co.cr/books?id=8Oo6AQAAMAAJ>).  "
  },
  {
    "id": 18202,
    "package_name": "portes",
    "title": "Portmanteau Tests for Time Series Models",
    "description": "Contains common univariate and multivariate portmanteau test statistics for time series models. These tests are based on using asymptotic distributions such as chi-square distribution and based on using the Monte Carlo significance tests. Also, it can be used to simulate from univariate and multivariate seasonal time series models.",
    "version": "6.0",
    "maintainer": "Esam Mahdi <emahdi2012@gmail.com>",
    "author": "Esam Mahdi",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=portes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "portes Portmanteau Tests for Time Series Models Contains common univariate and multivariate portmanteau test statistics for time series models. These tests are based on using asymptotic distributions such as chi-square distribution and based on using the Monte Carlo significance tests. Also, it can be used to simulate from univariate and multivariate seasonal time series models.  "
  },
  {
    "id": 18208,
    "package_name": "portvine",
    "title": "Vine Based (Un)Conditional Portfolio Risk Measure Estimation",
    "description": "Following Sommer (2022) <https://mediatum.ub.tum.de/1658240>\n    portfolio level risk estimates (e.g. Value at Risk, Expected\n    Shortfall) are estimated by modeling each asset univariately by an\n    ARMA-GARCH model and then their cross dependence via a Vine Copula\n    model in a rolling window fashion. One can even condition on\n    variables/time series at certain quantile levels to stress test the\n    risk measure estimates.",
    "version": "1.0.3",
    "maintainer": "Emanuel Sommer <emanuel_sommer@gmx.de>",
    "author": "Emanuel Sommer [cre, aut]",
    "url": "https://github.com/EmanuelSommer/portvine,\nhttps://emanuelsommer.github.io/portvine/",
    "bug_reports": "https://github.com/EmanuelSommer/portvine/issues",
    "repository": "https://cran.r-project.org/package=portvine",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "portvine Vine Based (Un)Conditional Portfolio Risk Measure Estimation Following Sommer (2022) <https://mediatum.ub.tum.de/1658240>\n    portfolio level risk estimates (e.g. Value at Risk, Expected\n    Shortfall) are estimated by modeling each asset univariately by an\n    ARMA-GARCH model and then their cross dependence via a Vine Copula\n    model in a rolling window fashion. One can even condition on\n    variables/time series at certain quantile levels to stress test the\n    risk measure estimates.  "
  },
  {
    "id": 18259,
    "package_name": "ppdiag",
    "title": "Diagnosis and Visualizations Tools for Temporal Point Processes",
    "description": "A suite of diagnostic tools for univariate point processes.\n    This includes tools for simulating and fitting both common and more\n    complex temporal point processes. We also include functions to \n    visualise these point processes and collect existing diagnostic\n    tools of Brown et al. (2002) <doi:10.1162/08997660252741149> and\n    Wu et al. (2021) <doi:10.1002/9781119821588.ch7>,\n    which can be used to assess the fit of a chosen point process\n    model.",
    "version": "0.1.1",
    "maintainer": "Owen G. Ward <owen.ward@columbia.edu>",
    "author": "Sally Sun [aut],\n  Owen G. Ward [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9678-3542>),\n  Jing Wu [aut],\n  Xiaoxi Zhao [aut],\n  Lihao Xiao [ctb],\n  Tian Zheng [aut]",
    "url": "https://owenward.github.io/ppdiag/",
    "bug_reports": "https://github.com/OwenWard/ppdiag/issues",
    "repository": "https://cran.r-project.org/package=ppdiag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ppdiag Diagnosis and Visualizations Tools for Temporal Point Processes A suite of diagnostic tools for univariate point processes.\n    This includes tools for simulating and fitting both common and more\n    complex temporal point processes. We also include functions to \n    visualise these point processes and collect existing diagnostic\n    tools of Brown et al. (2002) <doi:10.1162/08997660252741149> and\n    Wu et al. (2021) <doi:10.1002/9781119821588.ch7>,\n    which can be used to assess the fit of a chosen point process\n    model.  "
  },
  {
    "id": 18284,
    "package_name": "pracma",
    "title": "Practical Numerical Math Functions",
    "description": "\n    Provides a large number of functions from numerical analysis and\n    linear algebra, numerical optimization, differential equations,\n    time series, plus some well-known special mathematical functions.\n    Uses 'MATLAB' function names where appropriate to simplify porting.",
    "version": "2.4.6",
    "maintainer": "Hans W. Borchers <hwborchers@googlemail.com>",
    "author": "Hans W. Borchers [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pracma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pracma Practical Numerical Math Functions \n    Provides a large number of functions from numerical analysis and\n    linear algebra, numerical optimization, differential equations,\n    time series, plus some well-known special mathematical functions.\n    Uses 'MATLAB' function names where appropriate to simplify porting.  "
  },
  {
    "id": 18316,
    "package_name": "predtoolsTS",
    "title": "Time Series Prediction Tools",
    "description": "Makes the time series prediction easier by automatizing this process\n  using four main functions: prep(), modl(), pred() and postp(). Features different\n  preprocessing methods to homogenize variance and to remove trend and seasonality.\n  Also has the potential to bring together different predictive models to make comparatives.\n  Features ARIMA and Data Mining Regression models (using caret).",
    "version": "0.1.1",
    "maintainer": "Alberto Vico Moreno <avm00016@red.ujaen.es>",
    "author": "Alberto Vico Moreno [aut, cre],\n  Antonio Jesus Rivera Rivas [aut, ths],\n  Maria Dolores Perez Godoy [aut, ths]",
    "url": "https://github.com/avm00016/predtoolsTS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=predtoolsTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "predtoolsTS Time Series Prediction Tools Makes the time series prediction easier by automatizing this process\n  using four main functions: prep(), modl(), pred() and postp(). Features different\n  preprocessing methods to homogenize variance and to remove trend and seasonality.\n  Also has the potential to bring together different predictive models to make comparatives.\n  Features ARIMA and Data Mining Regression models (using caret).  "
  },
  {
    "id": 18401,
    "package_name": "productivity",
    "title": "Indices of Productivity Using Data Envelopment Analysis (DEA)",
    "description": "\n  Levels and changes of productivity and profitability are measured with various indices.\n  The package contains the multiplicatively complete F\u00e4re-Primont, Fisher, Hicks-Moorsteen, \n  Laspeyres, Lowe, and Paasche indices, as well as the classic Malmquist productivity index.\n  F\u00e4re-Primont and Lowe indices verify the transitivity property and can therefore be used for \n  multilateral or multitemporal comparison.\n  Fisher, Hicks-Moorsteen, Laspeyres, Malmquist, and Paasche indices are not transitive and are \n  only to be used for binary comparison.\n  All indices can also be decomposed into different components, providing insightful information \n  on the sources of productivity and profitability changes.\n  In the use of Malmquist productivity index, the technological change index can be further \n  decomposed into bias technological change components.\n  The package also allows to prohibit technological regression (negative technological change). In \n  the case of the Fisher, Hicks-Moorsteen, Laspeyres, Paasche and the transitive F\u00e4re-Primont \n  and Lowe indices, it is furthermore possible to rule out technological change. \n  Deflated shadow prices can also be obtained. Besides, the package allows parallel computing as \n  an option, depending on the user's computer configuration. \n  All computations are carried out with the nonparametric Data Envelopment Analysis (DEA), and \n  several assumptions regarding returns to scale are available.\n  All DEA linear programs are implemented using 'lp_solve'.",
    "version": "1.1.0",
    "maintainer": "Yann Desjeux <yann.desjeux@inra.fr>",
    "author": "K Herv\u00e9 Dakpo [aut],\n  Yann Desjeux [aut, cre],\n  Laure Latruffe [aut]",
    "url": "",
    "bug_reports": "https://r-forge.r-project.org/tracker/?group_id=2245",
    "repository": "https://cran.r-project.org/package=productivity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "productivity Indices of Productivity Using Data Envelopment Analysis (DEA) \n  Levels and changes of productivity and profitability are measured with various indices.\n  The package contains the multiplicatively complete F\u00e4re-Primont, Fisher, Hicks-Moorsteen, \n  Laspeyres, Lowe, and Paasche indices, as well as the classic Malmquist productivity index.\n  F\u00e4re-Primont and Lowe indices verify the transitivity property and can therefore be used for \n  multilateral or multitemporal comparison.\n  Fisher, Hicks-Moorsteen, Laspeyres, Malmquist, and Paasche indices are not transitive and are \n  only to be used for binary comparison.\n  All indices can also be decomposed into different components, providing insightful information \n  on the sources of productivity and profitability changes.\n  In the use of Malmquist productivity index, the technological change index can be further \n  decomposed into bias technological change components.\n  The package also allows to prohibit technological regression (negative technological change). In \n  the case of the Fisher, Hicks-Moorsteen, Laspeyres, Paasche and the transitive F\u00e4re-Primont \n  and Lowe indices, it is furthermore possible to rule out technological change. \n  Deflated shadow prices can also be obtained. Besides, the package allows parallel computing as \n  an option, depending on the user's computer configuration. \n  All computations are carried out with the nonparametric Data Envelopment Analysis (DEA), and \n  several assumptions regarding returns to scale are available.\n  All DEA linear programs are implemented using 'lp_solve'.  "
  },
  {
    "id": 18410,
    "package_name": "profoc",
    "title": "Probabilistic Forecast Combination Using CRPS Learning",
    "description": "Combine probabilistic forecasts using CRPS learning algorithms proposed in Berrisch, Ziel (2021) <doi:10.48550/arXiv.2102.00968> <doi:10.1016/j.jeconom.2021.11.008>. The package implements multiple online learning algorithms like Bernstein online aggregation; see Wintenberger (2014) <doi:10.48550/arXiv.1404.1356>. Quantile regression is also implemented for comparison purposes. Model parameters can be tuned automatically with respect to the loss of the forecast combination. Methods like predict(), update(), plot() and print() are available for convenience. This package utilizes the optim C++ library for numeric optimization <https://github.com/kthohr/optim>.",
    "version": "1.3.3",
    "maintainer": "Jonathan Berrisch <Jonathan@Berrisch.biz>",
    "author": "Jonathan Berrisch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4944-9074>),\n  Florian Ziel [aut] (ORCID: <https://orcid.org/0000-0002-2974-2660>)",
    "url": "https://profoc.berrisch.biz, https://github.com/BerriJ/profoc",
    "bug_reports": "https://github.com/BerriJ/profoc/issues",
    "repository": "https://cran.r-project.org/package=profoc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "profoc Probabilistic Forecast Combination Using CRPS Learning Combine probabilistic forecasts using CRPS learning algorithms proposed in Berrisch, Ziel (2021) <doi:10.48550/arXiv.2102.00968> <doi:10.1016/j.jeconom.2021.11.008>. The package implements multiple online learning algorithms like Bernstein online aggregation; see Wintenberger (2014) <doi:10.48550/arXiv.1404.1356>. Quantile regression is also implemented for comparison purposes. Model parameters can be tuned automatically with respect to the loss of the forecast combination. Methods like predict(), update(), plot() and print() are available for convenience. This package utilizes the optim C++ library for numeric optimization <https://github.com/kthohr/optim>.  "
  },
  {
    "id": 18412,
    "package_name": "profrep",
    "title": "Profile Repeatability",
    "description": "Calculates profile repeatability for replicate stress response \n  curves, or similar time-series data. Profile repeatability is an individual \n  repeatability metric that uses the variances at each timepoint, the maximum \n  variance, the number of crossings (lines that cross over each other), and \n  the number of replicates to compute the repeatability score. \n  For more information see Reed et al. (2019) <doi:10.1016/j.ygcen.2018.09.015>. ",
    "version": "1.0.0",
    "maintainer": "Ursula K. Beattie <ursula.beattie@tufts.edu>",
    "author": "Ursula K. Beattie [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7131-3712>),\n  David Harris [aut, cph],\n  L. Michael Romero [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-8854-8884>),\n  J. Michael Reed [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-3571-2652>),\n  Zachary R. Weaver [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-6314-0690>)",
    "url": "https://ubeattie.github.io/profrep/",
    "bug_reports": "https://github.com/ubeattie/profrep/issues",
    "repository": "https://cran.r-project.org/package=profrep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "profrep Profile Repeatability Calculates profile repeatability for replicate stress response \n  curves, or similar time-series data. Profile repeatability is an individual \n  repeatability metric that uses the variances at each timepoint, the maximum \n  variance, the number of crossings (lines that cross over each other), and \n  the number of replicates to compute the repeatability score. \n  For more information see Reed et al. (2019) <doi:10.1016/j.ygcen.2018.09.015>.   "
  },
  {
    "id": 18427,
    "package_name": "promotionImpact",
    "title": "Analysis & Measurement of Promotion Effectiveness",
    "description": "Analysis and measurement of promotion effectiveness on a given target variable (e.g. daily sales). After converting promotion schedule into dummy or smoothed predictor variables, the package estimates the effects of these variables controlled for trend/periodicity/structural change using prophet by Taylor and Letham (2017) <doi:10.7287/peerj.preprints.3190v2> and some prespecified variables (e.g. start of a month).",
    "version": "0.1.5",
    "maintainer": "Nahyun Kim <nhkim1302@ncsoft.com>",
    "author": "Nahyun Kim [cre, aut],\n  Hyemin Um [aut],\n  Eunjo Lee [aut],\n  NCSOFT Corporation [cph]",
    "url": "https://github.com/ncsoft/promotionImpact",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=promotionImpact",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "promotionImpact Analysis & Measurement of Promotion Effectiveness Analysis and measurement of promotion effectiveness on a given target variable (e.g. daily sales). After converting promotion schedule into dummy or smoothed predictor variables, the package estimates the effects of these variables controlled for trend/periodicity/structural change using prophet by Taylor and Letham (2017) <doi:10.7287/peerj.preprints.3190v2> and some prespecified variables (e.g. start of a month).  "
  },
  {
    "id": 18431,
    "package_name": "promr",
    "title": "Prometheus 'PromQL' Query Client for 'R'",
    "description": "A native 'R' client library for querying the 'Prometheus' \n    time-series database, using the 'PromQL' query language.",
    "version": "0.1.3",
    "maintainer": "Dom Dwyer <dom@itsallbroken.com>",
    "author": "Dom Dwyer [aut, cre]",
    "url": "https://github.com/domodwyer/promr",
    "bug_reports": "https://github.com/domodwyer/promr/issues",
    "repository": "https://cran.r-project.org/package=promr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "promr Prometheus 'PromQL' Query Client for 'R' A native 'R' client library for querying the 'Prometheus' \n    time-series database, using the 'PromQL' query language.  "
  },
  {
    "id": 18437,
    "package_name": "prophet",
    "title": "Automatic Forecasting Procedure",
    "description": "Implements a procedure for forecasting time series data based on\n    an additive model where non-linear trends are fit with yearly, weekly, and\n    daily seasonality, plus holiday effects. It works best with time series\n    that have strong seasonal effects and several seasons of historical data.\n    Prophet is robust to missing data and shifts in the trend, and typically\n    handles outliers well.",
    "version": "1.0",
    "maintainer": "Sean Taylor <sjtz@pm.me>",
    "author": "Sean Taylor [cre, aut],\n  Ben Letham [aut]",
    "url": "https://github.com/facebook/prophet",
    "bug_reports": "https://github.com/facebook/prophet/issues",
    "repository": "https://cran.r-project.org/package=prophet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prophet Automatic Forecasting Procedure Implements a procedure for forecasting time series data based on\n    an additive model where non-linear trends are fit with yearly, weekly, and\n    daily seasonality, plus holiday effects. It works best with time series\n    that have strong seasonal effects and several seasons of historical data.\n    Prophet is robust to missing data and shifts in the trend, and typically\n    handles outliers well.  "
  },
  {
    "id": 18482,
    "package_name": "psdr",
    "title": "Use Time Series to Generate and Compare Power Spectral Density",
    "description": "Functions that allow you to generate and compare power spectral density (PSD) \n\tplots given time series data. Fast Fourier Transform (FFT) is used to take a time series \n\tdata, analyze the oscillations, and then output the frequencies of these oscillations \n\tin the time series in the form of a PSD plot.Thus given a time series, the dominant \n\tfrequencies in the time series can be identified. Additional functions in this package \n\tallow the dominant frequencies of multiple groups of time series to be compared with each other. \n\tTo see example usage with the main functions of this package, please visit\n\tthis site: <https://yhhc2.github.io/psdr/articles/Introduction.html>. \n\tThe mathematical operations used to generate the PSDs are described in these sites:\n\t<https://www.mathworks.com/help/matlab/ref/fft.html>.\n\t<https://www.mathworks.com/help/signal/ug/power-spectral-density-estimates-using-fft.html>.",
    "version": "1.0.3",
    "maintainer": "Yong-Han Hank Cheng <yhhc@uw.edu>",
    "author": "Yong-Han Hank Cheng [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7686-0697>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=psdr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "psdr Use Time Series to Generate and Compare Power Spectral Density Functions that allow you to generate and compare power spectral density (PSD) \n\tplots given time series data. Fast Fourier Transform (FFT) is used to take a time series \n\tdata, analyze the oscillations, and then output the frequencies of these oscillations \n\tin the time series in the form of a PSD plot.Thus given a time series, the dominant \n\tfrequencies in the time series can be identified. Additional functions in this package \n\tallow the dominant frequencies of multiple groups of time series to be compared with each other. \n\tTo see example usage with the main functions of this package, please visit\n\tthis site: <https://yhhc2.github.io/psdr/articles/Introduction.html>. \n\tThe mathematical operations used to generate the PSDs are described in these sites:\n\t<https://www.mathworks.com/help/matlab/ref/fft.html>.\n\t<https://www.mathworks.com/help/signal/ug/power-spectral-density-estimates-using-fft.html>.  "
  },
  {
    "id": 18500,
    "package_name": "pspatreg",
    "title": "Spatial and Spatio-Temporal Semiparametric Regression Models\nwith Spatial Lags",
    "description": "Estimation and inference of spatial and spatio-temporal \n    semiparametric models including spatial or spatio-temporal non-parametric \n    trends, parametric and non-parametric covariates and, possibly, a spatial \n    lag for the dependent variable and temporal correlation in the noise.\n    The spatio-temporal trend can be decomposed in ANOVA way including main and \n    interaction functional terms. Use of SAP algorithm to estimate the spatial \n    or spatio-temporal trend and non-parametric covariates. The methodology of \n    these models can be found in next references\n    Basile, R. et al. (2014), <doi:10.1016/j.jedc.2014.06.011>;\n    Rodriguez-Alvarez, M.X. et al. (2015) <doi:10.1007/s11222-014-9464-2> and,\n    particularly referred to the focus of the package, Minguez, R., \n    Basile, R. and Durban, M. (2020) <doi:10.1007/s10260-019-00492-8>.",
    "version": "1.1.2",
    "maintainer": "Roman Minguez <roman.minguez@uclm.es>",
    "author": "Roman Minguez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0490-3181>),\n  Roberto Basile [aut] (ORCID: <https://orcid.org/0000-0002-4531-2820>),\n  Maria Durban [aut] (ORCID: <https://orcid.org/0000-0002-4272-7895>),\n  Gonzalo Espana-Heredia [aut]",
    "url": "https://github.com/rominsal/pspatreg",
    "bug_reports": "https://github.com/rominsal/pspatreg/issues",
    "repository": "https://cran.r-project.org/package=pspatreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pspatreg Spatial and Spatio-Temporal Semiparametric Regression Models\nwith Spatial Lags Estimation and inference of spatial and spatio-temporal \n    semiparametric models including spatial or spatio-temporal non-parametric \n    trends, parametric and non-parametric covariates and, possibly, a spatial \n    lag for the dependent variable and temporal correlation in the noise.\n    The spatio-temporal trend can be decomposed in ANOVA way including main and \n    interaction functional terms. Use of SAP algorithm to estimate the spatial \n    or spatio-temporal trend and non-parametric covariates. The methodology of \n    these models can be found in next references\n    Basile, R. et al. (2014), <doi:10.1016/j.jedc.2014.06.011>;\n    Rodriguez-Alvarez, M.X. et al. (2015) <doi:10.1007/s11222-014-9464-2> and,\n    particularly referred to the focus of the package, Minguez, R., \n    Basile, R. and Durban, M. (2020) <doi:10.1007/s10260-019-00492-8>.  "
  },
  {
    "id": 18518,
    "package_name": "psychonetrics",
    "title": "Structural Equation Modeling and Confirmatory Network Analysis",
    "description": "Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.",
    "version": "0.13.2",
    "maintainer": "Sacha Epskamp <mail@sachaepskamp.com>",
    "author": "Sacha Epskamp [aut, cre]",
    "url": "http://psychonetrics.org/",
    "bug_reports": "https://github.com/SachaEpskamp/psychonetrics/issues",
    "repository": "https://cran.r-project.org/package=psychonetrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "psychonetrics Structural Equation Modeling and Confirmatory Network Analysis Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.  "
  },
  {
    "id": 18533,
    "package_name": "pttstability",
    "title": "Particle-Takens Stability",
    "description": "Includes a collection of functions presented in \"Measuring stability in ecological systems without static equilibria\" by Clark et al. (2022) <doi:10.1002/ecs2.4328> in Ecosphere.\n\tThese can be used to estimate the parameters of a stochastic state space model (i.e. a model where\n\ta time series is observed with error). The goal of this package is to estimate the variability\n\taround a deterministic process, both in terms of observation error - i.e. variability due to\n\timperfect observations that does not influence system state - and in terms of process noise - i.e.\n\tstochastic variation in the actual state of the process. Unlike classical methods for estimating\n\tvariability, this package does not necessarily assume that the deterministic state is fixed (i.e.\n\ta fixed-point equilibrium), meaning that variability around a dynamic trajectory can be estimated\n\t(e.g. stochastic fluctuations during predator-prey dynamics).",
    "version": "1.4",
    "maintainer": "Adam Clark <adam.tclark@gmail.com>",
    "author": "Adam Clark [aut, cre] (ORCID: <https://orcid.org/0000-0002-8843-3278>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pttstability",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pttstability Particle-Takens Stability Includes a collection of functions presented in \"Measuring stability in ecological systems without static equilibria\" by Clark et al. (2022) <doi:10.1002/ecs2.4328> in Ecosphere.\n\tThese can be used to estimate the parameters of a stochastic state space model (i.e. a model where\n\ta time series is observed with error). The goal of this package is to estimate the variability\n\taround a deterministic process, both in terms of observation error - i.e. variability due to\n\timperfect observations that does not influence system state - and in terms of process noise - i.e.\n\tstochastic variation in the actual state of the process. Unlike classical methods for estimating\n\tvariability, this package does not necessarily assume that the deterministic state is fixed (i.e.\n\ta fixed-point equilibrium), meaning that variability around a dynamic trajectory can be estimated\n\t(e.g. stochastic fluctuations during predator-prey dynamics).  "
  },
  {
    "id": 18632,
    "package_name": "qfa",
    "title": "Quantile-Frequency Analysis (QFA) of Time Series",
    "description": "Quantile-frequency analysis (QFA) of time series based on trigonometric quantile regression. \n Spline quantile regression (SQR) for regression coefficient estimation.\n References:\n    [1] Li, T.-H. (2012) \"Quantile periodograms,\" Journal of the American Statistical\n        Association, 107, 765\u2013776, <doi:10.1080/01621459.2012.682815>.\n    [2] Li, T.-H. (2014) Time Series with Mixed Spectra, CRC Press, <doi:10.1201/b15154>\n    [3] Li, T.-H. (2022) \"Quantile Fourier transform, quantile series, and nonparametric\n        estimation of quantile spectra,\" <doi:10.48550/arXiv.2211.05844>.\n    [4] Li, T.-H. (2024) \"Quantile crossing spectrum and spline autoregression\n         estimation,\" <doi:10.48550/arXiv.2412.02513>.\n    [5] Li, T.-H. (2024) \"Spline autoregression method for estimation of quantile spectrum,\"\n        <doi:10.48550/arXiv.2412.17163>.\n    [6] Li, T.-H., and Megiddo, N. (2025) \"Spline quantile regression,\" \n        <doi:10.48550/arXiv.2501.03883>.",
    "version": "4.2",
    "maintainer": "Ta-Hsin Li <thl024@outlook.com>",
    "author": "Ta-Hsin Li [cre, aut]",
    "url": "https://github.com/IBM/qfa, https://github.com/thl2019/QFA",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=qfa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "qfa Quantile-Frequency Analysis (QFA) of Time Series Quantile-frequency analysis (QFA) of time series based on trigonometric quantile regression. \n Spline quantile regression (SQR) for regression coefficient estimation.\n References:\n    [1] Li, T.-H. (2012) \"Quantile periodograms,\" Journal of the American Statistical\n        Association, 107, 765\u2013776, <doi:10.1080/01621459.2012.682815>.\n    [2] Li, T.-H. (2014) Time Series with Mixed Spectra, CRC Press, <doi:10.1201/b15154>\n    [3] Li, T.-H. (2022) \"Quantile Fourier transform, quantile series, and nonparametric\n        estimation of quantile spectra,\" <doi:10.48550/arXiv.2211.05844>.\n    [4] Li, T.-H. (2024) \"Quantile crossing spectrum and spline autoregression\n         estimation,\" <doi:10.48550/arXiv.2412.02513>.\n    [5] Li, T.-H. (2024) \"Spline autoregression method for estimation of quantile spectrum,\"\n        <doi:10.48550/arXiv.2412.17163>.\n    [6] Li, T.-H., and Megiddo, N. (2025) \"Spline quantile regression,\" \n        <doi:10.48550/arXiv.2501.03883>.  "
  },
  {
    "id": 18731,
    "package_name": "quantilogram",
    "title": "Cross-Quantilogram",
    "description": "Estimation and inference methods for the cross-quantilogram.\n    The cross-quantilogram is a measure of nonlinear dependence between\n    two variables, based on either unconditional or conditional quantile\n    functions.  It can be considered an extension of the correlogram,\n    which is a correlation function over multiple lag periods that mainly\n    focuses on linear dependency.  One can use the cross-quantilogram to\n    detect the presence of directional predictability from one time series\n    to another.  This package provides a statistical inference method\n    based on the stationary bootstrap.  For detailed theoretical and\n    empirical explanations, see Linton and Whang (2007) for univariate\n    time series analysis and Han, Linton, Oka and Whang (2016) for\n    multivariate time series analysis.  The full references for these key\n    publications are as follows: (1) Linton, O., and Whang, Y. J. (2007).\n    The quantilogram: with an application to evaluating directional\n    predictability.  Journal of Econometrics, 141(1), 250-282\n    <doi:10.1016/j.jeconom.2007.01.004>; (2) Han, H., Linton, O., Oka, T.,\n    and Whang, Y. J. (2016).  The cross-quantilogram: measuring quantile\n    dependence and testing directional predictability between time series.\n    Journal of Econometrics, 193(1), 251-270\n    <doi:10.1016/j.jeconom.2016.03.001>.",
    "version": "3.1.1",
    "maintainer": "Tatsushi Oka <oka.econ@gmail.com>",
    "author": "Tatsushi Oka [aut, cre],\n  Heejon Han [ctb],\n  Oliver Linton [ctb],\n  Yoon-Jae Whang [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=quantilogram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "quantilogram Cross-Quantilogram Estimation and inference methods for the cross-quantilogram.\n    The cross-quantilogram is a measure of nonlinear dependence between\n    two variables, based on either unconditional or conditional quantile\n    functions.  It can be considered an extension of the correlogram,\n    which is a correlation function over multiple lag periods that mainly\n    focuses on linear dependency.  One can use the cross-quantilogram to\n    detect the presence of directional predictability from one time series\n    to another.  This package provides a statistical inference method\n    based on the stationary bootstrap.  For detailed theoretical and\n    empirical explanations, see Linton and Whang (2007) for univariate\n    time series analysis and Han, Linton, Oka and Whang (2016) for\n    multivariate time series analysis.  The full references for these key\n    publications are as follows: (1) Linton, O., and Whang, Y. J. (2007).\n    The quantilogram: with an application to evaluating directional\n    predictability.  Journal of Econometrics, 141(1), 250-282\n    <doi:10.1016/j.jeconom.2007.01.004>; (2) Han, H., Linton, O., Oka, T.,\n    and Whang, Y. J. (2016).  The cross-quantilogram: measuring quantile\n    dependence and testing directional predictability between time series.\n    Journal of Econometrics, 193(1), 251-270\n    <doi:10.1016/j.jeconom.2016.03.001>.  "
  },
  {
    "id": 18742,
    "package_name": "quantspec",
    "title": "Quantile-Based Spectral Analysis of Time Series",
    "description": "Methods to determine, smooth and plot quantile periodograms for\n    univariate and multivariate time series. See Kley (2016) <doi:10.18637/jss.v070.i03>\n    for a description and tutorial.",
    "version": "1.2-4",
    "maintainer": "Tobias Kley <tobias.kley@uni-goettingen.de>",
    "author": "Tobias Kley [aut, cre],\n  Stefan Birr [ctb] (Contributions to lag window estimation)",
    "url": "https://github.com/tobiaskley/quantspec",
    "bug_reports": "https://github.com/tobiaskley/quantspec/issues",
    "repository": "https://cran.r-project.org/package=quantspec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "quantspec Quantile-Based Spectral Analysis of Time Series Methods to determine, smooth and plot quantile periodograms for\n    univariate and multivariate time series. See Kley (2016) <doi:10.18637/jss.v070.i03>\n    for a description and tutorial.  "
  },
  {
    "id": 18842,
    "package_name": "rEMM",
    "title": "Extensible Markov Model for Modelling Temporal Relationships\nBetween Clusters",
    "description": "Implements TRACDS (Temporal Relationships \n    between Clusters for Data Streams), a generalization of \n    Extensible Markov Model (EMM). TRACDS adds a temporal or order model\n    to data stream clustering by superimposing a dynamically adapting\n    Markov Chain. Also provides an implementation of EMM (TRACDS on top of tNN \n    data stream clustering). Development of this \n    package was supported in part by NSF IIS-0948893 and R21HG005912 from \n    the National Human Genome Research Institute. Hahsler and Dunham (2010) <doi:10.18637/jss.v035.i05>.",
    "version": "1.2.1",
    "maintainer": "Michael Hahsler <mhahsler@lyle.smu.edu>",
    "author": "Michael Hahsler [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2716-1405>),\n  Margaret H. Dunham [ctb]",
    "url": "https://github.com/mhahsler/rEMM",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rEMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rEMM Extensible Markov Model for Modelling Temporal Relationships\nBetween Clusters Implements TRACDS (Temporal Relationships \n    between Clusters for Data Streams), a generalization of \n    Extensible Markov Model (EMM). TRACDS adds a temporal or order model\n    to data stream clustering by superimposing a dynamically adapting\n    Markov Chain. Also provides an implementation of EMM (TRACDS on top of tNN \n    data stream clustering). Development of this \n    package was supported in part by NSF IIS-0948893 and R21HG005912 from \n    the National Human Genome Research Institute. Hahsler and Dunham (2010) <doi:10.18637/jss.v035.i05>.  "
  },
  {
    "id": 18845,
    "package_name": "rFIA",
    "title": "Estimation of Forest Variables using the FIA Database",
    "description": "The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted and model-based estimators to improve population, change, and ratio estimates.",
    "version": "1.1.2",
    "maintainer": "Jeffrey Doser <jwdoser@ncsu.edu>",
    "author": "Jeffrey Doser [aut, cre],\n  Hunter Stanke [aut],\n  Andrew Finley [aut]",
    "url": "https://github.com/doserjef/rFIA,\nhttps://www.doserlab.com/files/rFIA",
    "bug_reports": "https://github.com/doserjef/rFIA/issues",
    "repository": "https://cran.r-project.org/package=rFIA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rFIA Estimation of Forest Variables using the FIA Database The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted and model-based estimators to improve population, change, and ratio estimates.  "
  },
  {
    "id": 18867,
    "package_name": "rMEA",
    "title": "Synchrony in Motion Energy Analysis (MEA) Time-Series",
    "description": "A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Kleinbub, J. R., & Ramseyer, F. T. (2020). rMEA: An R package to assess nonverbal synchronization in motion energy analysis time-series. Psychotherapy research, 1-14. <doi:10.1080/10503307.2020.1844334>.",
    "version": "1.2.2",
    "maintainer": "Johann R. Kleinbub <johann.kleinbub@gmail.com>",
    "author": "Johann R. Kleinbub, Fabian Ramseyer",
    "url": "https://github.com/kleinbub/rMEA https://psync.ch",
    "bug_reports": "https://github.com/kleinbub/rMEA/issues",
    "repository": "https://cran.r-project.org/package=rMEA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rMEA Synchrony in Motion Energy Analysis (MEA) Time-Series A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Kleinbub, J. R., & Ramseyer, F. T. (2020). rMEA: An R package to assess nonverbal synchronization in motion energy analysis time-series. Psychotherapy research, 1-14. <doi:10.1080/10503307.2020.1844334>.  "
  },
  {
    "id": 18894,
    "package_name": "rSPARCS",
    "title": "Sites, Population, and Records Cleaning Skills",
    "description": "Data cleaning including 1) generating datasets for time-series and case-crossover analyses based on raw hospital records, 2) linking individuals to an areal map, 3) picking out cases living within a buffer of certain size surrounding a site, etc. For more information, please refer to Zhang W,etc. (2018) <doi:10.1016/j.envpol.2018.08.030>. ",
    "version": "0.1.1",
    "maintainer": "Wangjian Zhang <zhangwj227@mail.sysu.edu.cn>",
    "author": "Wangjian Zhang [aut, cre],\n  Zhicheng Du [aut],\n  Xinlei Deng [aut],\n  Ziqiang Lin [aut],\n  Bo Ye [aut],\n  Jijin Yao [aut],\n  Yanan Jin [aut],\n  Wayne Lawrence [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rSPARCS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rSPARCS Sites, Population, and Records Cleaning Skills Data cleaning including 1) generating datasets for time-series and case-crossover analyses based on raw hospital records, 2) linking individuals to an areal map, 3) picking out cases living within a buffer of certain size surrounding a site, etc. For more information, please refer to Zhang W,etc. (2018) <doi:10.1016/j.envpol.2018.08.030>.   "
  },
  {
    "id": 18900,
    "package_name": "rTG",
    "title": "Methods to Analyse Seasonal Radial Tree Growth Data",
    "description": "Methods for comparing different regression algorithms for \n    describing the temporal dynamics of secondary tree growth (xylem and \n    phloem). Users can compare the accuracy of the most common fitting methods \n    usually used to analyse xylem and phloem data, i.e., Gompertz function, \n    Double Gompertz function, General Additive Models (GAMs); and an algorithm \n    newly introduced to the field, i.e., Bayesian Regularised Neural Networks \n    (brnn). The core function of the package is XPSgrowth(), while the results \n    can be interpreted using implemented generic S3 methods, such as plot() and \n    summary().",
    "version": "1.0.4",
    "maintainer": "Jernej Jevsenak <jernej.jevsenak@gmail.com>",
    "author": "Jernej Jevsenak [aut, cre]",
    "url": "https://github.com/jernejjevsenak/rTG",
    "bug_reports": "https://github.com/jernejjevsenak/rTG/issues",
    "repository": "https://cran.r-project.org/package=rTG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rTG Methods to Analyse Seasonal Radial Tree Growth Data Methods for comparing different regression algorithms for \n    describing the temporal dynamics of secondary tree growth (xylem and \n    phloem). Users can compare the accuracy of the most common fitting methods \n    usually used to analyse xylem and phloem data, i.e., Gompertz function, \n    Double Gompertz function, General Additive Models (GAMs); and an algorithm \n    newly introduced to the field, i.e., Bayesian Regularised Neural Networks \n    (brnn). The core function of the package is XPSgrowth(), while the results \n    can be interpreted using implemented generic S3 methods, such as plot() and \n    summary().  "
  },
  {
    "id": 19021,
    "package_name": "rasterVis",
    "title": "Visualization Methods for Raster Data",
    "description": "Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.",
    "version": "0.51.7",
    "maintainer": "Oscar Perpinan Lamigueiro <oscar.perpinan@upm.es>",
    "author": "Oscar Perpinan Lamigueiro [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-4134-7196>),\n  Robert Hijmans [aut],\n  Alexandre Courtiol [ctb]",
    "url": "https://oscarperpinan.codeberg.page/rastervis/",
    "bug_reports": "https://codeberg.org/oscarperpinan/rastervis/issues",
    "repository": "https://cran.r-project.org/package=rasterVis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rasterVis Visualization Methods for Raster Data Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.  "
  },
  {
    "id": 19069,
    "package_name": "rblt",
    "title": "Bio-Logging Toolbox",
    "description": "An R-shiny application to visualize bio-loggers time series at a microsecond precision as Acceleration, Temperature, Pressure, Light intensity. It is possible to link behavioral labels extracted\n  from 'BORIS' software <http://www.boris.unito.it> or manually written in a csv file.",
    "version": "0.2.4.7",
    "maintainer": "Sebastien Geiger <sebastien.geiger@iphc.cnrs.fr>",
    "author": "Sebastien Geiger [aut, cre]",
    "url": "https://github.com/sg4r/rblt",
    "bug_reports": "https://github.com/sg4r/rblt/issues",
    "repository": "https://cran.r-project.org/package=rblt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rblt Bio-Logging Toolbox An R-shiny application to visualize bio-loggers time series at a microsecond precision as Acceleration, Temperature, Pressure, Light intensity. It is possible to link behavioral labels extracted\n  from 'BORIS' software <http://www.boris.unito.it> or manually written in a csv file.  "
  },
  {
    "id": 19120,
    "package_name": "rcrimeanalysis",
    "title": "An Implementation of Crime Analysis Methods",
    "description": "An implementation of functions for the analysis of crime incident or records\n  management system data. The package implements analysis algorithms scaled for city\n  or regional crime analysis units. The package provides functions for kernel density\n  estimation for crime heat maps, geocoding using the 'Google Maps' API, identification \n  of repeat crime incidents, spatio-temporal map comparison across time intervals, \n  time series analysis (forecasting and decomposition), detection of optimal parameters \n  for the identification of near repeat incidents, and near repeat analysis with crime \n  network linkage.",
    "version": "0.5.0",
    "maintainer": "Jamie Spaulding <jspaulding02@hamline.edu>",
    "author": "Jamie Spaulding and Keith Morris",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rcrimeanalysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcrimeanalysis An Implementation of Crime Analysis Methods An implementation of functions for the analysis of crime incident or records\n  management system data. The package implements analysis algorithms scaled for city\n  or regional crime analysis units. The package provides functions for kernel density\n  estimation for crime heat maps, geocoding using the 'Google Maps' API, identification \n  of repeat crime incidents, spatio-temporal map comparison across time intervals, \n  time series analysis (forecasting and decomposition), detection of optimal parameters \n  for the identification of near repeat incidents, and near repeat analysis with crime \n  network linkage.  "
  },
  {
    "id": 19156,
    "package_name": "rdwd",
    "title": "Select and Download Climate Data from 'DWD' (German Weather\nService)",
    "description": "Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see \n             <https://www.dwd.de/EN/climate_environment/cdc/cdc_node_en.html> for more information).\n             Choose observational time series from meteorological stations with 'selectDWD()'.\n             Find raster data from radar and interpolation according to <https://bookdown.org/brry/rdwd/raster-data.html>.\n             Download (multiple) data sets with progress bars and no re-downloads through 'dataDWD()'.\n             Read both tabular observational data and binary gridded datasets with 'readDWD()'.",
    "version": "1.9.3",
    "maintainer": "Berry Boessenkool <berry-b@gmx.de>",
    "author": "Berry Boessenkool [aut, cre]",
    "url": "https://bookdown.org/brry/rdwd/",
    "bug_reports": "https://github.com/brry/rdwd/issues",
    "repository": "https://cran.r-project.org/package=rdwd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdwd Select and Download Climate Data from 'DWD' (German Weather\nService) Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see \n             <https://www.dwd.de/EN/climate_environment/cdc/cdc_node_en.html> for more information).\n             Choose observational time series from meteorological stations with 'selectDWD()'.\n             Find raster data from radar and interpolation according to <https://bookdown.org/brry/rdwd/raster-data.html>.\n             Download (multiple) data sets with progress bars and no re-downloads through 'dataDWD()'.\n             Read both tabular observational data and binary gridded datasets with 'readDWD()'.  "
  },
  {
    "id": 19178,
    "package_name": "readabs",
    "title": "Download and Tidy Time Series Data from the Australian Bureau of\nStatistics",
    "description": "Downloads, imports, and tidies time series data from the \n    Australian Bureau of Statistics <https://www.abs.gov.au/>.",
    "version": "0.4.19",
    "maintainer": "Matt Cowgill <mattcowgill@gmail.com>",
    "author": "Matt Cowgill [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0422-3300>),\n  Zoe Meers [aut],\n  Jaron Lee [aut],\n  David Diviny [aut],\n  Hugh Parsonage [ctb],\n  Kinto Behr [ctb],\n  Angus Moore [ctb],\n  Francis Markham [ctb] (ORCID: <https://orcid.org/0000-0002-4266-2569>)",
    "url": "https://github.com/mattcowgill/readabs",
    "bug_reports": "https://github.com/mattcowgill/readabs/issues",
    "repository": "https://cran.r-project.org/package=readabs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "readabs Download and Tidy Time Series Data from the Australian Bureau of\nStatistics Downloads, imports, and tidies time series data from the \n    Australian Bureau of Statistics <https://www.abs.gov.au/>.  "
  },
  {
    "id": 19189,
    "package_name": "readrba",
    "title": "Download and Tidy Data from the Reserve Bank of Australia",
    "description": "Download up-to-date data from the Reserve Bank of Australia \n    in a tidy data frame. Package includes functions to download current and \n    historical statistical tables \n    (<https://www.rba.gov.au/statistics/tables/>) and forecasts \n    (<https://www.rba.gov.au/publications/smp/forecasts-archive.html>). Data\n    includes a broad range of Australian macroeconomic and financial time\n    series.",
    "version": "0.1.12",
    "maintainer": "Matt Cowgill <mattcowgill@gmail.com>",
    "author": "Matt Cowgill [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0422-3300>),\n  Angus Moore [ctb]",
    "url": "https://mattcowgill.github.io/readrba/index.html",
    "bug_reports": "https://github.com/MattCowgill/readrba/issues",
    "repository": "https://cran.r-project.org/package=readrba",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "readrba Download and Tidy Data from the Reserve Bank of Australia Download up-to-date data from the Reserve Bank of Australia \n    in a tidy data frame. Package includes functions to download current and \n    historical statistical tables \n    (<https://www.rba.gov.au/statistics/tables/>) and forecasts \n    (<https://www.rba.gov.au/publications/smp/forecasts-archive.html>). Data\n    includes a broad range of Australian macroeconomic and financial time\n    series.  "
  },
  {
    "id": 19282,
    "package_name": "regions",
    "title": "Processing Regional Statistics",
    "description": "Validating sub-national statistical typologies, re-coding across \n    standard typologies of sub-national statistics, and making valid aggregate\n    level imputation, re-aggregation, re-weighting and projection down to \n    lower hierarchical levels to create meaningful data panels and time series.",
    "version": "0.1.8",
    "maintainer": "Daniel Antal <daniel.antal@ceemid.eu>",
    "author": "Daniel Antal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7513-6760>),\n  Kasia Kulma [ctb] (ORCID: <https://orcid.org/0000-0002-2952-9720>),\n  Istvan Zsoldos [ctb] (ORCID: <https://orcid.org/0000-0001-5712-2103>),\n  Leo Lahti [ctb] (ORCID: <https://orcid.org/0000-0001-5537-637X>)",
    "url": "https://regions.dataobservatory.eu/",
    "bug_reports": "https://github.com/rOpenGov/regions",
    "repository": "https://cran.r-project.org/package=regions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "regions Processing Regional Statistics Validating sub-national statistical typologies, re-coding across \n    standard typologies of sub-national statistics, and making valid aggregate\n    level imputation, re-aggregation, re-weighting and projection down to \n    lower hierarchical levels to create meaningful data panels and time series.  "
  },
  {
    "id": 19300,
    "package_name": "regspec",
    "title": "Non-Parametric Bayesian Spectrum Estimation for Multirate Data",
    "description": "Computes linear Bayesian spectral estimates from multirate\tdata for second-order stationary time series. Provides credible intervals and methods for plotting various spectral estimates. Please see the paper `Should we sample a time series more frequently?' (doi below) for a full description of and motivation for the methodology.",
    "version": "2.7",
    "maintainer": "Ben Powell <ben.powell@york.ac.uk>",
    "author": "Ben Powell [aut, cre],\n  Guy Nason [aut]",
    "url": "https://doi.org/10.1111/rssa.12210",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=regspec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "regspec Non-Parametric Bayesian Spectrum Estimation for Multirate Data Computes linear Bayesian spectral estimates from multirate\tdata for second-order stationary time series. Provides credible intervals and methods for plotting various spectral estimates. Please see the paper `Should we sample a time series more frequently?' (doi below) for a full description of and motivation for the methodology.  "
  },
  {
    "id": 19303,
    "package_name": "regtools",
    "title": "Regression and Classification Tools",
    "description": "Tools for linear, nonlinear and nonparametric regression\n             and classification.  Novel graphical methods for assessment \n             of parametric models using nonparametric methods. One \n             vs. All and All vs. All multiclass classification, optional\n             class probabilities adjustment.  Nonparametric regression \n             (k-NN) for general dimension, local-linear option.  Nonlinear \n             regression with Eickert-White method for dealing with \n             heteroscedasticity.  Utilities for converting time series\n             to rectangular form.  Utilities for conversion between\n             factors and indicator variables.  Some code related to\n             \"Statistical Regression and Classification: from Linear\n             Models to Machine Learning\", N. Matloff, 2017, CRC,\n             ISBN 9781498710916.",
    "version": "1.7.0",
    "maintainer": "Norm Matloff <matloff@cs.ucdavis.edu>",
    "author": "Norm Matloff [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9179-6785>),\n  Robin Yancey [aut],\n  Bochao Xin [ctb],\n  Kenneth Lee [ctb],\n  Rongkui Han [ctb]",
    "url": "https://github.com/matloff/regtools",
    "bug_reports": "https://github.com/matloff/regtools/issues",
    "repository": "https://cran.r-project.org/package=regtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "regtools Regression and Classification Tools Tools for linear, nonlinear and nonparametric regression\n             and classification.  Novel graphical methods for assessment \n             of parametric models using nonparametric methods. One \n             vs. All and All vs. All multiclass classification, optional\n             class probabilities adjustment.  Nonparametric regression \n             (k-NN) for general dimension, local-linear option.  Nonlinear \n             regression with Eickert-White method for dealing with \n             heteroscedasticity.  Utilities for converting time series\n             to rectangular form.  Utilities for conversion between\n             factors and indicator variables.  Some code related to\n             \"Statistical Regression and Classification: from Linear\n             Models to Machine Learning\", N. Matloff, 2017, CRC,\n             ISBN 9781498710916.  "
  },
  {
    "id": 19329,
    "package_name": "remify",
    "title": "Processing and Transforming Relational Event History Data",
    "description": "Efficiently processes relational event history data and transforms them into formats suitable for other packages. The primary objective of this package is to convert event history data into a format that integrates with the packages in 'remverse' and is compatible with various analytical tools (e.g., computing network statistics, estimating tie-oriented or actor-oriented social network models). Second, it can also transform the data into formats compatible with other packages out of 'remverse'. The package processes the data for two types of temporal social network models: tie-oriented modeling framework (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented modeling framework (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>). ",
    "version": "3.2.9",
    "maintainer": "Giuseppe Arena <g.arena@uva.nl>",
    "author": "Giuseppe Arena [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5204-3326>),\n  Rumana Lakdawala [ctb],\n  Marlyne Meijerink-Bosman [ctb],\n  Diana Karimova [ctb],\n  Fabio Generoso Vieira [ctb],\n  Mahdi Shafiee Kamalabad [ctb],\n  Roger Leenders [ctb],\n  Joris Mulder [ctb]",
    "url": "https://tilburgnetworkgroup.github.io/remify/",
    "bug_reports": "https://github.com/TilburgNetworkGroup/remify/issues",
    "repository": "https://cran.r-project.org/package=remify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "remify Processing and Transforming Relational Event History Data Efficiently processes relational event history data and transforms them into formats suitable for other packages. The primary objective of this package is to convert event history data into a format that integrates with the packages in 'remverse' and is compatible with various analytical tools (e.g., computing network statistics, estimating tie-oriented or actor-oriented social network models). Second, it can also transform the data into formats compatible with other packages out of 'remverse'. The package processes the data for two types of temporal social network models: tie-oriented modeling framework (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented modeling framework (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>).   "
  },
  {
    "id": 19333,
    "package_name": "remote",
    "title": "Empirical Orthogonal Teleconnections in R",
    "description": "Empirical orthogonal teleconnections in R.\n    'remote' is short for 'R(-based) EMpirical Orthogonal TEleconnections'.\n    It implements a collection of functions to facilitate empirical\n    orthogonal teleconnection analysis. Empirical Orthogonal Teleconnections\n    (EOTs) denote a regression based approach to decompose spatio-temporal\n    fields into a set of independent orthogonal patterns. They are quite\n    similar to Empirical Orthogonal Functions (EOFs) with EOTs producing\n    less abstract results. In contrast to EOFs, which are orthogonal in both\n    space and time, EOT analysis produces patterns that are orthogonal in\n    either space or time.",
    "version": "1.2.3",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "author": "Tim Appelhans [cre, aut],\n  Florian Detsch [aut],\n  Thomas Nauss [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=remote",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "remote Empirical Orthogonal Teleconnections in R Empirical orthogonal teleconnections in R.\n    'remote' is short for 'R(-based) EMpirical Orthogonal TEleconnections'.\n    It implements a collection of functions to facilitate empirical\n    orthogonal teleconnection analysis. Empirical Orthogonal Teleconnections\n    (EOTs) denote a regression based approach to decompose spatio-temporal\n    fields into a set of independent orthogonal patterns. They are quite\n    similar to Empirical Orthogonal Functions (EOFs) with EOTs producing\n    less abstract results. In contrast to EOFs, which are orthogonal in both\n    space and time, EOT analysis produces patterns that are orthogonal in\n    either space or time.  "
  },
  {
    "id": 19334,
    "package_name": "remotePARTS",
    "title": "Spatiotemporal Autoregression Analyses for Large Data Sets",
    "description": "\n  These tools were created to test map-scale hypotheses about trends in large\n  remotely sensed data sets but any data with spatial and temporal variation\n  can be analyzed. Tests are conducted using the PARTS method for analyzing spatially\n  autocorrelated time series\n  (Ives et al., 2021: <doi:10.1016/j.rse.2021.112678>).\n  The method's unique approach can handle extremely large data sets that other\n  spatiotemporal models cannot, while still appropriately accounting for\n  spatial and temporal autocorrelation. This is done by partitioning the data\n  into smaller chunks, analyzing chunks separately and then combining the\n  separate analyses into a single, correlated test of the map-scale hypotheses.",
    "version": "1.0.4",
    "maintainer": "Clay Morrow <morrowcj@outlook.com>",
    "author": "Clay Morrow [aut, cre] (ORCID: <https://orcid.org/0000-0002-3069-3296>),\n  Anthony Ives [aut] (ORCID: <https://orcid.org/0000-0001-9375-9523>)",
    "url": "https://github.com/morrowcj/remotePARTS",
    "bug_reports": "https://github.com/morrowcj/remotePARTS/issues",
    "repository": "https://cran.r-project.org/package=remotePARTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "remotePARTS Spatiotemporal Autoregression Analyses for Large Data Sets \n  These tools were created to test map-scale hypotheses about trends in large\n  remotely sensed data sets but any data with spatial and temporal variation\n  can be analyzed. Tests are conducted using the PARTS method for analyzing spatially\n  autocorrelated time series\n  (Ives et al., 2021: <doi:10.1016/j.rse.2021.112678>).\n  The method's unique approach can handle extremely large data sets that other\n  spatiotemporal models cannot, while still appropriately accounting for\n  spatial and temporal autocorrelation. This is done by partitioning the data\n  into smaller chunks, analyzing chunks separately and then combining the\n  separate analyses into a single, correlated test of the map-scale hypotheses.  "
  },
  {
    "id": 19339,
    "package_name": "remulate",
    "title": "Simulate Dynamic Networks from Relational Event Models",
    "description": "Model based simulation of dynamic networks under tie-oriented (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>) relational event models. Supports simulation from a variety of relational event model extensions, including temporal variability in effects, heterogeneity through dyadic latent class relational event models (DLC-REM), random effects, blockmodels, and memory decay in relational event models (Lakdawala, R., 2024 <doi:10.48550/arXiv.2403.19329>). The development of this package was supported by a Vidi Grant (452-17-006) awarded by the Netherlands Organization for Scientific Research (NWO) Grant and an ERC Starting Grant  (758791).",
    "version": "2.1.0",
    "maintainer": "Rumana Lakdawala <rumanalakdawala@gmail.com>",
    "author": "Rumana Lakdawala [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9992-6035>),\n  Marlyne Meijerink-Bosman [ctb],\n  Giuseppe Arena [ctb],\n  Diana Karimova [ctb],\n  Mahdi Shafiee Kamalabad [ctb],\n  Fabio Generoso Vieira [ctb],\n  Roger Leenders [ctb],\n  Joris Mulder [ctb]",
    "url": "https://github.com/TilburgNetworkGroup/remulate",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=remulate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "remulate Simulate Dynamic Networks from Relational Event Models Model based simulation of dynamic networks under tie-oriented (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>) relational event models. Supports simulation from a variety of relational event model extensions, including temporal variability in effects, heterogeneity through dyadic latent class relational event models (DLC-REM), random effects, blockmodels, and memory decay in relational event models (Lakdawala, R., 2024 <doi:10.48550/arXiv.2403.19329>). The development of this package was supported by a Vidi Grant (452-17-006) awarded by the Netherlands Organization for Scientific Research (NWO) Grant and an ERC Starting Grant  (758791).  "
  },
  {
    "id": 19388,
    "package_name": "reservoirnet",
    "title": "Reservoir Computing and Echo State Networks",
    "description": "A simple user-friendly library based on the 'python' module 'reservoirpy'.\n             It provides a flexible interface to implement efficient Reservoir\n             Computing (RC) architectures with a particular focus on Echo State Networks\n             (ESN). Some of its features are: offline and online training, parallel implementation, \n             sparse matrix computation, fast spectral initialization, advanced learning \n             rules (e.g. Intrinsic Plasticity) etc. It also makes possible to easily create \n             complex architectures with multiple reservoirs (e.g. deep reservoirs), readouts, \n             and complex feedback loops. Moreover, graphical tools are included to easily \n             explore hyperparameters. Finally, it includes several tutorials exploring\n             time series forecasting, classification and hyperparameter tuning. For more information\n             about 'reservoirpy', please see Trouvain et al. (2020) <doi:10.1007/978-3-030-61616-8_40>.\n             This package was developed in the framework of the University of Bordeaux\u2019s IdEx\n             \"Investments for the Future\" program / RRI PHDS.",
    "version": "0.3.0",
    "maintainer": "Thomas Ferte <thomas.ferte@u-bordeaux.fr>",
    "author": "Thomas Ferte [aut, cre, trl],\n  Kalidou Ba [aut, trl],\n  Nathan Trouvain [aut],\n  Rodolphe Thiebaut [aut],\n  Xavier Hinaut [aut],\n  Boris Hejblum [aut, trl]",
    "url": "https://github.com/reservoirpy/reservoirR",
    "bug_reports": "https://github.com/reservoirpy/reservoirR/issues",
    "repository": "https://cran.r-project.org/package=reservoirnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "reservoirnet Reservoir Computing and Echo State Networks A simple user-friendly library based on the 'python' module 'reservoirpy'.\n             It provides a flexible interface to implement efficient Reservoir\n             Computing (RC) architectures with a particular focus on Echo State Networks\n             (ESN). Some of its features are: offline and online training, parallel implementation, \n             sparse matrix computation, fast spectral initialization, advanced learning \n             rules (e.g. Intrinsic Plasticity) etc. It also makes possible to easily create \n             complex architectures with multiple reservoirs (e.g. deep reservoirs), readouts, \n             and complex feedback loops. Moreover, graphical tools are included to easily \n             explore hyperparameters. Finally, it includes several tutorials exploring\n             time series forecasting, classification and hyperparameter tuning. For more information\n             about 'reservoirpy', please see Trouvain et al. (2020) <doi:10.1007/978-3-030-61616-8_40>.\n             This package was developed in the framework of the University of Bordeaux\u2019s IdEx\n             \"Investments for the Future\" program / RRI PHDS.  "
  },
  {
    "id": 19395,
    "package_name": "reslr",
    "title": "Modelling Relative Sea Level Data",
    "description": "The Bayesian modelling of relative sea-level data\n    using a comprehensive approach that incorporates\n    various statistical models within a unifying framework. \n    Details regarding each statistical models; \n    linear regression (Ashe et al 2019) <doi:10.1016/j.quascirev.2018.10.032>, \n    change point models (Cahill et al 2015) <doi:10.1088/1748-9326/10/8/084002>, \n    integrated Gaussian process models (Cahill et al 2015) <doi:10.1214/15-AOAS824>, \n    temporal splines (Upton et al 2023) <arXiv:2301.09556>, \n    spatio-temporal splines (Upton et al 2023) <arXiv:2301.09556> and\n    generalised additive models (Upton et al 2023) <arXiv:2301.09556>.\n    This package facilitates data loading, \n    model fitting and result summarisation.\n    Notably, it accommodates the inherent measurement errors\n    found in relative sea-level data across multiple dimensions,\n    allowing for their inclusion in the statistical models.",
    "version": "0.1.1",
    "maintainer": "Maeve Upton <uptonmaeve010@gmail.com>",
    "author": "Maeve Upton [cph, aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3185-7731>),\n  Andrew Parnell [aut],\n  Niamh Cahill [aut]",
    "url": "https://github.com/maeveupton/reslr,\nhttps://maeveupton.github.io/reslr/",
    "bug_reports": "https://github.com/maeveupton/reslr/issues",
    "repository": "https://cran.r-project.org/package=reslr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "reslr Modelling Relative Sea Level Data The Bayesian modelling of relative sea-level data\n    using a comprehensive approach that incorporates\n    various statistical models within a unifying framework. \n    Details regarding each statistical models; \n    linear regression (Ashe et al 2019) <doi:10.1016/j.quascirev.2018.10.032>, \n    change point models (Cahill et al 2015) <doi:10.1088/1748-9326/10/8/084002>, \n    integrated Gaussian process models (Cahill et al 2015) <doi:10.1214/15-AOAS824>, \n    temporal splines (Upton et al 2023) <arXiv:2301.09556>, \n    spatio-temporal splines (Upton et al 2023) <arXiv:2301.09556> and\n    generalised additive models (Upton et al 2023) <arXiv:2301.09556>.\n    This package facilitates data loading, \n    model fitting and result summarisation.\n    Notably, it accommodates the inherent measurement errors\n    found in relative sea-level data across multiple dimensions,\n    allowing for their inclusion in the statistical models.  "
  },
  {
    "id": 19397,
    "package_name": "resourcecodedata",
    "title": "Resourcecode Database Configuration Data",
    "description": "Includes Resourcecode hindcast database (see\n    <https://resourcecode.ifremer.fr>) configuration data: nodes locations\n    for both the sea-state parameters and the spectra data; examples of\n    time series of 1D and 2D surface elevation variance spectral density.",
    "version": "1.0.0",
    "maintainer": "Nicolas Raillard <nicolas.raillard@ifremer.fr>",
    "author": "Nicolas Raillard [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3385-5104>)",
    "url": "https://github.com/Resourcecode-project/r-resourcecodedata/,\nhttps://resourcecode-project.r-universe.dev/resourcecodedata/,\nhttps://resourcecode-project.github.io/r-resourcecodedata/",
    "bug_reports": "https://github.com/Resourcecode-project/r-resourcecodedata/issues",
    "repository": "https://cran.r-project.org/package=resourcecodedata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "resourcecodedata Resourcecode Database Configuration Data Includes Resourcecode hindcast database (see\n    <https://resourcecode.ifremer.fr>) configuration data: nodes locations\n    for both the sea-state parameters and the spectra data; examples of\n    time series of 1D and 2D surface elevation variance spectral density.  "
  },
  {
    "id": 19399,
    "package_name": "respR",
    "title": "Import, Process, Analyse, and Calculate Rates from Respirometry\nData",
    "description": "Provides a structural, reproducible workflow for the\n    processing and analysis of respirometry data. It contains analytical\n    functions and utilities for working with oxygen time-series to determine\n    respiration or oxygen production rates, and to make it easier to report and\n    share analyses. See Harianto et al. 2019 <doi:10.1111/2041-210X.13162>.",
    "version": "2.3.4",
    "maintainer": "Nicholas Carey <nicholascarey@gmail.com>",
    "author": "Nicholas Carey [aut, cre],\n  Januar Harianto [aut]",
    "url": "https://github.com/januarharianto/respr,\nhttps://januarharianto.github.io/respR/,\nhttps://doi.org/10.1111/2041-210X.13162",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=respR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "respR Import, Process, Analyse, and Calculate Rates from Respirometry\nData Provides a structural, reproducible workflow for the\n    processing and analysis of respirometry data. It contains analytical\n    functions and utilities for working with oxygen time-series to determine\n    respiration or oxygen production rates, and to make it easier to report and\n    share analyses. See Harianto et al. 2019 <doi:10.1111/2041-210X.13162>.  "
  },
  {
    "id": 19417,
    "package_name": "retistruct",
    "title": "Retinal Reconstruction Program",
    "description": "Reconstructs retinae by morphing a flat surface with cuts\n    (a dissected flat-mount retina) onto a curvilinear surface (the\n    standard retinal shape). It can estimate the position of a point\n    on the intact adult retina to within 8 degrees of arc (3.6% of\n    nasotemporal axis). The coordinates in reconstructed retinae can\n    be transformed to visuotopic coordinates. For more details see\n    Sterratt, D. C., Lyngholm, D., Willshaw, D. J. and Thompson, I. D.\n    (2013) <doi:10.1371/journal.pcbi.1002921>.",
    "version": "0.8.1",
    "maintainer": "David C. Sterratt <david.c.sterratt@ed.ac.uk>",
    "author": "David C. Sterratt [aut, cre, cph],\n  Daniel Lyngholm [aut, cph],\n  Jan Okul [aut, cph]",
    "url": "http://davidcsterratt.github.io/retistruct/",
    "bug_reports": "https://github.com/davidcsterratt/retistruct/issues",
    "repository": "https://cran.r-project.org/package=retistruct",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "retistruct Retinal Reconstruction Program Reconstructs retinae by morphing a flat surface with cuts\n    (a dissected flat-mount retina) onto a curvilinear surface (the\n    standard retinal shape). It can estimate the position of a point\n    on the intact adult retina to within 8 degrees of arc (3.6% of\n    nasotemporal axis). The coordinates in reconstructed retinae can\n    be transformed to visuotopic coordinates. For more details see\n    Sterratt, D. C., Lyngholm, D., Willshaw, D. J. and Thompson, I. D.\n    (2013) <doi:10.1371/journal.pcbi.1002921>.  "
  },
  {
    "id": 19493,
    "package_name": "rhosa",
    "title": "Higher-Order Spectral Analysis",
    "description": "Higher-order spectra or polyspectra of time series, such as bispectrum and bicoherence, have been investigated in abundant literature and applied to problems of signal detection in a wide range of fields. This package aims to provide a simple API to estimate and analyze them. The current implementation is based on Brillinger and Irizarry (1998) <doi:10.1016/S0165-1684(97)00217-X> for estimating bispectrum or bicoherence, Lii and Helland (1981) <doi:10.1145/355958.355961> for cross-bispectrum, and Kim and Powers (1979) <doi:10.1109/TPS.1979.4317207> for cross-bicoherence.",
    "version": "0.3.0",
    "maintainer": "Takeshi Abe <tabe@fixedpoint.jp>",
    "author": "Takeshi Abe [aut, cre] (ORCID: <https://orcid.org/0000-0002-7074-4561>)",
    "url": "https://tabe.github.io/rhosa/",
    "bug_reports": "https://github.com/tabe/rhosa/issues",
    "repository": "https://cran.r-project.org/package=rhosa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rhosa Higher-Order Spectral Analysis Higher-order spectra or polyspectra of time series, such as bispectrum and bicoherence, have been investigated in abundant literature and applied to problems of signal detection in a wide range of fields. This package aims to provide a simple API to estimate and analyze them. The current implementation is based on Brillinger and Irizarry (1998) <doi:10.1016/S0165-1684(97)00217-X> for estimating bispectrum or bicoherence, Lii and Helland (1981) <doi:10.1145/355958.355961> for cross-bispectrum, and Kim and Powers (1979) <doi:10.1109/TPS.1979.4317207> for cross-bicoherence.  "
  },
  {
    "id": 19505,
    "package_name": "rid",
    "title": "Multiple Change-Point Detection in Multivariate Time Series",
    "description": "Provides efficient functions for detecting multiple change points in multidimensional time series. The models can be piecewise constant or polynomial. Adaptive threshold selection methods are available, see Fan and Wu (2024)\t<arXiv:2403.00600>.",
    "version": "0.0.1",
    "maintainer": "Xinyuan Fan <fxy22@mails.tsinghua.edu.cn>",
    "author": "Xinyuan Fan [aut, cre, cph],\n  Weichi Wu [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rid Multiple Change-Point Detection in Multivariate Time Series Provides efficient functions for detecting multiple change points in multidimensional time series. The models can be piecewise constant or polynomial. Adaptive threshold selection methods are available, see Fan and Wu (2024)\t<arXiv:2403.00600>.  "
  },
  {
    "id": 19544,
    "package_name": "riverconn",
    "title": "Fragmentation and Connectivity Indices for Riverscapes",
    "description": "Indices for assessing riverscape fragmentation, including the Dendritic Connectivity Index, the Population Connectivity Index, the River Fragmentation Index, the Probability of Connectivity, and the Integral Index of connectivity. For a review, see Jumani et al. (2020) <doi:10.1088/1748-9326/abcb37> and Baldan et al. (2022) <doi:10.1016/j.envsoft.2022.105470> Functions to calculate temporal indices improvement when fragmentation due to barriers is reduced are also included.",
    "version": "0.3.31",
    "maintainer": "Damiano Baldan <damiano.baldan91@gmail.com>",
    "author": "Damiano Baldan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9237-4883>),\n  David Cunillera-Montcusi [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8666-346X>),\n  Andrea Funk [ctb] (ORCID: <https://orcid.org/0000-0002-0568-1234>)",
    "url": "https://github.com/damianobaldan/riverconn",
    "bug_reports": "https://github.com/damianobaldan/riverconn/issues",
    "repository": "https://cran.r-project.org/package=riverconn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "riverconn Fragmentation and Connectivity Indices for Riverscapes Indices for assessing riverscape fragmentation, including the Dendritic Connectivity Index, the Population Connectivity Index, the River Fragmentation Index, the Probability of Connectivity, and the Integral Index of connectivity. For a review, see Jumani et al. (2020) <doi:10.1088/1748-9326/abcb37> and Baldan et al. (2022) <doi:10.1016/j.envsoft.2022.105470> Functions to calculate temporal indices improvement when fragmentation due to barriers is reduced are also included.  "
  },
  {
    "id": 19588,
    "package_name": "rmacrostrat",
    "title": "Fetch Geologic Data from the 'Macrostrat' Platform",
    "description": "Work with the 'Macrostrat' (<https://macrostrat.org/>) Web Service \n    (v.2, <https://macrostrat.org/api/v2>) to fetch geological data relevant to\n    the spatial and temporal distribution of sedimentary, igneous, and\n    metamorphic rocks as well as data extracted from them. ",
    "version": "1.0.0",
    "maintainer": "Lewis A. Jones <LewisA.Jones@outlook.com>",
    "author": "Lewis A. Jones [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3902-8986>),\n  William Gearty [aut] (ORCID: <https://orcid.org/0000-0003-0076-3262>),\n  Christopher D. Dean [aut] (ORCID:\n    <https://orcid.org/0000-0001-6471-6903>),\n  Bethany Allen [aut] (ORCID: <https://orcid.org/0000-0003-0282-6407>)",
    "url": "https://rmacrostrat.palaeoverse.org, https://palaeoverse.org,\nhttps://macrostrat.org,\nhttps://github.com/UW-Macrostrat/macrostrat/issues",
    "bug_reports": "https://github.com/palaeoverse/rmacrostrat/issues",
    "repository": "https://cran.r-project.org/package=rmacrostrat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rmacrostrat Fetch Geologic Data from the 'Macrostrat' Platform Work with the 'Macrostrat' (<https://macrostrat.org/>) Web Service \n    (v.2, <https://macrostrat.org/api/v2>) to fetch geological data relevant to\n    the spatial and temporal distribution of sedimentary, igneous, and\n    metamorphic rocks as well as data extracted from them.   "
  },
  {
    "id": 19612,
    "package_name": "rminer",
    "title": "Machine Learning Classification and Regression Methods",
    "description": "Facilitates the use of machine learning algorithms in classification and regression (including time series forecasting) tasks by presenting a short and coherent set of functions. Versions: 1.5.0 improved mparheuristic function (new hyperparameter heuristics); 1.4.9 / 1.4.8 improved help, several warning and error code fixes (more stable version, all examples run correctly); 1.4.7 - improved Importance function and examples, minor error fixes; 1.4.6 / 1.4.5 / 1.4.4 new automated machine learning (AutoML) and ensembles, via improved fit(), mining() and mparheuristic() functions, and new categorical preprocessing, via improved delevels() function; 1.4.3 new metrics (e.g., macro precision, explained variance), new \"lssvm\" model and improved mparheuristic() function; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16 classification and 18 regression models); 1.4.1 new tutorial and more robust version; 1.4 - new classification and regression models, with a total of 14 classification and 15 regression methods, including: Decision Trees, Neural Networks, Support Vector Machines, Random Forests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and regression metrics; 1.2 - new input importance methods via improved Importance() function; 1.0 - first version.",
    "version": "1.5.0",
    "maintainer": "Paulo Cortez <pcortez@dsi.uminho.pt>",
    "author": "Paulo Cortez [aut, cre]",
    "url": "https://cran.r-project.org/package=rminer",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rminer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rminer Machine Learning Classification and Regression Methods Facilitates the use of machine learning algorithms in classification and regression (including time series forecasting) tasks by presenting a short and coherent set of functions. Versions: 1.5.0 improved mparheuristic function (new hyperparameter heuristics); 1.4.9 / 1.4.8 improved help, several warning and error code fixes (more stable version, all examples run correctly); 1.4.7 - improved Importance function and examples, minor error fixes; 1.4.6 / 1.4.5 / 1.4.4 new automated machine learning (AutoML) and ensembles, via improved fit(), mining() and mparheuristic() functions, and new categorical preprocessing, via improved delevels() function; 1.4.3 new metrics (e.g., macro precision, explained variance), new \"lssvm\" model and improved mparheuristic() function; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16 classification and 18 regression models); 1.4.1 new tutorial and more robust version; 1.4 - new classification and regression models, with a total of 14 classification and 15 regression methods, including: Decision Trees, Neural Networks, Support Vector Machines, Random Forests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and regression metrics; 1.2 - new input importance methods via improved Importance() function; 1.0 - first version.  "
  },
  {
    "id": 19647,
    "package_name": "rnrfa",
    "title": "UK National River Flow Archive Data from R",
    "description": "Utility functions to retrieve data from the UK National River\n    Flow Archive (<https://nrfa.ceh.ac.uk/>, terms and conditions:\n    <https://nrfa.ceh.ac.uk/help/costs-terms-and-conditions>). The package\n    contains R wrappers to the UK NRFA data temporary-API. There are\n    functions to retrieve stations falling in a bounding box, to generate\n    a map and extracting time series and general information. The package\n    is fully described in Vitolo et al (2016) \"rnrfa: An R package to\n    Retrieve, Filter and Visualize Data from the UK National River Flow\n    Archive\"\n    <https://journal.r-project.org/archive/2016/RJ-2016-036/RJ-2016-036.pdf>.",
    "version": "2.1.0.7",
    "maintainer": "Ilaria Prosdocimi <prosdocimi.ilaria@gmail.com>",
    "author": "Ilaria Prosdocimi [ctb, cre] (ORCID:\n    <https://orcid.org/0000-0001-8565-094X>),\n  Claudia Vitolo [aut] (ORCID: <https://orcid.org/0000-0002-4252-1176>,\n    Claudia is the original creator of the package),\n  Matthew Fry [ctb] (Matthew supervised the unofficial API integration.),\n  Wouter Buytaert [ctb] (This package is part of Claudia Vitolo's PhD\n    work and Wouter is the supervisor.),\n  Michael Spencer [ctb] (Michael updated the function osg_parse to work\n    with grid references of different lengths.),\n  Tobias Gauster [ctb] (Tobias improved the function osg_parse\n    introducing vectorisation)",
    "url": "https://ilapros.github.io/rnrfa/",
    "bug_reports": "https://github.com/ilapros/rnrfa/issues",
    "repository": "https://cran.r-project.org/package=rnrfa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rnrfa UK National River Flow Archive Data from R Utility functions to retrieve data from the UK National River\n    Flow Archive (<https://nrfa.ceh.ac.uk/>, terms and conditions:\n    <https://nrfa.ceh.ac.uk/help/costs-terms-and-conditions>). The package\n    contains R wrappers to the UK NRFA data temporary-API. There are\n    functions to retrieve stations falling in a bounding box, to generate\n    a map and extracting time series and general information. The package\n    is fully described in Vitolo et al (2016) \"rnrfa: An R package to\n    Retrieve, Filter and Visualize Data from the UK National River Flow\n    Archive\"\n    <https://journal.r-project.org/archive/2016/RJ-2016-036/RJ-2016-036.pdf>.  "
  },
  {
    "id": 19648,
    "package_name": "roads",
    "title": "Road Network Projection",
    "description": "Iterative least cost path and minimum spanning tree methods for projecting \n    forest road networks. The methods connect a set of target points to an existing \n    road network using 'igraph' <https://igraph.org> to identify least cost routes.\n    The cost of constructing a road segment between adjacent pixels is determined\n    by a user supplied weight raster and a weight function; options include the\n    average of adjacent weight raster values, and a function of the elevation \n    differences between adjacent cells that penalizes steep grades. These road\n    network projection methods are intended for integration into R workflows and \n    modelling frameworks used for forecasting forest change, and can be applied \n    over multiple time-steps without rebuilding a graph at each time-step.",
    "version": "1.2.0",
    "maintainer": "Sarah Endicott <sarah.endicott@ec.gc.ca>",
    "author": "Sarah Endicott [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9644-5343>),\n  Kyle Lochhead [aut],\n  Josie Hughes [aut],\n  Patrick Kirby [aut],\n  Her Majesty the Queen in Right of Canada as represented by the Minister\n    of the Environment [cph] (Copyright holder for included functions\n    buildSimList, getLandingsFromTarget, pathsToLines, plotRoads,\n    projectRoads, rasterizeLine, rasterToLineSegments),\n  Province of British Columbia [cph] (Copyright holder for included\n    functions getGraph, lcpList, mstList, shortestPaths,\n    getClosestRoad, buildSnapRoads)",
    "url": "https://github.com/LandSciTech/roads,\nhttps://landscitech.github.io/roads/",
    "bug_reports": "https://github.com/LandSciTech/roads/issues",
    "repository": "https://cran.r-project.org/package=roads",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roads Road Network Projection Iterative least cost path and minimum spanning tree methods for projecting \n    forest road networks. The methods connect a set of target points to an existing \n    road network using 'igraph' <https://igraph.org> to identify least cost routes.\n    The cost of constructing a road segment between adjacent pixels is determined\n    by a user supplied weight raster and a weight function; options include the\n    average of adjacent weight raster values, and a function of the elevation \n    differences between adjacent cells that penalizes steep grades. These road\n    network projection methods are intended for integration into R workflows and \n    modelling frameworks used for forecasting forest change, and can be applied \n    over multiple time-steps without rebuilding a graph at each time-step.  "
  },
  {
    "id": 19657,
    "package_name": "robcp",
    "title": "Robust Change-Point Tests",
    "description": "Provides robust methods to detect change-points in uni- or multivariate time series. They can cope with corrupted data and heavy tails. Focus is on the detection of abrupt changes in location, but changes in the scale or dependence structure can be detected as well. This package provides tests for change detection in uni- and multivariate time series based on Huberized versions of CUSUM tests proposed in Duerre and Fried (2019) <DOI:10.48550/arXiv.1905.06201>, and tests for change detection in univariate time series based on 2-sample U-statistics or 2-sample U-quantiles as proposed by Dehling et al. (2015) <DOI:10.1007/978-1-4939-3076-0_12> and Dehling, Fried and Wendler (2020) <DOI:10.1093/biomet/asaa004>. Furthermore, the packages provides tests on changes in the scale or the correlation as proposed in Gerstenberger, Vogel and Wendler (2020) <DOI:10.1080/01621459.2019.1629938>, Dehling et al. (2017) <DOI:10.1017/S026646661600044X>, and Wied et al. (2014) <DOI:10.1016/j.csda.2013.03.005>.",
    "version": "0.3.9",
    "maintainer": "Sheila Goerz <sheila.goerz@tu-dortmund.de>",
    "author": "Sheila Goerz [aut, cre],\n  Alexander Duerre [aut],\n  Roland Fried [ctb, ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=robcp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "robcp Robust Change-Point Tests Provides robust methods to detect change-points in uni- or multivariate time series. They can cope with corrupted data and heavy tails. Focus is on the detection of abrupt changes in location, but changes in the scale or dependence structure can be detected as well. This package provides tests for change detection in uni- and multivariate time series based on Huberized versions of CUSUM tests proposed in Duerre and Fried (2019) <DOI:10.48550/arXiv.1905.06201>, and tests for change detection in univariate time series based on 2-sample U-statistics or 2-sample U-quantiles as proposed by Dehling et al. (2015) <DOI:10.1007/978-1-4939-3076-0_12> and Dehling, Fried and Wendler (2020) <DOI:10.1093/biomet/asaa004>. Furthermore, the packages provides tests on changes in the scale or the correlation as proposed in Gerstenberger, Vogel and Wendler (2020) <DOI:10.1080/01621459.2019.1629938>, Dehling et al. (2017) <DOI:10.1017/S026646661600044X>, and Wied et al. (2014) <DOI:10.1016/j.csda.2013.03.005>.  "
  },
  {
    "id": 19659,
    "package_name": "robfilter",
    "title": "Robust Time Series Filters",
    "description": "Implementations for several robust procedures that allow for (online)\n        extraction of the signal of univariate or multivariate time series by\n        applying robust regression techniques to a moving time window are provided.\n        Included are univariate filtering procedures based on repeated-median \n        regression as well as hybrid and trimmed filters derived from it; \n        see Schettlinger et al. (2006) <doi:10.1515/BMT.2006.010>. The adaptive \n        online repeated median by Schettlinger et al. (2010) <doi:10.1002/acs.1105> \n        and the slope comparing adaptive repeated median by Borowski and Fried (2013) \n        <doi:10.1007/s11222-013-9391-7> choose the width of the moving time \n        window adaptively. Multivariate versions are also provided; see  \n        Borowski et al. (2009) <doi:10.1080/03610910802514972> for a multivariate \n        online adaptive repeated median and Borowski (2012) <doi:10.17877/DE290R-14393>  \n        for a multivariate slope comparing adaptive repeated median. Furthermore, \n        a repeated-median based filter with automatic outlier replacement and \n        shift detection is provided; see Fried (2004) <doi:10.1080/10485250410001656444>.",
    "version": "4.1.6",
    "maintainer": "Roland Fried <fried@statistik.tu-dortmund.de>",
    "author": "Roland Fried [aut, cre],\n  Karen Schettlinger [aut],\n  Matthias Borowski [aut],\n  Robin Nunkesser [ctb],\n  Thorsten Bernholt [ctb]",
    "url": "https://msnat.statistik.tu-dortmund.de/en/team/chair/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=robfilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "robfilter Robust Time Series Filters Implementations for several robust procedures that allow for (online)\n        extraction of the signal of univariate or multivariate time series by\n        applying robust regression techniques to a moving time window are provided.\n        Included are univariate filtering procedures based on repeated-median \n        regression as well as hybrid and trimmed filters derived from it; \n        see Schettlinger et al. (2006) <doi:10.1515/BMT.2006.010>. The adaptive \n        online repeated median by Schettlinger et al. (2010) <doi:10.1002/acs.1105> \n        and the slope comparing adaptive repeated median by Borowski and Fried (2013) \n        <doi:10.1007/s11222-013-9391-7> choose the width of the moving time \n        window adaptively. Multivariate versions are also provided; see  \n        Borowski et al. (2009) <doi:10.1080/03610910802514972> for a multivariate \n        online adaptive repeated median and Borowski (2012) <doi:10.17877/DE290R-14393>  \n        for a multivariate slope comparing adaptive repeated median. Furthermore, \n        a repeated-median based filter with automatic outlier replacement and \n        shift detection is provided; see Fried (2004) <doi:10.1080/10485250410001656444>.  "
  },
  {
    "id": 19689,
    "package_name": "robustarima",
    "title": "Robust ARIMA Modeling",
    "description": "Functions for fitting a linear regression model with ARIMA\n  errors using a filtered tau-estimate.\n  The methodology is described in Maronna et al (2017, ISBN:9781119214687).",
    "version": "0.2.7",
    "maintainer": "Stephen Kaluzny <spkaluzny@gmail.com>",
    "author": "Stephen Kaluzny [aut, cre],\n  Bill Dunlap [ctb],\n  TIBCO Software Inc. [aut, cph]",
    "url": "https://github.com/spkaluzny/robustarima",
    "bug_reports": "https://github.com/spkaluzny/robustarima/issues",
    "repository": "https://cran.r-project.org/package=robustarima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "robustarima Robust ARIMA Modeling Functions for fitting a linear regression model with ARIMA\n  errors using a filtered tau-estimate.\n  The methodology is described in Maronna et al (2017, ISBN:9781119214687).  "
  },
  {
    "id": 19722,
    "package_name": "roll",
    "title": "Rolling and Expanding Statistics",
    "description": "Fast and efficient computation of rolling and expanding statistics for time-series data.",
    "version": "1.2.0",
    "maintainer": "Jason Foster <jason.j.foster@gmail.com>",
    "author": "Jason Foster [aut, cre]",
    "url": "https://github.com/jasonjfoster/roll",
    "bug_reports": "https://github.com/jasonjfoster/roll/issues",
    "repository": "https://cran.r-project.org/package=roll",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roll Rolling and Expanding Statistics Fast and efficient computation of rolling and expanding statistics for time-series data.  "
  },
  {
    "id": 19726,
    "package_name": "rollinglda",
    "title": "Construct Consistent Time Series from Textual Data",
    "description": "A rolling version of the Latent Dirichlet Allocation, see Rieger et al. (2021) <doi:10.18653/v1/2021.findings-emnlp.201>. By a sequential approach, it enables the construction of LDA-based time series of topics that are consistent with previous states of LDA models. After an initial modeling, updates can be computed efficiently, allowing for real-time monitoring and detection of events or structural breaks.",
    "version": "0.1.4",
    "maintainer": "Jonas Rieger <jonas.rieger@tu-dortmund.de>",
    "author": "Jonas Rieger [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0007-4478>)",
    "url": "https://github.com/JonasRieger/rollinglda",
    "bug_reports": "https://github.com/JonasRieger/rollinglda/issues",
    "repository": "https://cran.r-project.org/package=rollinglda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rollinglda Construct Consistent Time Series from Textual Data A rolling version of the Latent Dirichlet Allocation, see Rieger et al. (2021) <doi:10.18653/v1/2021.findings-emnlp.201>. By a sequential approach, it enables the construction of LDA-based time series of topics that are consistent with previous states of LDA models. After an initial modeling, updates can be computed efficiently, allowing for real-time monitoring and detection of events or structural breaks.  "
  },
  {
    "id": 19747,
    "package_name": "rosario",
    "title": "A Null Model Algorithm to Analyze Cyclical Data in Ecology",
    "description": "Implements a null model analysis to quantify concurrent temporal niche overlap (i.e., activity or phenology) among biological identities (e.g., individuals, populations, species) using the Rosario randomization algorithm Castro-Arellano et al. (2010) <doi:10.1111/j.2041-210X.2010.00031.x>.",
    "version": "0.1.0",
    "maintainer": "Iv\u00e1n Castro-Arellano <ic13@txstate.edu>",
    "author": "\u00c1ngel L. Robles-Fern\u00e1ndez [aut],\n  Maria A. Hurtado-Materon [aut],\n  Tatiana Vel\u00e1squez-Roa [aut, ths],\n  Iv\u00e1n Castro-Arellano [cre]",
    "url": "https://alrobles.github.io/rosario/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rosario",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rosario A Null Model Algorithm to Analyze Cyclical Data in Ecology Implements a null model analysis to quantify concurrent temporal niche overlap (i.e., activity or phenology) among biological identities (e.g., individuals, populations, species) using the Rosario randomization algorithm Castro-Arellano et al. (2010) <doi:10.1111/j.2041-210X.2010.00031.x>.  "
  },
  {
    "id": 19784,
    "package_name": "rplanes",
    "title": "Plausibility Analysis of Epidemiological Signals",
    "description": "Provides functionality to prepare data and analyze plausibility of both forecasted and reported epidemiological signals. The functions implement a set of plausibility algorithms that are agnostic to geographic and time resolutions and are calculated independently then presented as a combined score.",
    "version": "0.1.0",
    "maintainer": "VP Nagraj <nagraj@nagraj.net>",
    "author": "VP Nagraj [aut, cre] (ORCID: <https://orcid.org/0000-0003-0060-566X>),\n  Desiree Williams [aut],\n  Amy Benefield [aut]",
    "url": "https://signaturescience.github.io/rplanes/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rplanes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rplanes Plausibility Analysis of Epidemiological Signals Provides functionality to prepare data and analyze plausibility of both forecasted and reported epidemiological signals. The functions implement a set of plausibility algorithms that are agnostic to geographic and time resolutions and are calculated independently then presented as a combined score.  "
  },
  {
    "id": 19792,
    "package_name": "rpnf",
    "title": "Point and Figure Package",
    "description": "A set of functions to analyze and print the development of a\n    commodity using the Point and Figure (P&F) approach. A P&F processor can be used\n    to calculate daily statistics for the time series. These statistics can be used\n    for deeper investigations as well as to create plots. Plots can be generated as\n    well known X/O Plots in plain text format, and additionally in a more graphical\n    format.",
    "version": "1.0.5",
    "maintainer": "Sascha Herrmann <sascha.herrmann.consulting@gmail.com>",
    "author": "Sascha Herrmann",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rpnf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rpnf Point and Figure Package A set of functions to analyze and print the development of a\n    commodity using the Point and Figure (P&F) approach. A P&F processor can be used\n    to calculate daily statistics for the time series. These statistics can be used\n    for deeper investigations as well as to create plots. Plots can be generated as\n    well known X/O Plots in plain text format, and additionally in a more graphical\n    format.  "
  },
  {
    "id": 19871,
    "package_name": "rstac",
    "title": "Client Library for SpatioTemporal Asset Catalog",
    "description": "Provides functions to access, search and download spacetime earth\n    observation data via SpatioTemporal Asset Catalog (STAC). This package \n    supports the version 1.0.0 (and older) of the STAC specification\n    (<https://github.com/radiantearth/stac-spec>). \n    For further details see Simoes et al. (2021) <doi:10.1109/IGARSS47720.2021.9553518>.",
    "version": "1.0.1",
    "maintainer": "Felipe Carvalho <lipecaso@gmail.com>",
    "author": "Rolf Simoes [aut],\n  Felipe Carvalho [aut, cre],\n  Brazil Data Cube Team [aut],\n  National Institute for Space Research (INPE) [cph]",
    "url": "https://brazil-data-cube.github.io/rstac/",
    "bug_reports": "https://github.com/brazil-data-cube/rstac/issues",
    "repository": "https://cran.r-project.org/package=rstac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rstac Client Library for SpatioTemporal Asset Catalog Provides functions to access, search and download spacetime earth\n    observation data via SpatioTemporal Asset Catalog (STAC). This package \n    supports the version 1.0.0 (and older) of the STAC specification\n    (<https://github.com/radiantearth/stac-spec>). \n    For further details see Simoes et al. (2021) <doi:10.1109/IGARSS47720.2021.9553518>.  "
  },
  {
    "id": 19927,
    "package_name": "rts",
    "title": "Raster Time Series Analysis",
    "description": "This framework aims to provide classes and methods for manipulating and processing of raster time series data (e.g. a time series of satellite images).",
    "version": "1.1-14",
    "maintainer": "Babak Naimi <naimi.b@gmail.com>",
    "author": "Babak Naimi",
    "url": "https://r-gis.net/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rts Raster Time Series Analysis This framework aims to provide classes and methods for manipulating and processing of raster time series data (e.g. a time series of satellite images).  "
  },
  {
    "id": 19929,
    "package_name": "rtsdata",
    "title": "R Time Series Intelligent Data Storage",
    "description": "A tool that allows to download and save historical time series data \n\tfor future use offline. The intelligent updating functionality will only download \n\tthe new available information; thus, saving you time and Internet bandwidth. \n\tIt will only re-download the full data-set if any inconsistencies are detected. \n\tThis package supports following data provides: 'Yahoo' (finance.yahoo.com), \n\t'FRED' (fred.stlouisfed.org), 'Quandl' (data.nasdaq.com), \n\t'AlphaVantage' (www.alphavantage.co), 'Tiingo' (www.tiingo.com).",
    "version": "0.1.4",
    "maintainer": "Irina Kapler <irkapler@gmail.com>",
    "author": "RTSVizTeam [aut, cph],\n  Irina Kapler [cre]",
    "url": "https://bitbucket.org/rtsvizteam/rtsdata",
    "bug_reports": "https://bitbucket.org/rtsvizteam/rtsdata/issues",
    "repository": "https://cran.r-project.org/package=rtsdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rtsdata R Time Series Intelligent Data Storage A tool that allows to download and save historical time series data \n\tfor future use offline. The intelligent updating functionality will only download \n\tthe new available information; thus, saving you time and Internet bandwidth. \n\tIt will only re-download the full data-set if any inconsistencies are detected. \n\tThis package supports following data provides: 'Yahoo' (finance.yahoo.com), \n\t'FRED' (fred.stlouisfed.org), 'Quandl' (data.nasdaq.com), \n\t'AlphaVantage' (www.alphavantage.co), 'Tiingo' (www.tiingo.com).  "
  },
  {
    "id": 19935,
    "package_name": "rugarch",
    "title": "Univariate GARCH Models",
    "description": "ARFIMA, in-mean, external regressors and various GARCH flavors, with methods for fit, forecast, simulation, inference and plotting.",
    "version": "1.5-4",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>),\n  Tobias Kley [ctb]",
    "url": "https://github.com/alexiosg/rugarch",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rugarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rugarch Univariate GARCH Models ARFIMA, in-mean, external regressors and various GARCH flavors, with methods for fit, forecast, simulation, inference and plotting.  "
  },
  {
    "id": 19938,
    "package_name": "rumidas",
    "title": "Univariate GARCH-MIDAS, Double-Asymmetric GARCH-MIDAS and\nMEM-MIDAS",
    "description": "Adds the MIxing-Data Sampling (MIDAS, Ghysels et al. (2007) <doi:10.1080/07474930600972467>) components to a variety of GARCH and MEM (Engle (2002) <doi:10.1002/jae.683>, Engle and Gallo (2006) <doi:10.1016/j.jeconom.2005.01.018>, and Amendola et al. (2024) <doi:10.1016/j.seps.2023.101764>) models, with the aim of predicting the volatility with additional low-frequency (that is, MIDAS) terms. The estimation takes place through simple functions, which provide in-sample and (if present) and out-of-sample evaluations. 'rumidas' also offers a summary tool, which synthesizes the main information of the estimated model. There is also the possibility of generating one-step-ahead and multi-step-ahead forecasts. ",
    "version": "0.1.3",
    "maintainer": "Vincenzo Candila <vcandila@unisa.it>",
    "author": "Vincenzo Candila [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rumidas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rumidas Univariate GARCH-MIDAS, Double-Asymmetric GARCH-MIDAS and\nMEM-MIDAS Adds the MIxing-Data Sampling (MIDAS, Ghysels et al. (2007) <doi:10.1080/07474930600972467>) components to a variety of GARCH and MEM (Engle (2002) <doi:10.1002/jae.683>, Engle and Gallo (2006) <doi:10.1016/j.jeconom.2005.01.018>, and Amendola et al. (2024) <doi:10.1016/j.seps.2023.101764>) models, with the aim of predicting the volatility with additional low-frequency (that is, MIDAS) terms. The estimation takes place through simple functions, which provide in-sample and (if present) and out-of-sample evaluations. 'rumidas' also offers a summary tool, which synthesizes the main information of the estimated model. There is also the possibility of generating one-step-ahead and multi-step-ahead forecasts.   "
  },
  {
    "id": 19946,
    "package_name": "runner",
    "title": "Running Operations for Vectors",
    "description": "Lightweight library for rolling windows operations. Package enables\n  full control over the window length, window lag and a time indices. With a runner \n  one can apply any R function on a rolling windows. The package eases work with \n  equally and unequally spaced time series.",
    "version": "0.4.5",
    "maintainer": "Dawid Ka\u0142\u0119dkowski <dawid.kaledkowski@gmail.com>",
    "author": "Dawid Ka\u0142\u0119dkowski [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9533-457X>)",
    "url": "",
    "bug_reports": "https://github.com/gogonzo/runner/issues",
    "repository": "https://cran.r-project.org/package=runner",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "runner Running Operations for Vectors Lightweight library for rolling windows operations. Package enables\n  full control over the window length, window lag and a time indices. With a runner \n  one can apply any R function on a rolling windows. The package eases work with \n  equally and unequally spaced time series.  "
  },
  {
    "id": 19948,
    "package_name": "runstats",
    "title": "Fast Computation of Running Statistics for Time Series",
    "description": "Provides methods for fast computation of running sample \n    statistics for time series. These include: (1) mean, (2) \n    standard deviation, and (3) variance over a fixed-length window \n    of time-series, (4) correlation, (5) covariance, and (6) \n    Euclidean distance (L2 norm) between short-time pattern and \n    time-series. Implemented methods utilize Convolution Theorem to \n    compute convolutions via Fast Fourier Transform (FFT).",
    "version": "1.1.0",
    "maintainer": "Marta Karas <marta.karass@gmail.com>",
    "author": "Marta Karas [aut, cre] (ORCID: <https://orcid.org/0000-0001-5889-3970>),\n  Jacek Urbanek [aut] (ORCID: <https://orcid.org/0000-0002-1890-8899>),\n  John Muschelli [ctb] (ORCID: <https://orcid.org/0000-0001-6469-1750>),\n  Lacey Etzkorn [ctb]",
    "url": "https://github.com/martakarass/runstats",
    "bug_reports": "https://github.com/martakarass/runstats/issues",
    "repository": "https://cran.r-project.org/package=runstats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "runstats Fast Computation of Running Statistics for Time Series Provides methods for fast computation of running sample \n    statistics for time series. These include: (1) mean, (2) \n    standard deviation, and (3) variance over a fixed-length window \n    of time-series, (4) correlation, (5) covariance, and (6) \n    Euclidean distance (L2 norm) between short-time pattern and \n    time-series. Implemented methods utilize Convolution Theorem to \n    compute convolutions via Fast Fourier Transform (FFT).  "
  },
  {
    "id": 19984,
    "package_name": "rwunderground",
    "title": "R Interface to Weather Underground API",
    "description": "Tools for getting historical weather information and forecasts \n    from wunderground.com. Historical weather and forecast data includes, but \n    is not limited to, temperature, humidity, windchill, wind speed, dew point, \n    heat index. Additionally, the weather underground weather API also includes \n    information on sunrise/sunset, tidal conditions, satellite/webcam imagery, \n    weather alerts, hurricane alerts and historical high/low temperatures.",
    "version": "0.1.8",
    "maintainer": "Eric Hare <eric@omnianalytics.io>",
    "author": "Alex Shum <alex@ALShum.com>",
    "url": "https://github.com/ALShum/rwunderground,\nhttp://www.wunderground.com/weather/api",
    "bug_reports": "https://github.com/alshum/rwunderground/issues",
    "repository": "https://cran.r-project.org/package=rwunderground",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rwunderground R Interface to Weather Underground API Tools for getting historical weather information and forecasts \n    from wunderground.com. Historical weather and forecast data includes, but \n    is not limited to, temperature, humidity, windchill, wind speed, dew point, \n    heat index. Additionally, the weather underground weather API also includes \n    information on sunrise/sunset, tidal conditions, satellite/webcam imagery, \n    weather alerts, hurricane alerts and historical high/low temperatures.  "
  },
  {
    "id": 19993,
    "package_name": "s2dv",
    "title": "Seasonal to Decadal Verification",
    "description": "An advanced version of package 's2dverification'. Intended for \n    seasonal to decadal (s2d) climate forecast verification, but also applicable\n    to other types of forecasts or general climate analysis. This package is \n    specifically designed for comparing experimental and observational datasets. \n    It provides functionality for data retrieval, post-processing, skill score \n    computation against observations, and visualization. Compared to \n    's2dverification', 's2dv' is more compatible with the package 'startR', able \n    to use multiple cores for computation and handle multi-dimensional arrays \n    with a higher flexibility. The Climate Data Operators (CDO) version used in \n    development is 1.9.8. Implements methods described in Wilks (2011) \n    <doi:10.1016/B978-0-12-385022-5.00008-7>, DelSole and Tippett \n    (2016) <doi:10.1175/MWR-D-15-0218.1>, Kharin et al. (2012) \n    <doi:10.1029/2012GL052647>, Doblas-Reyes et al. (2003) \n    <doi:10.1007/s00382-003-0350-4>.",
    "version": "2.2.1",
    "maintainer": "Ariadna Batalla <ariadna.batalla@bsc.es>",
    "author": "BSC-CNS [aut, cph],\n  An-Chi Ho [aut],\n  Nuria Perez-Zanon [aut],\n  Roberto Bilbao [ctb],\n  Josep Cos [ctb],\n  Carlos Delgado [ctb],\n  Lloren\u00e7 Lled\u00f3 [ctb],\n  Andrea Manrique [ctb],\n  Deborah Verfaillie [ctb],\n  Eva Rif\u00e0 [ctb],\n  Vict\u00f2ria Agudetse [ctb],\n  Nadia Milders [ctb],\n  Ariadna Batalla [ctb, cre]",
    "url": "https://gitlab.earth.bsc.es/es/s2dv/",
    "bug_reports": "https://gitlab.earth.bsc.es/es/s2dv/-/issues",
    "repository": "https://cran.r-project.org/package=s2dv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "s2dv Seasonal to Decadal Verification An advanced version of package 's2dverification'. Intended for \n    seasonal to decadal (s2d) climate forecast verification, but also applicable\n    to other types of forecasts or general climate analysis. This package is \n    specifically designed for comparing experimental and observational datasets. \n    It provides functionality for data retrieval, post-processing, skill score \n    computation against observations, and visualization. Compared to \n    's2dverification', 's2dv' is more compatible with the package 'startR', able \n    to use multiple cores for computation and handle multi-dimensional arrays \n    with a higher flexibility. The Climate Data Operators (CDO) version used in \n    development is 1.9.8. Implements methods described in Wilks (2011) \n    <doi:10.1016/B978-0-12-385022-5.00008-7>, DelSole and Tippett \n    (2016) <doi:10.1175/MWR-D-15-0218.1>, Kharin et al. (2012) \n    <doi:10.1029/2012GL052647>, Doblas-Reyes et al. (2003) \n    <doi:10.1007/s00382-003-0350-4>.  "
  },
  {
    "id": 20012,
    "package_name": "sTSD",
    "title": "Simulate Time Series Diagnostics",
    "description": "These are tools that allow users to do time series diagnostics, primarily\n    tests of unit root, by way of simulation. While there is nothing necessarily\n    wrong with the received wisdom of critical values generated decades ago, \n    simulation provides its own perks. Not only is simulation broadly informative\n    as to what these various test statistics do and what are their plausible \n    values, simulation provides more flexibility for assessing unit root by way\n    of different thresholds or different hypothesized distributions.",
    "version": "0.2.0",
    "maintainer": "Steven Miller <steve@svmiller.com>",
    "author": "Steven Miller [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4072-6263>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sTSD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sTSD Simulate Time Series Diagnostics These are tools that allow users to do time series diagnostics, primarily\n    tests of unit root, by way of simulation. While there is nothing necessarily\n    wrong with the received wisdom of critical values generated decades ago, \n    simulation provides its own perks. Not only is simulation broadly informative\n    as to what these various test statistics do and what are their plausible \n    values, simulation provides more flexibility for assessing unit root by way\n    of different thresholds or different hypothesized distributions.  "
  },
  {
    "id": 20019,
    "package_name": "sad",
    "title": "Verify the Scale, Anisotropy and Direction of Weather Forecasts",
    "description": "Implementation of the wavelet-based spatial verification method of Buschow and Friederichs \"SAD: Verifying the Scale, Anisotropy and Direction of precipitation forecasts\" (2020, submitted to QJRMS). Forecasts and Observations are transformed by a decimated or redundant dual-tree complex wavelet transform to analyze the spatial scale, degree of anisotropy and preferred direction in each field. These structural attributes are compared by a series of scores. An experimental algorithm for the correction of these errors is included as well.",
    "version": "0.1.3",
    "maintainer": "Sebastian Buschow <s6sebusc@uni-bonn.de>",
    "author": "Sebastian Buschow [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4750-361X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sad",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sad Verify the Scale, Anisotropy and Direction of Weather Forecasts Implementation of the wavelet-based spatial verification method of Buschow and Friederichs \"SAD: Verifying the Scale, Anisotropy and Direction of precipitation forecasts\" (2020, submitted to QJRMS). Forecasts and Observations are transformed by a decimated or redundant dual-tree complex wavelet transform to analyze the spatial scale, degree of anisotropy and preferred direction in each field. These structural attributes are compared by a series of scores. An experimental algorithm for the correction of these errors is included as well.  "
  },
  {
    "id": 20024,
    "package_name": "sae2",
    "title": "Small Area Estimation: Time-Series Models",
    "description": "Time series area-level models for small area estimation. \n      The package supplements the functionality of the sae package. Specifically, it includes\n      EBLUP fitting of the Rao-Yu model in the original form without a spatial component. \n      The package also offers a modified (\"dynamic\") version of the Rao-Yu model, replacing\n      the assumption of stationarity. Both univariate and multivariate applications are\n      supported. Of particular note is the allowance for covariance of the area-level sample \n      estimates over time, as encountered in rotating panel designs such as the U.S. National \n      Crime Victimization Survey or present in a time-series of 5-year estimates from the \n      American Community Survey. Key references to the methods include\n      J.N.K. Rao and I. Molina (2015, ISBN:9781118735787),\n      J.N.K. Rao and M. Yu (1994) <doi:10.2307/3315407>, and\n      R.E. Fay and R.A. Herriot (1979) <doi:10.1080/01621459.1979.10482505>.",
    "version": "1.2-2",
    "maintainer": "Robert Fay <bobfay@hotmail.com>",
    "author": "Robert Fay [aut, cre],\n  Mamadou Diallo [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sae2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sae2 Small Area Estimation: Time-Series Models Time series area-level models for small area estimation. \n      The package supplements the functionality of the sae package. Specifically, it includes\n      EBLUP fitting of the Rao-Yu model in the original form without a spatial component. \n      The package also offers a modified (\"dynamic\") version of the Rao-Yu model, replacing\n      the assumption of stationarity. Both univariate and multivariate applications are\n      supported. Of particular note is the allowance for covariance of the area-level sample \n      estimates over time, as encountered in rotating panel designs such as the U.S. National \n      Crime Victimization Survey or present in a time-series of 5-year estimates from the \n      American Community Survey. Key references to the methods include\n      J.N.K. Rao and I. Molina (2015, ISBN:9781118735787),\n      J.N.K. Rao and M. Yu (1994) <doi:10.2307/3315407>, and\n      R.E. Fay and R.A. Herriot (1979) <doi:10.1080/01621459.1979.10482505>.  "
  },
  {
    "id": 20040,
    "package_name": "saeRobust",
    "title": "Robust Small Area Estimation",
    "description": "Methods to fit robust alternatives to commonly used models used in\n    Small Area Estimation. The methods here used are based on best linear\n    unbiased predictions and linear mixed models. At this time available models\n    include area level models incorporating spatial and temporal correlation in\n    the random effects.",
    "version": "0.5.0",
    "maintainer": "Sebastian Warnholz <wahani@gmail.com>",
    "author": "Sebastian Warnholz [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/wahani/saeRobust/issues",
    "repository": "https://cran.r-project.org/package=saeRobust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "saeRobust Robust Small Area Estimation Methods to fit robust alternatives to commonly used models used in\n    Small Area Estimation. The methods here used are based on best linear\n    unbiased predictions and linear mixed models. At this time available models\n    include area level models incorporating spatial and temporal correlation in\n    the random effects.  "
  },
  {
    "id": 20058,
    "package_name": "sageR",
    "title": "Applied Statistics for Economics and Management with R",
    "description": "Datasets and functions for the book \"Statistiques pour l\u2019\u00e9conomie et la gestion\", \"Th\u00e9orie et applications en entreprise\", F. Bertrand, Ch. Derquenne, G. Dufr\u00e9not, F. Jawadi and M. Maumy, C. Borsenberger editor, (2021, ISBN:9782807319448, De Boeck Sup\u00e9rieur, Louvain-la-Neuve). \n    The first chapter of the book is dedicated to an introduction to statistics and their world. \n    The second chapter deals with univariate exploratory statistics and graphics. \n    The third chapter deals with bivariate and multivariate exploratory statistics and graphics. \n    The fourth chapter is dedicated to data exploration with Principal Component Analysis. \n    The fifth chapter is dedicated to data exploration with Correspondance Analysis.\n    The sixth chapter is dedicated to data exploration with Multiple Correspondance Analysis. \n    The seventh chapter is dedicated to data exploration with automatic clustering. \n    The eighth chapter is dedicated to an introduction to probability theory and classical probability distributions.\n    The ninth chapter is dedicated to an estimation theory, one-sample and two-sample tests.\n    The tenth chapter is dedicated to an Gaussian linear model.\n    The eleventh chapter is dedicated to an introduction to time series.\n    The twelfth chapter is dedicated to an introduction to probit and logit models.\n    Various example datasets are shipped with the package as well as some new functions.",
    "version": "0.7.0",
    "maintainer": "Frederic Bertrand <frederic.bertrand@lecnam.net>",
    "author": "Frederic Bertrand [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0837-8281>),\n  Claire Borsenberger [ctb],\n  Christian Derquenne [ctb],\n  Gilles Dufr\u00e9not [ctb],\n  Fredj Jawadi [ctb],\n  Myriam Maumy-Bertrand [aut] (ORCID:\n    <https://orcid.org/0000-0002-4615-1512>)",
    "url": "https://fbertran.github.io/homepage/,\nhttps://fbertran.github.io/sageR/,\nhttps://github.com/fbertran/sageR/",
    "bug_reports": "https://github.com/fbertran/sageR/issues/",
    "repository": "https://cran.r-project.org/package=sageR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sageR Applied Statistics for Economics and Management with R Datasets and functions for the book \"Statistiques pour l\u2019\u00e9conomie et la gestion\", \"Th\u00e9orie et applications en entreprise\", F. Bertrand, Ch. Derquenne, G. Dufr\u00e9not, F. Jawadi and M. Maumy, C. Borsenberger editor, (2021, ISBN:9782807319448, De Boeck Sup\u00e9rieur, Louvain-la-Neuve). \n    The first chapter of the book is dedicated to an introduction to statistics and their world. \n    The second chapter deals with univariate exploratory statistics and graphics. \n    The third chapter deals with bivariate and multivariate exploratory statistics and graphics. \n    The fourth chapter is dedicated to data exploration with Principal Component Analysis. \n    The fifth chapter is dedicated to data exploration with Correspondance Analysis.\n    The sixth chapter is dedicated to data exploration with Multiple Correspondance Analysis. \n    The seventh chapter is dedicated to data exploration with automatic clustering. \n    The eighth chapter is dedicated to an introduction to probability theory and classical probability distributions.\n    The ninth chapter is dedicated to an estimation theory, one-sample and two-sample tests.\n    The tenth chapter is dedicated to an Gaussian linear model.\n    The eleventh chapter is dedicated to an introduction to time series.\n    The twelfth chapter is dedicated to an introduction to probit and logit models.\n    Various example datasets are shipped with the package as well as some new functions.  "
  },
  {
    "id": 20066,
    "package_name": "samadb",
    "title": "South Africa Macroeconomic Database API",
    "description": "An R API providing access to a relational database with macroeconomic time series data for South Africa,\n obtained from the South African Reserve Bank (SARB) and Statistics South Africa (STATSSA), and updated on a weekly basis\n via the EconData <https://www.econdata.co.za/> platform and automated scraping of the SARB and STATSSA websites.\n The database is maintained at the Department of Economics at Stellenbosch University.",
    "version": "0.3.1",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/Stellenbosch-Econometrics/SAMADB-Issues/issues",
    "repository": "https://cran.r-project.org/package=samadb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samadb South Africa Macroeconomic Database API An R API providing access to a relational database with macroeconomic time series data for South Africa,\n obtained from the South African Reserve Bank (SARB) and Statistics South Africa (STATSSA), and updated on a weekly basis\n via the EconData <https://www.econdata.co.za/> platform and automated scraping of the SARB and STATSSA websites.\n The database is maintained at the Department of Economics at Stellenbosch University.  "
  },
  {
    "id": 20094,
    "package_name": "samurais",
    "title": "Statistical Models for the Unsupervised Segmentation of\nTime-Series ('SaMUraiS')",
    "description": "Provides a variety of original and flexible user-friendly \n    statistical latent variable models and unsupervised learning algorithms to \n    segment and represent time-series data (univariate or multivariate), and \n    more generally, longitudinal data, which include regime changes. \n    'samurais' is built upon the following packages, each of them is an \n    autonomous time-series segmentation approach: Regression with Hidden \n    Logistic Process ('RHLP'), Hidden Markov Model Regression ('HMMR'), \n    Multivariate 'RHLP' ('MRHLP'), Multivariate 'HMMR' ('MHMMR'), Piece-Wise \n    regression ('PWR'). For the advantages/differences of each of them, the \n    user is referred to our mentioned paper references.",
    "version": "0.1.0",
    "maintainer": "Florian Lecocq <florian.lecocq@outlook.com>",
    "author": "Faicel Chamroukhi [aut] (ORCID:\n    <https://orcid.org/0000-0002-5894-3103>),\n  Marius Bartcus [aut],\n  Florian Lecocq [aut, cre]",
    "url": "https://github.com/fchamroukhi/SaMUraiS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=samurais",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samurais Statistical Models for the Unsupervised Segmentation of\nTime-Series ('SaMUraiS') Provides a variety of original and flexible user-friendly \n    statistical latent variable models and unsupervised learning algorithms to \n    segment and represent time-series data (univariate or multivariate), and \n    more generally, longitudinal data, which include regime changes. \n    'samurais' is built upon the following packages, each of them is an \n    autonomous time-series segmentation approach: Regression with Hidden \n    Logistic Process ('RHLP'), Hidden Markov Model Regression ('HMMR'), \n    Multivariate 'RHLP' ('MRHLP'), Multivariate 'HMMR' ('MHMMR'), Piece-Wise \n    regression ('PWR'). For the advantages/differences of each of them, the \n    user is referred to our mentioned paper references.  "
  },
  {
    "id": 20106,
    "package_name": "santaR",
    "title": "Short Asynchronous Time-Series Analysis",
    "description": "A graphical and automated pipeline for the analysis \n\t\tof short time-series in R ('santaR'). This approach is designed to accommodate asynchronous \n\t\ttime sampling (i.e. different time points for different individuals), \n\t\tinter-individual variability, noisy measurements and large numbers of variables. \n\t\tBased on a smoothing splines functional model, 'santaR' is able to detect variables\n\t\thighlighting significantly different temporal trajectories between study groups.\n\t\tDesigned initially for metabolic phenotyping, 'santaR' is also suited for other Systems Biology \n\t\tdisciplines. Command line and graphical analysis (via a 'shiny' application) enable fast and\n\t\tparallel automated analysis and reporting, intuitive visualisation and comprehensive plotting\n\t\toptions for non-specialist users.",
    "version": "1.2.4",
    "maintainer": "Arnaud Wolfer <adwolfer@gmail.com>",
    "author": "Arnaud Wolfer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5856-3218>),\n  Timothy Ebbels [ctb],\n  Joe Cheng [ctb] (Shiny javascript custom-input control)",
    "url": "https://github.com/adwolfer/santaR,\nhttps://adwolfer.github.io/santaR/",
    "bug_reports": "https://github.com/adwolfer/santaR/issues/new",
    "repository": "https://cran.r-project.org/package=santaR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "santaR Short Asynchronous Time-Series Analysis A graphical and automated pipeline for the analysis \n\t\tof short time-series in R ('santaR'). This approach is designed to accommodate asynchronous \n\t\ttime sampling (i.e. different time points for different individuals), \n\t\tinter-individual variability, noisy measurements and large numbers of variables. \n\t\tBased on a smoothing splines functional model, 'santaR' is able to detect variables\n\t\thighlighting significantly different temporal trajectories between study groups.\n\t\tDesigned initially for metabolic phenotyping, 'santaR' is also suited for other Systems Biology \n\t\tdisciplines. Command line and graphical analysis (via a 'shiny' application) enable fast and\n\t\tparallel automated analysis and reporting, intuitive visualisation and comprehensive plotting\n\t\toptions for non-specialist users.  "
  },
  {
    "id": 20116,
    "package_name": "sarp.snowprofile",
    "title": "Snow Profile Analysis for Snowpack and Avalanche Research",
    "description": "Analysis and plotting tools for snow profile data produced from manual snowpack \n  observations and physical snowpack models. The functions in this package support snowpack \n  and avalanche research by reading various formats of data (including CAAML, SMET,\n  generic csv, and outputs from the snow cover model SNOWPACK), manipulate the data, and \n  produce graphics such as stratigraphy and time series profiles. Package developed by \n  the Simon Fraser University Avalanche Research Program <http://www.avalancheresearch.ca>. \n  Graphics apply visualization concepts from Horton, Nowak, and Haegeli (2020, \n  <doi:10.5194/nhess-20-1557-2020>).",
    "version": "1.3.2",
    "maintainer": "Pascal Haegeli <pascal_haegeli@sfu.ca>",
    "author": "Pascal Haegeli [aut, cre],\n  Simon Horton [aut],\n  Florian Herla [aut],\n  SFU Avalanche Research Program [fnd]",
    "url": "http://www.avalancheresearch.ca",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sarp.snowprofile",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sarp.snowprofile Snow Profile Analysis for Snowpack and Avalanche Research Analysis and plotting tools for snow profile data produced from manual snowpack \n  observations and physical snowpack models. The functions in this package support snowpack \n  and avalanche research by reading various formats of data (including CAAML, SMET,\n  generic csv, and outputs from the snow cover model SNOWPACK), manipulate the data, and \n  produce graphics such as stratigraphy and time series profiles. Package developed by \n  the Simon Fraser University Avalanche Research Program <http://www.avalancheresearch.ca>. \n  Graphics apply visualization concepts from Horton, Nowak, and Haegeli (2020, \n  <doi:10.5194/nhess-20-1557-2020>).  "
  },
  {
    "id": 20117,
    "package_name": "sarp.snowprofile.alignment",
    "title": "Snow Profile Alignment, Aggregation, and Clustering",
    "description": "Snow profiles describe the vertical (1D) stratigraphy of layered \n    snow with different layer characteristics, such as grain type, hardness, \n    deposition date, and many more. Hence, they represent a data format similar \n    to multivariate time series containing categorical, ordinal, and numerical \n    data types. Use this package to align snow profiles by matching their \n    individual layers based on Dynamic Time Warping (DTW). The aligned profiles \n    can then be assessed with an independent, global similarity measure that is \n    geared towards avalanche hazard assessment. Finally, through exploiting data\n    aggregation and clustering methods, the similarity measure provides the\n    foundation for grouping and summarizing snow profiles according to similar\n    hazard conditions. In particular, this package allows for averaging large\n    numbers of snow profiles with DTW Barycenter Averaging and thereby \n    facilitates the computation of individual layer distributions and summary \n    statistics that are relevant for avalanche forecasting purposes. \n    For more background information refer to Herla, Horton, Mair,\n    and Haegeli (2021) <doi:10.5194/gmd-14-239-2021>, Herla, Mair, and Haegeli \n    (2022) <doi:10.5194/tc-16-3149-2022>, and Horton, Herla, and Haegeli (2024)\n    <doi:10.5194/egusphere-2024-1609>.",
    "version": "2.0.2",
    "maintainer": "Florian Herla <fherla@sfu.ca>",
    "author": "Florian Herla [aut, cre],\n  Pascal Haegeli [aut],\n  Simon Horton [aut],\n  Paul Billecocq [aut],\n  SFU Avalanche Research Program [fnd]",
    "url": "https://avalancheresearch.ca/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sarp.snowprofile.alignment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sarp.snowprofile.alignment Snow Profile Alignment, Aggregation, and Clustering Snow profiles describe the vertical (1D) stratigraphy of layered \n    snow with different layer characteristics, such as grain type, hardness, \n    deposition date, and many more. Hence, they represent a data format similar \n    to multivariate time series containing categorical, ordinal, and numerical \n    data types. Use this package to align snow profiles by matching their \n    individual layers based on Dynamic Time Warping (DTW). The aligned profiles \n    can then be assessed with an independent, global similarity measure that is \n    geared towards avalanche hazard assessment. Finally, through exploiting data\n    aggregation and clustering methods, the similarity measure provides the\n    foundation for grouping and summarizing snow profiles according to similar\n    hazard conditions. In particular, this package allows for averaging large\n    numbers of snow profiles with DTW Barycenter Averaging and thereby \n    facilitates the computation of individual layer distributions and summary \n    statistics that are relevant for avalanche forecasting purposes. \n    For more background information refer to Herla, Horton, Mair,\n    and Haegeli (2021) <doi:10.5194/gmd-14-239-2021>, Herla, Mair, and Haegeli \n    (2022) <doi:10.5194/tc-16-3149-2022>, and Horton, Herla, and Haegeli (2024)\n    <doi:10.5194/egusphere-2024-1609>.  "
  },
  {
    "id": 20133,
    "package_name": "sazedR",
    "title": "Parameter-Free Domain-Agnostic Season Length Detection in Time\nSeries",
    "description": "Spectral and Average Autocorrelation Zero Distance Density\n    ('sazed') is a method for estimating the season length of a \n    seasonal time series. 'sazed' is aimed at practitioners, as it employs only \n    domain-agnostic preprocessing and does not depend on parameter tuning or \n    empirical constants. The computation of 'sazed' relies on the efficient \n    autocorrelation computation methods suggested by Thibauld Nion (2012, URL: \n    <https://etudes.tibonihoo.net/literate_musing/autocorrelations.html>) and by \n    Bob Carpenter (2012, URL: \n    <https://lingpipe-blog.com/2012/06/08/autocorrelation-fft-kiss-eigen/>).",
    "version": "2.0.2",
    "maintainer": "Tiago Santos <teixeiradossantos@tugraz.at>",
    "author": "Maximilian Toller [aut],\n  Tiago Santos [aut, cre],\n  Roman Kern [aut]",
    "url": "https://github.com/mtoller/autocorr_season_length_detection/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sazedR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sazedR Parameter-Free Domain-Agnostic Season Length Detection in Time\nSeries Spectral and Average Autocorrelation Zero Distance Density\n    ('sazed') is a method for estimating the season length of a \n    seasonal time series. 'sazed' is aimed at practitioners, as it employs only \n    domain-agnostic preprocessing and does not depend on parameter tuning or \n    empirical constants. The computation of 'sazed' relies on the efficient \n    autocorrelation computation methods suggested by Thibauld Nion (2012, URL: \n    <https://etudes.tibonihoo.net/literate_musing/autocorrelations.html>) and by \n    Bob Carpenter (2012, URL: \n    <https://lingpipe-blog.com/2012/06/08/autocorrelation-fft-kiss-eigen/>).  "
  },
  {
    "id": 20237,
    "package_name": "scorepeak",
    "title": "Peak Functions for Peak Detection in Univariate Time Series",
    "description": "Provides peak functions, which enable us to detect peaks in time series. The methods implemented in this package are based on Girish Keshav Palshikar (2009) <https://www.researchgate.net/publication/228853276_Simple_Algorithms_for_Peak_Detection_in_Time-Series>.",
    "version": "0.1.2",
    "maintainer": "Shota Ochi <shotaochi1990@gmail.com>",
    "author": "Shota Ochi [aut, cre, cph]",
    "url": "https://github.com/ShotaOchi/scorepeak",
    "bug_reports": "https://github.com/ShotaOchi/scorepeak/issues",
    "repository": "https://cran.r-project.org/package=scorepeak",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scorepeak Peak Functions for Peak Detection in Univariate Time Series Provides peak functions, which enable us to detect peaks in time series. The methods implemented in this package are based on Girish Keshav Palshikar (2009) <https://www.researchgate.net/publication/228853276_Simple_Algorithms_for_Peak_Detection_in_Time-Series>.  "
  },
  {
    "id": 20238,
    "package_name": "scoring",
    "title": "Proper Scoring Rules",
    "description": "Evaluating probabilistic forecasts via proper scoring rules.  scoring implements the beta, power, and pseudospherical families of proper scoring rules, along with ordered versions of the latter two families.  Included among these families are popular rules like the Brier (quadratic) score, logarithmic score, and spherical score.  For two-alternative forecasts, also includes functionality for plotting scores that one would obtain under specific scoring rules.",
    "version": "0.6",
    "maintainer": "Ed Merkle <merklee@missouri.edu>",
    "author": "Ed Merkle",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scoring",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scoring Proper Scoring Rules Evaluating probabilistic forecasts via proper scoring rules.  scoring implements the beta, power, and pseudospherical families of proper scoring rules, along with ordered versions of the latter two families.  Included among these families are popular rules like the Brier (quadratic) score, logarithmic score, and spherical score.  For two-alternative forecasts, also includes functionality for plotting scores that one would obtain under specific scoring rules.  "
  },
  {
    "id": 20239,
    "package_name": "scoringRules",
    "title": "Scoring Rules for Parametric and Simulated Distribution\nForecasts",
    "description": "Dictionary-like reference for computing scoring rules in a wide\n    range of situations. Covers both parametric forecast distributions (such as\n    mixtures of Gaussians) and distributions generated via simulation. Further \n    details can be found in the package vignettes <doi:10.18637/jss.v090.i12>, \n    <doi:10.18637/jss.v110.i08>.",
    "version": "1.1.3",
    "maintainer": "Fabian Krueger <Fabian.Krueger83@gmail.com>",
    "author": "Alexander I. Jordan [aut] (ORCID:\n    <https://orcid.org/0000-0001-7423-1352>),\n  Fabian Krueger [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5112-9037>),\n  Sebastian Lerch [aut] (ORCID: <https://orcid.org/0000-0002-3467-4375>),\n  Sam Allen [aut] (ORCID: <https://orcid.org/0000-0003-1971-8277>),\n  Maximiliane Graeter [ctb]",
    "url": "https://github.com/FK83/scoringRules",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scoringRules",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scoringRules Scoring Rules for Parametric and Simulated Distribution\nForecasts Dictionary-like reference for computing scoring rules in a wide\n    range of situations. Covers both parametric forecast distributions (such as\n    mixtures of Gaussians) and distributions generated via simulation. Further \n    details can be found in the package vignettes <doi:10.18637/jss.v090.i12>, \n    <doi:10.18637/jss.v110.i08>.  "
  },
  {
    "id": 20240,
    "package_name": "scoringfunctions",
    "title": "A Collection of Loss Functions for Assessing Point Forecasts",
    "description": "\n    Implements multiple consistent scoring functions\n    (Gneiting T (2011) <doi:10.1198/jasa.2011.r10138>) for assessing point\n    forecasts and point predictions. Detailed documentation of scoring\n    functions' properties is included for facilitating interpretation of\n    results.",
    "version": "1.1",
    "maintainer": "Hristos Tyralis <montchrister@gmail.com>",
    "author": "Hristos Tyralis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8932-4997>),\n  Georgia Papacharalampous [aut] (ORCID:\n    <https://orcid.org/0000-0001-5446-954X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scoringfunctions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scoringfunctions A Collection of Loss Functions for Assessing Point Forecasts \n    Implements multiple consistent scoring functions\n    (Gneiting T (2011) <doi:10.1198/jasa.2011.r10138>) for assessing point\n    forecasts and point predictions. Detailed documentation of scoring\n    functions' properties is included for facilitating interpretation of\n    results.  "
  },
  {
    "id": 20289,
    "package_name": "sdmTMB",
    "title": "Spatial and Spatiotemporal SPDE-Based GLMMs with 'TMB'",
    "description": "Implements spatial and spatiotemporal GLMMs (Generalized Linear\n    Mixed Effect Models) using 'TMB', 'fmesher', and the SPDE (Stochastic Partial\n    Differential Equation) Gaussian Markov random field approximation to\n    Gaussian random fields. One common application is for spatially explicit\n    species distribution models (SDMs).\n    See Anderson et al. (2024) <doi:10.1101/2022.03.24.485545>.",
    "version": "0.8.0",
    "maintainer": "Sean C. Anderson <sean@seananderson.ca>",
    "author": "Sean C. Anderson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9563-1937>),\n  Eric J. Ward [aut] (ORCID: <https://orcid.org/0000-0002-4359-0296>),\n  Philina A. English [aut] (ORCID:\n    <https://orcid.org/0000-0003-2992-6782>),\n  Lewis A. K. Barnett [aut] (ORCID:\n    <https://orcid.org/0000-0002-9381-8375>),\n  James T. Thorson [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-7415-1010>, VAST author),\n  Joe Watson [ctb] (Censored Poisson),\n  Julia Indivero [ctb] (ORCID: <https://orcid.org/0000-0001-5310-9542>,\n    Vignette writing),\n  Jillian C. Dunic [ctb] (ORCID: <https://orcid.org/0000-0002-0729-3083>),\n  Joseph Barss [ctb],\n  Cole C. Monnahan [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0003-0871-6700>, VAST contributor),\n  Mollie Brooks [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0001-6963-8326>, glmmTMB author),\n  Ben Bolker [ctb, cph] (ORCID: <https://orcid.org/0000-0002-2127-0443>,\n    glmmTMB author),\n  Kasper Kristensen [ctb, cph] (TMB/glmmTMB author),\n  Martin Maechler [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0002-8685-9910>, glmmTMB author),\n  Arni Magnusson [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0003-2769-6741>, glmmTMB author),\n  Hans J. Skaug [ctb, cph] (glmmTMB author, SPDE barrier),\n  Anders Nielsen [ctb, cph] (ORCID:\n    <https://orcid.org/0000-0001-9683-9262>, glmmTMB author),\n  Casper Berg [ctb, cph] (ORCID: <https://orcid.org/0000-0002-3812-5269>,\n    glmmTMB author),\n  Koen van Bentham [ctb, cph] (glmmTMB author),\n  Olav Nikolai Breivik [ctb, cph] (SPDE barrier),\n  Simon Wood [ctb, cph] (mgcv: smoother prediction),\n  Paul-Christian B\u00fcrkner [ctb, cph] (brms: smoother matrix parsing),\n  His Majesty the King in Right of Canada, as represented by the Minister\n    of the Department of Fisheries and Oceans [cph]",
    "url": "https://sdmTMB.github.io/sdmTMB/, https://github.com/sdmTMB/sdmTMB",
    "bug_reports": "https://github.com/sdmTMB/sdmTMB/issues",
    "repository": "https://cran.r-project.org/package=sdmTMB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sdmTMB Spatial and Spatiotemporal SPDE-Based GLMMs with 'TMB' Implements spatial and spatiotemporal GLMMs (Generalized Linear\n    Mixed Effect Models) using 'TMB', 'fmesher', and the SPDE (Stochastic Partial\n    Differential Equation) Gaussian Markov random field approximation to\n    Gaussian random fields. One common application is for spatially explicit\n    species distribution models (SDMs).\n    See Anderson et al. (2024) <doi:10.1101/2022.03.24.485545>.  "
  },
  {
    "id": 20294,
    "package_name": "sdrt",
    "title": "Estimating the Sufficient Dimension Reduction Subspaces in Time\nSeries",
    "description": "The sdrt() function is designed for estimating subspaces for Sufficient Dimension Reduction (SDR) in time series, with a specific focus on the Time Series Central Mean subspace (TS-CMS). The package employs the Fourier transformation method proposed by Samadi and De Alwis (2023) <doi:10.48550/arXiv.2312.02110> and the Nadaraya-Watson kernel smoother method proposed by Park et al. (2009) <doi:10.1198/jcgs.2009.08076> for estimating the TS-CMS. The package provides tools for estimating distances between subspaces and includes functions for selecting model parameters using the Fourier transformation method. ",
    "version": "1.0.0",
    "maintainer": "Tharindu P. De Alwis <talwis@wpi.edu>",
    "author": "Tharindu P. De Alwis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3446-0502>),\n  S. Yaser Samadi [ctb, aut] (ORCID:\n    <https://orcid.org/0000-0002-6121-0234>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sdrt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sdrt Estimating the Sufficient Dimension Reduction Subspaces in Time\nSeries The sdrt() function is designed for estimating subspaces for Sufficient Dimension Reduction (SDR) in time series, with a specific focus on the Time Series Central Mean subspace (TS-CMS). The package employs the Fourier transformation method proposed by Samadi and De Alwis (2023) <doi:10.48550/arXiv.2312.02110> and the Nadaraya-Watson kernel smoother method proposed by Park et al. (2009) <doi:10.1198/jcgs.2009.08076> for estimating the TS-CMS. The package provides tools for estimating distances between subspaces and includes functions for selecting model parameters using the Fourier transformation method.   "
  },
  {
    "id": 20304,
    "package_name": "searchAnalyzeR",
    "title": "Advanced Analytics and Testing Framework for Systematic Review\nSearch Strategies",
    "description": "Provides comprehensive analytics, reporting, and testing capabilities \n    for systematic review search strategies. The package focuses on validating search \n    performance, generating standardized 'PRISMA'-compliant reports, and ensuring \n    reproducibility in evidence synthesis. Features include precision-recall analysis, \n    cross-database performance comparison, benchmark validation against gold standards, \n    sensitivity analysis, temporal coverage assessment, automated report generation,\n    and statistical comparison of search strategies. Supports multiple export formats \n    including 'CSV', 'Excel', 'RIS', 'BibTeX', and 'EndNote'. Includes tools for duplicate \n    detection, search strategy optimization, cross-validation frameworks, meta-analysis \n    of benchmark results, power analysis for study design, and reproducibility package \n    creation. Optionally connects to 'PubMed' for direct database searching and real-time \n    strategy comparison using the 'E-utilities' 'API'. Enhanced with bootstrap comparison \n    methods, 'McNemar' test for strategy evaluation, and comprehensive visualization tools \n    for performance assessment. Methods based on Manning et al. (2008) \n    for information retrieval metrics, Moher et al. (2009)\n    for 'PRISMA' guidelines, and Sampson et al. (2006) for \n    systematic review search methodology.",
    "version": "0.1.0",
    "maintainer": "Chao Liu <chaoliu@cedarville.edu>",
    "author": "Chao Liu [aut, cre] (ORCID: <https://orcid.org/0000-0002-9979-8272>)",
    "url": "https://github.com/chaoliu-cl/searchAnalyzeR",
    "bug_reports": "https://github.com/chaoliu-cl/searchAnalyzeR/issues",
    "repository": "https://cran.r-project.org/package=searchAnalyzeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "searchAnalyzeR Advanced Analytics and Testing Framework for Systematic Review\nSearch Strategies Provides comprehensive analytics, reporting, and testing capabilities \n    for systematic review search strategies. The package focuses on validating search \n    performance, generating standardized 'PRISMA'-compliant reports, and ensuring \n    reproducibility in evidence synthesis. Features include precision-recall analysis, \n    cross-database performance comparison, benchmark validation against gold standards, \n    sensitivity analysis, temporal coverage assessment, automated report generation,\n    and statistical comparison of search strategies. Supports multiple export formats \n    including 'CSV', 'Excel', 'RIS', 'BibTeX', and 'EndNote'. Includes tools for duplicate \n    detection, search strategy optimization, cross-validation frameworks, meta-analysis \n    of benchmark results, power analysis for study design, and reproducibility package \n    creation. Optionally connects to 'PubMed' for direct database searching and real-time \n    strategy comparison using the 'E-utilities' 'API'. Enhanced with bootstrap comparison \n    methods, 'McNemar' test for strategy evaluation, and comprehensive visualization tools \n    for performance assessment. Methods based on Manning et al. (2008) \n    for information retrieval metrics, Moher et al. (2009)\n    for 'PRISMA' guidelines, and Sampson et al. (2006) for \n    systematic review search methodology.  "
  },
  {
    "id": 20308,
    "package_name": "seasonal",
    "title": "R Interface to X-13-ARIMA-SEATS",
    "description": "Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment\n    software by the US Census Bureau. It offers full access to almost all\n    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model\n    search, outlier detection and support for user defined holiday variables,\n    such as Chinese New Year or Indian Diwali. A graphical user interface can be\n    used through the 'seasonalview' package. Uses the X-13-binaries from the\n    'x13binary' package.",
    "version": "1.10.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7192-7044>),\n  Dirk Eddelbuettel [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Andrea Ranzato [ctb]",
    "url": "http://www.seasonal.website",
    "bug_reports": "https://github.com/christophsax/seasonal/issues",
    "repository": "https://cran.r-project.org/package=seasonal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonal R Interface to X-13-ARIMA-SEATS Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment\n    software by the US Census Bureau. It offers full access to almost all\n    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model\n    search, outlier detection and support for user defined holiday variables,\n    such as Chinese New Year or Indian Diwali. A graphical user interface can be\n    used through the 'seasonalview' package. Uses the X-13-binaries from the\n    'x13binary' package.  "
  },
  {
    "id": 20309,
    "package_name": "seasonalityPlot",
    "title": "Seasonality Variation Plots of Stock Prices and Cryptocurrencies",
    "description": "The price action at any given time is determined by investor \n  sentiment and market conditions. Although there is no established principle, \n  over a long period of time, things often move with a certain periodicity.\n  This is sometimes referred to as anomaly. \n  The seasonPlot() function in this package calculates and visualizes the \n  average value of price movements over a year for any given period. \n  In addition, the monthly increase or decrease in price movement is \n  represented with a colored background. \n  This seasonPlot() function can use the same symbols as the 'quantmod' package \n  (e.g. ^IXIC, ^DJI, SPY, BTC-USD, and ETH-USD etc). ",
    "version": "1.3.1",
    "maintainer": "Satoshi Kume <satoshi.kume.1984@gmail.com>",
    "author": "Satoshi Kume [aut, cre]",
    "url": "https://github.com/kumeS/seasonalityPlot,\nhttps://kumes.github.io/seasonalityPlot/,\nhttps://skume-seasonalityplot.hf.space/__docs__/#/",
    "bug_reports": "https://github.com/kumeS/seasonalityPlot/issues",
    "repository": "https://cran.r-project.org/package=seasonalityPlot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonalityPlot Seasonality Variation Plots of Stock Prices and Cryptocurrencies The price action at any given time is determined by investor \n  sentiment and market conditions. Although there is no established principle, \n  over a long period of time, things often move with a certain periodicity.\n  This is sometimes referred to as anomaly. \n  The seasonPlot() function in this package calculates and visualizes the \n  average value of price movements over a year for any given period. \n  In addition, the monthly increase or decrease in price movement is \n  represented with a colored background. \n  This seasonPlot() function can use the same symbols as the 'quantmod' package \n  (e.g. ^IXIC, ^DJI, SPY, BTC-USD, and ETH-USD etc).   "
  },
  {
    "id": 20310,
    "package_name": "seasonalview",
    "title": "Graphical User Interface for Seasonal Adjustment",
    "description": "A graphical user interface to the 'seasonal' package and\n  'X-13ARIMA-SEATS', the U.S. Census Bureau's seasonal adjustment software.",
    "version": "1.0.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7192-7044>)",
    "url": "http://www.seasonal.website",
    "bug_reports": "https://github.com/christophsax/seasonalview/issues",
    "repository": "https://cran.r-project.org/package=seasonalview",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonalview Graphical User Interface for Seasonal Adjustment A graphical user interface to the 'seasonal' package and\n  'X-13ARIMA-SEATS', the U.S. Census Bureau's seasonal adjustment software.  "
  },
  {
    "id": 20311,
    "package_name": "seastests",
    "title": "Seasonality Tests",
    "description": "An overall test for seasonality of a given time\n    series in addition to a set of individual seasonality tests as\n    described by Ollech and Webel (forthcoming): An overall seasonality\n    test. Bundesbank Discussion Paper.",
    "version": "0.15.4",
    "maintainer": "Daniel Ollech <daniel.ollech@bundesbank.de>",
    "author": "Daniel Ollech [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=seastests",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seastests Seasonality Tests An overall test for seasonality of a given time\n    series in addition to a set of individual seasonality tests as\n    described by Ollech and Webel (forthcoming): An overall seasonality\n    test. Bundesbank Discussion Paper.  "
  },
  {
    "id": 20329,
    "package_name": "seer",
    "title": "Feature-Based Forecast Model Selection",
    "description": "A novel meta-learning framework for forecast model selection using time series features. Many applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. We propose a classification framework which selects forecast models based on features calculated from the time series. We call this framework FFORMS (Feature-based FORecast Model Selection). FFORMS builds a mapping that relates the features of time series to the best forecast model using a random forest. 'seer' package is the implementation of the FFORMS algorithm. For more details see our paper at <https://www.monash.edu/business/econometrics-and-business-statistics/research/publications/ebs/wp06-2018.pdf>.",
    "version": "1.1.8",
    "maintainer": "Thiyanga Talagala <tstalagala@gmail.com>",
    "author": "Thiyanga Talagala [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0656-9789>),\n  Rob J Hyndman [ths, aut] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  George Athanasopoulos [ths, aut]",
    "url": "https://thiyangt.github.io/seer/",
    "bug_reports": "https://github.com/thiyangt/seer/issues",
    "repository": "https://cran.r-project.org/package=seer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seer Feature-Based Forecast Model Selection A novel meta-learning framework for forecast model selection using time series features. Many applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. We propose a classification framework which selects forecast models based on features calculated from the time series. We call this framework FFORMS (Feature-based FORecast Model Selection). FFORMS builds a mapping that relates the features of time series to the best forecast model using a random forest. 'seer' package is the implementation of the FFORMS algorithm. For more details see our paper at <https://www.monash.edu/business/econometrics-and-business-statistics/research/publications/ebs/wp06-2018.pdf>.  "
  },
  {
    "id": 20331,
    "package_name": "segMGarch",
    "title": "Multiple Change-Point Detection for High-Dimensional GARCH\nProcesses",
    "description": "Implements a segmentation algorithm for multiple change-point detection in high-dimensional GARCH processes. It simultaneously segments GARCH processes by identifying 'common' change-points, each of which can be shared by a subset or all of the component time series as a change-point in their within-series and/or cross-sectional correlation structure. ",
    "version": "1.3",
    "maintainer": "Karolos Korkas <kkorkas@yahoo.co.uk>",
    "author": "Haeran Cho [aut],\n  Karolos Korkas [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=segMGarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "segMGarch Multiple Change-Point Detection for High-Dimensional GARCH\nProcesses Implements a segmentation algorithm for multiple change-point detection in high-dimensional GARCH processes. It simultaneously segments GARCH processes by identifying 'common' change-points, each of which can be shared by a subset or all of the component time series as a change-point in their within-series and/or cross-sectional correlation structure.   "
  },
  {
    "id": 20333,
    "package_name": "segclust2d",
    "title": "Bivariate Segmentation/Clustering Methods and Tools",
    "description": "Provides two methods for segmentation and joint segmentation/clustering of\n    bivariate time-series. Originally intended for ecological segmentation\n    (home-range and behavioural modes) but easily applied on other series,\n    the package also provides tools for analysing outputs from R packages 'moveHMM' and 'marcher'.\n    The segmentation method is a bivariate extension of  Lavielle's method available in 'adehabitatLT' \n    (Lavielle, 1999 <doi:10.1016/S0304-4149(99)00023-X> and 2005 <doi:10.1016/j.sigpro.2005.01.012>).\n    This method rely on dynamic programming for efficient segmentation.\n    The segmentation/clustering method alternates steps of dynamic programming with an Expectation-Maximization algorithm.\n    This is an extension of Picard et al (2007) <doi:10.1111/j.1541-0420.2006.00729.x> method \n    (formerly available in 'cghseg' package) to the bivariate case.\n    The method is fully described in Patin et al (2018) <doi:10.1101/444794>.",
    "version": "0.3.3",
    "maintainer": "Remi Patin <remi.patin@normale.fr>",
    "author": "Remi Patin [aut, cre],\n  Marie-Pierre Etienne [aut],\n  Emilie Lebarbier [aut],\n  Simon Benhamou [aut]",
    "url": "https://github.com/rpatin/segclust2d",
    "bug_reports": "https://github.com/rpatin/segclust2d/issues",
    "repository": "https://cran.r-project.org/package=segclust2d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "segclust2d Bivariate Segmentation/Clustering Methods and Tools Provides two methods for segmentation and joint segmentation/clustering of\n    bivariate time-series. Originally intended for ecological segmentation\n    (home-range and behavioural modes) but easily applied on other series,\n    the package also provides tools for analysing outputs from R packages 'moveHMM' and 'marcher'.\n    The segmentation method is a bivariate extension of  Lavielle's method available in 'adehabitatLT' \n    (Lavielle, 1999 <doi:10.1016/S0304-4149(99)00023-X> and 2005 <doi:10.1016/j.sigpro.2005.01.012>).\n    This method rely on dynamic programming for efficient segmentation.\n    The segmentation/clustering method alternates steps of dynamic programming with an Expectation-Maximization algorithm.\n    This is an extension of Picard et al (2007) <doi:10.1111/j.1541-0420.2006.00729.x> method \n    (formerly available in 'cghseg' package) to the bivariate case.\n    The method is fully described in Patin et al (2018) <doi:10.1101/444794>.  "
  },
  {
    "id": 20336,
    "package_name": "segmenTier",
    "title": "Similarity-Based Segmentation of Multidimensional Signals",
    "description": "A dynamic programming solution to segmentation based on\n        maximization of arbitrary similarity measures within segments.\n\tThe general idea, theory and this implementation are described in\n\tMachne, Murray & Stadler (2017) <doi:10.1038/s41598-017-12401-8>.\n\tIn addition to the core algorithm, the package provides time-series\n\tprocessing and clustering functions as described in the publication.\n\tThese are generally applicable where a `k-means` clustering yields\n\tmeaningful results, and have been specifically developed for\n\tclustering of the Discrete Fourier Transform of periodic gene\n\texpression data (`circadian' or `yeast metabolic oscillations').\n\tThis clustering approach is outlined in the supplemental material of\n\tMachne & Murray (2012) <doi:10.1371/journal.pone.0037906>), and here\n\tis used as a basis of segment similarity measures. Notably, the\n\ttime-series processing and clustering functions can also be used as\n\tstand-alone tools, independent of segmentation, e.g., for \n        transcriptome data already mapped to genes.",
    "version": "0.1.2",
    "maintainer": "Rainer Machne <raim@tbi.univie.ac.at>",
    "author": "Rainer Machne, Douglas B. Murray, Peter F. Stadler",
    "url": "https://github.com/raim/segmenTier",
    "bug_reports": "https://github.com/raim/segmenTier/issues",
    "repository": "https://cran.r-project.org/package=segmenTier",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "segmenTier Similarity-Based Segmentation of Multidimensional Signals A dynamic programming solution to segmentation based on\n        maximization of arbitrary similarity measures within segments.\n\tThe general idea, theory and this implementation are described in\n\tMachne, Murray & Stadler (2017) <doi:10.1038/s41598-017-12401-8>.\n\tIn addition to the core algorithm, the package provides time-series\n\tprocessing and clustering functions as described in the publication.\n\tThese are generally applicable where a `k-means` clustering yields\n\tmeaningful results, and have been specifically developed for\n\tclustering of the Discrete Fourier Transform of periodic gene\n\texpression data (`circadian' or `yeast metabolic oscillations').\n\tThis clustering approach is outlined in the supplemental material of\n\tMachne & Murray (2012) <doi:10.1371/journal.pone.0037906>), and here\n\tis used as a basis of segment similarity measures. Notably, the\n\ttime-series processing and clustering functions can also be used as\n\tstand-alone tools, independent of segmentation, e.g., for \n        transcriptome data already mapped to genes.  "
  },
  {
    "id": 20417,
    "package_name": "sentometrics",
    "title": "An Integrated Framework for Textual Sentiment Time Series\nAggregation and Prediction",
    "description": "Optimized prediction based on textual sentiment, accounting for the intrinsic challenge that sentiment can be computed and pooled across texts and time in various ways. See Ardia et al. (2021) <doi:10.18637/jss.v099.i02>.",
    "version": "1.0.1",
    "maintainer": "Samuel Borms <borms_sam@hotmail.com>",
    "author": "Samuel Borms [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9533-1870>),\n  David Ardia [aut] (ORCID: <https://orcid.org/0000-0003-2823-782X>),\n  Keven Bluteau [aut] (ORCID: <https://orcid.org/0000-0003-2990-4807>),\n  Kris Boudt [aut] (ORCID: <https://orcid.org/0000-0002-1000-5142>),\n  Jeroen Van Pelt [ctb],\n  Andres Algaba [ctb]",
    "url": "https://sentometrics-research.com/sentometrics/",
    "bug_reports": "https://github.com/SentometricsResearch/sentometrics/issues",
    "repository": "https://cran.r-project.org/package=sentometrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sentometrics An Integrated Framework for Textual Sentiment Time Series\nAggregation and Prediction Optimized prediction based on textual sentiment, accounting for the intrinsic challenge that sentiment can be computed and pooled across texts and time in various ways. See Ardia et al. (2021) <doi:10.18637/jss.v099.i02>.  "
  },
  {
    "id": 20418,
    "package_name": "sentopics",
    "title": "Tools for Joint Sentiment and Topic Analysis of Textual Data",
    "description": "A framework that joins topic modeling and sentiment analysis of\n  textual data. The package implements a fast Gibbs sampling estimation of\n  Latent Dirichlet Allocation (Griffiths and Steyvers (2004)\n  <doi:10.1073/pnas.0307752101>) and Joint Sentiment/Topic Model (Lin, He,\n  Everson and Ruger (2012) <doi:10.1109/TKDE.2011.48>). It offers a variety of\n  helpers and visualizations to analyze the result of topic modeling. The\n  framework also allows enriching topic models with dates and externally\n  computed sentiment measures. A flexible aggregation scheme enables the\n  creation of time series of sentiment or topical proportions from the enriched\n  topic models. Moreover, a novel method jointly aggregates topic proportions\n  and sentiment measures to derive time series of topical sentiment.",
    "version": "0.7.6",
    "maintainer": "Olivier Delmarcelle <delmarcelle.olivier@gmail.com>",
    "author": "Olivier Delmarcelle [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4347-070X>),\n  Samuel Borms [ctb] (ORCID: <https://orcid.org/0000-0001-9533-1870>),\n  Chengua Lin [cph] (Original JST implementation),\n  Yulan He [cph] (Original JST implementation),\n  Jose Bernardo [cph] (Original JST implementation),\n  David Robinson [cph] (Implementation of reorder_within()),\n  Julia Silge [cph] (Implementation of reorder_within(), ORCID:\n    <https://orcid.org/0000-0002-3671-836X>)",
    "url": "https://github.com/odelmarcelle/sentopics",
    "bug_reports": "https://github.com/odelmarcelle/sentopics/issues",
    "repository": "https://cran.r-project.org/package=sentopics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sentopics Tools for Joint Sentiment and Topic Analysis of Textual Data A framework that joins topic modeling and sentiment analysis of\n  textual data. The package implements a fast Gibbs sampling estimation of\n  Latent Dirichlet Allocation (Griffiths and Steyvers (2004)\n  <doi:10.1073/pnas.0307752101>) and Joint Sentiment/Topic Model (Lin, He,\n  Everson and Ruger (2012) <doi:10.1109/TKDE.2011.48>). It offers a variety of\n  helpers and visualizations to analyze the result of topic modeling. The\n  framework also allows enriching topic models with dates and externally\n  computed sentiment measures. A flexible aggregation scheme enables the\n  creation of time series of sentiment or topical proportions from the enriched\n  topic models. Moreover, a novel method jointly aggregates topic proportions\n  and sentiment measures to derive time series of topical sentiment.  "
  },
  {
    "id": 20421,
    "package_name": "sephora",
    "title": "Statistical Estimation of Phenological Parameters",
    "description": "Provides functions and methods for estimating phenological dates (green up, \n  start of a season, maturity, senescence, end of a season and dormancy) from (nearly) \n  periodic Earth Observation time series. These dates are critical points of some \n  derivatives of an idealized curve which, in turn, is obtained through a functional principal \n  component analysis-based regression model. Some of the methods implemented here are \n  based on T. Krivobokova, P. Serra and F. Rosales (2022) <https://www.sciencedirect.com/science/article/pii/S0167947322000998>. \n  Methods for handling and plotting Earth observation time series are also provided.",
    "version": "0.1.31",
    "maintainer": "Inder Tecuapetla-G\u00f3mez <itecuapetla@conabio.gob.mx>",
    "author": "Inder Tecuapetla-G\u00f3mez [cre, aut] (ORDIC: 0000-0001-6251-972X),\n  Fanny Galicia-G\u00f3mez [ctb],\n  Francisco Rosales-Marticorena [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sephora",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sephora Statistical Estimation of Phenological Parameters Provides functions and methods for estimating phenological dates (green up, \n  start of a season, maturity, senescence, end of a season and dormancy) from (nearly) \n  periodic Earth Observation time series. These dates are critical points of some \n  derivatives of an idealized curve which, in turn, is obtained through a functional principal \n  component analysis-based regression model. Some of the methods implemented here are \n  based on T. Krivobokova, P. Serra and F. Rosales (2022) <https://www.sciencedirect.com/science/article/pii/S0167947322000998>. \n  Methods for handling and plotting Earth observation time series are also provided.  "
  },
  {
    "id": 20425,
    "package_name": "seqHMM",
    "title": "Mixture Hidden Markov Models for Social Sequence Data and Other\nMultivariate, Multichannel Categorical Time Series",
    "description": "Designed for estimating variants of hidden (latent) Markov models\n    (HMMs), mixture HMMs, and non-homogeneous HMMs (NHMMs) for social sequence\n    data and other categorical time series. Special cases include\n    feedback-augmented NHMMs, Markov models without latent layer, mixture\n    Markov models, and latent class models. The package supports models for one\n    or multiple subjects with one or multiple parallel sequences (channels).\n    External covariates can be added to explain cluster membership in mixture \n    models as well as initial, transition and emission probabilities in NHMMs.\n    The package provides functions for evaluating and comparing models, as well\n    as functions for visualizing of multichannel sequence data and HMMs. For\n    NHMMs, methods for computing average causal effects and marginal state and\n    emission probabilities are available. Models are estimated using maximum\n    likelihood via the EM algorithm or direct numerical maximization with\n    analytical gradients. Documentation is available via several vignettes,\n    and Helske and Helske (2019, <doi:10.18637/jss.v088.i03>). For methodology\n    behind the NHMMs, see Helske (2025, <doi:10.48550/arXiv.2503.16014>).",
    "version": "2.1.0",
    "maintainer": "Jouni Helske <jouni.helske@iki.fi>",
    "author": "Jouni Helske [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7130-793X>),\n  Satu Helske [aut] (ORCID: <https://orcid.org/0000-0003-0532-0153>)",
    "url": "",
    "bug_reports": "https://github.com/helske/seqHMM/issues",
    "repository": "https://cran.r-project.org/package=seqHMM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seqHMM Mixture Hidden Markov Models for Social Sequence Data and Other\nMultivariate, Multichannel Categorical Time Series Designed for estimating variants of hidden (latent) Markov models\n    (HMMs), mixture HMMs, and non-homogeneous HMMs (NHMMs) for social sequence\n    data and other categorical time series. Special cases include\n    feedback-augmented NHMMs, Markov models without latent layer, mixture\n    Markov models, and latent class models. The package supports models for one\n    or multiple subjects with one or multiple parallel sequences (channels).\n    External covariates can be added to explain cluster membership in mixture \n    models as well as initial, transition and emission probabilities in NHMMs.\n    The package provides functions for evaluating and comparing models, as well\n    as functions for visualizing of multichannel sequence data and HMMs. For\n    NHMMs, methods for computing average causal effects and marginal state and\n    emission probabilities are available. Models are estimated using maximum\n    likelihood via the EM algorithm or direct numerical maximization with\n    analytical gradients. Documentation is available via several vignettes,\n    and Helske and Helske (2019, <doi:10.18637/jss.v088.i03>). For methodology\n    behind the NHMMs, see Helske (2025, <doi:10.48550/arXiv.2503.16014>).  "
  },
  {
    "id": 20452,
    "package_name": "setartree",
    "title": "SETAR-Tree - A Novel and Accurate Tree Algorithm for Global Time\nSeries Forecasting",
    "description": "The implementation of a forecasting-specific tree-based model that is in particular suitable for global time series forecasting, as proposed in Godahewa et al. (2022) <arXiv:2211.08661v1>. The model uses the concept of Self Exciting Threshold Autoregressive (SETAR) models to define the node splits and thus, the model is named SETAR-Tree. The SETAR-Tree uses some time-series-specific splitting and stopping procedures. It trains global pooled regression models in the leaves allowing the models to learn cross-series information. The depth of the tree is controlled by conducting a statistical linearity test as well as measuring the error reduction percentage at each node split. Thus, the SETAR-Tree requires minimal external hyperparameter tuning and provides competitive results under its default configuration. A forest is developed by extending the SETAR-Tree. The SETAR-Forest combines the forecasts provided by a collection of diverse SETAR-Trees during the forecasting process. ",
    "version": "0.2.1",
    "maintainer": "Rakshitha Godahewa <rakshithagw@gmail.com>",
    "author": "Rakshitha Godahewa [cre, aut, cph],\n  Christoph Bergmeir [aut],\n  Daniel Schmidt [aut],\n  Geoffrey Webb [ctb]",
    "url": "https://github.com/rakshitha123/setartree",
    "bug_reports": "https://github.com/rakshitha123/setartree/issues",
    "repository": "https://cran.r-project.org/package=setartree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "setartree SETAR-Tree - A Novel and Accurate Tree Algorithm for Global Time\nSeries Forecasting The implementation of a forecasting-specific tree-based model that is in particular suitable for global time series forecasting, as proposed in Godahewa et al. (2022) <arXiv:2211.08661v1>. The model uses the concept of Self Exciting Threshold Autoregressive (SETAR) models to define the node splits and thus, the model is named SETAR-Tree. The SETAR-Tree uses some time-series-specific splitting and stopping procedures. It trains global pooled regression models in the leaves allowing the models to learn cross-series information. The depth of the tree is controlled by conducting a statistical linearity test as well as measuring the error reduction percentage at each node split. Thus, the SETAR-Tree requires minimal external hyperparameter tuning and provides competitive results under its default configuration. A forest is developed by extending the SETAR-Tree. The SETAR-Forest combines the forecasts provided by a collection of diverse SETAR-Trees during the forecasting process.   "
  },
  {
    "id": 20503,
    "package_name": "sgstar",
    "title": "Seasonal Generalized Space Time Autoregressive (S-GSTAR) Model",
    "description": "A set of function that implements for seasonal multivariate time series analysis based on Seasonal Generalized Space\n            Time Autoregressive with Seemingly Unrelated Regression (S-GSTAR-SUR) Model by Setiawan(2016)<https://www.researchgate.net/publication/316517889_S-GSTAR-SUR_model_for_seasonal_spatio_temporal_data_forecasting>.",
    "version": "0.1.2",
    "maintainer": "M. Yoga Satria Utama <221709801@stis.ac.id>",
    "author": "M. Yoga Satria Utama [aut, cre],\n  Ernawati Pasaribu [aut]",
    "url": "https://github.com/yogasatria30/sgstar",
    "bug_reports": "https://github.com/yogasatria30/sgstar/issues",
    "repository": "https://cran.r-project.org/package=sgstar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sgstar Seasonal Generalized Space Time Autoregressive (S-GSTAR) Model A set of function that implements for seasonal multivariate time series analysis based on Seasonal Generalized Space\n            Time Autoregressive with Seemingly Unrelated Regression (S-GSTAR-SUR) Model by Setiawan(2016)<https://www.researchgate.net/publication/316517889_S-GSTAR-SUR_model_for_seasonal_spatio_temporal_data_forecasting>.  "
  },
  {
    "id": 20597,
    "package_name": "shinyTempSignal",
    "title": "Explore Temporal and Other Phylogenetic Signals",
    "description": "Sequences sampled at different time points can be used to infer molecular phylogenies on natural time scales, but if the sequences records inaccurate sampling times, that are not the actual sampling times, then it will affect the molecular phylogenetic analysis. This shiny application helps exploring temporal characteristics of the evolutionary trees through linear regression analysis and with the ability to identify and remove incorrect labels. The method was extended to support exploring other phylogenetic signals under strict and relaxed models.",
    "version": "0.0.8",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-6485-8781>),\n  Xiao Luo [ctb],\n  Li Zhan [ctb],\n  Xuanan Zhu [ctb],\n  Jianfeng Lin [ctb]",
    "url": "https://github.com/YuLab-SMU/shinyTempSignal,\nhttps://www.sciencedirect.com/science/article/pii/S167385272400033X",
    "bug_reports": "https://github.com/YuLab-SMU/shinyTempSignal/issues",
    "repository": "https://cran.r-project.org/package=shinyTempSignal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shinyTempSignal Explore Temporal and Other Phylogenetic Signals Sequences sampled at different time points can be used to infer molecular phylogenies on natural time scales, but if the sequences records inaccurate sampling times, that are not the actual sampling times, then it will affect the molecular phylogenetic analysis. This shiny application helps exploring temporal characteristics of the evolutionary trees through linear regression analysis and with the ability to identify and remove incorrect labels. The method was extended to support exploring other phylogenetic signals under strict and relaxed models.  "
  },
  {
    "id": 20646,
    "package_name": "shoredate",
    "title": "Shoreline Dating Coastal Stone Age Sites",
    "description": "Provides tools for shoreline dating coastal Stone Age sites. The \n  implemented method was developed in Roalkvam (2023) \n  <doi:10.1016/j.quascirev.2022.107880> for the Norwegian Skagerrak coast. \n  Although it can be extended to other areas, this also forms the core area for \n  application of the package. Shoreline dating is based on the present-day \n  elevation of a site, a reconstruction of past relative sea-level change, and\n  empirically derived estimates of the likely elevation of the sites above the \n  contemporaneous sea-level when they were in use. The geographical and temporal \n  coverage of the method thus follows from the availability of local geological \n  reconstructions of shoreline displacement and the degree to which the \n  settlements to be dated have been located on or close to the shoreline when \n  they were in use. Methods for numerical treatment and visualisation of the \n  dates are provided, along with basic tools for visualising and evaluating the \n  location of sites. ",
    "version": "1.1.1",
    "maintainer": "Isak Roalkvam <isakroa@protonmail.com>",
    "author": "Isak Roalkvam [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6974-1374>)",
    "url": "https://github.com/isakro/shoredate,\nhttps://isakro.github.io/shoredate/",
    "bug_reports": "https://github.com/isakro/shoredate/issues",
    "repository": "https://cran.r-project.org/package=shoredate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shoredate Shoreline Dating Coastal Stone Age Sites Provides tools for shoreline dating coastal Stone Age sites. The \n  implemented method was developed in Roalkvam (2023) \n  <doi:10.1016/j.quascirev.2022.107880> for the Norwegian Skagerrak coast. \n  Although it can be extended to other areas, this also forms the core area for \n  application of the package. Shoreline dating is based on the present-day \n  elevation of a site, a reconstruction of past relative sea-level change, and\n  empirically derived estimates of the likely elevation of the sites above the \n  contemporaneous sea-level when they were in use. The geographical and temporal \n  coverage of the method thus follows from the availability of local geological \n  reconstructions of shoreline displacement and the degree to which the \n  settlements to be dated have been located on or close to the shoreline when \n  they were in use. Methods for numerical treatment and visualisation of the \n  dates are provided, along with basic tools for visualising and evaluating the \n  location of sites.   "
  },
  {
    "id": 20671,
    "package_name": "siebanxicor",
    "title": "Query Data Series from Bank of Mexico",
    "description": "Allows to retrieve time series of all indicators available in the Bank of Mexico's Economic Information System (<http://www.banxico.org.mx/SieInternet/>).",
    "version": "1.0.0",
    "maintainer": "No\u00e9 Palmerin  <sie@banxico.org.mx>",
    "author": "DGIE - Banco de M\u00e9xico",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=siebanxicor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "siebanxicor Query Data Series from Bank of Mexico Allows to retrieve time series of all indicators available in the Bank of Mexico's Economic Information System (<http://www.banxico.org.mx/SieInternet/>).  "
  },
  {
    "id": 20709,
    "package_name": "simITS",
    "title": "Analysis via Simulation of Interrupted Time Series (ITS) Data",
    "description": "Uses simulation to create prediction intervals for\n    post-policy outcomes in interrupted time series (ITS) designs,\n    following Miratrix (2020) <arXiv:2002.05746>. This package provides\n    methods for fitting ITS models with lagged outcomes and variables to\n    account for temporal dependencies.  It then conducts inference via\n    simulation, simulating a set of plausible counterfactual post-policy\n    series to compare to the observed post-policy series. This package\n    also provides methods to visualize such data, and also to incorporate\n    seasonality models and smoothing and aggregation/summarization.  This\n    work partially funded by Arnold Ventures in collaboration with\n    MDRC.",
    "version": "0.1.1",
    "maintainer": "Luke Miratrix <lmiratrix@g.harvard.edu>",
    "author": "Luke Miratrix [aut, cre],\n  Brit Henderson [ctb],\n  Chloe Anderson [ctb],\n  Arnold Ventures [fnd],\n  MDRC [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=simITS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "simITS Analysis via Simulation of Interrupted Time Series (ITS) Data Uses simulation to create prediction intervals for\n    post-policy outcomes in interrupted time series (ITS) designs,\n    following Miratrix (2020) <arXiv:2002.05746>. This package provides\n    methods for fitting ITS models with lagged outcomes and variables to\n    account for temporal dependencies.  It then conducts inference via\n    simulation, simulating a set of plausible counterfactual post-policy\n    series to compare to the observed post-policy series. This package\n    also provides methods to visualize such data, and also to incorporate\n    seasonality models and smoothing and aggregation/summarization.  This\n    work partially funded by Arnold Ventures in collaboration with\n    MDRC.  "
  },
  {
    "id": 20779,
    "package_name": "simts",
    "title": "Time Series Analysis Tools",
    "description": "A system contains easy-to-use tools as a support for time series analysis courses. In particular, it incorporates a technique called Generalized Method of Wavelet Moments (GMWM) as well as its robust implementation for fast and robust parameter estimation of time series models which is described, for example, in Guerrier et al. (2013) <doi: 10.1080/01621459.2013.799920>. More details can also be found in the paper linked to via the URL below.",
    "version": "0.2.3",
    "maintainer": "St\u00e9phane Guerrier <stef.guerrier@gmail.com>",
    "author": "St\u00e9phane Guerrier [aut, cre, cph],\n  James Balamuta [aut, cph],\n  Roberto Molinari [aut, cph],\n  Justin Lee [aut],\n  Lionel Voirol [aut],\n  Yuming Zhang [aut],\n  Wenchao Yang [ctb],\n  Nathanael Claussen [ctb],\n  Yunxiang Zhang [ctb],\n  Christian Gunning [cph],\n  Romain Francois [cph],\n  Ross Ihaka [cph],\n  R Core Team [cph]",
    "url": "https://github.com/SMAC-Group/simts,\nhttps://arxiv.org/pdf/1607.04543.pdf",
    "bug_reports": "https://github.com/SMAC-Group/simts/issues",
    "repository": "https://cran.r-project.org/package=simts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "simts Time Series Analysis Tools A system contains easy-to-use tools as a support for time series analysis courses. In particular, it incorporates a technique called Generalized Method of Wavelet Moments (GMWM) as well as its robust implementation for fast and robust parameter estimation of time series models which is described, for example, in Guerrier et al. (2013) <doi: 10.1080/01621459.2013.799920>. More details can also be found in the paper linked to via the URL below.  "
  },
  {
    "id": 20853,
    "package_name": "sleekts",
    "title": "4253H, Twice Smoothing",
    "description": "Compute Time series Resistant Smooth 4253H, twice smoothing method.",
    "version": "1.0.2",
    "maintainer": "Muntashir-Al-Arefin <sheen4783@gmail.com>",
    "author": "Muntashir-Al-Arefin, Prof. Md. Ayub Al.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sleekts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sleekts 4253H, Twice Smoothing Compute Time series Resistant Smooth 4253H, twice smoothing method.  "
  },
  {
    "id": 20857,
    "package_name": "slendr",
    "title": "A Simulation Framework for Spatiotemporal Population Genetics",
    "description": "A framework for simulating spatially explicit genomic data which\n    leverages real cartographic information for programmatic and visual encoding\n    of spatiotemporal population dynamics on real geographic landscapes. Population\n    genetic models are then automatically executed by the 'SLiM' software by Haller\n    et al. (2019) <doi:10.1093/molbev/msy228> behind the scenes, using a custom\n    built-in simulation 'SLiM' script. Additionally, fully abstract spatial models\n    not tied to a specific geographic location are supported, and users can also\n    simulate data from standard, non-spatial, random-mating models. These can be\n    simulated either with the 'SLiM' built-in back-end script, or using an efficient\n    coalescent population genetics simulator 'msprime' by Baumdicker et al. (2022)\n    <doi:10.1093/genetics/iyab229> with a custom-built 'Python' script bundled with the\n    R package. Simulated genomic data is saved in a tree-sequence format and can be\n    loaded, manipulated, and summarised using tree-sequence functionality via an R\n    interface to the 'Python' module 'tskit' by Kelleher et al. (2019)\n    <doi:10.1038/s41588-019-0483-y>. Complete model configuration, simulation and\n    analysis pipelines can be therefore constructed without a need to leave the R\n    environment, eliminating friction between disparate tools for population genetic\n    simulations and data analysis.",
    "version": "1.3.0",
    "maintainer": "Martin Petr <contact@bodkan.net>",
    "author": "Martin Petr [aut, cre] (ORCID: <https://orcid.org/0000-0003-4879-8421>)",
    "url": "https://github.com/bodkan/slendr",
    "bug_reports": "https://github.com/bodkan/slendr/issues",
    "repository": "https://cran.r-project.org/package=slendr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "slendr A Simulation Framework for Spatiotemporal Population Genetics A framework for simulating spatially explicit genomic data which\n    leverages real cartographic information for programmatic and visual encoding\n    of spatiotemporal population dynamics on real geographic landscapes. Population\n    genetic models are then automatically executed by the 'SLiM' software by Haller\n    et al. (2019) <doi:10.1093/molbev/msy228> behind the scenes, using a custom\n    built-in simulation 'SLiM' script. Additionally, fully abstract spatial models\n    not tied to a specific geographic location are supported, and users can also\n    simulate data from standard, non-spatial, random-mating models. These can be\n    simulated either with the 'SLiM' built-in back-end script, or using an efficient\n    coalescent population genetics simulator 'msprime' by Baumdicker et al. (2022)\n    <doi:10.1093/genetics/iyab229> with a custom-built 'Python' script bundled with the\n    R package. Simulated genomic data is saved in a tree-sequence format and can be\n    loaded, manipulated, and summarised using tree-sequence functionality via an R\n    interface to the 'Python' module 'tskit' by Kelleher et al. (2019)\n    <doi:10.1038/s41588-019-0483-y>. Complete model configuration, simulation and\n    analysis pipelines can be therefore constructed without a need to leave the R\n    environment, eliminating friction between disparate tools for population genetic\n    simulations and data analysis.  "
  },
  {
    "id": 20907,
    "package_name": "smooth",
    "title": "Forecasting Using State Space Models",
    "description": "Functions implementing Single Source of Error state space models for purposes of time series analysis and forecasting.\n             The package includes ADAM (Svetunkov, 2023, <https://openforecast.org/adam/>),\n             Exponential Smoothing (Hyndman et al., 2008, <doi: 10.1007/978-3-540-71918-2>),\n             SARIMA (Svetunkov & Boylan, 2019 <doi: 10.1080/00207543.2019.1600764>),\n             Complex Exponential Smoothing (Svetunkov & Kourentzes, 2018, <doi: 10.13140/RG.2.2.24986.29123>),\n             Simple Moving Average (Svetunkov & Petropoulos, 2018 <doi: 10.1080/00207543.2017.1380326>)\n             and several simulation functions. It also allows dealing with intermittent demand based on the\n             iETS framework (Svetunkov & Boylan, 2019, <doi: 10.13140/RG.2.2.35897.06242>).",
    "version": "4.3.1",
    "maintainer": "Ivan Svetunkov <ivan@svetunkov.com>",
    "author": "Ivan Svetunkov [aut, cre] (Senior Lecturer at Centre for Marketing\n    Analytics and Forecasting, Lancaster University, UK)",
    "url": "https://github.com/config-i1/smooth",
    "bug_reports": "https://github.com/config-i1/smooth/issues",
    "repository": "https://cran.r-project.org/package=smooth",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smooth Forecasting Using State Space Models Functions implementing Single Source of Error state space models for purposes of time series analysis and forecasting.\n             The package includes ADAM (Svetunkov, 2023, <https://openforecast.org/adam/>),\n             Exponential Smoothing (Hyndman et al., 2008, <doi: 10.1007/978-3-540-71918-2>),\n             SARIMA (Svetunkov & Boylan, 2019 <doi: 10.1080/00207543.2019.1600764>),\n             Complex Exponential Smoothing (Svetunkov & Kourentzes, 2018, <doi: 10.13140/RG.2.2.24986.29123>),\n             Simple Moving Average (Svetunkov & Petropoulos, 2018 <doi: 10.1080/00207543.2017.1380326>)\n             and several simulation functions. It also allows dealing with intermittent demand based on the\n             iETS framework (Svetunkov & Boylan, 2019, <doi: 10.13140/RG.2.2.35897.06242>).  "
  },
  {
    "id": 20920,
    "package_name": "smoots",
    "title": "Nonparametric Estimation of the Trend and Its Derivatives in TS",
    "description": "The nonparametric trend and its derivatives in equidistant time \n    series (TS) with short-memory stationary errors can be estimated. The \n    estimation is conducted via local polynomial regression using an \n    automatically selected bandwidth obtained by a built-in iterative plug-in \n    algorithm or a bandwidth fixed by the user. A Nadaraya-Watson kernel \n    smoother is also built-in as a comparison. With version 1.1.0, a linearity \n    test for the trend function, forecasting methods and backtesting \n    approaches are implemented as well.\n    The smoothing methods of the package are described in Feng, Y., Gries, T., \n    and Fritz, M. (2020) <doi:10.1080/10485252.2020.1759598>.",
    "version": "1.1.4",
    "maintainer": "Dominik Schulz <schulzd@mail.uni-paderborn.de>",
    "author": "Yuanhua Feng [aut] (Paderborn University, Germany),\n  Sebastian Letmathe [aut] (Paderborn University, Germany),\n  Dominik Schulz [aut, cre] (Paderborn University, Germany),\n  Thomas Gries [ctb] (Paderborn University, Germany),\n  Marlon Fritz [ctb] (Paderborn University, Germany)",
    "url": "https://wiwi.uni-paderborn.de/en/dep4/feng/\nhttps://wiwi.uni-paderborn.de/dep4/gries/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=smoots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smoots Nonparametric Estimation of the Trend and Its Derivatives in TS The nonparametric trend and its derivatives in equidistant time \n    series (TS) with short-memory stationary errors can be estimated. The \n    estimation is conducted via local polynomial regression using an \n    automatically selected bandwidth obtained by a built-in iterative plug-in \n    algorithm or a bandwidth fixed by the user. A Nadaraya-Watson kernel \n    smoother is also built-in as a comparison. With version 1.1.0, a linearity \n    test for the trend function, forecasting methods and backtesting \n    approaches are implemented as well.\n    The smoothing methods of the package are described in Feng, Y., Gries, T., \n    and Fritz, M. (2020) <doi:10.1080/10485252.2020.1759598>.  "
  },
  {
    "id": 20948,
    "package_name": "snotelr",
    "title": "Calculate and Visualize 'SNOTEL' Snow Data and Seasonality",
    "description": "Programmatic interface to the 'SNOTEL' snow data\n  (<https://www.nrcs.usda.gov/programs-initiatives/sswsf-snow-survey-and-water-supply-forecasting-program>). Provides easy downloads of snow \n  data into your R work space or a local directory. Additional post-processing \n  routines to extract snow season indexes are provided.",
    "version": "1.5.2",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "author": "Koen Hufkens [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5070-8109>),\n  BlueGreen Labs [cph, fnd]",
    "url": "https://github.com/bluegreen-labs/snotelr,\nhttps://bluegreen-labs.github.io/snotelr/",
    "bug_reports": "https://github.com/bluegreen-labs/snotelr/issues",
    "repository": "https://cran.r-project.org/package=snotelr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "snotelr Calculate and Visualize 'SNOTEL' Snow Data and Seasonality Programmatic interface to the 'SNOTEL' snow data\n  (<https://www.nrcs.usda.gov/programs-initiatives/sswsf-snow-survey-and-water-supply-forecasting-program>). Provides easy downloads of snow \n  data into your R work space or a local directory. Additional post-processing \n  routines to extract snow season indexes are provided.  "
  },
  {
    "id": 21017,
    "package_name": "sovereign",
    "title": "State-Dependent Empirical Analysis",
    "description": "A set of tools for state-dependent \n  empirical analysis through both VAR- and local projection-based \n  state-dependent forecasts, impulse response functions, \n  historical decompositions, and forecast error variance decompositions.   ",
    "version": "1.2.1",
    "maintainer": "Tyler J. Pike <tjpike7@gmail.com>",
    "author": "Tyler J. Pike [aut, cre]",
    "url": "https://github.com/tylerJPike/sovereign,\nhttps://tylerjpike.github.io/sovereign/",
    "bug_reports": "https://github.com/tylerJPike/sovereign/issues",
    "repository": "https://cran.r-project.org/package=sovereign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sovereign State-Dependent Empirical Analysis A set of tools for state-dependent \n  empirical analysis through both VAR- and local projection-based \n  state-dependent forecasts, impulse response functions, \n  historical decompositions, and forecast error variance decompositions.     "
  },
  {
    "id": 21024,
    "package_name": "spBFA",
    "title": "Spatial Bayesian Factor Analysis",
    "description": "Implements a spatial Bayesian non-parametric factor analysis model \n    with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC). \n    Spatial correlation is introduced in the columns of the factor loadings \n    matrix using a Bayesian non-parametric prior, the probit stick-breaking \n    process. Areal spatial data is modeled using a conditional autoregressive \n    (CAR) prior and point-referenced spatial data is treated using a Gaussian \n    process. The response variable can be modeled as Gaussian, probit, Tobit, or\n    Binomial (using Polya-Gamma augmentation). Temporal correlation is \n    introduced for the latent factors through a hierarchical structure and can \n    be specified as exponential or first-order autoregressive. Full details of \n    the package can be found in the accompanying vignette. Furthermore, the \n    details of the package can be found in \"Bayesian Non-Parametric Factor \n    Analysis for Longitudinal Spatial Surfaces\", by Berchuck et al (2019), \n    <doi:10.1214/20-BA1253> in Bayesian Analysis.",
    "version": "1.4.0",
    "maintainer": "Samuel I. Berchuck <sib2@duke.edu>",
    "author": "Samuel I. Berchuck [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spBFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spBFA Spatial Bayesian Factor Analysis Implements a spatial Bayesian non-parametric factor analysis model \n    with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC). \n    Spatial correlation is introduced in the columns of the factor loadings \n    matrix using a Bayesian non-parametric prior, the probit stick-breaking \n    process. Areal spatial data is modeled using a conditional autoregressive \n    (CAR) prior and point-referenced spatial data is treated using a Gaussian \n    process. The response variable can be modeled as Gaussian, probit, Tobit, or\n    Binomial (using Polya-Gamma augmentation). Temporal correlation is \n    introduced for the latent factors through a hierarchical structure and can \n    be specified as exponential or first-order autoregressive. Full details of \n    the package can be found in the accompanying vignette. Furthermore, the \n    details of the package can be found in \"Bayesian Non-Parametric Factor \n    Analysis for Longitudinal Spatial Surfaces\", by Berchuck et al (2019), \n    <doi:10.1214/20-BA1253> in Bayesian Analysis.  "
  },
  {
    "id": 21026,
    "package_name": "spBayes",
    "title": "Univariate and Multivariate Spatial-Temporal Modeling",
    "description": "Fits univariate and multivariate spatio-temporal\n        random effects models for point-referenced data using Markov chain Monte Carlo (MCMC). Details are given in Finley, Banerjee, and Gelfand (2015) <doi:10.18637/jss.v063.i13> and Finley and Banerjee <doi:10.1016/j.envsoft.2019.104608>.",
    "version": "0.4-8",
    "maintainer": "Andrew Finley <finleya@msu.edu>",
    "author": "Andrew Finley [aut, cre],\n  Sudipto Banerjee [aut]",
    "url": "https://www.finley-lab.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spBayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spBayes Univariate and Multivariate Spatial-Temporal Modeling Fits univariate and multivariate spatio-temporal\n        random effects models for point-referenced data using Markov chain Monte Carlo (MCMC). Details are given in Finley, Banerjee, and Gelfand (2015) <doi:10.18637/jss.v063.i13> and Finley and Banerjee <doi:10.1016/j.envsoft.2019.104608>.  "
  },
  {
    "id": 21034,
    "package_name": "spGARCH",
    "title": "Spatial ARCH and GARCH Models (spGARCH)",
    "description": "A collection of functions to deal with spatial and spatiotemporal autoregressive conditional heteroscedasticity (spatial ARCH and GARCH models) by Otto, Schmid, Garthoff (2018, Spatial Statistics) <doi:10.1016/j.spasta.2018.07.005>: simulation of spatial ARCH-type processes (spARCH, log/exponential-spARCH, complex-spARCH); quasi-maximum-likelihood estimation of the parameters of spARCH models and spatial autoregressive models with spARCH disturbances, diagnostic checks, visualizations.",
    "version": "0.2.3",
    "maintainer": "Philipp Otto <philipp.otto89@gmail.com>",
    "author": "Philipp Otto [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-9796-6682>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spGARCH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spGARCH Spatial ARCH and GARCH Models (spGARCH) A collection of functions to deal with spatial and spatiotemporal autoregressive conditional heteroscedasticity (spatial ARCH and GARCH models) by Otto, Schmid, Garthoff (2018, Spatial Statistics) <doi:10.1016/j.spasta.2018.07.005>: simulation of spatial ARCH-type processes (spARCH, log/exponential-spARCH, complex-spARCH); quasi-maximum-likelihood estimation of the parameters of spARCH models and spatial autoregressive models with spARCH disturbances, diagnostic checks, visualizations.  "
  },
  {
    "id": 21042,
    "package_name": "spStack",
    "title": "Bayesian Geostatistics Using Predictive Stacking",
    "description": "Fits Bayesian hierarchical spatial and spatial-temporal process\n    models for point-referenced Gaussian, Poisson, binomial, and binary data\n    using stacking of predictive densities. It involves sampling from\n    analytically available posterior distributions conditional upon candidate\n    values of the spatial process parameters and, subsequently assimilate\n    inference from these individual posterior distributions using Bayesian\n    predictive stacking. Our algorithm is highly parallelizable and hence, much\n    faster than traditional Markov chain Monte Carlo algorithms while delivering\n    competitive predictive performance. See Zhang, Tang, and Banerjee (2025)\n    <doi:10.1080/01621459.2025.2566449>, and, Pan, Zhang, Bradley, and Banerjee\n    (2025) <doi:10.48550/arXiv.2406.04655> for details.",
    "version": "1.1.2",
    "maintainer": "Soumyakanti Pan <span18@ucla.edu>",
    "author": "Soumyakanti Pan [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-9889-7112>),\n  Sudipto Banerjee [aut]",
    "url": "https://span-18.github.io/spStack-dev/",
    "bug_reports": "https://github.com/SPan-18/spStack-dev/issues",
    "repository": "https://cran.r-project.org/package=spStack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spStack Bayesian Geostatistics Using Predictive Stacking Fits Bayesian hierarchical spatial and spatial-temporal process\n    models for point-referenced Gaussian, Poisson, binomial, and binary data\n    using stacking of predictive densities. It involves sampling from\n    analytically available posterior distributions conditional upon candidate\n    values of the spatial process parameters and, subsequently assimilate\n    inference from these individual posterior distributions using Bayesian\n    predictive stacking. Our algorithm is highly parallelizable and hence, much\n    faster than traditional Markov chain Monte Carlo algorithms while delivering\n    competitive predictive performance. See Zhang, Tang, and Banerjee (2025)\n    <doi:10.1080/01621459.2025.2566449>, and, Pan, Zhang, Bradley, and Banerjee\n    (2025) <doi:10.48550/arXiv.2406.04655> for details.  "
  },
  {
    "id": 21043,
    "package_name": "spTDyn",
    "title": "Spatially Varying and Spatio-Temporal Dynamic Linear Models",
    "description": "Fits, spatially predicts, and temporally forecasts space-time data using Gaussian Process (GP): (1) spatially varying coefficient process models and (2) spatio-temporal dynamic linear models. Bakar et al., (2016). Bakar et al., (2015).",
    "version": "2.0.3",
    "maintainer": "K. Shuvo Bakar <shuvo.bakar@gmail.com>",
    "author": "K. Shuvo Bakar [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3215-4496>),\n  Philip Kokic [ctb],\n  Huidong Jin [ctb] (ORCID: <https://orcid.org/0000-0002-3925-0256>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spTDyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spTDyn Spatially Varying and Spatio-Temporal Dynamic Linear Models Fits, spatially predicts, and temporally forecasts space-time data using Gaussian Process (GP): (1) spatially varying coefficient process models and (2) spatio-temporal dynamic linear models. Bakar et al., (2016). Bakar et al., (2015).  "
  },
  {
    "id": 21045,
    "package_name": "spTimer",
    "title": "Spatio-Temporal Bayesian Modelling",
    "description": "Fits, spatially predicts and temporally forecasts large amounts of space-time data using  [1] Bayesian Gaussian Process (GP) Models, [2] Bayesian Auto-Regressive (AR) Models, and [3] Bayesian Gaussian Predictive Processes (GPP) based AR Models for spatio-temporal big-n problems. Bakar and Sahu (2015) <doi:10.18637/jss.v063.i15>.",
    "version": "3.3.3",
    "maintainer": "K. Shuvo Bakar <shuvo.bakar@gmail.com>",
    "author": "K. Shuvo Bakar [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3215-4496>),\n  Sujit K. Sahu [ctb] (ORCID: <https://orcid.org/0000-0003-2315-3598>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spTimer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spTimer Spatio-Temporal Bayesian Modelling Fits, spatially predicts and temporally forecasts large amounts of space-time data using  [1] Bayesian Gaussian Process (GP) Models, [2] Bayesian Auto-Regressive (AR) Models, and [3] Bayesian Gaussian Predictive Processes (GPP) based AR Models for spatio-temporal big-n problems. Bakar and Sahu (2015) <doi:10.18637/jss.v063.i15>.  "
  },
  {
    "id": 21052,
    "package_name": "spacetime",
    "title": "Classes and Methods for Spatio-Temporal Data",
    "description": "Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.",
    "version": "1.3-3",
    "maintainer": "Edzer Pebesma <edzer.pebesma@uni-muenster.de>",
    "author": "Edzer Pebesma [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8049-7069>),\n  Benedikt Graeler [ctb],\n  Tom Gottfried [ctb],\n  Robert J. Hijmans [ctb]",
    "url": "https://github.com/edzer/spacetime",
    "bug_reports": "https://github.com/edzer/spacetime/issues",
    "repository": "https://cran.r-project.org/package=spacetime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spacetime Classes and Methods for Spatio-Temporal Data Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.  "
  },
  {
    "id": 21054,
    "package_name": "spaero",
    "title": "Software for Project AERO",
    "description": "Implements methods for anticipating the emergence and eradication\n    of infectious diseases from surveillance time series. Also provides support\n    for computational experiments testing the performance of such methods.",
    "version": "0.6.0",
    "maintainer": "Eamon O'Dea <odea35@gmail.com>",
    "author": "Eamon O'Dea [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/e3bo/spaero/issues/",
    "repository": "https://cran.r-project.org/package=spaero",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spaero Software for Project AERO Implements methods for anticipating the emergence and eradication\n    of infectious diseases from surveillance time series. Also provides support\n    for computational experiments testing the performance of such methods.  "
  },
  {
    "id": 21055,
    "package_name": "spagmix",
    "title": "Artificial Spatial and Spatio-Temporal Densities on Bounded\nWindows",
    "description": "Simple utilities to design and generate density functions on bounded regions in space and space-time, and simulate independent, identically distributed data therefrom. See Davies & Lawson (2019) <doi:10.1080/00949655.2019.1575066> for example.",
    "version": "0.4-2",
    "maintainer": "Tilman M. Davies <tilman.davies@otago.ac.nz>",
    "author": "Anna K. Redmond [aut],\n  Tilman M. Davies [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spagmix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spagmix Artificial Spatial and Spatio-Temporal Densities on Bounded\nWindows Simple utilities to design and generate density functions on bounded regions in space and space-time, and simulate independent, identically distributed data therefrom. See Davies & Lawson (2019) <doi:10.1080/00949655.2019.1575066> for example.  "
  },
  {
    "id": 21069,
    "package_name": "sparklyr.flint",
    "title": "Sparklyr Extension for 'Flint'",
    "description": "This sparklyr extension makes 'Flint' time series\n    library functionalities (<https://github.com/twosigma/flint>) easily\n    accessible through R.",
    "version": "0.2.2",
    "maintainer": "Edgar Ruiz <edgar@rstudio.com>",
    "author": "Yitao Li [aut] (ORCID: <https://orcid.org/0000-0002-1261-905X>),\n  Edgar Ruiz [aut, cre]",
    "url": "<https://github.com/r-spark/sparklyr.flint>",
    "bug_reports": "https://github.com/r-spark/sparklyr.flint/issues",
    "repository": "https://cran.r-project.org/package=sparklyr.flint",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sparklyr.flint Sparklyr Extension for 'Flint' This sparklyr extension makes 'Flint' time series\n    library functionalities (<https://github.com/twosigma/flint>) easily\n    accessible through R.  "
  },
  {
    "id": 21075,
    "package_name": "sparr",
    "title": "Spatial and Spatiotemporal Relative Risk",
    "description": "Provides functions to estimate kernel-smoothed spatial and spatio-temporal densities and relative risk functions, and perform subsequent inference. Methodological details can be found in the accompanying tutorial: Davies et al. (2018) <DOI:10.1002/sim.7577>.",
    "version": "2.3-16",
    "maintainer": "Tilman M. Davies <tilman.davies@otago.ac.nz>",
    "author": "Tilman M. Davies [aut, cre],\n  Jonathan C. Marshall [aut]",
    "url": "https://tilmandavies.github.io/sparr/,\nhttps://github.com/tilmandavies/sparr/",
    "bug_reports": "https://github.com/tilmandavies/sparr/issues/",
    "repository": "https://cran.r-project.org/package=sparr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sparr Spatial and Spatiotemporal Relative Risk Provides functions to estimate kernel-smoothed spatial and spatio-temporal densities and relative risk functions, and perform subsequent inference. Methodological details can be found in the accompanying tutorial: Davies et al. (2018) <DOI:10.1002/sim.7577>.  "
  },
  {
    "id": 21101,
    "package_name": "sparsesurv",
    "title": "Forecasting and Early Outbreak Detection for Sparse Count Data",
    "description": "Functions for fitting, forecasting, and early detection of outbreaks in\n    sparse surveillance count time series. Supports negative binomial (NB),\n    self-exciting NB, generalise autoregressive moving average (GARMA) NB , zero-inflated NB (ZINB), self-exciting ZINB, generalise autoregressive moving average ZINB, and hurdle formulations. Climatic and environmental covariates\n    can be included in the regression component and/or the zero-modified components.\n    Includes outbreak-detection algorithms for NB, ZINB, and hurdle models, with\n    utilities for prediction and diagnostics.",
    "version": "0.1.1",
    "maintainer": "Alexandros Angelakis <alexandros.angelakis@swisstph.ch>",
    "author": "Alexandros Angelakis [aut, cre],\n  Bryan Nyawanda [aut],\n  Penelope Vounatsou [aut]",
    "url": "https://github.com/alexangelakis-ang/sparsesurv",
    "bug_reports": "https://github.com/alexangelakis-ang/sparsesurv/issues",
    "repository": "https://cran.r-project.org/package=sparsesurv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sparsesurv Forecasting and Early Outbreak Detection for Sparse Count Data Functions for fitting, forecasting, and early detection of outbreaks in\n    sparse surveillance count time series. Supports negative binomial (NB),\n    self-exciting NB, generalise autoregressive moving average (GARMA) NB , zero-inflated NB (ZINB), self-exciting ZINB, generalise autoregressive moving average ZINB, and hurdle formulations. Climatic and environmental covariates\n    can be included in the regression component and/or the zero-modified components.\n    Includes outbreak-detection algorithms for NB, ZINB, and hurdle models, with\n    utilities for prediction and diagnostics.  "
  },
  {
    "id": 21107,
    "package_name": "spatPomp",
    "title": "Inference for Spatiotemporal Partially Observed Markov Processes",
    "description": "Inference on panel data using spatiotemporal partially-observed Markov process (SpatPOMP) models. The 'spatPomp' package extends 'pomp' to include algorithms taking advantage of the spatial structure in order to assist with handling high dimensional processes. See Asfaw et al. (2024) <doi:10.48550/arXiv.2101.01157> for further description of the package.",
    "version": "1.1.0",
    "maintainer": "Edward Ionides <ionides@umich.edu>",
    "author": "Kidus Asfaw [aut],\n  Edward Ionides [cre, aut],\n  Aaron A. King [aut],\n  Allister Ho [ctb],\n  Joonha Park [ctb],\n  Jesse Wheeler [ctb],\n  Jifan Li [ctb],\n  Ning Ning [ctb],\n  Haogao Gu [ctb],\n  Kunyang He [ctb],\n  Gottfried Julian [ctb]",
    "url": "https://github.com/spatPomp-org/spatPomp",
    "bug_reports": "https://github.com/spatPomp-org/spatPomp/issues/",
    "repository": "https://cran.r-project.org/package=spatPomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spatPomp Inference for Spatiotemporal Partially Observed Markov Processes Inference on panel data using spatiotemporal partially-observed Markov process (SpatPOMP) models. The 'spatPomp' package extends 'pomp' to include algorithms taking advantage of the spatial structure in order to assist with handling high dimensional processes. See Asfaw et al. (2024) <doi:10.48550/arXiv.2101.01157> for further description of the package.  "
  },
  {
    "id": 21108,
    "package_name": "spate",
    "title": "Spatio-Temporal Modeling of Large Data Using a Spectral SPDE\nApproach",
    "description": "Functionality for spatio-temporal modeling of large data sets is provided. A Gaussian process in space and time is defined through a stochastic partial differential equation (SPDE). The SPDE is solved in the spectral space, and after discretizing in time and space, a linear Gaussian state space model is obtained. When doing inference, the main computational difficulty consists in evaluating the likelihood and in sampling from the full conditional of the spectral coefficients, or equivalently, the latent space-time process. In comparison to the traditional approach of using a spatio-temporal covariance function, the spectral SPDE approach is computationally advantageous. See Sigrist, Kuensch, and Stahel (2015) <doi:10.1111/rssb.12061> for more information on the methodology. This package aims at providing tools for two different modeling approaches. First, the SPDE based spatio-temporal model can be used as a component in a customized hierarchical Bayesian model (HBM). The functions of the package then provide parameterizations of the process part of the model as well as computationally efficient algorithms needed for doing inference with the HBM. Alternatively, the adaptive MCMC algorithm implemented in the package can be used as an algorithm for doing inference without any additional modeling. The MCMC algorithm supports data that follow a Gaussian or a censored distribution with point mass at zero. Covariates can be included in the model through a regression term.",
    "version": "1.7.5",
    "maintainer": "Fabio Sigrist <fabiosigrist@gmail.com>",
    "author": "Fabio Sigrist, Hans R. Kuensch, Werner A. Stahel",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spate Spatio-Temporal Modeling of Large Data Using a Spectral SPDE\nApproach Functionality for spatio-temporal modeling of large data sets is provided. A Gaussian process in space and time is defined through a stochastic partial differential equation (SPDE). The SPDE is solved in the spectral space, and after discretizing in time and space, a linear Gaussian state space model is obtained. When doing inference, the main computational difficulty consists in evaluating the likelihood and in sampling from the full conditional of the spectral coefficients, or equivalently, the latent space-time process. In comparison to the traditional approach of using a spatio-temporal covariance function, the spectral SPDE approach is computationally advantageous. See Sigrist, Kuensch, and Stahel (2015) <doi:10.1111/rssb.12061> for more information on the methodology. This package aims at providing tools for two different modeling approaches. First, the SPDE based spatio-temporal model can be used as a component in a customized hierarchical Bayesian model (HBM). The functions of the package then provide parameterizations of the process part of the model as well as computationally efficient algorithms needed for doing inference with the HBM. Alternatively, the adaptive MCMC algorithm implemented in the package can be used as an algorithm for doing inference without any additional modeling. The MCMC algorithm supports data that follow a Gaussian or a censored distribution with point mass at zero. Covariates can be included in the model through a regression term.  "
  },
  {
    "id": 21172,
    "package_name": "spectralAnomaly",
    "title": "Detect Anomalies Using the Spectral Residual Algorithm",
    "description": "Apply the spectral residual algorithm to data, such as a\n    time series, to detect anomalies. Anomaly scores can be used to determine\n    outliers based upon a threshold or fed into more sophisticated prediction\n    models. Methods are based upon \"Time-Series Anomaly Detection Service at\n    Microsoft\", Ren, H., Xu, B., Wang, Y., et al., (2019)\n    <doi:10.48550/arXiv.1906.03821>.",
    "version": "0.1.1",
    "maintainer": "Allen OBrien <allen.g.obrien@gmail.com>",
    "author": "Allen OBrien [aut, cre, cph]",
    "url": "https://al-obrien.github.io/spectralAnomaly/,\nhttps://github.com/al-obrien/spectralAnomaly",
    "bug_reports": "https://github.com/al-obrien/spectralAnomaly/issues",
    "repository": "https://cran.r-project.org/package=spectralAnomaly",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spectralAnomaly Detect Anomalies Using the Spectral Residual Algorithm Apply the spectral residual algorithm to data, such as a\n    time series, to detect anomalies. Anomaly scores can be used to determine\n    outliers based upon a threshold or fed into more sophisticated prediction\n    models. Methods are based upon \"Time-Series Anomaly Detection Service at\n    Microsoft\", Ren, H., Xu, B., Wang, Y., et al., (2019)\n    <doi:10.48550/arXiv.1906.03821>.  "
  },
  {
    "id": 21218,
    "package_name": "spiralize",
    "title": "Visualize Data on Spirals",
    "description": "It visualizes data along an Archimedean spiral <https://en.wikipedia.org/wiki/Archimedean_spiral>, \n    makes so-called spiral graph or spiral chart. \n    It has two major advantages for visualization: 1. It is able to visualize data with very long axis with high \n    resolution. 2. It is efficient for time series data to reveal periodic patterns.",
    "version": "1.1.0",
    "maintainer": "Zuguang Gu <z.gu@dkfz.de>",
    "author": "Zuguang Gu [aut, cre] (ORCID: <https://orcid.org/0000-0002-7395-8709>)",
    "url": "https://github.com/jokergoo/spiralize,\nhttps://jokergoo.github.io/spiralize/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spiralize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spiralize Visualize Data on Spirals It visualizes data along an Archimedean spiral <https://en.wikipedia.org/wiki/Archimedean_spiral>, \n    makes so-called spiral graph or spiral chart. \n    It has two major advantages for visualization: 1. It is able to visualize data with very long axis with high \n    resolution. 2. It is efficient for time series data to reveal periodic patterns.  "
  },
  {
    "id": 21239,
    "package_name": "splusTimeSeries",
    "title": "Time Series from 'S-PLUS'",
    "description": "A collection of classes and methods for working with\n  indexed rectangular data. The index values can be\n  calendar (timeSeries class) or numeric (signalSeries class).\n  Methods are included for aggregation, alignment, merging, and summaries.\n  The code was originally available in 'S-PLUS'.",
    "version": "1.5.7",
    "maintainer": "Stephen Kaluzny <spkaluzny@gmail.com>",
    "author": "Stephen Kaluzny [aut, cre],\n  TIBCO Software Inc. [aut, cph]",
    "url": "https://github.com/spkaluzny/splusTimeSeries",
    "bug_reports": "https://github.com/spkaluzny/splusTimeSeries/issues",
    "repository": "https://cran.r-project.org/package=splusTimeSeries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "splusTimeSeries Time Series from 'S-PLUS' A collection of classes and methods for working with\n  indexed rectangular data. The index values can be\n  calendar (timeSeries class) or numeric (signalSeries class).\n  Methods are included for aggregation, alignment, merging, and summaries.\n  The code was originally available in 'S-PLUS'.  "
  },
  {
    "id": 21244,
    "package_name": "spmoran",
    "title": "Fast Spatial and Spatio-Temporal Regression using Moran\nEigenvectors",
    "description": "A collection of functions for estimating spatial and spatio-temporal regression models. Moran eigenvectors are used as spatial basis functions to efficiently approximate spatially dependent Gaussian processes (i.e., random effects eigenvector spatial filtering; see Murakami and Griffith 2015 <doi: 10.1007/s10109-015-0213-7>). The implemented models include linear regression with residual spatial dependence, spatially/spatio-temporally varying coefficient models (Murakami et al., 2017, 2024; <doi:10.1016/j.spasta.2016.12.001>,<doi:10.48550/arXiv.2410.07229>), spatially filtered unconditional quantile regression (Murakami and Seya, 2019 <doi:10.1002/env.2556>), Gaussian and non-Gaussian spatial mixed models through compositionally-warping (Murakami et al. 2021, <doi:10.1016/j.spasta.2021.100520>).",
    "version": "0.3.3",
    "maintainer": "Daisuke Murakami <dmuraka@ism.ac.jp>",
    "author": "Daisuke Murakami [aut, cre]",
    "url": "https://github.com/dmuraka/spmoran",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spmoran",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spmoran Fast Spatial and Spatio-Temporal Regression using Moran\nEigenvectors A collection of functions for estimating spatial and spatio-temporal regression models. Moran eigenvectors are used as spatial basis functions to efficiently approximate spatially dependent Gaussian processes (i.e., random effects eigenvector spatial filtering; see Murakami and Griffith 2015 <doi: 10.1007/s10109-015-0213-7>). The implemented models include linear regression with residual spatial dependence, spatially/spatio-temporally varying coefficient models (Murakami et al., 2017, 2024; <doi:10.1016/j.spasta.2016.12.001>,<doi:10.48550/arXiv.2410.07229>), spatially filtered unconditional quantile regression (Murakami and Seya, 2019 <doi:10.1002/env.2556>), Gaussian and non-Gaussian spatial mixed models through compositionally-warping (Murakami et al. 2021, <doi:10.1016/j.spasta.2021.100520>).  "
  },
  {
    "id": 21250,
    "package_name": "spooky",
    "title": "Time Feature Extrapolation Using Spectral Analysis and\nJack-Knife Resampling",
    "description": "Proposes application of spectral analysis and jack-knife resampling for multivariate sequence forecasting. The application allows for a fast random search in a compact space of hyper-parameters composed by Sequence Length and Jack-Knife Leave-N-Out.",
    "version": "1.4.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino",
    "url": "https://rpubs.com/giancarlo_vercellino/spooky",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spooky",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spooky Time Feature Extrapolation Using Spectral Analysis and\nJack-Knife Resampling Proposes application of spectral analysis and jack-knife resampling for multivariate sequence forecasting. The application allows for a fast random search in a compact space of hyper-parameters composed by Sequence Length and Jack-Knife Leave-N-Out.  "
  },
  {
    "id": 21256,
    "package_name": "spotoroo",
    "title": "Spatiotemporal Clustering of Satellite Hot Spot Data",
    "description": "An algorithm to cluster satellite hot spot data spatially and temporally.",
    "version": "0.1.5",
    "maintainer": "Weihao Li <llreczx@gmail.com>",
    "author": "Weihao Li [aut, cre] (ORCID: <https://orcid.org/0000-0003-4959-106X>),\n  Di Cook [ctb] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Emily Dodwell [ctb]",
    "url": "https://tengmcing.github.io/spotoroo/,\nhttps://github.com/TengMCing/spotoroo/",
    "bug_reports": "https://github.com/TengMCing/spotoroo/issues",
    "repository": "https://cran.r-project.org/package=spotoroo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spotoroo Spatiotemporal Clustering of Satellite Hot Spot Data An algorithm to cluster satellite hot spot data spatially and temporally.  "
  },
  {
    "id": 21273,
    "package_name": "spsurvey",
    "title": "Spatial Sampling Design and Analysis",
    "description": "A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more. For additional details, see Dumelle et al. (2023) <doi:10.18637/jss.v105.i03>.",
    "version": "5.6.0",
    "maintainer": "Michael Dumelle <Dumelle.Michael@epa.gov>",
    "author": "Michael Dumelle [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3393-5529>),\n  Tom Kincaid [aut],\n  Anthony (Tony) R. Olsen [aut],\n  Marc Weber [aut],\n  Don Stevens [ctb],\n  Denis White [ctb],\n  Amanda M. Nahlik [ctb],\n  Sarah Lehmann [ctb]",
    "url": "https://usepa.github.io/spsurvey/,\nhttps://github.com/USEPA/spsurvey",
    "bug_reports": "https://github.com/USEPA/spsurvey/issues",
    "repository": "https://cran.r-project.org/package=spsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spsurvey Spatial Sampling Design and Analysis A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more. For additional details, see Dumelle et al. (2023) <doi:10.18637/jss.v105.i03>.  "
  },
  {
    "id": 21293,
    "package_name": "sr",
    "title": "Smooth Regression - The Gamma Test and Tools",
    "description": "Finds causal connections in precision data, finds lags and embeddings in \n  time series, guides training of neural networks and other smooth models, evaluates \n  their performance, gives a mathematically grounded answer to the over-training \n  problem.  Smooth regression is based on the Gamma test, which measures smoothness\n  in a multivariate relationship.  Causal relations are smooth, noise is not.  \n  'sr' includes the Gamma test and search techniques that use it. \n  References: Evans & Jones (2002) <doi:10.1098/rspa.2002.1010>, \n  AJ Jones (2004) <doi:10.1007/s10287-003-0006-1>.",
    "version": "0.1.0",
    "maintainer": "Wayne Haythorn <support@smoothregression.com>",
    "author": "Wayne Haythorn [aut, cre],\n  Antonia Jones [aut] (Principal creator of the Gamma test),\n  Sam Kemp [ctb] (Wrote the original code for the Gamma test in R)",
    "url": "https://smoothregression.com, https://github.com/haythorn/sr/",
    "bug_reports": "https://github.com/haythorn/sr/issues",
    "repository": "https://cran.r-project.org/package=sr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sr Smooth Regression - The Gamma Test and Tools Finds causal connections in precision data, finds lags and embeddings in \n  time series, guides training of neural networks and other smooth models, evaluates \n  their performance, gives a mathematically grounded answer to the over-training \n  problem.  Smooth regression is based on the Gamma test, which measures smoothness\n  in a multivariate relationship.  Causal relations are smooth, noise is not.  \n  'sr' includes the Gamma test and search techniques that use it. \n  References: Evans & Jones (2002) <doi:10.1098/rspa.2002.1010>, \n  AJ Jones (2004) <doi:10.1007/s10287-003-0006-1>.  "
  },
  {
    "id": 21294,
    "package_name": "sra",
    "title": "Selection Response Analysis",
    "description": "Artificial selection through selective breeding is an efficient way to induce changes in traits of interest in experimental populations. This package (sra) provides a set of tools to analyse artificial-selection response datasets. The data typically feature for several generations the average value of a trait in a population, the variance of the trait, the population size and the average value of the parents that were chosen to breed. Sra implements two families of models aiming at describing the dynamics of the genetic architecture of the trait during the selection response. The first family relies on purely descriptive (phenomenological) models, based on an autoregressive framework. The second family provides different mechanistic models, accounting e.g. for inbreeding, mutations, genetic and environmental canalization, or epistasis. The parameters underlying the dynamics of the time series are estimated by maximum likelihood. The sra package thus provides (i) a wrapper for the R functions mle() and optim() aiming at fitting in a convenient way a predetermined set of models, and (ii) some functions to plot and analyze the output of the models. ",
    "version": "0.1.4.1",
    "maintainer": "Arnaud Le Rouzic <arnaud.le-rouzic@universite-paris-saclay.fr>",
    "author": "Arnaud Le Rouzic",
    "url": "https://github.com/lerouzic/sra",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sra Selection Response Analysis Artificial selection through selective breeding is an efficient way to induce changes in traits of interest in experimental populations. This package (sra) provides a set of tools to analyse artificial-selection response datasets. The data typically feature for several generations the average value of a trait in a population, the variance of the trait, the population size and the average value of the parents that were chosen to breed. Sra implements two families of models aiming at describing the dynamics of the genetic architecture of the trait during the selection response. The first family relies on purely descriptive (phenomenological) models, based on an autoregressive framework. The second family provides different mechanistic models, accounting e.g. for inbreeding, mutations, genetic and environmental canalization, or epistasis. The parameters underlying the dynamics of the time series are estimated by maximum likelihood. The sra package thus provides (i) a wrapper for the R functions mle() and optim() aiming at fitting in a convenient way a predetermined set of models, and (ii) some functions to plot and analyze the output of the models.   "
  },
  {
    "id": 21309,
    "package_name": "ssaBSS",
    "title": "Stationary Subspace Analysis",
    "description": "Stationary subspace analysis (SSA) is a blind source separation (BSS) variant where stationary components are separated from non-stationary components. Several SSA methods for multivariate time series are provided here (Flumian et al. (2021); Hara et al. (2010) <doi:10.1007/978-3-642-17537-4_52>) along with functions to simulate time series with time-varying variance and autocovariance (Patilea and Raissi(2014) <doi:10.1080/01621459.2014.884504>).",
    "version": "0.1.1",
    "maintainer": "Markus Matilainen <markus.matilainen@outlook.com>",
    "author": "Markus Matilainen [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-5597-2670>),\n  Lea Flumian [aut],\n  Klaus Nordhausen [aut] (ORCID: <https://orcid.org/0000-0002-3758-8501>),\n  Sara Taskinen [aut] (ORCID: <https://orcid.org/0000-0001-9470-7258>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ssaBSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ssaBSS Stationary Subspace Analysis Stationary subspace analysis (SSA) is a blind source separation (BSS) variant where stationary components are separated from non-stationary components. Several SSA methods for multivariate time series are provided here (Flumian et al. (2021); Hara et al. (2010) <doi:10.1007/978-3-642-17537-4_52>) along with functions to simulate time series with time-varying variance and autocovariance (Patilea and Raissi(2014) <doi:10.1080/01621459.2014.884504>).  "
  },
  {
    "id": 21338,
    "package_name": "sstvars",
    "title": "Toolkit for Reduced Form and Structural Smooth Transition Vector\nAutoregressive Models",
    "description": "Penalized and non-penalized maximum likelihood estimation of smooth\n  transition vector autoregressive models with various types of transition weight\n  functions, conditional distributions, and identification methods. Constrained\n  estimation with various types of constraints is available. Residual based\n  model diagnostics, forecasting, simulations, counterfactual analysis, and\n  computation of impulse response functions, generalized impulse response functions,\n  generalized forecast error variance decompositions, as well as historical\n  decompositions. See\n  Heather Anderson, Farshid Vahid (1998) <doi:10.1016/S0304-4076(97)00076-6>,\n  Helmut L\u00fctkepohl, Aleksei Net\u0161unajev (2017) <doi:10.1016/j.jedc.2017.09.001>,\n  Markku Lanne, Savi Virolainen (2025) <doi:10.1016/j.jedc.2025.105162>,\n  Savi Virolainen (2025) <doi:10.48550/arXiv.2404.19707>.",
    "version": "1.2.2",
    "maintainer": "Savi Virolainen <savi.virolainen@helsinki.fi>",
    "author": "Savi Virolainen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5075-6821>)",
    "url": "https://github.com/saviviro/sstvars",
    "bug_reports": "https://github.com/saviviro/sstvars/issues",
    "repository": "https://cran.r-project.org/package=sstvars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sstvars Toolkit for Reduced Form and Structural Smooth Transition Vector\nAutoregressive Models Penalized and non-penalized maximum likelihood estimation of smooth\n  transition vector autoregressive models with various types of transition weight\n  functions, conditional distributions, and identification methods. Constrained\n  estimation with various types of constraints is available. Residual based\n  model diagnostics, forecasting, simulations, counterfactual analysis, and\n  computation of impulse response functions, generalized impulse response functions,\n  generalized forecast error variance decompositions, as well as historical\n  decompositions. See\n  Heather Anderson, Farshid Vahid (1998) <doi:10.1016/S0304-4076(97)00076-6>,\n  Helmut L\u00fctkepohl, Aleksei Net\u0161unajev (2017) <doi:10.1016/j.jedc.2017.09.001>,\n  Markku Lanne, Savi Virolainen (2025) <doi:10.1016/j.jedc.2025.105162>,\n  Savi Virolainen (2025) <doi:10.48550/arXiv.2404.19707>.  "
  },
  {
    "id": 21344,
    "package_name": "stR",
    "title": "Seasonal Trend Decomposition Using Regression",
    "description": "Methods for decomposing seasonal data: STR (a Seasonal-Trend \n  time series decomposition procedure based on Regression) and Robust STR. In \n  some ways, STR is similar to Ridge Regression and Robust STR can be related to \n  LASSO. They allow for multiple seasonal components, multiple linear covariates \n  with constant, flexible and seasonal influence. Seasonal patterns (for both \n  seasonal components and seasonal covariates) can be fractional and flexible \n  over time; moreover they can be either strictly periodic or have a more \n  complex topology. The methods provide confidence intervals for the estimated \n  components. The methods can also be used for forecasting.",
    "version": "0.7.1",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Alexander Dokumentov [aut] (ORCID:\n    <https://orcid.org/0000-0003-0478-0983>),\n  Rob Hyndman [aut, cre] (ORCID: <https://orcid.org/0000-0002-2140-5352>)",
    "url": "https://pkg.robjhyndman.com/stR/,\nhttps://github.com/robjhyndman/stR",
    "bug_reports": "https://github.com/robjhyndman/stR/issues",
    "repository": "https://cran.r-project.org/package=stR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stR Seasonal Trend Decomposition Using Regression Methods for decomposing seasonal data: STR (a Seasonal-Trend \n  time series decomposition procedure based on Regression) and Robust STR. In \n  some ways, STR is similar to Ridge Regression and Robust STR can be related to \n  LASSO. They allow for multiple seasonal components, multiple linear covariates \n  with constant, flexible and seasonal influence. Seasonal patterns (for both \n  seasonal components and seasonal covariates) can be fractional and flexible \n  over time; moreover they can be either strictly periodic or have a more \n  complex topology. The methods provide confidence intervals for the estimated \n  components. The methods can also be used for forecasting.  "
  },
  {
    "id": 21346,
    "package_name": "sta",
    "title": "Seasonal Trend Analysis for Time Series Imagery in R",
    "description": "Efficiently estimate shape parameters of periodic time series \n    imagery with which  a statistical seasonal trend analysis (STA) is subsequently performed. \n    STA output can be exported in conventional raster formats. \n    Methods to visualize STA output are also implemented as well as the calculation \n    of additional basic statistics. STA is based on (R. Eastman, F. Sangermano, \n    B. Ghimire, H. Zhu, H. Chen, N. Neeti, Y. Cai, E. Machado and S. Crema, 2009) <doi:10.1080/01431160902755338>.",
    "version": "0.1.7",
    "maintainer": "Inder Tecuapetla-Gomez <itecuapetla@conabio.gob.mx>",
    "author": "Inder Tecuapetla-Gomez [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sta Seasonal Trend Analysis for Time Series Imagery in R Efficiently estimate shape parameters of periodic time series \n    imagery with which  a statistical seasonal trend analysis (STA) is subsequently performed. \n    STA output can be exported in conventional raster formats. \n    Methods to visualize STA output are also implemented as well as the calculation \n    of additional basic statistics. STA is based on (R. Eastman, F. Sangermano, \n    B. Ghimire, H. Zhu, H. Chen, N. Neeti, Y. Cai, E. Machado and S. Crema, 2009) <doi:10.1080/01431160902755338>.  "
  },
  {
    "id": 21364,
    "package_name": "stampr",
    "title": "Spatial Temporal Analysis of Moving Polygons",
    "description": "Perform spatial temporal analysis of moving polygons; a\n    longstanding analysis problem in Geographic Information Systems. Facilitates\n    directional analysis, distance analysis, and some other simple functionality for\n    examining spatial-temporal patterns of moving polygons.",
    "version": "0.3.1",
    "maintainer": "Jed Long <jed.long@uwo.ca>",
    "author": "Jed Long [aut, cre] (ORCID: <https://orcid.org/0000-0002-2815-0399>),\n  Colin Robertson [aut]",
    "url": "https://github.com/jedalong/stampr",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stampr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stampr Spatial Temporal Analysis of Moving Polygons Perform spatial temporal analysis of moving polygons; a\n    longstanding analysis problem in Geographic Information Systems. Facilitates\n    directional analysis, distance analysis, and some other simple functionality for\n    examining spatial-temporal patterns of moving polygons.  "
  },
  {
    "id": 21375,
    "package_name": "starm",
    "title": "Spatio-Temporal Autologistic Regression Model",
    "description": "Estimates the coefficients of the two-time centered autologistic regression model based on Gegout-Petit A., Guerin-Dubrana L., Li S. \"A new centered spatio-temporal autologistic regression model. Application to local spread of plant diseases.\" 2019. <arXiv:1811.06782>, using a grid of binary variables to estimate the spread of a disease on the grid over the years. ",
    "version": "0.1.0",
    "maintainer": "Yannis Barboni <yannis.barboni1@gmail.com>",
    "author": "Yannis Barboni [aut, cre],\n  Anne Gegout-Petit [aut],\n  Shuxian Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=starm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "starm Spatio-Temporal Autologistic Regression Model Estimates the coefficients of the two-time centered autologistic regression model based on Gegout-Petit A., Guerin-Dubrana L., Li S. \"A new centered spatio-temporal autologistic regression model. Application to local spread of plant diseases.\" 2019. <arXiv:1811.06782>, using a grid of binary variables to estimate the spread of a disease on the grid over the years.   "
  },
  {
    "id": 21395,
    "package_name": "statcomp",
    "title": "Statistical Complexity and Information Measures for Time Series\nAnalysis",
    "description": "An implementation of local and global statistical complexity measures (aka Information Theory Quantifiers, ITQ) for time series analysis based on ordinal statistics (Bandt and Pompe (2002) <DOI:10.1103/PhysRevLett.88.174102>). Several distance measures that operate on ordinal pattern distributions, auxiliary functions for ordinal pattern analysis, and generating functions for stochastic and deterministic-chaotic processes for ITQ testing are provided. ",
    "version": "0.1.0",
    "maintainer": "Sebastian Sippel <sebastian.sippel@env.ethz.ch>",
    "author": "Sebastian Sippel [aut, cre] (Original package development was supported\n    by MPI Biogeochemistry, BGI Department),\n  Holger Lange [aut],\n  Fabian Gans [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=statcomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "statcomp Statistical Complexity and Information Measures for Time Series\nAnalysis An implementation of local and global statistical complexity measures (aka Information Theory Quantifiers, ITQ) for time series analysis based on ordinal statistics (Bandt and Pompe (2002) <DOI:10.1103/PhysRevLett.88.174102>). Several distance measures that operate on ordinal pattern distributions, auxiliary functions for ordinal pattern analysis, and generating functions for stochastic and deterministic-chaotic processes for ITQ testing are provided.   "
  },
  {
    "id": 21399,
    "package_name": "statespacer",
    "title": "State Space Modelling in 'R'",
    "description": "A tool that makes estimating models in state space form \n    a breeze. See \"Time Series Analysis by State Space Methods\" by \n    Durbin and Koopman (2012, ISBN: 978-0-19-964117-8) for details \n    about the algorithms implemented.",
    "version": "0.5.0",
    "maintainer": "Dylan Beijers <dylanbeijers@gmail.com>",
    "author": "Dylan Beijers [aut, cre]",
    "url": "https://DylanB95.github.io/statespacer/,\nhttps://github.com/DylanB95/statespacer/",
    "bug_reports": "https://github.com/DylanB95/statespacer/issues/",
    "repository": "https://cran.r-project.org/package=statespacer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "statespacer State Space Modelling in 'R' A tool that makes estimating models in state space form \n    a breeze. See \"Time Series Analysis by State Space Methods\" by \n    Durbin and Koopman (2012, ISBN: 978-0-19-964117-8) for details \n    about the algorithms implemented.  "
  },
  {
    "id": 21409,
    "package_name": "statioVAR",
    "title": "Trend Removal for Vector Autoregressive Workflows",
    "description": "Detrending multivariate time-series to approximate stationarity when dealing with intensive longitudinal data, prior to Vector Autoregressive (VAR) or multilevel-VAR estimation. Classical VAR assumes weak stationarity (constant first two moments), and deterministic trends inflate spurious autocorrelation, biasing Granger-causality and impulse-response analyses. All functions operate on raw panel data and write detrended columns back to the data set, but differ in the level at which the trend is estimated. See, for instance, Wang & Maxwell (2015) <doi:10.1037/met0000030>; Burger et al. (2022) <doi:10.4324/9781003111238-13>; Epskamp et al. (2018) <doi:10.1177/2167702617744325>.  ",
    "version": "0.1.3",
    "maintainer": "Giuseppe Corbelli <giuseppe.corbelli@uniroma1.it>",
    "author": "Giuseppe Corbelli [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2864-3548>)",
    "url": "https://github.com/g-corbelli/statioVAR",
    "bug_reports": "https://github.com/g-corbelli/statioVAR/issues",
    "repository": "https://cran.r-project.org/package=statioVAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "statioVAR Trend Removal for Vector Autoregressive Workflows Detrending multivariate time-series to approximate stationarity when dealing with intensive longitudinal data, prior to Vector Autoregressive (VAR) or multilevel-VAR estimation. Classical VAR assumes weak stationarity (constant first two moments), and deterministic trends inflate spurious autocorrelation, biasing Granger-causality and impulse-response analyses. All functions operate on raw panel data and write detrended columns back to the data set, but differ in the level at which the trend is estimated. See, for instance, Wang & Maxwell (2015) <doi:10.1037/met0000030>; Burger et al. (2022) <doi:10.4324/9781003111238-13>; Epskamp et al. (2018) <doi:10.1177/2167702617744325>.    "
  },
  {
    "id": 21428,
    "package_name": "stcos",
    "title": "Space-Time Change of Support",
    "description": "Spatio-temporal change of support (STCOS) methods are designed for statistical inference\n\ton geographic and time domains which differ from those on which the data were observed. In\n\tparticular, a parsimonious class of STCOS models supporting Gaussian outcomes was introduced\n\tby Bradley, Wikle, and Holan <doi:10.1002/sta4.94>. The 'stcos' package contains tools which\n\tfacilitate use of STCOS models.",
    "version": "0.3.1",
    "maintainer": "Andrew M. Raim <andrew.raim@gmail.com>",
    "author": "Andrew M. Raim [aut, cre],\n  Scott H. Holan [aut, res],\n  Jonathan R. Bradley [aut, res],\n  Christopher K. Wikle [aut, res]",
    "url": "https://github.com/holans/ST-COS",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stcos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stcos Space-Time Change of Support Spatio-temporal change of support (STCOS) methods are designed for statistical inference\n\ton geographic and time domains which differ from those on which the data were observed. In\n\tparticular, a parsimonious class of STCOS models supporting Gaussian outcomes was introduced\n\tby Bradley, Wikle, and Holan <doi:10.1002/sta4.94>. The 'stcos' package contains tools which\n\tfacilitate use of STCOS models.  "
  },
  {
    "id": 21438,
    "package_name": "stelfi",
    "title": "Hawkes and Log-Gaussian Cox Point Processes Using Template Model\nBuilder",
    "description": "Fit Hawkes and log-Gaussian Cox process models with extensions. Introduced in Hawkes (1971) <doi:10.2307/2334319> a Hawkes process is a self-exciting temporal point process where the occurrence of an event immediately increases the chance of another. We extend this to consider self-inhibiting process and a non-homogeneous background rate. A log-Gaussian Cox process is a Poisson point process where the log-intensity is given by a Gaussian random field. We extend this  to a joint likelihood formulation fitting a marked log-Gaussian Cox model. In addition, the package offers functionality to fit self-exciting spatiotemporal point processes. Models are fitted via maximum likelihood using 'TMB' (Template Model Builder). Where included 1) random fields are assumed to be Gaussian and are integrated over using the Laplace approximation and 2) a stochastic partial differential equation model, introduced by Lindgren, Rue, and Lindstr\u00f6m. (2011) <doi:10.1111/j.1467-9868.2011.00777.x>, is defined for the field(s). ",
    "version": "1.0.2",
    "maintainer": "Charlotte M. Jones-Todd <c.jonestodd@auckland.ac.nz>",
    "author": "Charlotte M. Jones-Todd [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1201-2781>, Charlotte Jones-Todd wrote\n    and continued developmend of the main code.),\n  Alec van Helsdingen [aut] (Alec van Helsdingen wrote the Hawkes\n    templates and extended self-exciting TMB templates),\n  Xiangjie Xue [ctb] (Xiangjie Xue worked the early spatio-temporal\n    self-exciting TMB templates),\n  Joseph Reps [ctb] (Joseph Reps worked on the spatio-temporal\n    self-exciting TMB templates),\n  Marsden Fund 3723517 [fnd],\n  Asian Office of Aerospace Research & Development FA2386-21-1-4028 [fnd]",
    "url": "https://github.com/cmjt/stelfi/",
    "bug_reports": "https://github.com/cmjt/stelfi/issues",
    "repository": "https://cran.r-project.org/package=stelfi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stelfi Hawkes and Log-Gaussian Cox Point Processes Using Template Model\nBuilder Fit Hawkes and log-Gaussian Cox process models with extensions. Introduced in Hawkes (1971) <doi:10.2307/2334319> a Hawkes process is a self-exciting temporal point process where the occurrence of an event immediately increases the chance of another. We extend this to consider self-inhibiting process and a non-homogeneous background rate. A log-Gaussian Cox process is a Poisson point process where the log-intensity is given by a Gaussian random field. We extend this  to a joint likelihood formulation fitting a marked log-Gaussian Cox model. In addition, the package offers functionality to fit self-exciting spatiotemporal point processes. Models are fitted via maximum likelihood using 'TMB' (Template Model Builder). Where included 1) random fields are assumed to be Gaussian and are integrated over using the Laplace approximation and 2) a stochastic partial differential equation model, introduced by Lindgren, Rue, and Lindstr\u00f6m. (2011) <doi:10.1111/j.1467-9868.2011.00777.x>, is defined for the field(s).   "
  },
  {
    "id": 21457,
    "package_name": "steps",
    "title": "Spatially- and Temporally-Explicit Population Simulator",
    "description": "Software to simulate population change across space and time. Visintin et al. (2020) <doi:10.1111/2041-210X.13354>.",
    "version": "1.3.0",
    "maintainer": "Casey Visintin <casey.visintin@unimelb.edu.au>",
    "author": "Casey Visintin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2245-8998>),\n  Nick Golding [ctb],\n  Skipton Woolley [ctb]",
    "url": "https://github.com/steps-dev/steps",
    "bug_reports": "https://github.com/steps-dev/steps/issues",
    "repository": "https://cran.r-project.org/package=steps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "steps Spatially- and Temporally-Explicit Population Simulator Software to simulate population change across space and time. Visintin et al. (2020) <doi:10.1111/2041-210X.13354>.  "
  },
  {
    "id": 21463,
    "package_name": "stfit",
    "title": "Spatio-Temporal Functional Imputation Tool",
    "description": "A general spatiotemporal satellite image imputation method based on sparse functional data analytic techniques. The imputation method applies and extends the Functional Principal Analysis by Conditional Estimation (PACE). The underlying idea for the proposed procedure is to impute a missing pixel by borrowing information from temporally and spatially contiguous pixels based on the best linear unbiased prediction.  ",
    "version": "0.99.9",
    "maintainer": "Weicheng Zhu <mingsnu@gmail.com>",
    "author": "Weicheng Zhu [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/mingsnu/stfit/issues",
    "repository": "https://cran.r-project.org/package=stfit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stfit Spatio-Temporal Functional Imputation Tool A general spatiotemporal satellite image imputation method based on sparse functional data analytic techniques. The imputation method applies and extends the Functional Principal Analysis by Conditional Estimation (PACE). The underlying idea for the proposed procedure is to impute a missing pixel by borrowing information from temporally and spatially contiguous pixels based on the best linear unbiased prediction.    "
  },
  {
    "id": 21464,
    "package_name": "stgam",
    "title": "Spatially and Temporally Varying Coefficient Models Using\nGeneralized Additive Models",
    "description": "A framework for specifying spatially, temporally and spatially-and-temporally varying coefficient models using Generalized Additive Models with smooths. The smooths are parameterised with location, time and predictor variables. The framework supports the investigation of the presence and nature of any space-time dependencies in the data by evaluating multiple model forms (specifications) using a Generalized Cross-Validation score. The workflow sequence is to: i) Prepare the data by lengthening it to have a single location and time variables for each observation. ii) Evaluate all possible spatial and/or temporal models in which each predictor is specified in different ways. iii) Evaluate each model and pick the best one. iv) Create the final model. v) Calculate the varying coefficient estimates to quantify how the relationships between the target and predictor variables vary over space, time or space-time. vi) Create maps, time series plots etc. For more details see: Comber et al (2023) <doi:10.4230/LIPIcs.GIScience.2023.22>, Comber et al (2024) <doi:10.1080/13658816.2023.2270285>  and Comber et al (2004) <doi:10.3390/ijgi13120459>.",
    "version": "1.1.0",
    "maintainer": "Lex Comber <a.comber@leeds.ac.uk>",
    "author": "Lex Comber [aut, cre],\n  Paul Harris [ctb],\n  Chris Brunsdon [ctb]",
    "url": "https://github.com/lexcomber/stgam",
    "bug_reports": "https://github.com/lexcomber/stgam/issues",
    "repository": "https://cran.r-project.org/package=stgam",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stgam Spatially and Temporally Varying Coefficient Models Using\nGeneralized Additive Models A framework for specifying spatially, temporally and spatially-and-temporally varying coefficient models using Generalized Additive Models with smooths. The smooths are parameterised with location, time and predictor variables. The framework supports the investigation of the presence and nature of any space-time dependencies in the data by evaluating multiple model forms (specifications) using a Generalized Cross-Validation score. The workflow sequence is to: i) Prepare the data by lengthening it to have a single location and time variables for each observation. ii) Evaluate all possible spatial and/or temporal models in which each predictor is specified in different ways. iii) Evaluate each model and pick the best one. iv) Create the final model. v) Calculate the varying coefficient estimates to quantify how the relationships between the target and predictor variables vary over space, time or space-time. vi) Create maps, time series plots etc. For more details see: Comber et al (2023) <doi:10.4230/LIPIcs.GIScience.2023.22>, Comber et al (2024) <doi:10.1080/13658816.2023.2270285>  and Comber et al (2004) <doi:10.3390/ijgi13120459>.  "
  },
  {
    "id": 21467,
    "package_name": "stilt",
    "title": "Separable Gaussian Process Interpolation (Emulation)",
    "description": "Functions for simplified emulation of time series computer model output in model parameter space using Gaussian processes. Stilt can be used more generally for Kriging of spatio-temporal fields. There are functions to predict at new parameter settings, to test the emulator using cross-validation (which includes information on 95% confidence interval empirical coverage), and to produce contour plots over 2D slices in model parameter space.",
    "version": "1.3.1",
    "maintainer": "Kelsey Ruckert <datamgmt@scrim.psu.edu>",
    "author": "Roman Olson [aut],\n  Won Chang [aut],\n  Klaus Keller [aut],\n  Murali Haran [aut],\n  Kelsey Ruckert [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stilt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stilt Separable Gaussian Process Interpolation (Emulation) Functions for simplified emulation of time series computer model output in model parameter space using Gaussian processes. Stilt can be used more generally for Kriging of spatio-temporal fields. There are functions to predict at new parameter settings, to test the emulator using cross-validation (which includes information on 95% confidence interval empirical coverage), and to produce contour plots over 2D slices in model parameter space.  "
  },
  {
    "id": 21471,
    "package_name": "stlARIMA",
    "title": "STL Decomposition and ARIMA Hybrid Forecasting Model",
    "description": "Univariate time series forecasting with STL decomposition based auto regressive integrated moving average (ARIMA) hybrid  model. For method details see Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>. ",
    "version": "0.1.0",
    "maintainer": "Ronit Jaiswal <ronitjaiswal2912@gmail.com>",
    "author": "Ronit Jaiswal [aut, cre],\n  Girish Kumar Jha [aut, ctb],\n  Rajeev Ranjan Kumar [ctb],\n  Kapil Choudhary [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stlARIMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stlARIMA STL Decomposition and ARIMA Hybrid Forecasting Model Univariate time series forecasting with STL decomposition based auto regressive integrated moving average (ARIMA) hybrid  model. For method details see Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>.   "
  },
  {
    "id": 21472,
    "package_name": "stlELM",
    "title": "Hybrid Forecasting Model Based on STL Decomposition and ELM",
    "description": "Univariate time series forecasting with STL decomposition based Extreme Learning Machine hybrid  model. For method details see Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>. ",
    "version": "0.1.1",
    "maintainer": "Girish Kumar Jha <girish.stat@gmail.com>",
    "author": "Girish Kumar Jha [aut, cre],\n  Ronit Jaiswal [aut, ctb],\n  Kapil Choudhary [ctb],\n  Rajeev Ranjan Kumar [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stlELM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stlELM Hybrid Forecasting Model Based on STL Decomposition and ELM Univariate time series forecasting with STL decomposition based Extreme Learning Machine hybrid  model. For method details see Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>.   "
  },
  {
    "id": 21473,
    "package_name": "stlTDNN",
    "title": "STL Decomposition and TDNN Hybrid Time Series Forecasting",
    "description": "Implementation of hybrid STL decomposition based time delay neural network model for univariate time series forecasting. For method details see Jha G K, Sinha, K (2014). <doi:10.1007/s00521-012-1264-z>, Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>. ",
    "version": "0.1.0",
    "maintainer": "Girish Kumar Jha <girish.stat@gmail.com>",
    "author": "Girish Kumar Jha [aut, cre],\n  Ronit Jaiswal [aut, ctb],\n  Kapil Choudhary [ctb],\n  Rajeev Ranjan Kumar [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stlTDNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stlTDNN STL Decomposition and TDNN Hybrid Time Series Forecasting Implementation of hybrid STL decomposition based time delay neural network model for univariate time series forecasting. For method details see Jha G K, Sinha, K (2014). <doi:10.1007/s00521-012-1264-z>, Xiong T, Li C, Bao Y (2018). <doi:10.1016/j.neucom.2017.11.053>.   "
  },
  {
    "id": 21474,
    "package_name": "stlnpp",
    "title": "Spatio-Temporal Analysis of Point Patterns on Linear Networks",
    "description": "Statistical analysis of spatio-temporal point processes on linear networks. This packages provides tools to visualise and analyse spatio-temporal point patterns on linear networks using first, second, and higher-order summary statistics.",
    "version": "0.5.0",
    "maintainer": "Mehdi Moradi <m2.moradi@yahoo.com>",
    "author": "Mehdi Moradi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3905-4498>),\n  Ottmar Cronie [ctb],\n  Jorge Mateu [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stlnpp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stlnpp Spatio-Temporal Analysis of Point Patterns on Linear Networks Statistical analysis of spatio-temporal point processes on linear networks. This packages provides tools to visualise and analyse spatio-temporal point patterns on linear networks using first, second, and higher-order summary statistics.  "
  },
  {
    "id": 21475,
    "package_name": "stlplus",
    "title": "Enhanced Seasonal Decomposition of Time Series by Loess",
    "description": "Decompose a time series into seasonal, trend, and remainder\n    components using an implementation of Seasonal Decomposition of Time\n    Series by Loess (STL) that provides several enhancements over the STL\n    method in the stats package.  These enhancements include handling missing\n    values, providing higher order (quadratic) loess smoothing with automated\n    parameter choices, frequency component smoothing beyond the seasonal and\n    trend components, and some basic plot methods for diagnostics.",
    "version": "0.5.1",
    "maintainer": "Ryan Hafen <rhafen@gmail.com>",
    "author": "Ryan Hafen [aut, cre]",
    "url": "https://github.com/hafen/stlplus",
    "bug_reports": "https://github.com/hafen/stlplus/issues",
    "repository": "https://cran.r-project.org/package=stlplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stlplus Enhanced Seasonal Decomposition of Time Series by Loess Decompose a time series into seasonal, trend, and remainder\n    components using an implementation of Seasonal Decomposition of Time\n    Series by Loess (STL) that provides several enhancements over the STL\n    method in the stats package.  These enhancements include handling missing\n    values, providing higher order (quadratic) loess smoothing with automated\n    parameter choices, frequency component smoothing beyond the seasonal and\n    trend components, and some basic plot methods for diagnostics.  "
  },
  {
    "id": 21480,
    "package_name": "stocc",
    "title": "Fit a Spatial Occupancy Model via Gibbs Sampling",
    "description": "Fit a spatial-temporal occupancy models using\n    a probit formulation instead of a traditional logit\n    model.",
    "version": "1.31",
    "maintainer": "Devin S. Johnson <devin.johnson@noaa.gov>",
    "author": "Devin S. Johnson",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stocc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stocc Fit a Spatial Occupancy Model via Gibbs Sampling Fit a spatial-temporal occupancy models using\n    a probit formulation instead of a traditional logit\n    model.  "
  },
  {
    "id": 21493,
    "package_name": "stopp",
    "title": "Spatio-Temporal Point Pattern Methods, Model Fitting,\nDiagnostics, Simulation, Local Tests",
    "description": "Toolbox for different kinds of spatio-temporal analyses to be performed on observed point patterns, following the growing stream of literature on point process theory. This R package implements functions to perform different kinds of analyses on point processes, proposed in the papers (Siino, Adelfio, and Mateu 2018<doi:10.1007/s00477-018-1579-0>; Siino et al. 2018<doi:10.1002/env.2463>; Adelfio et al. 2020<doi:10.1007/s00477-019-01748-1>; D\u2019Angelo, Adelfio, and Mateu 2021<doi:10.1016/j.spasta.2021.100534>; D\u2019Angelo, Adelfio, and Mateu 2022<doi:10.1007/s00362-022-01338-4>; D\u2019Angelo, Adelfio, and Mateu 2023<doi:10.1016/j.csda.2022.107679>). The main topics include modeling, statistical inference, and simulation issues on spatio-temporal point processes on Euclidean space and linear networks. Version 1.0.0 has been updated for accompanying the journal publication D Angelo and Adelfio 2025 <doi:10.18637/jss.v113.i10>.",
    "version": "1.0.0",
    "maintainer": "Nicoletta D'Angelo <nicoletta.dangelo@unipa.it>",
    "author": "Nicoletta D'Angelo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8878-5986>),\n  Giada Adelfio [aut] (ORCID: <https://orcid.org/0000-0002-3194-4296>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stopp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stopp Spatio-Temporal Point Pattern Methods, Model Fitting,\nDiagnostics, Simulation, Local Tests Toolbox for different kinds of spatio-temporal analyses to be performed on observed point patterns, following the growing stream of literature on point process theory. This R package implements functions to perform different kinds of analyses on point processes, proposed in the papers (Siino, Adelfio, and Mateu 2018<doi:10.1007/s00477-018-1579-0>; Siino et al. 2018<doi:10.1002/env.2463>; Adelfio et al. 2020<doi:10.1007/s00477-019-01748-1>; D\u2019Angelo, Adelfio, and Mateu 2021<doi:10.1016/j.spasta.2021.100534>; D\u2019Angelo, Adelfio, and Mateu 2022<doi:10.1007/s00362-022-01338-4>; D\u2019Angelo, Adelfio, and Mateu 2023<doi:10.1016/j.csda.2022.107679>). The main topics include modeling, statistical inference, and simulation issues on spatio-temporal point processes on Euclidean space and linear networks. Version 1.0.0 has been updated for accompanying the journal publication D Angelo and Adelfio 2025 <doi:10.18637/jss.v113.i10>.  "
  },
  {
    "id": 21502,
    "package_name": "stpp",
    "title": "Space-Time Point Pattern Simulation, Visualisation and Analysis",
    "description": "Many of the models encountered in applications of point process methods to the study of spatio-temporal phenomena are covered in 'stpp'. This package provides statistical tools for analyzing the global and local second-order properties of spatio-temporal point processes, including estimators of the space-time inhomogeneous K-function and pair correlation function. It also includes tools to get static and dynamic display of spatio-temporal point patterns. See Gabriel et al (2013) <doi:10.18637/jss.v053.i02>.",
    "version": "2.0-8",
    "maintainer": "Edith Gabriel <edith.gabriel@inrae.fr>",
    "author": "Edith Gabriel [aut, cre],\n  Peter J Diggle [aut],\n  Barry Rowlingson [aut],\n  Francisco J Rodriguez-Cortes [aut]",
    "url": "",
    "bug_reports": "https://github.com/stpp-GitHub-community",
    "repository": "https://cran.r-project.org/package=stpp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stpp Space-Time Point Pattern Simulation, Visualisation and Analysis Many of the models encountered in applications of point process methods to the study of spatio-temporal phenomena are covered in 'stpp'. This package provides statistical tools for analyzing the global and local second-order properties of spatio-temporal point processes, including estimators of the space-time inhomogeneous K-function and pair correlation function. It also includes tools to get static and dynamic display of spatio-temporal point patterns. See Gabriel et al (2013) <doi:10.18637/jss.v053.i02>.  "
  },
  {
    "id": 21503,
    "package_name": "stppSim",
    "title": "Spatiotemporal Point Patterns Simulation",
    "description": "Generates artificial point patterns marked by their\n  spatial and temporal signatures. The resulting point cloud\n  may exhibit inherent interactions between both signatures.\n  The simulation integrates microsimulation \n  (Holm, E., (2017)<doi:10.1002/9781118786352.wbieg0320>) \n  and agent-based models (Bonabeau, E., (2002)<doi:10.1073/pnas.082080899>),\n  beginning with the configuration of movement characteristics for \n  the specified agents (referred to as 'walkers') and their interactions \n  within the simulation environment. These interactions \n  (Quaglietta, L. and Porto, M., (2019)<doi:10.1186/s40462-019-0154-8>) \n  result in specific spatiotemporal patterns that can be visualized, \n  analyzed, and used for various analytical purposes. \n  Given the growing scarcity of detailed spatiotemporal data \n  across many domains, this package provides an alternative data source \n  for applications in social and life sciences.",
    "version": "1.3.4",
    "maintainer": "Monsuru Adepeju <monsuur2010@yahoo.com>",
    "author": "Monsuru Adepeju [cre, aut]",
    "url": "https://github.com/MAnalytics/stppSim",
    "bug_reports": "https://github.com/Manalytics/stppSim/issues/new/choose",
    "repository": "https://cran.r-project.org/package=stppSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stppSim Spatiotemporal Point Patterns Simulation Generates artificial point patterns marked by their\n  spatial and temporal signatures. The resulting point cloud\n  may exhibit inherent interactions between both signatures.\n  The simulation integrates microsimulation \n  (Holm, E., (2017)<doi:10.1002/9781118786352.wbieg0320>) \n  and agent-based models (Bonabeau, E., (2002)<doi:10.1073/pnas.082080899>),\n  beginning with the configuration of movement characteristics for \n  the specified agents (referred to as 'walkers') and their interactions \n  within the simulation environment. These interactions \n  (Quaglietta, L. and Porto, M., (2019)<doi:10.1186/s40462-019-0154-8>) \n  result in specific spatiotemporal patterns that can be visualized, \n  analyzed, and used for various analytical purposes. \n  Given the growing scarcity of detailed spatiotemporal data \n  across many domains, this package provides an alternative data source \n  for applications in social and life sciences.  "
  },
  {
    "id": 21523,
    "package_name": "stray",
    "title": "Anomaly Detection in High Dimensional and Temporal Data",
    "description": "\n    This is a modification of 'HDoutliers' package. The 'HDoutliers' algorithm is a powerful \n    unsupervised algorithm for detecting anomalies in high-dimensional data, with a \n    strong theoretical foundation. However, it suffers from some limitations that \n    significantly hinder its performance level, under certain circumstances. This package \n    implements the algorithm proposed in Talagala, Hyndman and Smith-Miles (2019) \n    <arXiv:1908.04000>  for detecting anomalies in high-dimensional data\n    that addresses these limitations of 'HDoutliers' algorithm. We define an anomaly as an observation that deviates markedly from the majority\n    with a large distance gap. An approach based on extreme value theory is used \n    for the anomalous threshold calculation.",
    "version": "0.1.1",
    "maintainer": "Priyanga Dilini Talagala <pritalagala@gmail.com>",
    "author": "Priyanga Dilini Talagala [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2870-7449>),\n  Rob J Hyndman [ths] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Kate Smith-Miles [ths]",
    "url": "",
    "bug_reports": "https://github.com/pridiltal/stray/issues",
    "repository": "https://cran.r-project.org/package=stray",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stray Anomaly Detection in High Dimensional and Temporal Data \n    This is a modification of 'HDoutliers' package. The 'HDoutliers' algorithm is a powerful \n    unsupervised algorithm for detecting anomalies in high-dimensional data, with a \n    strong theoretical foundation. However, it suffers from some limitations that \n    significantly hinder its performance level, under certain circumstances. This package \n    implements the algorithm proposed in Talagala, Hyndman and Smith-Miles (2019) \n    <arXiv:1908.04000>  for detecting anomalies in high-dimensional data\n    that addresses these limitations of 'HDoutliers' algorithm. We define an anomaly as an observation that deviates markedly from the majority\n    with a large distance gap. An approach based on extreme value theory is used \n    for the anomalous threshold calculation.  "
  },
  {
    "id": 21535,
    "package_name": "stressr",
    "title": "Fetch and plot financial stress index and component data",
    "description": "Forms queries to submit to the Cleveland Federal Reserve Bank web\n    site's financial stress index data site.  Provides query functions for both\n    the composite stress index and the components data. By default the download\n    includes daily time series data starting September 25, 1991.  The functions\n    return a class of either type easing or cfsi which contain a list of items\n    related to the query and its graphical presentation.  The list includes the\n    time series data as an xts object.  The package provides four lattice time\n    series plots to render the time series data in a manner similar to the\n    bank's own presentation.",
    "version": "1.0.0",
    "maintainer": "Matt Barry <mrb@softisms.com>",
    "author": "Matt Barry <mrb@softisms.com>",
    "url": "https://github.com/mrbcuda/stressr",
    "bug_reports": "https://github.com/mrbcuda/stressr/issues",
    "repository": "https://cran.r-project.org/package=stressr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stressr Fetch and plot financial stress index and component data Forms queries to submit to the Cleveland Federal Reserve Bank web\n    site's financial stress index data site.  Provides query functions for both\n    the composite stress index and the components data. By default the download\n    includes daily time series data starting September 25, 1991.  The functions\n    return a class of either type easing or cfsi which contain a list of items\n    related to the query and its graphical presentation.  The list includes the\n    time series data as an xts object.  The package provides four lattice time\n    series plots to render the time series data in a manner similar to the\n    bank's own presentation.  "
  },
  {
    "id": 21560,
    "package_name": "stxplore",
    "title": "Exploration of Spatio-Temporal Data",
    "description": "A set of statistical tools for spatio-temporal data exploration.     \n    Includes simple plotting functions, covariance calculations and computations \n    similar to principal component analysis for spatio-temporal data. Can use \n    both dataframes and stars objects for all plots and computations. For more \n    details refer 'Spatio-Temporal Statistics with R' (Christopher K. Wikle, \n    Andrew Zammit-Mangion, Noel Cressie, 2019, ISBN:9781138711136).",
    "version": "0.1.0",
    "maintainer": "Sevvandi Kandanaarachchi <sevvandik@gmail.com>",
    "author": "Sevvandi Kandanaarachchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0337-0395>),\n  Petra Kunhert [aut] (ORCID: <https://orcid.org/0000-0001-9070-0091>),\n  Andrew Zammit-Mangion [ctb] (ORCID:\n    <https://orcid.org/0000-0002-4164-6866>)",
    "url": "https://sevvandi.github.io/stxplore/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stxplore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stxplore Exploration of Spatio-Temporal Data A set of statistical tools for spatio-temporal data exploration.     \n    Includes simple plotting functions, covariance calculations and computations \n    similar to principal component analysis for spatio-temporal data. Can use \n    both dataframes and stars objects for all plots and computations. For more \n    details refer 'Spatio-Temporal Statistics with R' (Christopher K. Wikle, \n    Andrew Zammit-Mangion, Noel Cressie, 2019, ISBN:9781138711136).  "
  },
  {
    "id": 21583,
    "package_name": "sufficientForecasting",
    "title": "Sufficient Forecasting using Factor Models",
    "description": "The sufficient forecasting (SF) method is implemented by this package for a single time series forecasting using many predictors and a possibly nonlinear forecasting function. Assuming that the predictors are driven by some latent factors, the SF first conducts factor analysis and then performs sufficient dimension reduction on the estimated factors to derive predictive indices for forecasting. The package implements several dimension reduction approaches, including principal components (PC), sliced inverse regression (SIR), and directional regression (DR). Methods for dimension reduction are as described in: Fan, J., Xue, L. and Yao, J. (2017) <doi:10.1016/j.jeconom.2017.08.009>, Luo, W., Xue, L., Yao, J. and Yu, X. (2022) <doi:10.1093/biomet/asab037> and Yu, X., Yao, J. and Xue, L. (2022) <doi:10.1080/07350015.2020.1813589>.",
    "version": "0.1.0",
    "maintainer": "Jing Fu <jingfu991224@outlook.com>",
    "author": "Jianqing Fan [aut],\n  Jing Fu [aut, cre],\n  Wei Luo [aut],\n  Lingzhou Xue [aut],\n  Jiawei Yao [aut],\n  Xiufan Yu [aut]",
    "url": "https://github.com/JingFu1224/sufficientForecasting",
    "bug_reports": "https://github.com/JingFu1224/sufficientForecasting/issues",
    "repository": "https://cran.r-project.org/package=sufficientForecasting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sufficientForecasting Sufficient Forecasting using Factor Models The sufficient forecasting (SF) method is implemented by this package for a single time series forecasting using many predictors and a possibly nonlinear forecasting function. Assuming that the predictors are driven by some latent factors, the SF first conducts factor analysis and then performs sufficient dimension reduction on the estimated factors to derive predictive indices for forecasting. The package implements several dimension reduction approaches, including principal components (PC), sliced inverse regression (SIR), and directional regression (DR). Methods for dimension reduction are as described in: Fan, J., Xue, L. and Yao, J. (2017) <doi:10.1016/j.jeconom.2017.08.009>, Luo, W., Xue, L., Yao, J. and Yu, X. (2022) <doi:10.1093/biomet/asab037> and Yu, X., Yao, J. and Xue, L. (2022) <doi:10.1080/07350015.2020.1813589>.  "
  },
  {
    "id": 21585,
    "package_name": "sugarglider",
    "title": "Create Glyph-Maps of Spatiotemporal Data",
    "description": "Provides 'ggplot2' extensions to construct glyph-maps for visualizing seasonality in spatiotemporal data. See the Journal of Statistical Software reference: Zhang, H. S., Cook, D., Laa, U., Langren\u00e9, N., & Men\u00e9ndez, P. (2024) <doi:10.18637/jss.v110.i07>. The manuscript for this package is currently under preparation and can be found on GitHub at <https://github.com/maliny12/paper-sugarglider>. ",
    "version": "1.0.3",
    "maintainer": "Maliny Po <malinypo12@gmail.com>",
    "author": "Maliny Po [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0008-4686-6631>),\n  S. Nathan Yang [aut] (ORCID: <https://orcid.org/0009-0002-9985-1042>),\n  H. Sherry Zhang [ctb] (ORCID: <https://orcid.org/0000-0002-7122-1463>),\n  Dianne Cook [ctb] (ORCID: <https://orcid.org/0000-0002-3813-7155>)",
    "url": "https://maliny12.github.io/sugarglider/,\nhttps://github.com/maliny12/sugarglider",
    "bug_reports": "https://github.com/maliny12/sugarglider/issues",
    "repository": "https://cran.r-project.org/package=sugarglider",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sugarglider Create Glyph-Maps of Spatiotemporal Data Provides 'ggplot2' extensions to construct glyph-maps for visualizing seasonality in spatiotemporal data. See the Journal of Statistical Software reference: Zhang, H. S., Cook, D., Laa, U., Langren\u00e9, N., & Men\u00e9ndez, P. (2024) <doi:10.18637/jss.v110.i07>. The manuscript for this package is currently under preparation and can be found on GitHub at <https://github.com/maliny12/paper-sugarglider>.   "
  },
  {
    "id": 21587,
    "package_name": "sugrrants",
    "title": "Supporting Graphs for Analysing Time Series",
    "description": "Provides 'ggplot2' graphics for analysing time\n    series data. It aims to fit into the 'tidyverse' and grammar of\n    graphics framework for handling temporal data.",
    "version": "0.2.9",
    "maintainer": "Earo Wang <earo.wang@gmail.com>",
    "author": "Earo Wang [aut, cre] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Di Cook [aut, ths] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Rob Hyndman [aut, ths] (ORCID: <https://orcid.org/0000-0002-2140-5352>)",
    "url": "https://pkg.earo.me/sugrrants/",
    "bug_reports": "https://github.com/earowang/sugrrants/issues",
    "repository": "https://cran.r-project.org/package=sugrrants",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sugrrants Supporting Graphs for Analysing Time Series Provides 'ggplot2' graphics for analysing time\n    series data. It aims to fit into the 'tidyverse' and grammar of\n    graphics framework for handling temporal data.  "
  },
  {
    "id": 21653,
    "package_name": "surveil",
    "title": "Time Series Models for Disease Surveillance",
    "description": "Fits time trend models for routine disease surveillance tasks and returns probability distributions for a variety of quantities of interest, including age-standardized rates, period and cumulative percent change, and measures of health inequality. The models are appropriate for count data such as disease incidence and mortality data, employing a Poisson or binomial likelihood and the first-difference (random-walk) prior for unknown risk. Optionally add a covariance matrix for multiple, correlated time series models. Inference is completed using Markov chain Monte Carlo via the Stan modeling language. References: Donegan, Hughes, and Lee (2022) <doi:10.2196/34589>; Stan Development Team (2021) <https://mc-stan.org>; Theil (1972, ISBN:0-444-10378-3).",
    "version": "0.3.0",
    "maintainer": "Connor Donegan <connor.donegan@gmail.com>",
    "author": "Connor Donegan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9698-5443>)",
    "url": "https://connordonegan.github.io/surveil/,\nhttps://github.com/ConnorDonegan/surveil/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=surveil",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveil Time Series Models for Disease Surveillance Fits time trend models for routine disease surveillance tasks and returns probability distributions for a variety of quantities of interest, including age-standardized rates, period and cumulative percent change, and measures of health inequality. The models are appropriate for count data such as disease incidence and mortality data, employing a Poisson or binomial likelihood and the first-difference (random-walk) prior for unknown risk. Optionally add a covariance matrix for multiple, correlated time series models. Inference is completed using Markov chain Monte Carlo via the Stan modeling language. References: Donegan, Hughes, and Lee (2022) <doi:10.2196/34589>; Stan Development Team (2021) <https://mc-stan.org>; Theil (1972, ISBN:0-444-10378-3).  "
  },
  {
    "id": 21710,
    "package_name": "svines",
    "title": "Stationary Vine Copula Models",
    "description": "Provides functionality to fit and simulate from stationary vine \n  copula models for time series, see Nagler et al. (2022) \n  <doi:10.1016/j.jeconom.2021.11.015>.",
    "version": "0.2.7",
    "maintainer": "Thomas Nagler <mail@tnagler.com>",
    "author": "Thomas Nagler [aut, cre]",
    "url": "https://github.com/tnagler/svines",
    "bug_reports": "https://github.com/tnagler/svines/issues",
    "repository": "https://cran.r-project.org/package=svines",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svines Stationary Vine Copula Models Provides functionality to fit and simulate from stationary vine \n  copula models for time series, see Nagler et al. (2022) \n  <doi:10.1016/j.jeconom.2021.11.015>.  "
  },
  {
    "id": 21756,
    "package_name": "sym.arma",
    "title": "Autoregressive and Moving Average Symmetric Models",
    "description": "Functions for fitting the Autoregressive and Moving Average Symmetric Model for univariate time series introduced by Maior and Cysneiros (2018), <doi:10.1007/s00362-016-0753-z>. Fitting method: conditional maximum likelihood estimation. For details see: Wei (2006), Time Series Analysis: Univariate and Multivariate Methods, Section 7.2.",
    "version": "1.0",
    "maintainer": "Vinicius Quintas Souto Maior <vinicius@de.ufpe.br>",
    "author": "Vinicius Quintas Souto Maior [aut,cre,cph] and Francisco Jose A Cysneiros [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sym.arma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sym.arma Autoregressive and Moving Average Symmetric Models Functions for fitting the Autoregressive and Moving Average Symmetric Model for univariate time series introduced by Maior and Cysneiros (2018), <doi:10.1007/s00362-016-0753-z>. Fitting method: conditional maximum likelihood estimation. For details see: Wei (2006), Time Series Analysis: Univariate and Multivariate Methods, Section 7.2.  "
  },
  {
    "id": 21769,
    "package_name": "synchrony",
    "title": "Methods for Computing Spatial, Temporal, and Spatiotemporal\nStatistics",
    "description": "Methods for computing spatial, temporal, and spatiotemporal\n    statistics as described in Gouhier and Guichard (2014) \n    <doi:10.1111/2041-210X.12188>. These methods include \n    empirical univariate, bivariate and multivariate\n    variograms; fitting variogram models; phase locking and synchrony analysis;\n    generating autocorrelated and cross-correlated matrices.",
    "version": "0.3.8",
    "maintainer": "Tarik C. Gouhier <tarik.gouhier@gmail.com>",
    "author": "Tarik C. Gouhier",
    "url": "http://github.com/tgouhier/synchrony",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=synchrony",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "synchrony Methods for Computing Spatial, Temporal, and Spatiotemporal\nStatistics Methods for computing spatial, temporal, and spatiotemporal\n    statistics as described in Gouhier and Guichard (2014) \n    <doi:10.1111/2041-210X.12188>. These methods include \n    empirical univariate, bivariate and multivariate\n    variograms; fitting variogram models; phase locking and synchrony analysis;\n    generating autocorrelated and cross-correlated matrices.  "
  },
  {
    "id": 21774,
    "package_name": "synthesis",
    "title": "Generate Synthetic Data from Statistical Models",
    "description": "Generate synthetic time series from commonly used statistical models, including linear, nonlinear and chaotic systems. Applications to testing methods can be found in Jiang, Z., Sharma, A., & Johnson, F. (2019) <doi:10.1016/j.advwatres.2019.103430> and Jiang, Z., Sharma, A., & Johnson, F. (2020) <doi:10.1029/2019WR026962> associated with an open-source tool by Jiang, Z., Rashid, M. M., Johnson, F., & Sharma, A. (2020) <doi:10.1016/j.envsoft.2020.104907>.",
    "version": "1.2.5",
    "maintainer": "Ze Jiang <ze.jiang@unsw.edu.au>",
    "author": "Ze Jiang [aut, cre] (ORCID: <https://orcid.org/0000-0002-3472-0829>)",
    "url": "https://github.com/zejiang-unsw/synthesis#readme",
    "bug_reports": "https://github.com/zejiang-unsw/synthesis/issues",
    "repository": "https://cran.r-project.org/package=synthesis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "synthesis Generate Synthetic Data from Statistical Models Generate synthetic time series from commonly used statistical models, including linear, nonlinear and chaotic systems. Applications to testing methods can be found in Jiang, Z., Sharma, A., & Johnson, F. (2019) <doi:10.1016/j.advwatres.2019.103430> and Jiang, Z., Sharma, A., & Johnson, F. (2020) <doi:10.1029/2019WR026962> associated with an open-source tool by Jiang, Z., Rashid, M. M., Johnson, F., & Sharma, A. (2020) <doi:10.1016/j.envsoft.2020.104907>.  "
  },
  {
    "id": 21776,
    "package_name": "synthesizer",
    "title": "Fast, Robust, and High-Quality Synthetic Data Generation with a\nTuneable Privacy-Utility Trade-Off",
    "description": "Synthesize numeric, categorical, mixed and time series data. Data \n    circumstances including mixed (or zero-inflated) distributions and missing\n    data patterns are reproduced in the synthetic data. A single parameter allows\n    balancing between high-quality synthetic data that represents correlations of\n    the original data and lower quality but more privacy safe synthetic data\n    without correlations. Tuning can be done per variable or for the whole\n    dataset.",
    "version": "0.6.0",
    "maintainer": "Mark van der Loo <mark.vanderloo@gmail.com>",
    "author": "Mark van der Loo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9807-4686>)",
    "url": "https://github.com/markvanderloo/synthesizer",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=synthesizer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "synthesizer Fast, Robust, and High-Quality Synthetic Data Generation with a\nTuneable Privacy-Utility Trade-Off Synthesize numeric, categorical, mixed and time series data. Data \n    circumstances including mixed (or zero-inflated) distributions and missing\n    data patterns are reproduced in the synthetic data. A single parameter allows\n    balancing between high-quality synthetic data that represents correlations of\n    the original data and lower quality but more privacy safe synthetic data\n    without correlations. Tuning can be done per variable or for the whole\n    dataset.  "
  },
  {
    "id": 21788,
    "package_name": "tEDM",
    "title": "Temporal Empirical Dynamic Modeling",
    "description": "Inferring causation from time series data through empirical dynamic modeling (EDM), with methods such as convergent cross mapping from Sugihara et al. (2012) <doi:10.1126/science.1227079>, partial cross mapping as outlined in Leng et al. (2020) <doi:10.1038/s41467-020-16238-0>, and cross mapping cardinality as described in Tao et al. (2023) <doi:10.1016/j.fmre.2023.01.007>.",
    "version": "1.1",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "author": "Wenbo Lv [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0002-6003-3800>)",
    "url": "https://stscl.github.io/tEDM/, https://github.com/stscl/tEDM",
    "bug_reports": "https://github.com/stscl/tEDM/issues",
    "repository": "https://cran.r-project.org/package=tEDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tEDM Temporal Empirical Dynamic Modeling Inferring causation from time series data through empirical dynamic modeling (EDM), with methods such as convergent cross mapping from Sugihara et al. (2012) <doi:10.1126/science.1227079>, partial cross mapping as outlined in Leng et al. (2020) <doi:10.1038/s41467-020-16238-0>, and cross mapping cardinality as described in Tao et al. (2023) <doi:10.1016/j.fmre.2023.01.007>.  "
  },
  {
    "id": 21818,
    "package_name": "tabs",
    "title": "Temporal Altitudinal Biogeographic Shifts",
    "description": "A standardized workflow to reconstruct spatial configurations of altitude-bounded biogeographic systems over time. For example, 'tabs' can model how island archipelagos expand or contract with changing sea levels or how alpine biomes shift in response to tree line movements. It provides functionality to account for various geophysical processes such as crustal deformation and other tectonic changes, allowing for a more accurate representation of biogeographic system dynamics. For more information see De Groeve et al. (2025) <doi:10.3897/arphapreprints.e151900>.",
    "version": "0.1.1",
    "maintainer": "Johannes De Groeve <j.degroeve@uva.nl>",
    "author": "Johannes De Groeve [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1274-3237>),\n  Sietze Norder [aut] (ORCID: <https://orcid.org/0000-0003-4692-4543>),\n  Eline Sterre Rentier [aut] (ORCID:\n    <https://orcid.org/0000-0001-6234-1300>),\n  Suzette Flantua [ctb] (ORCID: <https://orcid.org/0000-0001-6526-3037>),\n  Kenneth Rijsdijk [ctb] (ORCID: <https://orcid.org/0000-0002-0943-2577>)",
    "url": "https://uva_ibed_piac.gitlab.io/tabs/",
    "bug_reports": "https://gitlab.com/uva_ibed_piac/tabs/-/issues",
    "repository": "https://cran.r-project.org/package=tabs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tabs Temporal Altitudinal Biogeographic Shifts A standardized workflow to reconstruct spatial configurations of altitude-bounded biogeographic systems over time. For example, 'tabs' can model how island archipelagos expand or contract with changing sea levels or how alpine biomes shift in response to tree line movements. It provides functionality to account for various geophysical processes such as crustal deformation and other tectonic changes, allowing for a more accurate representation of biogeographic system dynamics. For more information see De Groeve et al. (2025) <doi:10.3897/arphapreprints.e151900>.  "
  },
  {
    "id": 21833,
    "package_name": "tagtools",
    "title": "Work with Data from High-Resolution Biologging Tags",
    "description": "High-resolution movement-sensor tags typically include accelerometers \n    to measure body posture and sudden movements or changes in speed, \n    magnetometers to measure direction of travel, and pressure sensors\n    to measure dive depth in aquatic or marine animals. The sensors in these tags usually sample many times per second. Some tags include sensors for speed, turning rate (gyroscopes), and sound. This package provides software tools to facilitate calibration, processing, and analysis of such data. Tools are provided for: data import/export; \n    calibration (from raw data to calibrated data in scientific units); \n    visualization (for example, multi-panel time-series plots); \n    data processing (such as event detection, calculation of derived metrics like jerk and \n    dynamic acceleration, dive detection, and dive parameter calculation); and statistical analysis (for example, track reconstruction, a rotation test, and Mahalanobis distance analysis).",
    "version": "0.2.0",
    "maintainer": "Stacy DeRuiter <stacy.deruiter@calvin.edu>",
    "author": "Stacy DeRuiter [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0571-0306>),\n  Mark Johnson [aut, cph],\n  David Sweeney [aut],\n  Ye Joo McNamara-Oh [aut],\n  Samuel Fynewever [aut],\n  (Oghenkevwe) Racheal Tejevbo [aut],\n  Tiago Marques [aut],\n  Yuqian Wang [aut],\n  (Oghenesuvwe) Su Ogedegbe [aut]",
    "url": "<https://animaltags.org>,\n<https://animaltags.github.io/tagtools_r/index.html>",
    "bug_reports": "https://github.com/animaltags/tagtools_r/issues",
    "repository": "https://cran.r-project.org/package=tagtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tagtools Work with Data from High-Resolution Biologging Tags High-resolution movement-sensor tags typically include accelerometers \n    to measure body posture and sudden movements or changes in speed, \n    magnetometers to measure direction of travel, and pressure sensors\n    to measure dive depth in aquatic or marine animals. The sensors in these tags usually sample many times per second. Some tags include sensors for speed, turning rate (gyroscopes), and sound. This package provides software tools to facilitate calibration, processing, and analysis of such data. Tools are provided for: data import/export; \n    calibration (from raw data to calibrated data in scientific units); \n    visualization (for example, multi-panel time-series plots); \n    data processing (such as event detection, calculation of derived metrics like jerk and \n    dynamic acceleration, dive detection, and dive parameter calculation); and statistical analysis (for example, track reconstruction, a rotation test, and Mahalanobis distance analysis).  "
  },
  {
    "id": 21877,
    "package_name": "tcpl",
    "title": "ToxCast Data Analysis Pipeline",
    "description": "The ToxCast Data Analysis Pipeline ('tcpl') is an R package that manages, curve-fits, plots, and stores ToxCast data to populate its linked MySQL database, 'invitrodb'. The package was developed for the chemical screening data curated by the US EPA's Toxicity Forecaster (ToxCast) program, but 'tcpl' can be used to support diverse chemical screening efforts.",
    "version": "3.3.1",
    "maintainer": "Madison Feshuk <feshuk.madison@epa.gov>",
    "author": "Dayne L Filer [aut],\n  Jason Brown [ctb] (ORCID: <https://orcid.org/0009-0000-2294-641X>),\n  Madison Feshuk [cre] (ORCID: <https://orcid.org/0000-0002-1390-6405>),\n  Carter Thunes [ctb],\n  Sarah E Davidson-Fritz [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2891-9380>),\n  Kelly Carstens [ctb] (ORCID: <https://orcid.org/0000-0002-1746-5379>),\n  Elizabeth Gilson [ctb],\n  Lindsay Knupp [ctb],\n  Lori Kolaczkowski [ctb],\n  Ashley Ko [ctb],\n  Zhihui Zhao [ctb],\n  Kurt Dunham [ctb],\n  Todd Zurlinden [ctb] (ORCID: <https://orcid.org/0000-0003-1372-3913>),\n  Parth Kothiya [ctb],\n  Woodrow R Setzer [ctb],\n  Matthew T Martin [ctb, ths],\n  Richard S Judson [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0002-2348-9633>),\n  Katie Paul Friedman [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2710-1691>)",
    "url": "https://github.com/USEPA/CompTox-ToxCast-tcpl,\nhttps://www.epa.gov/comptox-tools/toxicity-forecasting-toxcast",
    "bug_reports": "https://github.com/USEPA/CompTox-ToxCast-tcpl/issues",
    "repository": "https://cran.r-project.org/package=tcpl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tcpl ToxCast Data Analysis Pipeline The ToxCast Data Analysis Pipeline ('tcpl') is an R package that manages, curve-fits, plots, and stores ToxCast data to populate its linked MySQL database, 'invitrodb'. The package was developed for the chemical screening data curated by the US EPA's Toxicity Forecaster (ToxCast) program, but 'tcpl' can be used to support diverse chemical screening efforts.  "
  },
  {
    "id": 21885,
    "package_name": "tdata",
    "title": "Prepare Your Time-Series Data for Further Analysis",
    "description": "Provides a set of tools for managing time-series data,\n    with a particular emphasis on defining various frequency types such\n    as daily and weekly. It also includes functionality for converting\n    data between different frequencies.",
    "version": "0.3.0",
    "maintainer": "Ramin Mojab <rmojab63@gmail.com>",
    "author": "Ramin Mojab [aut, cre]",
    "url": "https://github.com/rmojab63/LDT",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tdata Prepare Your Time-Series Data for Further Analysis Provides a set of tools for managing time-series data,\n    with a particular emphasis on defining various frequency types such\n    as daily and weekly. It also includes functionality for converting\n    data between different frequencies.  "
  },
  {
    "id": 21914,
    "package_name": "tempR",
    "title": "Temporal Sensory Data Analysis",
    "description": "Analysis and visualization of data from temporal sensory methods, including for temporal check-all-that-apply (TCATA) and temporal dominance of sensations (TDS). Methods are mainly from manuscripts by Castura, J.C., Ant\u00fanez, L., Gim\u00e9nez, A., and Ares, G. (2016) <doi:10.1016/j.foodqual.2015.06.017>, Castura, Baker, and Ross (2016) <doi:10.1016/j.foodqual.2016.06.011>, and Pineau et al. (2009) <doi:10.1016/j.foodqual.2009.04.005>.",
    "version": "0.10.1.1",
    "maintainer": "J.C. Castura <jcastura@compusense.com>",
    "author": "J.C. Castura [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-1640-833X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tempR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tempR Temporal Sensory Data Analysis Analysis and visualization of data from temporal sensory methods, including for temporal check-all-that-apply (TCATA) and temporal dominance of sensations (TDS). Methods are mainly from manuscripts by Castura, J.C., Ant\u00fanez, L., Gim\u00e9nez, A., and Ares, G. (2016) <doi:10.1016/j.foodqual.2015.06.017>, Castura, Baker, and Ross (2016) <doi:10.1016/j.foodqual.2016.06.011>, and Pineau et al. (2009) <doi:10.1016/j.foodqual.2009.04.005>.  "
  },
  {
    "id": 21915,
    "package_name": "tempdisagg",
    "title": "Methods for Temporal Disaggregation and Interpolation of Time\nSeries",
    "description": "Temporal disaggregation methods are used to disaggregate and\n    interpolate a low frequency time series to a higher frequency series, where\n    either the sum, the mean, the first or the last value of the resulting\n    high frequency series is consistent with the low frequency series. Temporal\n    disaggregation can be performed with or without one or more high frequency\n    indicator series. Contains the methods of Chow-Lin, Santos-Silva-Cardoso,\n    Fernandez, Litterman, Denton and Denton-Cholette, summarized in Sax and\n    Steiner (2013) <doi:10.32614/RJ-2013-028>. Supports most R time series\n    classes.",
    "version": "1.2.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7192-7044>),\n  Peter Steiner [aut],\n  Tommaso Di Fonzo [ctb],\n  Nelson Stevens [ctb],\n  Tobias Schieferdecker [ctb]",
    "url": "https://cynkra.github.io/tempdisagg/,\nhttps://journal.r-project.org/articles/RJ-2013-028/",
    "bug_reports": "https://github.com/cynkra/tempdisagg/issues",
    "repository": "https://cran.r-project.org/package=tempdisagg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tempdisagg Methods for Temporal Disaggregation and Interpolation of Time\nSeries Temporal disaggregation methods are used to disaggregate and\n    interpolate a low frequency time series to a higher frequency series, where\n    either the sum, the mean, the first or the last value of the resulting\n    high frequency series is consistent with the low frequency series. Temporal\n    disaggregation can be performed with or without one or more high frequency\n    indicator series. Contains the methods of Chow-Lin, Santos-Silva-Cardoso,\n    Fernandez, Litterman, Denton and Denton-Cholette, summarized in Sax and\n    Steiner (2013) <doi:10.32614/RJ-2013-028>. Supports most R time series\n    classes.  "
  },
  {
    "id": 21916,
    "package_name": "temper",
    "title": "Temporal Encoder-Masked Probabilistic Ensemble Regressor",
    "description": "Implements a probabilistic ensemble time-series forecaster that combines an auto-encoder with a neural decision forest whose split variables are learned through a differentiable feature-mask layer. Functions are written with 'torch' tensors and provide CRPS (Continuous Ranked Probability Scores) training plus mixture-distribution post-processing.",
    "version": "1.1.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/temper",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=temper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "temper Temporal Encoder-Masked Probabilistic Ensemble Regressor Implements a probabilistic ensemble time-series forecaster that combines an auto-encoder with a neural decision forest whose split variables are learned through a differentiable feature-mask layer. Functions are written with 'torch' tensors and provide CRPS (Continuous Ranked Probability Scores) training plus mixture-distribution post-processing.  "
  },
  {
    "id": 21921,
    "package_name": "tempted",
    "title": "Temporal Tensor Decomposition, a Dimensionality Reduction Tool\nfor Longitudinal Multivariate Data",
    "description": "\n    TEMPoral TEnsor Decomposition (TEMPTED), is a dimension reduction method for multivariate longitudinal data with varying temporal sampling. It formats the data into a temporal tensor and decomposes it into a summation of low-dimensional components, each consisting of a subject loading vector, a feature loading vector, and a continuous temporal loading function. These loadings provide a low-dimensional representation of subjects or samples and can be used to identify features associated with clusters of subjects or samples. TEMPTED provides the flexibility of allowing subjects to have different temporal sampling, so time points do not need to be binned, and missing time points do not need to be imputed.",
    "version": "0.1.1",
    "maintainer": "Pixu Shi <pixu.shi@duke.edu>",
    "author": "Pixu Shi",
    "url": "https://github.com/pixushi/tempted",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tempted",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tempted Temporal Tensor Decomposition, a Dimensionality Reduction Tool\nfor Longitudinal Multivariate Data \n    TEMPoral TEnsor Decomposition (TEMPTED), is a dimension reduction method for multivariate longitudinal data with varying temporal sampling. It formats the data into a temporal tensor and decomposes it into a summation of low-dimensional components, each consisting of a subject loading vector, a feature loading vector, and a continuous temporal loading function. These loadings provide a low-dimensional representation of subjects or samples and can be used to identify features associated with clusters of subjects or samples. TEMPTED provides the flexibility of allowing subjects to have different temporal sampling, so time points do not need to be binned, and missing time points do not need to be imputed.  "
  },
  {
    "id": 21923,
    "package_name": "tenm",
    "title": "Temporal Ecological Niche Models",
    "description": "Implements methods and functions to calibrate \n  time-specific niche models (multi-temporal calibration), letting users \n  execute a strict calibration and selection process of niche models based \n  on ellipsoids, as well as functions to project the potential distribution in \n  the present and in global change  scenarios.The 'tenm' package has functions\n  to recover information that may be lost or overlooked while applying a data \n  curation protocol. This curation involves preserving occurrences that may \n  appear spatially redundant (occurring in the same pixel) but originate from \n  different time periods. A novel aspect of this package is that it might \n  reconstruct the fundamental niche more accurately than mono-calibrated \n  approaches. The theoretical background of the package can be found in \n  Peterson et al. (2011)<doi:10.5860/CHOICE.49-6266>.",
    "version": "0.5.1",
    "maintainer": "Luis Osorio-Olvera <luismurao@gmail.com>",
    "author": "Luis Osorio-Olvera [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0701-5398>),\n  Miguel Hern\u00e1ndez [aut] (ORCID: <https://orcid.org/0000-0002-6086-3460>),\n  Rusby G. Contreras-D\u00edaz [aut] (ORCID:\n    <https://orcid.org/0000-0002-0569-8984>),\n  Xavier Chiappa-Carrara [aut] (ORCID:\n    <https://orcid.org/0000-0002-1708-2095>),\n  Fernanda Rosales-Ramos [aut] (ORCID:\n    <https://orcid.org/0009-0004-7805-4735>),\n  Mariana Mungu\u00eda-Carrara [aut] (ORCID:\n    <https://orcid.org/0000-0003-3514-3397>),\n  Oliver L\u00f3pez-Corona [aut] (ORCID:\n    <https://orcid.org/0000-0002-2926-7791>),\n  Townsend Peterson [ctb] (ORCID:\n    <https://orcid.org/0000-0003-0243-2379>),\n  Jorge Sober\u00f3n [ctb] (ORCID: <https://orcid.org/0000-0003-2160-4148>)",
    "url": "https://luismurao.github.io/tenm/",
    "bug_reports": "https://github.com/luismurao/tenm/issues",
    "repository": "https://cran.r-project.org/package=tenm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tenm Temporal Ecological Niche Models Implements methods and functions to calibrate \n  time-specific niche models (multi-temporal calibration), letting users \n  execute a strict calibration and selection process of niche models based \n  on ellipsoids, as well as functions to project the potential distribution in \n  the present and in global change  scenarios.The 'tenm' package has functions\n  to recover information that may be lost or overlooked while applying a data \n  curation protocol. This curation involves preserving occurrences that may \n  appear spatially redundant (occurring in the same pixel) but originate from \n  different time periods. A novel aspect of this package is that it might \n  reconstruct the fundamental niche more accurately than mono-calibrated \n  approaches. The theoretical background of the package can be found in \n  Peterson et al. (2011)<doi:10.5860/CHOICE.49-6266>.  "
  },
  {
    "id": 21930,
    "package_name": "tensorTS",
    "title": "Factor and Autoregressive Models for Tensor Time Series",
    "description": "Factor and autoregressive models for matrix and tensor valued time series. We provide functions for estimation, simulation and prediction. The models are discussed in \n    Li et al (2021) <doi:10.48550/arXiv.2110.00928>, Chen et al (2020) <DOI:10.1080/01621459.2021.1912757>, \n    Chen et al (2020) <DOI:10.1016/j.jeconom.2020.07.015>, and Xiao et al (2020) <doi:10.48550/arXiv.2006.02611>.",
    "version": "1.0.2",
    "maintainer": "Zebang Li <zl326@stat.rutgers.edu>",
    "author": "Zebang Li [aut, cre],\n  Ruofan Yu [aut],\n  Rong Chen [aut],\n  Yuefeng Han [aut],\n  Han Xiao [aut],\n  Dan Yang [aut]",
    "url": "https://github.com/zebang/tensorTS",
    "bug_reports": "https://github.com/ZeBang/tensorTS/issues",
    "repository": "https://cran.r-project.org/package=tensorTS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tensorTS Factor and Autoregressive Models for Tensor Time Series Factor and autoregressive models for matrix and tensor valued time series. We provide functions for estimation, simulation and prediction. The models are discussed in \n    Li et al (2021) <doi:10.48550/arXiv.2110.00928>, Chen et al (2020) <DOI:10.1080/01621459.2021.1912757>, \n    Chen et al (2020) <DOI:10.1016/j.jeconom.2020.07.015>, and Xiao et al (2020) <doi:10.48550/arXiv.2006.02611>.  "
  },
  {
    "id": 21935,
    "package_name": "tergmLite",
    "title": "Fast Simulation of Simple Temporal Exponential Random Graph\nModels",
    "description": "Provides functions for the computationally efficient simulation of \n    dynamic networks estimated with the statistical framework of temporal \n    exponential random graph models, implemented in the 'tergm' package.",
    "version": "2.6.1",
    "maintainer": "Samuel M. Jenness <samuel.m.jenness@emory.edu>",
    "author": "Samuel M. Jenness [aut, cre],\n  Chad Klumb [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tergmLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tergmLite Fast Simulation of Simple Temporal Exponential Random Graph\nModels Provides functions for the computationally efficient simulation of \n    dynamic networks estimated with the statistical framework of temporal \n    exponential random graph models, implemented in the 'tergm' package.  "
  },
  {
    "id": 21942,
    "package_name": "ternvis",
    "title": "Visualisation, Verification and Calibration of Ternary\nProbabilistic Forecasts",
    "description": "A suite of functions for visualising ternary probabilistic forecasts, as discussed in the paper by Jupp (2012) <doi:10.1098/rsta.2011.0350>.",
    "version": "1.3",
    "maintainer": "Tim Jupp <T.E.Jupp@exeter.ac.uk>",
    "author": "Tim Jupp [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ternvis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ternvis Visualisation, Verification and Calibration of Ternary\nProbabilistic Forecasts A suite of functions for visualising ternary probabilistic forecasts, as discussed in the paper by Jupp (2012) <doi:10.1098/rsta.2011.0350>.  "
  },
  {
    "id": 21950,
    "package_name": "testcorr",
    "title": "Testing Zero Correlation",
    "description": "Computes the test statistics for examining the significance of autocorrelation in univariate time series, cross-correlation in bivariate time series, Pearson correlations in multivariate series and test statistics for i.i.d. property of univariate series given in Dalla, Giraitis and Phillips (2022), <https://www.cambridge.org/core/journals/econometric-theory/article/abs/robust-tests-for-white-noise-and-crosscorrelation/4D77C12C52433F4C6735E584C779403A>, <https://elischolar.library.yale.edu/cowles-discussion-paper-series/57/>.",
    "version": "0.3.0",
    "maintainer": "Violetta Dalla <vidalla@econ.uoa.gr>",
    "author": "Violetta Dalla [aut, cre],\n  Liudas Giraitis [aut],\n  Peter C. B. Phillips [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=testcorr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testcorr Testing Zero Correlation Computes the test statistics for examining the significance of autocorrelation in univariate time series, cross-correlation in bivariate time series, Pearson correlations in multivariate series and test statistics for i.i.d. property of univariate series given in Dalla, Giraitis and Phillips (2022), <https://www.cambridge.org/core/journals/econometric-theory/article/abs/robust-tests-for-white-noise-and-crosscorrelation/4D77C12C52433F4C6735E584C779403A>, <https://elischolar.library.yale.edu/cowles-discussion-paper-series/57/>.  "
  },
  {
    "id": 22002,
    "package_name": "tfarima",
    "title": "Transfer Function and ARIMA Models",
    "description": "Build customized transfer function and ARIMA models with multiple operators \n    and parameter restrictions. Provides tools for model identification, estimation \n    using exact or conditional maximum likelihood, diagnostic checking, automatic outlier \n    detection, calendar effects, forecasting, and seasonal adjustment. The new version \n    also supports unobserved component ARIMA model specification and estimation \n    for structural time series analysis.",
    "version": "0.4.1",
    "maintainer": "Jose L. Gallego <jose.gallego@unican.es>",
    "author": "Jose L. Gallego [aut, cre]",
    "url": "https://github.com/gallegoj/tfarima",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tfarima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tfarima Transfer Function and ARIMA Models Build customized transfer function and ARIMA models with multiple operators \n    and parameter restrictions. Provides tools for model identification, estimation \n    using exact or conditional maximum likelihood, diagnostic checking, automatic outlier \n    detection, calendar effects, forecasting, and seasonal adjustment. The new version \n    also supports unobserved component ARIMA model specification and estimation \n    for structural time series analysis.  "
  },
  {
    "id": 22020,
    "package_name": "theft",
    "title": "Tools for Handling Extraction of Features from Time Series",
    "description": "Consolidates and calculates different sets of time-series features from multiple\n    'R' and 'Python' packages including 'Rcatch22' Henderson, T. (2021) <doi:10.5281/zenodo.5546815>,\n    'feasts' O'Hara-Wild, M., Hyndman, R., and Wang, E. (2021) <https://CRAN.R-project.org/package=feasts>,\n    'tsfeatures' Hyndman, R., Kang, Y., Montero-Manso, P., Talagala, T., Wang, E., Yang, Y., and O'Hara-Wild, M. (2020)\n    <https://CRAN.R-project.org/package=tsfeatures>, 'tsfresh' Christ, M., Braun, N., Neuffer, J.,\n    and Kempa-Liehr A.W. (2018) <doi:10.1016/j.neucom.2018.03.067>, 'TSFEL' Barandas, M., et al. (2020)\n    <doi:10.1016/j.softx.2020.100456>, and 'Kats' Facebook Infrastructure Data Science (2021)\n    <https://facebookresearch.github.io/Kats/>.",
    "version": "0.8.2",
    "maintainer": "Trent Henderson <then6675@uni.sydney.edu.au>",
    "author": "Trent Henderson [cre, aut],\n  Annie Bryant [ctb]",
    "url": "https://hendersontrent.github.io/theft/",
    "bug_reports": "https://github.com/hendersontrent/theft/issues",
    "repository": "https://cran.r-project.org/package=theft",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "theft Tools for Handling Extraction of Features from Time Series Consolidates and calculates different sets of time-series features from multiple\n    'R' and 'Python' packages including 'Rcatch22' Henderson, T. (2021) <doi:10.5281/zenodo.5546815>,\n    'feasts' O'Hara-Wild, M., Hyndman, R., and Wang, E. (2021) <https://CRAN.R-project.org/package=feasts>,\n    'tsfeatures' Hyndman, R., Kang, Y., Montero-Manso, P., Talagala, T., Wang, E., Yang, Y., and O'Hara-Wild, M. (2020)\n    <https://CRAN.R-project.org/package=tsfeatures>, 'tsfresh' Christ, M., Braun, N., Neuffer, J.,\n    and Kempa-Liehr A.W. (2018) <doi:10.1016/j.neucom.2018.03.067>, 'TSFEL' Barandas, M., et al. (2020)\n    <doi:10.1016/j.softx.2020.100456>, and 'Kats' Facebook Infrastructure Data Science (2021)\n    <https://facebookresearch.github.io/Kats/>.  "
  },
  {
    "id": 22021,
    "package_name": "theftdlc",
    "title": "Analyse and Interpret Time Series Features",
    "description": "Provides a suite of functions for analysing, interpreting, and visualising\n    time-series features calculated from different feature sets from the 'theft' package. \n    Implements statistical learning methodologies described in Henderson, T.,  \n    Bryant, A., and Fulcher, B. (2023) <doi:10.48550/arXiv.2303.17809>.",
    "version": "0.2.1",
    "maintainer": "Trent Henderson <then6675@uni.sydney.edu.au>",
    "author": "Trent Henderson [cre, aut]",
    "url": "https://hendersontrent.github.io/theftdlc/",
    "bug_reports": "https://github.com/hendersontrent/theftdlc/issues",
    "repository": "https://cran.r-project.org/package=theftdlc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "theftdlc Analyse and Interpret Time Series Features Provides a suite of functions for analysing, interpreting, and visualising\n    time-series features calculated from different feature sets from the 'theft' package. \n    Implements statistical learning methodologies described in Henderson, T.,  \n    Bryant, A., and Fulcher, B. (2023) <doi:10.48550/arXiv.2303.17809>.  "
  },
  {
    "id": 22027,
    "package_name": "thief",
    "title": "Temporal Hierarchical Forecasting",
    "description": "Methods and tools for generating forecasts at different temporal\n    frequencies using a hierarchical time series approach.",
    "version": "0.3",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph],\n  Nikolaos Kourentzes [aut, cph]",
    "url": "http://pkg.robjhyndman.com/thief,\nhttps://github.com/robjhyndman/thief",
    "bug_reports": "https://github.com/robjhyndman/thief/issues",
    "repository": "https://cran.r-project.org/package=thief",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "thief Temporal Hierarchical Forecasting Methods and tools for generating forecasts at different temporal\n    frequencies using a hierarchical time series approach.  "
  },
  {
    "id": 22070,
    "package_name": "tidycharts",
    "title": "Generate Tidy Charts Inspired by 'IBCS'",
    "description": "There is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The 'tidycharts' package enables the user to generate charts compliant with International Business Communication Standards ('IBCS').\n    It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What's more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments.\n    We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible.\n    All charts are generated in SVG format and can be shown in the 'RStudio' viewer pane or exported to HTML output of 'knitr'/'markdown'.",
    "version": "0.1.3",
    "maintainer": "Bartosz Sawicki <sawicki.bartosz@interia.pl>",
    "author": "Przemys\u0142aw Biecek [aut] (ORCID:\n    <https://orcid.org/0000-0001-8423-1823>),\n  Piotr Pi\u0105tyszek [aut],\n  Kinga U\u0142asik [aut],\n  Bartosz Sawicki [aut, cre]",
    "url": "https://mi2datalab.github.io/tidycharts/,\nhttps://github.com/MI2DataLab/tidycharts",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidycharts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidycharts Generate Tidy Charts Inspired by 'IBCS' There is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The 'tidycharts' package enables the user to generate charts compliant with International Business Communication Standards ('IBCS').\n    It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What's more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments.\n    We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible.\n    All charts are generated in SVG format and can be shown in the 'RStudio' viewer pane or exported to HTML output of 'knitr'/'markdown'.  "
  },
  {
    "id": 22143,
    "package_name": "tigerhitteR",
    "title": "Pre-Process of Time Series Data Set in R",
    "description": "Pre-process for discrete time series data set which is not continuous at the column\n    of 'date'. Refilling records of missing 'date' and other columns to the hollow data set so that\n    final data set is able to be dealt with time series analysis.",
    "version": "1.1.0",
    "maintainer": "Will Kuan <aiien61will@gmail.com>",
    "author": "Will Kuan <aiien61will@gmail.com>",
    "url": "https://github.com/Willdata/tigerhitteR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tigerhitteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tigerhitteR Pre-Process of Time Series Data Set in R Pre-process for discrete time series data set which is not continuous at the column\n    of 'date'. Refilling records of missing 'date' and other columns to the hollow data set so that\n    final data set is able to be dealt with time series analysis.  "
  },
  {
    "id": 22149,
    "package_name": "tigris",
    "title": "Load Census TIGER/Line Shapefiles",
    "description": "Download TIGER/Line shapefiles from the United States Census Bureau\n    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>)\n    and load into R as 'sf' objects.",
    "version": "2.2.1",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "author": "Kyle Walker [aut, cre],\n  Bob Rudis [ctb]",
    "url": "https://github.com/walkerke/tigris",
    "bug_reports": "https://github.com/walkerke/tigris/issues",
    "repository": "https://cran.r-project.org/package=tigris",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tigris Load Census TIGER/Line Shapefiles Download TIGER/Line shapefiles from the United States Census Bureau\n    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>)\n    and load into R as 'sf' objects.  "
  },
  {
    "id": 22165,
    "package_name": "timeSeriesDataSets",
    "title": "Time Series Data Sets",
    "description": "Provides a diverse collection of time series datasets\n    spanning various fields such as economics, finance, energy, healthcare, and more.\n    Designed to support time series analysis in R by offering datasets from\n    multiple disciplines, making it a valuable resource for researchers and analysts.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/timeseriesdatasets_R",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timeSeriesDataSets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timeSeriesDataSets Time Series Data Sets Provides a diverse collection of time series datasets\n    spanning various fields such as economics, finance, energy, healthcare, and more.\n    Designed to support time series analysis in R by offering datasets from\n    multiple disciplines, making it a valuable resource for researchers and analysts.  "
  },
  {
    "id": 22168,
    "package_name": "timedelay",
    "title": "Time Delay Estimation for Stochastic Time Series of\nGravitationally Lensed Quasars",
    "description": "We provide a toolbox to estimate the time delay between the brightness time series of gravitationally lensed quasar images via Bayesian and profile likelihood approaches. The model is based on a state-space representation for  irregularly observed time series data generated from a latent continuous-time Ornstein-Uhlenbeck process. Our Bayesian method adopts scientifically motivated hyper-prior distributions and a Metropolis-Hastings within Gibbs sampler, producing posterior samples of the model parameters that include the time delay. A profile likelihood of the time delay is a simple approximation to the marginal posterior distribution of the time delay. Both Bayesian and profile likelihood approaches complement each other, producing almost identical results; the Bayesian way is more principled but the profile likelihood is easier to implement. A new functionality is added in version 1.0.9 for estimating the time delay between doubly-lensed light curves observed in two bands. See also Tak et al. (2017) <doi:10.1214/17-AOAS1027>, Tak et al. (2018) <doi:10.1080/10618600.2017.1415911>, Hu and Tak (2020) <arXiv:2005.08049>.",
    "version": "1.0.11",
    "maintainer": "Hyungsuk Tak <hyungsuk.tak@gmail.com>",
    "author": "Hyungsuk Tak, Kaisey Mandel, David A. van Dyk, Vinay L. Kashyap, Xiao-Li Meng, Aneta Siemiginowska, and Zhirui Hu",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timedelay",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timedelay Time Delay Estimation for Stochastic Time Series of\nGravitationally Lensed Quasars We provide a toolbox to estimate the time delay between the brightness time series of gravitationally lensed quasar images via Bayesian and profile likelihood approaches. The model is based on a state-space representation for  irregularly observed time series data generated from a latent continuous-time Ornstein-Uhlenbeck process. Our Bayesian method adopts scientifically motivated hyper-prior distributions and a Metropolis-Hastings within Gibbs sampler, producing posterior samples of the model parameters that include the time delay. A profile likelihood of the time delay is a simple approximation to the marginal posterior distribution of the time delay. Both Bayesian and profile likelihood approaches complement each other, producing almost identical results; the Bayesian way is more principled but the profile likelihood is easier to implement. A new functionality is added in version 1.0.9 for estimating the time delay between doubly-lensed light curves observed in two bands. See also Tak et al. (2017) <doi:10.1214/17-AOAS1027>, Tak et al. (2018) <doi:10.1080/10618600.2017.1415911>, Hu and Tak (2020) <arXiv:2005.08049>.  "
  },
  {
    "id": 22170,
    "package_name": "timefully",
    "title": "Time-Series Management Made Easy",
    "description": "Manage time-series data frames across time zones, resolutions, and date ranges, \n    while filling gaps using weekday/hour patterns or simple fill helpers or plotting them interactively.\n    It is designed to work seamlessly with the tidyverse and dygraphs environments.",
    "version": "0.1.0",
    "maintainer": "Marc Ca\u00f1igueral <marccanyigueral@gmail.com>",
    "author": "Marc Ca\u00f1igueral [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9724-5829>)",
    "url": "https://github.com/resourcefully-dev/timefully/,\nhttps://resourcefully-dev.github.io/timefully/",
    "bug_reports": "https://github.com/resourcefully-dev/timefully/issues",
    "repository": "https://cran.r-project.org/package=timefully",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timefully Time-Series Management Made Easy Manage time-series data frames across time zones, resolutions, and date ranges, \n    while filling gaps using weekday/hour patterns or simple fill helpers or plotting them interactively.\n    It is designed to work seamlessly with the tidyverse and dygraphs environments.  "
  },
  {
    "id": 22172,
    "package_name": "timeordered",
    "title": "Time-Ordered and Time-Aggregated Network Analyses",
    "description": "Approaches for incorporating time into network analysis. Methods include: construction of time-ordered networks (temporal graphs); shortest-time and shortest-path-length analyses; resource spread calculations; data resampling and rarefaction for null model construction; reduction to time-aggregated networks with variable window sizes; application of common descriptive statistics to these networks; vector clock latencies; and plotting functionalities. The package supports <doi:10.1371/journal.pone.0020298>. ",
    "version": "1.0.3",
    "maintainer": "Benjamin Wong Blonder <benjamin.blonder@berkeley.edu>",
    "author": "Benjamin Wong Blonder [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timeordered",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timeordered Time-Ordered and Time-Aggregated Network Analyses Approaches for incorporating time into network analysis. Methods include: construction of time-ordered networks (temporal graphs); shortest-time and shortest-path-length analyses; resource spread calculations; data resampling and rarefaction for null model construction; reduction to time-aggregated networks with variable window sizes; application of common descriptive statistics to these networks; vector clock latencies; and plotting functionalities. The package supports <doi:10.1371/journal.pone.0020298>.   "
  },
  {
    "id": 22176,
    "package_name": "timeseriesdb",
    "title": "A Time Series Database for Official Statistics with R and\nPostgreSQL",
    "description": "Archive and manage times series data from official statistics. The 'timeseriesdb' package was designed to manage a large catalog of time series from official statistics which are typically published on a monthly, quarterly or yearly basis. Thus timeseriesdb is optimized to handle updates caused by data revision as well as elaborate, multi-lingual meta information. ",
    "version": "1.0.0-1.1.2",
    "maintainer": "Matthias Bannert <bannert@kof.ethz.ch>",
    "author": "Matthias Bannert [aut, cre],\n  Severin Th\u00f6ni [aut],\n  Ioan Gabriel Bucur [ctb]",
    "url": "https://github.com/mbannert/timeseriesdb",
    "bug_reports": "https://github.com/mbannert/timeseriesdb/issues",
    "repository": "https://cran.r-project.org/package=timeseriesdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timeseriesdb A Time Series Database for Official Statistics with R and\nPostgreSQL Archive and manage times series data from official statistics. The 'timeseriesdb' package was designed to manage a large catalog of time series from official statistics which are typically published on a monthly, quarterly or yearly basis. Thus timeseriesdb is optimized to handle updates caused by data revision as well as elaborate, multi-lingual meta information.   "
  },
  {
    "id": 22177,
    "package_name": "timetools",
    "title": "Seasonal/Sequential (Instants/Durations, Even or not) Time\nSeries",
    "description": "Objects to manipulate sequential and seasonal time series. Sequential time series based on time instants and time duration are handled. Both can be regularly or unevenly spaced (overlapping duration are allowed). Only POSIX* format are used for dates and times. The following classes are provided : 'POSIXcti', 'POSIXctp', 'TimeIntervalDataFrame', 'TimeInstantDataFrame', 'SubtimeDataFrame' ; methods to switch from a class to another and to modify the time support of series (hourly time series to daily time series for instance) are also defined. Tools provided can be used for instance to handle environmental monitoring data (not always produced on a regular time base).",
    "version": "1.15.5",
    "maintainer": "Vladislav Navel <vnavel@yahoo.fr>",
    "author": "Vladislav Navel [aut, cre]",
    "url": "https://sourceforge.net/projects/timetools/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timetools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timetools Seasonal/Sequential (Instants/Durations, Even or not) Time\nSeries Objects to manipulate sequential and seasonal time series. Sequential time series based on time instants and time duration are handled. Both can be regularly or unevenly spaced (overlapping duration are allowed). Only POSIX* format are used for dates and times. The following classes are provided : 'POSIXcti', 'POSIXctp', 'TimeIntervalDataFrame', 'TimeInstantDataFrame', 'SubtimeDataFrame' ; methods to switch from a class to another and to modify the time support of series (hourly time series to daily time series for instance) are also defined. Tools provided can be used for instance to handle environmental monitoring data (not always produced on a regular time base).  "
  },
  {
    "id": 22178,
    "package_name": "timevarcorr",
    "title": "Time Varying Correlation",
    "description": "\n    Computes how the correlation between 2 time-series changes over time.\n    To do so, the package follows the method from Choi & Shin (2021) <doi:10.1007/s42952-020-00073-6>.\n    It performs a non-parametric kernel smoothing (using a common bandwidth) of all underlying components required for the computation of a correlation coefficient (i.e., x, y, x^2, y^2, xy).\n    An automatic selection procedure for the bandwidth parameter is implemented.\n    Alternative kernels can be used (Epanechnikov, box and normal).\n    Both Pearson and Spearman correlation coefficients can be estimated and change in correlation over time can be tested.",
    "version": "0.1.1",
    "maintainer": "Alexandre Courtiol <alexandre.courtiol@gmail.com>",
    "author": "Alexandre Courtiol [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0637-2959>),\n  Fran\u00e7ois Rousset [aut] (ORCID: <https://orcid.org/0000-0003-4670-0371>)",
    "url": "https://courtiol.github.io/timevarcorr/,\nhttps://github.com/courtiol/timevarcorr",
    "bug_reports": "https://github.com/courtiol/timevarcorr/issues",
    "repository": "https://cran.r-project.org/package=timevarcorr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timevarcorr Time Varying Correlation \n    Computes how the correlation between 2 time-series changes over time.\n    To do so, the package follows the method from Choi & Shin (2021) <doi:10.1007/s42952-020-00073-6>.\n    It performs a non-parametric kernel smoothing (using a common bandwidth) of all underlying components required for the computation of a correlation coefficient (i.e., x, y, x^2, y^2, xy).\n    An automatic selection procedure for the bandwidth parameter is implemented.\n    Alternative kernels can be used (Epanechnikov, box and normal).\n    Both Pearson and Spearman correlation coefficients can be estimated and change in correlation over time can be tested.  "
  },
  {
    "id": 22179,
    "package_name": "timsac",
    "title": "Time Series Analysis and Control Package",
    "description": "Functions for statistical analysis, prediction and control of time\n series based mainly on Akaike and Nakagawa (1988) <ISBN 978-90-277-2786-2>.",
    "version": "1.3.8-4",
    "maintainer": "Masami Saga <msaga@mtb.biglobe.ne.jp>",
    "author": "The Institute of Statistical Mathematics",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timsac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timsac Time Series Analysis and Control Package Functions for statistical analysis, prediction and control of time\n series based mainly on Akaike and Nakagawa (1988) <ISBN 978-90-277-2786-2>.  "
  },
  {
    "id": 22185,
    "package_name": "tinyVAST",
    "title": "Multivariate Spatio-Temporal Models using Structural Equations",
    "description": "Fits a wide variety of multivariate spatio-temporal models\n    with simultaneous and lagged interactions among variables (including\n    vector autoregressive spatio-temporal ('VAST') dynamics)\n    for areal, continuous, or network spatial domains.  \n    It includes time-variable, space-variable, and space-time-variable \n    interactions using dynamic structural equation models ('DSEM') \n    as expressive interface, and the 'mgcv' package to specify splines \n    via the formula interface.  See Thorson et al. (2025)\n    <doi:10.1111/geb.70035> for more details.",
    "version": "1.3.0",
    "maintainer": "James T. Thorson <James.Thorson@noaa.gov>",
    "author": "James T. Thorson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7415-1010>),\n  Sean C. Anderson [aut] (ORCID: <https://orcid.org/0000-0001-9563-1937>)",
    "url": "https://vast-lib.github.io/tinyVAST/",
    "bug_reports": "https://github.com/vast-lib/tinyVAST/issues",
    "repository": "https://cran.r-project.org/package=tinyVAST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinyVAST Multivariate Spatio-Temporal Models using Structural Equations Fits a wide variety of multivariate spatio-temporal models\n    with simultaneous and lagged interactions among variables (including\n    vector autoregressive spatio-temporal ('VAST') dynamics)\n    for areal, continuous, or network spatial domains.  \n    It includes time-variable, space-variable, and space-time-variable \n    interactions using dynamic structural equation models ('DSEM') \n    as expressive interface, and the 'mgcv' package to specify splines \n    via the formula interface.  See Thorson et al. (2025)\n    <doi:10.1111/geb.70035> for more details.  "
  },
  {
    "id": 22196,
    "package_name": "tinytiger",
    "title": "Lightweight Interface to TIGER/Line Shapefiles",
    "description": "Download geographic shapes from the United States Census Bureau \n    TIGER/Line Shapefiles <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>.\n    Functions support downloading and reading in geographic boundary data.\n    All downloads can be set up with a cache to avoid multiple downloads.\n    Data is available back to 2000 for most geographies.",
    "version": "0.0.11",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>),\n  Cory McCartan [aut]",
    "url": "https://github.com/alarm-redist/tinytiger,\nhttps://alarm-redist.org/tinytiger/",
    "bug_reports": "https://github.com/alarm-redist/tinytiger/issues",
    "repository": "https://cran.r-project.org/package=tinytiger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinytiger Lightweight Interface to TIGER/Line Shapefiles Download geographic shapes from the United States Census Bureau \n    TIGER/Line Shapefiles <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>.\n    Functions support downloading and reading in geographic boundary data.\n    All downloads can be set up with a cache to avoid multiple downloads.\n    Data is available back to 2000 for most geographies.  "
  },
  {
    "id": 22226,
    "package_name": "tma",
    "title": "Transmodal Analysis (TMA)",
    "description": "A robust computational framework for analyzing complex multimodal data. Extends existing state-dependent models to account for diverse data streams, addressing challenges such as varying temporal scales and learner characteristics to improve the robustness and interpretability of findings. For methodological details, see Shaffer, Wang, and Ruis (2025) \"Transmodal Analysis\" <doi:10.18608/jla.2025.8423>.",
    "version": "0.3.1",
    "maintainer": "Cody L Marquart <cody.marquart@wisc.edu>",
    "author": "Cody L Marquart [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3387-6792>),\n  Muhammad Hasnat Ashiq [aut],\n  David Williamson Shaffer [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tma",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tma Transmodal Analysis (TMA) A robust computational framework for analyzing complex multimodal data. Extends existing state-dependent models to account for diverse data streams, addressing challenges such as varying temporal scales and learner characteristics to improve the robustness and interpretability of findings. For methodological details, see Shaffer, Wang, and Ruis (2025) \"Transmodal Analysis\" <doi:10.18608/jla.2025.8423>.  "
  },
  {
    "id": 22229,
    "package_name": "tmap.glyphs",
    "title": "Extension to 'tmap' for Creating Glyphs",
    "description": "Provides new layer functions to 'tmap' for drawing glyphs. A glyph is a small chart (e.g., donut chart) shown at specific map locations to visualize multivariate or time-series data. The functions work with the syntax of 'tmap' and allow flexible control over size, layout, and appearance.",
    "version": "0.1",
    "maintainer": "Martijn Tennekes <mtennekes@gmail.com>",
    "author": "Martijn Tennekes [aut, cre]",
    "url": "https://github.com/r-tmap/tmap.glyphs,\nhttps://r-tmap.github.io/tmap.glyphs/",
    "bug_reports": "https://github.com/r-tmap/tmap.glyphs/issues",
    "repository": "https://cran.r-project.org/package=tmap.glyphs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tmap.glyphs Extension to 'tmap' for Creating Glyphs Provides new layer functions to 'tmap' for drawing glyphs. A glyph is a small chart (e.g., donut chart) shown at specific map locations to visualize multivariate or time-series data. The functions work with the syntax of 'tmap' and allow flexible control over size, layout, and appearance.  "
  },
  {
    "id": 22303,
    "package_name": "tpc",
    "title": "Tiered PC Algorithm",
    "description": "Constraint-based causal discovery using the PC algorithm while\n    accounting for a partial node ordering, for example a partial temporal ordering\n    when the data were collected in different waves of a cohort study.\n    Andrews RM, Foraita R, Didelez V, Witte J (2021) <arXiv:2108.13395>  \n    provide a guide how to use tpc to analyse cohort data.",
    "version": "1.0",
    "maintainer": "Ronja Foraita <foraita@leibniz-bips.de>",
    "author": "Janine Witte [aut],\n  Ronja Foraita [cre, ctb] (ORCID:\n    <https://orcid.org/0000-0003-2216-6653>),\n  DFG [fnd]",
    "url": "https://github.com/bips-hb/tpc",
    "bug_reports": "https://github.com/bips-hb/tpc/issues",
    "repository": "https://cran.r-project.org/package=tpc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tpc Tiered PC Algorithm Constraint-based causal discovery using the PC algorithm while\n    accounting for a partial node ordering, for example a partial temporal ordering\n    when the data were collected in different waves of a cohort study.\n    Andrews RM, Foraita R, Didelez V, Witte J (2021) <arXiv:2108.13395>  \n    provide a guide how to use tpc to analyse cohort data.  "
  },
  {
    "id": 22307,
    "package_name": "tpr",
    "title": "Temporal Process Regression",
    "description": "Regression models for temporal process responses with\n        time-varying coefficient.",
    "version": "0.3-3",
    "maintainer": "Jun Yan <jun.yan@uconn.edu>",
    "author": "Jun Yan <jun.yan@uconn.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tpr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tpr Temporal Process Regression Regression models for temporal process responses with\n        time-varying coefficient.  "
  },
  {
    "id": 22346,
    "package_name": "transformerForecasting",
    "title": "Transformer Deep Learning Model for Time Series Forecasting",
    "description": "Time series forecasting faces challenges due to the non-stationarity, nonlinearity, and chaotic nature of the data. Traditional deep learning models like Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) process data sequentially but are inefficient for long sequences. To overcome the limitations of these models, we proposed a transformer-based deep learning architecture utilizing an attention mechanism for parallel processing, enhancing prediction accuracy and efficiency. This paper presents user-friendly code for the implementation of the proposed transformer-based deep learning architecture utilizing an attention mechanism for parallel\u00a0processing. References:  Nayak et al. (2024) <doi:10.1007/s40808-023-01944-7> and Nayak et al. (2024) <doi:10.1016/j.simpa.2024.100716>.",
    "version": "0.1.0",
    "maintainer": "G H Harish Nayak <harishnayak626@gmail.com>",
    "author": "G H Harish Nayak [aut, cre],\n  Md Wasi Alam [ths],\n  B Samuel Naik [ctb],\n  G Avinash [ctb],\n  Kabilan S [ctb],\n  Varshini B S [ctb],\n  Mrinmoy Ray [ths],\n  Rajeev Ranjan Kumar [ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=transformerForecasting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "transformerForecasting Transformer Deep Learning Model for Time Series Forecasting Time series forecasting faces challenges due to the non-stationarity, nonlinearity, and chaotic nature of the data. Traditional deep learning models like Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) process data sequentially but are inefficient for long sequences. To overcome the limitations of these models, we proposed a transformer-based deep learning architecture utilizing an attention mechanism for parallel processing, enhancing prediction accuracy and efficiency. This paper presents user-friendly code for the implementation of the proposed transformer-based deep learning architecture utilizing an attention mechanism for parallel\u00a0processing. References:  Nayak et al. (2024) <doi:10.1007/s40808-023-01944-7> and Nayak et al. (2024) <doi:10.1016/j.simpa.2024.100716>.  "
  },
  {
    "id": 22358,
    "package_name": "transx",
    "title": "Transform Univariate Time Series",
    "description": "Univariate time series operations that follow an opinionated design. \n    The main principle of 'transx' is to keep the number of observations the same. \n    Operations that reduce this number have to fill the observations gap.",
    "version": "0.0.1",
    "maintainer": "Kostas Vasilopoulos <k.vasilopoulo@gmail.com>",
    "author": "Kostas Vasilopoulos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9769-6395>)",
    "url": "https://github.com/kvasilopoulos/transx",
    "bug_reports": "https://github.com/kvasilopoulos/transx/issues",
    "repository": "https://cran.r-project.org/package=transx",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "transx Transform Univariate Time Series Univariate time series operations that follow an opinionated design. \n    The main principle of 'transx' is to keep the number of observations the same. \n    Operations that reduce this number have to fill the observations gap.  "
  },
  {
    "id": 22363,
    "package_name": "trawl",
    "title": "Estimation and Simulation of Trawl Processes",
    "description": "Contains R functions for simulating and estimating integer-valued trawl processes as \n    described in the article Veraart (2019),\"Modeling, simulation and inference for\n    multivariate time series of counts using trawl processes\", Journal of Multivariate Analysis,\n    169, pages 110-129,\n    <doi:10.1016/j.jmva.2018.08.012> and for \n    simulating random vectors from the bivariate negative binomial and the bi- and trivariate \n    logarithmic series distributions.",
    "version": "0.2.2",
    "maintainer": "Almut E. D. Veraart <a.veraart@imperial.ac.uk>",
    "author": "Almut E. D. Veraart",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=trawl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trawl Estimation and Simulation of Trawl Processes Contains R functions for simulating and estimating integer-valued trawl processes as \n    described in the article Veraart (2019),\"Modeling, simulation and inference for\n    multivariate time series of counts using trawl processes\", Journal of Multivariate Analysis,\n    169, pages 110-129,\n    <doi:10.1016/j.jmva.2018.08.012> and for \n    simulating random vectors from the bivariate negative binomial and the bi- and trivariate \n    logarithmic series distributions.  "
  },
  {
    "id": 22384,
    "package_name": "treesliceR",
    "title": "To Slice Phylogenetic Trees and Infer Evolutionary Patterns Over\nTime",
    "description": "Provide a range of functions with multiple criteria for cutting phylogenetic trees at any evolutionary depth. It enables users to cut trees in any orientation, such as rootwardly (from root to tips) and tipwardly (from tips to its root), or allows users to define a specific time interval of interest. It can also be used to create multiple tree pieces of equal temporal width. Moreover, it allows the assessment of novel temporal rates for various phylogenetic indexes, which can be quickly displayed graphically.",
    "version": "1.1.0",
    "maintainer": "Matheus Lima Araujo <matheusaraujolima@live.com>",
    "author": "Matheus Lima Araujo [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9111-725X>),\n  Luiz Gabriel Souza e Souza Ferreira [aut] (ORCID:\n    <https://orcid.org/0009-0002-5881-9791>),\n  Gabriel Nakamura [aut] (ORCID: <https://orcid.org/0000-0002-5144-5312>),\n  Marco Tulio Pacheco Coelho [aut] (ORCID:\n    <https://orcid.org/0000-0002-7831-3053>),\n  Thiago Fernando Rangel [aut] (ORCID:\n    <https://orcid.org/0000-0002-2001-7382>)",
    "url": "https://github.com/AraujoMat/treesliceR,\nhttps://araujomat.github.io/treesliceR/",
    "bug_reports": "https://github.com/AraujoMat/treesliceR/issues",
    "repository": "https://cran.r-project.org/package=treesliceR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "treesliceR To Slice Phylogenetic Trees and Infer Evolutionary Patterns Over\nTime Provide a range of functions with multiple criteria for cutting phylogenetic trees at any evolutionary depth. It enables users to cut trees in any orientation, such as rootwardly (from root to tips) and tipwardly (from tips to its root), or allows users to define a specific time interval of interest. It can also be used to create multiple tree pieces of equal temporal width. Moreover, it allows the assessment of novel temporal rates for various phylogenetic indexes, which can be quickly displayed graphically.  "
  },
  {
    "id": 22393,
    "package_name": "trendchange",
    "title": "Innovative Trend Analysis and Time-Series Change Point Analysis",
    "description": "Innovative Trend Analysis is a graphical method to examine the trends in time series data. Sequential Mann-Kendall test uses the intersection of prograde and retrograde series to indicate the possible change point in time series data. Distribution free cumulative sum charts indicate location and significance of the change point in time series.\n  Zekai, S. (2011). <doi:10.1061/(ASCE)HE.1943-5584.0000556>.\n  Grayson, R. B. et al. (1996). Hydrological Recipes: Estimation Techniques in Australian Hydrology. Cooperative Research Centre for Catchment Hydrology, Australia, p. 125. \n  Sneyers, S. (1990). On the statistical analysis of series of observations. Technical note no 5 143, WMO No 725 415. Secretariat of the World Meteorological Organization, Geneva, 192 pp.",
    "version": "1.2",
    "maintainer": "Sandeep Kumar Patakamuri <sandeep.patakamuri@gmail.com>",
    "author": "Sandeep Kumar Patakamuri [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8965-8287>),\n  Bappa Das [aut, ctb] (ORCID: <https://orcid.org/0000-0003-1286-1492>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=trendchange",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trendchange Innovative Trend Analysis and Time-Series Change Point Analysis Innovative Trend Analysis is a graphical method to examine the trends in time series data. Sequential Mann-Kendall test uses the intersection of prograde and retrograde series to indicate the possible change point in time series data. Distribution free cumulative sum charts indicate location and significance of the change point in time series.\n  Zekai, S. (2011). <doi:10.1061/(ASCE)HE.1943-5584.0000556>.\n  Grayson, R. B. et al. (1996). Hydrological Recipes: Estimation Techniques in Australian Hydrology. Cooperative Research Centre for Catchment Hydrology, Australia, p. 125. \n  Sneyers, S. (1990). On the statistical analysis of series of observations. Technical note no 5 143, WMO No 725 415. Secretariat of the World Meteorological Organization, Geneva, 192 pp.  "
  },
  {
    "id": 22394,
    "package_name": "trendsegmentR",
    "title": "Linear Trend Segmentation",
    "description": "Performs the detection of linear trend changes for univariate time series \n    by implementing the bottom-up unbalanced wavelet transformation proposed by \n    H. Maeng and P. Fryzlewicz (2023). The estimated number and locations of the \n    change-points are returned with the piecewise-linear estimator for signal.",
    "version": "1.3.0",
    "maintainer": "Hyeyoung Maeng <hyeyoung.maeng@durham.ac.uk>",
    "author": "Hyeyoung Maeng [aut, cre],\n  Piotr Fryzlewicz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=trendsegmentR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trendsegmentR Linear Trend Segmentation Performs the detection of linear trend changes for univariate time series \n    by implementing the bottom-up unbalanced wavelet transformation proposed by \n    H. Maeng and P. Fryzlewicz (2023). The estimated number and locations of the \n    change-points are returned with the piecewise-linear estimator for signal.  "
  },
  {
    "id": 22395,
    "package_name": "trendseries",
    "title": "Extract Trends from Time Series",
    "description": "Extract trends from monthly and quarterly economic time series.\n    Provides two main functions: augment_trends() for pipe-friendly 'tibble' workflows\n    and extract_trends() for direct time series analysis. Includes key econometric\n    filters and modern parameter experimentation tools.",
    "version": "1.1.0",
    "maintainer": "Vinicius Oike <viniciusoike@gmail.com>",
    "author": "Vinicius Oike [aut, cre]",
    "url": "https://github.com/viniciusoike/trendseries,\nhttps://viniciusoike.github.io/trendseries/",
    "bug_reports": "https://github.com/viniciusoike/trendseries/issues",
    "repository": "https://cran.r-project.org/package=trendseries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trendseries Extract Trends from Time Series Extract trends from monthly and quarterly economic time series.\n    Provides two main functions: augment_trends() for pipe-friendly 'tibble' workflows\n    and extract_trends() for direct time series analysis. Includes key econometric\n    filters and modern parameter experimentation tools.  "
  },
  {
    "id": 22396,
    "package_name": "trendtestR",
    "title": "Exploratory Trend Analysis and Visualization for Time-Series and\nGrouped Data",
    "description": "Provides a set of exploratory data analysis (EDA) tools for \n    visualizing trends, diagnosing data types for beginner-friendly workflows, \n    and automatically routing to suitable statistical tests or trend exploration \n    models. Includes unified plotting functions for trend lines, grouped boxplots, \n    and comparative scatterplots; automated statistical testing (e.g., t-test, \n    Wilcoxon, ANOVA, Kruskal-Wallis, Tukey, Dunn) with optional effect size \n    calculation; and model-based trend analysis using generalized additive \n    models (GAM) for count data, generalized linear models (GLM) for continuous \n    data, and zero-inflated models (ZIP/ZINB) for count data with potential \n    zero-inflation. \n    Also supports time-window continuity checks, cross-year \n    handling in compare_monthly_cases(), and ARIMA-ready preparation with \n    stationarity diagnostics, ensuring consistent parameter styles for \n    reproducible research and user-friendly workflows.Methods are \n    based on R Core Team (2024) <https://www.R-project.org/>, \n    Wood, S.N.(2017, ISBN:978-1498728331),\n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>, \n    Simon Jackman (2024) <https://github.com/atahk/pscl/>,    \n    Achim Zeileis, Christian Kleiber, Simon Jackman (2008) <doi:10.18637/jss.v027.i08>.",
    "version": "1.0.1",
    "maintainer": "Gelan Huang <huanggelan97@icloud.com>",
    "author": "Gelan Huang [aut, cre]",
    "url": "https://github.com/GrahnH/trendtestR",
    "bug_reports": "https://github.com/GrahnH/trendtestR/issues",
    "repository": "https://cran.r-project.org/package=trendtestR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trendtestR Exploratory Trend Analysis and Visualization for Time-Series and\nGrouped Data Provides a set of exploratory data analysis (EDA) tools for \n    visualizing trends, diagnosing data types for beginner-friendly workflows, \n    and automatically routing to suitable statistical tests or trend exploration \n    models. Includes unified plotting functions for trend lines, grouped boxplots, \n    and comparative scatterplots; automated statistical testing (e.g., t-test, \n    Wilcoxon, ANOVA, Kruskal-Wallis, Tukey, Dunn) with optional effect size \n    calculation; and model-based trend analysis using generalized additive \n    models (GAM) for count data, generalized linear models (GLM) for continuous \n    data, and zero-inflated models (ZIP/ZINB) for count data with potential \n    zero-inflation. \n    Also supports time-window continuity checks, cross-year \n    handling in compare_monthly_cases(), and ARIMA-ready preparation with \n    stationarity diagnostics, ensuring consistent parameter styles for \n    reproducible research and user-friendly workflows.Methods are \n    based on R Core Team (2024) <https://www.R-project.org/>, \n    Wood, S.N.(2017, ISBN:978-1498728331),\n    Hyndman RJ, Khandakar Y (2008) <doi:10.18637/jss.v027.i03>, \n    Simon Jackman (2024) <https://github.com/atahk/pscl/>,    \n    Achim Zeileis, Christian Kleiber, Simon Jackman (2008) <doi:10.18637/jss.v027.i08>.  "
  },
  {
    "id": 22418,
    "package_name": "triptych",
    "title": "Diagnostic Graphics to Evaluate Forecast Performance",
    "description": "Overall predictive performance is measured by a mean score\n    (or loss), which decomposes into miscalibration, discrimination, and\n    uncertainty components. The main focus is visualization of these distinct\n    and complementary aspects in joint displays.\n    See Dimitriadis, Gneiting, Jordan, Vogel (2024) <doi:10.1016/j.ijforecast.2023.09.007>.",
    "version": "0.1.3",
    "maintainer": "Alexander I. Jordan <alexander.jordan@h-its.org>",
    "author": "Timo Dimitriadis [aut, cph],\n  Alexander I. Jordan [aut, cre, cph]",
    "url": "https://github.com/aijordan/triptych/,\nhttps://aijordan.github.io/triptych/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=triptych",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "triptych Diagnostic Graphics to Evaluate Forecast Performance Overall predictive performance is measured by a mean score\n    (or loss), which decomposes into miscalibration, discrimination, and\n    uncertainty components. The main focus is visualization of these distinct\n    and complementary aspects in joint displays.\n    See Dimitriadis, Gneiting, Jordan, Vogel (2024) <doi:10.1016/j.ijforecast.2023.09.007>.  "
  },
  {
    "id": 22440,
    "package_name": "tsBSS",
    "title": "Blind Source Separation and Supervised Dimension Reduction for\nTime Series",
    "description": "Different estimators are provided to solve the blind source separation problem for multivariate time series with stochastic volatility and supervised dimension reduction problem for multivariate time series. Different functions based on AMUSE and SOBI are also provided for estimating the dimension of the white noise subspace. The package is fully described in Nordhausen, Matilainen, Miettinen, Virta and Taskinen (2021) <doi:10.18637/jss.v098.i15>.",
    "version": "1.0.0",
    "maintainer": "Markus Matilainen <markus.matilainen@outlook.com>",
    "author": "Markus Matilainen [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-5597-2670>),\n  Christophe Croux [aut],\n  Jari Miettinen [aut] (ORCID: <https://orcid.org/0000-0002-3270-7014>),\n  Klaus Nordhausen [aut] (ORCID: <https://orcid.org/0000-0002-3758-8501>),\n  Hannu Oja [aut],\n  Sara Taskinen [aut] (ORCID: <https://orcid.org/0000-0001-9470-7258>),\n  Joni Virta [aut] (ORCID: <https://orcid.org/0000-0002-2150-2769>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsBSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsBSS Blind Source Separation and Supervised Dimension Reduction for\nTime Series Different estimators are provided to solve the blind source separation problem for multivariate time series with stochastic volatility and supervised dimension reduction problem for multivariate time series. Different functions based on AMUSE and SOBI are also provided for estimating the dimension of the white noise subspace. The package is fully described in Nordhausen, Matilainen, Miettinen, Virta and Taskinen (2021) <doi:10.18637/jss.v098.i15>.  "
  },
  {
    "id": 22441,
    "package_name": "tsDyn",
    "title": "Nonlinear Time Series Models with Regime Switching",
    "description": "Implements nonlinear autoregressive (AR) time series models. For univariate series, a non-parametric approach is available through additive nonlinear AR. Parametric modeling and testing for regime switching dynamics is available when the transition is either direct (TAR: threshold AR) or smooth (STAR: smooth transition AR, LSTAR). For multivariate series, one can estimate a range of TVAR or threshold cointegration TVECM models with two or three regimes. Tests can be conducted for TVAR as well as for TVECM (Hansen and Seo 2002 and Seo 2006). ",
    "version": "11.0.5.2",
    "maintainer": "Matthieu Stigler <Matthieu.Stigler@gmail.com>",
    "author": "Antonio Fabio Di Narzo [aut] (ORCID:\n    <https://orcid.org/0000-0002-4033-5038>),\n  Jose Luis Aznarte [ctb] (ORCID:\n    <https://orcid.org/0000-0002-1636-244X>),\n  Matthieu Stigler [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6802-4290>)",
    "url": "https://github.com/MatthieuStigler/tsDyn/wiki",
    "bug_reports": "https://github.com/MatthieuStigler/tsDyn/issues",
    "repository": "https://cran.r-project.org/package=tsDyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsDyn Nonlinear Time Series Models with Regime Switching Implements nonlinear autoregressive (AR) time series models. For univariate series, a non-parametric approach is available through additive nonlinear AR. Parametric modeling and testing for regime switching dynamics is available when the transition is either direct (TAR: threshold AR) or smooth (STAR: smooth transition AR, LSTAR). For multivariate series, one can estimate a range of TVAR or threshold cointegration TVECM models with two or three regimes. Tests can be conducted for TVAR as well as for TVECM (Hansen and Seo 2002 and Seo 2006).   "
  },
  {
    "id": 22442,
    "package_name": "tsLSTMx",
    "title": "Predict Time Series Using LSTM Model Including Exogenous\nVariable to Denote Zero Values",
    "description": "It is a versatile tool for predicting time series data using Long Short-Term Memory (LSTM) models. It is specifically designed to handle time series with an exogenous variable, allowing users to denote whether data was available for a particular period or not. The package encompasses various functionalities, including hyperparameter tuning, custom loss function support, model evaluation, and one-step-ahead forecasting. With an emphasis on ease of use and flexibility, it empowers users to explore, evaluate, and deploy LSTM models for accurate time series predictions and forecasting in diverse applications. More details can be found in Garai and Paul (2023) <doi:10.1016/j.iswa.2023.200202>.",
    "version": "0.1.0",
    "maintainer": "Sandip Garai <sandipnicksandy@gmail.com>",
    "author": "Sandip Garai [aut, cre],\n  Krishna Pada Sarkar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsLSTMx",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsLSTMx Predict Time Series Using LSTM Model Including Exogenous\nVariable to Denote Zero Values It is a versatile tool for predicting time series data using Long Short-Term Memory (LSTM) models. It is specifically designed to handle time series with an exogenous variable, allowing users to denote whether data was available for a particular period or not. The package encompasses various functionalities, including hyperparameter tuning, custom loss function support, model evaluation, and one-step-ahead forecasting. With an emphasis on ease of use and flexibility, it empowers users to explore, evaluate, and deploy LSTM models for accurate time series predictions and forecasting in diverse applications. More details can be found in Garai and Paul (2023) <doi:10.1016/j.iswa.2023.200202>.  "
  },
  {
    "id": 22443,
    "package_name": "tsModel",
    "title": "Time Series Modeling for Air Pollution and Health",
    "description": "Tools for specifying time series regression models.",
    "version": "0.6-2",
    "maintainer": "Roger D. Peng <roger.peng@austin.utexas.edu>",
    "author": "Roger D. Peng <roger.peng@austin.utexas.edu>, with contributions from Aidan McDermott",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsModel Time Series Modeling for Air Pollution and Health Tools for specifying time series regression models.  "
  },
  {
    "id": 22444,
    "package_name": "tsPI",
    "title": "Improved Prediction Intervals for ARIMA Processes and Structural\nTime Series",
    "description": "Prediction intervals for ARIMA and structural time series\n    models using importance sampling approach with uninformative priors for model\n    parameters, leading to more accurate coverage probabilities in frequentist\n    sense. Instead of sampling the future observations and hidden states of the\n    state space representation of the model, only model parameters are sampled,\n    and the method is based solving the equations corresponding to the conditional\n    coverage probability of the prediction intervals. This makes method relatively\n    fast compared to for example MCMC methods, and standard errors of prediction\n    limits can also be computed straightforwardly.",
    "version": "1.0.4",
    "maintainer": "Jouni Helske <jouni.helske@iki.fi>",
    "author": "Jouni Helske",
    "url": "",
    "bug_reports": "https://github.com/helske/tsPI/issues",
    "repository": "https://cran.r-project.org/package=tsPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsPI Improved Prediction Intervals for ARIMA Processes and Structural\nTime Series Prediction intervals for ARIMA and structural time series\n    models using importance sampling approach with uninformative priors for model\n    parameters, leading to more accurate coverage probabilities in frequentist\n    sense. Instead of sampling the future observations and hidden states of the\n    state space representation of the model, only model parameters are sampled,\n    and the method is based solving the equations corresponding to the conditional\n    coverage probability of the prediction intervals. This makes method relatively\n    fast compared to for example MCMC methods, and standard errors of prediction\n    limits can also be computed straightforwardly.  "
  },
  {
    "id": 22445,
    "package_name": "tsSelect",
    "title": "Execution of Time Series Models",
    "description": "Execution of various time series models and choosing the best one\n    either by a specific error metric or by picking the best one by majority vote.\n    The models are based on the \"forecast\" package, written by Prof. Rob Hyndman.",
    "version": "0.1.8",
    "maintainer": "Avi Blinder <aviblinder@gmail.com>",
    "author": "Avi Blinder  <aviblinder@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsSelect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsSelect Execution of Time Series Models Execution of various time series models and choosing the best one\n    either by a specific error metric or by picking the best one by majority vote.\n    The models are based on the \"forecast\" package, written by Prof. Rob Hyndman.  "
  },
  {
    "id": 22447,
    "package_name": "tsapp",
    "title": "Time Series, Analysis and Application",
    "description": "Accompanies the book Rainer Schlittgen and Cristina Sattarhoff (2020) <https://www.degruyter.com/view/title/575978>  \"Angewandte Zeitreihenanalyse mit R, 4. Auflage\" . The package contains the time series and functions used therein. It was developed over many years teaching courses about time series analysis.  ",
    "version": "1.0.4",
    "maintainer": "Rainer Schlittgen <R.Schlittgen@t-online.de>",
    "author": "Rainer Schlittgen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsapp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsapp Time Series, Analysis and Application Accompanies the book Rainer Schlittgen and Cristina Sattarhoff (2020) <https://www.degruyter.com/view/title/575978>  \"Angewandte Zeitreihenanalyse mit R, 4. Auflage\" . The package contains the time series and functions used therein. It was developed over many years teaching courses about time series analysis.    "
  },
  {
    "id": 22448,
    "package_name": "tsaux",
    "title": "Time Series Forecasting Auxiliary Functions",
    "description": "A suite of auxiliary functions that enhance time series estimation and forecasting, including a robust anomaly detection routine based on Chen and Liu (1993) <doi:10.2307/2290724> (imported and wrapped from the 'tsoutliers' package), utilities for managing calendar and time conversions, performance metrics to assess both point forecasts and distributional predictions, advanced simulation by allowing the generation of time series components\u2014such as trend, seasonal, ARMA, irregular, and anomalies\u2014in a modular fashion based on the innovations form of the state space model and a number of transformation methods including Box-Cox, Logit, 'Softplus-Logit' and Sigmoid.",
    "version": "1.0.0",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>)",
    "url": "https://github.com/tsmodels/tsaux",
    "bug_reports": "https://github.com/tsmodels/tsaux/issues",
    "repository": "https://cran.r-project.org/package=tsaux",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsaux Time Series Forecasting Auxiliary Functions A suite of auxiliary functions that enhance time series estimation and forecasting, including a robust anomaly detection routine based on Chen and Liu (1993) <doi:10.2307/2290724> (imported and wrapped from the 'tsoutliers' package), utilities for managing calendar and time conversions, performance metrics to assess both point forecasts and distributional predictions, advanced simulation by allowing the generation of time series components\u2014such as trend, seasonal, ARMA, irregular, and anomalies\u2014in a modular fashion based on the innovations form of the state space model and a number of transformation methods including Box-Cox, Logit, 'Softplus-Logit' and Sigmoid.  "
  },
  {
    "id": 22449,
    "package_name": "tscopula",
    "title": "Time Series Copula Models",
    "description": "Functions for the analysis of time series using copula models.  \n    The package is based on methodology described in the following references.\n    McNeil, A.J. (2021) <doi:10.3390/risks9010014>,\n    Bladt, M., & McNeil, A.J. (2021) <doi:10.1016/j.ecosta.2021.07.004>,\n    Bladt, M., & McNeil, A.J. (2022) <doi:10.1515/demo-2022-0105>.",
    "version": "0.3.9",
    "maintainer": "Alexander McNeil <alexanderjmcneil@gmail.com>",
    "author": "Alexander McNeil [aut, cre],\n  Martin Bladt [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tscopula",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tscopula Time Series Copula Models Functions for the analysis of time series using copula models.  \n    The package is based on methodology described in the following references.\n    McNeil, A.J. (2021) <doi:10.3390/risks9010014>,\n    Bladt, M., & McNeil, A.J. (2021) <doi:10.1016/j.ecosta.2021.07.004>,\n    Bladt, M., & McNeil, A.J. (2022) <doi:10.1515/demo-2022-0105>.  "
  },
  {
    "id": 22450,
    "package_name": "tsdataleaks",
    "title": "Exploit Data Leakages in Time Series Forecasting Competitions",
    "description": "Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. For example: randomly chosen blocks of time series are concatenated to form a new time series, scale-shifts, repeating patterns in time series,  white noise is added in the original time series to form a new time series, etc.  'tsdataleaks' package can be used to detect data leakages in a collection of  time series.",
    "version": "2.1.1",
    "maintainer": "Thiyanga S. Talagala <ttalagala@sjp.ac.lk>",
    "author": "Thiyanga S. Talagala [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0656-9789>)",
    "url": "https://github.com/thiyangt/tsdataleaks",
    "bug_reports": "https://github.com/thiyangt/tsdataleaks/issues",
    "repository": "https://cran.r-project.org/package=tsdataleaks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsdataleaks Exploit Data Leakages in Time Series Forecasting Competitions Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. For example: randomly chosen blocks of time series are concatenated to form a new time series, scale-shifts, repeating patterns in time series,  white noise is added in the original time series to form a new time series, etc.  'tsdataleaks' package can be used to detect data leakages in a collection of  time series.  "
  },
  {
    "id": 22451,
    "package_name": "tsdb",
    "title": "Terribly-Simple Data Base for Time Series",
    "description": "A terribly-simple data base for numeric\n  time series, written purely in R, so no external\n  database-software is needed. Series are stored in\n  plain-text files (the most-portable and enduring file\n  type) in CSV format. Timestamps are encoded using R's\n  native numeric representation for 'Date'/'POSIXct',\n  which makes them fast to parse, but keeps them\n  accessible with other software. The package provides\n  tools for saving and updating series in this\n  standardised format, for retrieving and joining data,\n  for summarising files and directories, and for\n  coercing series from and to other data types (such as\n  'zoo' series).",
    "version": "1.1-0",
    "maintainer": "Enrico Schumann <es@enricoschumann.net>",
    "author": "Enrico Schumann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7601-6576>)",
    "url": "http://enricoschumann.net/R/packages/tsdb/,\nhttps://github.com/enricoschumann/tsdb,\nhttps://gitlab.com/enricoschumann/tsdb",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsdb Terribly-Simple Data Base for Time Series A terribly-simple data base for numeric\n  time series, written purely in R, so no external\n  database-software is needed. Series are stored in\n  plain-text files (the most-portable and enduring file\n  type) in CSV format. Timestamps are encoded using R's\n  native numeric representation for 'Date'/'POSIXct',\n  which makes them fast to parse, but keeps them\n  accessible with other software. The package provides\n  tools for saving and updating series in this\n  standardised format, for retrieving and joining data,\n  for summarising files and directories, and for\n  coercing series from and to other data types (such as\n  'zoo' series).  "
  },
  {
    "id": 22452,
    "package_name": "tsdecomp",
    "title": "Decomposition of Time Series Data",
    "description": "ARIMA-model-based decomposition of quarterly and \n monthly time series data.\n The methodology is developed and described, among others, in \n Burman (1980) <DOI:10.2307/2982132> and \n Hillmer and Tiao (1982) <DOI:10.2307/2287770>.",
    "version": "0.2",
    "maintainer": "Javier L\u00f3pez-de-Lacalle <javlacalle@yahoo.es>",
    "author": "Javier L\u00f3pez-de-Lacalle <javlacalle@yahoo.es>",
    "url": "https://jalobe.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsdecomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsdecomp Decomposition of Time Series Data ARIMA-model-based decomposition of quarterly and \n monthly time series data.\n The methodology is developed and described, among others, in \n Burman (1980) <DOI:10.2307/2982132> and \n Hillmer and Tiao (1982) <DOI:10.2307/2287770>.  "
  },
  {
    "id": 22454,
    "package_name": "tsdisagg2",
    "title": "Time Series Disaggregation",
    "description": "Disaggregates low frequency time series data to higher frequency series. Implements the following methods for temporal disaggregation: Boot, Feibes and Lisman (1967) <DOI:10.2307/2985238>, Chow and Lin (1971) <DOI:10.2307/1928739>, Fernandez (1981) <DOI:10.2307/1924371> and Litterman (1983) <DOI:10.2307/1391858>.",
    "version": "0.1.0",
    "maintainer": "Jorge Vieira <jorgealexandrevieira@gmail.com>",
    "author": "Jorge Vieira <jorgealexandrevieira@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsdisagg2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsdisagg2 Time Series Disaggregation Disaggregates low frequency time series data to higher frequency series. Implements the following methods for temporal disaggregation: Boot, Feibes and Lisman (1967) <DOI:10.2307/2985238>, Chow and Lin (1971) <DOI:10.2307/1928739>, Fernandez (1981) <DOI:10.2307/1924371> and Litterman (1983) <DOI:10.2307/1391858>.  "
  },
  {
    "id": 22456,
    "package_name": "tseffects",
    "title": "Dynamic (Causal) Inferences from Time Series (with Interactions)",
    "description": "Autoregressive distributed lag (A[R]DL) models (and their reparameterized equivalent, the Generalized Error-Correction Model [GECM]) (see De Boef and Keele 2008 <doi:10.1111/j.1540-5907.2007.00307.x>) are the workhorse models in uncovering dynamic inferences. ADL models are simple to estimate; this is what makes them attractive. Once these models are estimated, what is less clear is how to uncover a rich set of dynamic inferences from these models. We provide tools for recovering those inferences in three forms: causal inferences from ADL models, traditional time series quantities of interest (short- and long-run effects), and dynamic conditional relationships.",
    "version": "0.1.4",
    "maintainer": "Soren Jordan <sorenjordanpols@gmail.com>",
    "author": "Soren Jordan [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4201-1085>),\n  Garrett N. Vande Kamp [aut],\n  Reshi Rajan [aut]",
    "url": "https://sorenjordan.github.io/tseffects/,\nhttps://github.com/sorenjordan/tseffects",
    "bug_reports": "https://github.com/sorenjordan/tseffects/issues",
    "repository": "https://cran.r-project.org/package=tseffects",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tseffects Dynamic (Causal) Inferences from Time Series (with Interactions) Autoregressive distributed lag (A[R]DL) models (and their reparameterized equivalent, the Generalized Error-Correction Model [GECM]) (see De Boef and Keele 2008 <doi:10.1111/j.1540-5907.2007.00307.x>) are the workhorse models in uncovering dynamic inferences. ADL models are simple to estimate; this is what makes them attractive. Once these models are estimated, what is less clear is how to uncover a rich set of dynamic inferences from these models. We provide tools for recovering those inferences in three forms: causal inferences from ADL models, traditional time series quantities of interest (short- and long-run effects), and dynamic conditional relationships.  "
  },
  {
    "id": 22457,
    "package_name": "tsensembler",
    "title": "Dynamic Ensembles for Time Series Forecasting",
    "description": "A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. \"Arbitrated Ensemble for Time Series Forecasting.\" to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: \"Arbitrated Ensemble for Solar Radiation Forecasting.\" International Work-Conference on Artificial Neural Networks. Springer, 2017 <doi:10.1007/978-3-319-59153-7_62>.",
    "version": "0.1.0",
    "maintainer": "Vitor Cerqueira <cerqueira.vitormanuel@gmail.com>",
    "author": "Vitor Cerqueira [aut, cre],\n  Luis Torgo [ctb],\n  Carlos Soares [ctb]",
    "url": "https://github.com/vcerqueira/tsensembler",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsensembler",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsensembler Dynamic Ensembles for Time Series Forecasting A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. \"Arbitrated Ensemble for Time Series Forecasting.\" to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: \"Arbitrated Ensemble for Solar Radiation Forecasting.\" International Work-Conference on Artificial Neural Networks. Springer, 2017 <doi:10.1007/978-3-319-59153-7_62>.  "
  },
  {
    "id": 22459,
    "package_name": "tseries",
    "title": "Time Series Analysis and Computational Finance",
    "description": "Time series analysis and computational finance.",
    "version": "0.10-58",
    "maintainer": "Kurt Hornik <Kurt.Hornik@R-project.org>",
    "author": "Adrian Trapletti [aut],\n  Kurt Hornik [aut, cre] (ORCID: <https://orcid.org/0000-0003-4198-9911>),\n  Blake LeBaron [ctb] (BDS test code)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tseries",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tseries Time Series Analysis and Computational Finance Time series analysis and computational finance.  "
  },
  {
    "id": 22460,
    "package_name": "tseriesChaos",
    "title": "Analysis of Nonlinear Time Series",
    "description": "Routines for the analysis of nonlinear time series. This\n        work is largely inspired by the TISEAN project, by Rainer\n        Hegger, Holger Kantz and Thomas Schreiber:\n        <http://www.mpipks-dresden.mpg.de/~tisean/>.",
    "version": "0.1-13.1",
    "maintainer": "Antonio Fabio Di Narzo <antonio.fabio@gmail.com>",
    "author": "Antonio, Fabio Di Narzo",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tseriesChaos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tseriesChaos Analysis of Nonlinear Time Series Routines for the analysis of nonlinear time series. This\n        work is largely inspired by the TISEAN project, by Rainer\n        Hegger, Holger Kantz and Thomas Schreiber:\n        <http://www.mpipks-dresden.mpg.de/~tisean/>.  "
  },
  {
    "id": 22461,
    "package_name": "tseriesEntropy",
    "title": "Entropy Based Analysis and Tests for Time Series",
    "description": "Implements an Entropy measure of dependence based on the Bhattacharya-Hellinger-Matusita distance. Can be used as a (nonlinear) autocorrelation/crosscorrelation function for continuous and categorical time series. The package includes tests for serial and cross dependence and nonlinearity based on it. Some routines have a parallel version that can be used in a multicore/cluster environment. The package makes use of S4 classes.",
    "version": "0.7-2",
    "maintainer": "Simone Giannerini <simone.giannerini@unibo.it>",
    "author": "Simone Giannerini [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0710-668X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tseriesEntropy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tseriesEntropy Entropy Based Analysis and Tests for Time Series Implements an Entropy measure of dependence based on the Bhattacharya-Hellinger-Matusita distance. Can be used as a (nonlinear) autocorrelation/crosscorrelation function for continuous and categorical time series. The package includes tests for serial and cross dependence and nonlinearity based on it. Some routines have a parallel version that can be used in a multicore/cluster environment. The package makes use of S4 classes.  "
  },
  {
    "id": 22462,
    "package_name": "tseriesTARMA",
    "title": "Analysis of Nonlinear Time Series Through Threshold\nAutoregressive Moving Average Models (TARMA) Models",
    "description": "Routines for nonlinear time series analysis based on Threshold Autoregressive Moving Average (TARMA) models. It provides functions and methods for: TARMA model fitting and forecasting, including robust estimators, see Goracci et al. JBES (2025) <doi:10.1080/07350015.2024.2412011>; tests for threshold effects, see Giannerini et al. JoE (2024) <doi:10.1016/j.jeconom.2023.01.004>, Goracci et al. Statistica Sinica (2023) <doi:10.5705/ss.202021.0120>, Angelini et al. (2024) <doi:10.48550/arXiv.2308.00444>;  unit-root tests based on TARMA models, see Chan et al. Statistica Sinica (2024) <doi:10.5705/ss.202022.0125>.",
    "version": "0.5-1",
    "maintainer": "Simone Giannerini <simone.giannerini@uniud.it>",
    "author": "Simone Giannerini [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0710-668X>),\n  Greta Goracci [aut] (ORCID: <https://orcid.org/0000-0001-5212-0539>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tseriesTARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tseriesTARMA Analysis of Nonlinear Time Series Through Threshold\nAutoregressive Moving Average Models (TARMA) Models Routines for nonlinear time series analysis based on Threshold Autoregressive Moving Average (TARMA) models. It provides functions and methods for: TARMA model fitting and forecasting, including robust estimators, see Goracci et al. JBES (2025) <doi:10.1080/07350015.2024.2412011>; tests for threshold effects, see Giannerini et al. JoE (2024) <doi:10.1016/j.jeconom.2023.01.004>, Goracci et al. Statistica Sinica (2023) <doi:10.5705/ss.202021.0120>, Angelini et al. (2024) <doi:10.48550/arXiv.2308.00444>;  unit-root tests based on TARMA models, see Chan et al. Statistica Sinica (2024) <doi:10.5705/ss.202022.0125>.  "
  },
  {
    "id": 22463,
    "package_name": "tsfeatures",
    "title": "Time Series Feature Extraction",
    "description": "Methods for extracting various features from time series data. The features provided are those from Hyndman, Wang and Laptev (2013) <doi:10.1109/ICDMW.2015.104>, Kang, Hyndman and Smith-Miles (2017) <doi:10.1016/j.ijforecast.2016.09.004> and from Fulcher, Little and Jones (2013) <doi:10.1098/rsif.2013.0048>. Features include spectral entropy, autocorrelations, measures of the strength of seasonality and trend, and so on. Users can also define their own feature functions.",
    "version": "1.1.1",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Yanfei Kang [aut] (ORCID: <https://orcid.org/0000-0001-8769-6650>),\n  Pablo Montero-Manso [aut],\n  Mitchell O'Hara-Wild [aut] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Thiyanga Talagala [aut] (ORCID:\n    <https://orcid.org/0000-0002-0656-9789>),\n  Earo Wang [aut] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Yangzhuoran Yang [aut],\n  Souhaib Ben Taieb [ctb],\n  Cao Hanqing [ctb],\n  D K Lake [ctb],\n  Nikolay Laptev [ctb],\n  J R Moorman [ctb],\n  Bohan Zhang [ctb]",
    "url": "https://pkg.robjhyndman.com/tsfeatures/,\nhttps://github.com/robjhyndman/tsfeatures",
    "bug_reports": "https://github.com/robjhyndman/tsfeatures/issues",
    "repository": "https://cran.r-project.org/package=tsfeatures",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsfeatures Time Series Feature Extraction Methods for extracting various features from time series data. The features provided are those from Hyndman, Wang and Laptev (2013) <doi:10.1109/ICDMW.2015.104>, Kang, Hyndman and Smith-Miles (2017) <doi:10.1016/j.ijforecast.2016.09.004> and from Fulcher, Little and Jones (2013) <doi:10.1098/rsif.2013.0048>. Features include spectral entropy, autocorrelations, measures of the strength of seasonality and trend, and so on. Users can also define their own feature functions.  "
  },
  {
    "id": 22464,
    "package_name": "tsfgrnn",
    "title": "Time Series Forecasting Using GRNN",
    "description": "A general regression neural network (GRNN) is a variant of a\n    Radial Basis Function Network characterized by a fast single-pass learning.\n    'tsfgrnn' allows you to forecast time series using a GRNN model Francisco \n    Martinez et al. (2019) <doi:10.1007/978-3-030-20521-8_17> and Francisco\n    Martinez et al. (2022) <doi:10.1016/j.neucom.2021.12.028>. When the forecasting\n    horizon is higher than 1, two multi-step ahead forecasting strategies can be used.\n    The model built is autoregressive, that is, it is only based on the \n    observations of the time series. You can consult and plot how the\n    prediction was done. It is also possible to assess the forecasting accuracy\n    of the model using rolling origin evaluation.",
    "version": "1.0.5",
    "maintainer": "Francisco Martinez <fmartin@ujaen.es>",
    "author": "Maria Pilar Frias-Bustamante [aut],\n  Ana Maria Martinez-Rodriguez [aut],\n  Antonio Conde-Sanchez [aut],\n  Francisco Martinez [aut, cre]",
    "url": "https://github.com/franciscomartinezdelrio/tsfgrnn",
    "bug_reports": "https://github.com/franciscomartinezdelrio/tsfgrnn",
    "repository": "https://cran.r-project.org/package=tsfgrnn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsfgrnn Time Series Forecasting Using GRNN A general regression neural network (GRNN) is a variant of a\n    Radial Basis Function Network characterized by a fast single-pass learning.\n    'tsfgrnn' allows you to forecast time series using a GRNN model Francisco \n    Martinez et al. (2019) <doi:10.1007/978-3-030-20521-8_17> and Francisco\n    Martinez et al. (2022) <doi:10.1016/j.neucom.2021.12.028>. When the forecasting\n    horizon is higher than 1, two multi-step ahead forecasting strategies can be used.\n    The model built is autoregressive, that is, it is only based on the \n    observations of the time series. You can consult and plot how the\n    prediction was done. It is also possible to assess the forecasting accuracy\n    of the model using rolling origin evaluation.  "
  },
  {
    "id": 22465,
    "package_name": "tsfknn",
    "title": "Time Series Forecasting Using Nearest Neighbors",
    "description": "Allows forecasting time series using nearest neighbors regression\n    Francisco Martinez, Maria P. Frias, Maria D. Perez-Godoy and Antonio J.\n    Rivera (2019) <doi:10.1007/s10462-017-9593-z>. When the forecasting horizon\n    is higher than 1, two multi-step ahead forecasting strategies can be used.\n    The model built is autoregressive, that is, it is only based on the \n    observations of the time series. The nearest neighbors used in a prediction\n    can be consulted and plotted.",
    "version": "0.6.0",
    "maintainer": "Francisco Martinez <fmartin@ujaen.es>",
    "author": "Francisco Martinez [aut, cre]",
    "url": "https://github.com/franciscomartinezdelrio/tsfknn",
    "bug_reports": "https://github.com/franciscomartinezdelrio/tsfknn/issues",
    "repository": "https://cran.r-project.org/package=tsfknn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsfknn Time Series Forecasting Using Nearest Neighbors Allows forecasting time series using nearest neighbors regression\n    Francisco Martinez, Maria P. Frias, Maria D. Perez-Godoy and Antonio J.\n    Rivera (2019) <doi:10.1007/s10462-017-9593-z>. When the forecasting horizon\n    is higher than 1, two multi-step ahead forecasting strategies can be used.\n    The model built is autoregressive, that is, it is only based on the \n    observations of the time series. The nearest neighbors used in a prediction\n    can be consulted and plotted.  "
  },
  {
    "id": 22466,
    "package_name": "tsfngm",
    "title": "Time Series Forecasting using Nonlinear Growth Models",
    "description": "Nonlinear growth models are extremely useful in gaining insight into the underlying mechanism. These models are generally 'mechanistic,' with parameters that have biological meaning. This package allows you to fit and forecast time series data using nonlinear growth models. ",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Mrinmoy Ray [aut, cre],\n  K. N. Singh [ctb],\n  Kanchan Sinha [ctb],\n  Rajeev Ranjan Kumar [ctb],\n  Prakash Kumar [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsfngm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsfngm Time Series Forecasting using Nonlinear Growth Models Nonlinear growth models are extremely useful in gaining insight into the underlying mechanism. These models are generally 'mechanistic,' with parameters that have biological meaning. This package allows you to fit and forecast time series data using nonlinear growth models.   "
  },
  {
    "id": 22469,
    "package_name": "tsgc",
    "title": "Time Series Methods Based on Growth Curves",
    "description": "The 'tsgc' package provides comprehensive tools for the analysis and forecasting of epidemic trajectories.\n    It is designed to model the progression of an epidemic over time while accounting for the various uncertainties\n    inherent in real-time data. Underpinned by a dynamic Gompertz model, the package adopts a state space approach,\n    using the Kalman filter for flexible and robust estimation of the non-linear growth pattern commonly observed in\n    epidemic data. The reinitialization feature enhances the model\u2019s ability to adapt to the emergence of new waves.\n    The forecasts generated by the package are of value to public health officials and researchers who need to\n    understand and predict the course of an epidemic to inform decision-making. Beyond its application in public\n    health, the package is also a useful resource for researchers and practitioners in fields where the trajectories\n    of interest resemble those of epidemics, such as innovation diffusion. The package includes functionalities for\n    data preprocessing, model fitting, and forecast visualization, as well as tools for evaluating forecast accuracy.\n    The core methodologies implemented in 'tsgc' are based on well-established statistical techniques as described in\n    Harvey and Kattuman (2020) <doi:10.1162/99608f92.828f40de>, Harvey and Kattuman (2021)\n    <doi:10.1098/rsif.2021.0179>, and Ashby, Harvey, Kattuman, and Thamotheram (2024)\n    <https://www.jbs.cam.ac.uk/wp-content/uploads/2024/03/cchle-tsgc-paper-2024.pdf>.",
    "version": "0.0",
    "maintainer": "Craig Thamotheram <cpt@tacindex.com>",
    "author": "Craig Thamotheram [aut, cre]",
    "url": "https://github.com/Craig-PT/tsgc",
    "bug_reports": "https://github.com/Craig-PT/tsgc/issues",
    "repository": "https://cran.r-project.org/package=tsgc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsgc Time Series Methods Based on Growth Curves The 'tsgc' package provides comprehensive tools for the analysis and forecasting of epidemic trajectories.\n    It is designed to model the progression of an epidemic over time while accounting for the various uncertainties\n    inherent in real-time data. Underpinned by a dynamic Gompertz model, the package adopts a state space approach,\n    using the Kalman filter for flexible and robust estimation of the non-linear growth pattern commonly observed in\n    epidemic data. The reinitialization feature enhances the model\u2019s ability to adapt to the emergence of new waves.\n    The forecasts generated by the package are of value to public health officials and researchers who need to\n    understand and predict the course of an epidemic to inform decision-making. Beyond its application in public\n    health, the package is also a useful resource for researchers and practitioners in fields where the trajectories\n    of interest resemble those of epidemics, such as innovation diffusion. The package includes functionalities for\n    data preprocessing, model fitting, and forecast visualization, as well as tools for evaluating forecast accuracy.\n    The core methodologies implemented in 'tsgc' are based on well-established statistical techniques as described in\n    Harvey and Kattuman (2020) <doi:10.1162/99608f92.828f40de>, Harvey and Kattuman (2021)\n    <doi:10.1098/rsif.2021.0179>, and Ashby, Harvey, Kattuman, and Thamotheram (2024)\n    <https://www.jbs.cam.ac.uk/wp-content/uploads/2024/03/cchle-tsgc-paper-2024.pdf>.  "
  },
  {
    "id": 22470,
    "package_name": "tsiR",
    "title": "An Implementation of the TSIR Model",
    "description": "An implementation of the time-series Susceptible-Infected-Recovered (TSIR) model using a number of different fitting options for infectious disease time series data. The manuscript based on this package can be found here <doi:10.1371/journal.pone.0185528>. The method implemented here is described by Finkenstadt and Grenfell (2000) <doi:10.1111/1467-9876.00187>.",
    "version": "0.4.3",
    "maintainer": "Alexander D. Becker <adbecker@princeton.edu>",
    "author": "Alexander D. Becker [aut, cre],\n  Sinead E. Morris [ctb],\n  Ottar N. Bjornstad [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsiR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsiR An Implementation of the TSIR Model An implementation of the time-series Susceptible-Infected-Recovered (TSIR) model using a number of different fitting options for infectious disease time series data. The manuscript based on this package can be found here <doi:10.1371/journal.pone.0185528>. The method implemented here is described by Finkenstadt and Grenfell (2000) <doi:10.1111/1467-9876.00187>.  "
  },
  {
    "id": 22471,
    "package_name": "tsibble",
    "title": "Tidy Temporal Data Frames and Tools",
    "description": "Provides a 'tbl_ts' class (the 'tsibble') for\n    temporal data in an data- and model-oriented format. The 'tsibble'\n    provides tools to easily manipulate and analyse temporal data, such as\n    filling in time gaps and aggregating over calendar periods.",
    "version": "1.1.6",
    "maintainer": "Earo Wang <earo.wang@gmail.com>",
    "author": "Earo Wang [aut, cre] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Di Cook [aut, ths] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Rob Hyndman [aut, ths] (ORCID: <https://orcid.org/0000-0002-2140-5352>),\n  Mitchell O'Hara-Wild [aut] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Tyler Smith [ctb],\n  Wil Davis [ctb]",
    "url": "https://tsibble.tidyverts.org",
    "bug_reports": "https://github.com/tidyverts/tsibble/issues",
    "repository": "https://cran.r-project.org/package=tsibble",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsibble Tidy Temporal Data Frames and Tools Provides a 'tbl_ts' class (the 'tsibble') for\n    temporal data in an data- and model-oriented format. The 'tsibble'\n    provides tools to easily manipulate and analyse temporal data, such as\n    filling in time gaps and aggregating over calendar periods.  "
  },
  {
    "id": 22472,
    "package_name": "tsibbledata",
    "title": "Diverse Datasets for 'tsibble'",
    "description": "Provides diverse datasets in the 'tsibble' data structure. These datasets are useful for learning and demonstrating how tidy temporal data can tidied, visualised, and forecasted.",
    "version": "0.4.1",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre],\n  Rob Hyndman [aut],\n  Earo Wang [aut],\n  Rakshitha Godahewa [aut],\n  Christoph Bergmeir [ctb]",
    "url": "https://tsibbledata.tidyverts.org/,\nhttps://github.com/tidyverts/tsibbledata/",
    "bug_reports": "https://github.com/tidyverts/tsibbledata/issues",
    "repository": "https://cran.r-project.org/package=tsibbledata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsibbledata Diverse Datasets for 'tsibble' Provides diverse datasets in the 'tsibble' data structure. These datasets are useful for learning and demonstrating how tidy temporal data can tidied, visualised, and forecasted.  "
  },
  {
    "id": 22473,
    "package_name": "tsibbletalk",
    "title": "Interactive Graphics for Tsibble Objects",
    "description": "A shared tsibble data easily communicates between\n    htmlwidgets on both client and server sides, powered by 'crosstalk'. A\n    shiny module is provided to visually explore periodic/aperiodic\n    temporal patterns.",
    "version": "0.1.0",
    "maintainer": "Earo Wang <earo.wang@gmail.com>",
    "author": "Earo Wang [aut, cre] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Di Cook [aut] (ORCID: <https://orcid.org/0000-0002-3813-7155>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsibbletalk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsibbletalk Interactive Graphics for Tsibble Objects A shared tsibble data easily communicates between\n    htmlwidgets on both client and server sides, powered by 'crosstalk'. A\n    shiny module is provided to visually explore periodic/aperiodic\n    temporal patterns.  "
  },
  {
    "id": 22474,
    "package_name": "tsintermittent",
    "title": "Intermittent Time Series Forecasting",
    "description": "Time series methods for intermittent demand forecasting. Includes Croston's method and its variants (Moving Average, SBA), and the TSB method. Users can obtain optimal parameters on a variety of loss functions, or use fixed ones (Kourenztes (2014) <doi:10.1016/j.ijpe.2014.06.007>). Intermittent time series classification methods and iMAPA that uses multiple temporal aggregation levels are also provided (Petropoulos & Kourenztes (2015) <doi:10.1057/jors.2014.62>).",
    "version": "1.10",
    "maintainer": "Nikolaos Kourentzes <nikolaos@kourentzes.com>",
    "author": "Nikolaos Kourentzes [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-0211-5218>),\n  Fotios Petropoulos [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3039-4955>)",
    "url": "https://kourentzes.com/forecasting/2014/06/23/intermittent-demand-forecasting-package-for-r/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsintermittent",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsintermittent Intermittent Time Series Forecasting Time series methods for intermittent demand forecasting. Includes Croston's method and its variants (Moving Average, SBA), and the TSB method. Users can obtain optimal parameters on a variety of loss functions, or use fixed ones (Kourenztes (2014) <doi:10.1016/j.ijpe.2014.06.007>). Intermittent time series classification methods and iMAPA that uses multiple temporal aggregation levels are also provided (Petropoulos & Kourenztes (2015) <doi:10.1057/jors.2014.62>).  "
  },
  {
    "id": 22475,
    "package_name": "tsissm",
    "title": "Linear Innovations State Space Unobserved Components Model",
    "description": "Unobserved components time series model using the linear innovations state space representation (single source of error) with choice of error distributions and option for dynamic variance. Methods for estimation using automatic differentiation, automatic model selection and ensembling, prediction, filtering, simulation and backtesting. Based on the model described in Hyndman et al (2012) <doi:10.1198/jasa.2011.tm09771>.",
    "version": "1.0.2",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>)",
    "url": "https://github.com/tsmodels/tsissm,\nhttps://www.nopredict.com/packages/tsissm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsissm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsissm Linear Innovations State Space Unobserved Components Model Unobserved components time series model using the linear innovations state space representation (single source of error) with choice of error distributions and option for dynamic variance. Methods for estimation using automatic differentiation, automatic model selection and ensembling, prediction, filtering, simulation and backtesting. Based on the model described in Hyndman et al (2012) <doi:10.1198/jasa.2011.tm09771>.  "
  },
  {
    "id": 22477,
    "package_name": "tsmethods",
    "title": "Time Series Methods",
    "description": "Generic methods for use in a time series probabilistic framework, allowing for a common calling convention across packages. Additional methods for time series prediction ensembles and probabilistic plotting of predictions is included. A more detailed description is available at <https://www.nopredict.com/packages/tsmethods> which shows the currently implemented methods in the 'tsmodels' framework. ",
    "version": "1.0.2",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>)",
    "url": "https://www.nopredict.com/packages/tsmethods,\nhttps://github.com/tsmodels/tsmethods",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsmethods",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsmethods Time Series Methods Generic methods for use in a time series probabilistic framework, allowing for a common calling convention across packages. Additional methods for time series prediction ensembles and probabilistic plotting of predictions is included. A more detailed description is available at <https://www.nopredict.com/packages/tsmethods> which shows the currently implemented methods in the 'tsmodels' framework.   "
  },
  {
    "id": 22478,
    "package_name": "tsmp",
    "title": "Time Series with Matrix Profile",
    "description": "A toolkit implementing the Matrix Profile concept\n    that was created by CS-UCR\n    <http://www.cs.ucr.edu/~eamonn/MatrixProfile.html>.",
    "version": "0.4.16",
    "maintainer": "Francisco Bischoff <fbischoff@med.up.pt>",
    "author": "Francisco Bischoff [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5301-8672>),\n  Michael Yeh [res, ccp, ctb] (ORCID:\n    <https://orcid.org/0000-0002-9807-2963>),\n  Diego Silva [res, ccp, ctb] (ORCID:\n    <https://orcid.org/0000-0002-5184-9413>),\n  Yan Zhu [res, ccp, ctb] (ORCID:\n    <https://orcid.org/0000-0002-5952-2108>),\n  Hoang Dau [res, ccp, ctb] (ORCID:\n    <https://orcid.org/0000-0003-2439-5185>),\n  Michele Linardi [res, ccp, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3249-2068>)",
    "url": "https://github.com/matrix-profile-foundation/tsmp",
    "bug_reports": "https://github.com/matrix-profile-foundation/tsmp/issues",
    "repository": "https://cran.r-project.org/package=tsmp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsmp Time Series with Matrix Profile A toolkit implementing the Matrix Profile concept\n    that was created by CS-UCR\n    <http://www.cs.ucr.edu/~eamonn/MatrixProfile.html>.  "
  },
  {
    "id": 22479,
    "package_name": "tsna",
    "title": "Tools for Temporal Social Network Analysis",
    "description": "Temporal SNA tools for continuous- and discrete-time longitudinal networks having vertex, edge, and attribute dynamics stored in the 'networkDynamic' format. This work was supported by grant R01HD68395 from the National Institute of Health.",
    "version": "0.3.6",
    "maintainer": "Skye Bender-deMoll <skyebend@uw.edu>",
    "author": "Skye Bender-deMoll [aut, cre],\n  Martina Morris [aut],\n  James Moody [ctb]",
    "url": "https://statnet.org/",
    "bug_reports": "https://github.com/statnet/tsna/issues",
    "repository": "https://cran.r-project.org/package=tsna",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsna Tools for Temporal Social Network Analysis Temporal SNA tools for continuous- and discrete-time longitudinal networks having vertex, edge, and attribute dynamics stored in the 'networkDynamic' format. This work was supported by grant R01HD68395 from the National Institute of Health.  "
  },
  {
    "id": 22481,
    "package_name": "tsnet",
    "title": "Fitting, Comparing, and Visualizing Networks Based on Time\nSeries Data",
    "description": "Fit, compare, and visualize Bayesian graphical vector autoregressive (GVAR) network models using 'Stan'. These models are commonly used in psychology to represent temporal and contemporaneous relationships between multiple variables in intensive longitudinal data. Fitted models can be compared with a test based on matrix norm differences of posterior point estimates to quantify the differences between two estimated networks. See also Siepe, Kloft & Heck (2024) <doi:10.31234/osf.io/uwfjc>.",
    "version": "0.2.0",
    "maintainer": "Bj\u00f6rn S. Siepe <bjoernsiepe@gmail.com>",
    "author": "Bj\u00f6rn S. Siepe [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9558-4648>),\n  Matthias Kloft [aut] (ORCID: <https://orcid.org/0000-0003-1845-6957>),\n  Daniel W. Heck [ctb] (ORCID: <https://orcid.org/0000-0002-6302-9252>)",
    "url": "https://github.com/bsiepe/tsnet",
    "bug_reports": "https://github.com/bsiepe/tsnet/issues",
    "repository": "https://cran.r-project.org/package=tsnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsnet Fitting, Comparing, and Visualizing Networks Based on Time\nSeries Data Fit, compare, and visualize Bayesian graphical vector autoregressive (GVAR) network models using 'Stan'. These models are commonly used in psychology to represent temporal and contemporaneous relationships between multiple variables in intensive longitudinal data. Fitted models can be compared with a test based on matrix norm differences of posterior point estimates to quantify the differences between two estimated networks. See also Siepe, Kloft & Heck (2024) <doi:10.31234/osf.io/uwfjc>.  "
  },
  {
    "id": 22482,
    "package_name": "tsoutliers",
    "title": "Detection of Outliers in Time Series",
    "description": "Detection of outliers in time series following the \n    Chen and Liu (1993) <DOI:10.2307/2290724> procedure. \n    Innovational outliers, additive outliers, level shifts, \n    temporary changes and seasonal level shifts are considered.",
    "version": "0.6-10",
    "maintainer": "Javier L\u00f3pez-de-Lacalle <javlacalle@yahoo.es>",
    "author": "Javier L\u00f3pez-de-Lacalle <javlacalle@yahoo.es>",
    "url": "https://jalobe.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsoutliers",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsoutliers Detection of Outliers in Time Series Detection of outliers in time series following the \n    Chen and Liu (1993) <DOI:10.2307/2290724> procedure. \n    Innovational outliers, additive outliers, level shifts, \n    temporary changes and seasonal level shifts are considered.  "
  },
  {
    "id": 22484,
    "package_name": "tspredit",
    "title": "Time Series Prediction with Integrated Tuning",
    "description": "\n  Time series prediction is a critical task in data analysis, requiring not only the selection of appropriate models, but also suitable data preprocessing and tuning strategies. \n  TSPredIT (Time Series Prediction with Integrated Tuning) is a framework that provides a seamless integration of data preprocessing, decomposition, model training, hyperparameter optimization, and evaluation. \n  Unlike other frameworks, TSPredIT emphasizes the co-optimization of both preprocessing and modeling steps, improving predictive performance. \n  It supports a variety of statistical and machine learning models, filtering techniques, outlier detection, data augmentation, and ensemble strategies. \n  More information is available in Salles et al. <doi:10.1007/978-3-662-68014-8_2>.",
    "version": "1.2.747",
    "maintainer": "Eduardo Ogasawara <eogasawara@ieee.org>",
    "author": "Eduardo Ogasawara [aut, ths, cre] (ORCID:\n    <https://orcid.org/0000-0002-0466-0626>),\n  Cristiane Gea [aut],\n  Diego Carvalho [ctb],\n  Diogo Santos [aut],\n  Eduardo Bezerra [ctb],\n  Esther Pacitti [ctb],\n  Fabio Porto [ctb],\n  Fernando Alexandrino [aut],\n  Rebecca Salles [aut],\n  Vitoria Birindiba [aut],\n  CEFET/RJ [cph]",
    "url": "https://cefet-rj-dal.github.io/tspredit/,\nhttps://github.com/cefet-rj-dal/tspredit",
    "bug_reports": "https://github.com/cefet-rj-dal/tspredit/issues",
    "repository": "https://cran.r-project.org/package=tspredit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tspredit Time Series Prediction with Integrated Tuning \n  Time series prediction is a critical task in data analysis, requiring not only the selection of appropriate models, but also suitable data preprocessing and tuning strategies. \n  TSPredIT (Time Series Prediction with Integrated Tuning) is a framework that provides a seamless integration of data preprocessing, decomposition, model training, hyperparameter optimization, and evaluation. \n  Unlike other frameworks, TSPredIT emphasizes the co-optimization of both preprocessing and modeling steps, improving predictive performance. \n  It supports a variety of statistical and machine learning models, filtering techniques, outlier detection, data augmentation, and ensemble strategies. \n  More information is available in Salles et al. <doi:10.1007/978-3-662-68014-8_2>.  "
  },
  {
    "id": 22485,
    "package_name": "tsqn",
    "title": "Applications of the Qn Estimator to Time Series (Univariate and\nMultivariate)",
    "description": "Time Series Qn is a package with applications of the Qn estimator of Rousseeuw and Croux (1993) <doi:10.1080/01621459.1993.10476408> to univariate and multivariate Time Series in time and frequency domains. More specifically, the robust estimation of autocorrelation or autocovariance matrix functions from Ma and Genton (2000, 2001) <doi:10.1111/1467-9892.00203>, <doi:10.1006/jmva.2000.1942> and Cotta (2017) <doi:10.13140/RG.2.2.14092.10883> are provided. The robust pseudo-periodogram of Molinares et. al. (2009) <doi:10.1016/j.jspi.2008.12.014> is also given. This packages also provides the M-estimator of the long-memory parameter d based on the robustification of the GPH estimator proposed by Reisen et al. (2017) <doi:10.1016/j.jspi.2017.02.008>. ",
    "version": "1.0.0",
    "maintainer": "Higor Cotta <cotta.higor@gmail.com>",
    "author": "Higor Cotta, Valderio Reisen, Pascal Bondon and C\u00e9line L\u00e9vy-Leduc",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsqn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsqn Applications of the Qn Estimator to Time Series (Univariate and\nMultivariate) Time Series Qn is a package with applications of the Qn estimator of Rousseeuw and Croux (1993) <doi:10.1080/01621459.1993.10476408> to univariate and multivariate Time Series in time and frequency domains. More specifically, the robust estimation of autocorrelation or autocovariance matrix functions from Ma and Genton (2000, 2001) <doi:10.1111/1467-9892.00203>, <doi:10.1006/jmva.2000.1942> and Cotta (2017) <doi:10.13140/RG.2.2.14092.10883> are provided. The robust pseudo-periodogram of Molinares et. al. (2009) <doi:10.1016/j.jspi.2008.12.014> is also given. This packages also provides the M-estimator of the long-memory parameter d based on the robustification of the GPH estimator proposed by Reisen et al. (2017) <doi:10.1016/j.jspi.2017.02.008>.   "
  },
  {
    "id": 22487,
    "package_name": "tsrobprep",
    "title": "Robust Preprocessing of Time Series Data",
    "description": "Methods for handling the missing values outliers are introduced in\n    this package. The recognized missing values and outliers are replaced \n    using a model-based approach. The model may consist of both autoregressive\n    components and external regressors. The methods work robust and efficient,\n    and they are fully tunable. The primary motivation for writing the package\n    was preprocessing of the energy systems data, e.g. power plant production\n    time series, but the package could be used with any time series data. For \n    details, see Narajewski et al. (2021) <doi:10.1016/j.softx.2021.100809>.",
    "version": "0.3.2",
    "maintainer": "Micha\u0142 Narajewski <michal.narajewski@uni-due.de>",
    "author": "Micha\u0142 Narajewski [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3115-0162>),\n  Jens Kley-Holsteg [aut],\n  Florian Ziel [aut] (ORCID: <https://orcid.org/0000-0002-2974-2660>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsrobprep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsrobprep Robust Preprocessing of Time Series Data Methods for handling the missing values outliers are introduced in\n    this package. The recognized missing values and outliers are replaced \n    using a model-based approach. The model may consist of both autoregressive\n    components and external regressors. The methods work robust and efficient,\n    and they are fully tunable. The primary motivation for writing the package\n    was preprocessing of the energy systems data, e.g. power plant production\n    time series, but the package could be used with any time series data. For \n    details, see Narajewski et al. (2021) <doi:10.1016/j.softx.2021.100809>.  "
  },
  {
    "id": 22488,
    "package_name": "tssim",
    "title": "Simulation of Daily and Monthly Time Series",
    "description": "Flexible simulation of time series using time series\n    components, including seasonal, calendar and outlier effects. Main\n    algorithm described in Ollech, D. (2021) <doi:10.1515/jtse-2020-0028>.",
    "version": "0.2.7",
    "maintainer": "Daniel Ollech <daniel.ollech@bundesbank.de>",
    "author": "Daniel Ollech [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tssim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tssim Simulation of Daily and Monthly Time Series Flexible simulation of time series using time series\n    components, including seasonal, calendar and outlier effects. Main\n    algorithm described in Ollech, D. (2021) <doi:10.1515/jtse-2020-0028>.  "
  },
  {
    "id": 22489,
    "package_name": "tstests",
    "title": "Time Series Goodness of Fit and Forecast Evaluation Tests",
    "description": "Goodness of Fit and Forecast Evaluation Tests for timeseries models. Includes, among others, the Generalized Method of Moments (GMM) Orthogonality Test of Hansen (1982), the Nyblom (1989) parameter constancy test, the sign-bias test of Engle and Ng (1993), and a range of tests for value at risk and expected shortfall evaluation.",
    "version": "1.0.1",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>)",
    "url": "https://www.nopredict.com/packages/tstests,\nhttps://github.com/tsmodels/tstests",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tstests",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tstests Time Series Goodness of Fit and Forecast Evaluation Tests Goodness of Fit and Forecast Evaluation Tests for timeseries models. Includes, among others, the Generalized Method of Moments (GMM) Orthogonality Test of Hansen (1982), the Nyblom (1989) parameter constancy test, the sign-bias test of Engle and Ng (1993), and a range of tests for value at risk and expected shortfall evaluation.  "
  },
  {
    "id": 22490,
    "package_name": "tstools",
    "title": "A Time Series Toolbox for Official Statistics",
    "description": "Plot official statistics' time series conveniently: automatic\n    legends, highlight windows, stacked bar chars with positive and\n    negative contributions, sum-as-line option, two y-axes with automatic\n    horizontal grids that fit both axes and other popular chart types.\n    'tstools' comes with a plethora of defaults to let you plot without\n    setting an abundance of parameters first, but gives you the\n    flexibility to tweak the defaults. In addition to charts, 'tstools'\n    provides a super fast, 'data.table' backed time series I/O that allows\n    the user to export / import long format, wide format and transposed\n    wide format data to various file types.",
    "version": "0.4.4",
    "maintainer": "St\u00e9phane Bisinger <bisinger@kof.ethz.ch>",
    "author": "Matthias Bannert [aut],\n  Severin Thoeni [aut],\n  St\u00e9phane Bisinger [aut, cre]",
    "url": "https://kof-ch.github.io/tstools/,\nhttps://github.com/KOF-ch/tstools",
    "bug_reports": "https://github.com/KOF-ch/tstools/issues",
    "repository": "https://cran.r-project.org/package=tstools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tstools A Time Series Toolbox for Official Statistics Plot official statistics' time series conveniently: automatic\n    legends, highlight windows, stacked bar chars with positive and\n    negative contributions, sum-as-line option, two y-axes with automatic\n    horizontal grids that fit both axes and other popular chart types.\n    'tstools' comes with a plethora of defaults to let you plot without\n    setting an abundance of parameters first, but gives you the\n    flexibility to tweak the defaults. In addition to charts, 'tstools'\n    provides a super fast, 'data.table' backed time series I/O that allows\n    the user to export / import long format, wide format and transposed\n    wide format data to various file types.  "
  },
  {
    "id": 22491,
    "package_name": "tsutils",
    "title": "Time Series Exploration, Modelling and Forecasting",
    "description": "Includes: (i) tests and visualisations that can help the modeller explore time series components and perform decomposition; (ii) modelling shortcuts, such as functions to construct lagmatrices and seasonal dummy variables of various forms; (iii) an implementation of the Theta method; (iv) tools to facilitate the design of the forecasting process, such as ABC-XYZ analyses; and (v) \"quality of life\" functions, such as treating time series for trailing and leading values.",
    "version": "0.9.4",
    "maintainer": "Nikolaos Kourentzes <nikolaos@kourentzes.com>",
    "author": "Nikolaos Kourentzes [aut, cre],\n  Ivan Svetunkov [ctb],\n  Oliver Schaer [ctb]",
    "url": "https://github.com/trnnick/tsutils/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsutils Time Series Exploration, Modelling and Forecasting Includes: (i) tests and visualisations that can help the modeller explore time series components and perform decomposition; (ii) modelling shortcuts, such as functions to construct lagmatrices and seasonal dummy variables of various forms; (iii) an implementation of the Theta method; (iv) tools to facilitate the design of the forecasting process, such as ABC-XYZ analyses; and (v) \"quality of life\" functions, such as treating time series for trailing and leading values.  "
  },
  {
    "id": 22493,
    "package_name": "tsviz",
    "title": "Easy and Interactive Time Series Visualization",
    "description": "An 'RStudio' add-in to visualize time series. Time series are searched in the global environment as data.frame objects with a column of type date and a column of type numeric. Interactive charts are produced using 'plotly' package.",
    "version": "0.1.0",
    "maintainer": "Emanuele Fabbiani <emanuele.fabbiani@xtreamers.io>",
    "author": "Marta Peroni [aut],\n  Emanuele Fabbiani [cre]",
    "url": "https://github.com/donlelef/tsviz",
    "bug_reports": "https://github.com/donlelef/tsviz/issues",
    "repository": "https://cran.r-project.org/package=tsviz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsviz Easy and Interactive Time Series Visualization An 'RStudio' add-in to visualize time series. Time series are searched in the global environment as data.frame objects with a column of type date and a column of type numeric. Interactive charts are produced using 'plotly' package.  "
  },
  {
    "id": 22495,
    "package_name": "tswge",
    "title": "Time Series for Data Science",
    "description": "Accompanies the texts Time Series for Data Science with R by Woodward, Sadler and Robertson & Applied Time Series Analysis with R, 2nd edition by Woodward, Gray, and Elliott.  It is helpful for data analysis and for time series instruction.",
    "version": "2.2.0",
    "maintainer": "Bivin Sadler <bsadler@smu.edu>",
    "author": "Wayne Woodward [aut],\n  Bivin Sadler [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tswge",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tswge Time Series for Data Science Accompanies the texts Time Series for Data Science with R by Woodward, Sadler and Robertson & Applied Time Series Analysis with R, 2nd edition by Woodward, Gray, and Elliott.  It is helpful for data analysis and for time series instruction.  "
  },
  {
    "id": 22496,
    "package_name": "tsxtreme",
    "title": "Bayesian Modelling of Extremal Dependence in Time Series",
    "description": "Characterisation of the extremal dependence structure of time series, avoiding pre-processing and filtering as done typically with peaks-over-threshold methods. It uses the conditional approach of Heffernan and Tawn (2004) <DOI:10.1111/j.1467-9868.2004.02050.x> which is very flexible in terms of extremal and asymptotic dependence structures, and Bayesian methods improve efficiency and allow for deriving measures of uncertainty. For example, the extremal index, related to the size of clusters in time, can be estimated and samples from its posterior distribution obtained.",
    "version": "0.3.4",
    "maintainer": "Thomas Lugrin <thomas.lugrin@alumni.epfl.ch>",
    "author": "Thomas Lugrin [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsxtreme",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsxtreme Bayesian Modelling of Extremal Dependence in Time Series Characterisation of the extremal dependence structure of time series, avoiding pre-processing and filtering as done typically with peaks-over-threshold methods. It uses the conditional approach of Heffernan and Tawn (2004) <DOI:10.1111/j.1467-9868.2004.02050.x> which is very flexible in terms of extremal and asymptotic dependence structures, and Bayesian methods improve efficiency and allow for deriving measures of uncertainty. For example, the extremal index, related to the size of clusters in time, can be estimated and samples from its posterior distribution obtained.  "
  },
  {
    "id": 22538,
    "package_name": "twc",
    "title": "Terrestrial Water Cycle",
    "description": "An open-access tool/framework that constitutes the core functions\n  to analyze terrestrial water cycle data across various spatio-temporal scales.",
    "version": "0.0.2",
    "maintainer": "Mijael Rodrigo Vargas Godoy <mirovago@gmail.com>",
    "author": "Mijael Rodrigo Vargas Godoy [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1828-9266>),\n  Yannis Markonis [aut] (ORCID: <https://orcid.org/0000-0003-0144-8969>)",
    "url": "https://github.com/imarkonis/twc",
    "bug_reports": "https://github.com/imarkonis/twc/issues",
    "repository": "https://cran.r-project.org/package=twc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "twc Terrestrial Water Cycle An open-access tool/framework that constitutes the core functions\n  to analyze terrestrial water cycle data across various spatio-temporal scales.  "
  },
  {
    "id": 22539,
    "package_name": "twdtw",
    "title": "Time-Weighted Dynamic Time Warping",
    "description": "Implements Time-Weighted Dynamic Time Warping (TWDTW), \n    a measure for quantifying time series similarity. The TWDTW algorithm, \n    described in Maus et al. (2016) <doi:10.1109/JSTARS.2016.2517118> and \n    Maus et al. (2019) <doi:10.18637/jss.v088.i05>, is applicable to multi-dimensional \n    time series of various resolutions. It is particularly suitable for comparing \n    time series with seasonality for environmental and ecological data analysis, \n    covering domains such as remote sensing imagery, climate data, hydrology, \n    and animal movement. The 'twdtw' package offers a user-friendly 'R' interface, \n    efficient 'Fortran' routines for TWDTW calculations, flexible time weighting \n    definitions, as well as utilities for time series preprocessing and visualization.",
    "version": "1.0-1",
    "maintainer": "Victor Maus <vwmaus1@gmail.com>",
    "author": "Victor Maus [aut, cre] (ORCID: <https://orcid.org/0000-0002-7385-4723>)",
    "url": "https://github.com/vwmaus/twdtw/",
    "bug_reports": "https://github.com/vwmaus/twdtw/issues/",
    "repository": "https://cran.r-project.org/package=twdtw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "twdtw Time-Weighted Dynamic Time Warping Implements Time-Weighted Dynamic Time Warping (TWDTW), \n    a measure for quantifying time series similarity. The TWDTW algorithm, \n    described in Maus et al. (2016) <doi:10.1109/JSTARS.2016.2517118> and \n    Maus et al. (2019) <doi:10.18637/jss.v088.i05>, is applicable to multi-dimensional \n    time series of various resolutions. It is particularly suitable for comparing \n    time series with seasonality for environmental and ecological data analysis, \n    covering domains such as remote sensing imagery, climate data, hydrology, \n    and animal movement. The 'twdtw' package offers a user-friendly 'R' interface, \n    efficient 'Fortran' routines for TWDTW calculations, flexible time weighting \n    definitions, as well as utilities for time series preprocessing and visualization.  "
  },
  {
    "id": 22575,
    "package_name": "uGMAR",
    "title": "Estimate Univariate Gaussian and Student's t Mixture\nAutoregressive Models",
    "description": "Maximum likelihood estimation of univariate Gaussian Mixture Autoregressive (GMAR),\n    Student's t Mixture Autoregressive (StMAR), and Gaussian and Student's t Mixture Autoregressive (G-StMAR) models, \n    quantile residual tests, graphical diagnostics, forecast and simulate from GMAR, StMAR and G-StMAR processes. \n    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2015) <doi:10.1111/jtsa.12108>, \n    Mika Meitz, Daniel Preve, Pentti Saikkonen (2023) <doi:10.1080/03610926.2021.1916531>,\n    Savi Virolainen (2022) <doi:10.1515/snde-2020-0060>.",
    "version": "3.6.0",
    "maintainer": "Savi Virolainen <savi.virolainen@helsinki.fi>",
    "author": "Savi Virolainen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5075-6821>)",
    "url": "",
    "bug_reports": "https://github.com/saviviro/uGMAR/issues",
    "repository": "https://cran.r-project.org/package=uGMAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "uGMAR Estimate Univariate Gaussian and Student's t Mixture\nAutoregressive Models Maximum likelihood estimation of univariate Gaussian Mixture Autoregressive (GMAR),\n    Student's t Mixture Autoregressive (StMAR), and Gaussian and Student's t Mixture Autoregressive (G-StMAR) models, \n    quantile residual tests, graphical diagnostics, forecast and simulate from GMAR, StMAR and G-StMAR processes. \n    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2015) <doi:10.1111/jtsa.12108>, \n    Mika Meitz, Daniel Preve, Pentti Saikkonen (2023) <doi:10.1080/03610926.2021.1916531>,\n    Savi Virolainen (2022) <doi:10.1515/snde-2020-0060>.  "
  },
  {
    "id": 22589,
    "package_name": "ufRisk",
    "title": "Risk Measure Calculation in Financial TS",
    "description": "Enables the user to calculate Value at Risk (VaR) and Expected \n    Shortfall (ES) by means of various parametric and semiparametric \n    GARCH-type models. For the latter the estimation of the nonparametric scale\n    function is carried out by means of a data-driven smoothing approach. Model\n    quality, in terms of forecasting VaR and ES, can be assessed by means of \n    various backtesting methods such as the traffic light test for VaR and a \n    newly developed traffic light test for ES. The approaches implemented in \n    this package are described in e.g. Feng Y., Beran J., Letmathe S. and \n    Ghosh S. (2020) <https://ideas.repec.org/p/pdn/ciepap/137.html> as well as \n    Letmathe S., Feng Y. and Uhde A. (2021) \n    <https://ideas.repec.org/p/pdn/ciepap/141.html>. ",
    "version": "1.0.7",
    "maintainer": "Sebastian Letmathe <sebastian.letmathe@uni-paderborn.de>",
    "author": "Yuanhua Feng [aut] (Paderborn University, Germany),\n  Xuehai Zhang [aut] (Former research associate at Paderborn University,\n    Germany),\n  Christian Peitz [aut] (Paderborn University, Germany),\n  Dominik Schulz [aut] (Paderborn University, Germany),\n  Shujie Li [aut] (Paderborn Universtiy, Germany),\n  Sebastian Letmathe [aut, cre] (Paderborn University, Germany)",
    "url": "https://wiwi.uni-paderborn.de/en/dep4/feng/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ufRisk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ufRisk Risk Measure Calculation in Financial TS Enables the user to calculate Value at Risk (VaR) and Expected \n    Shortfall (ES) by means of various parametric and semiparametric \n    GARCH-type models. For the latter the estimation of the nonparametric scale\n    function is carried out by means of a data-driven smoothing approach. Model\n    quality, in terms of forecasting VaR and ES, can be assessed by means of \n    various backtesting methods such as the traffic light test for VaR and a \n    newly developed traffic light test for ES. The approaches implemented in \n    this package are described in e.g. Feng Y., Beran J., Letmathe S. and \n    Ghosh S. (2020) <https://ideas.repec.org/p/pdn/ciepap/137.html> as well as \n    Letmathe S., Feng Y. and Uhde A. (2021) \n    <https://ideas.repec.org/p/pdn/ciepap/141.html>.   "
  },
  {
    "id": 22591,
    "package_name": "ugatsdb",
    "title": "Uganda Time Series Database API",
    "description": "An R API providing easy access to a relational database with macroeconomic, \n             financial and development related time series data for Uganda. \n             Overall more than 5000 series at varying frequency (daily, monthly, \n             quarterly, annual in fiscal or calendar years) can be accessed through \n             the API. The data is provided by the Bank of Uganda, \n             the Ugandan Ministry of Finance, Planning and Economic Development,\n             the IMF and the World Bank. The database is being updated once a month. ",
    "version": "0.2.3",
    "maintainer": "Sebastian Krantz <sebastian.krantz@graduateinstitute.ch>",
    "author": "Sebastian Krantz [aut, cre]",
    "url": "https://mepd.finance.go.ug/apps.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ugatsdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ugatsdb Uganda Time Series Database API An R API providing easy access to a relational database with macroeconomic, \n             financial and development related time series data for Uganda. \n             Overall more than 5000 series at varying frequency (daily, monthly, \n             quarterly, annual in fiscal or calendar years) can be accessed through \n             the API. The data is provided by the Bank of Uganda, \n             the Ugandan Ministry of Finance, Planning and Economic Development,\n             the IMF and the World Bank. The database is being updated once a month.   "
  },
  {
    "id": 22619,
    "package_name": "unfold",
    "title": "Mapping Hidden Geometry into Future Sequences",
    "description": "A variational mapping approach that reveals and expands future temporal dynamics from folded high-dimensional geometric distance spaces, unfold turns a set of time series into a 4D block of pairwise distances between reframed windows, learns a variational mapper that maps those distances to the next reframed window, and produces horizon-wise predictive functions for each input series. In short: it unfolds the future path of each series from a folded geometric distance representation.",
    "version": "1.0.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/unfold",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=unfold",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "unfold Mapping Hidden Geometry into Future Sequences A variational mapping approach that reveals and expands future temporal dynamics from folded high-dimensional geometric distance spaces, unfold turns a set of time series into a 4D block of pairwise distances between reframed windows, learns a variational mapper that maps those distances to the next reframed window, and produces horizon-wise predictive functions for each input series. In short: it unfolds the future path of each series from a folded geometric distance representation.  "
  },
  {
    "id": 22658,
    "package_name": "unsystation",
    "title": "Stationarity Test Based on Unsystematic Sub-Sampling",
    "description": "Performs a test for second-order stationarity of time series based\n    on unsystematic sub-samples.",
    "version": "0.2.1",
    "maintainer": "Haeran Cho <haeran.cho@bristol.ac.uk>",
    "author": "Haeran Cho [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=unsystation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "unsystation Stationarity Test Based on Unsystematic Sub-Sampling Performs a test for second-order stationarity of time series based\n    on unsystematic sub-samples.  "
  },
  {
    "id": 22663,
    "package_name": "uotm",
    "title": "Uncertainty of Time Series Model Selection Methods",
    "description": "We propose a new procedure, called model uncertainty variance, which can quantify the uncertainty of model selection on Autoregressive Moving Average models. The model uncertainty variance not pay attention to the accuracy of prediction, but focus on model selection uncertainty and providing more information of the model selection results. And to estimate the model measures, we propose an simplify and faster algorithm based on bootstrap method, which is proven to be effective and feasible by Monte-Carlo simulation. At the same time, we also made some optimizations and adjustments to the Model Confidence Bounds algorithm, so that it can be applied to the time series model selection method. The consistency of the algorithm result is also verified by Monte-Carlo simulation. We propose a new procedure, called model uncertainty variance, which can quantify the uncertainty of model selection on Autoregressive Moving Average models. The model uncertainty variance focuses on model selection uncertainty and providing more information of the model selection results. To estimate the model uncertainty variance, we propose an simplified and faster algorithm based on bootstrap method, which is proven to be effective and feasible by Monte-Carlo simulation. At the same time, we also made some optimizations and adjustments to the Model Confidence Bounds algorithm, so that it can be applied to the time series model selection method. The consistency of the algorithm result is also verified by Monte-Carlo simulation. Please see Li,Y., Luo,Y., Ferrari,D., Hu,X. and Qin,Y. (2019) Model Confidence Bounds for Variable Selection. Biometrics, 75:392-403.<DOI:10.1111/biom.13024> for more information.",
    "version": "0.1.6",
    "maintainer": "Heming Deng Developer <dheming@ruc.edu.cn>",
    "author": "Heming Deng Developer [aut, cre, cph],\n  Sunan Gao Dev [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=uotm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "uotm Uncertainty of Time Series Model Selection Methods We propose a new procedure, called model uncertainty variance, which can quantify the uncertainty of model selection on Autoregressive Moving Average models. The model uncertainty variance not pay attention to the accuracy of prediction, but focus on model selection uncertainty and providing more information of the model selection results. And to estimate the model measures, we propose an simplify and faster algorithm based on bootstrap method, which is proven to be effective and feasible by Monte-Carlo simulation. At the same time, we also made some optimizations and adjustments to the Model Confidence Bounds algorithm, so that it can be applied to the time series model selection method. The consistency of the algorithm result is also verified by Monte-Carlo simulation. We propose a new procedure, called model uncertainty variance, which can quantify the uncertainty of model selection on Autoregressive Moving Average models. The model uncertainty variance focuses on model selection uncertainty and providing more information of the model selection results. To estimate the model uncertainty variance, we propose an simplified and faster algorithm based on bootstrap method, which is proven to be effective and feasible by Monte-Carlo simulation. At the same time, we also made some optimizations and adjustments to the Model Confidence Bounds algorithm, so that it can be applied to the time series model selection method. The consistency of the algorithm result is also verified by Monte-Carlo simulation. Please see Li,Y., Luo,Y., Ferrari,D., Hu,X. and Qin,Y. (2019) Model Confidence Bounds for Variable Selection. Biometrics, 75:392-403.<DOI:10.1111/biom.13024> for more information.  "
  },
  {
    "id": 22675,
    "package_name": "urca",
    "title": "Unit Root and Cointegration Tests for Time Series Data",
    "description": "Unit root and cointegration tests encountered in applied \n econometric analysis are implemented.",
    "version": "1.3-4",
    "maintainer": "Bernhard Pfaff <bernhard@pfaffikus.de>",
    "author": "Bernhard Pfaff [aut, cre],\n  Eric Zivot [ctb],\n  Matthieu Stigler [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=urca",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "urca Unit Root and Cointegration Tests for Time Series Data Unit root and cointegration tests encountered in applied \n econometric analysis are implemented.  "
  },
  {
    "id": 22680,
    "package_name": "uroot",
    "title": "Unit Root Tests for Seasonal Time Series",
    "description": "Seasonal unit roots and seasonal stability tests.\n    P-values based on response surface regressions are available for both tests.\n    P-values based on bootstrap are available for seasonal unit root tests.",
    "version": "2.1-3",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Javier L\u00f3pez-de-Lacalle [aut],\n  Georgi N. Boshnakov [cre]",
    "url": "https://geobosh.github.io/uroot/",
    "bug_reports": "https://github.com/GeoBosh/uroot/issues",
    "repository": "https://cran.r-project.org/package=uroot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "uroot Unit Root Tests for Seasonal Time Series Seasonal unit roots and seasonal stability tests.\n    P-values based on response surface regressions are available for both tests.\n    P-values based on bootstrap are available for seasonal unit root tests.  "
  },
  {
    "id": 22700,
    "package_name": "usl",
    "title": "Analyze System Scalability with the Universal Scalability Law",
    "description": "The Universal Scalability Law (Gunther 2007)\n    <doi:10.1007/978-3-540-31010-5> is a model to predict hardware and\n    software scalability. It uses system capacity as a function of load to\n    forecast the scalability for the system.",
    "version": "3.0.4",
    "maintainer": "Stefan Moeding <stm@moeding.net>",
    "author": "Neil J. Gunther [aut],\n  Stefan Moeding [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/smoeding/usl/issues",
    "repository": "https://cran.r-project.org/package=usl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "usl Analyze System Scalability with the Universal Scalability Law The Universal Scalability Law (Gunther 2007)\n    <doi:10.1007/978-3-540-31010-5> is a model to predict hardware and\n    software scalability. It uses system capacity as a function of load to\n    forecast the scalability for the system.  "
  },
  {
    "id": 22716,
    "package_name": "utsf",
    "title": "Univariate Time Series Forecasting",
    "description": "An engine for univariate time series forecasting using\n    different regression models in an autoregressive way. The engine\n    provides an uniform interface for applying the different models. \n    Furthermore, it is extensible so that users can easily apply their\n    own regression models to univariate time series forecasting and \n    benefit from all the features of the engine, such as preprocessings\n    or estimation of forecast accuracy.",
    "version": "1.3.1",
    "maintainer": "Francisco Martinez <fmartin@ujaen.es>",
    "author": "Maria Pilar Frias-Bustamante [aut] (ORCID:\n    <https://orcid.org/0000-0001-6886-0953>),\n  Francisco Martinez [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5206-1898>)",
    "url": "https://github.com/franciscomartinezdelrio/utsf",
    "bug_reports": "https://github.com/franciscomartinezdelrio/utsf/issues",
    "repository": "https://cran.r-project.org/package=utsf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "utsf Univariate Time Series Forecasting An engine for univariate time series forecasting using\n    different regression models in an autoregressive way. The engine\n    provides an uniform interface for applying the different models. \n    Furthermore, it is extensible so that users can easily apply their\n    own regression models to univariate time series forecasting and \n    benefit from all the features of the engine, such as preprocessings\n    or estimation of forecast accuracy.  "
  },
  {
    "id": 22752,
    "package_name": "valueprhr",
    "title": "Value-Price Analysis with Bayesian and Panel Data Methods",
    "description": "Provides tools for analyzing the relationship between direct\n    prices (based on labor values) and prices of production using Bayesian\n    generalized linear models, panel data methods, partial least squares\n    regression, canonical correlation analysis, and panel vector\n    autoregression. Includes functions for model comparison, out-of-sample\n    validation, and structural break detection. Here, methods use raw accounting data with explicit temporal structure, following Gomez Julian (2023) <doi:10.17605/OSF.IO/7J8KF>\n    and standard econometric techniques for panel data analysis.",
    "version": "0.1.0",
    "maintainer": "Jose Mauricio Gomez Julian <isadore.nabi@pm.me>",
    "author": "Jose Mauricio Gomez Julian [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-2412-3150>)",
    "url": "https://github.com/isadorenabi/valueprhr",
    "bug_reports": "https://github.com/isadorenabi/valueprhr/issues",
    "repository": "https://cran.r-project.org/package=valueprhr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "valueprhr Value-Price Analysis with Bayesian and Panel Data Methods Provides tools for analyzing the relationship between direct\n    prices (based on labor values) and prices of production using Bayesian\n    generalized linear models, panel data methods, partial least squares\n    regression, canonical correlation analysis, and panel vector\n    autoregression. Includes functions for model comparison, out-of-sample\n    validation, and structural break detection. Here, methods use raw accounting data with explicit temporal structure, following Gomez Julian (2023) <doi:10.17605/OSF.IO/7J8KF>\n    and standard econometric techniques for panel data analysis.  "
  },
  {
    "id": 22777,
    "package_name": "vars",
    "title": "VAR Modelling",
    "description": "Estimation, lag selection, diagnostic testing, forecasting, causality analysis, forecast error variance decomposition and impulse response functions of VAR models and estimation of SVAR and SVEC models.",
    "version": "1.6-1",
    "maintainer": "Bernhard Pfaff <bernhard@pfaffikus.de>",
    "author": "Bernhard Pfaff [aut, cre],\n  Matthieu Stigler [ctb]",
    "url": "https://www.pfaffikus.de",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vars VAR Modelling Estimation, lag selection, diagnostic testing, forecasting, causality analysis, forecast error variance decomposition and impulse response functions of VAR models and estimation of SVAR and SVEC models.  "
  },
  {
    "id": 22787,
    "package_name": "vccp",
    "title": "Vine Copula Change Point Detection in Multivariate Time Series",
    "description": "Implements the Vine Copula Change Point (VCCP) methodology for the estimation of the number and location of multiple change points in the vine copula structure of multivariate time series. The method uses vine copulas, various state-of-the-art segmentation methods to identify multiple change points, and a likelihood ratio test or the stationary bootstrap for inference. The vine copulas allow for various forms of dependence between time series including tail, symmetric and asymmetric dependence. The functions have been extensively tested on simulated multivariate time series data and fMRI data. For details on the VCCP methodology, please see Xiong & Cribben (2021).",
    "version": "0.1.1",
    "maintainer": "Xin Xiong <xinxiong@hsph.harvard.edu>",
    "author": "Xin Xiong [aut, cre],\n  Ivor Cribben [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vccp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vccp Vine Copula Change Point Detection in Multivariate Time Series Implements the Vine Copula Change Point (VCCP) methodology for the estimation of the number and location of multiple change points in the vine copula structure of multivariate time series. The method uses vine copulas, various state-of-the-art segmentation methods to identify multiple change points, and a likelihood ratio test or the stationary bootstrap for inference. The vine copulas allow for various forms of dependence between time series including tail, symmetric and asymmetric dependence. The functions have been extensively tested on simulated multivariate time series data and fMRI data. For details on the VCCP methodology, please see Xiong & Cribben (2021).  "
  },
  {
    "id": 22797,
    "package_name": "vctsfr",
    "title": "Visualizing Collections of Time Series Forecasts",
    "description": "A way of visualizing collections of time series and, optionally\n    their future values, forecasts for their future values and prediction\n    intervals for the forecasts. A web-based GUI can be used to display the\n    information in a collection of time series.",
    "version": "0.1.1",
    "maintainer": "Francisco Martinez <fmartin@ujaen.es>",
    "author": "Maria Pilar Frias-Bustamante [aut] (ORCID:\n    <https://orcid.org/0000-0001-6886-0953>),\n  Francisco Martinez [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5206-1898>)",
    "url": "https://github.com/franciscomartinezdelrio/vctsfr",
    "bug_reports": "https://github.com/franciscomartinezdelrio/vctsfr/issues",
    "repository": "https://cran.r-project.org/package=vctsfr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vctsfr Visualizing Collections of Time Series Forecasts A way of visualizing collections of time series and, optionally\n    their future values, forecasts for their future values and prediction\n    intervals for the forecasts. A web-based GUI can be used to display the\n    information in a collection of time series.  "
  },
  {
    "id": 22806,
    "package_name": "vectorwavelet",
    "title": "Vector Wavelet Coherence for Multiple Time Series",
    "description": "New wavelet methodology (vector wavelet coherence) (Oygur, T., Unal, G, 2020 <doi:10.1007/s40435-020-00706-y>) \n  to handle dynamic co-movements of multivariate time series via extending multiple and quadruple wavelet coherence methodologies. \n  This package can be used to perform multiple wavelet coherence, quadruple wavelet coherence, and n-dimensional vector wavelet coherence analyses.",
    "version": "0.1.0",
    "maintainer": "Tunc Oygur <info@tuncoygur.com.tr>",
    "author": "Tunc Oygur [aut, cre],\n  Gazanfer Unal [aut],\n  Tarik C. Gouhier [ctb],\n  Aslak Grinsted [ctb],\n  Viliam Simko [ctb]",
    "url": "https://github.com/toygur/vectorwavelet",
    "bug_reports": "https://github.com/toygur/vectorwavelet/issues",
    "repository": "https://cran.r-project.org/package=vectorwavelet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vectorwavelet Vector Wavelet Coherence for Multiple Time Series New wavelet methodology (vector wavelet coherence) (Oygur, T., Unal, G, 2020 <doi:10.1007/s40435-020-00706-y>) \n  to handle dynamic co-movements of multivariate time series via extending multiple and quadruple wavelet coherence methodologies. \n  This package can be used to perform multiple wavelet coherence, quadruple wavelet coherence, and n-dimensional vector wavelet coherence analyses.  "
  },
  {
    "id": 22830,
    "package_name": "verification",
    "title": "Weather Forecast Verification",
    "description": "Utilities for verifying discrete, continuous and probabilistic forecasts, and forecasts expressed as parametric distributions are included.",
    "version": "1.45",
    "maintainer": "Eric Gilleland <eric.gilleland@colostate.edu>",
    "author": "Eric Gilleland [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8058-7643>),\n  Matt Pocernich [ctb],\n  Sabrina Wahl [ctb],\n  Ronald Frenette [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=verification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "verification Weather Forecast Verification Utilities for verifying discrete, continuous and probabilistic forecasts, and forecasts expressed as parametric distributions are included.  "
  },
  {
    "id": 22869,
    "package_name": "virtualPollen",
    "title": "Simulating Pollen Curves from Virtual Taxa with Different Life\nand Niche Traits",
    "description": "Tools to generate virtual environmental drivers with a given temporal autocorrelation, and to simulate pollen curves at annual resolution over millennial time-scales based on these drivers and virtual taxa with different life traits and niche features. It also provides the means to simulate quasi-realistic pollen-data conditions by applying simulated accumulation rates and given depth intervals between consecutive samples.",
    "version": "1.0.2",
    "maintainer": "Blas M. Benito <blasbenito@gmail.com>",
    "author": "Blas M. Benito [aut, cre]",
    "url": "https://github.com/BlasBenito/virtualPollen",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=virtualPollen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "virtualPollen Simulating Pollen Curves from Virtual Taxa with Different Life\nand Niche Traits Tools to generate virtual environmental drivers with a given temporal autocorrelation, and to simulate pollen curves at annual resolution over millennial time-scales based on these drivers and virtual taxa with different life traits and niche features. It also provides the means to simulate quasi-realistic pollen-data conditions by applying simulated accumulation rates and given depth intervals between consecutive samples.  "
  },
  {
    "id": 22895,
    "package_name": "vital",
    "title": "Tidy Analysis Tools for Mortality, Fertility, Migration and\nPopulation Data",
    "description": "Analysing vital statistics based on tools\n    consistent with the tidyverse. Tools are provided for data visualization,\n    life table calculations, computing net migration numbers, Lee-Carter\n    modelling; functional data modelling and forecasting.",
    "version": "2.0.1",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  Sixian Tang [aut] (ORCID: <https://orcid.org/0000-0002-7292-462X>),\n  Miles McBain [ctb] (ORCID: <https://orcid.org/0000-0003-2865-2548>),\n  Mitchell O'Hara-Wild [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>)",
    "url": "https://pkg.robjhyndman.com/vital/,\nhttps://github.com/robjhyndman/vital",
    "bug_reports": "https://github.com/robjhyndman/vital/issues",
    "repository": "https://cran.r-project.org/package=vital",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vital Tidy Analysis Tools for Mortality, Fertility, Migration and\nPopulation Data Analysing vital statistics based on tools\n    consistent with the tidyverse. Tools are provided for data visualization,\n    life table calculations, computing net migration numbers, Lee-Carter\n    modelling; functional data modelling and forecasting.  "
  },
  {
    "id": 22897,
    "package_name": "vivainsights",
    "title": "Analyze and Visualize Data from 'Microsoft Viva Insights'",
    "description": "Provides a versatile range of functions, including exploratory data analysis, time-series analysis, organizational network analysis, and data validation, whilst at the same time implements a set of best practices in analyzing and visualizing data specific to 'Microsoft Viva Insights'.",
    "version": "0.7.0",
    "maintainer": "Martin Chan <martin.chan@microsoft.com>",
    "author": "Martin Chan [aut, cre],\n  Carlos Morales [aut]",
    "url": "https://microsoft.github.io/vivainsights/",
    "bug_reports": "https://github.com/microsoft/vivainsights/issues/",
    "repository": "https://cran.r-project.org/package=vivainsights",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vivainsights Analyze and Visualize Data from 'Microsoft Viva Insights' Provides a versatile range of functions, including exploratory data analysis, time-series analysis, organizational network analysis, and data validation, whilst at the same time implements a set of best practices in analyzing and visualizing data specific to 'Microsoft Viva Insights'.  "
  },
  {
    "id": 22904,
    "package_name": "vmdTDNN",
    "title": "VMD Based Time Delay Neural Network Model",
    "description": "Forecasting univariate time series with Variational Mode Decomposition (VMD) based time delay neural network models.For method details see Konstantin, D.and Dominique, Z. (2014). <doi:10.1109/TSP.2013.2288675>. ",
    "version": "0.1.1",
    "maintainer": "Kapil Choudhary <kapiliasri@gmail.com>",
    "author": "Kapil Choudhary [aut, cre],\n  Girish Kumar Jha [aut, ths, ctb],\n  Rajender Parsad [aut, ctb],\n  Ronit Jaiswal [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vmdTDNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vmdTDNN VMD Based Time Delay Neural Network Model Forecasting univariate time series with Variational Mode Decomposition (VMD) based time delay neural network models.For method details see Konstantin, D.and Dominique, Z. (2014). <doi:10.1109/TSP.2013.2288675>.   "
  },
  {
    "id": 22939,
    "package_name": "vse4ts",
    "title": "Identify Memory Patterns in Time Series Using Variance Scale\nExponent",
    "description": "Methods for calculating the variance scale exponent to\n    identify memory patterns in time series data. Includes tests for white\n    noise, short memory, and long memory. See Fu, H. et al. (2018)\n    <doi:10.1016/j.physa.2018.06.092>.",
    "version": "1.0.0",
    "maintainer": "Mengyang Zheng <mengyang.zheng@outlook.com>",
    "author": "Mengyang Zheng [aut, cre],\n  Hui Fu [aut]",
    "url": "https://z-my-cn.github.io/vse4ts/",
    "bug_reports": "https://github.com/z-my-cn/vse4ts/issues",
    "repository": "https://cran.r-project.org/package=vse4ts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vse4ts Identify Memory Patterns in Time Series Using Variance Scale\nExponent Methods for calculating the variance scale exponent to\n    identify memory patterns in time series data. Includes tests for white\n    noise, short memory, and long memory. See Fu, H. et al. (2018)\n    <doi:10.1016/j.physa.2018.06.092>.  "
  },
  {
    "id": 22988,
    "package_name": "warp",
    "title": "Group Dates",
    "description": "Tooling to group dates by a variety of periods including:\n    yearly, monthly, by second, by week of the month, and more.  The\n    groups are defined in such a way that they also represent the distance\n    between dates in terms of the period. This extracts valuable\n    information that can be used in further calculations that rely on a\n    specific temporal spacing between observations.",
    "version": "0.2.2",
    "maintainer": "Davis Vaughan <davis@posit.co>",
    "author": "Davis Vaughan [aut, cre],\n  Posit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://github.com/DavisVaughan/warp,\nhttps://davisvaughan.github.io/warp/",
    "bug_reports": "https://github.com/DavisVaughan/warp/issues",
    "repository": "https://cran.r-project.org/package=warp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "warp Group Dates Tooling to group dates by a variety of periods including:\n    yearly, monthly, by second, by week of the month, and more.  The\n    groups are defined in such a way that they also represent the distance\n    between dates in terms of the period. This extracts valuable\n    information that can be used in further calculations that rely on a\n    specific temporal spacing between observations.  "
  },
  {
    "id": 22991,
    "package_name": "washeR",
    "title": "Time Series Outlier Detection",
    "description": "Time series outlier detection with non parametric test. This is a new outlier detection methodology (washer): efficient for time saving elaboration and implementation procedures, adaptable for general assumptions and for needing very short time series, reliable and effective as involving robust non parametric test. You can find two approaches: single time series (a vector) and grouped time series (a data frame). For other informations: Andrea Venturini (2011) Statistica - Universita di Bologna, Vol.71, pp.329-344. For an informal explanation look at R-bloggers on web.",
    "version": "0.1.3",
    "maintainer": "Andrea Venturini <andrea.venturini@bancaditalia.it>",
    "author": "Andrea Venturini",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=washeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "washeR Time Series Outlier Detection Time series outlier detection with non parametric test. This is a new outlier detection methodology (washer): efficient for time saving elaboration and implementation procedures, adaptable for general assumptions and for needing very short time series, reliable and effective as involving robust non parametric test. You can find two approaches: single time series (a vector) and grouped time series (a data frame). For other informations: Andrea Venturini (2011) Statistica - Universita di Bologna, Vol.71, pp.329-344. For an informal explanation look at R-bloggers on web.  "
  },
  {
    "id": 23001,
    "package_name": "wavScalogram",
    "title": "Wavelet Scalogram Tools for Time Series Analysis",
    "description": "Provides scalogram based wavelet tools for time series analysis: wavelet power spectrum, scalogram, windowed scalogram, windowed scalogram difference (see Bolos et al. (2017) <doi:10.1016/j.amc.2017.05.046>), scale index and windowed scale index (Benitez et al. (2010) <doi:10.1016/j.camwa.2010.05.010>).",
    "version": "1.1.3",
    "maintainer": "Vicente J. Bolos <vicente.bolos@uv.es>",
    "author": "Vicente J. Bolos and Rafael Benitez",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wavScalogram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wavScalogram Wavelet Scalogram Tools for Time Series Analysis Provides scalogram based wavelet tools for time series analysis: wavelet power spectrum, scalogram, windowed scalogram, windowed scalogram difference (see Bolos et al. (2017) <doi:10.1016/j.amc.2017.05.046>), scale index and windowed scale index (Benitez et al. (2010) <doi:10.1016/j.camwa.2010.05.010>).  "
  },
  {
    "id": 23005,
    "package_name": "wavemulcor",
    "title": "Wavelet Routines for Global and Local Multiple Regression and\nCorrelation",
    "description": "Wavelet routines that calculate single sets of wavelet\n    multiple regressions and correlations, and cross-regressions and\n    cross-correlations from a multivariate time series.  Dynamic versions\n    of the routines allow the wavelet local multiple (cross-)regressions\n    and (cross-)correlations to evolve over time.",
    "version": "3.1.2",
    "maintainer": "Javier Fernandez-Macho <javier.fernandezmacho@ehu.es>",
    "author": "Javier Fernandez-Macho [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5970-4382>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wavemulcor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wavemulcor Wavelet Routines for Global and Local Multiple Regression and\nCorrelation Wavelet routines that calculate single sets of wavelet\n    multiple regressions and correlations, and cross-regressions and\n    cross-correlations from a multivariate time series.  Dynamic versions\n    of the routines allow the wavelet local multiple (cross-)regressions\n    and (cross-)correlations to evolve over time.  "
  },
  {
    "id": 23008,
    "package_name": "waveslim",
    "title": "Basic Wavelet Routines for One-, Two-, and Three-Dimensional\nSignal Processing",
    "description": "Basic wavelet routines for time series (1D), image (2D) and array \n  (3D) analysis.  The code provided here is based on wavelet methodology \n  developed in Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001); \n  the dual-tree complex wavelet transform (DTCWT) from Kingsbury (1999, 2001) as\n  implemented by Selesnick; and Hilbert wavelet pairs (Selesnick 2001, 2002).  \n  All figures in chapters 4-7 of GSW (2001) are reproducible using this package \n  and R code available at the book website(s) below.",
    "version": "1.8.5",
    "maintainer": "Brandon Whitcher <bwhitcher@gmail.com>",
    "author": "Brandon Whitcher",
    "url": "https://waveslim.blogspot.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=waveslim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "waveslim Basic Wavelet Routines for One-, Two-, and Three-Dimensional\nSignal Processing Basic wavelet routines for time series (1D), image (2D) and array \n  (3D) analysis.  The code provided here is based on wavelet methodology \n  developed in Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001); \n  the dual-tree complex wavelet transform (DTCWT) from Kingsbury (1999, 2001) as\n  implemented by Selesnick; and Hilbert wavelet pairs (Selesnick 2001, 2002).  \n  All figures in chapters 4-7 of GSW (2001) are reproducible using this package \n  and R code available at the book website(s) below.  "
  },
  {
    "id": 23009,
    "package_name": "wavethresh",
    "title": "Wavelets Statistics and Transforms",
    "description": "Performs 1, 2 and 3D real and complex-valued wavelet transforms,\n\tnondecimated transforms, wavelet packet transforms, nondecimated\n\twavelet packet transforms, multiple wavelet transforms,\n\tcomplex-valued wavelet transforms, wavelet shrinkage for\n\tvarious kinds of data, locally stationary wavelet time series,\n\tnonstationary multiscale transfer function modeling, density\n\testimation.",
    "version": "4.7.3",
    "maintainer": "Guy Nason <g.nason@imperial.ac.uk>",
    "author": "Guy Nason [aut, cre],\n  Stuart Barber [ctb],\n  Tim Downie [ctb],\n  Piotr Frylewicz [ctb],\n  Arne Kovac [ctb],\n  Todd Ogden [ctb],\n  Bernard Silverman [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wavethresh",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wavethresh Wavelets Statistics and Transforms Performs 1, 2 and 3D real and complex-valued wavelet transforms,\n\tnondecimated transforms, wavelet packet transforms, nondecimated\n\twavelet packet transforms, multiple wavelet transforms,\n\tcomplex-valued wavelet transforms, wavelet shrinkage for\n\tvarious kinds of data, locally stationary wavelet time series,\n\tnonstationary multiscale transfer function modeling, density\n\testimation.  "
  },
  {
    "id": 23016,
    "package_name": "wbsts",
    "title": "Multiple Change-Point Detection for Nonstationary Time Series",
    "description": "Implements detection for the number and locations of\n    the change-points in a time series using the Wild Binary Segmentation and\n    the Locally Stationary Wavelet model of Korkas and Fryzlewicz (2017) <doi:10.5705/ss.202015.0262>.",
    "version": "2.1",
    "maintainer": "Karolos Korkas <kkorkas@yahoo.co.uk>",
    "author": "Karolos Korkas and Piotr Fryzlewicz",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wbsts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wbsts Multiple Change-Point Detection for Nonstationary Time Series Implements detection for the number and locations of\n    the change-points in a time series using the Wild Binary Segmentation and\n    the Locally Stationary Wavelet model of Korkas and Fryzlewicz (2017) <doi:10.5705/ss.202015.0262>.  "
  },
  {
    "id": 23028,
    "package_name": "weakARMA",
    "title": "Tools for the Analysis of Weak ARMA Models",
    "description": "Numerous time series admit autoregressive moving average (ARMA)\n  representations, in which the errors are uncorrelated but not necessarily\n  independent.\n  These models are called weak ARMA by opposition to the standard ARMA models, \n  also called strong ARMA models, in which the error terms are supposed to be \n  independent and identically distributed (iid).\n  This package allows the study of nonlinear time series models through weak \n  ARMA representations.\n  It determines identification, estimation and validation for ARMA models and \n  for AR and MA models in particular. \n  Functions can also be used in the strong case.\n  This package also works on white noises by omitting arguments 'p', 'q', 'ar'\n  and 'ma'.\n  See Francq, C. and Zako\u00efan, J. (1998) <doi:10.1016/S0378-3758(97)00139-0> and \n  Boubacar Ma\u00efnassara, Y. and Saussereau, B. (2018)\n  <doi:10.1080/01621459.2017.1380030> for more details.",
    "version": "1.0.3",
    "maintainer": "Julien Yves Rolland <julien.rolland@univ-fcomte.fr>",
    "author": "Yacouba Boubacar Ma\u00efnassara [aut] (ORCID:\n    <https://orcid.org/0000-0002-8604-5407>),\n  Julien Yves Rolland [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0960-6688>),\n  Coraline Parguey [ctb],\n  Vincent Mouillot [ctb]",
    "url": "https://plmlab.math.cnrs.fr/jrolland/weakARMA",
    "bug_reports": "https://plmlab.math.cnrs.fr/jrolland/weakARMA/-/issues",
    "repository": "https://cran.r-project.org/package=weakARMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "weakARMA Tools for the Analysis of Weak ARMA Models Numerous time series admit autoregressive moving average (ARMA)\n  representations, in which the errors are uncorrelated but not necessarily\n  independent.\n  These models are called weak ARMA by opposition to the standard ARMA models, \n  also called strong ARMA models, in which the error terms are supposed to be \n  independent and identically distributed (iid).\n  This package allows the study of nonlinear time series models through weak \n  ARMA representations.\n  It determines identification, estimation and validation for ARMA models and \n  for AR and MA models in particular. \n  Functions can also be used in the strong case.\n  This package also works on white noises by omitting arguments 'p', 'q', 'ar'\n  and 'ma'.\n  See Francq, C. and Zako\u00efan, J. (1998) <doi:10.1016/S0378-3758(97)00139-0> and \n  Boubacar Ma\u00efnassara, Y. and Saussereau, B. (2018)\n  <doi:10.1080/01621459.2017.1380030> for more details.  "
  },
  {
    "id": 23030,
    "package_name": "weathR",
    "title": "Interact with the U.S. National Weather Service API",
    "description": "Enables interaction with the National Weather Service application programming web-interface for fetching of real-time and forecast meteorological data. Users can provide latitude and longitude, Automated Surface Observing System identifier, or Automated Weather Observing System identifier to fetch recent weather observations and recent forecasts for the given location or station. Additionally, auxiliary functions exist to identify stations nearest to a point, convert wind direction from character to degrees, and fetch active warnings. Results are returned as simple feature objects whenever possible.",
    "version": "0.1.0",
    "maintainer": "Jeffrey Fowler <JeffreyF6120@gmail.com>",
    "author": "Jeffrey Fowler [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0003-9448-0980>)",
    "url": "https://github.com/JeffreyFowler/weathR",
    "bug_reports": "https://github.com/JeffreyFowler/weathR/issues",
    "repository": "https://cran.r-project.org/package=weathR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "weathR Interact with the U.S. National Weather Service API Enables interaction with the National Weather Service application programming web-interface for fetching of real-time and forecast meteorological data. Users can provide latitude and longitude, Automated Surface Observing System identifier, or Automated Weather Observing System identifier to fetch recent weather observations and recent forecasts for the given location or station. Additionally, auxiliary functions exist to identify stations nearest to a point, convert wind direction from character to degrees, and fetch active warnings. Results are returned as simple feature objects whenever possible.  "
  },
  {
    "id": 23031,
    "package_name": "weatherindices",
    "title": "Calculate Weather Indices",
    "description": "Weather indices represent the overall weekly effect of a weather variable on crop yield throughout the cropping season. This package contains functions that can convert the weekly weather data into yearly weighted Weather indices with weights being the correlation coefficient between weekly weather data over the years and crop yield over the years. This can be done for an individual weather variable and for two weather variables at a time as the interaction effect. This method was first devised by Jain, RC, Agrawal R, and Jha, MP (1980), \"Effect of climatic variables on rice yield and its forecast\",MAUSAM, 31(4), 591\u2013596, <doi:10.54302/mausam.v31i4.3477>. Later, the method have been used by various researchers and the latest can found in Gupta, AK, Sarkar, KA, Dhakre, DS, & Bhattacharya, D (2022), \"Weather Based Potato Yield Modelling using Statistical and Machine Learning Technique\",Environment and Ecology, 40(3B), 1444\u20131449,<https://www.environmentandecology.com/volume-40-2022>.",
    "version": "0.1.0",
    "maintainer": "Akhilesh Kumar Gupta <akhileshgupta.ouat@gmail.com>",
    "author": "Akhilesh Kumar Gupta [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-9380-1103>),\n  Kader Ali Sarkar [ths],\n  Digvijay Singh Dhakre [ths],\n  Debasis Bhattacharya [ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=weatherindices",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "weatherindices Calculate Weather Indices Weather indices represent the overall weekly effect of a weather variable on crop yield throughout the cropping season. This package contains functions that can convert the weekly weather data into yearly weighted Weather indices with weights being the correlation coefficient between weekly weather data over the years and crop yield over the years. This can be done for an individual weather variable and for two weather variables at a time as the interaction effect. This method was first devised by Jain, RC, Agrawal R, and Jha, MP (1980), \"Effect of climatic variables on rice yield and its forecast\",MAUSAM, 31(4), 591\u2013596, <doi:10.54302/mausam.v31i4.3477>. Later, the method have been used by various researchers and the latest can found in Gupta, AK, Sarkar, KA, Dhakre, DS, & Bhattacharya, D (2022), \"Weather Based Potato Yield Modelling using Statistical and Machine Learning Technique\",Environment and Ecology, 40(3B), 1444\u20131449,<https://www.environmentandecology.com/volume-40-2022>.  "
  },
  {
    "id": 23064,
    "package_name": "wex",
    "title": "Compute the Exact Observation Weights for the Kalman Filter and\nSmoother",
    "description": "Computes the exact observation weights for the Kalman filter and smoother, based on the method described in Koopman and Harvey (2003) <www.sciencedirect.com/science/article/pii/S0165188902000611>.\n    The package supports in-depth exploration of state-space models, enabling researchers and practitioners to extract meaningful insights from time series data.\n    This functionality is especially valuable in dynamic factor models, where the computed weights can be used to decompose the contributions of individual variables to the latent factors.\n    See the README file for examples.",
    "version": "0.1.0",
    "maintainer": "Tim Ginker <timginker@gmail.com>",
    "author": "Tim Ginker [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7138-5417>)",
    "url": "https://github.com/timginker/wex",
    "bug_reports": "https://github.com/timginker/wex/issues",
    "repository": "https://cran.r-project.org/package=wex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wex Compute the Exact Observation Weights for the Kalman Filter and\nSmoother Computes the exact observation weights for the Kalman filter and smoother, based on the method described in Koopman and Harvey (2003) <www.sciencedirect.com/science/article/pii/S0165188902000611>.\n    The package supports in-depth exploration of state-space models, enabling researchers and practitioners to extract meaningful insights from time series data.\n    This functionality is especially valuable in dynamic factor models, where the computed weights can be used to decompose the contributions of individual variables to the latent factors.\n    See the README file for examples.  "
  },
  {
    "id": 23092,
    "package_name": "widals",
    "title": "Weighting by Inverse Distance with Adaptive Least Squares",
    "description": "Computationally easy modeling, interpolation, forecasting of massive temporal-spacial data.",
    "version": "0.6.2",
    "maintainer": "Dave Zes <zesdave@gmail.com>",
    "author": "Dave Zes [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=widals",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "widals Weighting by Inverse Distance with Adaptive Least Squares Computationally easy modeling, interpolation, forecasting of massive temporal-spacial data.  "
  },
  {
    "id": 23105,
    "package_name": "wildlifeDI",
    "title": "Calculate Indices of Dynamic Interaction for Wildlife Tracking\nData",
    "description": "Dynamic interaction refers to spatial-temporal associations in the movements of two (or more) animals. This package provides tools for calculating a suite of indices used for quantifying dynamic interaction with wildlife telemetry data. For more information on each of the methods employed see the references within. The package (as of version >= 0.3) also has new tools for automating contact analysis in large tracking datasets. The package (as of version 1.0) uses the 'move2' class of objects for working with tracking dataset.",
    "version": "1.0.1",
    "maintainer": "Jed Long <jed.long@uwo.ca>",
    "author": "Jed Long [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2815-0399>)",
    "url": "https://github.com/jedalong/wildlifeDI",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wildlifeDI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wildlifeDI Calculate Indices of Dynamic Interaction for Wildlife Tracking\nData Dynamic interaction refers to spatial-temporal associations in the movements of two (or more) animals. This package provides tools for calculating a suite of indices used for quantifying dynamic interaction with wildlife telemetry data. For more information on each of the methods employed see the references within. The package (as of version >= 0.3) also has new tools for automating contact analysis in large tracking datasets. The package (as of version 1.0) uses the 'move2' class of objects for working with tracking dataset.  "
  },
  {
    "id": 23132,
    "package_name": "womblR",
    "title": "Spatiotemporal Boundary Detection Model for Areal Unit Data",
    "description": "Implements a spatiotemporal boundary detection model with a dissimilarity\n    metric for areal data with inference in a Bayesian setting using Markov chain\n    Monte Carlo (MCMC). The response variable can be modeled as Gaussian (no nugget),\n    probit or Tobit link and spatial correlation is introduced at each time point\n    through a conditional autoregressive (CAR) prior. Temporal correlation is introduced\n    through a hierarchical structure and can be specified as exponential or first-order\n    autoregressive. Full details of the package can be found in the accompanying vignette.\n    Furthermore, the details of the package can be found in \"Diagnosing Glaucoma \n    Progression with Visual Field Data Using a Spatiotemporal Boundary Detection Method\", \n    by Berchuck et al (2019) <doi:10.1080/01621459.2018.1537911>.",
    "version": "1.0.6",
    "maintainer": "Samuel I. Berchuck <sib2@duke.edu>",
    "author": "Samuel I. Berchuck [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5705-3144>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=womblR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "womblR Spatiotemporal Boundary Detection Model for Areal Unit Data Implements a spatiotemporal boundary detection model with a dissimilarity\n    metric for areal data with inference in a Bayesian setting using Markov chain\n    Monte Carlo (MCMC). The response variable can be modeled as Gaussian (no nugget),\n    probit or Tobit link and spatial correlation is introduced at each time point\n    through a conditional autoregressive (CAR) prior. Temporal correlation is introduced\n    through a hierarchical structure and can be specified as exponential or first-order\n    autoregressive. Full details of the package can be found in the accompanying vignette.\n    Furthermore, the details of the package can be found in \"Diagnosing Glaucoma \n    Progression with Visual Field Data Using a Spatiotemporal Boundary Detection Method\", \n    by Berchuck et al (2019) <doi:10.1080/01621459.2018.1537911>.  "
  },
  {
    "id": 23152,
    "package_name": "worldbank",
    "title": "Client for World Banks's 'Indicators' and 'Poverty and\nInequality Platform (PIP)' APIs",
    "description": "Download and search data from the 'World Bank Indicators\n    API', which provides access to nearly 16,000 time series indicators.\n    See\n    <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation>\n    for further details about the API.",
    "version": "0.7.1",
    "maintainer": "Maximilian M\u00fccke <muecke.maximilian@gmail.com>",
    "author": "Maximilian M\u00fccke [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9432-9795>)",
    "url": "https://m-muecke.github.io/worldbank/,\nhttps://github.com/m-muecke/worldbank",
    "bug_reports": "https://github.com/m-muecke/worldbank/issues",
    "repository": "https://cran.r-project.org/package=worldbank",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "worldbank Client for World Banks's 'Indicators' and 'Poverty and\nInequality Platform (PIP)' APIs Download and search data from the 'World Bank Indicators\n    API', which provides access to nearly 16,000 time series indicators.\n    See\n    <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation>\n    for further details about the API.  "
  },
  {
    "id": 23160,
    "package_name": "wpeR",
    "title": "Streamlined Analysis of Wild Pedigree Data",
    "description": "Analyzing pedigree data of wild\n    populations. While primarily designed to process outputs from the\n    'COLONY' (Jones & Wang (2010) <doi:10.1111/j.1755-0998.2009.02787.x>)\n    pedigree reconstruction software, it can also accommodate\n    data from other sources. By linking reconstructed pedigrees with\n    genetic sample metadata, 'wpeR' produces spatial and temporal\n    visualizations as well as tabular summaries that support\n    interpretation of family structures and dynamics. The main goal of the\n    package is to provide a solution for the analysis of\n    complex wild pedigree data and to help the user to gain insights\n    into genetic relationships within wild animal populations.",
    "version": "0.1.0",
    "maintainer": "Gregor Simcic <grega0simcic@gmail.com>",
    "author": "Tomaz Skrbinsek [aut],\n  Gregor Simcic [aut, cre]",
    "url": "https://gr3602.github.io/wpeR/",
    "bug_reports": "https://github.com/GR3602/wpeR/issues",
    "repository": "https://cran.r-project.org/package=wpeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wpeR Streamlined Analysis of Wild Pedigree Data Analyzing pedigree data of wild\n    populations. While primarily designed to process outputs from the\n    'COLONY' (Jones & Wang (2010) <doi:10.1111/j.1755-0998.2009.02787.x>)\n    pedigree reconstruction software, it can also accommodate\n    data from other sources. By linking reconstructed pedigrees with\n    genetic sample metadata, 'wpeR' produces spatial and temporal\n    visualizations as well as tabular summaries that support\n    interpretation of family structures and dynamics. The main goal of the\n    package is to provide a solution for the analysis of\n    complex wild pedigree data and to help the user to gain insights\n    into genetic relationships within wild animal populations.  "
  },
  {
    "id": 23168,
    "package_name": "wqc",
    "title": "Wavelet Quantile Correlation Analysis",
    "description": "Estimate and plot wavelet quantile correlations(Kumar and Padakandla,2022) between two time series. Wavelet quantile correlation is used to capture the dependency between two time series across quantiles and different frequencies. This method is useful in identifying potential hedges and safe-haven instruments for investment purposes. See Kumar and Padakandla(2022) <doi:10.1016/j.frl.2022.102707> for further details.",
    "version": "0.1.2",
    "maintainer": "Anoop S Kumar <akumar.sasikumar@gmail.com>",
    "author": "Anoop S Kumar [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wqc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wqc Wavelet Quantile Correlation Analysis Estimate and plot wavelet quantile correlations(Kumar and Padakandla,2022) between two time series. Wavelet quantile correlation is used to capture the dependency between two time series across quantiles and different frequencies. This method is useful in identifying potential hedges and safe-haven instruments for investment purposes. See Kumar and Padakandla(2022) <doi:10.1016/j.frl.2022.102707> for further details.  "
  },
  {
    "id": 23169,
    "package_name": "wql",
    "title": "Exploring Water Quality Monitoring Data",
    "description": "Functions to assist in the processing and\n    exploration of data from environmental monitoring programs.\n    The package name stands for \"water quality\" and reflects the\n    original focus on time series data for physical and chemical\n    properties of water, as well as the biota. Intended for\n    programs that sample approximately monthly, quarterly or\n    annually at discrete stations, a feature of many legacy data\n    sets. Most of the functions should be useful for analysis of\n    similar-frequency time series regardless of the subject\n    matter.",
    "version": "1.0.3",
    "maintainer": "Jemma Stachelek <jemma.stachelek@gmail.com>",
    "author": "Alan Jassby [aut],\n  James Cloern [ctb],\n  Jemma Stachelek [ctb, cre]",
    "url": "https://github.com/jsta/wql",
    "bug_reports": "https://github.com/jsta/wql/issues",
    "repository": "https://cran.r-project.org/package=wql",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wql Exploring Water Quality Monitoring Data Functions to assist in the processing and\n    exploration of data from environmental monitoring programs.\n    The package name stands for \"water quality\" and reflects the\n    original focus on time series data for physical and chemical\n    properties of water, as well as the biota. Intended for\n    programs that sample approximately monthly, quarterly or\n    annually at discrete stations, a feature of many legacy data\n    sets. Most of the functions should be useful for analysis of\n    similar-frequency time series regardless of the subject\n    matter.  "
  },
  {
    "id": 23185,
    "package_name": "wsjplot",
    "title": "Style Time Series Plots Like the Wall Street Journal",
    "description": "Easily override the default visual choices in 'ggplot2' to make \n    your time series plots look more like the Wall Street Journal. Specific \n    theme design choices include omitting x-axis grid lines and displaying \n    sparse light grey y-axis grid lines. Additionally, this allows to label \n    the y-axis scales with your units only displayed on the top-most number, \n    while also removing the bottom most number (unless specifically \n    overridden). The goal is visual simplicity, because who has time to waste \n    looking at a cluttered graph? ",
    "version": "0.1.0",
    "maintainer": "Stephen Lee <smlee.981@gmail.com>",
    "author": "Stephen Lee [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wsjplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wsjplot Style Time Series Plots Like the Wall Street Journal Easily override the default visual choices in 'ggplot2' to make \n    your time series plots look more like the Wall Street Journal. Specific \n    theme design choices include omitting x-axis grid lines and displaying \n    sparse light grey y-axis grid lines. Additionally, this allows to label \n    the y-axis scales with your units only displayed on the top-most number, \n    while also removing the bottom most number (unless specifically \n    overridden). The goal is visual simplicity, because who has time to waste \n    looking at a cluttered graph?   "
  },
  {
    "id": 23191,
    "package_name": "wv",
    "title": "Wavelet Variance",
    "description": "Provides a series of tools to compute and plot quantities related to classical and robust wavelet variance for time series and regular lattices. More details can be found, for example, in Serroukh, A., Walden, A.T., & Percival, D.B. (2000) <doi:10.2307/2669537> and Guerrier, S. & Molinari, R. (2016) <doi:10.48550/arXiv.1607.05858>.  ",
    "version": "0.1.3",
    "maintainer": "St\u00e9phane Guerrier <stef.guerrier@gmail.com>",
    "author": "St\u00e9phane Guerrier [aut, cre],\n  James Balamuta [aut],\n  Justin Lee [aut],\n  Roberto Molinari [aut],\n  Yuming Zhang [aut],\n  Mucyo Karemera [aut],\n  Nathanael Claussen [ctb],\n  Haotian Xu [ctb],\n  Lionel Voirol [ctb]",
    "url": "https://github.com/SMAC-Group/wv",
    "bug_reports": "https://github.com/SMAC-Group/wv/issues",
    "repository": "https://cran.r-project.org/package=wv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wv Wavelet Variance Provides a series of tools to compute and plot quantities related to classical and robust wavelet variance for time series and regular lattices. More details can be found, for example, in Serroukh, A., Walden, A.T., & Percival, D.B. (2000) <doi:10.2307/2669537> and Guerrier, S. & Molinari, R. (2016) <doi:10.48550/arXiv.1607.05858>.    "
  },
  {
    "id": 23192,
    "package_name": "wwntests",
    "title": "Hypothesis Tests for Functional Time Series",
    "description": "Provides a collection of white noise hypothesis tests for functional time series and related visualizations. \n  These include tests based on the norms of autocovariance operators that are built under both strong and weak \n  white noise assumptions. Additionally, tests based on the spectral density operator and on principal component\n  dimensional reduction are included, which are built under strong white noise assumptions. \n  Also, this package provides goodness-of-fit tests for functional autoregressive of order 1 models.\n  These methods are described in Kokoszka et al. (2017) <doi:10.1016/j.jmva.2017.08.004>, Characiejus and Rice (2019) \n  <doi:10.1016/j.ecosta.2019.01.003>, Gabrys and Kokoszka (2007) <doi:10.1198/016214507000001111>, \n  and Kim et al. (2023) <doi: 10.1214/23-SS143>\n  respectively.",
    "version": "1.1.0",
    "maintainer": "Mihyun Kim <mihyun.kim@mail.wvu.edu>",
    "author": "Mihyun Kim [aut, cre],\n  Daniel Petoukhov [aut]",
    "url": "",
    "bug_reports": "https://github.com/veritasmih/wwntests/issues",
    "repository": "https://cran.r-project.org/package=wwntests",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wwntests Hypothesis Tests for Functional Time Series Provides a collection of white noise hypothesis tests for functional time series and related visualizations. \n  These include tests based on the norms of autocovariance operators that are built under both strong and weak \n  white noise assumptions. Additionally, tests based on the spectral density operator and on principal component\n  dimensional reduction are included, which are built under strong white noise assumptions. \n  Also, this package provides goodness-of-fit tests for functional autoregressive of order 1 models.\n  These methods are described in Kokoszka et al. (2017) <doi:10.1016/j.jmva.2017.08.004>, Characiejus and Rice (2019) \n  <doi:10.1016/j.ecosta.2019.01.003>, Gabrys and Kokoszka (2007) <doi:10.1198/016214507000001111>, \n  and Kim et al. (2023) <doi: 10.1214/23-SS143>\n  respectively.  "
  },
  {
    "id": 23193,
    "package_name": "wxgenR",
    "title": "A Stochastic Weather Generator with Seasonality",
    "description": "A weather generator to simulate precipitation and temperature for regions with seasonality. Users input training data containing precipitation, temperature, and seasonality (up to 26 seasons). Including weather season as a training variable allows users to explore the effects of potential changes in season duration as well as average start- and end-time dates due to phenomena like climate change. Data for training should be a single time series but can originate from station data, basin averages, grid cells, etc.\n    Bearup, L., Gangopadhyay, S., & Mikkelson, K. (2021). \"Hydroclimate Analysis Lower Santa Cruz River Basin Study (Technical Memorandum No ENV-2020-056).\" Bureau of Reclamation.\n    Gangopadhyay, S., Bearup, L. A., Verdin, A., Pruitt, T., Halper, E., & Shamir, E. (2019, December 1). \"A collaborative stochastic weather generator for climate impacts assessment in the Lower Santa Cruz River Basin, Arizona.\" Fall Meeting 2019, American Geophysical Union. <https://ui.adsabs.harvard.edu/abs/2019AGUFMGC41G1267G>.",
    "version": "1.4.4",
    "maintainer": "David Woodson <dwoodson@usbr.gov>",
    "author": "Subhrendu Gangopadhyay [aut],\n  Lindsay Bearup [aut],\n  David Woodson [aut, cre],\n  Marketa McGuire [aut],\n  Andrew Verdin [aut],\n  Eylon Shamir [aut],\n  Eve Halper [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wxgenR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wxgenR A Stochastic Weather Generator with Seasonality A weather generator to simulate precipitation and temperature for regions with seasonality. Users input training data containing precipitation, temperature, and seasonality (up to 26 seasons). Including weather season as a training variable allows users to explore the effects of potential changes in season duration as well as average start- and end-time dates due to phenomena like climate change. Data for training should be a single time series but can originate from station data, basin averages, grid cells, etc.\n    Bearup, L., Gangopadhyay, S., & Mikkelson, K. (2021). \"Hydroclimate Analysis Lower Santa Cruz River Basin Study (Technical Memorandum No ENV-2020-056).\" Bureau of Reclamation.\n    Gangopadhyay, S., Bearup, L. A., Verdin, A., Pruitt, T., Halper, E., & Shamir, E. (2019, December 1). \"A collaborative stochastic weather generator for climate impacts assessment in the Lower Santa Cruz River Basin, Arizona.\" Fall Meeting 2019, American Geophysical Union. <https://ui.adsabs.harvard.edu/abs/2019AGUFMGC41G1267G>.  "
  },
  {
    "id": 23198,
    "package_name": "x12",
    "title": "Interface to 'X12-ARIMA'/'X13-ARIMA-SEATS' and Structure for\nBatch Processing of Seasonal Adjustment",
    "description": "The 'X13-ARIMA-SEATS' <https://www.census.gov/data/software/x13as.html> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.",
    "version": "1.11.0",
    "maintainer": "Alexander Kowarik <alexander.kowarik@statistik.gv.at>",
    "author": "Alexander Kowarik [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>),\n  Angelika Meraner [aut]",
    "url": "https://github.com/statistikat/x12",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=x12",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "x12 Interface to 'X12-ARIMA'/'X13-ARIMA-SEATS' and Structure for\nBatch Processing of Seasonal Adjustment The 'X13-ARIMA-SEATS' <https://www.census.gov/data/software/x13as.html> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.  "
  },
  {
    "id": 23199,
    "package_name": "x13binary",
    "title": "Provide the 'x13ashtml' Seasonal Adjustment Binary",
    "description": "The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.",
    "version": "1.1.61.1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Christoph Sax [aut] (ORCID: <https://orcid.org/0000-0002-7192-7044>),\n  Kirill M\u00fcller [ctb] (ORCID: <https://orcid.org/0000-0002-1416-3412>),\n  Jeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Michael Antonov [ctb]",
    "url": "https://github.com/x13org/x13binary",
    "bug_reports": "https://github.com/x13org/x13binary/issues/",
    "repository": "https://cran.r-project.org/package=x13binary",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "x13binary Provide the 'x13ashtml' Seasonal Adjustment Binary The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.  "
  },
  {
    "id": 23246,
    "package_name": "xmrr",
    "title": "Generate XMR Control Chart Data from Time-Series Data",
    "description": "XMRs combine X-Bar control charts and Moving Range control charts. These functions also will recalculate the reference lines when significant change has occurred. ",
    "version": "1.1.1",
    "maintainer": "Alex Zanidean <AZanidean@mhc.ab.ca>",
    "author": "Alex Zanidean [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/Zanidean/xmrr/issues",
    "repository": "https://cran.r-project.org/package=xmrr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xmrr Generate XMR Control Chart Data from Time-Series Data XMRs combine X-Bar control charts and Moving Range control charts. These functions also will recalculate the reference lines when significant change has occurred.   "
  },
  {
    "id": 23249,
    "package_name": "xpect",
    "title": "Probabilistic Time Series Forecasting with XGBoost and Conformal\nInference",
    "description": "Implements a probabilistic approach to time series forecasting combining XGBoost regression with conformal inference methods. The package provides functionality for generating predictive distributions, evaluating uncertainty, and optimizing hyperparameters using Bayesian, coarse-to-fine, or random search strategies.",
    "version": "1.0",
    "maintainer": "Giancarlo Vercellino <giancarlo.vercellino@gmail.com>",
    "author": "Giancarlo Vercellino [aut, cre, cph]",
    "url": "https://rpubs.com/giancarlo_vercellino/xpect",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xpect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xpect Probabilistic Time Series Forecasting with XGBoost and Conformal\nInference Implements a probabilistic approach to time series forecasting combining XGBoost regression with conformal inference methods. The package provides functionality for generating predictive distributions, evaluating uncertainty, and optimizing hyperparameters using Bayesian, coarse-to-fine, or random search strategies.  "
  },
  {
    "id": 23260,
    "package_name": "xsp",
    "title": "The Chi-Square Periodogram",
    "description": "The circadian period of a time series data is predicted and the statistical significance of the periodicity are calculated using the chi-square periodogram.",
    "version": "0.1.2",
    "maintainer": "Hitoshi Iuchi <hiuchi@sfc.keio.ac.jp>",
    "author": "Hitoshi Iuchi, Rikuhiro G. Yamada",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xsp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xsp The Chi-Square Periodogram The circadian period of a time series data is predicted and the statistical significance of the periodicity are calculated using the chi-square periodogram.  "
  },
  {
    "id": 23262,
    "package_name": "xts",
    "title": "eXtensible Time Series",
    "description": "Provide for uniform handling of R's different time-based data classes by extending zoo, maximizing native format information preservation and allowing for user level customization and extension, while simplifying cross-class interoperability.",
    "version": "0.14.1",
    "maintainer": "Joshua M. Ulrich <josh.m.ulrich@gmail.com>",
    "author": "Jeffrey A. Ryan [aut, cph],\n  Joshua M. Ulrich [cre, aut],\n  Ross Bennett [ctb],\n  Corwin Joy [ctb]",
    "url": "https://joshuaulrich.github.io/xts/,\nhttps://github.com/joshuaulrich/xts",
    "bug_reports": "https://github.com/joshuaulrich/xts/issues",
    "repository": "https://cran.r-project.org/package=xts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xts eXtensible Time Series Provide for uniform handling of R's different time-based data classes by extending zoo, maximizing native format information preservation and allowing for user level customization and extension, while simplifying cross-class interoperability.  "
  },
  {
    "id": 23290,
    "package_name": "yodel",
    "title": "A General Bayesian Model Averaging Helper",
    "description": "Provides helper functions to perform Bayesian model averaging\n    using Markov chain Monte Carlo samples from separate models. Calculates\n    weights and obtains draws from the model-averaged posterior for quantities\n    of interest specified by the user. Weight calculations can be done using\n    marginal likelihoods or log-predictive likelihoods as in Ando, T., & Tsay,\n    R. (2010) <doi:10.1016/j.ijforecast.2009.08.001>.",
    "version": "1.0.0",
    "maintainer": "Richard Payne <paynestatistics@gmail.com>",
    "author": "Richard Payne [aut, cre],\n  Eli Lilly and Company [cph]",
    "url": "https://github.com/rich-payne/yodel",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=yodel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "yodel A General Bayesian Model Averaging Helper Provides helper functions to perform Bayesian model averaging\n    using Markov chain Monte Carlo samples from separate models. Calculates\n    weights and obtains draws from the model-averaged posterior for quantities\n    of interest specified by the user. Weight calculations can be done using\n    marginal likelihoods or log-predictive likelihoods as in Ando, T., & Tsay,\n    R. (2010) <doi:10.1016/j.ijforecast.2009.08.001>.  "
  },
  {
    "id": 23298,
    "package_name": "z22",
    "title": "Official Gridded Data from the German Census 2022",
    "description": "Provides fast and easy access to German census grid data\n    from the 2011 and 2022 censuses <https://www.zensus2022.de/>, including a\n    wide range of socio-economic indicators at multiple spatial resolutions\n    (100m, 1km, 10km). Enables efficient download, processing, and analysis\n    of large census datasets covering population, households, families,\n    dwellings, and buildings. Harmonized data structures allow direct\n    comparison with the 2011 census, supporting temporal and spatial analyses.\n    Facilitates conversion of data into common formats for spatial analysis and\n    mapping ('terra', 'sf', 'ggplot2').",
    "version": "1.1.0",
    "maintainer": "Jonas Lieth <jonas.lieth@gesis.org>",
    "author": "Jonas Lieth [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-3451-3176>)",
    "url": "https://github.com/jslth/z22/, https://jslth.github.io/z22/",
    "bug_reports": "https://github.com/jslth/z22/issues",
    "repository": "https://cran.r-project.org/package=z22",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "z22 Official Gridded Data from the German Census 2022 Provides fast and easy access to German census grid data\n    from the 2011 and 2022 censuses <https://www.zensus2022.de/>, including a\n    wide range of socio-economic indicators at multiple spatial resolutions\n    (100m, 1km, 10km). Enables efficient download, processing, and analysis\n    of large census datasets covering population, households, families,\n    dwellings, and buildings. Harmonized data structures allow direct\n    comparison with the 2011 census, supporting temporal and spatial analyses.\n    Facilitates conversion of data into common formats for spatial analysis and\n    mapping ('terra', 'sf', 'ggplot2').  "
  }
]