[
  {
    "id": 1318,
    "package_name": "testthat",
    "title": "Unit Testing for R",
    "description": "Software testing is important, but, in part because it is\nfrustrating and boring, many of us avoid it. 'testthat' is a\ntesting framework for R that is easy to learn and use, and\nintegrates with your existing 'workflow'.",
    "version": "3.3.1",
    "maintainer": "Hadley Wickham <hadley@posit.co>",
    "author": "Hadley Wickham [aut, cre],\nPosit Software, PBC [cph, fnd],\nR Core team [ctb] (Implementation of utils::recover())",
    "url": "https://testthat.r-lib.org, https://github.com/r-lib/testthat",
    "bug_reports": "https://github.com/r-lib/testthat/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "announce_snapshot_file"
      ],
      [
        "auto_test"
      ],
      [
        "auto_test_package"
      ],
      [
        "capture_condition"
      ],
      [
        "capture_error"
      ],
      [
        "capture_expectation"
      ],
      [
        "capture_message"
      ],
      [
        "capture_messages"
      ],
      [
        "capture_output"
      ],
      [
        "capture_output_lines"
      ],
      [
        "capture_warning"
      ],
      [
        "capture_warnings"
      ],
      [
        "check_reporter"
      ],
      [
        "CheckReporter"
      ],
      [
        "CompactProgressReporter"
      ],
      [
        "compare"
      ],
      [
        "compare_file_binary"
      ],
      [
        "compare_file_text"
      ],
      [
        "context"
      ],
      [
        "context_start_file"
      ],
      [
        "DebugReporter"
      ],
      [
        "default_compact_reporter"
      ],
      [
        "default_parallel_reporter"
      ],
      [
        "default_reporter"
      ],
      [
        "describe"
      ],
      [
        "edition_get"
      ],
      [
        "equals"
      ],
      [
        "equals_reference"
      ],
      [
        "evaluate_promise"
      ],
      [
        "exp_signal"
      ],
      [
        "expect"
      ],
      [
        "expect_all_equal"
      ],
      [
        "expect_all_false"
      ],
      [
        "expect_all_true"
      ],
      [
        "expect_condition"
      ],
      [
        "expect_contains"
      ],
      [
        "expect_cpp_tests_pass"
      ],
      [
        "expect_disjoint"
      ],
      [
        "expect_equal"
      ],
      [
        "expect_equal_to_reference"
      ],
      [
        "expect_equivalent"
      ],
      [
        "expect_error"
      ],
      [
        "expect_failure"
      ],
      [
        "expect_false"
      ],
      [
        "expect_gt"
      ],
      [
        "expect_gte"
      ],
      [
        "expect_identical"
      ],
      [
        "expect_in"
      ],
      [
        "expect_invisible"
      ],
      [
        "expect_is"
      ],
      [
        "expect_known_hash"
      ],
      [
        "expect_known_output"
      ],
      [
        "expect_known_value"
      ],
      [
        "expect_length"
      ],
      [
        "expect_less_than"
      ],
      [
        "expect_lt"
      ],
      [
        "expect_lte"
      ],
      [
        "expect_mapequal"
      ],
      [
        "expect_match"
      ],
      [
        "expect_message"
      ],
      [
        "expect_more_than"
      ],
      [
        "expect_named"
      ],
      [
        "expect_no_condition"
      ],
      [
        "expect_no_error"
      ],
      [
        "expect_no_failure"
      ],
      [
        "expect_no_match"
      ],
      [
        "expect_no_message"
      ],
      [
        "expect_no_success"
      ],
      [
        "expect_no_warning"
      ],
      [
        "expect_null"
      ],
      [
        "expect_output"
      ],
      [
        "expect_output_file"
      ],
      [
        "expect_r6_class"
      ],
      [
        "expect_reference"
      ],
      [
        "expect_s3_class"
      ],
      [
        "expect_s4_class"
      ],
      [
        "expect_s7_class"
      ],
      [
        "expect_setequal"
      ],
      [
        "expect_shape"
      ],
      [
        "expect_silent"
      ],
      [
        "expect_snapshot"
      ],
      [
        "expect_snapshot_error"
      ],
      [
        "expect_snapshot_failure"
      ],
      [
        "expect_snapshot_file"
      ],
      [
        "expect_snapshot_output"
      ],
      [
        "expect_snapshot_value"
      ],
      [
        "expect_snapshot_warning"
      ],
      [
        "expect_success"
      ],
      [
        "expect_that"
      ],
      [
        "expect_true"
      ],
      [
        "expect_type"
      ],
      [
        "expect_vector"
      ],
      [
        "expect_visible"
      ],
      [
        "expect_warning"
      ],
      [
        "expectation"
      ],
      [
        "extract_test"
      ],
      [
        "fail"
      ],
      [
        "FailReporter"
      ],
      [
        "find_test_scripts"
      ],
      [
        "get_reporter"
      ],
      [
        "gives_warning"
      ],
      [
        "has_names"
      ],
      [
        "is_a"
      ],
      [
        "is_checking"
      ],
      [
        "is_equivalent_to"
      ],
      [
        "is_identical_to"
      ],
      [
        "is_informative_error"
      ],
      [
        "is_less_than"
      ],
      [
        "is_more_than"
      ],
      [
        "is_parallel"
      ],
      [
        "is_snapshot"
      ],
      [
        "is_testing"
      ],
      [
        "is.expectation"
      ],
      [
        "it"
      ],
      [
        "JunitReporter"
      ],
      [
        "ListReporter"
      ],
      [
        "local_edition"
      ],
      [
        "local_mock"
      ],
      [
        "local_mocked_bindings"
      ],
      [
        "local_mocked_r6_class"
      ],
      [
        "local_mocked_s3_method"
      ],
      [
        "local_mocked_s4_method"
      ],
      [
        "local_on_cran"
      ],
      [
        "local_reproducible_output"
      ],
      [
        "local_snapshotter"
      ],
      [
        "local_test_context"
      ],
      [
        "local_test_directory"
      ],
      [
        "LocationReporter"
      ],
      [
        "make_expectation"
      ],
      [
        "MinimalReporter"
      ],
      [
        "mock_output_sequence"
      ],
      [
        "MultiReporter"
      ],
      [
        "new_expectation"
      ],
      [
        "not"
      ],
      [
        "ParallelProgressReporter"
      ],
      [
        "pass"
      ],
      [
        "prints_text"
      ],
      [
        "ProgressReporter"
      ],
      [
        "quasi_label"
      ],
      [
        "Reporter"
      ],
      [
        "RStudioReporter"
      ],
      [
        "run_cpp_tests"
      ],
      [
        "set_max_fails"
      ],
      [
        "set_reporter"
      ],
      [
        "set_state_inspector"
      ],
      [
        "setup"
      ],
      [
        "show_failure"
      ],
      [
        "shows_message"
      ],
      [
        "SilentReporter"
      ],
      [
        "simulate_test_env"
      ],
      [
        "skip"
      ],
      [
        "skip_if"
      ],
      [
        "skip_if_not"
      ],
      [
        "skip_if_not_installed"
      ],
      [
        "skip_if_offline"
      ],
      [
        "skip_if_translated"
      ],
      [
        "skip_on_appveyor"
      ],
      [
        "skip_on_bioc"
      ],
      [
        "skip_on_ci"
      ],
      [
        "skip_on_covr"
      ],
      [
        "skip_on_cran"
      ],
      [
        "skip_on_os"
      ],
      [
        "skip_on_travis"
      ],
      [
        "skip_unless_r"
      ],
      [
        "SlowReporter"
      ],
      [
        "snapshot_accept"
      ],
      [
        "snapshot_download_gh"
      ],
      [
        "snapshot_reject"
      ],
      [
        "snapshot_review"
      ],
      [
        "source_dir"
      ],
      [
        "source_file"
      ],
      [
        "source_test_helpers"
      ],
      [
        "source_test_setup"
      ],
      [
        "source_test_teardown"
      ],
      [
        "StopReporter"
      ],
      [
        "succeed"
      ],
      [
        "SummaryReporter"
      ],
      [
        "takes_less_than"
      ],
      [
        "TapReporter"
      ],
      [
        "TeamcityReporter"
      ],
      [
        "teardown"
      ],
      [
        "teardown_env"
      ],
      [
        "test_check"
      ],
      [
        "test_dir"
      ],
      [
        "test_env"
      ],
      [
        "test_example"
      ],
      [
        "test_examples"
      ],
      [
        "test_file"
      ],
      [
        "test_local"
      ],
      [
        "test_package"
      ],
      [
        "test_path"
      ],
      [
        "test_rd"
      ],
      [
        "test_that"
      ],
      [
        "testing_package"
      ],
      [
        "testthat_example"
      ],
      [
        "testthat_examples"
      ],
      [
        "testthat_print"
      ],
      [
        "testthat_tolerance"
      ],
      [
        "throws_error"
      ],
      [
        "try_again"
      ],
      [
        "use_catch"
      ],
      [
        "verify_output"
      ],
      [
        "watch"
      ],
      [
        "with_mock"
      ],
      [
        "with_mocked_bindings"
      ],
      [
        "with_reporter"
      ]
    ],
    "topics": [
      [
        "unit-testing"
      ],
      [
        "cpp"
      ]
    ],
    "score": 21.8914,
    "stars": 918,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "testthat Unit Testing for R Software testing is important, but, in part because it is\nfrustrating and boring, many of us avoid it. 'testthat' is a\ntesting framework for R that is easy to learn and use, and\nintegrates with your existing 'workflow'. %>% announce_snapshot_file auto_test auto_test_package capture_condition capture_error capture_expectation capture_message capture_messages capture_output capture_output_lines capture_warning capture_warnings check_reporter CheckReporter CompactProgressReporter compare compare_file_binary compare_file_text context context_start_file DebugReporter default_compact_reporter default_parallel_reporter default_reporter describe edition_get equals equals_reference evaluate_promise exp_signal expect expect_all_equal expect_all_false expect_all_true expect_condition expect_contains expect_cpp_tests_pass expect_disjoint expect_equal expect_equal_to_reference expect_equivalent expect_error expect_failure expect_false expect_gt expect_gte expect_identical expect_in expect_invisible expect_is expect_known_hash expect_known_output expect_known_value expect_length expect_less_than expect_lt expect_lte expect_mapequal expect_match expect_message expect_more_than expect_named expect_no_condition expect_no_error expect_no_failure expect_no_match expect_no_message expect_no_success expect_no_warning expect_null expect_output expect_output_file expect_r6_class expect_reference expect_s3_class expect_s4_class expect_s7_class expect_setequal expect_shape expect_silent expect_snapshot expect_snapshot_error expect_snapshot_failure expect_snapshot_file expect_snapshot_output expect_snapshot_value expect_snapshot_warning expect_success expect_that expect_true expect_type expect_vector expect_visible expect_warning expectation extract_test fail FailReporter find_test_scripts get_reporter gives_warning has_names is_a is_checking is_equivalent_to is_identical_to is_informative_error is_less_than is_more_than is_parallel is_snapshot is_testing is.expectation it JunitReporter ListReporter local_edition local_mock local_mocked_bindings local_mocked_r6_class local_mocked_s3_method local_mocked_s4_method local_on_cran local_reproducible_output local_snapshotter local_test_context local_test_directory LocationReporter make_expectation MinimalReporter mock_output_sequence MultiReporter new_expectation not ParallelProgressReporter pass prints_text ProgressReporter quasi_label Reporter RStudioReporter run_cpp_tests set_max_fails set_reporter set_state_inspector setup show_failure shows_message SilentReporter simulate_test_env skip skip_if skip_if_not skip_if_not_installed skip_if_offline skip_if_translated skip_on_appveyor skip_on_bioc skip_on_ci skip_on_covr skip_on_cran skip_on_os skip_on_travis skip_unless_r SlowReporter snapshot_accept snapshot_download_gh snapshot_reject snapshot_review source_dir source_file source_test_helpers source_test_setup source_test_teardown StopReporter succeed SummaryReporter takes_less_than TapReporter TeamcityReporter teardown teardown_env test_check test_dir test_env test_example test_examples test_file test_local test_package test_path test_rd test_that testing_package testthat_example testthat_examples testthat_print testthat_tolerance throws_error try_again use_catch verify_output watch with_mock with_mocked_bindings with_reporter unit-testing cpp"
  },
  {
    "id": 465,
    "package_name": "devtools",
    "title": "Tools to Make Developing R Packages Easier",
    "description": "Collection of package development tools.",
    "version": "2.4.6.9000",
    "maintainer": "Jennifer Bryan <jenny@posit.co>",
    "author": "Hadley Wickham [aut],\nJim Hester [aut],\nWinston Chang [aut],\nJennifer Bryan [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-6983-2759>),\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://devtools.r-lib.org/, https://github.com/r-lib/devtools",
    "bug_reports": "https://github.com/r-lib/devtools/issues",
    "repository": "",
    "exports": [
      [
        "as.package"
      ],
      [
        "bash"
      ],
      [
        "build"
      ],
      [
        "build_manual"
      ],
      [
        "build_readme"
      ],
      [
        "build_rmd"
      ],
      [
        "build_site"
      ],
      [
        "build_vignettes"
      ],
      [
        "check"
      ],
      [
        "check_built"
      ],
      [
        "check_dep_version"
      ],
      [
        "check_mac_release"
      ],
      [
        "check_man"
      ],
      [
        "check_rhub"
      ],
      [
        "check_win_devel"
      ],
      [
        "check_win_oldrelease"
      ],
      [
        "check_win_release"
      ],
      [
        "clean_dll"
      ],
      [
        "clean_vignettes"
      ],
      [
        "create"
      ],
      [
        "dev_mode"
      ],
      [
        "dev_package_deps"
      ],
      [
        "dev_packages"
      ],
      [
        "dev_sitrep"
      ],
      [
        "document"
      ],
      [
        "find_rtools"
      ],
      [
        "github_pull"
      ],
      [
        "github_release"
      ],
      [
        "has_devel"
      ],
      [
        "has_tests"
      ],
      [
        "install"
      ],
      [
        "install_bioc"
      ],
      [
        "install_bitbucket"
      ],
      [
        "install_cran"
      ],
      [
        "install_deps"
      ],
      [
        "install_dev"
      ],
      [
        "install_dev_deps"
      ],
      [
        "install_git"
      ],
      [
        "install_github"
      ],
      [
        "install_gitlab"
      ],
      [
        "install_local"
      ],
      [
        "install_svn"
      ],
      [
        "install_url"
      ],
      [
        "install_version"
      ],
      [
        "is.package"
      ],
      [
        "lint"
      ],
      [
        "load_all"
      ],
      [
        "loaded_packages"
      ],
      [
        "missing_s3"
      ],
      [
        "package_file"
      ],
      [
        "package_info"
      ],
      [
        "parse_deps"
      ],
      [
        "r_env_vars"
      ],
      [
        "release"
      ],
      [
        "release_checks"
      ],
      [
        "reload"
      ],
      [
        "revdep"
      ],
      [
        "revdep_maintainers"
      ],
      [
        "run_examples"
      ],
      [
        "session_info"
      ],
      [
        "show_news"
      ],
      [
        "source_gist"
      ],
      [
        "source_url"
      ],
      [
        "spell_check"
      ],
      [
        "submit_cran"
      ],
      [
        "test"
      ],
      [
        "test_active_file"
      ],
      [
        "test_coverage"
      ],
      [
        "test_coverage_active_file"
      ],
      [
        "test_coverage_file"
      ],
      [
        "test_file"
      ],
      [
        "uninstall"
      ],
      [
        "unload"
      ],
      [
        "update_packages"
      ],
      [
        "uses_testthat"
      ],
      [
        "wd"
      ],
      [
        "with_debug"
      ]
    ],
    "topics": [
      [
        "package-creation"
      ]
    ],
    "score": 19.5347,
    "stars": 2483,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "devtools Tools to Make Developing R Packages Easier Collection of package development tools. as.package bash build build_manual build_readme build_rmd build_site build_vignettes check check_built check_dep_version check_mac_release check_man check_rhub check_win_devel check_win_oldrelease check_win_release clean_dll clean_vignettes create dev_mode dev_package_deps dev_packages dev_sitrep document find_rtools github_pull github_release has_devel has_tests install install_bioc install_bitbucket install_cran install_deps install_dev install_dev_deps install_git install_github install_gitlab install_local install_svn install_url install_version is.package lint load_all loaded_packages missing_s3 package_file package_info parse_deps r_env_vars release release_checks reload revdep revdep_maintainers run_examples session_info show_news source_gist source_url spell_check submit_cran test test_active_file test_coverage test_coverage_active_file test_coverage_file test_file uninstall unload update_packages uses_testthat wd with_debug package-creation"
  },
  {
    "id": 978,
    "package_name": "pkgdown",
    "title": "Make Static HTML Documentation for a Package",
    "description": "Generate an attractive and useful website from a source\npackage.  'pkgdown' converts your documentation, vignettes,\n'README', and more to 'HTML' making it easy to share\ninformation about your package online.",
    "version": "2.2.0.9000",
    "maintainer": "Hadley Wickham <hadley@posit.co>",
    "author": "Hadley Wickham [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-4757-117X>),\nJay Hesselberth [aut] (ORCID: <https://orcid.org/0000-0002-6299-179X>),\nMa\u00eblle Salmon [aut] (ORCID: <https://orcid.org/0000-0002-2815-0399>),\nOlivier Roy [aut],\nSalim Br\u00fcggemann [aut] (ORCID: <https://orcid.org/0000-0002-5329-5987>),\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://pkgdown.r-lib.org/, https://github.com/r-lib/pkgdown",
    "bug_reports": "https://github.com/r-lib/pkgdown/issues",
    "repository": "",
    "exports": [
      [
        "as_pkgdown"
      ],
      [
        "build_article"
      ],
      [
        "build_articles"
      ],
      [
        "build_articles_index"
      ],
      [
        "build_favicons"
      ],
      [
        "build_home"
      ],
      [
        "build_home_index"
      ],
      [
        "build_llm_docs"
      ],
      [
        "build_news"
      ],
      [
        "build_redirects"
      ],
      [
        "build_reference"
      ],
      [
        "build_reference_index"
      ],
      [
        "build_search"
      ],
      [
        "build_site"
      ],
      [
        "build_site_github_pages"
      ],
      [
        "build_tutorials"
      ],
      [
        "check_pkgdown"
      ],
      [
        "clean_cache"
      ],
      [
        "clean_site"
      ],
      [
        "data_template"
      ],
      [
        "deploy_site_github"
      ],
      [
        "deploy_to_branch"
      ],
      [
        "fig_settings"
      ],
      [
        "in_pkgdown"
      ],
      [
        "init_site"
      ],
      [
        "pkgdown_print"
      ],
      [
        "pkgdown_sitrep"
      ],
      [
        "preview_site"
      ],
      [
        "rd2html"
      ],
      [
        "render_page"
      ],
      [
        "template_articles"
      ],
      [
        "template_navbar"
      ],
      [
        "template_reference"
      ]
    ],
    "topics": [
      [
        "documentation-tool"
      ],
      [
        "quarto"
      ]
    ],
    "score": 18.4311,
    "stars": 754,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "pkgdown Make Static HTML Documentation for a Package Generate an attractive and useful website from a source\npackage.  'pkgdown' converts your documentation, vignettes,\n'README', and more to 'HTML' making it easy to share\ninformation about your package online. as_pkgdown build_article build_articles build_articles_index build_favicons build_home build_home_index build_llm_docs build_news build_redirects build_reference build_reference_index build_search build_site build_site_github_pages build_tutorials check_pkgdown clean_cache clean_site data_template deploy_site_github deploy_to_branch fig_settings in_pkgdown init_site pkgdown_print pkgdown_sitrep preview_site rd2html render_page template_articles template_navbar template_reference documentation-tool quarto"
  },
  {
    "id": 1135,
    "package_name": "roxygen2",
    "title": "In-Line Documentation for R",
    "description": "Generate your Rd documentation, 'NAMESPACE' file, and\ncollation field using specially formatted comments. Writing\ndocumentation in-line with code makes it easier to keep your\ndocumentation up-to-date as your requirements change.\n'roxygen2' is inspired by the 'Doxygen' system for C++.",
    "version": "7.3.3.9000",
    "maintainer": "Hadley Wickham <hadley@posit.co>",
    "author": "Hadley Wickham [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0003-4757-117X>),\nPeter Danenberg [aut, cph],\nG\u00e1bor Cs\u00e1rdi [aut],\nManuel Eugster [aut, cph],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://roxygen2.r-lib.org/, https://github.com/r-lib/roxygen2",
    "bug_reports": "https://github.com/r-lib/roxygen2/issues",
    "repository": "",
    "exports": [
      [
        "block_get_tag"
      ],
      [
        "block_get_tag_value"
      ],
      [
        "block_get_tags"
      ],
      [
        "block_has_tags"
      ],
      [
        "env_file"
      ],
      [
        "env_package"
      ],
      [
        "escape_examples"
      ],
      [
        "is_s3_generic"
      ],
      [
        "is_s3_method"
      ],
      [
        "load_installed"
      ],
      [
        "load_options"
      ],
      [
        "load_pkgload"
      ],
      [
        "load_source"
      ],
      [
        "namespace_roclet"
      ],
      [
        "object"
      ],
      [
        "object_format"
      ],
      [
        "parse_file"
      ],
      [
        "parse_package"
      ],
      [
        "parse_text"
      ],
      [
        "rd_roclet"
      ],
      [
        "rd_section"
      ],
      [
        "roc_proc_text"
      ],
      [
        "roclet"
      ],
      [
        "roclet_clean"
      ],
      [
        "roclet_find"
      ],
      [
        "roclet_output"
      ],
      [
        "roclet_preprocess"
      ],
      [
        "roclet_process"
      ],
      [
        "roclet_tags"
      ],
      [
        "roxy_block"
      ],
      [
        "roxy_meta_get"
      ],
      [
        "roxy_tag"
      ],
      [
        "roxy_tag_parse"
      ],
      [
        "roxy_tag_rd"
      ],
      [
        "roxy_tag_warning"
      ],
      [
        "roxygenise"
      ],
      [
        "roxygenize"
      ],
      [
        "tag_code"
      ],
      [
        "tag_examples"
      ],
      [
        "tag_inherit"
      ],
      [
        "tag_markdown"
      ],
      [
        "tag_markdown_with_sections"
      ],
      [
        "tag_name"
      ],
      [
        "tag_name_description"
      ],
      [
        "tag_toggle"
      ],
      [
        "tag_two_part"
      ],
      [
        "tag_value"
      ],
      [
        "tag_words"
      ],
      [
        "tag_words_line"
      ],
      [
        "tags_list"
      ],
      [
        "tags_metadata"
      ],
      [
        "update_collate"
      ],
      [
        "vignette_roclet"
      ],
      [
        "warn_roxy_tag"
      ]
    ],
    "topics": [
      [
        "devtools"
      ],
      [
        "documentation"
      ],
      [
        "cpp"
      ]
    ],
    "score": 18.3671,
    "stars": 622,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "roxygen2 In-Line Documentation for R Generate your Rd documentation, 'NAMESPACE' file, and\ncollation field using specially formatted comments. Writing\ndocumentation in-line with code makes it easier to keep your\ndocumentation up-to-date as your requirements change.\n'roxygen2' is inspired by the 'Doxygen' system for C++. block_get_tag block_get_tag_value block_get_tags block_has_tags env_file env_package escape_examples is_s3_generic is_s3_method load_installed load_options load_pkgload load_source namespace_roclet object object_format parse_file parse_package parse_text rd_roclet rd_section roc_proc_text roclet roclet_clean roclet_find roclet_output roclet_preprocess roclet_process roclet_tags roxy_block roxy_meta_get roxy_tag roxy_tag_parse roxy_tag_rd roxy_tag_warning roxygenise roxygenize tag_code tag_examples tag_inherit tag_markdown tag_markdown_with_sections tag_name tag_name_description tag_toggle tag_two_part tag_value tag_words tag_words_line tags_list tags_metadata update_collate vignette_roclet warn_roxy_tag devtools documentation cpp"
  },
  {
    "id": 279,
    "package_name": "bayesplot",
    "title": "Plotting for Bayesian Models",
    "description": "Plotting functions for posterior analysis, MCMC\ndiagnostics, prior and posterior predictive checks, and other\nvisualizations to support the applied Bayesian workflow\nadvocated in Gabry, Simpson, Vehtari, Betancourt, and Gelman\n(2019) <doi:10.1111/rssa.12378>. The package is designed not\nonly to provide convenient functionality for users, but also a\ncommon set of functions that can be easily used by developers\nworking on a variety of R packages for Bayesian modeling,\nparticularly (but not exclusively) packages interfacing with\n'Stan'.",
    "version": "1.15.0.9000",
    "maintainer": "Jonah Gabry <jgabry@gmail.com>",
    "author": "Jonah Gabry [aut, cre],\nTristan Mahr [aut] (ORCID: <https://orcid.org/0000-0002-8890-5116>),\nPaul-Christian B\u00fcrkner [ctb],\nMartin Modr\u00e1k [ctb],\nMalcolm Barrett [ctb],\nFrank Weber [ctb],\nEduardo Coronado Sroka [ctb],\nTeemu Sailynoja [ctb],\nAki Vehtari [ctb],\nBehram Uluk\u0131r [ctb],\nVisruth Srimath Kandali [ctb]",
    "url": "https://mc-stan.org/bayesplot/",
    "bug_reports": "https://github.com/stan-dev/bayesplot/issues/",
    "repository": "",
    "exports": [
      [
        "abline_01"
      ],
      [
        "available_mcmc"
      ],
      [
        "available_ppc"
      ],
      [
        "available_ppd"
      ],
      [
        "bayesplot_grid"
      ],
      [
        "bayesplot_theme_get"
      ],
      [
        "bayesplot_theme_replace"
      ],
      [
        "bayesplot_theme_set"
      ],
      [
        "bayesplot_theme_update"
      ],
      [
        "color_scheme_get"
      ],
      [
        "color_scheme_set"
      ],
      [
        "color_scheme_view"
      ],
      [
        "example_group_data"
      ],
      [
        "example_mcmc_draws"
      ],
      [
        "example_x_data"
      ],
      [
        "example_y_data"
      ],
      [
        "example_yrep_draws"
      ],
      [
        "facet_bg"
      ],
      [
        "facet_text"
      ],
      [
        "grid_lines"
      ],
      [
        "hline_0"
      ],
      [
        "hline_at"
      ],
      [
        "lbub"
      ],
      [
        "legend_move"
      ],
      [
        "legend_none"
      ],
      [
        "legend_text"
      ],
      [
        "log_posterior"
      ],
      [
        "mcmc_acf"
      ],
      [
        "mcmc_acf_bar"
      ],
      [
        "mcmc_areas"
      ],
      [
        "mcmc_areas_data"
      ],
      [
        "mcmc_areas_ridges"
      ],
      [
        "mcmc_areas_ridges_data"
      ],
      [
        "mcmc_combo"
      ],
      [
        "mcmc_dens"
      ],
      [
        "mcmc_dens_chains"
      ],
      [
        "mcmc_dens_chains_data"
      ],
      [
        "mcmc_dens_overlay"
      ],
      [
        "mcmc_hex"
      ],
      [
        "mcmc_hist"
      ],
      [
        "mcmc_hist_by_chain"
      ],
      [
        "mcmc_intervals"
      ],
      [
        "mcmc_intervals_data"
      ],
      [
        "mcmc_neff"
      ],
      [
        "mcmc_neff_data"
      ],
      [
        "mcmc_neff_hist"
      ],
      [
        "mcmc_nuts_acceptance"
      ],
      [
        "mcmc_nuts_divergence"
      ],
      [
        "mcmc_nuts_energy"
      ],
      [
        "mcmc_nuts_stepsize"
      ],
      [
        "mcmc_nuts_treedepth"
      ],
      [
        "mcmc_pairs"
      ],
      [
        "mcmc_parcoord"
      ],
      [
        "mcmc_parcoord_data"
      ],
      [
        "mcmc_rank_ecdf"
      ],
      [
        "mcmc_rank_hist"
      ],
      [
        "mcmc_rank_overlay"
      ],
      [
        "mcmc_recover_hist"
      ],
      [
        "mcmc_recover_intervals"
      ],
      [
        "mcmc_recover_scatter"
      ],
      [
        "mcmc_rhat"
      ],
      [
        "mcmc_rhat_data"
      ],
      [
        "mcmc_rhat_hist"
      ],
      [
        "mcmc_scatter"
      ],
      [
        "mcmc_trace"
      ],
      [
        "mcmc_trace_data"
      ],
      [
        "mcmc_trace_highlight"
      ],
      [
        "mcmc_violin"
      ],
      [
        "neff_ratio"
      ],
      [
        "nuts_params"
      ],
      [
        "overlay_function"
      ],
      [
        "pairs_condition"
      ],
      [
        "pairs_style_np"
      ],
      [
        "panel_bg"
      ],
      [
        "param_glue"
      ],
      [
        "param_range"
      ],
      [
        "parcoord_style_np"
      ],
      [
        "plot_bg"
      ],
      [
        "pp_check"
      ],
      [
        "ppc_bars"
      ],
      [
        "ppc_bars_data"
      ],
      [
        "ppc_bars_grouped"
      ],
      [
        "ppc_boxplot"
      ],
      [
        "ppc_data"
      ],
      [
        "ppc_dens"
      ],
      [
        "ppc_dens_overlay"
      ],
      [
        "ppc_dens_overlay_grouped"
      ],
      [
        "ppc_dots"
      ],
      [
        "ppc_ecdf_overlay"
      ],
      [
        "ppc_ecdf_overlay_grouped"
      ],
      [
        "ppc_error_binned"
      ],
      [
        "ppc_error_data"
      ],
      [
        "ppc_error_hist"
      ],
      [
        "ppc_error_hist_grouped"
      ],
      [
        "ppc_error_scatter"
      ],
      [
        "ppc_error_scatter_avg"
      ],
      [
        "ppc_error_scatter_avg_grouped"
      ],
      [
        "ppc_error_scatter_avg_vs_x"
      ],
      [
        "ppc_freqpoly"
      ],
      [
        "ppc_freqpoly_grouped"
      ],
      [
        "ppc_hist"
      ],
      [
        "ppc_intervals"
      ],
      [
        "ppc_intervals_data"
      ],
      [
        "ppc_intervals_grouped"
      ],
      [
        "ppc_km_overlay"
      ],
      [
        "ppc_km_overlay_grouped"
      ],
      [
        "ppc_loo_intervals"
      ],
      [
        "ppc_loo_pit"
      ],
      [
        "ppc_loo_pit_data"
      ],
      [
        "ppc_loo_pit_ecdf"
      ],
      [
        "ppc_loo_pit_overlay"
      ],
      [
        "ppc_loo_pit_qq"
      ],
      [
        "ppc_loo_ribbon"
      ],
      [
        "ppc_pit_ecdf"
      ],
      [
        "ppc_pit_ecdf_grouped"
      ],
      [
        "ppc_ribbon"
      ],
      [
        "ppc_ribbon_data"
      ],
      [
        "ppc_ribbon_grouped"
      ],
      [
        "ppc_rootogram"
      ],
      [
        "ppc_scatter"
      ],
      [
        "ppc_scatter_avg"
      ],
      [
        "ppc_scatter_avg_data"
      ],
      [
        "ppc_scatter_avg_grouped"
      ],
      [
        "ppc_scatter_data"
      ],
      [
        "ppc_stat"
      ],
      [
        "ppc_stat_2d"
      ],
      [
        "ppc_stat_data"
      ],
      [
        "ppc_stat_freqpoly"
      ],
      [
        "ppc_stat_freqpoly_grouped"
      ],
      [
        "ppc_stat_grouped"
      ],
      [
        "ppc_violin_grouped"
      ],
      [
        "ppd_boxplot"
      ],
      [
        "ppd_data"
      ],
      [
        "ppd_dens"
      ],
      [
        "ppd_dens_overlay"
      ],
      [
        "ppd_dots"
      ],
      [
        "ppd_ecdf_overlay"
      ],
      [
        "ppd_freqpoly"
      ],
      [
        "ppd_freqpoly_grouped"
      ],
      [
        "ppd_hist"
      ],
      [
        "ppd_intervals"
      ],
      [
        "ppd_intervals_data"
      ],
      [
        "ppd_intervals_grouped"
      ],
      [
        "ppd_ribbon"
      ],
      [
        "ppd_ribbon_data"
      ],
      [
        "ppd_ribbon_grouped"
      ],
      [
        "ppd_stat"
      ],
      [
        "ppd_stat_2d"
      ],
      [
        "ppd_stat_data"
      ],
      [
        "ppd_stat_freqpoly"
      ],
      [
        "ppd_stat_freqpoly_grouped"
      ],
      [
        "ppd_stat_grouped"
      ],
      [
        "rhat"
      ],
      [
        "scatter_style_np"
      ],
      [
        "theme_default"
      ],
      [
        "trace_style_np"
      ],
      [
        "vars"
      ],
      [
        "vline_0"
      ],
      [
        "vline_at"
      ],
      [
        "xaxis_text"
      ],
      [
        "xaxis_ticks"
      ],
      [
        "xaxis_title"
      ],
      [
        "yaxis_text"
      ],
      [
        "yaxis_ticks"
      ],
      [
        "yaxis_title"
      ]
    ],
    "topics": [
      [
        "bayesian"
      ],
      [
        "ggplot2"
      ],
      [
        "mcmc"
      ],
      [
        "pandoc"
      ],
      [
        "stan"
      ],
      [
        "statistical-graphics"
      ],
      [
        "visualization"
      ]
    ],
    "score": 17.9864,
    "stars": 439,
    "primary_category": "statistics",
    "source_universe": "stan-dev",
    "search_text": "bayesplot Plotting for Bayesian Models Plotting functions for posterior analysis, MCMC\ndiagnostics, prior and posterior predictive checks, and other\nvisualizations to support the applied Bayesian workflow\nadvocated in Gabry, Simpson, Vehtari, Betancourt, and Gelman\n(2019) <doi:10.1111/rssa.12378>. The package is designed not\nonly to provide convenient functionality for users, but also a\ncommon set of functions that can be easily used by developers\nworking on a variety of R packages for Bayesian modeling,\nparticularly (but not exclusively) packages interfacing with\n'Stan'. abline_01 available_mcmc available_ppc available_ppd bayesplot_grid bayesplot_theme_get bayesplot_theme_replace bayesplot_theme_set bayesplot_theme_update color_scheme_get color_scheme_set color_scheme_view example_group_data example_mcmc_draws example_x_data example_y_data example_yrep_draws facet_bg facet_text grid_lines hline_0 hline_at lbub legend_move legend_none legend_text log_posterior mcmc_acf mcmc_acf_bar mcmc_areas mcmc_areas_data mcmc_areas_ridges mcmc_areas_ridges_data mcmc_combo mcmc_dens mcmc_dens_chains mcmc_dens_chains_data mcmc_dens_overlay mcmc_hex mcmc_hist mcmc_hist_by_chain mcmc_intervals mcmc_intervals_data mcmc_neff mcmc_neff_data mcmc_neff_hist mcmc_nuts_acceptance mcmc_nuts_divergence mcmc_nuts_energy mcmc_nuts_stepsize mcmc_nuts_treedepth mcmc_pairs mcmc_parcoord mcmc_parcoord_data mcmc_rank_ecdf mcmc_rank_hist mcmc_rank_overlay mcmc_recover_hist mcmc_recover_intervals mcmc_recover_scatter mcmc_rhat mcmc_rhat_data mcmc_rhat_hist mcmc_scatter mcmc_trace mcmc_trace_data mcmc_trace_highlight mcmc_violin neff_ratio nuts_params overlay_function pairs_condition pairs_style_np panel_bg param_glue param_range parcoord_style_np plot_bg pp_check ppc_bars ppc_bars_data ppc_bars_grouped ppc_boxplot ppc_data ppc_dens ppc_dens_overlay ppc_dens_overlay_grouped ppc_dots ppc_ecdf_overlay ppc_ecdf_overlay_grouped ppc_error_binned ppc_error_data ppc_error_hist ppc_error_hist_grouped ppc_error_scatter ppc_error_scatter_avg ppc_error_scatter_avg_grouped ppc_error_scatter_avg_vs_x ppc_freqpoly ppc_freqpoly_grouped ppc_hist ppc_intervals ppc_intervals_data ppc_intervals_grouped ppc_km_overlay ppc_km_overlay_grouped ppc_loo_intervals ppc_loo_pit ppc_loo_pit_data ppc_loo_pit_ecdf ppc_loo_pit_overlay ppc_loo_pit_qq ppc_loo_ribbon ppc_pit_ecdf ppc_pit_ecdf_grouped ppc_ribbon ppc_ribbon_data ppc_ribbon_grouped ppc_rootogram ppc_scatter ppc_scatter_avg ppc_scatter_avg_data ppc_scatter_avg_grouped ppc_scatter_data ppc_stat ppc_stat_2d ppc_stat_data ppc_stat_freqpoly ppc_stat_freqpoly_grouped ppc_stat_grouped ppc_violin_grouped ppd_boxplot ppd_data ppd_dens ppd_dens_overlay ppd_dots ppd_ecdf_overlay ppd_freqpoly ppd_freqpoly_grouped ppd_hist ppd_intervals ppd_intervals_data ppd_intervals_grouped ppd_ribbon ppd_ribbon_data ppd_ribbon_grouped ppd_stat ppd_stat_2d ppd_stat_data ppd_stat_freqpoly ppd_stat_freqpoly_grouped ppd_stat_grouped rhat scatter_style_np theme_default trace_style_np vars vline_0 vline_at xaxis_text xaxis_ticks xaxis_title yaxis_text yaxis_ticks yaxis_title bayesian ggplot2 mcmc pandoc stan statistical-graphics visualization"
  },
  {
    "id": 1444,
    "package_name": "withr",
    "title": "Run Code 'With' Temporarily Modified Global State",
    "description": "A set of functions to run code 'with' safely and\ntemporarily modified global state. Many of these functions were\noriginally a part of the 'devtools' package, this provides a\nsimple package with limited dependencies to provide access to\nthese functions.",
    "version": "3.0.2.9001",
    "maintainer": "Lionel Henry <lionel@posit.co>",
    "author": "Jim Hester [aut],\nLionel Henry [aut, cre],\nKirill M\u00fcller [aut],\nKevin Ushey [aut],\nHadley Wickham [aut],\nWinston Chang [aut],\nJennifer Bryan [ctb],\nRichard Cotton [ctb],\nPosit Software, PBC [cph, fnd]",
    "url": "https://withr.r-lib.org, https://github.com/r-lib/withr#readme",
    "bug_reports": "https://github.com/r-lib/withr/issues",
    "repository": "",
    "exports": [
      [
        "defer"
      ],
      [
        "defer_parent"
      ],
      [
        "deferred_clear"
      ],
      [
        "deferred_run"
      ],
      [
        "global_defer"
      ],
      [
        "local_"
      ],
      [
        "local_bmp"
      ],
      [
        "local_cairo_pdf"
      ],
      [
        "local_cairo_ps"
      ],
      [
        "local_collate"
      ],
      [
        "local_connection"
      ],
      [
        "local_db_connection"
      ],
      [
        "local_dir"
      ],
      [
        "local_environment"
      ],
      [
        "local_envvar"
      ],
      [
        "local_file"
      ],
      [
        "local_jpeg"
      ],
      [
        "local_language"
      ],
      [
        "local_libpaths"
      ],
      [
        "local_locale"
      ],
      [
        "local_makevars"
      ],
      [
        "local_message_sink"
      ],
      [
        "local_namespace"
      ],
      [
        "local_options"
      ],
      [
        "local_output_sink"
      ],
      [
        "local_package"
      ],
      [
        "local_par"
      ],
      [
        "local_path"
      ],
      [
        "local_pdf"
      ],
      [
        "local_png"
      ],
      [
        "local_postscript"
      ],
      [
        "local_preserve_seed"
      ],
      [
        "local_rng_version"
      ],
      [
        "local_seed"
      ],
      [
        "local_svg"
      ],
      [
        "local_temp_libpaths"
      ],
      [
        "local_tempdir"
      ],
      [
        "local_tempfile"
      ],
      [
        "local_tiff"
      ],
      [
        "local_timezone"
      ],
      [
        "local_xfig"
      ],
      [
        "makevars_user"
      ],
      [
        "set_makevars"
      ],
      [
        "with_"
      ],
      [
        "with_bmp"
      ],
      [
        "with_cairo_pdf"
      ],
      [
        "with_cairo_ps"
      ],
      [
        "with_collate"
      ],
      [
        "with_connection"
      ],
      [
        "with_db_connection"
      ],
      [
        "with_dir"
      ],
      [
        "with_environment"
      ],
      [
        "with_envvar"
      ],
      [
        "with_file"
      ],
      [
        "with_jpeg"
      ],
      [
        "with_language"
      ],
      [
        "with_libpaths"
      ],
      [
        "with_locale"
      ],
      [
        "with_makevars"
      ],
      [
        "with_message_sink"
      ],
      [
        "with_namespace"
      ],
      [
        "with_options"
      ],
      [
        "with_output_sink"
      ],
      [
        "with_package"
      ],
      [
        "with_par"
      ],
      [
        "with_path"
      ],
      [
        "with_pdf"
      ],
      [
        "with_png"
      ],
      [
        "with_postscript"
      ],
      [
        "with_preserve_seed"
      ],
      [
        "with_rng_version"
      ],
      [
        "with_seed"
      ],
      [
        "with_svg"
      ],
      [
        "with_temp_libpaths"
      ],
      [
        "with_tempdir"
      ],
      [
        "with_tempfile"
      ],
      [
        "with_tiff"
      ],
      [
        "with_timezone"
      ],
      [
        "with_xfig"
      ]
    ],
    "topics": [],
    "score": 17.9308,
    "stars": 178,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "withr Run Code 'With' Temporarily Modified Global State A set of functions to run code 'with' safely and\ntemporarily modified global state. Many of these functions were\noriginally a part of the 'devtools' package, this provides a\nsimple package with limited dependencies to provide access to\nthese functions. defer defer_parent deferred_clear deferred_run global_defer local_ local_bmp local_cairo_pdf local_cairo_ps local_collate local_connection local_db_connection local_dir local_environment local_envvar local_file local_jpeg local_language local_libpaths local_locale local_makevars local_message_sink local_namespace local_options local_output_sink local_package local_par local_path local_pdf local_png local_postscript local_preserve_seed local_rng_version local_seed local_svg local_temp_libpaths local_tempdir local_tempfile local_tiff local_timezone local_xfig makevars_user set_makevars with_ with_bmp with_cairo_pdf with_cairo_ps with_collate with_connection with_db_connection with_dir with_environment with_envvar with_file with_jpeg with_language with_libpaths with_locale with_makevars with_message_sink with_namespace with_options with_output_sink with_package with_par with_path with_pdf with_png with_postscript with_preserve_seed with_rng_version with_seed with_svg with_temp_libpaths with_tempdir with_tempfile with_tiff with_timezone with_xfig "
  },
  {
    "id": 200,
    "package_name": "StanHeaders",
    "title": "C++ Header Files for Stan",
    "description": "The C++ header files of the Stan project are provided by\nthis package, but it contains little R code or documentation.\nThe main reference is the vignette. There is a shared object\ncontaining part of the 'CVODES' library, but its functionality\nis not accessible from R. 'StanHeaders' is primarily useful for\ndevelopers who want to utilize the 'LinkingTo' directive of\ntheir package's DESCRIPTION file to build on the Stan library\nwithout incurring unnecessary dependencies. The Stan project\ndevelops a probabilistic programming language that implements\nfull or approximate Bayesian statistical inference via Markov\nChain Monte Carlo or 'variational' methods and implements\n(optionally penalized) maximum likelihood estimation via\noptimization. The Stan library includes an advanced automatic\ndifferentiation scheme, 'templated' statistical and linear\nalgebra functions that can handle the automatically\n'differentiable' scalar types (and doubles, 'ints', etc.), and\na parser for the Stan language. The 'rstan' package provides\nuser-facing R functions to parse, compile, test, estimate, and\nanalyze Stan models.",
    "version": "2.36.0.9000",
    "maintainer": "Ben Goodrich <benjamin.goodrich@columbia.edu>",
    "author": "Ben Goodrich [cre, aut],\nJoshua Pritikin [ctb],\nAndrew Gelman [aut],\nBob Carpenter [aut],\nMatt Hoffman [aut],\nDaniel Lee [aut],\nMichael Betancourt [aut],\nMarcus Brubaker [aut],\nJiqiang Guo [aut],\nPeter Li [aut],\nAllen Riddell [aut],\nMarco Inacio [aut],\nMitzi Morris [aut],\nJeffrey Arnold [aut],\nRob Goedman [aut],\nBrian Lau [aut],\nRob Trangucci [aut],\nJonah Gabry [aut],\nAlp Kucukelbir [aut],\nRobert Grant [aut],\nDustin Tran [aut],\nMichael Malecki [aut],\nYuanjun Gao [aut],\nHamada S. Badr [aut] (ORCID: <https://orcid.org/0000-0002-9808-2344>),\nTrustees of Columbia University [cph],\nLawrence Livermore National Security [cph] (CVODES),\nThe Regents of the University of California [cph] (CVODES),\nSouthern Methodist University [cph] (CVODES)",
    "url": "https://mc-stan.org/",
    "bug_reports": "https://github.com/stan-dev/rstan/issues",
    "repository": "",
    "exports": [
      [
        "stanFunction"
      ]
    ],
    "topics": [
      [
        "bayesian-data-analysis"
      ],
      [
        "bayesian-inference"
      ],
      [
        "bayesian-statistics"
      ],
      [
        "mcmc"
      ],
      [
        "stan"
      ]
    ],
    "score": 17.123,
    "stars": 1068,
    "primary_category": "statistics",
    "source_universe": "stan-dev",
    "search_text": "StanHeaders C++ Header Files for Stan The C++ header files of the Stan project are provided by\nthis package, but it contains little R code or documentation.\nThe main reference is the vignette. There is a shared object\ncontaining part of the 'CVODES' library, but its functionality\nis not accessible from R. 'StanHeaders' is primarily useful for\ndevelopers who want to utilize the 'LinkingTo' directive of\ntheir package's DESCRIPTION file to build on the Stan library\nwithout incurring unnecessary dependencies. The Stan project\ndevelops a probabilistic programming language that implements\nfull or approximate Bayesian statistical inference via Markov\nChain Monte Carlo or 'variational' methods and implements\n(optionally penalized) maximum likelihood estimation via\noptimization. The Stan library includes an advanced automatic\ndifferentiation scheme, 'templated' statistical and linear\nalgebra functions that can handle the automatically\n'differentiable' scalar types (and doubles, 'ints', etc.), and\na parser for the Stan language. The 'rstan' package provides\nuser-facing R functions to parse, compile, test, estimate, and\nanalyze Stan models. stanFunction bayesian-data-analysis bayesian-inference bayesian-statistics mcmc stan"
  },
  {
    "id": 1084,
    "package_name": "remotes",
    "title": "R Package Installation from Remote Repositories, Including\n'GitHub'",
    "description": "Download and install R packages stored in 'GitHub',\n'GitLab', 'Bitbucket', 'Bioconductor', or plain 'subversion' or\n'git' repositories.  This package provides the 'install_*'\nfunctions in 'devtools'. Indeed most of the code was copied\nover from 'devtools'.",
    "version": "2.5.0.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nJim Hester [aut],\nHadley Wickham [aut],\nWinston Chang [aut],\nMartin Morgan [aut],\nDan Tenenbaum [aut],\nPosit Software, PBC [cph, fnd],\nAscent Digital Services [cph]",
    "url": "https://remotes.r-lib.org, https://github.com/r-lib/remotes#readme",
    "bug_reports": "https://github.com/r-lib/remotes/issues",
    "repository": "",
    "exports": [
      [
        "add_metadata"
      ],
      [
        "available_packages"
      ],
      [
        "available_packages_reset"
      ],
      [
        "available_packages_set"
      ],
      [
        "bioc_install_repos"
      ],
      [
        "bioc_version"
      ],
      [
        "dev_package_deps"
      ],
      [
        "download_version"
      ],
      [
        "git_credentials"
      ],
      [
        "github_pull"
      ],
      [
        "github_release"
      ],
      [
        "github_remote"
      ],
      [
        "gitlab_pat"
      ],
      [
        "install_bioc"
      ],
      [
        "install_bitbucket"
      ],
      [
        "install_cran"
      ],
      [
        "install_deps"
      ],
      [
        "install_dev"
      ],
      [
        "install_git"
      ],
      [
        "install_github"
      ],
      [
        "install_gitlab"
      ],
      [
        "install_local"
      ],
      [
        "install_remote"
      ],
      [
        "install_svn"
      ],
      [
        "install_url"
      ],
      [
        "install_version"
      ],
      [
        "local_package_deps"
      ],
      [
        "package_deps"
      ],
      [
        "parse_github_repo_spec"
      ],
      [
        "parse_github_url"
      ],
      [
        "parse_repo_spec"
      ],
      [
        "remote_download"
      ],
      [
        "remote_metadata"
      ],
      [
        "remote_package_name"
      ],
      [
        "remote_sha"
      ],
      [
        "standardise_dep"
      ],
      [
        "system_requirements"
      ],
      [
        "update_packages"
      ]
    ],
    "topics": [],
    "score": 17.05,
    "stars": 352,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "remotes R Package Installation from Remote Repositories, Including\n'GitHub' Download and install R packages stored in 'GitHub',\n'GitLab', 'Bitbucket', 'Bioconductor', or plain 'subversion' or\n'git' repositories.  This package provides the 'install_*'\nfunctions in 'devtools'. Indeed most of the code was copied\nover from 'devtools'. add_metadata available_packages available_packages_reset available_packages_set bioc_install_repos bioc_version dev_package_deps download_version git_credentials github_pull github_release github_remote gitlab_pat install_bioc install_bitbucket install_cran install_deps install_dev install_git install_github install_gitlab install_local install_remote install_svn install_url install_version local_package_deps package_deps parse_github_repo_spec parse_github_url parse_repo_spec remote_download remote_metadata remote_package_name remote_sha standardise_dep system_requirements update_packages "
  },
  {
    "id": 757,
    "package_name": "lifecycle",
    "title": "Manage the Life Cycle of your Package Functions",
    "description": "Manage the life cycle of your exported functions with\nshared conventions, documentation badges, and user-friendly\ndeprecation warnings.",
    "version": "1.0.4.9000",
    "maintainer": "Lionel Henry <lionel@posit.co>",
    "author": "Lionel Henry [aut, cre],\nHadley Wickham [aut] (ORCID: <https://orcid.org/0000-0003-4757-117X>),\nPosit Software, PBC [cph, fnd]",
    "url": "https://lifecycle.r-lib.org/, https://github.com/r-lib/lifecycle",
    "bug_reports": "https://github.com/r-lib/lifecycle/issues",
    "repository": "",
    "exports": [
      [
        "badge"
      ],
      [
        "deprecate_soft"
      ],
      [
        "deprecate_stop"
      ],
      [
        "deprecate_warn"
      ],
      [
        "deprecated"
      ],
      [
        "expect_defunct"
      ],
      [
        "expect_deprecated"
      ],
      [
        "is_present"
      ],
      [
        "last_lifecycle_warnings"
      ],
      [
        "lifecycle_linter"
      ],
      [
        "lint_lifecycle"
      ],
      [
        "lint_tidyverse_lifecycle"
      ],
      [
        "pkg_lifecycle_statuses"
      ],
      [
        "signal_experimental"
      ],
      [
        "signal_stage"
      ],
      [
        "signal_superseded"
      ]
    ],
    "topics": [],
    "score": 17.0017,
    "stars": 92,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "lifecycle Manage the Life Cycle of your Package Functions Manage the life cycle of your exported functions with\nshared conventions, documentation badges, and user-friendly\ndeprecation warnings. badge deprecate_soft deprecate_stop deprecate_warn deprecated expect_defunct expect_deprecated is_present last_lifecycle_warnings lifecycle_linter lint_lifecycle lint_tidyverse_lifecycle pkg_lifecycle_statuses signal_experimental signal_stage signal_superseded "
  },
  {
    "id": 691,
    "package_name": "httpuv",
    "title": "HTTP and WebSocket Server Library",
    "description": "Provides low-level socket and protocol support for\nhandling HTTP and WebSocket requests directly from within R. It\nis primarily intended as a building block for other packages,\nrather than making it particularly easy to create complete web\napplications using httpuv alone.  httpuv is built on top of the\nlibuv and http-parser C libraries, both of which were developed\nby Joyent, Inc. (See LICENSE file for libuv and http-parser\nlicense information.)",
    "version": "1.6.16.9000",
    "maintainer": "Winston Chang <winston@posit.co>",
    "author": "Joe Cheng [aut],\nWinston Chang [aut, cre],\nPosit, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>),\nHector Corrada Bravo [ctb],\nJeroen Ooms [ctb],\nAndrzej Krzemienski [cph] (optional.hpp),\nlibuv project contributors [cph] (libuv library, see src/libuv/AUTHORS\nfile),\nJoyent, Inc. and other Node contributors [cph] (libuv library, see\nsrc/libuv/AUTHORS file; and http-parser library, see\nsrc/http-parser/AUTHORS file),\nNiels Provos [cph] (libuv subcomponent: tree.h),\nInternet Systems Consortium, Inc. [cph] (libuv subcomponent: inet_pton\nand inet_ntop, contained in src/libuv/src/inet.c),\nAlexander Chemeris [cph] (libuv subcomponent: stdint-msvc2008.h (from\nmsinttypes)),\nGoogle, Inc. [cph] (libuv subcomponent: pthread-fixes.c),\nSony Mobile Communcations AB [cph] (libuv subcomponent:\npthread-fixes.c),\nBerkeley Software Design Inc. [cph] (libuv subcomponent:\nandroid-ifaddrs.h, android-ifaddrs.c),\nKenneth MacKay [cph] (libuv subcomponent: android-ifaddrs.h,\nandroid-ifaddrs.c),\nEmergya (Cloud4all, FP7/2007-2013, grant agreement no 289016) [cph]\n(libuv subcomponent: android-ifaddrs.h, android-ifaddrs.c),\nSteve Reid [aut] (SHA-1 implementation),\nJames Brown [aut] (SHA-1 implementation),\nBob Trower [aut] (base64 implementation),\nAlexander Peslyak [aut] (MD5 implementation),\nTrantor Standard Systems [cph] (base64 implementation),\nIgor Sysoev [cph] (http-parser)",
    "url": "https://rstudio.github.io/httpuv/,\nhttps://github.com/rstudio/httpuv",
    "bug_reports": "https://github.com/rstudio/httpuv/issues",
    "repository": "",
    "exports": [
      [
        "as.staticPath"
      ],
      [
        "decodeURI"
      ],
      [
        "decodeURIComponent"
      ],
      [
        "encodeURI"
      ],
      [
        "encodeURIComponent"
      ],
      [
        "excludeStaticPath"
      ],
      [
        "getRNGState"
      ],
      [
        "interrupt"
      ],
      [
        "ipFamily"
      ],
      [
        "listServers"
      ],
      [
        "randomPort"
      ],
      [
        "rawToBase64"
      ],
      [
        "runServer"
      ],
      [
        "runStaticServer"
      ],
      [
        "service"
      ],
      [
        "startDaemonizedServer"
      ],
      [
        "startPipeServer"
      ],
      [
        "startServer"
      ],
      [
        "staticPath"
      ],
      [
        "staticPathOptions"
      ],
      [
        "stopAllServers"
      ],
      [
        "stopDaemonizedServer"
      ],
      [
        "stopServer"
      ],
      [
        "WebSocket"
      ]
    ],
    "topics": [
      [
        "libuv1"
      ],
      [
        "cpp"
      ]
    ],
    "score": 15.8654,
    "stars": 248,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "httpuv HTTP and WebSocket Server Library Provides low-level socket and protocol support for\nhandling HTTP and WebSocket requests directly from within R. It\nis primarily intended as a building block for other packages,\nrather than making it particularly easy to create complete web\napplications using httpuv alone.  httpuv is built on top of the\nlibuv and http-parser C libraries, both of which were developed\nby Joyent, Inc. (See LICENSE file for libuv and http-parser\nlicense information.) as.staticPath decodeURI decodeURIComponent encodeURI encodeURIComponent excludeStaticPath getRNGState interrupt ipFamily listServers randomPort rawToBase64 runServer runStaticServer service startDaemonizedServer startPipeServer startServer staticPath staticPathOptions stopAllServers stopDaemonizedServer stopServer WebSocket libuv1 cpp"
  },
  {
    "id": 419,
    "package_name": "covr",
    "title": "Test Coverage for Packages",
    "description": "Track and report code coverage for your package and\n(optionally) upload the results to a coverage service like\n'Codecov' <https://about.codecov.io> or 'Coveralls'\n<https://coveralls.io>. Code coverage is a measure of the\namount of code being exercised by a set of tests. It is an\nindirect measure of test quality and completeness. This package\nis compatible with any testing methodology or framework and\ntracks coverage of both R code and compiled C/C++/FORTRAN code.",
    "version": "3.6.5.9000",
    "maintainer": "Jim Hester <james.f.hester@gmail.com>",
    "author": "Jim Hester [aut, cre],\nWillem Ligtenberg [ctb],\nKirill M\u00fcller [ctb],\nHenrik Bengtsson [ctb],\nSteve Peak [ctb],\nKirill Sevastyanenko [ctb],\nJon Clayden [ctb],\nRobert Flight [ctb],\nEric Brown [ctb],\nBrodie Gaslam [ctb],\nWill Beasley [ctb],\nRobert Krzyzanowski [ctb],\nMarkus Wamser [ctb],\nKarl Forner [ctb],\nGergely Dar\u00f3czi [ctb],\nJouni Helske [ctb],\nKun Ren [ctb],\nJeroen Ooms [ctb],\nKen Williams [ctb],\nChris Campbell [ctb],\nDavid Hugh-Jones [ctb],\nQin Wang [ctb],\nDoug Kelkhoff [ctb],\nIvan Sagalaev [ctb, cph] (highlight.js library),\nMark Otto [ctb] (Bootstrap library),\nJacob Thornton [ctb] (Bootstrap library),\nBootstrap contributors [ctb] (Bootstrap library),\nTwitter, Inc [cph] (Bootstrap library)",
    "url": "https://covr.r-lib.org, https://github.com/r-lib/covr",
    "bug_reports": "https://github.com/r-lib/covr/issues",
    "repository": "",
    "exports": [
      [
        "azure"
      ],
      [
        "code_coverage"
      ],
      [
        "codecov"
      ],
      [
        "coverage_to_list"
      ],
      [
        "coveralls"
      ],
      [
        "display_name"
      ],
      [
        "environment_coverage"
      ],
      [
        "file_coverage"
      ],
      [
        "file_report"
      ],
      [
        "function_coverage"
      ],
      [
        "gitlab"
      ],
      [
        "in_covr"
      ],
      [
        "package_coverage"
      ],
      [
        "percent_coverage"
      ],
      [
        "report"
      ],
      [
        "tally_coverage"
      ],
      [
        "to_cobertura"
      ],
      [
        "to_sonarqube"
      ],
      [
        "value"
      ],
      [
        "zero_coverage"
      ]
    ],
    "topics": [
      [
        "codecov"
      ],
      [
        "coverage"
      ],
      [
        "coverage-report"
      ],
      [
        "travis-ci"
      ]
    ],
    "score": 15.8274,
    "stars": 345,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "covr Test Coverage for Packages Track and report code coverage for your package and\n(optionally) upload the results to a coverage service like\n'Codecov' <https://about.codecov.io> or 'Coveralls'\n<https://coveralls.io>. Code coverage is a measure of the\namount of code being exercised by a set of tests. It is an\nindirect measure of test quality and completeness. This package\nis compatible with any testing methodology or framework and\ntracks coverage of both R code and compiled C/C++/FORTRAN code. azure code_coverage codecov coverage_to_list coveralls display_name environment_coverage file_coverage file_report function_coverage gitlab in_covr package_coverage percent_coverage report tally_coverage to_cobertura to_sonarqube value zero_coverage codecov coverage coverage-report travis-ci"
  },
  {
    "id": 753,
    "package_name": "learnr",
    "title": "Interactive Tutorials for R",
    "description": "Create interactive tutorials using R Markdown. Use a\ncombination of narrative, figures, videos, exercises, and\nquizzes to create self-paced tutorials for learning about R and\nR packages.",
    "version": "0.11.6.9000",
    "maintainer": "Garrick Aden-Buie <garrick@posit.co>",
    "author": "Garrick Aden-Buie [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7111-0077>),\nBarret Schloerke [aut] (ORCID: <https://orcid.org/0000-0001-9986-114X>),\nJJ Allaire [aut, ccp],\nAlexander Rossell Hayes [aut] (ORCID:\n<https://orcid.org/0000-0001-9412-0457>),\nNischal Shrestha [ctb] (ORCID: <https://orcid.org/0000-0003-3321-1712>),\nAngela Li [ctb] (vignette),\nPosit, PBC [cph, fnd],\nAjax.org B.V. [ctb, cph] (Ace library),\nZeno Rocha [ctb, cph] (clipboard.js library),\nNick Payne [ctb, cph] (Bootbox library),\nJake Archibald [ctb, cph] (idb-keyval library),\ni18next authors [ctb, cph] (i18next library)",
    "url": "https://rstudio.github.io/learnr/,\nhttps://github.com/rstudio/learnr",
    "bug_reports": "https://github.com/rstudio/learnr/issues",
    "repository": "",
    "exports": [
      [
        "answer"
      ],
      [
        "answer_fn"
      ],
      [
        "available_tutorials"
      ],
      [
        "correct"
      ],
      [
        "disable_all_tags"
      ],
      [
        "duplicate_env"
      ],
      [
        "event_register_handler"
      ],
      [
        "external_evaluator"
      ],
      [
        "filesystem_storage"
      ],
      [
        "finalize_question"
      ],
      [
        "get_tutorial_info"
      ],
      [
        "get_tutorial_state"
      ],
      [
        "incorrect"
      ],
      [
        "initialize_tutorial"
      ],
      [
        "mark_as"
      ],
      [
        "mock_chunk"
      ],
      [
        "mock_exercise"
      ],
      [
        "one_time"
      ],
      [
        "question"
      ],
      [
        "question_checkbox"
      ],
      [
        "question_is_correct"
      ],
      [
        "question_is_valid"
      ],
      [
        "question_numeric"
      ],
      [
        "question_radio"
      ],
      [
        "question_text"
      ],
      [
        "question_ui_completed"
      ],
      [
        "question_ui_initialize"
      ],
      [
        "question_ui_try_again"
      ],
      [
        "quiz"
      ],
      [
        "random_encouragement"
      ],
      [
        "random_phrases_add"
      ],
      [
        "random_praise"
      ],
      [
        "run_tutorial"
      ],
      [
        "safe"
      ],
      [
        "safe_env"
      ],
      [
        "tutorial"
      ],
      [
        "tutorial_html_dependency"
      ],
      [
        "tutorial_options"
      ],
      [
        "tutorial_package_dependencies"
      ]
    ],
    "topics": [
      [
        "interactive"
      ],
      [
        "python"
      ],
      [
        "rmarkdown"
      ],
      [
        "shiny"
      ],
      [
        "sql"
      ],
      [
        "teaching"
      ],
      [
        "tutorial"
      ]
    ],
    "score": 15.0078,
    "stars": 726,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "learnr Interactive Tutorials for R Create interactive tutorials using R Markdown. Use a\ncombination of narrative, figures, videos, exercises, and\nquizzes to create self-paced tutorials for learning about R and\nR packages. answer answer_fn available_tutorials correct disable_all_tags duplicate_env event_register_handler external_evaluator filesystem_storage finalize_question get_tutorial_info get_tutorial_state incorrect initialize_tutorial mark_as mock_chunk mock_exercise one_time question question_checkbox question_is_correct question_is_valid question_numeric question_radio question_text question_ui_completed question_ui_initialize question_ui_try_again quiz random_encouragement random_phrases_add random_praise run_tutorial safe safe_env tutorial tutorial_html_dependency tutorial_options tutorial_package_dependencies interactive python rmarkdown shiny sql teaching tutorial"
  },
  {
    "id": 443,
    "package_name": "datawizard",
    "title": "Easy Data Wrangling and Statistical Transformations",
    "description": "A lightweight package to assist in key steps involved in\nany data analysis workflow: (1) wrangling the raw data to get\nit in the needed form, (2) applying preprocessing steps and\nstatistical transformations, and (3) compute statistical\nsummaries of data properties and distributions. It is also the\ndata wrangling backend for packages in 'easystats' ecosystem.\nReferences: Patil et al. (2022) <doi:10.21105/joss.04684>.",
    "version": "1.3.0",
    "maintainer": "Etienne Bacher <etienne.bacher@protonmail.com>",
    "author": "Indrajeet Patil [aut] (ORCID: <https://orcid.org/0000-0003-1995-6531>),\nEtienne Bacher [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-9271-5075>),\nDominique Makowski [aut] (ORCID:\n<https://orcid.org/0000-0001-5375-9967>),\nDaniel L\u00fcdecke [aut] (ORCID: <https://orcid.org/0000-0002-8895-3206>),\nMattan S. Ben-Shachar [aut] (ORCID:\n<https://orcid.org/0000-0002-4287-4801>),\nBrenton M. Wiernik [aut] (ORCID:\n<https://orcid.org/0000-0001-9560-6336>),\nR\u00e9mi Th\u00e9riault [ctb] (ORCID: <https://orcid.org/0000-0003-4315-6788>),\nThomas J. Faulkenberry [rev],\nRobert Garrett [rev]",
    "url": "https://easystats.github.io/datawizard/",
    "bug_reports": "https://github.com/easystats/datawizard/issues",
    "repository": "",
    "exports": [
      [
        "adjust"
      ],
      [
        "as.prop.table"
      ],
      [
        "assign_labels"
      ],
      [
        "categorize"
      ],
      [
        "center"
      ],
      [
        "centre"
      ],
      [
        "change_scale"
      ],
      [
        "coef_var"
      ],
      [
        "coerce_to_numeric"
      ],
      [
        "colnames_to_row"
      ],
      [
        "column_as_rownames"
      ],
      [
        "contr.deviation"
      ],
      [
        "convert_na_to"
      ],
      [
        "convert_to_na"
      ],
      [
        "data_addprefix"
      ],
      [
        "data_addsuffix"
      ],
      [
        "data_adjust"
      ],
      [
        "data_arrange"
      ],
      [
        "data_codebook"
      ],
      [
        "data_duplicated"
      ],
      [
        "data_extract"
      ],
      [
        "data_filter"
      ],
      [
        "data_group"
      ],
      [
        "data_join"
      ],
      [
        "data_match"
      ],
      [
        "data_merge"
      ],
      [
        "data_modify"
      ],
      [
        "data_partition"
      ],
      [
        "data_peek"
      ],
      [
        "data_read"
      ],
      [
        "data_relocate"
      ],
      [
        "data_remove"
      ],
      [
        "data_rename"
      ],
      [
        "data_rename_rows"
      ],
      [
        "data_reorder"
      ],
      [
        "data_replicate"
      ],
      [
        "data_restoretype"
      ],
      [
        "data_rotate"
      ],
      [
        "data_seek"
      ],
      [
        "data_select"
      ],
      [
        "data_separate"
      ],
      [
        "data_summary"
      ],
      [
        "data_tabulate"
      ],
      [
        "data_to_long"
      ],
      [
        "data_to_wide"
      ],
      [
        "data_transpose"
      ],
      [
        "data_ungroup"
      ],
      [
        "data_unique"
      ],
      [
        "data_unite"
      ],
      [
        "data_write"
      ],
      [
        "degroup"
      ],
      [
        "demean"
      ],
      [
        "describe_distribution"
      ],
      [
        "detrend"
      ],
      [
        "display"
      ],
      [
        "distribution_coef_var"
      ],
      [
        "distribution_mode"
      ],
      [
        "empty_columns"
      ],
      [
        "empty_rows"
      ],
      [
        "extract_column_names"
      ],
      [
        "find_columns"
      ],
      [
        "kurtosis"
      ],
      [
        "labels_to_levels"
      ],
      [
        "mean_sd"
      ],
      [
        "means_by_group"
      ],
      [
        "median_mad"
      ],
      [
        "normalize"
      ],
      [
        "print_html"
      ],
      [
        "print_md"
      ],
      [
        "ranktransform"
      ],
      [
        "recode_into"
      ],
      [
        "recode_values"
      ],
      [
        "remove_empty"
      ],
      [
        "remove_empty_columns"
      ],
      [
        "remove_empty_rows"
      ],
      [
        "replace_nan_inf"
      ],
      [
        "rescale"
      ],
      [
        "rescale_weights"
      ],
      [
        "reshape_ci"
      ],
      [
        "reshape_longer"
      ],
      [
        "reshape_wider"
      ],
      [
        "reverse"
      ],
      [
        "reverse_scale"
      ],
      [
        "row_count"
      ],
      [
        "row_means"
      ],
      [
        "row_sums"
      ],
      [
        "row_to_colnames"
      ],
      [
        "rowid_as_column"
      ],
      [
        "rownames_as_column"
      ],
      [
        "skewness"
      ],
      [
        "slide"
      ],
      [
        "smoothness"
      ],
      [
        "standardise"
      ],
      [
        "standardize"
      ],
      [
        "text_concatenate"
      ],
      [
        "text_format"
      ],
      [
        "text_fullstop"
      ],
      [
        "text_lastchar"
      ],
      [
        "text_paste"
      ],
      [
        "text_remove"
      ],
      [
        "text_wrap"
      ],
      [
        "to_factor"
      ],
      [
        "to_numeric"
      ],
      [
        "unnormalize"
      ],
      [
        "unstandardise"
      ],
      [
        "unstandardize"
      ],
      [
        "visualisation_recipe"
      ],
      [
        "weighted_mad"
      ],
      [
        "weighted_mean"
      ],
      [
        "weighted_median"
      ],
      [
        "weighted_sd"
      ],
      [
        "winsorize"
      ]
    ],
    "topics": [
      [
        "data"
      ],
      [
        "dplyr"
      ],
      [
        "hacktoberfest"
      ],
      [
        "janitor"
      ],
      [
        "manipulation"
      ],
      [
        "reshape"
      ],
      [
        "tidyr"
      ],
      [
        "wrangling"
      ]
    ],
    "score": 14.9487,
    "stars": 232,
    "primary_category": "statistics",
    "source_universe": "easystats",
    "search_text": "datawizard Easy Data Wrangling and Statistical Transformations A lightweight package to assist in key steps involved in\nany data analysis workflow: (1) wrangling the raw data to get\nit in the needed form, (2) applying preprocessing steps and\nstatistical transformations, and (3) compute statistical\nsummaries of data properties and distributions. It is also the\ndata wrangling backend for packages in 'easystats' ecosystem.\nReferences: Patil et al. (2022) <doi:10.21105/joss.04684>. adjust as.prop.table assign_labels categorize center centre change_scale coef_var coerce_to_numeric colnames_to_row column_as_rownames contr.deviation convert_na_to convert_to_na data_addprefix data_addsuffix data_adjust data_arrange data_codebook data_duplicated data_extract data_filter data_group data_join data_match data_merge data_modify data_partition data_peek data_read data_relocate data_remove data_rename data_rename_rows data_reorder data_replicate data_restoretype data_rotate data_seek data_select data_separate data_summary data_tabulate data_to_long data_to_wide data_transpose data_ungroup data_unique data_unite data_write degroup demean describe_distribution detrend display distribution_coef_var distribution_mode empty_columns empty_rows extract_column_names find_columns kurtosis labels_to_levels mean_sd means_by_group median_mad normalize print_html print_md ranktransform recode_into recode_values remove_empty remove_empty_columns remove_empty_rows replace_nan_inf rescale rescale_weights reshape_ci reshape_longer reshape_wider reverse reverse_scale row_count row_means row_sums row_to_colnames rowid_as_column rownames_as_column skewness slide smoothness standardise standardize text_concatenate text_format text_fullstop text_lastchar text_paste text_remove text_wrap to_factor to_numeric unnormalize unstandardise unstandardize visualisation_recipe weighted_mad weighted_mean weighted_median weighted_sd winsorize data dplyr hacktoberfest janitor manipulation reshape tidyr wrangling"
  },
  {
    "id": 462,
    "package_name": "desc",
    "title": "Manipulate DESCRIPTION Files",
    "description": "Tools to read, write, create, and manipulate DESCRIPTION\nfiles.  It is intended for packages that create or manipulate\nother packages.",
    "version": "1.4.3.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nKirill M\u00fcller [aut],\nJim Hester [aut],\nMa\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>),\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://desc.r-lib.org/, https://github.com/r-lib/desc",
    "bug_reports": "https://github.com/r-lib/desc/issues",
    "repository": "",
    "exports": [
      [
        "check_field"
      ],
      [
        "cran_ascii_fields"
      ],
      [
        "cran_valid_fields"
      ],
      [
        "dep_types"
      ],
      [
        "desc"
      ],
      [
        "desc_add_author"
      ],
      [
        "desc_add_author_gh"
      ],
      [
        "desc_add_me"
      ],
      [
        "desc_add_orcid"
      ],
      [
        "desc_add_remotes"
      ],
      [
        "desc_add_role"
      ],
      [
        "desc_add_ror"
      ],
      [
        "desc_add_to_collate"
      ],
      [
        "desc_add_urls"
      ],
      [
        "desc_bump_version"
      ],
      [
        "desc_change_maintainer"
      ],
      [
        "desc_clear_remotes"
      ],
      [
        "desc_clear_urls"
      ],
      [
        "desc_coerce_authors_at_r"
      ],
      [
        "desc_del"
      ],
      [
        "desc_del_author"
      ],
      [
        "desc_del_collate"
      ],
      [
        "desc_del_dep"
      ],
      [
        "desc_del_deps"
      ],
      [
        "desc_del_from_collate"
      ],
      [
        "desc_del_remotes"
      ],
      [
        "desc_del_role"
      ],
      [
        "desc_del_urls"
      ],
      [
        "desc_fields"
      ],
      [
        "desc_get"
      ],
      [
        "desc_get_author"
      ],
      [
        "desc_get_authors"
      ],
      [
        "desc_get_built"
      ],
      [
        "desc_get_collate"
      ],
      [
        "desc_get_deps"
      ],
      [
        "desc_get_field"
      ],
      [
        "desc_get_list"
      ],
      [
        "desc_get_maintainer"
      ],
      [
        "desc_get_or_fail"
      ],
      [
        "desc_get_remotes"
      ],
      [
        "desc_get_urls"
      ],
      [
        "desc_get_version"
      ],
      [
        "desc_has_dep"
      ],
      [
        "desc_has_fields"
      ],
      [
        "desc_normalize"
      ],
      [
        "desc_print"
      ],
      [
        "desc_reformat_fields"
      ],
      [
        "desc_reorder_fields"
      ],
      [
        "desc_set"
      ],
      [
        "desc_set_authors"
      ],
      [
        "desc_set_collate"
      ],
      [
        "desc_set_dep"
      ],
      [
        "desc_set_deps"
      ],
      [
        "desc_set_list"
      ],
      [
        "desc_set_remotes"
      ],
      [
        "desc_set_urls"
      ],
      [
        "desc_set_version"
      ],
      [
        "desc_to_latex"
      ],
      [
        "desc_validate"
      ],
      [
        "description"
      ]
    ],
    "topics": [],
    "score": 14.9462,
    "stars": 125,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "desc Manipulate DESCRIPTION Files Tools to read, write, create, and manipulate DESCRIPTION\nfiles.  It is intended for packages that create or manipulate\nother packages. check_field cran_ascii_fields cran_valid_fields dep_types desc desc_add_author desc_add_author_gh desc_add_me desc_add_orcid desc_add_remotes desc_add_role desc_add_ror desc_add_to_collate desc_add_urls desc_bump_version desc_change_maintainer desc_clear_remotes desc_clear_urls desc_coerce_authors_at_r desc_del desc_del_author desc_del_collate desc_del_dep desc_del_deps desc_del_from_collate desc_del_remotes desc_del_role desc_del_urls desc_fields desc_get desc_get_author desc_get_authors desc_get_built desc_get_collate desc_get_deps desc_get_field desc_get_list desc_get_maintainer desc_get_or_fail desc_get_remotes desc_get_urls desc_get_version desc_has_dep desc_has_fields desc_normalize desc_print desc_reformat_fields desc_reorder_fields desc_set desc_set_authors desc_set_collate desc_set_dep desc_set_deps desc_set_list desc_set_remotes desc_set_urls desc_set_version desc_to_latex desc_validate description "
  },
  {
    "id": 972,
    "package_name": "pkgbuild",
    "title": "Find Tools Needed to Build R Packages",
    "description": "Provides functions used to build R packages. Locates\ncompilers needed to build R packages on various platforms and\nensures the PATH is configured appropriately so R can use them.",
    "version": "1.4.8.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "Hadley Wickham [aut],\nJim Hester [aut],\nG\u00e1bor Cs\u00e1rdi [aut, cre],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://github.com/r-lib/pkgbuild, https://pkgbuild.r-lib.org",
    "bug_reports": "https://github.com/r-lib/pkgbuild/issues",
    "repository": "",
    "exports": [
      [
        "build"
      ],
      [
        "check_build_tools"
      ],
      [
        "check_compiler"
      ],
      [
        "check_latex"
      ],
      [
        "check_rtools"
      ],
      [
        "clean_dll"
      ],
      [
        "compile_dll"
      ],
      [
        "compiler_flags"
      ],
      [
        "find_rtools"
      ],
      [
        "has_build_tools"
      ],
      [
        "has_compiler"
      ],
      [
        "has_devel"
      ],
      [
        "has_latex"
      ],
      [
        "has_rtools"
      ],
      [
        "local_build_tools"
      ],
      [
        "needs_compile"
      ],
      [
        "pkg_has_src"
      ],
      [
        "pkg_links_to_cpp11"
      ],
      [
        "pkg_links_to_rcpp"
      ],
      [
        "pkgbuild_process"
      ],
      [
        "rcmd_build_tools"
      ],
      [
        "rtools_needed"
      ],
      [
        "rtools_path"
      ],
      [
        "setup_rtools"
      ],
      [
        "with_build_tools"
      ],
      [
        "with_debug"
      ],
      [
        "with_latex"
      ],
      [
        "without_cache"
      ],
      [
        "without_compiler"
      ],
      [
        "without_latex"
      ]
    ],
    "topics": [],
    "score": 14.3915,
    "stars": 75,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "pkgbuild Find Tools Needed to Build R Packages Provides functions used to build R packages. Locates\ncompilers needed to build R packages on various platforms and\nensures the PATH is configured appropriately so R can use them. build check_build_tools check_compiler check_latex check_rtools clean_dll compile_dll compiler_flags find_rtools has_build_tools has_compiler has_devel has_latex has_rtools local_build_tools needs_compile pkg_has_src pkg_links_to_cpp11 pkg_links_to_rcpp pkgbuild_process rcmd_build_tools rtools_needed rtools_path setup_rtools with_build_tools with_debug with_latex without_cache without_compiler without_latex "
  },
  {
    "id": 362,
    "package_name": "chromote",
    "title": "Headless Chrome Web Browser Interface",
    "description": "An implementation of the 'Chrome DevTools Protocol', for\ncontrolling a headless Chrome web browser.",
    "version": "0.5.1.9000",
    "maintainer": "Garrick Aden-Buie <garrick@posit.co>",
    "author": "Garrick Aden-Buie [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7111-0077>),\nWinston Chang [aut],\nBarret Schloerke [aut] (ORCID: <https://orcid.org/0000-0001-9986-114X>),\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://rstudio.github.io/chromote/,\nhttps://github.com/rstudio/chromote",
    "bug_reports": "https://github.com/rstudio/chromote/issues",
    "repository": "",
    "exports": [
      [
        "%...!%"
      ],
      [
        "%...>%"
      ],
      [
        "%...T!%"
      ],
      [
        "%...T>%"
      ],
      [
        "%>%"
      ],
      [
        "%T>%"
      ],
      [
        "Browser"
      ],
      [
        "catch"
      ],
      [
        "Chrome"
      ],
      [
        "chrome_versions_add"
      ],
      [
        "chrome_versions_list"
      ],
      [
        "chrome_versions_path"
      ],
      [
        "chrome_versions_path_cache"
      ],
      [
        "chrome_versions_remove"
      ],
      [
        "ChromeRemote"
      ],
      [
        "Chromote"
      ],
      [
        "chromote_info"
      ],
      [
        "ChromoteSession"
      ],
      [
        "default_chrome_args"
      ],
      [
        "default_chromote_object"
      ],
      [
        "finally"
      ],
      [
        "find_chrome"
      ],
      [
        "get_chrome_args"
      ],
      [
        "has_default_chromote_object"
      ],
      [
        "local_chrome_version"
      ],
      [
        "local_chromote_chrome"
      ],
      [
        "promise"
      ],
      [
        "set_chrome_args"
      ],
      [
        "set_default_chromote_object"
      ],
      [
        "then"
      ],
      [
        "with_chrome_version"
      ],
      [
        "with_chromote_chrome"
      ]
    ],
    "topics": [],
    "score": 14.3456,
    "stars": 176,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "chromote Headless Chrome Web Browser Interface An implementation of the 'Chrome DevTools Protocol', for\ncontrolling a headless Chrome web browser. %...!% %...>% %...T!% %...T>% %>% %T>% Browser catch Chrome chrome_versions_add chrome_versions_list chrome_versions_path chrome_versions_path_cache chrome_versions_remove ChromeRemote Chromote chromote_info ChromoteSession default_chrome_args default_chromote_object finally find_chrome get_chrome_args has_default_chromote_object local_chrome_version local_chromote_chrome promise set_chrome_args set_default_chromote_object then with_chrome_version with_chromote_chrome "
  },
  {
    "id": 979,
    "package_name": "pkgload",
    "title": "Simulate Package Installation and Attach",
    "description": "Simulates the process of installing a package and then\nattaching it. This is a key part of the 'devtools' package as\nit allows you to rapidly iterate while developing a package.",
    "version": "1.4.1.9000",
    "maintainer": "Lionel Henry <lionel@posit.co>",
    "author": "Hadley Wickham [aut],\nWinston Chang [aut],\nJim Hester [aut],\nLionel Henry [aut, cre],\nPosit Software, PBC [cph, fnd],\nR Core team [ctb] (Some namespace and vignette code extracted from base\nR)",
    "url": "https://github.com/r-lib/pkgload, https://pkgload.r-lib.org",
    "bug_reports": "https://github.com/r-lib/pkgload/issues",
    "repository": "",
    "exports": [
      [
        "check_dep_version"
      ],
      [
        "check_suggested"
      ],
      [
        "dev_example"
      ],
      [
        "dev_help"
      ],
      [
        "dev_meta"
      ],
      [
        "dev_topic_find"
      ],
      [
        "dev_topic_index"
      ],
      [
        "dev_topic_index_reset"
      ],
      [
        "has_tests"
      ],
      [
        "imports_env"
      ],
      [
        "inst"
      ],
      [
        "is_dev_package"
      ],
      [
        "is_loading"
      ],
      [
        "load_all"
      ],
      [
        "load_code"
      ],
      [
        "load_data"
      ],
      [
        "load_dll"
      ],
      [
        "ns_env"
      ],
      [
        "package_file"
      ],
      [
        "parse_deps"
      ],
      [
        "parse_ns_file"
      ],
      [
        "pkg_desc"
      ],
      [
        "pkg_env"
      ],
      [
        "pkg_name"
      ],
      [
        "pkg_ns"
      ],
      [
        "pkg_path"
      ],
      [
        "pkg_version"
      ],
      [
        "pkg_version_raw"
      ],
      [
        "pkgtest"
      ],
      [
        "run_example"
      ],
      [
        "unload"
      ],
      [
        "unregister"
      ]
    ],
    "topics": [],
    "score": 14.2534,
    "stars": 59,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "pkgload Simulate Package Installation and Attach Simulates the process of installing a package and then\nattaching it. This is a key part of the 'devtools' package as\nit allows you to rapidly iterate while developing a package. check_dep_version check_suggested dev_example dev_help dev_meta dev_topic_find dev_topic_index dev_topic_index_reset has_tests imports_env inst is_dev_package is_loading load_all load_code load_data load_dll ns_env package_file parse_deps parse_ns_file pkg_desc pkg_env pkg_name pkg_ns pkg_path pkg_version pkg_version_raw pkgtest run_example unload unregister "
  },
  {
    "id": 640,
    "package_name": "gitcreds",
    "title": "Query 'git' Credentials from 'R'",
    "description": "Query, set, delete credentials from the 'git' credential\nstore. Manage 'GitHub' tokens and other 'git' credentials. This\npackage is to be used by other packages that need to\nauthenticate to 'GitHub' and/or other 'git' repositories.",
    "version": "0.1.2.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://gitcreds.r-lib.org/, https://github.com/r-lib/gitcreds",
    "bug_reports": "https://github.com/r-lib/gitcreds/issues",
    "repository": "",
    "exports": [
      [
        "gitcreds_approve"
      ],
      [
        "gitcreds_cache_envvar"
      ],
      [
        "gitcreds_delete"
      ],
      [
        "gitcreds_fill"
      ],
      [
        "gitcreds_get"
      ],
      [
        "gitcreds_list"
      ],
      [
        "gitcreds_list_helpers"
      ],
      [
        "gitcreds_parse_output"
      ],
      [
        "gitcreds_reject"
      ],
      [
        "gitcreds_set"
      ]
    ],
    "topics": [
      [
        "credentials"
      ],
      [
        "credentials-helper"
      ],
      [
        "git"
      ],
      [
        "github"
      ]
    ],
    "score": 14.2174,
    "stars": 30,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "gitcreds Query 'git' Credentials from 'R' Query, set, delete credentials from the 'git' credential\nstore. Manage 'GitHub' tokens and other 'git' credentials. This\npackage is to be used by other packages that need to\nauthenticate to 'GitHub' and/or other 'git' repositories. gitcreds_approve gitcreds_cache_envvar gitcreds_delete gitcreds_fill gitcreds_get gitcreds_list gitcreds_list_helpers gitcreds_parse_output gitcreds_reject gitcreds_set credentials credentials-helper git github"
  },
  {
    "id": 428,
    "package_name": "crul",
    "title": "HTTP Client",
    "description": "A simple HTTP client, with tools for making HTTP requests,\nand mocking HTTP requests. The package is built on R6, and\ntakes inspiration from Ruby's 'faraday' gem\n(<https://rubygems.org/gems/faraday>). The package name is a\nplay on curl, the widely used command line tool for HTTP, and\nthis package is built on top of the R package 'curl', an\ninterface to 'libcurl' (<https://curl.se/libcurl/>).",
    "version": "1.6.0.9000",
    "maintainer": "Scott Chamberlain <myrmecocystus@gmail.com>",
    "author": "Scott Chamberlain [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1444-9135>)",
    "url": "https://docs.ropensci.org/crul/, https://github.com/ropensci/crul,\nhttps://books.ropensci.org/http-testing/",
    "bug_reports": "https://github.com/ropensci/crul/issues",
    "repository": "",
    "exports": [
      [
        "Async"
      ],
      [
        "AsyncQueue"
      ],
      [
        "AsyncVaried"
      ],
      [
        "auth"
      ],
      [
        "crul_settings"
      ],
      [
        "curl_verbose"
      ],
      [
        "handle"
      ],
      [
        "HttpClient"
      ],
      [
        "HttpRequest"
      ],
      [
        "HttpResponse"
      ],
      [
        "mock"
      ],
      [
        "ok"
      ],
      [
        "Paginator"
      ],
      [
        "proxy"
      ],
      [
        "set_auth"
      ],
      [
        "set_headers"
      ],
      [
        "set_opts"
      ],
      [
        "set_proxy"
      ],
      [
        "set_verbose"
      ],
      [
        "upload"
      ],
      [
        "url_build"
      ],
      [
        "url_parse"
      ]
    ],
    "topics": [
      [
        "http"
      ],
      [
        "https"
      ],
      [
        "api"
      ],
      [
        "web-services"
      ],
      [
        "curl"
      ],
      [
        "download"
      ],
      [
        "libcurl"
      ],
      [
        "async"
      ],
      [
        "mocking"
      ],
      [
        "caching"
      ]
    ],
    "score": 14.1266,
    "stars": 107,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "crul HTTP Client A simple HTTP client, with tools for making HTTP requests,\nand mocking HTTP requests. The package is built on R6, and\ntakes inspiration from Ruby's 'faraday' gem\n(<https://rubygems.org/gems/faraday>). The package name is a\nplay on curl, the widely used command line tool for HTTP, and\nthis package is built on top of the R package 'curl', an\ninterface to 'libcurl' (<https://curl.se/libcurl/>). Async AsyncQueue AsyncVaried auth crul_settings curl_verbose handle HttpClient HttpRequest HttpResponse mock ok Paginator proxy set_auth set_headers set_opts set_proxy set_verbose upload url_build url_parse http https api web-services curl download libcurl async mocking caching"
  },
  {
    "id": 1159,
    "package_name": "rstantools",
    "title": "Tools for Developing R Packages Interfacing with 'Stan'",
    "description": "Provides various tools for developers of R packages\ninterfacing with 'Stan' <https://mc-stan.org>, including\nfunctions to set up the required package structure, S3 generics\nand default methods to unify function naming across\n'Stan'-based R packages, and vignettes with recommendations for\ndevelopers.",
    "version": "2.5.0.9000",
    "maintainer": "Jonah Gabry <jgabry@gmail.com>",
    "author": "Jonah Gabry [aut, cre],\nBen Goodrich [aut],\nMartin Lysy [aut],\nAndrew Johnson [aut],\nHamada S. Badr [ctb],\nMarco Colombo [ctb],\nStefan Siegert [ctb],\nTrustees of Columbia University [cph]",
    "url": "https://mc-stan.org/rstantools/, https://discourse.mc-stan.org/",
    "bug_reports": "https://github.com/stan-dev/rstantools/issues",
    "repository": "",
    "exports": [
      [
        "bayes_R2"
      ],
      [
        "init_cpp"
      ],
      [
        "log_lik"
      ],
      [
        "loo_epred"
      ],
      [
        "loo_linpred"
      ],
      [
        "loo_pit"
      ],
      [
        "loo_predict"
      ],
      [
        "loo_predictive_interval"
      ],
      [
        "loo_R2"
      ],
      [
        "nsamples"
      ],
      [
        "posterior_epred"
      ],
      [
        "posterior_interval"
      ],
      [
        "posterior_linpred"
      ],
      [
        "posterior_predict"
      ],
      [
        "predictive_error"
      ],
      [
        "predictive_interval"
      ],
      [
        "prior_summary"
      ],
      [
        "rstan_config"
      ],
      [
        "rstan_create_package"
      ],
      [
        "rstantools_load_code"
      ],
      [
        "use_rstan"
      ]
    ],
    "topics": [
      [
        "bayesian-data-analysis"
      ],
      [
        "bayesian-statistics"
      ],
      [
        "developer-tools"
      ],
      [
        "stan"
      ]
    ],
    "score": 13.7585,
    "stars": 50,
    "primary_category": "statistics",
    "source_universe": "stan-dev",
    "search_text": "rstantools Tools for Developing R Packages Interfacing with 'Stan' Provides various tools for developers of R packages\ninterfacing with 'Stan' <https://mc-stan.org>, including\nfunctions to set up the required package structure, S3 generics\nand default methods to unify function naming across\n'Stan'-based R packages, and vignettes with recommendations for\ndevelopers. bayes_R2 init_cpp log_lik loo_epred loo_linpred loo_pit loo_predict loo_predictive_interval loo_R2 nsamples posterior_epred posterior_interval posterior_linpred posterior_predict predictive_error predictive_interval prior_summary rstan_config rstan_create_package rstantools_load_code use_rstan bayesian-data-analysis bayesian-statistics developer-tools stan"
  },
  {
    "id": 935,
    "package_name": "packrat",
    "title": "A Dependency Management System for Projects and their R Package\nDependencies",
    "description": "Manage the R packages your project depends on in an\nisolated, portable, and reproducible way.",
    "version": "0.9.3.9000",
    "maintainer": "Aron Atkins <aron@posit.co>",
    "author": "Aron Atkins [aut, cre],\nToph Allen [aut],\nKevin Ushey [aut],\nJonathan McPherson [aut],\nJoe Cheng [aut],\nJJ Allaire [aut],\nPosit Software, PBC [cph, fnd]",
    "url": "https://github.com/rstudio/packrat",
    "bug_reports": "https://github.com/rstudio/packrat/issues",
    "repository": "",
    "exports": [
      [
        ".snapshotImpl"
      ],
      [
        "bundle"
      ],
      [
        "bundles_dir"
      ],
      [
        "clean"
      ],
      [
        "disable"
      ],
      [
        "extlib"
      ],
      [
        "get_lockfile_metadata"
      ],
      [
        "get_opts"
      ],
      [
        "init"
      ],
      [
        "install"
      ],
      [
        "install_local"
      ],
      [
        "lib_dir"
      ],
      [
        "off"
      ],
      [
        "on"
      ],
      [
        "opts"
      ],
      [
        "packify"
      ],
      [
        "packrat_lib"
      ],
      [
        "packrat_mode"
      ],
      [
        "project_dir"
      ],
      [
        "repos_add"
      ],
      [
        "repos_add_local"
      ],
      [
        "repos_create"
      ],
      [
        "repos_list"
      ],
      [
        "repos_remove"
      ],
      [
        "repos_set"
      ],
      [
        "repos_set_local"
      ],
      [
        "repos_upload"
      ],
      [
        "restore"
      ],
      [
        "search_path"
      ],
      [
        "set_lockfile_metadata"
      ],
      [
        "set_opts"
      ],
      [
        "snapshot"
      ],
      [
        "src_dir"
      ],
      [
        "status"
      ],
      [
        "unbundle"
      ],
      [
        "unused_packages"
      ],
      [
        "user_lib"
      ],
      [
        "with_extlib"
      ]
    ],
    "topics": [],
    "score": 13.0504,
    "stars": 408,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "packrat A Dependency Management System for Projects and their R Package\nDependencies Manage the R packages your project depends on in an\nisolated, portable, and reproducible way. .snapshotImpl bundle bundles_dir clean disable extlib get_lockfile_metadata get_opts init install install_local lib_dir off on opts packify packrat_lib packrat_mode project_dir repos_add repos_add_local repos_create repos_list repos_remove repos_set repos_set_local repos_upload restore search_path set_lockfile_metadata set_opts snapshot src_dir status unbundle unused_packages user_lib with_extlib "
  },
  {
    "id": 745,
    "package_name": "leafem",
    "title": "'leaflet' Extensions for 'mapview'",
    "description": "Provides extensions for packages 'leaflet' & 'mapdeck',\nmany of which are used by package 'mapview'. Focus is on\nfunctionality readily available in Geographic Information\nSystems such as 'Quantum GIS'. Includes functions to display\ncoordinates of mouse pointer position, query image values via\nmouse pointer and zoom-to-layer buttons. Additionally, provides\na feature type agnostic function to add points, lines, polygons\nto a map.",
    "version": "0.2.5",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "author": "Tim Appelhans [cre, aut],\nChristoph Reudenbach [ctb],\nKenton Russell [ctb],\nJochen Darley [ctb],\nDaniel Montague [ctb, cph] (Leaflet.EasyButton plugin),\nLorenzo Busetto [ctb],\nLuigi Ranghetti [ctb],\nMiles McBain [ctb],\nSebastian Gatscha [ctb],\nBj\u00f6rn Harrtell [ctb, cph] (FlatGeobuf plugin),\nDaniel Dufour [ctb, cph] (georaster-layer-for-leaflet),\nYeedle Neuwirth [ctb],\nDerek Friend [ctb],\nKevin Cazelles [ctb] (ORCID: <https://orcid.org/0000-0001-6619-9874>)",
    "url": "https://github.com/r-spatial/leafem,\nhttps://r-spatial.github.io/leafem/",
    "bug_reports": "https://github.com/r-spatial/leafem/issues",
    "repository": "",
    "exports": [
      [
        "addCOG"
      ],
      [
        "addCopyExtent"
      ],
      [
        "addExtent"
      ],
      [
        "addFeatures"
      ],
      [
        "addFgb"
      ],
      [
        "addGeoRaster"
      ],
      [
        "addGeotiff"
      ],
      [
        "addHomeButton"
      ],
      [
        "addImageQuery"
      ],
      [
        "addLocalFile"
      ],
      [
        "addLogo"
      ],
      [
        "addMouseCoordinates"
      ],
      [
        "addPMPoints"
      ],
      [
        "addPMPolygons"
      ],
      [
        "addPMPolylines"
      ],
      [
        "addRasterRGB"
      ],
      [
        "addReactiveFeatures"
      ],
      [
        "addStarsImage"
      ],
      [
        "addStarsRGB"
      ],
      [
        "addStaticLabels"
      ],
      [
        "addTileFolder"
      ],
      [
        "clip2sfc"
      ],
      [
        "colorOptions"
      ],
      [
        "customizeLayersControl"
      ],
      [
        "garnishMap"
      ],
      [
        "hideLogo"
      ],
      [
        "imagequeryOptions"
      ],
      [
        "paintRules"
      ],
      [
        "removeHomeButton"
      ],
      [
        "removeLogo"
      ],
      [
        "removeMouseCoordinates"
      ],
      [
        "showLogo"
      ],
      [
        "updateLayersControl"
      ],
      [
        "updateLogo"
      ]
    ],
    "topics": [],
    "score": 12.6429,
    "stars": 110,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "leafem 'leaflet' Extensions for 'mapview' Provides extensions for packages 'leaflet' & 'mapdeck',\nmany of which are used by package 'mapview'. Focus is on\nfunctionality readily available in Geographic Information\nSystems such as 'Quantum GIS'. Includes functions to display\ncoordinates of mouse pointer position, query image values via\nmouse pointer and zoom-to-layer buttons. Additionally, provides\na feature type agnostic function to add points, lines, polygons\nto a map. addCOG addCopyExtent addExtent addFeatures addFgb addGeoRaster addGeotiff addHomeButton addImageQuery addLocalFile addLogo addMouseCoordinates addPMPoints addPMPolygons addPMPolylines addRasterRGB addReactiveFeatures addStarsImage addStarsRGB addStaticLabels addTileFolder clip2sfc colorOptions customizeLayersControl garnishMap hideLogo imagequeryOptions paintRules removeHomeButton removeLogo removeMouseCoordinates showLogo updateLayersControl updateLogo "
  },
  {
    "id": 490,
    "package_name": "downlit",
    "title": "Syntax Highlighting and Automatic Linking",
    "description": "Syntax highlighting of R code, specifically designed for\nthe needs of 'RMarkdown' packages like 'pkgdown', 'hugodown',\nand 'bookdown'. It includes linking of function calls to their\ndocumentation on the web, and automatic translation of ANSI\nescapes in output to the equivalent HTML.",
    "version": "0.4.5.9000",
    "maintainer": "Hadley Wickham <hadley@posit.co>",
    "author": "Hadley Wickham [aut, cre],\nPosit Software, PBC [cph, fnd]",
    "url": "https://downlit.r-lib.org/, https://github.com/r-lib/downlit",
    "bug_reports": "https://github.com/r-lib/downlit/issues",
    "repository": "",
    "exports": [
      [
        "autolink"
      ],
      [
        "autolink_url"
      ],
      [
        "classes_chroma"
      ],
      [
        "classes_pandoc"
      ],
      [
        "downlit_html_node"
      ],
      [
        "downlit_html_path"
      ],
      [
        "downlit_md_path"
      ],
      [
        "downlit_md_string"
      ],
      [
        "evaluate_and_highlight"
      ],
      [
        "highlight"
      ],
      [
        "href_article"
      ],
      [
        "href_package"
      ],
      [
        "href_topic"
      ],
      [
        "is_low_change"
      ]
    ],
    "topics": [
      [
        "syntax-highlighting"
      ]
    ],
    "score": 12.552,
    "stars": 90,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "downlit Syntax Highlighting and Automatic Linking Syntax highlighting of R code, specifically designed for\nthe needs of 'RMarkdown' packages like 'pkgdown', 'hugodown',\nand 'bookdown'. It includes linking of function calls to their\ndocumentation on the web, and automatic translation of ANSI\nescapes in output to the equivalent HTML. autolink autolink_url classes_chroma classes_pandoc downlit_html_node downlit_html_path downlit_md_path downlit_md_string evaluate_and_highlight highlight href_article href_package href_topic is_low_change syntax-highlighting"
  },
  {
    "id": 1046,
    "package_name": "r2d3",
    "title": "Interface to 'D3' Visualizations",
    "description": "Suite of tools for using 'D3', a library for producing\ndynamic, interactive data visualizations. Supports translating\nobjects into 'D3' friendly data structures, rendering 'D3'\nscripts, publishing 'D3' visualizations, incorporating 'D3' in\nR Markdown, creating interactive 'D3' applications with Shiny,\nand distributing 'D3' based 'htmlwidgets' in R packages.",
    "version": "0.2.5",
    "maintainer": "Nick Strayer <nick.strayer@rstudio.com>",
    "author": "Nick Strayer [aut, cre],\nJavier Luraschi [aut],\nJJ Allaire [aut],\nMike Bostock [ctb, cph] (d3.js library, http://d3js.org),\nRStudio [cph]",
    "url": "https://rstudio.github.io/r2d3/, https://github.com/rstudio/r2d3",
    "bug_reports": "https://github.com/rstudio/r2d3/issues",
    "repository": "",
    "exports": [
      [
        "as_d3_data"
      ],
      [
        "d3Output"
      ],
      [
        "default_sizing"
      ],
      [
        "html_dependencies_d3"
      ],
      [
        "r2d3"
      ],
      [
        "read_json"
      ],
      [
        "renderD3"
      ],
      [
        "save_d3_html"
      ],
      [
        "save_d3_png"
      ],
      [
        "sizingPolicy"
      ]
    ],
    "topics": [
      [
        "d3"
      ],
      [
        "r2d3"
      ],
      [
        "visualization"
      ]
    ],
    "score": 12.3205,
    "stars": 525,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "r2d3 Interface to 'D3' Visualizations Suite of tools for using 'D3', a library for producing\ndynamic, interactive data visualizations. Supports translating\nobjects into 'D3' friendly data structures, rendering 'D3'\nscripts, publishing 'D3' visualizations, incorporating 'D3' in\nR Markdown, creating interactive 'D3' applications with Shiny,\nand distributing 'D3' based 'htmlwidgets' in R packages. as_d3_data d3Output default_sizing html_dependencies_d3 r2d3 read_json renderD3 save_d3_html save_d3_png sizingPolicy d3 r2d3 visualization"
  },
  {
    "id": 1380,
    "package_name": "treeio",
    "title": "Base Classes and Functions for Phylogenetic Tree Input and\nOutput",
    "description": "'treeio' is an R package to make it easier to import and\nstore phylogenetic tree with associated data; and to link\nexternal data from different sources to phylogeny. It also\nsupports exporting phylogenetic tree with heterogeneous\nassociated data to a single tree file and can be served as a\nplatform for merging tree with associated data and converting\nfile formats.",
    "version": "1.35.0",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-6485-8781>),\nTommy Tsan-Yuk Lam [ctb, ths],\nShuangbin Xu [ctb] (ORCID: <https://orcid.org/0000-0003-3513-5362>),\nBradley Jones [ctb],\nCasey Dunn [ctb],\nTyler Bradley [ctb],\nKonstantinos Geles [ctb]",
    "url": "https://yulab-smu.top/contribution-tree-data/",
    "bug_reports": "https://github.com/YuLab-SMU/treeio/issues",
    "repository": "",
    "exports": [
      [
        ".data"
      ],
      [
        "%<>%"
      ],
      [
        "%>%"
      ],
      [
        "ancestor"
      ],
      [
        "as_tibble"
      ],
      [
        "as.phylo"
      ],
      [
        "as.treedata"
      ],
      [
        "child"
      ],
      [
        "drop.tip"
      ],
      [
        "find.hclust"
      ],
      [
        "full_join"
      ],
      [
        "get.data"
      ],
      [
        "get.fields"
      ],
      [
        "get.placements"
      ],
      [
        "get.tree"
      ],
      [
        "get.treetext"
      ],
      [
        "getNodeNum"
      ],
      [
        "inner_join"
      ],
      [
        "is.ggtree"
      ],
      [
        "is.rooted"
      ],
      [
        "isTip"
      ],
      [
        "label_branch_paml"
      ],
      [
        "mask"
      ],
      [
        "merge_tree"
      ],
      [
        "MRCA"
      ],
      [
        "Nnode"
      ],
      [
        "Nnode2"
      ],
      [
        "nodeid"
      ],
      [
        "nodelab"
      ],
      [
        "Ntip"
      ],
      [
        "offspring"
      ],
      [
        "parent"
      ],
      [
        "raxml2nwk"
      ],
      [
        "read.astral"
      ],
      [
        "read.beast"
      ],
      [
        "read.beast.newick"
      ],
      [
        "read.codeml"
      ],
      [
        "read.codeml_mlc"
      ],
      [
        "read.fasta"
      ],
      [
        "read.hyphy"
      ],
      [
        "read.hyphy.seq"
      ],
      [
        "read.iqtree"
      ],
      [
        "read.jplace"
      ],
      [
        "read.jtree"
      ],
      [
        "read.mcmctree"
      ],
      [
        "read.mega"
      ],
      [
        "read.mega_tabular"
      ],
      [
        "read.mrbayes"
      ],
      [
        "read.newick"
      ],
      [
        "read.nextstrain.json"
      ],
      [
        "read.nexus"
      ],
      [
        "read.nhx"
      ],
      [
        "read.paml_rst"
      ],
      [
        "read.phylip"
      ],
      [
        "read.phylip.seq"
      ],
      [
        "read.phylip.tree"
      ],
      [
        "read.phyloxml"
      ],
      [
        "read.r8s"
      ],
      [
        "read.raxml"
      ],
      [
        "read.tree"
      ],
      [
        "read.treeqza"
      ],
      [
        "read.treetime"
      ],
      [
        "rename_taxa"
      ],
      [
        "rescale_tree"
      ],
      [
        "root"
      ],
      [
        "rootnode"
      ],
      [
        "rtree"
      ],
      [
        "spt"
      ],
      [
        "tibble"
      ],
      [
        "treedata"
      ],
      [
        "write.beast"
      ],
      [
        "write.beast.newick"
      ],
      [
        "write.jplace"
      ],
      [
        "write.jtree"
      ],
      [
        "write.nexus"
      ],
      [
        "write.tree"
      ]
    ],
    "topics": [
      [
        "software"
      ],
      [
        "annotation"
      ],
      [
        "clustering"
      ],
      [
        "dataimport"
      ],
      [
        "datarepresentation"
      ],
      [
        "alignment"
      ],
      [
        "multiplesequencealignment"
      ],
      [
        "phylogenetics"
      ],
      [
        "exporter"
      ],
      [
        "parser"
      ],
      [
        "phylogenetic-trees"
      ]
    ],
    "score": 11.975,
    "stars": 103,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "treeio Base Classes and Functions for Phylogenetic Tree Input and\nOutput 'treeio' is an R package to make it easier to import and\nstore phylogenetic tree with associated data; and to link\nexternal data from different sources to phylogeny. It also\nsupports exporting phylogenetic tree with heterogeneous\nassociated data to a single tree file and can be served as a\nplatform for merging tree with associated data and converting\nfile formats. .data %<>% %>% ancestor as_tibble as.phylo as.treedata child drop.tip find.hclust full_join get.data get.fields get.placements get.tree get.treetext getNodeNum inner_join is.ggtree is.rooted isTip label_branch_paml mask merge_tree MRCA Nnode Nnode2 nodeid nodelab Ntip offspring parent raxml2nwk read.astral read.beast read.beast.newick read.codeml read.codeml_mlc read.fasta read.hyphy read.hyphy.seq read.iqtree read.jplace read.jtree read.mcmctree read.mega read.mega_tabular read.mrbayes read.newick read.nextstrain.json read.nexus read.nhx read.paml_rst read.phylip read.phylip.seq read.phylip.tree read.phyloxml read.r8s read.raxml read.tree read.treeqza read.treetime rename_taxa rescale_tree root rootnode rtree spt tibble treedata write.beast write.beast.newick write.jplace write.jtree write.nexus write.tree software annotation clustering dataimport datarepresentation alignment multiplesequencealignment phylogenetics exporter parser phylogenetic-trees"
  },
  {
    "id": 824,
    "package_name": "mockery",
    "title": "Mocking Library for R",
    "description": "The two main functionalities of this package are creating\nmock objects (functions) and selectively intercepting calls to\na given function that originate in some other function. It can\nbe used with any testing framework available for R. Mock\nobjects can be injected with either this package's own stub()\nfunction or a similar with_mocked_binding() facility present in\nthe 'testthat' package.",
    "version": "0.4.5.9000",
    "maintainer": "Hadley Wickham <hadley@posit.co>",
    "author": "Noam Finkelstein [aut],\nLukasz Bartnik [aut],\nJim Hester [aut],\nHadley Wickham [aut, cre]",
    "url": "https://github.com/r-lib/mockery",
    "bug_reports": "https://github.com/r-lib/mockery/issues",
    "repository": "",
    "exports": [
      [
        "expect_args"
      ],
      [
        "expect_call"
      ],
      [
        "expect_called"
      ],
      [
        "mock"
      ],
      [
        "mock_args"
      ],
      [
        "mock_calls"
      ],
      [
        "stub"
      ]
    ],
    "topics": [],
    "score": 11.9499,
    "stars": 104,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "mockery Mocking Library for R The two main functionalities of this package are creating\nmock objects (functions) and selectively intercepting calls to\na given function that originate in some other function. It can\nbe used with any testing framework available for R. Mock\nobjects can be injected with either this package's own stub()\nfunction or a similar with_mocked_binding() facility present in\nthe 'testthat' package. expect_args expect_call expect_called mock mock_args mock_calls stub "
  },
  {
    "id": 929,
    "package_name": "otel",
    "title": "OpenTelemetry R API",
    "description": "High-quality, ubiquitous, and portable telemetry to enable\neffective observability. OpenTelemetry is a collection of\ntools, APIs, and SDKs used to instrument, generate, collect,\nand export telemetry data (metrics, logs, and traces) for\nanalysis in order to understand your software's performance and\nbehavior. This package implements the OpenTelemetry API:\n<https://opentelemetry.io/docs/specs/otel/>. Use this package\nas a dependency if you want to instrument your R package for\nOpenTelemetry.",
    "version": "0.2.0.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre]",
    "url": "https://otel.r-lib.org, https://github.com/r-lib/otel",
    "bug_reports": "https://github.com/r-lib/otel/issues",
    "repository": "",
    "exports": [
      [
        "as_attributes"
      ],
      [
        "counter_add"
      ],
      [
        "default_tracer_name"
      ],
      [
        "end_span"
      ],
      [
        "extract_http_context"
      ],
      [
        "gauge_record"
      ],
      [
        "get_active_span"
      ],
      [
        "get_active_span_context"
      ],
      [
        "get_default_logger_provider"
      ],
      [
        "get_default_meter_provider"
      ],
      [
        "get_default_tracer_provider"
      ],
      [
        "get_logger"
      ],
      [
        "get_meter"
      ],
      [
        "get_tracer"
      ],
      [
        "histogram_record"
      ],
      [
        "invalid_span_id"
      ],
      [
        "invalid_trace_id"
      ],
      [
        "is_logging_enabled"
      ],
      [
        "is_measuring_enabled"
      ],
      [
        "is_tracing_enabled"
      ],
      [
        "local_active_span"
      ],
      [
        "log"
      ],
      [
        "log_debug"
      ],
      [
        "log_error"
      ],
      [
        "log_fatal"
      ],
      [
        "log_info"
      ],
      [
        "log_severity_levels"
      ],
      [
        "log_trace"
      ],
      [
        "log_warn"
      ],
      [
        "logger_provider_noop"
      ],
      [
        "meter_provider_noop"
      ],
      [
        "pack_http_context"
      ],
      [
        "span_kinds"
      ],
      [
        "span_status_codes"
      ],
      [
        "start_local_active_span"
      ],
      [
        "start_span"
      ],
      [
        "tracer_provider_noop"
      ],
      [
        "up_down_counter_add"
      ],
      [
        "with_active_span"
      ]
    ],
    "topics": [],
    "score": 11.9493,
    "stars": 19,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "otel OpenTelemetry R API High-quality, ubiquitous, and portable telemetry to enable\neffective observability. OpenTelemetry is a collection of\ntools, APIs, and SDKs used to instrument, generate, collect,\nand export telemetry data (metrics, logs, and traces) for\nanalysis in order to understand your software's performance and\nbehavior. This package implements the OpenTelemetry API:\n<https://opentelemetry.io/docs/specs/otel/>. Use this package\nas a dependency if you want to instrument your R package for\nOpenTelemetry. as_attributes counter_add default_tracer_name end_span extract_http_context gauge_record get_active_span get_active_span_context get_default_logger_provider get_default_meter_provider get_default_tracer_provider get_logger get_meter get_tracer histogram_record invalid_span_id invalid_trace_id is_logging_enabled is_measuring_enabled is_tracing_enabled local_active_span log log_debug log_error log_fatal log_info log_severity_levels log_trace log_warn logger_provider_noop meter_provider_noop pack_http_context span_kinds span_status_codes start_local_active_span start_span tracer_provider_noop up_down_counter_add with_active_span "
  },
  {
    "id": 1397,
    "package_name": "tzdb",
    "title": "Time Zone Database Information",
    "description": "Provides an up-to-date copy of the Internet Assigned\nNumbers Authority (IANA) Time Zone Database. It is updated\nperiodically to reflect changes made by political bodies to\ntime zone boundaries, UTC offsets, and daylight saving time\nrules. Additionally, this package provides a C++ interface for\nworking with the 'date' library. 'date' provides comprehensive\nsupport for working with dates and date-times, which this\npackage exposes to make it easier for other R packages to\nutilize. Headers are provided for calendar specific\ncalculations, along with a limited interface for time zone\nmanipulations.",
    "version": "0.5.0.9000",
    "maintainer": "Davis Vaughan <davis@posit.co>",
    "author": "Davis Vaughan [aut, cre],\nHoward Hinnant [cph] (Author of the included date library),\nPosit Software, PBC [cph, fnd]",
    "url": "https://tzdb.r-lib.org, https://github.com/r-lib/tzdb",
    "bug_reports": "https://github.com/r-lib/tzdb/issues",
    "repository": "",
    "exports": [
      [
        "tzdb_initialize"
      ],
      [
        "tzdb_names"
      ],
      [
        "tzdb_path"
      ],
      [
        "tzdb_version"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 11.8088,
    "stars": 7,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "tzdb Time Zone Database Information Provides an up-to-date copy of the Internet Assigned\nNumbers Authority (IANA) Time Zone Database. It is updated\nperiodically to reflect changes made by political bodies to\ntime zone boundaries, UTC offsets, and daylight saving time\nrules. Additionally, this package provides a C++ interface for\nworking with the 'date' library. 'date' provides comprehensive\nsupport for working with dates and date-times, which this\npackage exposes to make it easier for other R packages to\nutilize. Headers are provided for calendar specific\ncalculations, along with a limited interface for time zone\nmanipulations. tzdb_initialize tzdb_names tzdb_path tzdb_version cpp"
  },
  {
    "id": 1301,
    "package_name": "tarchetypes",
    "title": "Archetypes for Targets",
    "description": "Function-oriented Make-like declarative pipelines for\nStatistics and data science are supported in the 'targets' R\npackage. As an extension to 'targets', the 'tarchetypes'\npackage provides convenient user-side functions to make\n'targets' easier to use. By establishing reusable archetypes\nfor common kinds of targets and pipelines, these functions help\nexpress complicated reproducible pipelines concisely and\ncompactly. The methods in this package were influenced by the\n'targets' R package. by Will Landau (2018)\n<doi:10.21105/joss.00550>.",
    "version": "0.13.2.9004",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1878-3253>),\nRudolf Siegel [ctb] (ORCID: <https://orcid.org/0000-0002-6021-804X>),\nSamantha Oliver [rev] (ORCID: <https://orcid.org/0000-0001-5668-1165>),\nTristan Mahr [rev] (ORCID: <https://orcid.org/0000-0002-8890-5116>),\nEli Lilly and Company [cph, fnd]",
    "url": "https://docs.ropensci.org/tarchetypes/,\nhttps://github.com/ropensci/tarchetypes",
    "bug_reports": "https://github.com/ropensci/tarchetypes/issues",
    "repository": "",
    "exports": [
      [
        "all_of"
      ],
      [
        "any_of"
      ],
      [
        "contains"
      ],
      [
        "counter_init"
      ],
      [
        "counter_set_names"
      ],
      [
        "ends_with"
      ],
      [
        "everything"
      ],
      [
        "last_col"
      ],
      [
        "matches"
      ],
      [
        "num_range"
      ],
      [
        "one_of"
      ],
      [
        "starts_with"
      ],
      [
        "tar_age"
      ],
      [
        "tar_append_static_values"
      ],
      [
        "tar_arrow_feather"
      ],
      [
        "tar_assign"
      ],
      [
        "tar_aws_file"
      ],
      [
        "tar_aws_fst"
      ],
      [
        "tar_aws_fst_dt"
      ],
      [
        "tar_aws_fst_tbl"
      ],
      [
        "tar_aws_keras"
      ],
      [
        "tar_aws_parquet"
      ],
      [
        "tar_aws_qs"
      ],
      [
        "tar_aws_rds"
      ],
      [
        "tar_aws_torch"
      ],
      [
        "tar_change"
      ],
      [
        "tar_combine"
      ],
      [
        "tar_combine_raw"
      ],
      [
        "tar_cue_age"
      ],
      [
        "tar_cue_age_raw"
      ],
      [
        "tar_cue_force"
      ],
      [
        "tar_cue_skip"
      ],
      [
        "tar_download"
      ],
      [
        "tar_download_run"
      ],
      [
        "tar_eval"
      ],
      [
        "tar_eval_raw"
      ],
      [
        "tar_file"
      ],
      [
        "tar_file_fast"
      ],
      [
        "tar_file_read"
      ],
      [
        "tar_files"
      ],
      [
        "tar_files_input"
      ],
      [
        "tar_files_input_raw"
      ],
      [
        "tar_files_raw"
      ],
      [
        "tar_force"
      ],
      [
        "tar_force_change"
      ],
      [
        "tar_format_aws_feather"
      ],
      [
        "tar_format_feather"
      ],
      [
        "tar_format_nanoparquet"
      ],
      [
        "tar_fst"
      ],
      [
        "tar_fst_dt"
      ],
      [
        "tar_fst_tbl"
      ],
      [
        "tar_group_by"
      ],
      [
        "tar_group_by_run"
      ],
      [
        "tar_group_count"
      ],
      [
        "tar_group_count_index"
      ],
      [
        "tar_group_count_run"
      ],
      [
        "tar_group_select"
      ],
      [
        "tar_group_select_run"
      ],
      [
        "tar_group_size"
      ],
      [
        "tar_group_size_index"
      ],
      [
        "tar_group_size_run"
      ],
      [
        "tar_hook_before"
      ],
      [
        "tar_hook_before_raw"
      ],
      [
        "tar_hook_inner"
      ],
      [
        "tar_hook_inner_raw"
      ],
      [
        "tar_hook_outer"
      ],
      [
        "tar_hook_outer_raw"
      ],
      [
        "tar_keras"
      ],
      [
        "tar_knit"
      ],
      [
        "tar_knit_raw"
      ],
      [
        "tar_knit_run"
      ],
      [
        "tar_knitr_deps"
      ],
      [
        "tar_knitr_deps_expr"
      ],
      [
        "tar_map"
      ],
      [
        "tar_map_rep"
      ],
      [
        "tar_map_rep_raw"
      ],
      [
        "tar_map2"
      ],
      [
        "tar_map2_count"
      ],
      [
        "tar_map2_count_raw"
      ],
      [
        "tar_map2_group"
      ],
      [
        "tar_map2_raw"
      ],
      [
        "tar_map2_run"
      ],
      [
        "tar_map2_run_rep"
      ],
      [
        "tar_map2_size"
      ],
      [
        "tar_map2_size_raw"
      ],
      [
        "tar_nanoparquet"
      ],
      [
        "tar_nanoparquet_convert"
      ],
      [
        "tar_nanoparquet_read"
      ],
      [
        "tar_nanoparquet_write"
      ],
      [
        "tar_parquet"
      ],
      [
        "tar_plan"
      ],
      [
        "tar_qs"
      ],
      [
        "tar_quarto"
      ],
      [
        "tar_quarto_files"
      ],
      [
        "tar_quarto_raw"
      ],
      [
        "tar_quarto_rep"
      ],
      [
        "tar_quarto_rep_raw"
      ],
      [
        "tar_quarto_rep_rep"
      ],
      [
        "tar_quarto_rep_run"
      ],
      [
        "tar_quarto_rep_run_params"
      ],
      [
        "tar_quarto_run"
      ],
      [
        "tar_rds"
      ],
      [
        "tar_render"
      ],
      [
        "tar_render_raw"
      ],
      [
        "tar_render_rep"
      ],
      [
        "tar_render_rep_raw"
      ],
      [
        "tar_render_rep_rep"
      ],
      [
        "tar_render_rep_run"
      ],
      [
        "tar_render_rep_run_params"
      ],
      [
        "tar_render_run"
      ],
      [
        "tar_rep"
      ],
      [
        "tar_rep_index"
      ],
      [
        "tar_rep_map"
      ],
      [
        "tar_rep_map_raw"
      ],
      [
        "tar_rep_raw"
      ],
      [
        "tar_rep_run"
      ],
      [
        "tar_rep_run_map_rep"
      ],
      [
        "tar_rep2"
      ],
      [
        "tar_rep2_raw"
      ],
      [
        "tar_rep2_run"
      ],
      [
        "tar_rep2_run_rep"
      ],
      [
        "tar_select_names"
      ],
      [
        "tar_select_targets"
      ],
      [
        "tar_skip"
      ],
      [
        "tar_sub"
      ],
      [
        "tar_sub_raw"
      ],
      [
        "tar_tangle"
      ],
      [
        "tar_torch"
      ],
      [
        "tar_url"
      ],
      [
        "walk_ast"
      ],
      [
        "walk_call_knitr"
      ]
    ],
    "topics": [
      [
        "data-science"
      ],
      [
        "high-performance-computing"
      ],
      [
        "peer-reviewed"
      ],
      [
        "pipeline"
      ],
      [
        "r-targetopia"
      ],
      [
        "reproducibility"
      ],
      [
        "targets"
      ],
      [
        "workflow"
      ]
    ],
    "score": 11.7048,
    "stars": 146,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "tarchetypes Archetypes for Targets Function-oriented Make-like declarative pipelines for\nStatistics and data science are supported in the 'targets' R\npackage. As an extension to 'targets', the 'tarchetypes'\npackage provides convenient user-side functions to make\n'targets' easier to use. By establishing reusable archetypes\nfor common kinds of targets and pipelines, these functions help\nexpress complicated reproducible pipelines concisely and\ncompactly. The methods in this package were influenced by the\n'targets' R package. by Will Landau (2018)\n<doi:10.21105/joss.00550>. all_of any_of contains counter_init counter_set_names ends_with everything last_col matches num_range one_of starts_with tar_age tar_append_static_values tar_arrow_feather tar_assign tar_aws_file tar_aws_fst tar_aws_fst_dt tar_aws_fst_tbl tar_aws_keras tar_aws_parquet tar_aws_qs tar_aws_rds tar_aws_torch tar_change tar_combine tar_combine_raw tar_cue_age tar_cue_age_raw tar_cue_force tar_cue_skip tar_download tar_download_run tar_eval tar_eval_raw tar_file tar_file_fast tar_file_read tar_files tar_files_input tar_files_input_raw tar_files_raw tar_force tar_force_change tar_format_aws_feather tar_format_feather tar_format_nanoparquet tar_fst tar_fst_dt tar_fst_tbl tar_group_by tar_group_by_run tar_group_count tar_group_count_index tar_group_count_run tar_group_select tar_group_select_run tar_group_size tar_group_size_index tar_group_size_run tar_hook_before tar_hook_before_raw tar_hook_inner tar_hook_inner_raw tar_hook_outer tar_hook_outer_raw tar_keras tar_knit tar_knit_raw tar_knit_run tar_knitr_deps tar_knitr_deps_expr tar_map tar_map_rep tar_map_rep_raw tar_map2 tar_map2_count tar_map2_count_raw tar_map2_group tar_map2_raw tar_map2_run tar_map2_run_rep tar_map2_size tar_map2_size_raw tar_nanoparquet tar_nanoparquet_convert tar_nanoparquet_read tar_nanoparquet_write tar_parquet tar_plan tar_qs tar_quarto tar_quarto_files tar_quarto_raw tar_quarto_rep tar_quarto_rep_raw tar_quarto_rep_rep tar_quarto_rep_run tar_quarto_rep_run_params tar_quarto_run tar_rds tar_render tar_render_raw tar_render_rep tar_render_rep_raw tar_render_rep_rep tar_render_rep_run tar_render_rep_run_params tar_render_run tar_rep tar_rep_index tar_rep_map tar_rep_map_raw tar_rep_raw tar_rep_run tar_rep_run_map_rep tar_rep2 tar_rep2_raw tar_rep2_run tar_rep2_run_rep tar_select_names tar_select_targets tar_skip tar_sub tar_sub_raw tar_tangle tar_torch tar_url walk_ast walk_call_knitr data-science high-performance-computing peer-reviewed pipeline r-targetopia reproducibility targets workflow"
  },
  {
    "id": 1415,
    "package_name": "vdiffr",
    "title": "Visual Regression Testing and Graphical Diffing",
    "description": "An extension to the 'testthat' package that makes it easy\nto add graphical unit tests. It provides a Shiny application to\nmanage the test cases.",
    "version": "1.0.8.9000",
    "maintainer": "Lionel Henry <lionel@posit.co>",
    "author": "Lionel Henry [cre, aut],\nThomas Lin Pedersen [aut] (ORCID:\n<https://orcid.org/0000-0002-5147-4711>),\nPosit Software, PBC [cph, fnd],\nT Jake Luciani [aut] (svglite),\nMatthieu Decorde [aut] (svglite),\nVaudor Lise [aut] (svglite),\nTony Plate [ctb] (svglite: Early line dashing code),\nDavid Gohel [ctb] (svglite: Line dashing code and raster code),\nYixuan Qiu [ctb] (svglite: Improved styles; polypath implementation),\nH\u00e5kon Malmedal [ctb] (svglite: Opacity code)",
    "url": "https://vdiffr.r-lib.org/, https://github.com/r-lib/vdiffr",
    "bug_reports": "https://github.com/r-lib/vdiffr/issues",
    "repository": "",
    "exports": [
      [
        "expect_doppelganger"
      ],
      [
        "write_svg"
      ]
    ],
    "topics": [
      [
        "ggplot2"
      ],
      [
        "graphics"
      ],
      [
        "testthat"
      ],
      [
        "libpng"
      ],
      [
        "cpp"
      ]
    ],
    "score": 11.6,
    "stars": 195,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "vdiffr Visual Regression Testing and Graphical Diffing An extension to the 'testthat' package that makes it easy\nto add graphical unit tests. It provides a Shiny application to\nmanage the test cases. expect_doppelganger write_svg ggplot2 graphics testthat libpng cpp"
  },
  {
    "id": 748,
    "package_name": "leaflet.providers",
    "title": "Leaflet Providers",
    "description": "Contains third-party map tile provider information from\n'Leaflet.js',\n<https://github.com/leaflet-extras/leaflet-providers>, to be\nused with the 'leaflet' R package. Additionally,\n'leaflet.providers' enables users to retrieve up-to-date\nprovider information between package updates.",
    "version": "2.0.0.9000",
    "maintainer": "Barret Schloerke <barret@posit.co>",
    "author": "Leslie Huang [aut],\nBarret Schloerke [ctb, cre] (ORCID:\n<https://orcid.org/0000-0001-9986-114X>),\nLeaflet Providers contributors [ctb, cph] (Leaflet Providers plugin),\nPosit Software, PBC [cph, fnd]",
    "url": "https://rstudio.github.io/leaflet.providers/,\nhttps://github.com/rstudio/leaflet.providers",
    "bug_reports": "https://github.com/rstudio/leaflet.providers/issues",
    "repository": "",
    "exports": [
      [
        "get_providers"
      ],
      [
        "providers_default"
      ],
      [
        "providers_loaded"
      ],
      [
        "use_providers"
      ]
    ],
    "topics": [],
    "score": 11.5446,
    "stars": 15,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "leaflet.providers Leaflet Providers Contains third-party map tile provider information from\n'Leaflet.js',\n<https://github.com/leaflet-extras/leaflet-providers>, to be\nused with the 'leaflet' R package. Additionally,\n'leaflet.providers' enables users to retrieve up-to-date\nprovider information between package updates. get_providers providers_default providers_loaded use_providers "
  },
  {
    "id": 771,
    "package_name": "log4r",
    "title": "A Fast and Lightweight Logging System for R, Based on 'log4j'",
    "description": "The log4r package is meant to provide a fast, lightweight,\nobject-oriented approach to logging in R based on the\nwidely-emulated 'log4j' system and etymology.",
    "version": "0.4.4.9000",
    "maintainer": "Aaron Jacobs <atheriel@gmail.com>",
    "author": "John Myles White [aut, cph],\nKenton White [ctb],\nKirill M\u00fcller [ctb],\nAaron Jacobs [aut, cre]",
    "url": "https://github.com/johnmyleswhite/log4r, https://log4r.r-lib.org",
    "bug_reports": "https://github.com/johnmyleswhite/log4r/issues",
    "repository": "",
    "exports": [
      [
        "as.loglevel"
      ],
      [
        "available.loglevels"
      ],
      [
        "bare_log_layout"
      ],
      [
        "console_appender"
      ],
      [
        "create.logger"
      ],
      [
        "debug"
      ],
      [
        "default_log_layout"
      ],
      [
        "error"
      ],
      [
        "fatal"
      ],
      [
        "file_appender"
      ],
      [
        "http_appender"
      ],
      [
        "info"
      ],
      [
        "is.loglevel"
      ],
      [
        "json_log_layout"
      ],
      [
        "level"
      ],
      [
        "level<-"
      ],
      [
        "levellog"
      ],
      [
        "log_at"
      ],
      [
        "log_debug"
      ],
      [
        "log_error"
      ],
      [
        "log_fatal"
      ],
      [
        "log_info"
      ],
      [
        "log_warn"
      ],
      [
        "logfile"
      ],
      [
        "logfile<-"
      ],
      [
        "logfmt_log_layout"
      ],
      [
        "logformat"
      ],
      [
        "logformat<-"
      ],
      [
        "logger"
      ],
      [
        "loglevel"
      ],
      [
        "simple_log_layout"
      ],
      [
        "syslog_appender"
      ],
      [
        "tcp_appender"
      ],
      [
        "verbosity"
      ],
      [
        "warn"
      ]
    ],
    "topics": [
      [
        "logging"
      ]
    ],
    "score": 11.0088,
    "stars": 99,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "log4r A Fast and Lightweight Logging System for R, Based on 'log4j' The log4r package is meant to provide a fast, lightweight,\nobject-oriented approach to logging in R based on the\nwidely-emulated 'log4j' system and etymology. as.loglevel available.loglevels bare_log_layout console_appender create.logger debug default_log_layout error fatal file_appender http_appender info is.loglevel json_log_layout level level<- levellog log_at log_debug log_error log_fatal log_info log_warn logfile logfile<- logfmt_log_layout logformat logformat<- logger loglevel simple_log_layout syslog_appender tcp_appender verbosity warn logging"
  },
  {
    "id": 746,
    "package_name": "leafgl",
    "title": "High-Performance 'WebGl' Rendering for Package 'leaflet'",
    "description": "Provides bindings to the 'Leaflet.glify' JavaScript\nlibrary which extends the 'leaflet' JavaScript library to\nrender large data in the browser using 'WebGl'.",
    "version": "0.2.2",
    "maintainer": "Tim Appelhans <tim.appelhans@gmail.com>",
    "author": "Tim Appelhans [cre, aut, cph],\nColin Fay [ctb] (ORCID: <https://orcid.org/0000-0001-7343-1846>),\nRobert Plummer [ctb] (Leaflet.glify plugin),\nKent Johnson [ctb],\nSebastian Gatscha [ctb],\nOlivier Roy [ctb]",
    "url": "https://github.com/r-spatial/leafgl,\nhttps://r-spatial.github.io/leafgl/",
    "bug_reports": "https://github.com/r-spatial/leafgl/issues",
    "repository": "",
    "exports": [
      [
        "addGlPoints"
      ],
      [
        "addGlPolygons"
      ],
      [
        "addGlPolylines"
      ],
      [
        "clearGlGroup"
      ],
      [
        "clearGlLayers"
      ],
      [
        "leafglOutput"
      ],
      [
        "makeColorMatrix"
      ],
      [
        "makePopup"
      ],
      [
        "removeGlPoints"
      ],
      [
        "removeGlPolygons"
      ],
      [
        "removeGlPolylines"
      ],
      [
        "renderLeafgl"
      ]
    ],
    "topics": [],
    "score": 10.9782,
    "stars": 285,
    "primary_category": "spatial",
    "source_universe": "r-spatial",
    "search_text": "leafgl High-Performance 'WebGl' Rendering for Package 'leaflet' Provides bindings to the 'Leaflet.glify' JavaScript\nlibrary which extends the 'leaflet' JavaScript library to\nrender large data in the browser using 'WebGl'. addGlPoints addGlPolygons addGlPolylines clearGlGroup clearGlLayers leafglOutput makeColorMatrix makePopup removeGlPoints removeGlPolygons removeGlPolylines renderLeafgl "
  },
  {
    "id": 650,
    "package_name": "goodpractice",
    "title": "Advice on R Package Building",
    "description": "Give advice about good practices when building R packages.\nAdvice includes functions and syntax to avoid, package\nstructure, code complexity, code formatting, etc.",
    "version": "1.0.5.9000",
    "maintainer": "Mark Padgham <mark@ropensci.org>",
    "author": "Mark Padgham [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2172-5265>),\nAscent Digital Services UK Limited [cph] (GitHub: MangoTheCat),\nKarina Marks [aut] (GitHub: KarinaMarks),\nDaniel de Bortoli [aut] (GitHub: ddbortoli),\nGabor Csardi [aut],\nHannah Frick [aut],\nOwen Jones [aut] (GitHub: owenjonesuob),\nHannah Alexander [aut],\nAna Simmons [ctb] (GitHub: anasimmons),\nFabian Scheipl [ctb] (GitHub: fabian-s)",
    "url": "https://docs.ropensci.org/goodpractice/,\nhttps://github.com/ropensci-review-tools/goodpractice",
    "bug_reports": "https://github.com/ropensci-review-tools/goodpractice/issues",
    "repository": "",
    "exports": [
      [
        "all_checks"
      ],
      [
        "checks"
      ],
      [
        "describe_check"
      ],
      [
        "export_json"
      ],
      [
        "failed_checks"
      ],
      [
        "failed_positions"
      ],
      [
        "goodpractice"
      ],
      [
        "gp"
      ],
      [
        "make_check"
      ],
      [
        "make_prep"
      ],
      [
        "results"
      ]
    ],
    "topics": [],
    "score": 10.7358,
    "stars": 471,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "goodpractice Advice on R Package Building Give advice about good practices when building R packages.\nAdvice includes functions and syntax to avoid, package\nstructure, code complexity, code formatting, etc. all_checks checks describe_check export_json failed_checks failed_positions goodpractice gp make_check make_prep results "
  },
  {
    "id": 1066,
    "package_name": "rdflib",
    "title": "Tools to Manipulate and Query Semantic Data",
    "description": "The Resource Description Framework, or 'RDF' is a widely\nused data representation model that forms the cornerstone of\nthe Semantic Web. 'RDF' represents data as a graph rather than\nthe familiar data table or rectangle of relational databases.\nThe 'rdflib' package provides a friendly and concise user\ninterface for performing common tasks on 'RDF' data, such as\nreading, writing and converting between the various\nserializations of 'RDF' data, including 'rdfxml', 'turtle',\n'nquads', 'ntriples', and 'json-ld'; creating new 'RDF' graphs,\nand performing graph queries using 'SPARQL'. This package wraps\nthe low level 'redland' R package which provides direct\nbindings to the 'redland' C library.  Additionally, the package\nsupports the newer and more developer friendly 'JSON-LD' format\nthrough the 'jsonld' package. The package interface takes\ninspiration from the Python 'rdflib' library.",
    "version": "0.2.9",
    "maintainer": "Carl Boettiger <cboettig@gmail.com>",
    "author": "Carl Boettiger [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0002-1642-628X>),\nBryce Mecum [rev] (ORCID: <https://orcid.org/0000-0002-0381-3766>),\nAnna Krystalli [rev] (ORCID: <https://orcid.org/0000-0002-2378-4915>),\nViktor Senderov [ctb] (ORCID: <https://orcid.org/0000-0003-3340-5963>)",
    "url": "https://docs.ropensci.org/rdflib/,\nhttps://github.com/ropensci/rdflib",
    "bug_reports": "https://github.com/ropensci/rdflib/issues",
    "repository": "",
    "exports": [
      [
        "as_rdf"
      ],
      [
        "rdf"
      ],
      [
        "rdf_add"
      ],
      [
        "rdf_free"
      ],
      [
        "rdf_has_bdb"
      ],
      [
        "rdf_parse"
      ],
      [
        "rdf_query"
      ],
      [
        "rdf_serialize"
      ],
      [
        "read_nquads"
      ],
      [
        "write_nquads"
      ]
    ],
    "topics": [
      [
        "peer-reviewed"
      ]
    ],
    "score": 10.3875,
    "stars": 60,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rdflib Tools to Manipulate and Query Semantic Data The Resource Description Framework, or 'RDF' is a widely\nused data representation model that forms the cornerstone of\nthe Semantic Web. 'RDF' represents data as a graph rather than\nthe familiar data table or rectangle of relational databases.\nThe 'rdflib' package provides a friendly and concise user\ninterface for performing common tasks on 'RDF' data, such as\nreading, writing and converting between the various\nserializations of 'RDF' data, including 'rdfxml', 'turtle',\n'nquads', 'ntriples', and 'json-ld'; creating new 'RDF' graphs,\nand performing graph queries using 'SPARQL'. This package wraps\nthe low level 'redland' R package which provides direct\nbindings to the 'redland' C library.  Additionally, the package\nsupports the newer and more developer friendly 'JSON-LD' format\nthrough the 'jsonld' package. The package interface takes\ninspiration from the Python 'rdflib' library. as_rdf rdf rdf_add rdf_free rdf_has_bdb rdf_parse rdf_query rdf_serialize read_nquads write_nquads peer-reviewed"
  },
  {
    "id": 1108,
    "package_name": "rhub",
    "title": "Tools for R Package Developers",
    "description": "R-hub v2 uses GitHub Actions to run 'R CMD check' and\nsimilar package checks. The 'rhub' package helps you set up\nR-hub v2 for your R package, and start running checks.",
    "version": "2.0.1.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nMa\u00eblle Salmon [aut] (ORCID: <https://orcid.org/0000-0002-2815-0399>),\nR Consortium [fnd]",
    "url": "https://github.com/r-hub/rhub, https://r-hub.github.io/rhub/",
    "bug_reports": "https://github.com/r-hub/rhub/issues",
    "repository": "",
    "exports": [
      [
        "check"
      ],
      [
        "check_for_cran"
      ],
      [
        "check_on_centos"
      ],
      [
        "check_on_debian"
      ],
      [
        "check_on_fedora"
      ],
      [
        "check_on_linux"
      ],
      [
        "check_on_macos"
      ],
      [
        "check_on_solaris"
      ],
      [
        "check_on_ubuntu"
      ],
      [
        "check_on_windows"
      ],
      [
        "check_with_rdevel"
      ],
      [
        "check_with_roldrel"
      ],
      [
        "check_with_rpatched"
      ],
      [
        "check_with_rrelease"
      ],
      [
        "check_with_sanitizers"
      ],
      [
        "check_with_valgrind"
      ],
      [
        "get_check"
      ],
      [
        "last_check"
      ],
      [
        "list_my_checks"
      ],
      [
        "list_package_checks"
      ],
      [
        "list_validated_emails"
      ],
      [
        "local_check_linux"
      ],
      [
        "local_check_linux_images"
      ],
      [
        "platforms"
      ],
      [
        "rc_list_local_tokens"
      ],
      [
        "rc_list_repos"
      ],
      [
        "rc_new_token"
      ],
      [
        "rc_submit"
      ],
      [
        "rhub_check"
      ],
      [
        "rhub_doctor"
      ],
      [
        "rhub_platforms"
      ],
      [
        "rhub_setup"
      ],
      [
        "validate_email"
      ]
    ],
    "topics": [],
    "score": 10.2558,
    "stars": 366,
    "primary_category": "infrastructure",
    "source_universe": "r-hub",
    "search_text": "rhub Tools for R Package Developers R-hub v2 uses GitHub Actions to run 'R CMD check' and\nsimilar package checks. The 'rhub' package helps you set up\nR-hub v2 for your R package, and start running checks. check check_for_cran check_on_centos check_on_debian check_on_fedora check_on_linux check_on_macos check_on_solaris check_on_ubuntu check_on_windows check_with_rdevel check_with_roldrel check_with_rpatched check_with_rrelease check_with_sanitizers check_with_valgrind get_check last_check list_my_checks list_package_checks list_validated_emails local_check_linux local_check_linux_images platforms rc_list_local_tokens rc_list_repos rc_new_token rc_submit rhub_check rhub_doctor rhub_platforms rhub_setup validate_email "
  },
  {
    "id": 355,
    "package_name": "cffr",
    "title": "Generate Citation File Format ('cff') Metadata for R Packages",
    "description": "The Citation File Format version 1.2.0\n<doi:10.5281/zenodo.5171937> is a human and machine readable\nfile format which provides citation metadata for software. This\npackage provides core utilities to generate and validate this\nmetadata.",
    "version": "1.2.0.9000",
    "maintainer": "Diego Hernang\u00f3mez <diego.hernangomezherrero@gmail.com>",
    "author": "Diego Hernang\u00f3mez [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0001-8457-4658>),\nJo\u00e3o Martins [rev] (ORCID: <https://orcid.org/0000-0001-7961-4280>),\nScott Chamberlain [rev] (ORCID:\n<https://orcid.org/0000-0003-1444-9135>)",
    "url": "https://docs.ropensci.org/cffr/, https://github.com/ropensci/cffr",
    "bug_reports": "https://github.com/ropensci/cffr/issues",
    "repository": "",
    "exports": [
      [
        "as_bibentry"
      ],
      [
        "as_cff"
      ],
      [
        "as_cff_person"
      ],
      [
        "as.cff"
      ],
      [
        "cff"
      ],
      [
        "cff_create"
      ],
      [
        "cff_extract_to_bibtex"
      ],
      [
        "cff_from_bibtex"
      ],
      [
        "cff_gha_update"
      ],
      [
        "cff_git_hook_install"
      ],
      [
        "cff_git_hook_remove"
      ],
      [
        "cff_modify"
      ],
      [
        "cff_parse_citation"
      ],
      [
        "cff_parse_person"
      ],
      [
        "cff_parse_person_bibtex"
      ],
      [
        "cff_read"
      ],
      [
        "cff_read_bib"
      ],
      [
        "cff_read_bib_text"
      ],
      [
        "cff_read_cff_citation"
      ],
      [
        "cff_read_citation"
      ],
      [
        "cff_read_description"
      ],
      [
        "cff_schema_definitions_entity"
      ],
      [
        "cff_schema_definitions_person"
      ],
      [
        "cff_schema_definitions_refs"
      ],
      [
        "cff_schema_keys"
      ],
      [
        "cff_schema_keys_license"
      ],
      [
        "cff_to_bibtex"
      ],
      [
        "cff_validate"
      ],
      [
        "cff_write"
      ],
      [
        "cff_write_bib"
      ],
      [
        "cff_write_citation"
      ],
      [
        "encoded_utf_to_latex"
      ],
      [
        "write_bib"
      ],
      [
        "write_citation"
      ]
    ],
    "topics": [
      [
        "attribution"
      ],
      [
        "citation"
      ],
      [
        "credit"
      ],
      [
        "citation-files"
      ],
      [
        "cff"
      ],
      [
        "metadata"
      ],
      [
        "citation-file-format"
      ],
      [
        "ropensci"
      ]
    ],
    "score": 10.1814,
    "stars": 26,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "cffr Generate Citation File Format ('cff') Metadata for R Packages The Citation File Format version 1.2.0\n<doi:10.5281/zenodo.5171937> is a human and machine readable\nfile format which provides citation metadata for software. This\npackage provides core utilities to generate and validate this\nmetadata. as_bibentry as_cff as_cff_person as.cff cff cff_create cff_extract_to_bibtex cff_from_bibtex cff_gha_update cff_git_hook_install cff_git_hook_remove cff_modify cff_parse_citation cff_parse_person cff_parse_person_bibtex cff_read cff_read_bib cff_read_bib_text cff_read_cff_citation cff_read_citation cff_read_description cff_schema_definitions_entity cff_schema_definitions_person cff_schema_definitions_refs cff_schema_keys cff_schema_keys_license cff_to_bibtex cff_validate cff_write cff_write_bib cff_write_citation encoded_utf_to_latex write_bib write_citation attribution citation credit citation-files cff metadata citation-file-format ropensci"
  },
  {
    "id": 638,
    "package_name": "git2rdata",
    "title": "Store and Retrieve Data.frames in a Git Repository",
    "description": "The git2rdata package is an R package for writing and\nreading dataframes as plain text files.  A metadata file stores\nimportant information.  1) Storing metadata allows to maintain\nthe classes of variables.  By default, git2rdata optimizes the\ndata for file storage. The optimization is most effective on\ndata containing factors.  The optimization makes the data less\nhuman readable.  The user can turn this off when they prefer a\nhuman readable format over smaller files. Details on the\nimplementation are available in vignette(\"plain_text\", package\n= \"git2rdata\").  2) Storing metadata also allows smaller row\nbased diffs between two consecutive commits.  This is a useful\nfeature when storing data as plain text files under version\ncontrol.  Details on this part of the implementation are\navailable in vignette(\"version_control\", package =\n\"git2rdata\").  Although we envisioned git2rdata with a git\nworkflow in mind, you can use it in combination with other\nversion control systems like subversion or mercurial.  3)\ngit2rdata is a useful tool in a reproducible and traceable\nworkflow.  vignette(\"workflow\", package = \"git2rdata\") gives a\ntoy example.  4) vignette(\"efficiency\", package = \"git2rdata\")\nprovides some insight into the efficiency of file storage, git\nrepository size and speed for writing and reading.",
    "version": "0.5.1",
    "maintainer": "Thierry Onkelinx <thierry.onkelinx@inbo.be>",
    "author": "Thierry Onkelinx [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8804-4216>, affiliation: Research\nInstitute for Nature and Forest (INBO)),\nFloris Vanderhaeghe [ctb] (ORCID:\n<https://orcid.org/0000-0002-6378-6229>, affiliation: Research\nInstitute for Nature and Forest (INBO)),\nPeter Desmet [ctb] (ORCID: <https://orcid.org/0000-0002-8442-8025>,\naffiliation: Research Institute for Nature and Forest (INBO)),\nEls Lommelen [ctb] (ORCID: <https://orcid.org/0000-0002-3481-5684>,\naffiliation: Research Institute for Nature and Forest (INBO)),\nResearch Institute for Nature and Forest (INBO) [cph, fnd] (ROR:\n<https://ror.org/00j54wy13>)",
    "url": "https://ropensci.github.io/git2rdata/,\nhttps://github.com/ropensci/git2rdata/,\nhttps://doi.org/10.5281/zenodo.1485309",
    "bug_reports": "https://github.com/ropensci/git2rdata/issues",
    "repository": "",
    "exports": [
      [
        "commit"
      ],
      [
        "data_package"
      ],
      [
        "display_metadata"
      ],
      [
        "is_git2rdata"
      ],
      [
        "is_git2rmeta"
      ],
      [
        "list_data"
      ],
      [
        "meta"
      ],
      [
        "prune_meta"
      ],
      [
        "pull"
      ],
      [
        "push"
      ],
      [
        "read_vc"
      ],
      [
        "recent_commit"
      ],
      [
        "relabel"
      ],
      [
        "rename_variable"
      ],
      [
        "repository"
      ],
      [
        "rm_data"
      ],
      [
        "status"
      ],
      [
        "update_metadata"
      ],
      [
        "upgrade_data"
      ],
      [
        "verify_vc"
      ],
      [
        "write_vc"
      ]
    ],
    "topics": [
      [
        "reproducible-research"
      ],
      [
        "version-control"
      ]
    ],
    "score": 10.077,
    "stars": 103,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "git2rdata Store and Retrieve Data.frames in a Git Repository The git2rdata package is an R package for writing and\nreading dataframes as plain text files.  A metadata file stores\nimportant information.  1) Storing metadata allows to maintain\nthe classes of variables.  By default, git2rdata optimizes the\ndata for file storage. The optimization is most effective on\ndata containing factors.  The optimization makes the data less\nhuman readable.  The user can turn this off when they prefer a\nhuman readable format over smaller files. Details on the\nimplementation are available in vignette(\"plain_text\", package\n= \"git2rdata\").  2) Storing metadata also allows smaller row\nbased diffs between two consecutive commits.  This is a useful\nfeature when storing data as plain text files under version\ncontrol.  Details on this part of the implementation are\navailable in vignette(\"version_control\", package =\n\"git2rdata\").  Although we envisioned git2rdata with a git\nworkflow in mind, you can use it in combination with other\nversion control systems like subversion or mercurial.  3)\ngit2rdata is a useful tool in a reproducible and traceable\nworkflow.  vignette(\"workflow\", package = \"git2rdata\") gives a\ntoy example.  4) vignette(\"efficiency\", package = \"git2rdata\")\nprovides some insight into the efficiency of file storage, git\nrepository size and speed for writing and reading. commit data_package display_metadata is_git2rdata is_git2rmeta list_data meta prune_meta pull push read_vc recent_commit relabel rename_variable repository rm_data status update_metadata upgrade_data verify_vc write_vc reproducible-research version-control"
  },
  {
    "id": 367,
    "package_name": "ckanr",
    "title": "Client for the Comprehensive Knowledge Archive Network ('CKAN')\nAPI",
    "description": "Client for 'CKAN' API (<https://ckan.org/>). Includes\ninterface to 'CKAN' 'APIs' for search, list, show for packages,\norganizations, and resources. In addition, provides an\ninterface to the 'datastore' API.",
    "version": "0.8.1",
    "maintainer": "Florian Mayer <Florian.Mayer@dpc.wa.gov.au>",
    "author": "Scott Chamberlain [aut] (ORCID:\n<https://orcid.org/0000-0003-1444-9135>),\nImanuel Costigan [aut],\nWush Wu [aut] (ORCID: <https://orcid.org/0000-0001-5180-0567>),\nFlorian Mayer [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-4269-4242>),\nSharla Gelfand [aut],\nFrancisco Alves [aut] (ORCID: <https://orcid.org/0000-0003-3390-0534>),\nHanna B\u00f6hner [aut] (ORCID: <https://orcid.org/0000-0001-7356-5457>)",
    "url": "https://docs.ropensci.org/ckanr/ (website)\nhttps://github.com/ropensci/ckanr (devel)",
    "bug_reports": "https://github.com/ropensci/ckanr/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "activity_create"
      ],
      [
        "activity_data_show"
      ],
      [
        "activity_diff"
      ],
      [
        "activity_show"
      ],
      [
        "am_following_user"
      ],
      [
        "api_token_create"
      ],
      [
        "api_token_list"
      ],
      [
        "api_token_revoke"
      ],
      [
        "as.ckan_group"
      ],
      [
        "as.ckan_organization"
      ],
      [
        "as.ckan_package"
      ],
      [
        "as.ckan_related"
      ],
      [
        "as.ckan_resource"
      ],
      [
        "as.ckan_resource_view"
      ],
      [
        "as.ckan_tag"
      ],
      [
        "as.ckan_user"
      ],
      [
        "as.ckan_vocabulary"
      ],
      [
        "changes"
      ],
      [
        "ckan_action"
      ],
      [
        "ckan_fetch"
      ],
      [
        "ckan_info"
      ],
      [
        "ckan_version"
      ],
      [
        "ckanr_settings"
      ],
      [
        "ckanr_setup"
      ],
      [
        "config_option_list"
      ],
      [
        "config_option_show"
      ],
      [
        "config_option_update"
      ],
      [
        "dashboard_activity_list"
      ],
      [
        "dashboard_count"
      ],
      [
        "dashboard_mark_activities_old"
      ],
      [
        "dashboard_new_activities_count"
      ],
      [
        "dataset_am_following"
      ],
      [
        "dataset_follow"
      ],
      [
        "dataset_followee_count"
      ],
      [
        "dataset_followee_list"
      ],
      [
        "dataset_follower_count"
      ],
      [
        "dataset_follower_list"
      ],
      [
        "dataset_purge"
      ],
      [
        "dataset_unfollow"
      ],
      [
        "ds_create"
      ],
      [
        "ds_create_dataset"
      ],
      [
        "ds_search"
      ],
      [
        "ds_search_sql"
      ],
      [
        "follow_user"
      ],
      [
        "followee_count"
      ],
      [
        "followee_list"
      ],
      [
        "get_default_key"
      ],
      [
        "get_default_url"
      ],
      [
        "get_test_behaviour"
      ],
      [
        "get_test_did"
      ],
      [
        "get_test_gid"
      ],
      [
        "get_test_key"
      ],
      [
        "get_test_oid"
      ],
      [
        "get_test_rid"
      ],
      [
        "get_test_url"
      ],
      [
        "group_activity_list"
      ],
      [
        "group_am_following"
      ],
      [
        "group_create"
      ],
      [
        "group_delete"
      ],
      [
        "group_follow"
      ],
      [
        "group_followee_count"
      ],
      [
        "group_followee_list"
      ],
      [
        "group_follower_count"
      ],
      [
        "group_follower_list"
      ],
      [
        "group_list"
      ],
      [
        "group_list_authz"
      ],
      [
        "group_member_create"
      ],
      [
        "group_member_delete"
      ],
      [
        "group_patch"
      ],
      [
        "group_show"
      ],
      [
        "group_unfollow"
      ],
      [
        "group_update"
      ],
      [
        "help_show"
      ],
      [
        "is.ckan_group"
      ],
      [
        "is.ckan_organization"
      ],
      [
        "is.ckan_package"
      ],
      [
        "is.ckan_related"
      ],
      [
        "is.ckan_resource"
      ],
      [
        "is.ckan_resource_view"
      ],
      [
        "is.ckan_tag"
      ],
      [
        "is.ckan_user"
      ],
      [
        "is.ckan_vocabulary"
      ],
      [
        "job_cancel"
      ],
      [
        "job_clear"
      ],
      [
        "job_list"
      ],
      [
        "job_show"
      ],
      [
        "license_list"
      ],
      [
        "member_create"
      ],
      [
        "member_delete"
      ],
      [
        "member_list"
      ],
      [
        "member_roles_list"
      ],
      [
        "organization_activity_list"
      ],
      [
        "organization_create"
      ],
      [
        "organization_delete"
      ],
      [
        "organization_list"
      ],
      [
        "organization_list_for_user"
      ],
      [
        "organization_member_create"
      ],
      [
        "organization_member_delete"
      ],
      [
        "organization_purge"
      ],
      [
        "organization_show"
      ],
      [
        "package_activity_list"
      ],
      [
        "package_collaborator_create"
      ],
      [
        "package_collaborator_delete"
      ],
      [
        "package_collaborator_list"
      ],
      [
        "package_collaborator_list_for_user"
      ],
      [
        "package_create"
      ],
      [
        "package_create_default_resource_views"
      ],
      [
        "package_delete"
      ],
      [
        "package_list"
      ],
      [
        "package_list_current"
      ],
      [
        "package_owner_org_update"
      ],
      [
        "package_patch"
      ],
      [
        "package_relationship_create"
      ],
      [
        "package_relationship_delete"
      ],
      [
        "package_relationship_update"
      ],
      [
        "package_relationships_list"
      ],
      [
        "package_resource_reorder"
      ],
      [
        "package_revise"
      ],
      [
        "package_revision_list"
      ],
      [
        "package_search"
      ],
      [
        "package_show"
      ],
      [
        "package_update"
      ],
      [
        "ping"
      ],
      [
        "recently_changed_packages_activity_list"
      ],
      [
        "related_create"
      ],
      [
        "related_delete"
      ],
      [
        "related_list"
      ],
      [
        "related_show"
      ],
      [
        "resource_create"
      ],
      [
        "resource_create_default_resource_views"
      ],
      [
        "resource_delete"
      ],
      [
        "resource_patch"
      ],
      [
        "resource_search"
      ],
      [
        "resource_show"
      ],
      [
        "resource_update"
      ],
      [
        "resource_view_clear"
      ],
      [
        "resource_view_create"
      ],
      [
        "resource_view_delete"
      ],
      [
        "resource_view_list"
      ],
      [
        "resource_view_reorder"
      ],
      [
        "resource_view_show"
      ],
      [
        "resource_view_update"
      ],
      [
        "revision_list"
      ],
      [
        "send_email_notifications"
      ],
      [
        "servers"
      ],
      [
        "src_ckan"
      ],
      [
        "status_show"
      ],
      [
        "tag_autocomplete"
      ],
      [
        "tag_create"
      ],
      [
        "tag_list"
      ],
      [
        "tag_search"
      ],
      [
        "tag_show"
      ],
      [
        "task_status_delete"
      ],
      [
        "task_status_show"
      ],
      [
        "task_status_update"
      ],
      [
        "task_status_update_many"
      ],
      [
        "term_translation_show"
      ],
      [
        "term_translation_update"
      ],
      [
        "term_translation_update_many"
      ],
      [
        "unfollow_user"
      ],
      [
        "user_activity_list"
      ],
      [
        "user_create"
      ],
      [
        "user_delete"
      ],
      [
        "user_followee_count"
      ],
      [
        "user_followee_list"
      ],
      [
        "user_follower_count"
      ],
      [
        "user_follower_list"
      ],
      [
        "user_invite"
      ],
      [
        "user_list"
      ],
      [
        "user_show"
      ],
      [
        "vocabulary_create"
      ],
      [
        "vocabulary_delete"
      ],
      [
        "vocabulary_list"
      ],
      [
        "vocabulary_show"
      ],
      [
        "vocabulary_update"
      ]
    ],
    "topics": [
      [
        "database"
      ],
      [
        "open-data"
      ],
      [
        "ckan"
      ],
      [
        "api"
      ],
      [
        "data"
      ],
      [
        "dataset"
      ],
      [
        "api-wrapper"
      ],
      [
        "ckan-api"
      ]
    ],
    "score": 9.9287,
    "stars": 101,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "ckanr Client for the Comprehensive Knowledge Archive Network ('CKAN')\nAPI Client for 'CKAN' API (<https://ckan.org/>). Includes\ninterface to 'CKAN' 'APIs' for search, list, show for packages,\norganizations, and resources. In addition, provides an\ninterface to the 'datastore' API. %>% activity_create activity_data_show activity_diff activity_show am_following_user api_token_create api_token_list api_token_revoke as.ckan_group as.ckan_organization as.ckan_package as.ckan_related as.ckan_resource as.ckan_resource_view as.ckan_tag as.ckan_user as.ckan_vocabulary changes ckan_action ckan_fetch ckan_info ckan_version ckanr_settings ckanr_setup config_option_list config_option_show config_option_update dashboard_activity_list dashboard_count dashboard_mark_activities_old dashboard_new_activities_count dataset_am_following dataset_follow dataset_followee_count dataset_followee_list dataset_follower_count dataset_follower_list dataset_purge dataset_unfollow ds_create ds_create_dataset ds_search ds_search_sql follow_user followee_count followee_list get_default_key get_default_url get_test_behaviour get_test_did get_test_gid get_test_key get_test_oid get_test_rid get_test_url group_activity_list group_am_following group_create group_delete group_follow group_followee_count group_followee_list group_follower_count group_follower_list group_list group_list_authz group_member_create group_member_delete group_patch group_show group_unfollow group_update help_show is.ckan_group is.ckan_organization is.ckan_package is.ckan_related is.ckan_resource is.ckan_resource_view is.ckan_tag is.ckan_user is.ckan_vocabulary job_cancel job_clear job_list job_show license_list member_create member_delete member_list member_roles_list organization_activity_list organization_create organization_delete organization_list organization_list_for_user organization_member_create organization_member_delete organization_purge organization_show package_activity_list package_collaborator_create package_collaborator_delete package_collaborator_list package_collaborator_list_for_user package_create package_create_default_resource_views package_delete package_list package_list_current package_owner_org_update package_patch package_relationship_create package_relationship_delete package_relationship_update package_relationships_list package_resource_reorder package_revise package_revision_list package_search package_show package_update ping recently_changed_packages_activity_list related_create related_delete related_list related_show resource_create resource_create_default_resource_views resource_delete resource_patch resource_search resource_show resource_update resource_view_clear resource_view_create resource_view_delete resource_view_list resource_view_reorder resource_view_show resource_view_update revision_list send_email_notifications servers src_ckan status_show tag_autocomplete tag_create tag_list tag_search tag_show task_status_delete task_status_show task_status_update task_status_update_many term_translation_show term_translation_update term_translation_update_many unfollow_user user_activity_list user_create user_delete user_followee_count user_followee_list user_follower_count user_follower_list user_invite user_list user_show vocabulary_create vocabulary_delete vocabulary_list vocabulary_show vocabulary_update database open-data ckan api data dataset api-wrapper ckan-api"
  },
  {
    "id": 660,
    "package_name": "gradethis",
    "title": "Automated Feedback for Student Exercises in 'learnr' Tutorials",
    "description": "Pairing with the 'learnr' R package, 'gradethis' provides\nmultiple methods to grade 'learnr' exercises.  To learn more\nabout 'learnr' tutorials, please visit\n<https://rstudio.github.io/learnr/>.",
    "version": "0.2.14",
    "maintainer": "Garrick Aden-Buie <garrick@posit.co>",
    "author": "Garrick Aden-Buie [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7111-0077>),\nDaniel Chen [aut] (ORCID: <https://orcid.org/0000-0003-3857-1741>),\nGarrett Grolemund [ccp, aut] (ORCID:\n<https://orcid.org/0000-0002-7765-6011>),\nAlexander Rossell Hayes [aut] (ORCID:\n<https://orcid.org/0000-0001-9412-0457>),\nBarret Schloerke [aut] (ORCID: <https://orcid.org/0000-0001-9986-114X>),\nPosit, PBC [cph, fnd]",
    "url": "https://pkgs.rstudio.com/gradethis/,\nhttps://rstudio.github.io/learnr/,\nhttps://github.com/rstudio/gradethis",
    "bug_reports": "https://github.com/rstudio/gradethis/issues",
    "repository": "",
    "exports": [
      [
        ".engine"
      ],
      [
        ".envir_prep"
      ],
      [
        ".envir_result"
      ],
      [
        ".envir_solution"
      ],
      [
        ".evaluate_result"
      ],
      [
        ".label"
      ],
      [
        ".last_value"
      ],
      [
        ".result"
      ],
      [
        ".solution"
      ],
      [
        ".solution_all"
      ],
      [
        ".solution_code"
      ],
      [
        ".solution_code_all"
      ],
      [
        ".stage"
      ],
      [
        ".user"
      ],
      [
        ".user_code"
      ],
      [
        "%>%"
      ],
      [
        "code_feedback"
      ],
      [
        "condition"
      ],
      [
        "debug_this"
      ],
      [
        "eval_gradethis"
      ],
      [
        "evaluate_condition"
      ],
      [
        "fail"
      ],
      [
        "fail_if"
      ],
      [
        "fail_if_code_feedback"
      ],
      [
        "fail_if_equal"
      ],
      [
        "fail_if_error"
      ],
      [
        "fail_if_not_equal"
      ],
      [
        "give_code_feedback"
      ],
      [
        "give_encouragement"
      ],
      [
        "give_praise"
      ],
      [
        "grade_code"
      ],
      [
        "grade_conditions"
      ],
      [
        "grade_feedback"
      ],
      [
        "grade_learnr"
      ],
      [
        "grade_result"
      ],
      [
        "grade_result_strict"
      ],
      [
        "grade_this"
      ],
      [
        "grade_this_code"
      ],
      [
        "graded"
      ],
      [
        "gradethis_demo"
      ],
      [
        "gradethis_equal"
      ],
      [
        "gradethis_error_checker"
      ],
      [
        "gradethis_exercise_checker"
      ],
      [
        "gradethis_setup"
      ],
      [
        "maybe_code_feedback"
      ],
      [
        "mock_this_exercise"
      ],
      [
        "pass"
      ],
      [
        "pass_if"
      ],
      [
        "pass_if_equal"
      ],
      [
        "pipe_warning"
      ],
      [
        "random_encourage"
      ],
      [
        "random_encouragement"
      ],
      [
        "random_praise"
      ],
      [
        "solution_object_exists"
      ],
      [
        "solution_object_get"
      ],
      [
        "solution_object_list"
      ],
      [
        "user_object_exists"
      ],
      [
        "user_object_get"
      ],
      [
        "user_object_list"
      ],
      [
        "with_exercise"
      ]
    ],
    "topics": [],
    "score": 9.8011,
    "stars": 166,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "gradethis Automated Feedback for Student Exercises in 'learnr' Tutorials Pairing with the 'learnr' R package, 'gradethis' provides\nmultiple methods to grade 'learnr' exercises.  To learn more\nabout 'learnr' tutorials, please visit\n<https://rstudio.github.io/learnr/>. .engine .envir_prep .envir_result .envir_solution .evaluate_result .label .last_value .result .solution .solution_all .solution_code .solution_code_all .stage .user .user_code %>% code_feedback condition debug_this eval_gradethis evaluate_condition fail fail_if fail_if_code_feedback fail_if_equal fail_if_error fail_if_not_equal give_code_feedback give_encouragement give_praise grade_code grade_conditions grade_feedback grade_learnr grade_result grade_result_strict grade_this grade_this_code graded gradethis_demo gradethis_equal gradethis_error_checker gradethis_exercise_checker gradethis_setup maybe_code_feedback mock_this_exercise pass pass_if pass_if_equal pipe_warning random_encourage random_encouragement random_praise solution_object_exists solution_object_get solution_object_list user_object_exists user_object_get user_object_list with_exercise "
  },
  {
    "id": 341,
    "package_name": "carrier",
    "title": "Isolate Functions for Remote Execution",
    "description": "Sending functions to remote processes can be wasteful of\nresources because they carry their environments with them. With\nthe carrier package, it is easy to create functions that are\nisolated from their environment. These isolated functions, also\ncalled crates, print at the console with their total size and\ncan be easily tested locally before being sent to a remote.",
    "version": "0.3.0.9000",
    "maintainer": "Lionel Henry <lionel@posit.co>",
    "author": "Lionel Henry [aut, cre],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://github.com/r-lib/carrier",
    "bug_reports": "https://github.com/r-lib/carrier/issues",
    "repository": "",
    "exports": [
      [
        "crate"
      ],
      [
        "is_crate"
      ]
    ],
    "topics": [],
    "score": 9.6469,
    "stars": 65,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "carrier Isolate Functions for Remote Execution Sending functions to remote processes can be wasteful of\nresources because they carry their environments with them. With\nthe carrier package, it is easy to create functions that are\nisolated from their environment. These isolated functions, also\ncalled crates, print at the console with their total size and\ncan be easily tested locally before being sent to a remote. crate is_crate "
  },
  {
    "id": 1275,
    "package_name": "stats19",
    "title": "Work with Open Road Traffic Casualty Data from Great Britain",
    "description": "Work with and download road traffic casualty data from\nGreat Britain. Enables access to the UK's official road safety\nstatistics, 'STATS19'. Enables users to specify a download\ndirectory for the data, which can be set permanently by adding\n`STATS19_DOWNLOAD_DIRECTORY=/path/to/a/dir` to your `.Renviron`\nfile, which can be opened with `usethis::edit_r_environ()`. The\ndata is provided as a series of `.csv` files. This package\ndownloads, reads-in and formats the data, making it suitable\nfor analysis. See the stats19 vignette for details. Data\navailable from 1979 to 2024. See the official data series at\n<https://www.data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-accidents-safety-data>.\nThe package is described in a paper in the Journal of Open\nSource Software (Lovelace et al. 2019)\n<doi:10.21105/joss.01181>. See Gilardi et al. (2022)\n<doi:10.1111/rssa.12823>, Vidal-Tortosa et al. (2021)\n<doi:10.1016/j.jth.2021.101291>, Tait et al. (2023)\n<doi:10.1016/j.aap.2022.106895>, and Le\u00f3n et al. (2025)\n<doi:10.18637/jss.v114.i09> for examples of how the data can be\nused for methodological and empirical research.",
    "version": "3.4.0.9000",
    "maintainer": "Robin Lovelace <rob00x@gmail.com>",
    "author": "Robin Lovelace [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-5679-6536>),\nMalcolm Morgan [aut] (ORCID: <https://orcid.org/0000-0002-9488-9183>),\nLayik Hama [aut] (ORCID: <https://orcid.org/0000-0003-1912-4890>),\nMark Padgham [aut] (ORCID: <https://orcid.org/0000-0003-2172-5265>),\nDavid Ranzolin [rev],\nAdam Sparks [rev, ctb] (ORCID: <https://orcid.org/0000-0002-0061-8359>),\nIvo Wengraf [ctb],\nRAC Foundation [fnd],\nBlaise Kelly [aut] (ORCID: <https://orcid.org/0000-0003-2623-1598>)",
    "url": "https://github.com/ropensci/stats19,\nhttps://docs.ropensci.org/stats19/",
    "bug_reports": "https://github.com/ropensci/stats19/issues",
    "repository": "",
    "exports": [
      [
        "dl_stats19"
      ],
      [
        "find_file_name"
      ],
      [
        "format_casualties"
      ],
      [
        "format_collisions"
      ],
      [
        "format_column_names"
      ],
      [
        "format_ppp"
      ],
      [
        "format_sf"
      ],
      [
        "format_vehicles"
      ],
      [
        "get_data_directory"
      ],
      [
        "get_MOT"
      ],
      [
        "get_stats19"
      ],
      [
        "get_stats19_adjustments"
      ],
      [
        "get_ULEZ"
      ],
      [
        "locate_one_file"
      ],
      [
        "match_tag"
      ],
      [
        "read_casualties"
      ],
      [
        "read_collisions"
      ],
      [
        "read_vehicles"
      ]
    ],
    "topics": [
      [
        "stats19"
      ],
      [
        "road-safety"
      ],
      [
        "transport"
      ],
      [
        "car-crashes"
      ],
      [
        "ropensci"
      ],
      [
        "data"
      ]
    ],
    "score": 9.6277,
    "stars": 67,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "stats19 Work with Open Road Traffic Casualty Data from Great Britain Work with and download road traffic casualty data from\nGreat Britain. Enables access to the UK's official road safety\nstatistics, 'STATS19'. Enables users to specify a download\ndirectory for the data, which can be set permanently by adding\n`STATS19_DOWNLOAD_DIRECTORY=/path/to/a/dir` to your `.Renviron`\nfile, which can be opened with `usethis::edit_r_environ()`. The\ndata is provided as a series of `.csv` files. This package\ndownloads, reads-in and formats the data, making it suitable\nfor analysis. See the stats19 vignette for details. Data\navailable from 1979 to 2024. See the official data series at\n<https://www.data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-accidents-safety-data>.\nThe package is described in a paper in the Journal of Open\nSource Software (Lovelace et al. 2019)\n<doi:10.21105/joss.01181>. See Gilardi et al. (2022)\n<doi:10.1111/rssa.12823>, Vidal-Tortosa et al. (2021)\n<doi:10.1016/j.jth.2021.101291>, Tait et al. (2023)\n<doi:10.1016/j.aap.2022.106895>, and Le\u00f3n et al. (2025)\n<doi:10.18637/jss.v114.i09> for examples of how the data can be\nused for methodological and empirical research. dl_stats19 find_file_name format_casualties format_collisions format_column_names format_ppp format_sf format_vehicles get_data_directory get_MOT get_stats19 get_stats19_adjustments get_ULEZ locate_one_file match_tag read_casualties read_collisions read_vehicles stats19 road-safety transport car-crashes ropensci data"
  },
  {
    "id": 532,
    "package_name": "epiparameter",
    "title": "Classes and Helper Functions for Working with Epidemiological\nParameters",
    "description": "Classes and helper functions for loading, extracting,\nconverting, manipulating, plotting and aggregating\nepidemiological parameters for infectious diseases.\nEpidemiological parameters extracted from the literature are\nloaded from the 'epiparameterDB' R package.",
    "version": "0.4.1.9000",
    "maintainer": "Joshua W. Lambert <joshua.lambert@lshtm.ac.uk>",
    "author": "Joshua W. Lambert [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0001-5218-3046>),\nAdam Kucharski [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-8814-9421>),\nCarmen Tamayo Cuartero [aut] (ORCID:\n<https://orcid.org/0000-0003-4184-2864>),\nHugo Gruson [ctb, rev] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nSebastian Funk [ctb] (ORCID: <https://orcid.org/0000-0002-2842-3406>),\nPratik Gupte [rev] (ORCID: <https://orcid.org/0000-0001-5294-7819>),\nJames M. Azam [rev] (ORCID: <https://orcid.org/0000-0001-5782-7330>),\nChris Hartgerink [rev] (ORCID: <https://orcid.org/0000-0003-1050-6809>),\nTim Taylor [rev] (ORCID: <https://orcid.org/0000-0002-8587-7113>),\nLondon School of Hygiene and Tropical Medicine, LSHTM [cph] (ROR:\n<https://ror.org/00a0jsq62>)",
    "url": "https://github.com/epiverse-trace/epiparameter/,\nhttps://epiverse-trace.github.io/epiparameter/",
    "bug_reports": "https://github.com/epiverse-trace/epiparameter/issues",
    "repository": "",
    "exports": [
      [
        "as_epiparameter"
      ],
      [
        "assert_epiparameter"
      ],
      [
        "calc_disc_dist_quantile"
      ],
      [
        "cdf"
      ],
      [
        "convert_params_to_summary_stats"
      ],
      [
        "convert_summary_stats_to_params"
      ],
      [
        "create_citation"
      ],
      [
        "create_metadata"
      ],
      [
        "create_method_assess"
      ],
      [
        "create_prob_distribution"
      ],
      [
        "create_region"
      ],
      [
        "create_summary_stats"
      ],
      [
        "create_uncertainty"
      ],
      [
        "discretise"
      ],
      [
        "discretize"
      ],
      [
        "epidist_db"
      ],
      [
        "epiparameter"
      ],
      [
        "epiparameter_db"
      ],
      [
        "extract_param"
      ],
      [
        "generate"
      ],
      [
        "get_citation"
      ],
      [
        "get_parameters"
      ],
      [
        "is_continuous"
      ],
      [
        "is_epiparameter"
      ],
      [
        "is_epiparameter_params"
      ],
      [
        "is_parameterised"
      ],
      [
        "is_parameterized"
      ],
      [
        "is_truncated"
      ],
      [
        "parameter_tbl"
      ],
      [
        "test_epiparameter"
      ]
    ],
    "topics": [
      [
        "data-access"
      ],
      [
        "data-package"
      ],
      [
        "epidemiology"
      ],
      [
        "epiverse"
      ],
      [
        "probability-distribution"
      ]
    ],
    "score": 9.4988,
    "stars": 34,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "epiparameter Classes and Helper Functions for Working with Epidemiological\nParameters Classes and helper functions for loading, extracting,\nconverting, manipulating, plotting and aggregating\nepidemiological parameters for infectious diseases.\nEpidemiological parameters extracted from the literature are\nloaded from the 'epiparameterDB' R package. as_epiparameter assert_epiparameter calc_disc_dist_quantile cdf convert_params_to_summary_stats convert_summary_stats_to_params create_citation create_metadata create_method_assess create_prob_distribution create_region create_summary_stats create_uncertainty discretise discretize epidist_db epiparameter epiparameter_db extract_param generate get_citation get_parameters is_continuous is_epiparameter is_epiparameter_params is_parameterised is_parameterized is_truncated parameter_tbl test_epiparameter data-access data-package epidemiology epiverse probability-distribution"
  },
  {
    "id": 1255,
    "package_name": "spatialsample",
    "title": "Spatial Resampling Infrastructure",
    "description": "Functions and classes for spatial resampling to use with\nthe 'rsample' package, such as spatial cross-validation\n(Brenning, 2012) <doi:10.1109/IGARSS.2012.6352393>. The scope\nof 'rsample' and 'spatialsample' is to provide the basic\nbuilding blocks for creating and analyzing resamples of a\nspatial data set, but neither package includes functions for\nmodeling or computing statistics. The resampled spatial data\nsets created by 'spatialsample' do not contain much overhead in\nmemory.",
    "version": "0.6.0.9000",
    "maintainer": "Michael Mahoney <mike.mahoney.218@gmail.com>",
    "author": "Michael Mahoney [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2402-304X>),\nJulia Silge [aut] (ORCID: <https://orcid.org/0000-0002-3671-836X>),\nPosit Software, PBC [cph, fnd]",
    "url": "https://github.com/tidymodels/spatialsample,\nhttps://spatialsample.tidymodels.org",
    "bug_reports": "https://github.com/tidymodels/spatialsample/issues",
    "repository": "",
    "exports": [
      [
        "analysis"
      ],
      [
        "assessment"
      ],
      [
        "autoplot"
      ],
      [
        "get_rsplit"
      ],
      [
        "spatial_block_cv"
      ],
      [
        "spatial_buffer_vfold_cv"
      ],
      [
        "spatial_clustering_cv"
      ],
      [
        "spatial_leave_location_out_cv"
      ],
      [
        "spatial_nndm_cv"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 9.1542,
    "stars": 76,
    "primary_category": "tidyverse",
    "source_universe": "tidymodels",
    "search_text": "spatialsample Spatial Resampling Infrastructure Functions and classes for spatial resampling to use with\nthe 'rsample' package, such as spatial cross-validation\n(Brenning, 2012) <doi:10.1109/IGARSS.2012.6352393>. The scope\nof 'rsample' and 'spatialsample' is to provide the basic\nbuilding blocks for creating and analyzing resamples of a\nspatial data set, but neither package includes functions for\nmodeling or computing statistics. The resampled spatial data\nsets created by 'spatialsample' do not contain much overhead in\nmemory. analysis assessment autoplot get_rsplit spatial_block_cv spatial_buffer_vfold_cv spatial_clustering_cv spatial_leave_location_out_cv spatial_nndm_cv cpp"
  },
  {
    "id": 383,
    "package_name": "codemetar",
    "title": "Generate 'CodeMeta' Metadata for R Packages",
    "description": "The 'Codemeta' Project defines a 'JSON-LD' format for\ndescribing software metadata, as detailed at\n<https://codemeta.github.io>. This package provides utilities\nto generate, parse, and modify 'codemeta.json' files\nautomatically for R packages, as well as tools and examples for\nworking with 'codemeta.json' 'JSON-LD' more generally.",
    "version": "0.3.6",
    "maintainer": "Carl Boettiger <cboettig@gmail.com>",
    "author": "Carl Boettiger [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0002-1642-628X>),\nAnna Krystalli [rev, ctb] (ORCID:\n<https://orcid.org/0000-0002-2378-4915>),\nToph Allen [rev] (ORCID: <https://orcid.org/0000-0003-4580-091X>),\nMa\u00eblle Salmon [ctb, aut] (ORCID:\n<https://orcid.org/0000-0002-2815-0399>),\nrOpenSci [fnd] (ROR: <https://ror.org/019jywm96>),\nKatrin Leinweber [ctb] (ORCID: <https://orcid.org/0000-0001-5135-5758>),\nNoam Ross [ctb] (ORCID: <https://orcid.org/0000-0002-2136-0000>),\nArfon Smith [ctb],\nJeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\nSebastian Meyer [ctb] (ORCID: <https://orcid.org/0000-0002-1791-9449>),\nMichael Rustler [ctb] (ORCID: <https://orcid.org/0000-0003-0647-7726>),\nHauke Sonnenberg [ctb] (ORCID: <https://orcid.org/0000-0001-9134-2871>),\nSebastian Kreutzer [ctb] (ORCID:\n<https://orcid.org/0000-0002-0734-2199>),\nThierry Onkelinx [ctb] (ORCID: <https://orcid.org/0000-0001-8804-4216>)",
    "url": "https://github.com/ropensci/codemetar,\nhttps://docs.ropensci.org/codemetar/",
    "bug_reports": "https://github.com/ropensci/codemetar/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "create_codemeta"
      ],
      [
        "extract_badges"
      ],
      [
        "give_opinions"
      ],
      [
        "write_codemeta"
      ]
    ],
    "topics": [
      [
        "metadata"
      ],
      [
        "codemeta"
      ],
      [
        "ropensci"
      ],
      [
        "citation"
      ],
      [
        "credit"
      ],
      [
        "linked-data"
      ],
      [
        "json-ld"
      ],
      [
        "peer-reviewed"
      ]
    ],
    "score": 9.1451,
    "stars": 67,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "codemetar Generate 'CodeMeta' Metadata for R Packages The 'Codemeta' Project defines a 'JSON-LD' format for\ndescribing software metadata, as detailed at\n<https://codemeta.github.io>. This package provides utilities\nto generate, parse, and modify 'codemeta.json' files\nautomatically for R packages, as well as tools and examples for\nworking with 'codemeta.json' 'JSON-LD' more generally. %>% create_codemeta extract_badges give_opinions write_codemeta metadata codemeta ropensci citation credit linked-data json-ld peer-reviewed"
  },
  {
    "id": 973,
    "package_name": "pkgcache",
    "title": "Cache 'CRAN'-Like Metadata and R Packages",
    "description": "Metadata and package cache for CRAN-like repositories.\nThis is a utility package to be used by package management\ntools that want to take advantage of caching.",
    "version": "2.2.4.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://r-lib.github.io/pkgcache/,\nhttps://github.com/r-lib/pkgcache",
    "bug_reports": "https://github.com/r-lib/pkgcache/issues",
    "repository": "",
    "exports": [
      [
        "bioc_devel_version"
      ],
      [
        "bioc_release_version"
      ],
      [
        "bioc_repos"
      ],
      [
        "bioc_version"
      ],
      [
        "bioc_version_map"
      ],
      [
        "cran_archive_cache"
      ],
      [
        "cran_archive_cleanup"
      ],
      [
        "cran_archive_list"
      ],
      [
        "cran_archive_summary"
      ],
      [
        "cran_archive_update"
      ],
      [
        "cranlike_metadata_cache"
      ],
      [
        "current_r_platform"
      ],
      [
        "current_r_platform_data"
      ],
      [
        "default_cran_mirror"
      ],
      [
        "default_platforms"
      ],
      [
        "get_cranlike_metadata_cache"
      ],
      [
        "get_graphics_api_version"
      ],
      [
        "get_internals_id"
      ],
      [
        "meta_cache_cleanup"
      ],
      [
        "meta_cache_deps"
      ],
      [
        "meta_cache_list"
      ],
      [
        "meta_cache_revdeps"
      ],
      [
        "meta_cache_summary"
      ],
      [
        "meta_cache_update"
      ],
      [
        "package_cache"
      ],
      [
        "parse_installed"
      ],
      [
        "parse_packages"
      ],
      [
        "pkg_cache_add_file"
      ],
      [
        "pkg_cache_delete_files"
      ],
      [
        "pkg_cache_find"
      ],
      [
        "pkg_cache_get_file"
      ],
      [
        "pkg_cache_list"
      ],
      [
        "pkg_cache_summary"
      ],
      [
        "ppm_has_binaries"
      ],
      [
        "ppm_platforms"
      ],
      [
        "ppm_r_versions"
      ],
      [
        "ppm_repo_url"
      ],
      [
        "ppm_snapshots"
      ],
      [
        "repo_add"
      ],
      [
        "repo_auth"
      ],
      [
        "repo_get"
      ],
      [
        "repo_resolve"
      ],
      [
        "repo_status"
      ],
      [
        "with_repo"
      ]
    ],
    "topics": [],
    "score": 8.9171,
    "stars": 29,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "pkgcache Cache 'CRAN'-Like Metadata and R Packages Metadata and package cache for CRAN-like repositories.\nThis is a utility package to be used by package management\ntools that want to take advantage of caching. bioc_devel_version bioc_release_version bioc_repos bioc_version bioc_version_map cran_archive_cache cran_archive_cleanup cran_archive_list cran_archive_summary cran_archive_update cranlike_metadata_cache current_r_platform current_r_platform_data default_cran_mirror default_platforms get_cranlike_metadata_cache get_graphics_api_version get_internals_id meta_cache_cleanup meta_cache_deps meta_cache_list meta_cache_revdeps meta_cache_summary meta_cache_update package_cache parse_installed parse_packages pkg_cache_add_file pkg_cache_delete_files pkg_cache_find pkg_cache_get_file pkg_cache_list pkg_cache_summary ppm_has_binaries ppm_platforms ppm_r_versions ppm_repo_url ppm_snapshots repo_add repo_auth repo_get repo_resolve repo_status with_repo "
  },
  {
    "id": 36,
    "package_name": "DataPackageR",
    "title": "Construct Reproducible Analytic Data Sets as R Packages",
    "description": "A framework to help construct R data packages in a\nreproducible manner. Potentially time consuming processing of\nraw data sets into analysis ready data sets is done in a\nreproducible manner and decoupled from the usual 'R CMD build'\nprocess so that data sets can be processed into R objects in\nthe data package and the data package can then be shared,\nbuilt, and installed by others without the need to repeat\ncomputationally costly data processing.  The package maintains\ndata provenance by turning the data processing scripts into\npackage vignettes, as well as enforcing documentation and\nversion checking of included data objects. Data packages can be\nversion controlled on 'GitHub', and used to share data for\nmanuscripts, collaboration and reproducible research.",
    "version": "0.16.2",
    "maintainer": "Dave Slager <dslager@fredhutch.org>",
    "author": "Greg Finak [aut, cph] (Original author and creator of DataPackageR),\nPaul Obrecht [ctb],\nEllis Hughes [ctb] (ORCID: <https://orcid.org/0000-0003-0637-4436>),\nJimmy Fulp [ctb],\nMarie Vendettuoli [ctb] (ORCID:\n<https://orcid.org/0000-0001-9321-1410>),\nDave Slager [ctb, cre] (ORCID: <https://orcid.org/0000-0003-2525-2039>),\nJason Taylor [ctb],\nKara Woo [rev] (Kara reviewed the package for rOpenSci, see\n<https://github.com/ropensci/onboarding/issues/230>),\nWilliam Landau [rev] (William reviewed the package for rOpenSci, see\n<https://github.com/ropensci/onboarding/issues/230>)",
    "url": "https://github.com/ropensci/DataPackageR,\nhttps://docs.ropensci.org/DataPackageR/",
    "bug_reports": "https://github.com/ropensci/DataPackageR/issues",
    "repository": "",
    "exports": [
      [
        "assert_data_version"
      ],
      [
        "construct_yml_config"
      ],
      [
        "data_version"
      ],
      [
        "datapackage_skeleton"
      ],
      [
        "datapackage.skeleton"
      ],
      [
        "datapackager_object_read"
      ],
      [
        "dataVersion"
      ],
      [
        "document"
      ],
      [
        "keepDataObjects"
      ],
      [
        "package_build"
      ],
      [
        "project_data_path"
      ],
      [
        "project_extdata_path"
      ],
      [
        "project_path"
      ],
      [
        "use_data_object"
      ],
      [
        "use_ignore"
      ],
      [
        "use_processing_script"
      ],
      [
        "use_raw_dataset"
      ],
      [
        "yml_add_files"
      ],
      [
        "yml_add_objects"
      ],
      [
        "yml_disable_compile"
      ],
      [
        "yml_enable_compile"
      ],
      [
        "yml_find"
      ],
      [
        "yml_list_files"
      ],
      [
        "yml_list_objects"
      ],
      [
        "yml_remove_files"
      ],
      [
        "yml_remove_objects"
      ],
      [
        "yml_write"
      ]
    ],
    "topics": [
      [
        "peer-reviewed"
      ],
      [
        "reproducibility"
      ]
    ],
    "score": 8.792,
    "stars": 155,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "DataPackageR Construct Reproducible Analytic Data Sets as R Packages A framework to help construct R data packages in a\nreproducible manner. Potentially time consuming processing of\nraw data sets into analysis ready data sets is done in a\nreproducible manner and decoupled from the usual 'R CMD build'\nprocess so that data sets can be processed into R objects in\nthe data package and the data package can then be shared,\nbuilt, and installed by others without the need to repeat\ncomputationally costly data processing.  The package maintains\ndata provenance by turning the data processing scripts into\npackage vignettes, as well as enforcing documentation and\nversion checking of included data objects. Data packages can be\nversion controlled on 'GitHub', and used to share data for\nmanuscripts, collaboration and reproducible research. assert_data_version construct_yml_config data_version datapackage_skeleton datapackage.skeleton datapackager_object_read dataVersion document keepDataObjects package_build project_data_path project_extdata_path project_path use_data_object use_ignore use_processing_script use_raw_dataset yml_add_files yml_add_objects yml_disable_compile yml_enable_compile yml_find yml_list_files yml_list_objects yml_remove_files yml_remove_objects yml_write peer-reviewed reproducibility"
  },
  {
    "id": 735,
    "package_name": "katex",
    "title": "Rendering Math to HTML, 'MathML', or R-Documentation Format",
    "description": "Convert latex math expressions to HTML and 'MathML' for\nuse in markdown documents or package manual pages. The\nrendering is done in R using the V8 engine (i.e. server-side),\nwhich eliminates the need for embedding the 'MathJax' library\ninto your web pages. In addition a 'math-to-rd' wrapper is\nprovided to automatically render beautiful math in R\ndocumentation files.",
    "version": "1.5.0",
    "maintainer": "Jeroen Ooms <jeroenooms@gmail.com>",
    "author": "Jeroen Ooms [aut, cre] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\nKhan Academy and other contributors [cph] (KaTeX JavaScript library)",
    "url": "https://docs.ropensci.org/katex/,\nhttps://github.com/ropensci/katex\nhttps://katex.org/docs/options.html (upstream)",
    "bug_reports": "https://github.com/ropensci/katex/issues",
    "repository": "",
    "exports": [
      [
        "example_math"
      ],
      [
        "katex_html"
      ],
      [
        "katex_mathml"
      ],
      [
        "math_to_rd"
      ],
      [
        "render_math_in_html"
      ]
    ],
    "topics": [],
    "score": 8.7784,
    "stars": 37,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "katex Rendering Math to HTML, 'MathML', or R-Documentation Format Convert latex math expressions to HTML and 'MathML' for\nuse in markdown documents or package manual pages. The\nrendering is done in R using the V8 engine (i.e. server-side),\nwhich eliminates the need for embedding the 'MathJax' library\ninto your web pages. In addition a 'math-to-rd' wrapper is\nprovided to automatically render beautiful math in R\ndocumentation files. example_math katex_html katex_mathml math_to_rd render_math_in_html "
  },
  {
    "id": 982,
    "package_name": "pkgsearch",
    "title": "Search and Query CRAN R Packages",
    "description": "Search CRAN metadata about packages by keyword,\npopularity, recent activity, package name and more. Uses the\n'R-hub' search server, see <https://r-pkg.org> and the CRAN\nmetadata database, that contains information about CRAN\npackages. Note that this is _not_ a CRAN project.",
    "version": "3.1.5.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nMa\u00eblle Salmon [aut] (ORCID: <https://orcid.org/0000-0002-2815-0399>),\nR Consortium [fnd]",
    "url": "https://github.com/r-hub/pkgsearch,\nhttps://r-hub.github.io/pkgsearch/",
    "bug_reports": "https://github.com/r-hub/pkgsearch/issues",
    "repository": "",
    "exports": [
      [
        "advanced_search"
      ],
      [
        "cran_events"
      ],
      [
        "cran_new"
      ],
      [
        "cran_package"
      ],
      [
        "cran_package_history"
      ],
      [
        "cran_packages"
      ],
      [
        "cran_top_downloaded"
      ],
      [
        "cran_trending"
      ],
      [
        "more"
      ],
      [
        "pkg_search"
      ],
      [
        "pkg_search_addin"
      ],
      [
        "ps"
      ]
    ],
    "topics": [
      [
        "ranking"
      ],
      [
        "search-engine"
      ]
    ],
    "score": 8.6717,
    "stars": 111,
    "primary_category": "infrastructure",
    "source_universe": "r-hub",
    "search_text": "pkgsearch Search and Query CRAN R Packages Search CRAN metadata about packages by keyword,\npopularity, recent activity, package name and more. Uses the\n'R-hub' search server, see <https://r-pkg.org> and the CRAN\nmetadata database, that contains information about CRAN\npackages. Note that this is _not_ a CRAN project. advanced_search cran_events cran_new cran_package cran_package_history cran_packages cran_top_downloaded cran_trending more pkg_search pkg_search_addin ps ranking search-engine"
  },
  {
    "id": 689,
    "package_name": "hoardr",
    "title": "Manage Cached Files",
    "description": "Suite of tools for managing cached files, targeting use in\nother R packages. Uses 'rappdirs' for cross-platform paths.\nProvides utilities to manage cache directories, including\ntargeting files by path or by key; cached directories can be\ncompressed and uncompressed easily to save disk space.",
    "version": "0.5.5",
    "maintainer": "Tam\u00e1s Stirling <stirling.tamas@gmail.com>",
    "author": "Scott Chamberlain [aut] (ORCID:\n<https://orcid.org/0000-0003-2542-2202>),\nTam\u00e1s Stirling [ctb, cre]",
    "url": "https://docs.ropensci.org/hoardr/,\nhttps://github.com/ropensci/hoardr",
    "bug_reports": "https://github.com/ropensci/hoardr/issues",
    "repository": "",
    "exports": [
      [
        "hoard"
      ]
    ],
    "topics": [
      [
        "caching"
      ],
      [
        "data"
      ],
      [
        "files"
      ],
      [
        "xml"
      ],
      [
        "pdf"
      ]
    ],
    "score": 8.4717,
    "stars": 23,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "hoardr Manage Cached Files Suite of tools for managing cached files, targeting use in\nother R packages. Uses 'rappdirs' for cross-platform paths.\nProvides utilities to manage cache directories, including\ntargeting files by path or by key; cached directories can be\ncompressed and uncompressed easily to save disk space. hoard caching data files xml pdf"
  },
  {
    "id": 323,
    "package_name": "brulee",
    "title": "High-Level Modeling Functions with 'torch'",
    "description": "Provides high-level modeling functions to define and train\nmodels using the 'torch' R package. Models include linear,\nlogistic, and multinomial regression as well as multilayer\nperceptrons.",
    "version": "0.6.0.9000",
    "maintainer": "Max Kuhn <max@posit.co>",
    "author": "Max Kuhn [aut, cre] (ORCID: <https://orcid.org/0000-0003-2402-136X>),\nDaniel Falbel [aut],\nPosit Software, PBC [cph, fnd]",
    "url": "https://github.com/tidymodels/brulee,\nhttps://brulee.tidymodels.org/",
    "bug_reports": "https://github.com/tidymodels/brulee/issues",
    "repository": "",
    "exports": [
      [
        "autoplot"
      ],
      [
        "brulee_activations"
      ],
      [
        "brulee_linear_reg"
      ],
      [
        "brulee_logistic_reg"
      ],
      [
        "brulee_mlp"
      ],
      [
        "brulee_mlp_two_layer"
      ],
      [
        "brulee_multinomial_reg"
      ],
      [
        "coef"
      ],
      [
        "matrix_to_dataset"
      ],
      [
        "schedule_cyclic"
      ],
      [
        "schedule_decay_expo"
      ],
      [
        "schedule_decay_time"
      ],
      [
        "schedule_step"
      ],
      [
        "set_learn_rate"
      ],
      [
        "tunable"
      ]
    ],
    "topics": [],
    "score": 8.1519,
    "stars": 74,
    "primary_category": "tidyverse",
    "source_universe": "tidymodels",
    "search_text": "brulee High-Level Modeling Functions with 'torch' Provides high-level modeling functions to define and train\nmodels using the 'torch' R package. Models include linear,\nlogistic, and multinomial regression as well as multilayer\nperceptrons. autoplot brulee_activations brulee_linear_reg brulee_logistic_reg brulee_mlp brulee_mlp_two_layer brulee_multinomial_reg coef matrix_to_dataset schedule_cyclic schedule_decay_expo schedule_decay_time schedule_step set_learn_rate tunable "
  },
  {
    "id": 983,
    "package_name": "pkgstats",
    "title": "Metrics of R Packages",
    "description": "Static code analyses for R packages using the external\ncode-tagging libraries 'ctags' and 'gtags'. Static analyses\nenable packages to be analysed very quickly, generally a couple\nof seconds at most. The package also provides access to a\ndatabase generating by applying the main function to the full\n'CRAN' archive, enabling the statistical properties of any\npackage to be compared with all other 'CRAN' packages.",
    "version": "0.2.1.005",
    "maintainer": "Mark Padgham <mark.padgham@email.com>",
    "author": "Mark Padgham [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2172-5265>),\nMichael Sumner [ctb] (ORCID: <https://orcid.org/0000-0002-2471-7511>),\nJeffrey Hollister [ctb] (ORCID:\n<https://orcid.org/0000-0002-9254-9740>),\nEgor Kotov [ctb] (ORCID: <https://orcid.org/0000-0001-6690-5345>)",
    "url": "https://docs.ropensci.org/pkgstats/,\nhttps://github.com/ropensci-review-tools/pkgstats",
    "bug_reports": "https://github.com/ropensci-review-tools/pkgstats/issues",
    "repository": "",
    "exports": [
      [
        "ctags_install"
      ],
      [
        "ctags_test"
      ],
      [
        "desc_stats"
      ],
      [
        "dl_pkgstats_data"
      ],
      [
        "extract_tarball"
      ],
      [
        "loc_stats"
      ],
      [
        "pkgstats"
      ],
      [
        "pkgstats_cran_current_from_full"
      ],
      [
        "pkgstats_fn_names"
      ],
      [
        "pkgstats_fns_from_archive"
      ],
      [
        "pkgstats_fns_update"
      ],
      [
        "pkgstats_from_archive"
      ],
      [
        "pkgstats_summary"
      ],
      [
        "pkgstats_update"
      ],
      [
        "plot_network"
      ],
      [
        "rd_stats"
      ],
      [
        "tags_data"
      ]
    ],
    "topics": [
      [
        "code-analysis"
      ],
      [
        "code-statistics"
      ],
      [
        "software-analysis"
      ],
      [
        "cpp"
      ]
    ],
    "score": 8.1004,
    "stars": 20,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "pkgstats Metrics of R Packages Static code analyses for R packages using the external\ncode-tagging libraries 'ctags' and 'gtags'. Static analyses\nenable packages to be analysed very quickly, generally a couple\nof seconds at most. The package also provides access to a\ndatabase generating by applying the main function to the full\n'CRAN' archive, enabling the statistical properties of any\npackage to be compared with all other 'CRAN' packages. ctags_install ctags_test desc_stats dl_pkgstats_data extract_tarball loc_stats pkgstats pkgstats_cran_current_from_full pkgstats_fn_names pkgstats_fns_from_archive pkgstats_fns_update pkgstats_from_archive pkgstats_summary pkgstats_update plot_network rd_stats tags_data code-analysis code-statistics software-analysis cpp"
  },
  {
    "id": 477,
    "package_name": "distionary",
    "title": "Create and Evaluate Probability Distributions",
    "description": "Create and evaluate probability distribution objects from\na variety of families or define custom distributions.\nAutomatically compute distributional properties, even when they\nhave not been specified. This package supports statistical\nmodeling and simulations, and forms the core of the probaverse\nsuite of R packages.",
    "version": "0.1.0",
    "maintainer": "Vincenzo Coia <vincenzo.coia@gmail.com>",
    "author": "Vincenzo Coia [aut, cre, cph],\nAmogh Joshi [ctb],\nShuyi Tan [ctb],\nZhipeng Zhu [ctb]",
    "url": "https://distionary.probaverse.com/,\nhttps://github.com/probaverse/distionary",
    "bug_reports": "https://github.com/probaverse/distionary/issues",
    "repository": "",
    "exports": [
      [
        "dgev"
      ],
      [
        "dgp"
      ],
      [
        "distribution"
      ],
      [
        "dst_bern"
      ],
      [
        "dst_beta"
      ],
      [
        "dst_binom"
      ],
      [
        "dst_cauchy"
      ],
      [
        "dst_chisq"
      ],
      [
        "dst_degenerate"
      ],
      [
        "dst_empirical"
      ],
      [
        "dst_exp"
      ],
      [
        "dst_f"
      ],
      [
        "dst_finite"
      ],
      [
        "dst_gamma"
      ],
      [
        "dst_geom"
      ],
      [
        "dst_gev"
      ],
      [
        "dst_gp"
      ],
      [
        "dst_hyper"
      ],
      [
        "dst_lnorm"
      ],
      [
        "dst_lp3"
      ],
      [
        "dst_nbinom"
      ],
      [
        "dst_norm"
      ],
      [
        "dst_null"
      ],
      [
        "dst_pearson3"
      ],
      [
        "dst_pois"
      ],
      [
        "dst_t"
      ],
      [
        "dst_unif"
      ],
      [
        "dst_weibull"
      ],
      [
        "enframe_cdf"
      ],
      [
        "enframe_chf"
      ],
      [
        "enframe_density"
      ],
      [
        "enframe_hazard"
      ],
      [
        "enframe_odds"
      ],
      [
        "enframe_pmf"
      ],
      [
        "enframe_quantile"
      ],
      [
        "enframe_return"
      ],
      [
        "enframe_survival"
      ],
      [
        "eval_cdf"
      ],
      [
        "eval_chf"
      ],
      [
        "eval_density"
      ],
      [
        "eval_hazard"
      ],
      [
        "eval_odds"
      ],
      [
        "eval_pmf"
      ],
      [
        "eval_property"
      ],
      [
        "eval_quantile"
      ],
      [
        "eval_return"
      ],
      [
        "eval_survival"
      ],
      [
        "is_distribution"
      ],
      [
        "is.distribution"
      ],
      [
        "kurtosis"
      ],
      [
        "kurtosis_exc"
      ],
      [
        "parameters"
      ],
      [
        "parameters<-"
      ],
      [
        "pgev"
      ],
      [
        "pgp"
      ],
      [
        "pretty_name"
      ],
      [
        "prob_left"
      ],
      [
        "prob_right"
      ],
      [
        "qgev"
      ],
      [
        "qgp"
      ],
      [
        "realise"
      ],
      [
        "realize"
      ],
      [
        "skewness"
      ],
      [
        "stdev"
      ],
      [
        "variance"
      ],
      [
        "vtype"
      ]
    ],
    "topics": [
      [
        "distributions"
      ]
    ],
    "score": 7.9321,
    "stars": 6,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "distionary Create and Evaluate Probability Distributions Create and evaluate probability distribution objects from\na variety of families or define custom distributions.\nAutomatically compute distributional properties, even when they\nhave not been specified. This package supports statistical\nmodeling and simulations, and forms the core of the probaverse\nsuite of R packages. dgev dgp distribution dst_bern dst_beta dst_binom dst_cauchy dst_chisq dst_degenerate dst_empirical dst_exp dst_f dst_finite dst_gamma dst_geom dst_gev dst_gp dst_hyper dst_lnorm dst_lp3 dst_nbinom dst_norm dst_null dst_pearson3 dst_pois dst_t dst_unif dst_weibull enframe_cdf enframe_chf enframe_density enframe_hazard enframe_odds enframe_pmf enframe_quantile enframe_return enframe_survival eval_cdf eval_chf eval_density eval_hazard eval_odds eval_pmf eval_property eval_quantile eval_return eval_survival is_distribution is.distribution kurtosis kurtosis_exc parameters parameters<- pgev pgp pretty_name prob_left prob_right qgev qgp realise realize skewness stdev variance vtype distributions"
  },
  {
    "id": 454,
    "package_name": "debugme",
    "title": "Debug R Packages",
    "description": "Specify debug messages as special string constants, and\ncontrol debugging of packages via environment variables.",
    "version": "1.2.0.9000",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\nPosit Software, PBC [cph, fnd]",
    "url": "https://github.com/r-lib/debugme#readme,\nhttps://r-lib.github.io/debugme/",
    "bug_reports": "https://github.com/r-lib/debugme/issues",
    "repository": "",
    "exports": [
      [
        "debug"
      ],
      [
        "debugme"
      ]
    ],
    "topics": [
      [
        "debugging-tool"
      ]
    ],
    "score": 7.8525,
    "stars": 153,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "debugme Debug R Packages Specify debug messages as special string constants, and\ncontrol debugging of packages via environment variables. debug debugme debugging-tool"
  },
  {
    "id": 1338,
    "package_name": "tic",
    "title": "Tasks Integrating Continuously: CI-Agnostic Workflow Definitions",
    "description": "Provides a way to describe common build and deployment\nworkflows for R-based projects: packages, websites (e.g.\nblogdown, pkgdown), or data processing (e.g. research\ncompendia). The recipe is described independent of the\ncontinuous integration tool used for processing the workflow\n(e.g. 'GitHub Actions' or 'Circle CI').  This package has been\npeer-reviewed by rOpenSci (v0.3.0.9004).",
    "version": "0.14.1",
    "maintainer": "Eli Miller <eli@eli.dev>",
    "author": "Eli Miller [aut, cre] (ORCID: <https://orcid.org/0000-0002-2127-9456>),\nPatrick Schratz [aut] (ORCID: <https://orcid.org/0000-0003-0748-6624>),\nKirill M\u00fcller [aut] (ORCID: <https://orcid.org/0000-0002-1416-3412>),\nMika Braginsky [aut],\nKarthik Ram [aut],\nJeroen Ooms [aut],\nMax Held [rev] (Max reviewed the package for ropensci, see\n<https://github.com/ropensci/software-review/issues/305>),\nAnna Krystalli [rev] (Anna reviewed the package for ropensci, see\n<https://github.com/ropensci/software-review/issues/305>),\nLaura DeCicco [rev] (Laura reviewed the package for ropensci, see\n<https://github.com/ropensci/software-review/issues/305>),\nrOpenSci [fnd] (ROR: <https://ror.org/019jywm96>)",
    "url": "https://github.com/ropensci/tic",
    "bug_reports": "https://github.com/ropensci/tic/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "add_code_step"
      ],
      [
        "add_package_checks"
      ],
      [
        "add_step"
      ],
      [
        "after_deploy"
      ],
      [
        "after_failure"
      ],
      [
        "after_install"
      ],
      [
        "after_script"
      ],
      [
        "after_success"
      ],
      [
        "base64serialize"
      ],
      [
        "base64unserialize"
      ],
      [
        "before_deploy"
      ],
      [
        "before_install"
      ],
      [
        "before_script"
      ],
      [
        "ci"
      ],
      [
        "ci_can_push"
      ],
      [
        "ci_cat_with_color"
      ],
      [
        "ci_get_branch"
      ],
      [
        "ci_get_build_number"
      ],
      [
        "ci_get_build_url"
      ],
      [
        "ci_get_commit"
      ],
      [
        "ci_get_env"
      ],
      [
        "ci_get_slug"
      ],
      [
        "ci_has_env"
      ],
      [
        "ci_is_env"
      ],
      [
        "ci_is_interactive"
      ],
      [
        "ci_is_tag"
      ],
      [
        "ci_on_circle"
      ],
      [
        "ci_on_ghactions"
      ],
      [
        "deploy"
      ],
      [
        "do_blogdown"
      ],
      [
        "do_bookdown"
      ],
      [
        "do_drat"
      ],
      [
        "do_package_checks"
      ],
      [
        "do_pkgdown"
      ],
      [
        "do_readme_rmd"
      ],
      [
        "dsl_get"
      ],
      [
        "dsl_init"
      ],
      [
        "dsl_load"
      ],
      [
        "get_stage"
      ],
      [
        "gha_add_secret"
      ],
      [
        "install"
      ],
      [
        "list_macros"
      ],
      [
        "prepare_all_stages"
      ],
      [
        "repo_bioc"
      ],
      [
        "repo_cloud"
      ],
      [
        "repo_cran"
      ],
      [
        "repo_default"
      ],
      [
        "run_all_stages"
      ],
      [
        "run_stage"
      ],
      [
        "script"
      ],
      [
        "step_add_to_drat"
      ],
      [
        "step_add_to_known_hosts"
      ],
      [
        "step_build_blogdown"
      ],
      [
        "step_build_bookdown"
      ],
      [
        "step_build_pkgdown"
      ],
      [
        "step_do_push_deploy"
      ],
      [
        "step_hello_world"
      ],
      [
        "step_install_cran"
      ],
      [
        "step_install_deps"
      ],
      [
        "step_install_github"
      ],
      [
        "step_install_ssh_keys"
      ],
      [
        "step_push_deploy"
      ],
      [
        "step_rcmdcheck"
      ],
      [
        "step_run_code"
      ],
      [
        "step_session_info"
      ],
      [
        "step_setup_push_deploy"
      ],
      [
        "step_setup_ssh"
      ],
      [
        "step_test_ssh"
      ],
      [
        "step_write_text_file"
      ],
      [
        "TicStep"
      ],
      [
        "update_yml"
      ],
      [
        "use_circle_yml"
      ],
      [
        "use_ghactions_deploy"
      ],
      [
        "use_ghactions_yml"
      ],
      [
        "use_tic"
      ],
      [
        "use_tic_badge"
      ],
      [
        "use_tic_r"
      ],
      [
        "use_update_tic"
      ]
    ],
    "topics": [
      [
        "appveyor"
      ],
      [
        "continuous-integration"
      ],
      [
        "deployment"
      ],
      [
        "githubactions"
      ],
      [
        "travis-ci"
      ]
    ],
    "score": 7.2415,
    "stars": 155,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "tic Tasks Integrating Continuously: CI-Agnostic Workflow Definitions Provides a way to describe common build and deployment\nworkflows for R-based projects: packages, websites (e.g.\nblogdown, pkgdown), or data processing (e.g. research\ncompendia). The recipe is described independent of the\ncontinuous integration tool used for processing the workflow\n(e.g. 'GitHub Actions' or 'Circle CI').  This package has been\npeer-reviewed by rOpenSci (v0.3.0.9004). %>% add_code_step add_package_checks add_step after_deploy after_failure after_install after_script after_success base64serialize base64unserialize before_deploy before_install before_script ci ci_can_push ci_cat_with_color ci_get_branch ci_get_build_number ci_get_build_url ci_get_commit ci_get_env ci_get_slug ci_has_env ci_is_env ci_is_interactive ci_is_tag ci_on_circle ci_on_ghactions deploy do_blogdown do_bookdown do_drat do_package_checks do_pkgdown do_readme_rmd dsl_get dsl_init dsl_load get_stage gha_add_secret install list_macros prepare_all_stages repo_bioc repo_cloud repo_cran repo_default run_all_stages run_stage script step_add_to_drat step_add_to_known_hosts step_build_blogdown step_build_bookdown step_build_pkgdown step_do_push_deploy step_hello_world step_install_cran step_install_deps step_install_github step_install_ssh_keys step_push_deploy step_rcmdcheck step_run_code step_session_info step_setup_push_deploy step_setup_ssh step_test_ssh step_write_text_file TicStep update_yml use_circle_yml use_ghactions_deploy use_ghactions_yml use_tic use_tic_badge use_tic_r use_update_tic appveyor continuous-integration deployment githubactions travis-ci"
  },
  {
    "id": 1272,
    "package_name": "stantargets",
    "title": "Targets for Stan Workflows",
    "description": "Bayesian data analysis usually incurs long runtimes and\ncumbersome custom code. A pipeline toolkit tailored to Bayesian\nstatisticians, the 'stantargets' R package leverages 'targets'\nand 'cmdstanr' to ease these burdens. 'stantargets' makes it\nsuper easy to set up scalable Stan pipelines that automatically\nparallelize the computation and skip expensive steps when the\nresults are already up to date. Minimal custom code is\nrequired, and there is no need to manually configure branching,\nso usage is much easier than 'targets' alone. 'stantargets' can\naccess all of 'cmdstanr''s major algorithms (MCMC, variational\nBayes, and optimization) and it supports both single-fit\nworkflows and multi-rep simulation studies. For the statistical\nmethodology, please refer to 'Stan' documentation (Stan\nDevelopment Team 2020) <https://mc-stan.org/>.",
    "version": "0.1.2.9000",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1878-3253>),\nKrzysztof Sakrejda [rev],\nMatthew T. Warkentin [rev],\nEli Lilly and Company [cph]",
    "url": "https://docs.ropensci.org/stantargets/,\nhttps://github.com/ropensci/stantargets,\nhttps://r-multiverse.org/topics/bayesian.html",
    "bug_reports": "https://github.com/ropensci/stantargets/issues",
    "repository": "",
    "exports": [
      [
        "tar_stan_compile"
      ],
      [
        "tar_stan_compile_run"
      ],
      [
        "tar_stan_example_data"
      ],
      [
        "tar_stan_example_file"
      ],
      [
        "tar_stan_gq"
      ],
      [
        "tar_stan_gq_rep_draws"
      ],
      [
        "tar_stan_gq_rep_run"
      ],
      [
        "tar_stan_gq_rep_summary"
      ],
      [
        "tar_stan_gq_run"
      ],
      [
        "tar_stan_mcmc"
      ],
      [
        "tar_stan_mcmc_rep_diagnostics"
      ],
      [
        "tar_stan_mcmc_rep_draws"
      ],
      [
        "tar_stan_mcmc_rep_run"
      ],
      [
        "tar_stan_mcmc_rep_summary"
      ],
      [
        "tar_stan_mcmc_run"
      ],
      [
        "tar_stan_mle"
      ],
      [
        "tar_stan_mle_rep_draws"
      ],
      [
        "tar_stan_mle_rep_run"
      ],
      [
        "tar_stan_mle_rep_summary"
      ],
      [
        "tar_stan_mle_run"
      ],
      [
        "tar_stan_output"
      ],
      [
        "tar_stan_rep_data_batch"
      ],
      [
        "tar_stan_summary"
      ],
      [
        "tar_stan_summary_join_data"
      ],
      [
        "tar_stan_vb"
      ],
      [
        "tar_stan_vb_rep_draws"
      ],
      [
        "tar_stan_vb_rep_run"
      ],
      [
        "tar_stan_vb_rep_summary"
      ],
      [
        "tar_stan_vb_run"
      ]
    ],
    "topics": [
      [
        "bayesian"
      ],
      [
        "high-performance-computing"
      ],
      [
        "make"
      ],
      [
        "r-targetopia"
      ],
      [
        "reproducibility"
      ],
      [
        "stan"
      ],
      [
        "statistics"
      ],
      [
        "targets"
      ]
    ],
    "score": 7.0092,
    "stars": 50,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "stantargets Targets for Stan Workflows Bayesian data analysis usually incurs long runtimes and\ncumbersome custom code. A pipeline toolkit tailored to Bayesian\nstatisticians, the 'stantargets' R package leverages 'targets'\nand 'cmdstanr' to ease these burdens. 'stantargets' makes it\nsuper easy to set up scalable Stan pipelines that automatically\nparallelize the computation and skip expensive steps when the\nresults are already up to date. Minimal custom code is\nrequired, and there is no need to manually configure branching,\nso usage is much easier than 'targets' alone. 'stantargets' can\naccess all of 'cmdstanr''s major algorithms (MCMC, variational\nBayes, and optimization) and it supports both single-fit\nworkflows and multi-rep simulation studies. For the statistical\nmethodology, please refer to 'Stan' documentation (Stan\nDevelopment Team 2020) <https://mc-stan.org/>. tar_stan_compile tar_stan_compile_run tar_stan_example_data tar_stan_example_file tar_stan_gq tar_stan_gq_rep_draws tar_stan_gq_rep_run tar_stan_gq_rep_summary tar_stan_gq_run tar_stan_mcmc tar_stan_mcmc_rep_diagnostics tar_stan_mcmc_rep_draws tar_stan_mcmc_rep_run tar_stan_mcmc_rep_summary tar_stan_mcmc_run tar_stan_mle tar_stan_mle_rep_draws tar_stan_mle_rep_run tar_stan_mle_rep_summary tar_stan_mle_run tar_stan_output tar_stan_rep_data_batch tar_stan_summary tar_stan_summary_join_data tar_stan_vb tar_stan_vb_rep_draws tar_stan_vb_rep_run tar_stan_vb_rep_summary tar_stan_vb_run bayesian high-performance-computing make r-targetopia reproducibility stan statistics targets"
  },
  {
    "id": 1136,
    "package_name": "roxygen2md",
    "title": "'Roxygen' to 'Markdown'",
    "description": "Converts elements of 'roxygen' documentation to\n'markdown'.",
    "version": "1.0.1.9016",
    "maintainer": "Kirill M\u00fcller <kirill@cynkra.com>",
    "author": "Kirill M\u00fcller [aut, cre],\nHeather Turner [ctb]",
    "url": "https://roxygen2md.r-lib.org/, https://github.com/r-lib/roxygen2md",
    "bug_reports": "https://github.com/r-lib/roxygen2md/issues",
    "repository": "",
    "exports": [
      [
        "find_rd"
      ],
      [
        "markdownify"
      ],
      [
        "roxygen2md"
      ]
    ],
    "topics": [
      [
        "documentation"
      ],
      [
        "markdown"
      ]
    ],
    "score": 6.9171,
    "stars": 68,
    "primary_category": "tidyverse",
    "source_universe": "r-lib",
    "search_text": "roxygen2md 'Roxygen' to 'Markdown' Converts elements of 'roxygen' documentation to\n'markdown'. find_rd markdownify roxygen2md documentation markdown"
  },
  {
    "id": 495,
    "package_name": "drjacoby",
    "title": "Flexible Markov Chain Monte Carlo via Reparameterization",
    "description": "drjacoby is an R package for performing Bayesian inference\nvia Markov chain monte carlo (MCMC). In addition to being\nhighly flexible it implements some advanced techniques that can\nimprove mixing in tricky situations.",
    "version": "1.5.4",
    "maintainer": "Bob Verity <r.verity@imperial.ac.uk>",
    "author": "Bob Verity [aut, cre],\nPete Winskill [aut]",
    "url": "",
    "bug_reports": "https://github.com/mrc-ide/drjacoby/issues",
    "repository": "",
    "exports": [
      [
        "check_drjacoby_loaded"
      ],
      [
        "cpp_template"
      ],
      [
        "define_params"
      ],
      [
        "plot_autocorrelation"
      ],
      [
        "plot_cor_mat"
      ],
      [
        "plot_credible"
      ],
      [
        "plot_density"
      ],
      [
        "plot_mc_acceptance"
      ],
      [
        "plot_pairs"
      ],
      [
        "plot_rung_loglike"
      ],
      [
        "plot_scatter"
      ],
      [
        "plot_trace"
      ],
      [
        "run_mcmc"
      ],
      [
        "sample_chains"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 6.4371,
    "stars": 12,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "drjacoby Flexible Markov Chain Monte Carlo via Reparameterization drjacoby is an R package for performing Bayesian inference\nvia Markov chain monte carlo (MCMC). In addition to being\nhighly flexible it implements some advanced techniques that can\nimprove mixing in tricky situations. check_drjacoby_loaded cpp_template define_params plot_autocorrelation plot_cor_mat plot_credible plot_density plot_mc_acceptance plot_pairs plot_rung_loglike plot_scatter plot_trace run_mcmc sample_chains cpp"
  },
  {
    "id": 719,
    "package_name": "jagstargets",
    "title": "Targets for JAGS Pipelines",
    "description": "Bayesian data analysis usually incurs long runtimes and\ncumbersome custom code. A pipeline toolkit tailored to Bayesian\nstatisticians, the 'jagstargets' R package is leverages\n'targets' and 'R2jags' to ease this burden. 'jagstargets' makes\nit super easy to set up scalable JAGS pipelines that\nautomatically parallelize the computation and skip expensive\nsteps when the results are already up to date. Minimal custom\ncode is required, and there is no need to manually configure\nbranching, so usage is much easier than 'targets' alone. For\nthe underlying methodology, please refer to the documentation\nof 'targets' <doi:10.21105/joss.02959> and 'JAGS' (Plummer\n2003)\n<https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf>.",
    "version": "1.2.3",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1878-3253>),\nDavid Lawrence Miller [rev],\nEli Lilly and Company [cph]",
    "url": "https://docs.ropensci.org/jagstargets/,\nhttps://github.com/ropensci/jagstargets,\nhttps://r-multiverse.org/topics/bayesian.html",
    "bug_reports": "https://github.com/ropensci/jagstargets/issues",
    "repository": "",
    "exports": [
      [
        "tar_jags"
      ],
      [
        "tar_jags_df"
      ],
      [
        "tar_jags_example_data"
      ],
      [
        "tar_jags_example_file"
      ],
      [
        "tar_jags_rep_data_batch"
      ],
      [
        "tar_jags_rep_dic"
      ],
      [
        "tar_jags_rep_draws"
      ],
      [
        "tar_jags_rep_run"
      ],
      [
        "tar_jags_rep_summary"
      ],
      [
        "tar_jags_run"
      ]
    ],
    "topics": [
      [
        "bayesian"
      ],
      [
        "high-performance-computing"
      ],
      [
        "jags"
      ],
      [
        "make"
      ],
      [
        "r-targetopia"
      ],
      [
        "reproducibility"
      ],
      [
        "rjags"
      ],
      [
        "statistics"
      ],
      [
        "targets"
      ],
      [
        "cpp"
      ]
    ],
    "score": 6.2455,
    "stars": 11,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "jagstargets Targets for JAGS Pipelines Bayesian data analysis usually incurs long runtimes and\ncumbersome custom code. A pipeline toolkit tailored to Bayesian\nstatisticians, the 'jagstargets' R package is leverages\n'targets' and 'R2jags' to ease this burden. 'jagstargets' makes\nit super easy to set up scalable JAGS pipelines that\nautomatically parallelize the computation and skip expensive\nsteps when the results are already up to date. Minimal custom\ncode is required, and there is no need to manually configure\nbranching, so usage is much easier than 'targets' alone. For\nthe underlying methodology, please refer to the documentation\nof 'targets' <doi:10.21105/joss.02959> and 'JAGS' (Plummer\n2003)\n<https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf>. tar_jags tar_jags_df tar_jags_example_data tar_jags_example_file tar_jags_rep_data_batch tar_jags_rep_dic tar_jags_rep_draws tar_jags_rep_run tar_jags_rep_summary tar_jags_run bayesian high-performance-computing jags make r-targetopia reproducibility rjags statistics targets cpp"
  },
  {
    "id": 263,
    "package_name": "autotest",
    "title": "Automatic Package Testing",
    "description": "Automatic testing of R packages via a simple YAML schema.",
    "version": "0.0.2.215",
    "maintainer": "Mark Padgham <mark.padgham@email.com>",
    "author": "Mark Padgham [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2172-5265>),\nJouni Helske [ctb] (ORCID: <https://orcid.org/0000-0001-7130-793X>)",
    "url": "https://docs.ropensci.org/autotest/,\nhttps://github.com/ropensci-review-tools/autotest",
    "bug_reports": "https://github.com/ropensci-review-tools/autotest/issues",
    "repository": "",
    "exports": [
      [
        "at_yaml_template"
      ],
      [
        "autotest_obj"
      ],
      [
        "autotest_package"
      ],
      [
        "autotest_types"
      ],
      [
        "autotest_yaml"
      ],
      [
        "examples_to_yaml"
      ],
      [
        "expect_autotest_no_err"
      ],
      [
        "expect_autotest_no_testdata"
      ],
      [
        "expect_autotest_no_warn"
      ],
      [
        "expect_autotest_notes"
      ],
      [
        "expect_autotest_testdata"
      ]
    ],
    "topics": [
      [
        "automated-testing"
      ],
      [
        "fuzzing"
      ],
      [
        "testing"
      ]
    ],
    "score": 6.0765,
    "stars": 53,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "autotest Automatic Package Testing Automatic testing of R packages via a simple YAML schema. at_yaml_template autotest_obj autotest_package autotest_types autotest_yaml examples_to_yaml expect_autotest_no_err expect_autotest_no_testdata expect_autotest_no_warn expect_autotest_notes expect_autotest_testdata automated-testing fuzzing testing"
  },
  {
    "id": 642,
    "package_name": "gittargets",
    "title": "Data Version Control for the Targets Package",
    "description": "In computationally demanding data analysis pipelines, the\n'targets' R package (2021, <doi:10.21105/joss.02959>) maintains\nan up-to-date set of results while skipping tasks that do not\nneed to rerun. This process increases speed and increases trust\nin the final end product. However, it also overwrites old\noutput with new output, and past results disappear by default.\nTo preserve historical output, the 'gittargets' package\ncaptures version-controlled snapshots of the data store, and\neach snapshot links to the underlying commit of the source\ncode. That way, when the user rolls back the code to a previous\nbranch or commit, 'gittargets' can recover the data\ncontemporaneous with that commit so that all targets remain up\nto date.",
    "version": "0.0.7.9000",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1878-3253>),\nSaras Windecker [rev],\nDavid Neuzerling [rev],\nEli Lilly and Company [cph]",
    "url": "https://docs.ropensci.org/gittargets/,\nhttps://github.com/ropensci/gittargets",
    "bug_reports": "https://github.com/ropensci/gittargets/issues",
    "repository": "",
    "exports": [
      [
        "tar_git_checkout"
      ],
      [
        "tar_git_init"
      ],
      [
        "tar_git_log"
      ],
      [
        "tar_git_ok"
      ],
      [
        "tar_git_snapshot"
      ],
      [
        "tar_git_status"
      ],
      [
        "tar_git_status_code"
      ],
      [
        "tar_git_status_data"
      ],
      [
        "tar_git_status_targets"
      ]
    ],
    "topics": [
      [
        "data-science"
      ],
      [
        "data-version-control"
      ],
      [
        "data-versioning"
      ],
      [
        "reproducibility"
      ],
      [
        "reproducible-research"
      ],
      [
        "targets"
      ],
      [
        "workflow"
      ]
    ],
    "score": 6.0237,
    "stars": 88,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "gittargets Data Version Control for the Targets Package In computationally demanding data analysis pipelines, the\n'targets' R package (2021, <doi:10.21105/joss.02959>) maintains\nan up-to-date set of results while skipping tasks that do not\nneed to rerun. This process increases speed and increases trust\nin the final end product. However, it also overwrites old\noutput with new output, and past results disappear by default.\nTo preserve historical output, the 'gittargets' package\ncaptures version-controlled snapshots of the data store, and\neach snapshot links to the underlying commit of the source\ncode. That way, when the user rolls back the code to a previous\nbranch or commit, 'gittargets' can recover the data\ncontemporaneous with that commit so that all targets remain up\nto date. tar_git_checkout tar_git_init tar_git_log tar_git_ok tar_git_snapshot tar_git_status tar_git_status_code tar_git_status_data tar_git_status_targets data-science data-version-control data-versioning reproducibility reproducible-research targets workflow"
  },
  {
    "id": 825,
    "package_name": "mockr",
    "title": "Mocking in R",
    "description": "Provides a means to mock a package function, i.e.,\ntemporarily substitute it for testing. Designed as a drop-in\nreplacement for the now deprecated 'testthat::with_mock()' and\n'testthat::local_mock()'.",
    "version": "0.2.0.9002",
    "maintainer": "Kirill M\u00fcller <krlmlr+r@mailbox.org>",
    "author": "Kirill M\u00fcller [aut, cre]",
    "url": "https://krlmlr.github.io/mockr/, https://github.com/krlmlr/mockr",
    "bug_reports": "https://github.com/krlmlr/mockr/issues",
    "repository": "",
    "exports": [
      [
        "get_mock_env"
      ],
      [
        "local_mock"
      ],
      [
        "with_mock"
      ]
    ],
    "topics": [],
    "score": 5.875,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "mockr Mocking in R Provides a means to mock a package function, i.e.,\ntemporarily substitute it for testing. Designed as a drop-in\nreplacement for the now deprecated 'testthat::with_mock()' and\n'testthat::local_mock()'. get_mock_env local_mock with_mock "
  },
  {
    "id": 980,
    "package_name": "pkgmatch",
    "title": "Find R Packages Matching Either Descriptions or Other R Packages",
    "description": "Find R packages matching either descriptions or other R\npackages.",
    "version": "0.5.1.014",
    "maintainer": "Mark Padgham <mark.padgham@email.com>",
    "author": "Mark Padgham [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-2172-5265>),\nDavis Vaughan [ctb]",
    "url": "https://docs.ropensci.org/pkgmatch/,\nhttps://github.com/ropensci-review-tools/pkgmatch",
    "bug_reports": "https://github.com/ropensci-review-tools/pkgmatch/issues",
    "repository": "",
    "exports": [
      [
        "generate_pkgmatch_example_data"
      ],
      [
        "get_ollama_url"
      ],
      [
        "ollama_check"
      ],
      [
        "pkgmatch_bm25"
      ],
      [
        "pkgmatch_bm25_fn_calls"
      ],
      [
        "pkgmatch_browse"
      ],
      [
        "pkgmatch_embeddings_from_pkgs"
      ],
      [
        "pkgmatch_embeddings_from_text"
      ],
      [
        "pkgmatch_load_data"
      ],
      [
        "pkgmatch_similar_fns"
      ],
      [
        "pkgmatch_similar_pkgs"
      ],
      [
        "pkgmatch_treesitter_fn_tags"
      ],
      [
        "pkgmatch_update_cache"
      ],
      [
        "pkgmatch_update_data"
      ],
      [
        "set_ollama_url"
      ],
      [
        "text_is_code"
      ]
    ],
    "topics": [
      [
        "embeddings"
      ],
      [
        "llms"
      ],
      [
        "natural-language-processing"
      ],
      [
        "cpp"
      ]
    ],
    "score": 5.8089,
    "stars": 8,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "pkgmatch Find R Packages Matching Either Descriptions or Other R Packages Find R packages matching either descriptions or other R\npackages. generate_pkgmatch_example_data get_ollama_url ollama_check pkgmatch_bm25 pkgmatch_bm25_fn_calls pkgmatch_browse pkgmatch_embeddings_from_pkgs pkgmatch_embeddings_from_text pkgmatch_load_data pkgmatch_similar_fns pkgmatch_similar_pkgs pkgmatch_treesitter_fn_tags pkgmatch_update_cache pkgmatch_update_data set_ollama_url text_is_code embeddings llms natural-language-processing cpp"
  },
  {
    "id": 164,
    "package_name": "ReLTER",
    "title": "An Interface for the eLTER Community",
    "description": "ReLTER provides access to DEIMS-SDR (https://deims.org/),\nand allows interaction with data and software implemented by\neLTER Research Infrastructure (RI) thus improving data sharing\namong European LTER projects.  ReLTER uses the R language to\naccess and interact with the DEIMS-SDR archive of information\nshared by the Long Term Ecological Research (LTER) network.\nThis package grew within eLTER H2020 as a major project that\nwill help advance the development of European Long-Term\nEcosystem Research Infrastructures (eLTER RI -\nhttps://elter-ri.eu).  The ReLTER package functions in\nparticular allow to: - retrieve the information about entities\n(e.g. sites, datasets, and activities) shared by DEIMS-SDR (see\ne.g. get_site_info function); - interact with the ODSEurope\n(maps.opendatascience.eu) starting with the dataset shared by\nDEIMS-SDR (https://deims.org/) (see e.g. the get_site_ODS()\nfunction); - use the eLTER site informations to download and\ncrop geospatial data from other platforms (see e.g.\nget_site_ODS function()); - improve the quality of the dataset\n(see e.g. get_id_worms()).  Functions currently implemented are\nderived from discussions of the needs among the eLTER users\ncommunity.  The ReLTER package will continue to follow the\nprogress of eLTER-RI and evolve, adding new tools and\nimprovements as required.",
    "version": "3.0.0",
    "maintainer": "Alessandro Oggioni <alessandro.oggioni@cnr.it>",
    "author": "Alessandro Oggioni [aut, cre, fnd] (ORCID:\n<https://orcid.org/0000-0002-7997-219X>),\nMicha Silver [aut, ctb] (ORCID:\n<https://orcid.org/0000-0002-1128-1325>),\nPaolo Tagliolato [aut, ctb] (ORCID:\n<https://orcid.org/0000-0002-0261-313X>),\nLuigi Ranghetti [aut, ctb] (ORCID:\n<https://orcid.org/0000-0001-6207-5188>),\nAllison Horst [rev] (Allison reviewed the package (v. 1.0.0) for\nrOpenSci, see\nhttps://github.com/ropensci/software-review/issues/485),\nWill Bolton [rev] (Will reviewed the package (v. 1.0.0) for rOpenSci,\nsee https://github.com/ropensci/software-review/issues/485),\nMauro Lepore [edt] (Mauro was editor for rOpenSci, see\nhttps://github.com/ropensci/software-review/issues/485)",
    "url": "https://docs.ropensci.org/ReLTER",
    "bug_reports": "https://github.com/ropensci/ReLTER/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "get_activity_info"
      ],
      [
        "get_dataset_info"
      ],
      [
        "get_deims_API_version"
      ],
      [
        "get_deims_base_url"
      ],
      [
        "get_location_info"
      ],
      [
        "get_network_sites"
      ],
      [
        "get_sensor_info"
      ],
      [
        "get_site_EcoDataCube"
      ],
      [
        "get_site_info"
      ],
      [
        "get_site_speciesOccurrences"
      ],
      [
        "get_sites_interactive"
      ],
      [
        "get_sites_within_3d_bounding_box"
      ],
      [
        "get_sites_within_radius"
      ],
      [
        "get_zenodo_data"
      ],
      [
        "map_occ_gbif2elter"
      ],
      [
        "map_occ_inat2elter"
      ],
      [
        "map_occ_obis2elter"
      ],
      [
        "package_settings"
      ],
      [
        "produce_network_points_map"
      ],
      [
        "produce_site_map"
      ],
      [
        "produce_site_observedProperties_pie"
      ],
      [
        "produce_site_observedProperties_waffle"
      ],
      [
        "produce_site_qrcode"
      ],
      [
        "reporting_produce_data_object_v1.3"
      ],
      [
        "reporting_produce_data_object_v2.0"
      ],
      [
        "reporting_save_archive"
      ],
      [
        "save_occ_eLTER_reporting_Archive"
      ],
      [
        "set_deims_base_url"
      ],
      [
        "taxon_id_pesi"
      ],
      [
        "taxon_id_worms"
      ]
    ],
    "topics": [
      [
        "biodiversity-informatics"
      ],
      [
        "data-science"
      ],
      [
        "ecology"
      ],
      [
        "elter"
      ],
      [
        "research-infrastructure"
      ]
    ],
    "score": 5.7952,
    "stars": 13,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "ReLTER An Interface for the eLTER Community ReLTER provides access to DEIMS-SDR (https://deims.org/),\nand allows interaction with data and software implemented by\neLTER Research Infrastructure (RI) thus improving data sharing\namong European LTER projects.  ReLTER uses the R language to\naccess and interact with the DEIMS-SDR archive of information\nshared by the Long Term Ecological Research (LTER) network.\nThis package grew within eLTER H2020 as a major project that\nwill help advance the development of European Long-Term\nEcosystem Research Infrastructures (eLTER RI -\nhttps://elter-ri.eu).  The ReLTER package functions in\nparticular allow to: - retrieve the information about entities\n(e.g. sites, datasets, and activities) shared by DEIMS-SDR (see\ne.g. get_site_info function); - interact with the ODSEurope\n(maps.opendatascience.eu) starting with the dataset shared by\nDEIMS-SDR (https://deims.org/) (see e.g. the get_site_ODS()\nfunction); - use the eLTER site informations to download and\ncrop geospatial data from other platforms (see e.g.\nget_site_ODS function()); - improve the quality of the dataset\n(see e.g. get_id_worms()).  Functions currently implemented are\nderived from discussions of the needs among the eLTER users\ncommunity.  The ReLTER package will continue to follow the\nprogress of eLTER-RI and evolve, adding new tools and\nimprovements as required. %>% get_activity_info get_dataset_info get_deims_API_version get_deims_base_url get_location_info get_network_sites get_sensor_info get_site_EcoDataCube get_site_info get_site_speciesOccurrences get_sites_interactive get_sites_within_3d_bounding_box get_sites_within_radius get_zenodo_data map_occ_gbif2elter map_occ_inat2elter map_occ_obis2elter package_settings produce_network_points_map produce_site_map produce_site_observedProperties_pie produce_site_observedProperties_waffle produce_site_qrcode reporting_produce_data_object_v1.3 reporting_produce_data_object_v2.0 reporting_save_archive save_occ_eLTER_reporting_Archive set_deims_base_url taxon_id_pesi taxon_id_worms biodiversity-informatics data-science ecology elter research-infrastructure"
  },
  {
    "id": 823,
    "package_name": "mlt.docreg",
    "title": "Most Likely Transformations: Documentation and Regression Tests",
    "description": "Additional documentation, a package vignette and\nregression tests for package mlt.",
    "version": "1.1-12",
    "maintainer": "Torsten Hothorn <Torsten.Hothorn@R-project.org>",
    "author": "Torsten Hothorn [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-8301-0471>)",
    "url": "http://ctm.R-forge.R-project.org",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "checkGH"
      ]
    ],
    "topics": [],
    "score": 5.6806,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "mlt.docreg Most Likely Transformations: Documentation and Regression Tests Additional documentation, a package vignette and\nregression tests for package mlt. checkGH "
  },
  {
    "id": 1133,
    "package_name": "rotemplate",
    "title": "pkgdown template and utilities for rOpenSci docs",
    "description": "This is a private template for use by rOpenSci packages.\nPlease don't use it for your own non-rOpenSci package.",
    "version": "2.0.1",
    "maintainer": "Ma\u00eblle Salmon <maelle.salmon@yahoo.se>",
    "author": "Ma\u00eblle Salmon [cre, aut] (ORCID:\n<https://orcid.org/0000-0002-2815-0399>),\nJeroen Ooms [aut],\nrOpenSci [fnd] (https://ropensci.org/, ROR:\n<https://ror.org/019jywm96>)",
    "url": "https://github.com/ropensci-org/rotemplate",
    "bug_reports": "https://github.com/ropensci-org/rotemplate/issues",
    "repository": "",
    "exports": [
      [
        "build_ropensci_docs"
      ],
      [
        "test"
      ],
      [
        "test2"
      ],
      [
        "test3"
      ],
      [
        "test4"
      ]
    ],
    "topics": [
      [
        "pkgdown"
      ]
    ],
    "score": 5.574,
    "stars": 25,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rotemplate pkgdown template and utilities for rOpenSci docs This is a private template for use by rOpenSci packages.\nPlease don't use it for your own non-rOpenSci package. build_ropensci_docs test test2 test3 test4 pkgdown"
  },
  {
    "id": 909,
    "package_name": "oompaData",
    "title": "Data to Illustrate OOMPA Algorithms",
    "description": "This is a data-only package to provide example data for\nother packages that are part of the \"Object-Oriented Microrray\nand Proteomics Analysis\" suite of packages. These are described\nin more detail at the package URL.",
    "version": "3.1.5",
    "maintainer": "Kevin R. Coombes <krc@silicovore.com>",
    "author": "Kevin R. Coombes [aut, cre]",
    "url": "http://oompa.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 5.4715,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "oompaData Data to Illustrate OOMPA Algorithms This is a data-only package to provide example data for\nother packages that are part of the \"Object-Oriented Microrray\nand Proteomics Analysis\" suite of packages. These are described\nin more detail at the package URL.  "
  },
  {
    "id": 1039,
    "package_name": "qualR",
    "title": "An R package to download S\u00e3o Paulo and Rio de Janeiro air\npollution data",
    "description": "A package to download information from CETESB QUALAR\n<https://cetesb.sp.gov.br/ar/qualar/> and MonitorAr\n<http://jeap.rio.rj.gov.br/je-metinfosmac/institucional/index.html>\nsystems. It contains function to download different parameters,\na set of criteria pollutants and the most frequent\nmeteorological parameters used in air quality data analysis and\nair quality model evaluation.",
    "version": "0.9.7",
    "maintainer": "Mario Gavidia-Calder\u00f3n <mario.calderon@iag.usp.br>",
    "author": "Mario Gavidia-Calder\u00f3n [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7371-1116>),\nMaria de Fatima Andrade [ctb, ths] (ORCID:\n<https://orcid.org/0000-0001-5351-8311>),\nDaniel Schuch [aut, ctb] (ORCID:\n<https://orcid.org/0000-0001-5977-4519>),\nBeatriz Milz [rev] (Beatriz reviewed the package (v. 0.9.6) for\nrOpenSci),\nKaue de Sousa [rev] (Kaue reviewed the package (v. 0.9.6) for rOpenSci)",
    "url": "https://docs.ropensci.org/qualR (website)\nhttps://github.com/ropensci/qualR",
    "bug_reports": "https://github.com/ropensci/qualR/issues",
    "repository": "",
    "exports": [
      [
        "cetesb_retrieve_met"
      ],
      [
        "cetesb_retrieve_met_pol"
      ],
      [
        "cetesb_retrieve_param"
      ],
      [
        "cetesb_retrieve_pol"
      ],
      [
        "monitor_ar_retrieve_met"
      ],
      [
        "monitor_ar_retrieve_met_pol"
      ],
      [
        "monitor_ar_retrieve_param"
      ],
      [
        "monitor_ar_retrieve_pol"
      ]
    ],
    "topics": [
      [
        "air-pollutants"
      ],
      [
        "air-quality-data"
      ],
      [
        "air-quality-measurements"
      ],
      [
        "brazil"
      ],
      [
        "cetesb"
      ],
      [
        "rio-de-janeiro"
      ],
      [
        "sao-paulo"
      ],
      [
        "weather-data"
      ]
    ],
    "score": 5.3235,
    "stars": 27,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "qualR An R package to download S\u00e3o Paulo and Rio de Janeiro air\npollution data A package to download information from CETESB QUALAR\n<https://cetesb.sp.gov.br/ar/qualar/> and MonitorAr\n<http://jeap.rio.rj.gov.br/je-metinfosmac/institucional/index.html>\nsystems. It contains function to download different parameters,\na set of criteria pollutants and the most frequent\nmeteorological parameters used in air quality data analysis and\nair quality model evaluation. cetesb_retrieve_met cetesb_retrieve_met_pol cetesb_retrieve_param cetesb_retrieve_pol monitor_ar_retrieve_met monitor_ar_retrieve_met_pol monitor_ar_retrieve_param monitor_ar_retrieve_pol air-pollutants air-quality-data air-quality-measurements brazil cetesb rio-de-janeiro sao-paulo weather-data"
  },
  {
    "id": 1151,
    "package_name": "rscontract",
    "title": "Generic implementation of the 'RStudio' connections contract",
    "description": "Provides a generic implementation of the 'RStudio'\nconnection contract to make it easier for database connections,\nand other type of connections, opened via R packages integrate\nwith the connections pane inside the 'RStudio' interactive\ndevelopment environment (IDE).",
    "version": "0.1.2",
    "maintainer": "Nathan Stephens <nathan@rstudio.com>",
    "author": "Nathan Stephens [aut, cre],\nEdgar Ruiz [aut]",
    "url": "https://github.com/rstudio/rscontract",
    "bug_reports": "https://github.com/rstudio/rscontract/issues",
    "repository": "",
    "exports": [
      [
        "as_rscontract"
      ],
      [
        "rscontract_close"
      ],
      [
        "rscontract_ide"
      ],
      [
        "rscontract_open"
      ],
      [
        "rscontract_spec"
      ],
      [
        "rscontract_update"
      ],
      [
        "sample_catalog"
      ]
    ],
    "topics": [
      [
        "connections-pane"
      ],
      [
        "rstudio"
      ]
    ],
    "score": 5.1206,
    "stars": 22,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "rscontract Generic implementation of the 'RStudio' connections contract Provides a generic implementation of the 'RStudio'\nconnection contract to make it easier for database connections,\nand other type of connections, opened via R packages integrate\nwith the connections pane inside the 'RStudio' interactive\ndevelopment environment (IDE). as_rscontract rscontract_close rscontract_ide rscontract_open rscontract_spec rscontract_update sample_catalog connections-pane rstudio"
  },
  {
    "id": 1004,
    "package_name": "porcelain",
    "title": "Turn a Package into an HTTP API",
    "description": "Wrapper around the plumber package to turn a package into\nan HTTP API. This adds some conventions that we find useful,\nsuch as some testing infrastructure and automatic validation of\nresponses against a json schema.",
    "version": "0.1.16",
    "maintainer": "Rich FitzJohn <rich.fitzjohn@gmail.com>",
    "author": "Rich FitzJohn [aut, cre],\nImperial College of Science, Technology and Medicine [cph]",
    "url": "https://github.com/reside-ic/porcelain",
    "bug_reports": "https://github.com/reside-ic/porcelain/issues",
    "repository": "",
    "exports": [
      [
        "porcelain"
      ],
      [
        "porcelain_add_headers"
      ],
      [
        "porcelain_background"
      ],
      [
        "porcelain_endpoint"
      ],
      [
        "porcelain_input_body_binary"
      ],
      [
        "porcelain_input_body_json"
      ],
      [
        "porcelain_input_query"
      ],
      [
        "porcelain_logger"
      ],
      [
        "porcelain_package_endpoint"
      ],
      [
        "porcelain_returning"
      ],
      [
        "porcelain_returning_binary"
      ],
      [
        "porcelain_returning_json"
      ],
      [
        "porcelain_returning_text"
      ],
      [
        "porcelain_roclet"
      ],
      [
        "porcelain_state"
      ],
      [
        "porcelain_stop"
      ]
    ],
    "topics": [],
    "score": 4.5563,
    "stars": 4,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "porcelain Turn a Package into an HTTP API Wrapper around the plumber package to turn a package into\nan HTTP API. This adds some conventions that we find useful,\nsuch as some testing infrastructure and automatic validation of\nresponses against a json schema. porcelain porcelain_add_headers porcelain_background porcelain_endpoint porcelain_input_body_binary porcelain_input_body_json porcelain_input_query porcelain_logger porcelain_package_endpoint porcelain_returning porcelain_returning_binary porcelain_returning_json porcelain_returning_text porcelain_roclet porcelain_state porcelain_stop "
  },
  {
    "id": 1278,
    "package_name": "stops",
    "title": "Structure Optimized Proximity Scaling",
    "description": "Methods that use flexible variants of multidimensional\nscaling (MDS) which incorporate parametric nonlinear distance\ntransformations and trade-off the goodness-of-fit fit with\nstructure considerations to find optimal hyperparameters, also\nknown as structure optimized proximity scaling (STOPS) (Rusch,\nMair & Hornik, 2023,<doi:10.1007/s11222-022-10197-w>). The\npackage contains various functions, wrappers, methods and\nclasses for fitting, plotting and displaying different 1-way\nMDS models with ratio, interval, ordinal optimal scaling in a\nSTOPS framework. These cover essentially the functionality of\nthe package smacofx, including Torgerson (classical) scaling\nwith power transformations of dissimilarities, SMACOF MDS with\npowers of dissimilarities, Sammon mapping with powers of\ndissimilarities, elastic scaling with powers of\ndissimilarities, spherical SMACOF with powers of\ndissimilarities, (ALSCAL) s-stress MDS with powers of\ndissimilarities, r-stress MDS, MDS with powers of\ndissimilarities and configuration distances, elastic scaling\npowers of dissimilarities and configuration distances, Sammon\nmapping powers of dissimilarities and configuration distances,\npower stress MDS (POST-MDS), approximate power stress, Box-Cox\nMDS, local MDS, Isomap, curvilinear component analysis (CLCA),\ncurvilinear distance analysis (CLDA) and sparsified (power)\nmultidimensional scaling and (power) multidimensional distance\nanalysis (experimental models from smacofx influenced by CLCA).\nAll of these models can also be fit by optimizing over\nhyperparameters based on goodness-of-fit fit only (i.e., no\nstructure considerations). The package further contains\nfunctions for optimization, specifically the adaptive\nLuus-Jaakola algorithm and a wrapper for Bayesian optimization\nwith treed Gaussian process with jumps to linear models, and\nfunctions for various c-structuredness indices. Hyperparameter\noptimization can be done with a number of techniques but we\nrecommend either Bayesian optimization or particle swarm. For\nusing \"Kriging\", users need to install a version of the\narchived 'DiceOptim' R package.",
    "version": "1.10-1",
    "maintainer": "Thomas Rusch <thomas.rusch@wu.ac.at>",
    "author": "Thomas Rusch [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-7773-2096>),\nPatrick Mair [aut] (ORCID: <https://orcid.org/0000-0003-0100-6511>),\nKurt Hornik [ctb] (ORCID: <https://orcid.org/0000-0003-4198-9911>)",
    "url": "https://r-forge.r-project.org/projects/stops/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "c_association"
      ],
      [
        "c_clumpiness"
      ],
      [
        "c_clusteredness"
      ],
      [
        "c_complexity"
      ],
      [
        "c_convexity"
      ],
      [
        "c_dependence"
      ],
      [
        "c_faithfulness"
      ],
      [
        "c_functionality"
      ],
      [
        "c_hierarchy"
      ],
      [
        "c_inequality"
      ],
      [
        "c_linearity"
      ],
      [
        "c_manifoldness"
      ],
      [
        "c_nonmonotonicity"
      ],
      [
        "c_outlying"
      ],
      [
        "c_regularity"
      ],
      [
        "c_shepardness"
      ],
      [
        "c_skinniness"
      ],
      [
        "c_sparsity"
      ],
      [
        "c_striatedness"
      ],
      [
        "c_stringiness"
      ],
      [
        "ljoptim"
      ],
      [
        "stop_bcmds"
      ],
      [
        "stop_clca"
      ],
      [
        "stop_cldae"
      ],
      [
        "stop_cldak"
      ],
      [
        "stop_elastic"
      ],
      [
        "stop_isomap1"
      ],
      [
        "stop_isomap2"
      ],
      [
        "stop_lmds"
      ],
      [
        "stop_powerelastic"
      ],
      [
        "stop_powermds"
      ],
      [
        "stop_powersammon"
      ],
      [
        "stop_powerstress"
      ],
      [
        "stop_rstress"
      ],
      [
        "stop_sammon"
      ],
      [
        "stop_sammon2"
      ],
      [
        "stop_smacofSphere"
      ],
      [
        "stop_smacofSym"
      ],
      [
        "stop_smddae"
      ],
      [
        "stop_smddak"
      ],
      [
        "stop_smds"
      ],
      [
        "stop_spmddae"
      ],
      [
        "stop_spmddak"
      ],
      [
        "stop_spmds"
      ],
      [
        "stop_sstress"
      ],
      [
        "stoploss"
      ],
      [
        "stops"
      ],
      [
        "tgpoptim"
      ]
    ],
    "topics": [
      [
        "openjdk"
      ]
    ],
    "score": 4.4886,
    "stars": 1,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "stops Structure Optimized Proximity Scaling Methods that use flexible variants of multidimensional\nscaling (MDS) which incorporate parametric nonlinear distance\ntransformations and trade-off the goodness-of-fit fit with\nstructure considerations to find optimal hyperparameters, also\nknown as structure optimized proximity scaling (STOPS) (Rusch,\nMair & Hornik, 2023,<doi:10.1007/s11222-022-10197-w>). The\npackage contains various functions, wrappers, methods and\nclasses for fitting, plotting and displaying different 1-way\nMDS models with ratio, interval, ordinal optimal scaling in a\nSTOPS framework. These cover essentially the functionality of\nthe package smacofx, including Torgerson (classical) scaling\nwith power transformations of dissimilarities, SMACOF MDS with\npowers of dissimilarities, Sammon mapping with powers of\ndissimilarities, elastic scaling with powers of\ndissimilarities, spherical SMACOF with powers of\ndissimilarities, (ALSCAL) s-stress MDS with powers of\ndissimilarities, r-stress MDS, MDS with powers of\ndissimilarities and configuration distances, elastic scaling\npowers of dissimilarities and configuration distances, Sammon\nmapping powers of dissimilarities and configuration distances,\npower stress MDS (POST-MDS), approximate power stress, Box-Cox\nMDS, local MDS, Isomap, curvilinear component analysis (CLCA),\ncurvilinear distance analysis (CLDA) and sparsified (power)\nmultidimensional scaling and (power) multidimensional distance\nanalysis (experimental models from smacofx influenced by CLCA).\nAll of these models can also be fit by optimizing over\nhyperparameters based on goodness-of-fit fit only (i.e., no\nstructure considerations). The package further contains\nfunctions for optimization, specifically the adaptive\nLuus-Jaakola algorithm and a wrapper for Bayesian optimization\nwith treed Gaussian process with jumps to linear models, and\nfunctions for various c-structuredness indices. Hyperparameter\noptimization can be done with a number of techniques but we\nrecommend either Bayesian optimization or particle swarm. For\nusing \"Kriging\", users need to install a version of the\narchived 'DiceOptim' R package. c_association c_clumpiness c_clusteredness c_complexity c_convexity c_dependence c_faithfulness c_functionality c_hierarchy c_inequality c_linearity c_manifoldness c_nonmonotonicity c_outlying c_regularity c_shepardness c_skinniness c_sparsity c_striatedness c_stringiness ljoptim stop_bcmds stop_clca stop_cldae stop_cldak stop_elastic stop_isomap1 stop_isomap2 stop_lmds stop_powerelastic stop_powermds stop_powersammon stop_powerstress stop_rstress stop_sammon stop_sammon2 stop_smacofSphere stop_smacofSym stop_smddae stop_smddak stop_smds stop_spmddae stop_spmddak stop_spmds stop_sstress stoploss stops tgpoptim openjdk"
  },
  {
    "id": 488,
    "package_name": "docthis",
    "title": "RStudio Addin to Ease Writing Documentation",
    "description": "An RStudio addin that builds the skeleton of documentation\nfor an R function or dataframe using the roxygen2 syntax.",
    "version": "0.1.1",
    "maintainer": "Matthew Lincoln <matthew.d.lincoln@gmail.com>",
    "author": "Matthew Lincoln [aut, cre]",
    "url": "https://github.com/mdlincoln/docthis",
    "bug_reports": "https://github.com/mdlincoln/docthis/issues",
    "repository": "",
    "exports": [
      [
        "doc_this"
      ],
      [
        "doc_this_addin"
      ]
    ],
    "topics": [],
    "score": 4.2402,
    "stars": 61,
    "primary_category": "visualization",
    "source_universe": "rstudio",
    "search_text": "docthis RStudio Addin to Ease Writing Documentation An RStudio addin that builds the skeleton of documentation\nfor an R function or dataframe using the roxygen2 syntax. doc_this doc_this_addin "
  },
  {
    "id": 479,
    "package_name": "distrDoc",
    "title": "Documentation for 'distr' Family of R Packages",
    "description": "Provides documentation in form of a common vignette to\npackages 'distr', 'distrEx', 'distrMod', 'distrSim',\n'distrTEst', 'distrTeach', and 'distrEllipse'.",
    "version": "2.8.5",
    "maintainer": "Peter Ruckdeschel <peter.ruckdeschel@uni-oldenburg.de>",
    "author": "Florian Camphausen [ctb] (contributed as student to the documented\npackages in the initial phase --2005),\nMatthias Kohl [aut, cph],\nPeter Ruckdeschel [cre, cph],\nThomas Stabla [ctb] (contributed as student to the documented packages\nin the initial phase --2005)",
    "url": "http://distr.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 3.9031,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "distrDoc Documentation for 'distr' Family of R Packages Provides documentation in form of a common vignette to\npackages 'distr', 'distrEx', 'distrMod', 'distrSim',\n'distrTEst', 'distrTeach', and 'distrEllipse'.  "
  },
  {
    "id": 1003,
    "package_name": "popler",
    "title": "Popler R Package",
    "description": "Browse and query the popler database.",
    "version": "0.2.0",
    "maintainer": "Compagnoni Aldo <aldo.compagnoni@aggiemail.usu.edu>",
    "author": "Compagnoni Aldo [cre, aut],\nBibian Andrew [aut],\nOchocki Brad [aut],\nLevin Sam [aut],\nMiller Tom [aut],\nBenjamin Bond-Lamberty [rev] (Ben reviewed the package for ropensci,\nsee <https://github.com/ropensci/software-review/issues/254>),\nCorinna Gries [rev] (Corinna reviewed the package for ropensci, see\n<https://github.com/ropensci/software-review/issues/254>)",
    "url": "https://github.com/ropensci/popler,\nhttps://docs.ropensci.org/popler/",
    "bug_reports": "https://github.com/ropensci/popler/issues",
    "repository": "",
    "exports": [
      [
        "filter"
      ],
      [
        "mutate"
      ],
      [
        "pplr_browse"
      ],
      [
        "pplr_citation"
      ],
      [
        "pplr_cov_unpack"
      ],
      [
        "pplr_dictionary"
      ],
      [
        "pplr_get_data"
      ],
      [
        "pplr_maps"
      ],
      [
        "pplr_metadata_url"
      ],
      [
        "pplr_report_dictionary"
      ],
      [
        "pplr_report_metadata"
      ],
      [
        "pplr_search"
      ],
      [
        "pplr_site_rep"
      ],
      [
        "pplr_site_rep_plot"
      ],
      [
        "pplr_summary"
      ],
      [
        "pplr_summary_table_update"
      ]
    ],
    "topics": [],
    "score": 3.8274,
    "stars": 7,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "popler Popler R Package Browse and query the popler database. filter mutate pplr_browse pplr_citation pplr_cov_unpack pplr_dictionary pplr_get_data pplr_maps pplr_metadata_url pplr_report_dictionary pplr_report_metadata pplr_search pplr_site_rep pplr_site_rep_plot pplr_summary pplr_summary_table_update "
  },
  {
    "id": 868,
    "package_name": "naomi.resources",
    "title": "Data dependencies for Naomi output generation",
    "description": "Makes data for Naomi output generation as an R package.",
    "version": "0.0.8",
    "maintainer": "Rachel Esra <REsra@avenirhealth.org>",
    "author": "Rachel Esra [aut, cre]",
    "url": "https://github.com/mrc-ide/naomi.resources",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "get_resources_info"
      ],
      [
        "get_shipp_workbook_path"
      ],
      [
        "load_shipp_exdata"
      ]
    ],
    "topics": [],
    "score": 3.7782,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "naomi.resources Data dependencies for Naomi output generation Makes data for Naomi output generation as an R package. get_resources_info get_shipp_workbook_path load_shipp_exdata "
  },
  {
    "id": 402,
    "package_name": "copulaData",
    "title": "Data Sets for Copula Modeling",
    "description": "Data sets used for copula modeling in addition to those in\nthe R package 'copula'.  These include a random subsample from\nthe US National Education Longitudinal Study (NELS) of 1988 and\nnursing home data from Wisconsin.",
    "version": "0.0-2",
    "maintainer": "Marius Hofert <mhofert@hku.hk>",
    "author": "Marius Hofert [aut, cre],\nIvan Kojadinovic [aut],\nMartin Maechler [aut],\nJun Yan [aut],\nEdward W. Frees [dtc] (NELS and nursingHomes)",
    "url": "https://copula.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 3.3222,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "copulaData Data Sets for Copula Modeling Data sets used for copula modeling in addition to those in\nthe R package 'copula'.  These include a random subsample from\nthe US National Education Longitudinal Study (NELS) of 1988 and\nnursing home data from Wisconsin.  "
  },
  {
    "id": 170,
    "package_name": "RobAStRDA",
    "title": "Interpolation Grids for Packages of the 'RobASt' - Family of\nPackages",
    "description": "Includes 'sysdata.rda' file for packages of the 'RobASt' -\nfamily of packages; is currently used by package 'RobExtremes'\nonly.",
    "version": "1.2.1",
    "maintainer": "Peter Ruckdeschel <peter.ruckdeschel@uni-oldenburg.de>",
    "author": "Matthias Kohl [aut, cph],\nBernhard Spangl [ctb] (contributed smoothed grid values of the Lagrange\nmultipliers),\nSascha Desmettre [ctb] (contributed smoothed grid values of the\nLagrange multipliers),\nEugen Massini [ctb] (contributed an interactive smoothing routine for\nsmoothing the Lagrange multipliers and smoothed grid values of the\nLagrange multipliers),\nMykhailo Pupashenko [ctb] (helped with manual smoothing of the\ninterpolators),\nDaria Pupashenko [ctb] (helped with manual smoothing of the\ninterpolators),\nGerald Kroisandt [ctb] (helped with manual smoothing of the\ninterpolators),\nPeter Ruckdeschel [cre, cph, aut]",
    "url": "https://r-forge.r-project.org/projects/robast/",
    "bug_reports": "",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 3.2553,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "RobAStRDA Interpolation Grids for Packages of the 'RobASt' - Family of\nPackages Includes 'sysdata.rda' file for packages of the 'RobASt' -\nfamily of packages; is currently used by package 'RobExtremes'\nonly.  "
  },
  {
    "id": 1047,
    "package_name": "r2readthedocs",
    "title": "Convert R Package Documentation to a 'readthedocs' Website",
    "description": "Convert R package documentation to a 'readthedocs'\nwebsite.",
    "version": "0.1.0.002",
    "maintainer": "Mark Padgham <mark.padgham@email.com>",
    "author": "Mark Padgham [aut, cre]",
    "url": "https://github.com/ropenscilabs/r2readthedocs",
    "bug_reports": "https://github.com/ropenscilabs/r2readthedocs/issues",
    "repository": "",
    "exports": [
      [
        "r2readthedocs"
      ],
      [
        "rtd_build"
      ],
      [
        "rtd_clean"
      ],
      [
        "rtd_dummy_pkg"
      ],
      [
        "rtd_open"
      ]
    ],
    "topics": [],
    "score": 2.9031,
    "stars": 16,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "r2readthedocs Convert R Package Documentation to a 'readthedocs' Website Convert R package documentation to a 'readthedocs'\nwebsite. r2readthedocs rtd_build rtd_clean rtd_dummy_pkg rtd_open "
  },
  {
    "id": 1319,
    "package_name": "testthat.buildkite",
    "title": "A testthat reporter for buildkite",
    "description": "A testthat reporter that prints progress output in a\nformat for use in buildkite logs.",
    "version": "0.0.1",
    "maintainer": "Robert Ashton <r.ashton@imperial.ac.uk>",
    "author": "Robert Ashton [aut, cre],\nImperial College of Science, Technology and Medicine [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "BuildkiteReporter"
      ]
    ],
    "topics": [],
    "score": 2.5441,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "testthat.buildkite A testthat reporter for buildkite A testthat reporter that prints progress output in a\nformat for use in buildkite logs. BuildkiteReporter "
  },
  {
    "id": 720,
    "package_name": "jameelinst.rpkg.theme",
    "title": "A 'pkgdown' Template for Jameel Institute Packages",
    "description": "Package website colours and logos taken from the Imperial\nCollege London and Jameel Institute brand guidelines.",
    "version": "0.0.0.9000",
    "maintainer": "Pratik Gupte <p.gupte24@imperial.ac.uk>",
    "author": "Pratik Gupte [aut, cre] (ORCID:\n<https://orcid.org/0000-0001-5294-7819>),\nAbdul Latif Jameel Institute for Disease and Emergency Analytics [cph,\nfnd],\nImperial College of Science, Technology and Medicine [cph, fnd]",
    "url": "https://github.com/j-idea/jameel-institute/jameelinst.rpkg.theme,\nhttps://jameel-institute.github.io/jameelinst.rpkg.theme",
    "bug_reports": "",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 1.699,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "jameel-institute",
    "search_text": "jameelinst.rpkg.theme A 'pkgdown' Template for Jameel Institute Packages Package website colours and logos taken from the Imperial\nCollege London and Jameel Institute brand guidelines.  "
  },
  {
    "id": 5,
    "package_name": "BH",
    "title": "Boost C++ Header Files",
    "description": "Boost provides free peer-reviewed portable C++ source \n libraries.  A large part of Boost is provided as C++ template code\n which is resolved entirely at compile-time without linking.  This \n package aims to provide the most useful subset of Boost libraries \n for template use among CRAN packages. By placing these libraries in \n this package, we offer a more efficient distribution system for CRAN \n as replication of this code in the sources of other packages is \n avoided. As of release 1.84.0-0, the following Boost libraries are\n included: 'accumulators' 'algorithm' 'align' 'any' 'atomic' 'beast'\n 'bimap' 'bind' 'circular_buffer' 'compute' 'concept' 'config'\n 'container' 'date_time' 'detail' 'dynamic_bitset' 'exception'\n 'flyweight' 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap'\n 'icl' 'integer' 'interprocess' 'intrusive' 'io' 'iostreams'\n 'iterator' 'lambda2' 'math' 'move' 'mp11' 'mpl' 'multiprecision'\n 'numeric' 'pending' 'phoenix' 'polygon' 'preprocessor' 'process'\n 'propery_tree' 'qvm' 'random' 'range' 'scope_exit' 'smart_ptr' 'sort'\n 'spirit' 'tuple' 'type_traits' 'typeof' 'unordered' 'url' 'utility'\n 'uuid'.",
    "version": "1.90.0-1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  John W. Emerson [aut],\n  Michael J. Kane [aut] (ORCID: <https://orcid.org/0000-0003-1899-6662>)",
    "url": "https://github.com/eddelbuettel/bh,\nhttps://dirk.eddelbuettel.com/code/bh.html",
    "bug_reports": "https://github.com/eddelbuettel/bh/issues",
    "repository": "https://cran.r-project.org/package=BH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BH Boost C++ Header Files Boost provides free peer-reviewed portable C++ source \n libraries.  A large part of Boost is provided as C++ template code\n which is resolved entirely at compile-time without linking.  This \n package aims to provide the most useful subset of Boost libraries \n for template use among CRAN packages. By placing these libraries in \n this package, we offer a more efficient distribution system for CRAN \n as replication of this code in the sources of other packages is \n avoided. As of release 1.84.0-0, the following Boost libraries are\n included: 'accumulators' 'algorithm' 'align' 'any' 'atomic' 'beast'\n 'bimap' 'bind' 'circular_buffer' 'compute' 'concept' 'config'\n 'container' 'date_time' 'detail' 'dynamic_bitset' 'exception'\n 'flyweight' 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap'\n 'icl' 'integer' 'interprocess' 'intrusive' 'io' 'iostreams'\n 'iterator' 'lambda2' 'math' 'move' 'mp11' 'mpl' 'multiprecision'\n 'numeric' 'pending' 'phoenix' 'polygon' 'preprocessor' 'process'\n 'propery_tree' 'qvm' 'random' 'range' 'scope_exit' 'smart_ptr' 'sort'\n 'spirit' 'tuple' 'type_traits' 'typeof' 'unordered' 'url' 'utility'\n 'uuid'.  "
  },
  {
    "id": 28,
    "package_name": "CrossCarry",
    "title": "Analysis of Data from a Crossover Design with GEE",
    "description": "Analyze data from a crossover design using generalized estimation equations (GEE), including carryover effects and various correlation structures based on the Kronecker product. It contains functions for semiparametric estimates of carry-over effects in repeated measures and allows estimation of complex carry-over effects. Related work includes: a) Cruz N.A., Melo O.O., Martinez C.A. (2023). \"CrossCarry: An R package for the analysis of data from a crossover design with GEE\". <doi:10.48550/arXiv.2304.02440>. b)  Cruz N.A., Melo O.O., Martinez C.A. (2023). \"A correlation structure for the analysis of Gaussian and non-Gaussian responses in crossover experimental designs with repeated measures\". <doi:10.1007/s00362-022-01391-z> and c) Cruz N.A., Melo O.O., Martinez C.A. (2023). \"Semiparametric generalized estimating equations for repeated measurements in cross-over designs\". <doi:10.1177/09622802231158736>.",
    "version": "1.2.0",
    "maintainer": "Nelson Alirio Cruz Gutierrez <nelson-alirio.cruz@uib.es>",
    "author": "Nelson Alirio Cruz Gutierrez [aut, cre, cph],\n  Oscar Orlando Melo [aut],\n  Carlos Alberto Martinez [aut],\n  Ricardo Alberich Marti [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CrossCarry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CrossCarry Analysis of Data from a Crossover Design with GEE Analyze data from a crossover design using generalized estimation equations (GEE), including carryover effects and various correlation structures based on the Kronecker product. It contains functions for semiparametric estimates of carry-over effects in repeated measures and allows estimation of complex carry-over effects. Related work includes: a) Cruz N.A., Melo O.O., Martinez C.A. (2023). \"CrossCarry: An R package for the analysis of data from a crossover design with GEE\". <doi:10.48550/arXiv.2304.02440>. b)  Cruz N.A., Melo O.O., Martinez C.A. (2023). \"A correlation structure for the analysis of Gaussian and non-Gaussian responses in crossover experimental designs with repeated measures\". <doi:10.1007/s00362-022-01391-z> and c) Cruz N.A., Melo O.O., Martinez C.A. (2023). \"Semiparametric generalized estimating equations for repeated measurements in cross-over designs\". <doi:10.1177/09622802231158736>.  "
  },
  {
    "id": 52,
    "package_name": "FAfA",
    "title": "Factor Analysis for All",
    "description": "Provides a comprehensive Shiny-based graphical user interface\n    for conducting a wide range of factor analysis procedures. 'FAfA'\n    (Factor Analysis for All) guides users through data uploading,\n    assumption checking (descriptives, collinearity, multivariate\n    normality, outliers), data wrangling (variable exclusion, data\n    splitting), factor retention analysis (e.g., Parallel Analysis, Hull\n    method, EGA), Exploratory Factor Analysis (EFA) with various rotation\n    and extraction methods, Confirmatory Factor Analysis (CFA) for model\n    testing, Reliability Analysis (e.g., Cronbach's Alpha, McDonald's\n    Omega), Measurement Invariance testing across groups, and item\n    weighting techniques. The application leverages established R packages\n    such as 'lavaan' and 'psych' to perform these analyses, offering an\n    accessible platform for researchers and students. Results are\n    presented in user-friendly tables and plots, with options for\n    downloading outputs.",
    "version": "0.5",
    "maintainer": "Abdullah Faruk KILIC <afarukkilic@trakya.edu.tr>",
    "author": "Abdullah Faruk KILIC [aut, cre],\n  Ahmet Caliskan [aut]",
    "url": "https://github.com/AFarukKILIC/FAfA",
    "bug_reports": "https://github.com/AFarukKILIC/FAfA/issues",
    "repository": "https://cran.r-project.org/package=FAfA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FAfA Factor Analysis for All Provides a comprehensive Shiny-based graphical user interface\n    for conducting a wide range of factor analysis procedures. 'FAfA'\n    (Factor Analysis for All) guides users through data uploading,\n    assumption checking (descriptives, collinearity, multivariate\n    normality, outliers), data wrangling (variable exclusion, data\n    splitting), factor retention analysis (e.g., Parallel Analysis, Hull\n    method, EGA), Exploratory Factor Analysis (EFA) with various rotation\n    and extraction methods, Confirmatory Factor Analysis (CFA) for model\n    testing, Reliability Analysis (e.g., Cronbach's Alpha, McDonald's\n    Omega), Measurement Invariance testing across groups, and item\n    weighting techniques. The application leverages established R packages\n    such as 'lavaan' and 'psych' to perform these analyses, offering an\n    accessible platform for researchers and students. Results are\n    presented in user-friendly tables and plots, with options for\n    downloading outputs.  "
  },
  {
    "id": 161,
    "package_name": "RcppArmadillo",
    "title": "'Rcpp' Integration for the 'Armadillo' Templated Linear Algebra\nLibrary",
    "description": "'Armadillo' is a templated C++ linear algebra library aiming towards\n a good balance between speed and ease of use. It provides high-level syntax and\n functionality deliberately similar to Matlab. It is useful for algorithm development\n directly in C++, or quick conversion of research code into production environments.\n It provides efficient classes for vectors, matrices and cubes where dense and sparse\n matrices are supported. Integer, floating point and complex numbers are supported.\n A sophisticated expression evaluator (based on template meta-programming) automatically\n combines several operations to increase speed and efficiency. Dynamic evaluation\n automatically chooses optimal code paths based on detected matrix structures.\n Matrix decompositions are provided through integration with LAPACK, or one of its\n high performance drop-in replacements (such as 'MKL' or 'OpenBLAS'). It can\n automatically use 'OpenMP' multi-threading (parallelisation) to speed up\n computationally expensive operations.\n\n   The 'RcppArmadillo' package includes the header files from the 'Armadillo' library;\n users do not need to install 'Armadillo' itself in order to use 'RcppArmadillo'.\n Starting from release 15.0.0, the minimum compilation standard is C++14 so 'Armadillo'\n version 14.6.3 is included as a fallback when an R package forces the C++11 standard.\n Package authors should set a '#define' to select the 'current' version, or select the\n 'legacy' version (also chosen as default) if they must. See 'GitHub issue #475' for\n details.\n\n   Since release 7.800.0, 'Armadillo' is licensed under Apache License 2; previous\n releases were under licensed as MPL 2.0 from version 3.800.0 onwards and LGPL-3\n prior to that; 'RcppArmadillo' (the 'Rcpp' bindings/bridge to Armadillo) is licensed\n under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",
    "version": "15.2.3-1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Romain Francois [aut] (ORCID: <https://orcid.org/0000-0002-2444-4226>),\n  Doug Bates [aut] (ORCID: <https://orcid.org/0000-0001-8316-9503>),\n  Binxiang Ni [aut],\n  Conrad Sanderson [aut] (ORCID: <https://orcid.org/0000-0002-0049-4501>)",
    "url": "https://github.com/RcppCore/RcppArmadillo,\nhttps://dirk.eddelbuettel.com/code/rcpp.armadillo.html",
    "bug_reports": "https://github.com/RcppCore/RcppArmadillo/issues",
    "repository": "https://cran.r-project.org/package=RcppArmadillo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppArmadillo 'Rcpp' Integration for the 'Armadillo' Templated Linear Algebra\nLibrary 'Armadillo' is a templated C++ linear algebra library aiming towards\n a good balance between speed and ease of use. It provides high-level syntax and\n functionality deliberately similar to Matlab. It is useful for algorithm development\n directly in C++, or quick conversion of research code into production environments.\n It provides efficient classes for vectors, matrices and cubes where dense and sparse\n matrices are supported. Integer, floating point and complex numbers are supported.\n A sophisticated expression evaluator (based on template meta-programming) automatically\n combines several operations to increase speed and efficiency. Dynamic evaluation\n automatically chooses optimal code paths based on detected matrix structures.\n Matrix decompositions are provided through integration with LAPACK, or one of its\n high performance drop-in replacements (such as 'MKL' or 'OpenBLAS'). It can\n automatically use 'OpenMP' multi-threading (parallelisation) to speed up\n computationally expensive operations.\n\n   The 'RcppArmadillo' package includes the header files from the 'Armadillo' library;\n users do not need to install 'Armadillo' itself in order to use 'RcppArmadillo'.\n Starting from release 15.0.0, the minimum compilation standard is C++14 so 'Armadillo'\n version 14.6.3 is included as a fallback when an R package forces the C++11 standard.\n Package authors should set a '#define' to select the 'current' version, or select the\n 'legacy' version (also chosen as default) if they must. See 'GitHub issue #475' for\n details.\n\n   Since release 7.800.0, 'Armadillo' is licensed under Apache License 2; previous\n releases were under licensed as MPL 2.0 from version 3.800.0 onwards and LGPL-3\n prior to that; 'RcppArmadillo' (the 'Rcpp' bindings/bridge to Armadillo) is licensed\n under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.  "
  },
  {
    "id": 182,
    "package_name": "SEMdeep",
    "title": "Structural Equation Modeling with Deep Neural Network and\nMachine Learning Algorithms",
    "description": "Training and validation of a custom (or data-driven) Structural\n    Equation Models using Deep Neural Networks or Machine Learning algorithms, which\n\textend the fitting procedures of the 'SEMgraph' R package <doi:10.32614/CRAN.package.SEMgraph>.",
    "version": "1.1.1",
    "maintainer": "Barbara Tarantino <barbara.tarantino01@universitadipavia.it>",
    "author": "Mario Grassi [aut],\n  Barbara Tarantino [cre]",
    "url": "https://github.com/BarbaraTarantino/SEMdeep",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SEMdeep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SEMdeep Structural Equation Modeling with Deep Neural Network and\nMachine Learning Algorithms Training and validation of a custom (or data-driven) Structural\n    Equation Models using Deep Neural Networks or Machine Learning algorithms, which\n\textend the fitting procedures of the 'SEMgraph' R package <doi:10.32614/CRAN.package.SEMgraph>.  "
  },
  {
    "id": 201,
    "package_name": "SuperCell",
    "title": "Simplification of scRNA-Seq Data by Merging Together Similar\nCells",
    "description": "Aggregates large single-cell data into metacell dataset by merging together gene expression of very similar cells. 'SuperCell' uses 'velocyto.R' <doi:10.1038/s41586-018-0414-6> <https://github.com/velocyto-team/velocyto.R> for RNA velocity and 'WeightedCluster' <doi:10.12682/lives.2296-1658.2013.24> <https://mephisto.unige.ch/weightedcluster/> for weighted clustering on metacells. We also recommend installing 'scater' Bioconductor package <doi:10.18129/B9.bioc.scater> <https://bioconductor.org/packages/release/bioc/html/scater.html>.",
    "version": "1.1",
    "maintainer": "Matei Teleman <matei.teleman@unil.ch>",
    "author": "Mariia Bilous [aut],\n  Matei Teleman [cre]",
    "url": "",
    "bug_reports": "https://github.com/GfellerLab/SuperCell/issues",
    "repository": "https://cran.r-project.org/package=SuperCell",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SuperCell Simplification of scRNA-Seq Data by Merging Together Similar\nCells Aggregates large single-cell data into metacell dataset by merging together gene expression of very similar cells. 'SuperCell' uses 'velocyto.R' <doi:10.1038/s41586-018-0414-6> <https://github.com/velocyto-team/velocyto.R> for RNA velocity and 'WeightedCluster' <doi:10.12682/lives.2296-1658.2013.24> <https://mephisto.unige.ch/weightedcluster/> for weighted clustering on metacells. We also recommend installing 'scater' Bioconductor package <doi:10.18129/B9.bioc.scater> <https://bioconductor.org/packages/release/bioc/html/scater.html>.  "
  },
  {
    "id": 230,
    "package_name": "airGR",
    "title": "Suite of GR Hydrological Models for Precipitation-Runoff\nModelling",
    "description": "Hydrological modelling tools developed at INRAE-Antony (HYCAR Research Unit, France). The package includes several conceptual rainfall-runoff models (GR4H, GR5H, GR4J, GR5J, GR6J, GR2M, GR1A) that can be applied either on a lumped or semi-distributed way. A snow accumulation and melt model (CemaNeige) and the associated functions for the calibration and evaluation of models are also included. Use help(airGR) for package description and references.",
    "version": "1.7.8",
    "maintainer": "Olivier Delaigue <airGR@inrae.fr>",
    "author": "Laurent Coron [aut, trl] (ORCID:\n    <https://orcid.org/0000-0002-1503-6204>),\n  Olivier Delaigue [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7668-8468>),\n  Guillaume Thirel [aut, ths] (ORCID:\n    <https://orcid.org/0000-0002-1444-1830>),\n  David Dorchies [aut] (ORCID: <https://orcid.org/0000-0002-6595-7984>),\n  Charles Perrin [aut, ths] (ORCID:\n    <https://orcid.org/0000-0001-8552-1881>),\n  Claude Michel [aut, ths],\n  Vazken Andr\u00e9assian [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0001-7124-9303>),\n  Fran\u00e7ois Bourgin [ctb] (ORCID: <https://orcid.org/0000-0002-2820-7260>),\n  Pierre Brigode [ctb] (ORCID: <https://orcid.org/0000-0001-8257-0741>),\n  Nicolas Le Moine [ctb],\n  Thibaut Mathevet [ctb] (ORCID: <https://orcid.org/0000-0002-4142-4454>),\n  Safouane Mouelhi [ctb],\n  Ludovic Oudin [ctb] (ORCID: <https://orcid.org/0000-0002-3712-0933>),\n  Raji Pushpalatha [ctb],\n  Audrey Val\u00e9ry [ctb]",
    "url": "https://hydrogr.github.io/airGR/",
    "bug_reports": "https://gitlab.irstea.fr/HYCAR-Hydro/airgr/-/issues",
    "repository": "https://cran.r-project.org/package=airGR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "airGR Suite of GR Hydrological Models for Precipitation-Runoff\nModelling Hydrological modelling tools developed at INRAE-Antony (HYCAR Research Unit, France). The package includes several conceptual rainfall-runoff models (GR4H, GR5H, GR4J, GR5J, GR6J, GR2M, GR1A) that can be applied either on a lumped or semi-distributed way. A snow accumulation and melt model (CemaNeige) and the associated functions for the calibration and evaluation of models are also included. Use help(airGR) for package description and references.  "
  },
  {
    "id": 282,
    "package_name": "bbr",
    "title": "R package for bbi",
    "description": "R package for making calls to bbi for running",
    "version": "1.14.3",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/metrumresearchgroup/bbr",
    "bug_reports": "https://github.com/metrumresearchgroup/bbr/issues",
    "repository": "https://github.com/metrumresearchgroup/bbr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 25,
    "primary_category": "pharmacometrics",
    "source_universe": "github:metrumresearchgroup",
    "search_text": "bbr R package for bbi R package for making calls to bbi for running  "
  },
  {
    "id": 283,
    "package_name": "bbr.bayes",
    "title": "Bayesian modeling with BBR",
    "description": "This package extends the BBR package for Bayesian modeling.",
    "version": "0.3.1",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/metrumresearchgroup/bbr.bayes",
    "bug_reports": "https://github.com/metrumresearchgroup/bbr.bayes/issues",
    "repository": "https://github.com/metrumresearchgroup/bbr.bayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 6,
    "primary_category": "pharmacometrics",
    "source_universe": "github:metrumresearchgroup",
    "search_text": "bbr.bayes Bayesian modeling with BBR This package extends the BBR package for Bayesian modeling.  "
  },
  {
    "id": 429,
    "package_name": "csmpv",
    "title": "Biomarker Confirmation, Selection, Modelling, Prediction, and\nValidation",
    "description": "\n   There are diverse purposes such as biomarker confirmation, novel biomarker discovery, constructing predictive models, model-based prediction, and validation. \n   It handles binary, continuous, and time-to-event outcomes at the sample or patient level.\n   - Biomarker confirmation utilizes established functions like glm() from 'stats', coxph() from 'survival', surv_fit(), and ggsurvplot() from 'survminer'.\n   - Biomarker discovery and variable selection are facilitated by three LASSO-related functions LASSO2(), LASSO_plus(), and LASSO2plus(), leveraging the 'glmnet' R package with additional steps.\n   - Eight versatile modeling functions are offered, each designed for predictive models across various outcomes and data types.\n     1) LASSO2(), LASSO_plus(), LASSO2plus(), and LASSO2_reg() perform variable selection using LASSO methods and construct predictive models based on selected variables.\n     2) XGBtraining() employs 'XGBoost' for model building and is the only function not involving variable selection.\n     3) Functions like LASSO2_XGBtraining(), LASSOplus_XGBtraining(), and LASSO2plus_XGBtraining() combine LASSO-related variable selection with 'XGBoost' for model construction.\n   - All models support prediction and validation, requiring a testing dataset comparable to the training dataset.\n   Additionally, the package introduces XGpred() for risk prediction based on survival data, with the XGpred_predict() function available for predicting risk groups in new datasets.\n   The methodology is based on our new algorithms and various references:\n   - Hastie et al. (1992, ISBN 0 534 16765-9), \n   - Therneau et al. (2000, ISBN 0-387-98784-3), \n   - Kassambara et al. (2021) <https://CRAN.R-project.org/package=survminer>,\n   - Friedman et al. (2010) <doi:10.18637/jss.v033.i01>,\n   - Simon et al. (2011) <doi:10.18637/jss.v039.i05>,\n   - Harrell (2023) <https://CRAN.R-project.org/package=rms>,\n   - Harrell (2023) <https://CRAN.R-project.org/package=Hmisc>,\n   - Chen and Guestrin (2016) <doi:10.48550/arXiv.1603.02754>,\n   - Aoki et al. (2023) <doi:10.1200/JCO.23.01115>.",
    "version": "1.0.5",
    "maintainer": "Aixiang Jiang <aijiang@bccrc.ca>",
    "author": "Aixiang Jiang [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-6153-7595>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=csmpv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "csmpv Biomarker Confirmation, Selection, Modelling, Prediction, and\nValidation \n   There are diverse purposes such as biomarker confirmation, novel biomarker discovery, constructing predictive models, model-based prediction, and validation. \n   It handles binary, continuous, and time-to-event outcomes at the sample or patient level.\n   - Biomarker confirmation utilizes established functions like glm() from 'stats', coxph() from 'survival', surv_fit(), and ggsurvplot() from 'survminer'.\n   - Biomarker discovery and variable selection are facilitated by three LASSO-related functions LASSO2(), LASSO_plus(), and LASSO2plus(), leveraging the 'glmnet' R package with additional steps.\n   - Eight versatile modeling functions are offered, each designed for predictive models across various outcomes and data types.\n     1) LASSO2(), LASSO_plus(), LASSO2plus(), and LASSO2_reg() perform variable selection using LASSO methods and construct predictive models based on selected variables.\n     2) XGBtraining() employs 'XGBoost' for model building and is the only function not involving variable selection.\n     3) Functions like LASSO2_XGBtraining(), LASSOplus_XGBtraining(), and LASSO2plus_XGBtraining() combine LASSO-related variable selection with 'XGBoost' for model construction.\n   - All models support prediction and validation, requiring a testing dataset comparable to the training dataset.\n   Additionally, the package introduces XGpred() for risk prediction based on survival data, with the XGpred_predict() function available for predicting risk groups in new datasets.\n   The methodology is based on our new algorithms and various references:\n   - Hastie et al. (1992, ISBN 0 534 16765-9), \n   - Therneau et al. (2000, ISBN 0-387-98784-3), \n   - Kassambara et al. (2021) <https://CRAN.R-project.org/package=survminer>,\n   - Friedman et al. (2010) <doi:10.18637/jss.v033.i01>,\n   - Simon et al. (2011) <doi:10.18637/jss.v039.i05>,\n   - Harrell (2023) <https://CRAN.R-project.org/package=rms>,\n   - Harrell (2023) <https://CRAN.R-project.org/package=Hmisc>,\n   - Chen and Guestrin (2016) <doi:10.48550/arXiv.1603.02754>,\n   - Aoki et al. (2023) <doi:10.1200/JCO.23.01115>.  "
  },
  {
    "id": 559,
    "package_name": "fairness",
    "title": "Algorithmic Fairness Metrics",
    "description": "Offers calculation, visualization and comparison of algorithmic fairness metrics. Fair machine learning is an emerging topic with the overarching aim to critically assess whether ML algorithms reinforce existing social biases. Unfair algorithms can propagate such biases and produce predictions with a disparate impact on various sensitive groups of individuals (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities). Fair algorithms possess the underlying foundation that these groups should be treated similarly or have similar prediction outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) <doi:10.1007/s10618-010-0190-x>, Chouldechova (2017) <doi:10.1089/big.2016.0047>, Feldman et al. (2015) <doi:10.1145/2783258.2783311> , Friedler et al. (2018) <doi:10.1145/3287560.3287589> and Zafar et al. (2017) <doi:10.1145/3038912.3052660>. The package also offers convenient visualizations to help understand fairness metrics.",
    "version": "1.2.3",
    "maintainer": "Nikita Kozodoi <n.kozodoi@icloud.com>",
    "author": "Nikita Kozodoi [aut, cre],\n  Tibor V. Varga [aut] (ORCID: <https://orcid.org/0000-0002-2383-699X>)",
    "url": "https://www.kozodoi.me/blog/algorithmic-fairness-in-r",
    "bug_reports": "https://github.com/kozodoi/fairness/issues",
    "repository": "https://cran.r-project.org/package=fairness",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fairness Algorithmic Fairness Metrics Offers calculation, visualization and comparison of algorithmic fairness metrics. Fair machine learning is an emerging topic with the overarching aim to critically assess whether ML algorithms reinforce existing social biases. Unfair algorithms can propagate such biases and produce predictions with a disparate impact on various sensitive groups of individuals (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities). Fair algorithms possess the underlying foundation that these groups should be treated similarly or have similar prediction outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) <doi:10.1007/s10618-010-0190-x>, Chouldechova (2017) <doi:10.1089/big.2016.0047>, Feldman et al. (2015) <doi:10.1145/2783258.2783311> , Friedler et al. (2018) <doi:10.1145/3287560.3287589> and Zafar et al. (2017) <doi:10.1145/3038912.3052660>. The package also offers convenient visualizations to help understand fairness metrics.  "
  },
  {
    "id": 568,
    "package_name": "fgdiR",
    "title": "Functional Gait Deviation Index",
    "description": "A typical gait analysis requires the examination of the motion of nine joint angles on the left-hand side and six joint angles on the right-hand side across multiple subjects. Due to the quantity and complexity of the data, it is useful to calculate the amount by which a subject\u2019s gait deviates from an average normal profile and to represent this deviation as a single number. Such a measure can quantify the overall severity of a condition affecting walking, monitor progress, or evaluate the outcome of an intervention prescribed to improve the gait pattern. This R package provides tools for computing the Functional Gait Deviation Index, a novel index for quantifying gait pathology using multivariate functional principal component analysis. The package supports analysis at the level of both legs combined, individual legs, and individual joints/planes. It includes functions for functional data preprocessing, multivariate functional principal component decomposition, FGDI computation, and visualisation of gait abnormality scores. Further details can be found in Minhas, S. K., Sangeux, M., Polak, J., & Carey, M. (2025). The Functional Gait Deviation Index. Journal of Applied Statistics <doi:10.1080/02664763.2025.2514150>.",
    "version": "0.1.0",
    "maintainer": "Michelle Carey <michelle.carey@ucd.ie>",
    "author": "Michelle Carey [aut, cre],\n  Sajal Kaur Minhas [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fgdiR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fgdiR Functional Gait Deviation Index A typical gait analysis requires the examination of the motion of nine joint angles on the left-hand side and six joint angles on the right-hand side across multiple subjects. Due to the quantity and complexity of the data, it is useful to calculate the amount by which a subject\u2019s gait deviates from an average normal profile and to represent this deviation as a single number. Such a measure can quantify the overall severity of a condition affecting walking, monitor progress, or evaluate the outcome of an intervention prescribed to improve the gait pattern. This R package provides tools for computing the Functional Gait Deviation Index, a novel index for quantifying gait pathology using multivariate functional principal component analysis. The package supports analysis at the level of both legs combined, individual legs, and individual joints/planes. It includes functions for functional data preprocessing, multivariate functional principal component decomposition, FGDI computation, and visualisation of gait abnormality scores. Further details can be found in Minhas, S. K., Sangeux, M., Polak, J., & Carey, M. (2025). The Functional Gait Deviation Index. Journal of Applied Statistics <doi:10.1080/02664763.2025.2514150>.  "
  },
  {
    "id": 588,
    "package_name": "forecastTools",
    "title": "Evaluation of time-series forecasts",
    "description": "An R package with tools for managing, evaluating forecasts of time-series",
    "version": "0.0.1",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/reichlab/forecastTools",
    "bug_reports": "https://github.com/reichlab/forecastTools/issues",
    "repository": "https://github.com/reichlab/forecastTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "github:reichlab",
    "search_text": "forecastTools Evaluation of time-series forecasts An R package with tools for managing, evaluating forecasts of time-series  "
  },
  {
    "id": 602,
    "package_name": "geeLite",
    "title": "Building and Managing Local Databases from 'Google Earth Engine'",
    "description": "Simplifies the creation, management, and updating of local databases using data extracted from 'Google Earth Engine' ('GEE'). It integrates with 'GEE' to store, aggregate, and process spatio-temporal data, leveraging 'SQLite' for efficient, serverless storage. The 'geeLite' package provides utilities for data transformation and supports real-time monitoring and analysis of geospatial features, making it suitable for researchers and practitioners in geospatial science. For details, see Kurbucz and Andr\u00e9e (2025) \"Building and Managing Local Databases from Google Earth Engine with the geeLite R Package\" <https://hdl.handle.net/10986/43165>.",
    "version": "1.0.6",
    "maintainer": "Marcell T. Kurbucz <m.kurbucz@ucl.ac.uk>",
    "author": "Marcell T. Kurbucz [aut, cre],\n  Bo Pieter Johannes Andr\u00e9e [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geeLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geeLite Building and Managing Local Databases from 'Google Earth Engine' Simplifies the creation, management, and updating of local databases using data extracted from 'Google Earth Engine' ('GEE'). It integrates with 'GEE' to store, aggregate, and process spatio-temporal data, leveraging 'SQLite' for efficient, serverless storage. The 'geeLite' package provides utilities for data transformation and supports real-time monitoring and analysis of geospatial features, making it suitable for researchers and practitioners in geospatial science. For details, see Kurbucz and Andr\u00e9e (2025) \"Building and Managing Local Databases from Google Earth Engine with the geeLite R Package\" <https://hdl.handle.net/10986/43165>.  "
  },
  {
    "id": 643,
    "package_name": "glmnetr",
    "title": "Nested Cross Validation for the Relaxed Lasso and Other Machine\nLearning Models",
    "description": "\n    Cross validation informed Relaxed LASSO (or more generally elastic net), gradient boosting machine ('xgboost'), Random Forest ('RandomForestSRC'), Oblique Random Forest ('aorsf'), Artificial Neural Network (ANN), Recursive Partitioning ('RPART') or step wise regression models are fit.  Cross validation leave out samples (leading to nested cross validation) or bootstrap out-of-bag samples are used to evaluate and compare performances between these models with results presented in tabular or graphical means.  Calibration plots can also be generated, again based upon (outer nested) cross validation or bootstrap leave out (out of bag) samples.\n    Note, at the time of this writing, in order to fit gradient boosting machine models one must install the packages 'DiceKriging' and 'rgenoud' using the install.packages() function. \n    For some datasets, for example when the design matrix is not of full rank, 'glmnet' may have very long run times when fitting the relaxed lasso model, from our experience when fitting Cox models on data with many predictors and many patients, making it difficult to get solutions from either glmnet() or cv.glmnet().  This may be remedied by using the 'path=TRUE' option when calling glmnet() and cv.glmnet().  Within the 'glmnetr' package the approach of path=TRUE is taken by default. \n    other packages doing similar include 'nestedcv' <https://cran.r-project.org/package=nestedcv>, 'glmnetSE' <https://cran.r-project.org/package=glmnetSE> which may provide different functionality when performing a nested CV. \n    Use of the 'glmnetr' has many similarities to the 'glmnet' package and it could be helpful for the user of 'glmnetr' also become familiar with the 'glmnet' package <https://cran.r-project.org/package=glmnet>, with the \"An Introduction to 'glmnet'\" and \"The Relaxed Lasso\" being especially useful in this regard. ",
    "version": "0.6-3",
    "maintainer": "Walter K Kremers <kremers.walter@mayo.edu>",
    "author": "Walter K Kremers [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5714-3473>),\n  Nicholas B Larson [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glmnetr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glmnetr Nested Cross Validation for the Relaxed Lasso and Other Machine\nLearning Models \n    Cross validation informed Relaxed LASSO (or more generally elastic net), gradient boosting machine ('xgboost'), Random Forest ('RandomForestSRC'), Oblique Random Forest ('aorsf'), Artificial Neural Network (ANN), Recursive Partitioning ('RPART') or step wise regression models are fit.  Cross validation leave out samples (leading to nested cross validation) or bootstrap out-of-bag samples are used to evaluate and compare performances between these models with results presented in tabular or graphical means.  Calibration plots can also be generated, again based upon (outer nested) cross validation or bootstrap leave out (out of bag) samples.\n    Note, at the time of this writing, in order to fit gradient boosting machine models one must install the packages 'DiceKriging' and 'rgenoud' using the install.packages() function. \n    For some datasets, for example when the design matrix is not of full rank, 'glmnet' may have very long run times when fitting the relaxed lasso model, from our experience when fitting Cox models on data with many predictors and many patients, making it difficult to get solutions from either glmnet() or cv.glmnet().  This may be remedied by using the 'path=TRUE' option when calling glmnet() and cv.glmnet().  Within the 'glmnetr' package the approach of path=TRUE is taken by default. \n    other packages doing similar include 'nestedcv' <https://cran.r-project.org/package=nestedcv>, 'glmnetSE' <https://cran.r-project.org/package=glmnetSE> which may provide different functionality when performing a nested CV. \n    Use of the 'glmnetr' has many similarities to the 'glmnet' package and it could be helpful for the user of 'glmnetr' also become familiar with the 'glmnet' package <https://cran.r-project.org/package=glmnet>, with the \"An Introduction to 'glmnet'\" and \"The Relaxed Lasso\" being especially useful in this regard.   "
  },
  {
    "id": 698,
    "package_name": "hypothesize",
    "title": "A Consistent API for Hypothesis Testing",
    "description": "Provides a consistent API for hypothesis testing built on\n    principles from 'Structure and Interpretation of Computer Programs':\n    data abstraction, closure (combining tests yields tests), and\n    higher-order functions (transforming tests). Implements z-tests,\n    Wald tests, likelihood ratio tests, Fisher's method for combining\n    p-values, and multiple testing corrections. Designed for use by\n    other packages that want to wrap their hypothesis tests in a\n    consistent interface.",
    "version": "0.10.0",
    "maintainer": "Alexander Towell <lex@metafunctor.com>",
    "author": "Alexander Towell [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6443-9897>)",
    "url": "https://github.com/queelius/hypothesize,\nhttps://queelius.github.io/hypothesize/",
    "bug_reports": "https://github.com/queelius/hypothesize/issues",
    "repository": "https://cran.r-project.org/package=hypothesize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hypothesize A Consistent API for Hypothesis Testing Provides a consistent API for hypothesis testing built on\n    principles from 'Structure and Interpretation of Computer Programs':\n    data abstraction, closure (combining tests yields tests), and\n    higher-order functions (transforming tests). Implements z-tests,\n    Wald tests, likelihood ratio tests, Fisher's method for combining\n    p-values, and multiple testing corrections. Designed for use by\n    other packages that want to wrap their hypothesis tests in a\n    consistent interface.  "
  },
  {
    "id": 713,
    "package_name": "interfacer",
    "title": "Define and Enforce Contracts for Dataframes as Function\nParameters",
    "description": "A dataframe validation framework for package builders who use\n  dataframes as function parameters. It performs checks on column names, coerces\n  data-types, and checks grouping to make sure user inputs conform to a\n  specification provided by the package author. It provides a mechanism for\n  package authors to automatically document supported dataframe inputs and\n  selectively dispatch to functions depending on the format of a dataframe much\n  like S3 does for classes. It also contains some developer tools to make\n  working with and documenting dataframe specifications easier. It helps package\n  developers to improve their documentation and simplifies parameter validation\n  where dataframes are used as function parameters.",
    "version": "0.4.0",
    "maintainer": "Robert Challen <rob.challen@bristol.ac.uk>",
    "author": "Robert Challen [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5504-7768>)",
    "url": "https://ai4ci.github.io/interfacer/,\nhttps://github.com/ai4ci/interfacer",
    "bug_reports": "https://github.com/ai4ci/interfacer/issues",
    "repository": "https://cran.r-project.org/package=interfacer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "interfacer Define and Enforce Contracts for Dataframes as Function\nParameters A dataframe validation framework for package builders who use\n  dataframes as function parameters. It performs checks on column names, coerces\n  data-types, and checks grouping to make sure user inputs conform to a\n  specification provided by the package author. It provides a mechanism for\n  package authors to automatically document supported dataframe inputs and\n  selectively dispatch to functions depending on the format of a dataframe much\n  like S3 does for classes. It also contains some developer tools to make\n  working with and documenting dataframe specifications easier. It helps package\n  developers to improve their documentation and simplifies parameter validation\n  where dataframes are used as function parameters.  "
  },
  {
    "id": 844,
    "package_name": "mpn.scorecard",
    "title": "Generate a scorecard with various measures of R package quality and risk",
    "description": "Collects various measures of quality and risk-of-use for an R package",
    "version": "0.5.3",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/metrumresearchgroup/mpn.scorecard",
    "bug_reports": "https://github.com/metrumresearchgroup/mpn.scorecard/issues",
    "repository": "https://github.com/metrumresearchgroup/mpn.scorecard",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 3,
    "primary_category": "pharmacometrics",
    "source_universe": "github:metrumresearchgroup",
    "search_text": "mpn.scorecard Generate a scorecard with various measures of R package quality and risk Collects various measures of quality and risk-of-use for an R package  "
  },
  {
    "id": 851,
    "package_name": "mrgvalidate",
    "title": "Create Validation Docs For R Packages",
    "description": "R package for generating validation documents for other R packages developed by Metrum.",
    "version": "2.0.0",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/metrumresearchgroup/mrgvalidate",
    "bug_reports": "https://github.com/metrumresearchgroup/mrgvalidate/issues",
    "repository": "https://github.com/metrumresearchgroup/mrgvalidate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 1,
    "primary_category": "pharmacometrics",
    "source_universe": "github:metrumresearchgroup",
    "search_text": "mrgvalidate Create Validation Docs For R Packages R package for generating validation documents for other R packages developed by Metrum.  "
  },
  {
    "id": 994,
    "package_name": "pmparams",
    "title": "R package for parameter tables",
    "description": "`pmparams` is a library written in R that generates clear, well-formatted parameter tables to report NONMEM model results.",
    "version": "0.3.2",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/metrumresearchgroup/pmparams",
    "bug_reports": "https://github.com/metrumresearchgroup/pmparams/issues",
    "repository": "https://github.com/metrumresearchgroup/pmparams",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 1,
    "primary_category": "pharmacometrics",
    "source_universe": "github:metrumresearchgroup",
    "search_text": "pmparams R package for parameter tables `pmparams` is a library written in R that generates clear, well-formatted parameter tables to report NONMEM model results.  "
  },
  {
    "id": 1036,
    "package_name": "qraLm",
    "title": "Functions to develop quantitative risk assessment for Listeria monocytogenes in foods",
    "description": "qraLm: A R package for quantitative risk assessment for Listeria monocytogenes in foods.",
    "version": "0.1.2",
    "maintainer": "Vasco Cadavez <vcadavez@ipb.pt>",
    "author": "",
    "url": "https://github.com/WorldHealthOrganization/qraLm",
    "bug_reports": "https://github.com/WorldHealthOrganization/qraLm/issues",
    "repository": "https://github.com/WorldHealthOrganization/qraLm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "github:WorldHealthOrganization",
    "search_text": "qraLm Functions to develop quantitative risk assessment for Listeria monocytogenes in foods qraLm: A R package for quantitative risk assessment for Listeria monocytogenes in foods.  "
  },
  {
    "id": 1118,
    "package_name": "rjd3jars",
    "title": "External jars for 'rjdverse' R Packages",
    "description": "It provides external jars required for the 'rjdverse' (as 'rjd3toolkit', 'rjd3x13' and 'rjd3tramoseats').",
    "version": "0.0.1",
    "maintainer": "Tanguy Barthelemy <tanguy.barthelemy@insee.fr>",
    "author": "Tanguy Barthelemy [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rjd3jars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rjd3jars External jars for 'rjdverse' R Packages It provides external jars required for the 'rjdverse' (as 'rjd3toolkit', 'rjd3x13' and 'rjd3tramoseats').  "
  },
  {
    "id": 1142,
    "package_name": "rqlm",
    "title": "Modified Poisson Regression for Binary Outcome and Related\nMethods",
    "description": "Modified Poisson, logistic and least-squares regression analyses for binary outcomes of Zou (2004) <doi:10.1093/aje/kwh090>, Noma (2025)<Forthcoming>, and Cheung (2007) <doi:10.1093/aje/kwm223> have been standard multivariate analysis methods to estimate risk ratio and risk difference in clinical and epidemiological studies. This R package involves an easy-to-handle function to implement these analyses by simple commands. Missing data analysis tools (multiple imputation) are also involved. In addition, recent studies have shown the ordinary robust variance estimator possibly has serious bias under small or moderate sample size situations for these methods. This package also provides computational tools to calculate alternative accurate confidence intervals.",
    "version": "4.2-1",
    "maintainer": "Hisashi Noma <noma@ism.ac.jp>",
    "author": "Hisashi Noma [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2520-9949>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rqlm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rqlm Modified Poisson Regression for Binary Outcome and Related\nMethods Modified Poisson, logistic and least-squares regression analyses for binary outcomes of Zou (2004) <doi:10.1093/aje/kwh090>, Noma (2025)<Forthcoming>, and Cheung (2007) <doi:10.1093/aje/kwm223> have been standard multivariate analysis methods to estimate risk ratio and risk difference in clinical and epidemiological studies. This R package involves an easy-to-handle function to implement these analyses by simple commands. Missing data analysis tools (multiple imputation) are also involved. In addition, recent studies have shown the ordinary robust variance estimator possibly has serious bias under small or moderate sample size situations for these methods. This package also provides computational tools to calculate alternative accurate confidence intervals.  "
  },
  {
    "id": 1193,
    "package_name": "serosim",
    "title": "Serosurvey simulation",
    "description": "serosim is an open source R package designed to aid inference",
    "version": "0.0.0.9000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/seroanalytics/serosim",
    "bug_reports": "https://github.com/seroanalytics/serosim/issues",
    "repository": "https://github.com/seroanalytics/serosim",
    "exports": [],
    "topics": [
      "antibodies",
      "infectious-disease-epidemiology",
      "serological-surveys",
      "serology",
      "serosurvey",
      "simulation-framework"
    ],
    "score": "NA",
    "stars": 7,
    "primary_category": "epidemiology",
    "source_universe": "github:seroanalytics",
    "search_text": "serosim Serosurvey simulation serosim is an open source R package designed to aid inference  antibodies infectious-disease-epidemiology serological-surveys serology serosurvey simulation-framework"
  },
  {
    "id": 1223,
    "package_name": "simFastBOIN",
    "title": "Fast Bayesian Optimal Interval Design for Phase I Dose-Finding\nTrials",
    "description": "\n    Conducting Bayesian Optimal Interval (BOIN) design for phase I \n    dose-finding trials. 'simFastBOIN' provides functions for pre-computing \n    decision tables, conducting trial simulations, and evaluating operating \n    characteristics. The package uses vectorized operations and the \n    Iso::pava() function for isotonic regression to achieve efficient \n    performance while maintaining full compatibility with BOIN methodology. \n    Version 1.3.2 adds p_saf and p_tox parameters for customizable safety and \n    toxicity thresholds. Version 1.3.1 fixes Date field. Version 1.2.1 adds \n    comprehensive 'roxygen2' documentation and enhanced print formatting with \n    flexible table output options. Version 1.2.0 integrated C-based PAVA for \n    isotonic regression. Version 1.1.0 introduced conservative MTD selection \n    (boundMTD) and flexible early stopping rules (n_earlystop_rule). Methods \n    are described in Liu and Yuan (2015) <doi:10.1111/rssc.12089>.",
    "version": "1.3.2",
    "maintainer": "Gosuke Homma <my.name.is.gosuke@gmail.com>",
    "author": "Gosuke Homma [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6854-5627>)",
    "url": "https://github.com/gosukehommaEX/simFastBOIN",
    "bug_reports": "https://github.com/gosukehommaEX/simFastBOIN/issues",
    "repository": "https://cran.r-project.org/package=simFastBOIN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "simFastBOIN Fast Bayesian Optimal Interval Design for Phase I Dose-Finding\nTrials \n    Conducting Bayesian Optimal Interval (BOIN) design for phase I \n    dose-finding trials. 'simFastBOIN' provides functions for pre-computing \n    decision tables, conducting trial simulations, and evaluating operating \n    characteristics. The package uses vectorized operations and the \n    Iso::pava() function for isotonic regression to achieve efficient \n    performance while maintaining full compatibility with BOIN methodology. \n    Version 1.3.2 adds p_saf and p_tox parameters for customizable safety and \n    toxicity thresholds. Version 1.3.1 fixes Date field. Version 1.2.1 adds \n    comprehensive 'roxygen2' documentation and enhanced print formatting with \n    flexible table output options. Version 1.2.0 integrated C-based PAVA for \n    isotonic regression. Version 1.1.0 introduced conservative MTD selection \n    (boundMTD) and flexible early stopping rules (n_earlystop_rule). Methods \n    are described in Liu and Yuan (2015) <doi:10.1111/rssc.12089>.  "
  },
  {
    "id": 1367,
    "package_name": "toxpiR",
    "title": "Create ToxPi Prioritization Models",
    "description": "\n  Enables users to build 'ToxPi' prioritization models and provides \n  functionality within the grid framework for plotting ToxPi graphs.\n  'toxpiR' allows for more customization than the 'ToxPi GUI' \n  (<https://toxpi.github.io/>) and integration into existing workflows for greater \n  ease-of-use, reproducibility, and transparency.\n  toxpiR package behaves nearly identically to the GUI; the package \n  documentation includes notes about all differences.\n  The vignettes download example files from \n  <https://github.com/ToxPi/ToxPi-example-files>.",
    "version": "1.3.1",
    "maintainer": "Jonathon F Fleming <jffleming0129@gmail.com>",
    "author": "Jonathon F Fleming [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2447-3139>),\n  Dayne L Filer [aut, fnd] (ORCID:\n    <https://orcid.org/0000-0002-3443-5315>),\n  Dillon T Lloyd [aut],\n  Preethi Thunga [aut] (ORCID: <https://orcid.org/0000-0001-5447-0129>),\n  Skylar W Marvel [aut],\n  Alison A Motsinger-Reif [fnd] (ORCID:\n    <https://orcid.org/0000-0003-1346-2493>),\n  David M Reif [aut, fnd] (ORCID:\n    <https://orcid.org/0000-0001-7815-6767>)",
    "url": "https://github.com/ToxPi/toxpiR, https://toxpi.github.io/toxpiR/",
    "bug_reports": "https://github.com/ToxPi/toxpiR/issues",
    "repository": "https://cran.r-project.org/package=toxpiR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "toxpiR Create ToxPi Prioritization Models \n  Enables users to build 'ToxPi' prioritization models and provides \n  functionality within the grid framework for plotting ToxPi graphs.\n  'toxpiR' allows for more customization than the 'ToxPi GUI' \n  (<https://toxpi.github.io/>) and integration into existing workflows for greater \n  ease-of-use, reproducibility, and transparency.\n  toxpiR package behaves nearly identically to the GUI; the package \n  documentation includes notes about all differences.\n  The vignettes download example files from \n  <https://github.com/ToxPi/ToxPi-example-files>.  "
  },
  {
    "id": 1439,
    "package_name": "weightedGCM",
    "title": "Weighted Generalised Covariance Measure Conditional Independence\nTest",
    "description": "A conditional independence test that can be applied both to\n    univariate and multivariate random variables. The test is based on a\n    weighted form of the sample covariance of the residuals after a\n    nonlinear regression on the conditioning variables. Details are\n    described in Scheidegger, Hoerrmann and Buehlmann (2022) \"The Weighted\n    Generalised Covariance Measure\" <http://jmlr.org/papers/v23/21-1328.html>.\n    The test is a generalisation of the Generalised Covariance Measure (GCM)\n    implemented in the R package 'GeneralisedCovarianceMeasure' by Jonas Peters and\n    Rajen D. Shah based on Shah and Peters (2020) \"The Hardness of\n    Conditional Independence Testing and the Generalised Covariance\n    Measure\" <doi:10.1214/19-AOS1857>.",
    "version": "0.1.1",
    "maintainer": "Cyrill Scheidegger <cyrill.scheidegger@stat.math.ethz.ch>",
    "author": "Cyrill Scheidegger [aut, cre, cph],\n  Julia Hoerrmann [ths],\n  Peter Buehlmann [ths],\n  Jonas Peters [ctb, cph] (Parts of the code are inspired by similar\n    functions from the R package 'GeneralisedCovarianceMeasure' by\n    Jonas Peters and Rajen D. Shah),\n  Rajen D. Shah [ctb, cph] (Parts of the code are inspired by similar\n    functions from the R package 'GeneralisedCovarianceMeasure' by\n    Jonas Peters and Rajen D. Shah)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=weightedGCM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "weightedGCM Weighted Generalised Covariance Measure Conditional Independence\nTest A conditional independence test that can be applied both to\n    univariate and multivariate random variables. The test is based on a\n    weighted form of the sample covariance of the residuals after a\n    nonlinear regression on the conditioning variables. Details are\n    described in Scheidegger, Hoerrmann and Buehlmann (2022) \"The Weighted\n    Generalised Covariance Measure\" <http://jmlr.org/papers/v23/21-1328.html>.\n    The test is a generalisation of the Generalised Covariance Measure (GCM)\n    implemented in the R package 'GeneralisedCovarianceMeasure' by Jonas Peters and\n    Rajen D. Shah based on Shah and Peters (2020) \"The Hardness of\n    Conditional Independence Testing and the Generalised Covariance\n    Measure\" <doi:10.1214/19-AOS1857>.  "
  },
  {
    "id": 1455,
    "package_name": "xfun",
    "title": "Supporting Functions for Packages Maintained by 'Yihui Xie'",
    "description": "Miscellaneous functions commonly used in other packages maintained by 'Yihui Xie'.",
    "version": "0.55",
    "maintainer": "Yihui Xie <xie@yihui.name>",
    "author": "Yihui Xie [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0645-5666>, URL: https://yihui.org),\n  Wush Wu [ctb],\n  Daijiang Li [ctb],\n  Xianying Tan [ctb],\n  Salim Br\u00fcggemann [ctb] (ORCID: <https://orcid.org/0000-0002-5329-5987>),\n  Christophe Dervieux [ctb]",
    "url": "https://github.com/yihui/xfun",
    "bug_reports": "https://github.com/yihui/xfun/issues",
    "repository": "https://cran.r-project.org/package=xfun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xfun Supporting Functions for Packages Maintained by 'Yihui Xie' Miscellaneous functions commonly used in other packages maintained by 'Yihui Xie'.  "
  },
  {
    "id": 1473,
    "package_name": "yulab.utils",
    "title": "Supporting Functions for Packages Maintained by 'YuLab-SMU'",
    "description": "Miscellaneous functions commonly used by 'YuLab-SMU'.",
    "version": "0.2.3",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6485-8781>)",
    "url": "https://yulab-smu.top/",
    "bug_reports": "https://github.com/YuLab-SMU/yulab.utils/issues",
    "repository": "https://cran.r-project.org/package=yulab.utils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "yulab.utils Supporting Functions for Packages Maintained by 'YuLab-SMU' Miscellaneous functions commonly used by 'YuLab-SMU'.  "
  },
  {
    "id": 1522,
    "package_name": "AFR",
    "title": "Toolkit for Regression Analysis of Kazakhstan Banking Sector\nData",
    "description": "Tool is created for regression, prediction and forecast analysis of macroeconomic and credit data.\n  The package includes functions from existing R packages adapted for banking sector of Kazakhstan.\n  The purpose of the package is to optimize statistical functions for easier interpretation for bank analysts and non-statisticians.",
    "version": "0.3.7",
    "maintainer": "Sultan Zhaparov <saldau.sultan@gmail.com>",
    "author": "Timur Abilkassymov [aut],\n  Shyngys Shuneyev [aut],\n  Alua Makhmetova [aut],\n  Sultan Zhaparov [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AFR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AFR Toolkit for Regression Analysis of Kazakhstan Banking Sector\nData Tool is created for regression, prediction and forecast analysis of macroeconomic and credit data.\n  The package includes functions from existing R packages adapted for banking sector of Kazakhstan.\n  The purpose of the package is to optimize statistical functions for easier interpretation for bank analysts and non-statisticians.  "
  },
  {
    "id": 1537,
    "package_name": "AIPW",
    "title": "Augmented Inverse Probability Weighting",
    "description": "The 'AIPW' package implements the augmented inverse probability weighting, a doubly robust estimator, for average causal effect estimation with user-defined stacked machine learning algorithms. To cite the 'AIPW' package, please use: \"Yongqi Zhong, Edward H. Kennedy, Lisa M. Bodnar, Ashley I. Naimi (2021). AIPW: An R Package for Augmented Inverse Probability Weighted Estimation of Average Causal Effects. American Journal of Epidemiology. <doi:10.1093/aje/kwab207>\". Visit: <https://yqzhong7.github.io/AIPW/> for more information.",
    "version": "0.6.9.2",
    "maintainer": "Yongqi Zhong <yq.zhong7@gmail.com>",
    "author": "Yongqi Zhong [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4042-7450>),\n  Ashley Naimi [aut] (ORCID: <https://orcid.org/0000-0002-1510-8175>),\n  Gabriel Conzuelo [ctb],\n  Edward Kennedy [ctb]",
    "url": "https://github.com/yqzhong7/AIPW",
    "bug_reports": "https://github.com/yqzhong7/AIPW/issues",
    "repository": "https://cran.r-project.org/package=AIPW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AIPW Augmented Inverse Probability Weighting The 'AIPW' package implements the augmented inverse probability weighting, a doubly robust estimator, for average causal effect estimation with user-defined stacked machine learning algorithms. To cite the 'AIPW' package, please use: \"Yongqi Zhong, Edward H. Kennedy, Lisa M. Bodnar, Ashley I. Naimi (2021). AIPW: An R Package for Augmented Inverse Probability Weighted Estimation of Average Causal Effects. American Journal of Epidemiology. <doi:10.1093/aje/kwab207>\". Visit: <https://yqzhong7.github.io/AIPW/> for more information.  "
  },
  {
    "id": 1617,
    "package_name": "AWR",
    "title": "'AWS' Java 'SDK' for R",
    "description": "Make the compiled Java modules of the Amazon Web Services ('AWS') 'SDK' available to be used in downstream R packages interacting with 'AWS'. See <https://aws.amazon.com/sdk-for-java> for more information on the 'AWS' 'SDK' for Java.",
    "version": "1.11.189-1",
    "maintainer": "Gergely Daroczi <daroczig@rapporter.net>",
    "author": "Gergely Daroczi <daroczig@rapporter.net>",
    "url": "https://github.com/daroczig/AWR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AWR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AWR 'AWS' Java 'SDK' for R Make the compiled Java modules of the Amazon Web Services ('AWS') 'SDK' available to be used in downstream R packages interacting with 'AWS'. See <https://aws.amazon.com/sdk-for-java> for more information on the 'AWS' 'SDK' for Java.  "
  },
  {
    "id": 1641,
    "package_name": "AdapSamp",
    "title": "Adaptive Sampling Algorithms",
    "description": "For distributions whose probability density functions are log-concave, the adaptive rejection sampling algorithm can be used to build envelope functions for sampling. For others, we can use the modified adaptive rejection sampling algorithm, the concave-convex adaptive rejection sampling algorithm and the adaptive slice sampling algorithm. So we designed an R package mainly including 4 functions: rARS(), rMARS(), rCCARS() and rASS(). These functions can realize sampling based on the algorithms above.",
    "version": "1.1.1",
    "maintainer": "Dong Zhang <dzhang0716@126.com>",
    "author": "Dong Zhang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AdapSamp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AdapSamp Adaptive Sampling Algorithms For distributions whose probability density functions are log-concave, the adaptive rejection sampling algorithm can be used to build envelope functions for sampling. For others, we can use the modified adaptive rejection sampling algorithm, the concave-convex adaptive rejection sampling algorithm and the adaptive slice sampling algorithm. So we designed an R package mainly including 4 functions: rARS(), rMARS(), rCCARS() and rASS(). These functions can realize sampling based on the algorithms above.  "
  },
  {
    "id": 1704,
    "package_name": "AnthropMMD",
    "title": "An R Package for the Mean Measure of Divergence (MMD)",
    "description": "Offers a graphical user interface for the calculation of the mean measure of divergence, with facilities for trait selection and graphical representations <doi:10.1002/ajpa.23336>.",
    "version": "4.1.0",
    "maintainer": "Fr\u00e9d\u00e9ric Santos <frederic.santos@u-bordeaux.fr>",
    "author": "Fr\u00e9d\u00e9ric Santos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1445-3871>)",
    "url": "https://gitlab.com/f-santos/anthropmmd/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AnthropMMD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AnthropMMD An R Package for the Mean Measure of Divergence (MMD) Offers a graphical user interface for the calculation of the mean measure of divergence, with facilities for trait selection and graphical representations <doi:10.1002/ajpa.23336>.  "
  },
  {
    "id": 1709,
    "package_name": "Aoptbdtvc",
    "title": "A-Optimal Block Designs for Comparing Test Treatments with\nControls",
    "description": "A collection of functions to construct A-optimal block designs for comparing test treatments with one or more control(s). Mainly A-optimal balanced treatment incomplete block designs, weighted A-optimal balanced treatment incomplete block designs, A-optimal group divisible treatment designs and A-optimal balanced bipartite block designs can be constructed using the package. The designs are constructed using algorithms based on linear integer programming. To the best of our knowledge, these facilities to construct A-optimal block designs for comparing test treatments with one or more controls are not available in the existing R packages. For more details on designs for tests versus control(s) comparisons, please see Hedayat, A. S. and Majumdar, D. (1984) <doi:10.1080/00401706.1984.10487989> A-Optimal Incomplete Block Designs for Control-Test Treatment Comparisons, Technometrics, 26, 363-370 and Mandal, B. N. , Gupta, V. K., Parsad, Rajender. (2017) <doi:10.1080/03610926.2015.1071394> Balanced treatment incomplete block designs through integer programming. Communications in Statistics - Theory and Methods 46(8), 3728-3737. ",
    "version": "0.0.3",
    "maintainer": "Baidya Nath Mandal <mandal.stat@gmail.com>",
    "author": "Baidya Nath Mandal [aut, cre],\n  Sukanta Dash [aut],\n  Rajender Parsad [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Aoptbdtvc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Aoptbdtvc A-Optimal Block Designs for Comparing Test Treatments with\nControls A collection of functions to construct A-optimal block designs for comparing test treatments with one or more control(s). Mainly A-optimal balanced treatment incomplete block designs, weighted A-optimal balanced treatment incomplete block designs, A-optimal group divisible treatment designs and A-optimal balanced bipartite block designs can be constructed using the package. The designs are constructed using algorithms based on linear integer programming. To the best of our knowledge, these facilities to construct A-optimal block designs for comparing test treatments with one or more controls are not available in the existing R packages. For more details on designs for tests versus control(s) comparisons, please see Hedayat, A. S. and Majumdar, D. (1984) <doi:10.1080/00401706.1984.10487989> A-Optimal Incomplete Block Designs for Control-Test Treatment Comparisons, Technometrics, 26, 363-370 and Mandal, B. N. , Gupta, V. K., Parsad, Rajender. (2017) <doi:10.1080/03610926.2015.1071394> Balanced treatment incomplete block designs through integer programming. Communications in Statistics - Theory and Methods 46(8), 3728-3737.   "
  },
  {
    "id": 1723,
    "package_name": "ArchaeoPhases.dataset",
    "title": "Data Sets for 'ArchaeoPhases' Vignettes",
    "description": "Provides the data sets used to build the 'ArchaeoPhases' vignettes.  The data sets were formerly distributed with 'ArchaeoPhases', however they exceed current CRAN policy for package size.",
    "version": "0.2.0",
    "maintainer": "Anne Philippe <anne.philippe@univ-nantes.fr>",
    "author": "Anne Philippe [aut, cre],\n  Thomas S. Dye [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ArchaeoPhases.dataset",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ArchaeoPhases.dataset Data Sets for 'ArchaeoPhases' Vignettes Provides the data sets used to build the 'ArchaeoPhases' vignettes.  The data sets were formerly distributed with 'ArchaeoPhases', however they exceed current CRAN policy for package size.  "
  },
  {
    "id": 1750,
    "package_name": "AutoTransQF",
    "title": "A Novel Automatic Shifted Log Transformation",
    "description": "A novel parametrization of log transformation and a shift parameter to automate the transformation process are proposed in R package 'AutoTransQF' based on Feng et al. (2016). Please read Feng et al. (2016) <doi:10.1002/sta4.104> for more details of the method.",
    "version": "0.1.3",
    "maintainer": "Yue Hu <yuehu2000@outlook.com>",
    "author": "Yue Hu [aut, cre],\n  Hyeon Lee [aut],\n  J. S. Marron [aut]",
    "url": "https://github.com/yyyuehhu/AutoTransQF",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AutoTransQF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AutoTransQF A Novel Automatic Shifted Log Transformation A novel parametrization of log transformation and a shift parameter to automate the transformation process are proposed in R package 'AutoTransQF' based on Feng et al. (2016). Please read Feng et al. (2016) <doi:10.1002/sta4.104> for more details of the method.  "
  },
  {
    "id": 1760,
    "package_name": "AzureCognitive",
    "title": "Interface to Azure Cognitive Services",
    "description": "An interface to Azure Cognitive Services <https://learn.microsoft.com/en-us/azure/cognitive-services/>. Both an 'Azure Resource Manager' interface, for deploying Cognitive Services resources, and a client framework are supplied. While 'AzureCognitive' can be called by the end-user, it is meant to provide a foundation for other packages that will support specific services, like Computer Vision, Custom Vision, language translation, and so on. Part of the 'AzureR' family of packages.",
    "version": "1.0.2",
    "maintainer": "Hong Ooi <hongooi73@gmail.com>",
    "author": "Hong Ooi [aut, cre],\n  Microsoft [cph]",
    "url": "https://github.com/Azure/AzureCognitive\nhttps://github.com/Azure/AzureR",
    "bug_reports": "https://github.com/Azure/AzureCognitive/issues",
    "repository": "https://cran.r-project.org/package=AzureCognitive",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AzureCognitive Interface to Azure Cognitive Services An interface to Azure Cognitive Services <https://learn.microsoft.com/en-us/azure/cognitive-services/>. Both an 'Azure Resource Manager' interface, for deploying Cognitive Services resources, and a client framework are supplied. While 'AzureCognitive' can be called by the end-user, it is meant to provide a foundation for other packages that will support specific services, like Computer Vision, Custom Vision, language translation, and so on. Part of the 'AzureR' family of packages.  "
  },
  {
    "id": 1767,
    "package_name": "AzureRMR",
    "title": "Interface to 'Azure Resource Manager'",
    "description": "A lightweight but powerful R interface to the 'Azure Resource Manager' REST API. The package exposes a comprehensive class framework and related tools for creating, updating and deleting 'Azure' resource groups, resources and templates. While 'AzureRMR' can be used to manage any 'Azure' service, it can also be extended by other packages to provide extra functionality for specific services. Part of the 'AzureR' family of packages.",
    "version": "2.4.5",
    "maintainer": "Hong Ooi <hongooi73@gmail.com>",
    "author": "Hong Ooi [aut, cre],\n  Microsoft [cph]",
    "url": "https://github.com/Azure/AzureRMR https://github.com/Azure/AzureR",
    "bug_reports": "https://github.com/Azure/AzureRMR/issues",
    "repository": "https://cran.r-project.org/package=AzureRMR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AzureRMR Interface to 'Azure Resource Manager' A lightweight but powerful R interface to the 'Azure Resource Manager' REST API. The package exposes a comprehensive class framework and related tools for creating, updating and deleting 'Azure' resource groups, resources and templates. While 'AzureRMR' can be used to manage any 'Azure' service, it can also be extended by other packages to provide extra functionality for specific services. Part of the 'AzureR' family of packages.  "
  },
  {
    "id": 1794,
    "package_name": "BBmisc",
    "title": "Miscellaneous Helper Functions for B. Bischl",
    "description": "Miscellaneous helper functions for and from B. Bischl and\n    some other guys, mainly for package development.",
    "version": "1.13",
    "maintainer": "Bernd Bischl <bernd_bischl@gmx.net>",
    "author": "Bernd Bischl [aut, cre],\n  Michel Lang [aut],\n  Jakob Bossek [aut],\n  Daniel Horn [aut],\n  Jakob Richter [aut],\n  Dirk Surmann [aut]",
    "url": "https://github.com/berndbischl/BBmisc",
    "bug_reports": "https://github.com/berndbischl/BBmisc/issues",
    "repository": "https://cran.r-project.org/package=BBmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BBmisc Miscellaneous Helper Functions for B. Bischl Miscellaneous helper functions for and from B. Bischl and\n    some other guys, mainly for package development.  "
  },
  {
    "id": 1829,
    "package_name": "BGData",
    "title": "A Suite of Packages for Analysis of Big Genomic Data",
    "description": "An umbrella package providing a phenotype/genotype data structure\n    and scalable and efficient computational methods for large genomic datasets\n    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',\n    and 'symDMatrix'.",
    "version": "2.4.1",
    "maintainer": "Alexander Grueneberg <cran@agrueneberg.info>",
    "author": "Gustavo de los Campos [aut],\n  Alexander Grueneberg [aut, cre],\n  Paulino Perez [ctb],\n  Ana Vazquez [ctb]",
    "url": "https://github.com/QuantGen/BGData",
    "bug_reports": "https://github.com/QuantGen/BGData/issues",
    "repository": "https://cran.r-project.org/package=BGData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BGData A Suite of Packages for Analysis of Big Genomic Data An umbrella package providing a phenotype/genotype data structure\n    and scalable and efficient computational methods for large genomic datasets\n    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',\n    and 'symDMatrix'.  "
  },
  {
    "id": 1836,
    "package_name": "BGmisc",
    "title": "An R Package for Extended Behavior Genetics Analysis",
    "description": "Provides functions for behavior genetics analysis, \n    including variance component model identification [Hunter et al. (2021) <doi:10.1007/s10519-021-10055-x>],\n    calculation of relatedness coefficients using path-tracing methods \n    [Wright (1922) <doi:10.1086/279872>; McArdle & McDonald (1984) <doi:10.1111/j.2044-8317.1984.tb00802.x>], \n    inference of relatedness, pedigree conversion, and simulation of multi-generational family data \n    [Lyu et al. (2024) <doi:10.1101/2024.12.19.629449>]. For a full overview, \n    see [Garrison et al. (2024) <doi:10.21105/joss.06203>].",
    "version": "1.5.0",
    "maintainer": "S. Mason Garrison <garrissm@wfu.edu>",
    "author": "S. Mason Garrison [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4804-6003>),\n  Michael D. Hunter [aut] (ORCID:\n    <https://orcid.org/0000-0002-3651-6709>),\n  Xuanyu Lyu [aut] (ORCID: <https://orcid.org/0000-0002-2841-5529>),\n  Rachel N. Good [ctb],\n  Jonathan D. Trattner [aut] (ORCID:\n    <https://orcid.org/0000-0002-1097-7603>, url:\n    https://www.jdtrat.com/),\n  S. Alexandra Burt [aut] (ORCID:\n    <https://orcid.org/0000-0001-5538-7431>)",
    "url": "https://github.com/R-Computing-Lab/BGmisc/,\nhttps://r-computing-lab.github.io/BGmisc/",
    "bug_reports": "https://github.com/R-Computing-Lab/BGmisc/issues",
    "repository": "https://cran.r-project.org/package=BGmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BGmisc An R Package for Extended Behavior Genetics Analysis Provides functions for behavior genetics analysis, \n    including variance component model identification [Hunter et al. (2021) <doi:10.1007/s10519-021-10055-x>],\n    calculation of relatedness coefficients using path-tracing methods \n    [Wright (1922) <doi:10.1086/279872>; McArdle & McDonald (1984) <doi:10.1111/j.2044-8317.1984.tb00802.x>], \n    inference of relatedness, pedigree conversion, and simulation of multi-generational family data \n    [Lyu et al. (2024) <doi:10.1101/2024.12.19.629449>]. For a full overview, \n    see [Garrison et al. (2024) <doi:10.21105/joss.06203>].  "
  },
  {
    "id": 1843,
    "package_name": "BIDistances",
    "title": "Bioinformatic Distances",
    "description": "A selection of distances measures for bioinformatics data. Other important distance measures for bioinformatics data are selected from the R package 'parallelDist'. A special distance measure for the Gene Ontology is available.",
    "version": "0.1.3",
    "maintainer": "Quirin Stier <Quirin_Stier@gmx.de>",
    "author": "Quirin Stier [aut, rev, ctb, cre] (ORCID:\n    <https://orcid.org/0000-0002-7896-4737>),\n  Michael Thrun [aut] (ORCID: <https://orcid.org/0000-0001-9542-5543>),\n  Luca Brinkmann [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BIDistances",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BIDistances Bioinformatic Distances A selection of distances measures for bioinformatics data. Other important distance measures for bioinformatics data are selected from the R package 'parallelDist'. A special distance measure for the Gene Ontology is available.  "
  },
  {
    "id": 1845,
    "package_name": "BIFIEsurvey",
    "title": "Tools for Survey Statistics in Educational Assessment",
    "description": "\n    Contains tools for survey statistics (especially in educational\n    assessment) for datasets with replication designs (jackknife, \n    bootstrap, replicate weights; see Kolenikov, 2010;\n    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,\n    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, \n    <doi:10.1080/02331889708802523>). \n    Descriptive statistics, linear and logistic regression, \n    path models for manifest variables with measurement error \n    correction and two-level hierarchical regressions for weighted \n    samples are included. Statistical inference can be conducted for \n    multiply imputed datasets and nested multiply imputed datasets\n    and is in particularly suited for the analysis of plausible values\n    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; \n    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &\n    Yanagida, 2016). The package development was supported by BIFIE \n    (Federal Institute for Educational Research, Innovation and Development \n    of the Austrian School System; Salzburg, Austria).",
    "version": "3.6-6",
    "maintainer": "Alexander Robitzsch <robitzsch@ipn.uni-kiel.de>",
    "author": "BIFIE [aut], Alexander Robitzsch [aut, cre], \n        Konrad Oberwimmer [aut]",
    "url": "https://github.com/alexanderrobitzsch/BIFIEsurvey,\nhttps://sites.google.com/view/alexander-robitzsch/software",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BIFIEsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BIFIEsurvey Tools for Survey Statistics in Educational Assessment \n    Contains tools for survey statistics (especially in educational\n    assessment) for datasets with replication designs (jackknife, \n    bootstrap, replicate weights; see Kolenikov, 2010;\n    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,\n    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, \n    <doi:10.1080/02331889708802523>). \n    Descriptive statistics, linear and logistic regression, \n    path models for manifest variables with measurement error \n    correction and two-level hierarchical regressions for weighted \n    samples are included. Statistical inference can be conducted for \n    multiply imputed datasets and nested multiply imputed datasets\n    and is in particularly suited for the analysis of plausible values\n    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; \n    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &\n    Yanagida, 2016). The package development was supported by BIFIE \n    (Federal Institute for Educational Research, Innovation and Development \n    of the Austrian School System; Salzburg, Austria).  "
  },
  {
    "id": 1874,
    "package_name": "BMRBr",
    "title": "'BMRB' File Downloader",
    "description": "Nuclear magnetic resonance (NMR) is a highly versatile analytical technique for studying molecular configuration, conformation, \n        and dynamics, especially those of biomacromolecules such as proteins. Biological Magnetic Resonance Data Bank ('BMRB') is a repository\n        for Data from NMR Spectroscopy on Proteins, Peptides, Nucleic Acids, and other Biomolecules. Currently, 'BMRB' offers an R package \n        'RBMRB' to fetch data, however, it doesn't easily offer individual data file downloading and storing in a local directory. When using \n        'RBMRB', the data will stored as an R object, which fundamentally hinders the NMR researches to access the rich information from raw \n        data, for example, the metadata. Here, 'BMRBr' File Downloader ('BMRBr') offers a more fundamental, low level downloader, which will \n        download original deposited .str format file. This type of file contains information such as entry title, authors, citation, protein\n        sequences, and so on.\n        Many factors affect NMR experiment outputs, such as temperature, resonance sensitivity and etc., approximately 40% of the entries in the 'BMRB' have \n        chemical shift accuracy problems [1,2] Unfortunately, current reference correction methods are heavily dependent on the availability of\n        assigned protein chemical shifts or protein structure. This is my current research project is going to solve, which will be included\n        in the future release of the package. The current version of the package is sufficient and robust enough for downloading individual \n        'BMRB' data file from the 'BMRB' database <http://www.bmrb.wisc.edu>. The functionalities of this package includes but not limited:\n        * To simplifies NMR researches by combine data downloading and results analysis together.\n        * To allows NMR data reaches a broader audience that could utilize more than just chemical shifts but also metadata.\n        * To offer reference corrected data for entries without assignment or structure information (future release).\n        Reference:\n        [1] E.L. Ulrich, H. Akutsu, J.F. Doreleijers, Y. Harano, Y.E. Ioannidis, J. Lin, et al., BioMagResBank, Nucl. Acids Res. 36 (2008) D402\u20138. <doi:10.1093/nar/gkm957>.\n        [2] L. Wang, H.R. Eghbalnia, A. Bahrami, J.L. Markley, Linear analysis of carbon-13 chemical shift differences and its application to the detection and correction of errors in referencing and spin system identifications, J. Biomol. NMR. 32 (2005) 13\u201322. <doi:10.1007/s10858-005-1717-0>.",
    "version": "0.2.0",
    "maintainer": "Xi Chen <billchenxi@gmail.com>",
    "author": "Xi Chen [aut, cre] (ORCID: <https://orcid.org/0000-0001-7094-6748>)",
    "url": "https://github.com/billchenxi/BMRBr",
    "bug_reports": "https://github.com/billchenxi/BMRBr/issues",
    "repository": "https://cran.r-project.org/package=BMRBr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BMRBr 'BMRB' File Downloader Nuclear magnetic resonance (NMR) is a highly versatile analytical technique for studying molecular configuration, conformation, \n        and dynamics, especially those of biomacromolecules such as proteins. Biological Magnetic Resonance Data Bank ('BMRB') is a repository\n        for Data from NMR Spectroscopy on Proteins, Peptides, Nucleic Acids, and other Biomolecules. Currently, 'BMRB' offers an R package \n        'RBMRB' to fetch data, however, it doesn't easily offer individual data file downloading and storing in a local directory. When using \n        'RBMRB', the data will stored as an R object, which fundamentally hinders the NMR researches to access the rich information from raw \n        data, for example, the metadata. Here, 'BMRBr' File Downloader ('BMRBr') offers a more fundamental, low level downloader, which will \n        download original deposited .str format file. This type of file contains information such as entry title, authors, citation, protein\n        sequences, and so on.\n        Many factors affect NMR experiment outputs, such as temperature, resonance sensitivity and etc., approximately 40% of the entries in the 'BMRB' have \n        chemical shift accuracy problems [1,2] Unfortunately, current reference correction methods are heavily dependent on the availability of\n        assigned protein chemical shifts or protein structure. This is my current research project is going to solve, which will be included\n        in the future release of the package. The current version of the package is sufficient and robust enough for downloading individual \n        'BMRB' data file from the 'BMRB' database <http://www.bmrb.wisc.edu>. The functionalities of this package includes but not limited:\n        * To simplifies NMR researches by combine data downloading and results analysis together.\n        * To allows NMR data reaches a broader audience that could utilize more than just chemical shifts but also metadata.\n        * To offer reference corrected data for entries without assignment or structure information (future release).\n        Reference:\n        [1] E.L. Ulrich, H. Akutsu, J.F. Doreleijers, Y. Harano, Y.E. Ioannidis, J. Lin, et al., BioMagResBank, Nucl. Acids Res. 36 (2008) D402\u20138. <doi:10.1093/nar/gkm957>.\n        [2] L. Wang, H.R. Eghbalnia, A. Bahrami, J.L. Markley, Linear analysis of carbon-13 chemical shift differences and its application to the detection and correction of errors in referencing and spin system identifications, J. Biomol. NMR. 32 (2005) 13\u201322. <doi:10.1007/s10858-005-1717-0>.  "
  },
  {
    "id": 1897,
    "package_name": "BRETIGEA",
    "title": "Brain Cell Type Specific Gene Expression Analysis",
    "description": "Analysis of relative cell type proportions in bulk gene expression data. Provides a well-validated set of brain cell type-specific marker genes derived from multiple types of experiments, as described in McKenzie (2018) <doi:10.1038/s41598-018-27293-5>. For brain tissue data sets, there are marker genes available for astrocytes, endothelial cells, microglia, neurons, oligodendrocytes, and oligodendrocyte precursor cells, derived from each of human, mice, and combination human/mouse data sets. However, if you have access to your own marker genes, the functions can be applied to bulk gene expression data from any tissue. Also implements multiple options for relative cell type proportion estimation using these marker genes, adapting and expanding on approaches from the 'CellCODE' R package described in Chikina (2015) <doi:10.1093/bioinformatics/btv015>. The number of cell type marker genes used in a given analysis can be increased or decreased based on your preferences and the data set. Finally, provides functions to use the estimates to adjust for variability in the relative proportion of cell types across samples prior to downstream analyses.",
    "version": "1.0.3",
    "maintainer": "Andrew McKenzie <amckenz@gmail.com>",
    "author": "Andrew McKenzie [aut, cre],\n    Minghui Wang [aut],\n    Bin Zhang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BRETIGEA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BRETIGEA Brain Cell Type Specific Gene Expression Analysis Analysis of relative cell type proportions in bulk gene expression data. Provides a well-validated set of brain cell type-specific marker genes derived from multiple types of experiments, as described in McKenzie (2018) <doi:10.1038/s41598-018-27293-5>. For brain tissue data sets, there are marker genes available for astrocytes, endothelial cells, microglia, neurons, oligodendrocytes, and oligodendrocyte precursor cells, derived from each of human, mice, and combination human/mouse data sets. However, if you have access to your own marker genes, the functions can be applied to bulk gene expression data from any tissue. Also implements multiple options for relative cell type proportion estimation using these marker genes, adapting and expanding on approaches from the 'CellCODE' R package described in Chikina (2015) <doi:10.1093/bioinformatics/btv015>. The number of cell type marker genes used in a given analysis can be increased or decreased based on your preferences and the data set. Finally, provides functions to use the estimates to adjust for variability in the relative proportion of cell types across samples prior to downstream analyses.  "
  },
  {
    "id": 1898,
    "package_name": "BRINDA",
    "title": "Computation of BRINDA Adjusted Micronutrient Biomarkers for\nInflammation",
    "description": "Inflammation can affect many micronutrient biomarkers and can thus lead to incorrect diagnosis of individuals and to over- or under-estimate the prevalence of deficiency in a population. Biomarkers Reflecting Inflammation and Nutritional Determinants of Anemia (BRINDA) is a multi-agency and multi-country partnership designed to improve the interpretation of nutrient biomarkers in settings of inflammation and to generate context-specific estimates of risk factors for anemia (Suchdev (2016) <doi:10.3945/an.115.010215>). In the past few years, BRINDA published a series of papers to provide guidance on how to adjust micronutrient biomarkers, retinol binding protein, serum retinol, serum ferritin by Namaste (2020), soluble transferrin receptor (sTfR), serum zinc, serum and Red Blood Cell (RBC) folate, and serum B-12, using inflammation markers, alpha-1-acid glycoprotein (AGP) and/or C-Reactive Protein (CRP) by Namaste (2020) <doi:10.1093/ajcn/nqaa141>, Rohner (2017) <doi:10.3945/ajcn.116.142232>, McDonald (2020) <doi:10.1093/ajcn/nqz304>, and Young (2020) <doi:10.1093/ajcn/nqz303>. The BRINDA inflammation adjustment method mainly focuses on Women of Reproductive Age (WRA) and Preschool-age Children (PSC); however, the general principle of the BRINDA method might apply to other population groups. The BRINDA R package is a user-friendly all-in-one R package that uses a series of functions to implement BRINDA adjustment method, as described above. The BRINDA R package will first carry out rigorous checks and provides users guidance to correct data or input errors (if they occur) prior to inflammation adjustments. After no errors are detected, the package implements the BRINDA inflammation adjustment for up to five micronutrient biomarkers, namely retinol-binding-protein, serum retinol, serum ferritin, sTfR, and serum zinc (when appropriate), using inflammation indicators of AGP and/or CRP for various population groups. Of note, adjustment for serum and RBC folate and serum B-12 is not included in the R package, since evidence shows that no adjustment is needed for these micronutrient biomarkers in either WRA or PSC groups (Young (2020) <doi:10.1093/ajcn/nqz303>).",
    "version": "0.1.5",
    "maintainer": "Hanqi Luo <LUOHANQI@gmail.com>",
    "author": "Hanqi Luo [cre, aut] (ORCID: <https://orcid.org/0000-0001-6253-5818>),\n  O Yaw Addo [aut] (ORCID: <https://orcid.org/0000-0003-1269-759X>),\n  Jiaxi Geng [ctb]",
    "url": "https://github.com/hanqiluo/BRINDA",
    "bug_reports": "https://github.com/hanqiluo/BRINDA/issues",
    "repository": "https://cran.r-project.org/package=BRINDA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BRINDA Computation of BRINDA Adjusted Micronutrient Biomarkers for\nInflammation Inflammation can affect many micronutrient biomarkers and can thus lead to incorrect diagnosis of individuals and to over- or under-estimate the prevalence of deficiency in a population. Biomarkers Reflecting Inflammation and Nutritional Determinants of Anemia (BRINDA) is a multi-agency and multi-country partnership designed to improve the interpretation of nutrient biomarkers in settings of inflammation and to generate context-specific estimates of risk factors for anemia (Suchdev (2016) <doi:10.3945/an.115.010215>). In the past few years, BRINDA published a series of papers to provide guidance on how to adjust micronutrient biomarkers, retinol binding protein, serum retinol, serum ferritin by Namaste (2020), soluble transferrin receptor (sTfR), serum zinc, serum and Red Blood Cell (RBC) folate, and serum B-12, using inflammation markers, alpha-1-acid glycoprotein (AGP) and/or C-Reactive Protein (CRP) by Namaste (2020) <doi:10.1093/ajcn/nqaa141>, Rohner (2017) <doi:10.3945/ajcn.116.142232>, McDonald (2020) <doi:10.1093/ajcn/nqz304>, and Young (2020) <doi:10.1093/ajcn/nqz303>. The BRINDA inflammation adjustment method mainly focuses on Women of Reproductive Age (WRA) and Preschool-age Children (PSC); however, the general principle of the BRINDA method might apply to other population groups. The BRINDA R package is a user-friendly all-in-one R package that uses a series of functions to implement BRINDA adjustment method, as described above. The BRINDA R package will first carry out rigorous checks and provides users guidance to correct data or input errors (if they occur) prior to inflammation adjustments. After no errors are detected, the package implements the BRINDA inflammation adjustment for up to five micronutrient biomarkers, namely retinol-binding-protein, serum retinol, serum ferritin, sTfR, and serum zinc (when appropriate), using inflammation indicators of AGP and/or CRP for various population groups. Of note, adjustment for serum and RBC folate and serum B-12 is not included in the R package, since evidence shows that no adjustment is needed for these micronutrient biomarkers in either WRA or PSC groups (Young (2020) <doi:10.1093/ajcn/nqz303>).  "
  },
  {
    "id": 1904,
    "package_name": "BSGW",
    "title": "Bayesian Survival Model with Lasso Shrinkage Using Generalized\nWeibull Regression",
    "description": "Bayesian survival model using Weibull regression on both scale and shape parameters. Dependence of shape parameter on covariates permits deviation from proportional-hazard assumption, leading to dynamic - i.e. non-constant with time - hazard ratios between subjects. Bayesian Lasso shrinkage in the form of two Laplace priors - one for scale and one for shape coefficients - allows for many covariates to be included. Cross-validation helper functions can be used to tune the shrinkage parameters. Monte Carlo Markov Chain (MCMC) sampling using a Gibbs wrapper around Radford Neal's univariate slice sampler (R package MfUSampler) is used for coefficient estimation.",
    "version": "0.9.4",
    "maintainer": "Alireza S. Mahani <alireza.s.mahani@gmail.com>",
    "author": "Alireza S. Mahani, Mansour T.A. Sharabiani",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BSGW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BSGW Bayesian Survival Model with Lasso Shrinkage Using Generalized\nWeibull Regression Bayesian survival model using Weibull regression on both scale and shape parameters. Dependence of shape parameter on covariates permits deviation from proportional-hazard assumption, leading to dynamic - i.e. non-constant with time - hazard ratios between subjects. Bayesian Lasso shrinkage in the form of two Laplace priors - one for scale and one for shape coefficients - allows for many covariates to be included. Cross-validation helper functions can be used to tune the shrinkage parameters. Monte Carlo Markov Chain (MCMC) sampling using a Gibbs wrapper around Radford Neal's univariate slice sampler (R package MfUSampler) is used for coefficient estimation.  "
  },
  {
    "id": 1911,
    "package_name": "BSSprep",
    "title": "Whitening Data as Preparation for Blind Source Separation",
    "description": "Whitening is the first step of almost all blind source separation (BSS) methods. A fast implementation of whitening for BSS is implemented to serve as a lightweight dependency for packages providing BSS methods.",
    "version": "0.1",
    "maintainer": "Markus Matilainen <markus.matilainen@outlook.com>",
    "author": "Markus Matilainen [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-5597-2670>),\n  Klaus Nordhausen [aut] (ORCID: <https://orcid.org/0000-0002-3758-8501>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BSSprep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BSSprep Whitening Data as Preparation for Blind Source Separation Whitening is the first step of almost all blind source separation (BSS) methods. A fast implementation of whitening for BSS is implemented to serve as a lightweight dependency for packages providing BSS methods.  "
  },
  {
    "id": 1929,
    "package_name": "BWGS",
    "title": "BreedWheat Genomic Selection Pipeline",
    "description": "Package for Breed Wheat Genomic Selection Pipeline. \n    The R package 'BWGS' is developed by Louis Gautier Tran <louis.gautier.tran@gmail.com> and Gilles Charmet <gilles.charmet@inra.fr>.\n    This repository is forked from original repository <https://forgemia.inra.fr/umr-gdec/bwgs>\n    and modified as a R package.",
    "version": "0.2.1",
    "maintainer": "Bangyou Zheng <bangyou.zheng@csiro.au>",
    "author": "Louis Gautier Tran [aut],\n  Gilles Charmet [aut],\n  Bangyou Zheng [cre]",
    "url": "https://github.com/byzheng/BWGS",
    "bug_reports": "https://github.com/byzheng/BWGS/issues",
    "repository": "https://cran.r-project.org/package=BWGS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BWGS BreedWheat Genomic Selection Pipeline Package for Breed Wheat Genomic Selection Pipeline. \n    The R package 'BWGS' is developed by Louis Gautier Tran <louis.gautier.tran@gmail.com> and Gilles Charmet <gilles.charmet@inra.fr>.\n    This repository is forked from original repository <https://forgemia.inra.fr/umr-gdec/bwgs>\n    and modified as a R package.  "
  },
  {
    "id": 1957,
    "package_name": "BayesCACE",
    "title": "Bayesian Model for CACE Analysis",
    "description": "Performs CACE (Complier Average Causal Effect analysis) on either a single study or meta-analysis of datasets with binary outcomes, using either complete or incomplete noncompliance information. Our package implements the Bayesian methods proposed in Zhou et al. (2019) <doi:10.1111/biom.13028>, which introduces a Bayesian hierarchical model for estimating CACE in meta-analysis of clinical trials with noncompliance, and Zhou et al. (2021) <doi:10.1080/01621459.2021.1900859>, with an application example on Epidural Analgesia.",
    "version": "1.2.3",
    "maintainer": "Jinhui Yang <james.yangjinhui@gmail.com>",
    "author": "Jinhui Yang [aut, cre] (ORCID: <https://orcid.org/0000-0001-8322-1121>),\n  Jincheng Zhou [aut] (ORCID: <https://orcid.org/0000-0003-2641-2495>),\n  James Hodges [ctb],\n  Haitao Chu [ctb] (ORCID: <https://orcid.org/0000-0003-0932-598X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesCACE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesCACE Bayesian Model for CACE Analysis Performs CACE (Complier Average Causal Effect analysis) on either a single study or meta-analysis of datasets with binary outcomes, using either complete or incomplete noncompliance information. Our package implements the Bayesian methods proposed in Zhou et al. (2019) <doi:10.1111/biom.13028>, which introduces a Bayesian hierarchical model for estimating CACE in meta-analysis of clinical trials with noncompliance, and Zhou et al. (2021) <doi:10.1080/01621459.2021.1900859>, with an application example on Epidural Analgesia.  "
  },
  {
    "id": 1991,
    "package_name": "BayesNetBP",
    "title": "Bayesian Network Belief Propagation",
    "description": "Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <https://www.jmlr.org/papers/v6/cowell05a.html>. For details please see Yu et. al. (2020) BayesNetBP: An R Package for Probabilistic Reasoning in Bayesian Networks <doi:10.18637/jss.v094.i03>. The optional 'cyjShiny' package for running the Shiny app is available at <https://github.com/cytoscape/cyjShiny>. Please see the example in the documentation of 'runBayesNetApp' function for installing 'cyjShiny' package from GitHub. ",
    "version": "1.6.1",
    "maintainer": "Han Yu <hyu9@buffalo.edu>",
    "author": "Han Yu, Rachael Blair, Janhavi Moharil, Andrew Yan",
    "url": "",
    "bug_reports": "https://github.com/hyu-ub/BayesNetBP/issues",
    "repository": "https://cran.r-project.org/package=BayesNetBP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesNetBP Bayesian Network Belief Propagation Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <https://www.jmlr.org/papers/v6/cowell05a.html>. For details please see Yu et. al. (2020) BayesNetBP: An R Package for Probabilistic Reasoning in Bayesian Networks <doi:10.18637/jss.v094.i03>. The optional 'cyjShiny' package for running the Shiny app is available at <https://github.com/cytoscape/cyjShiny>. Please see the example in the documentation of 'runBayesNetApp' function for installing 'cyjShiny' package from GitHub.   "
  },
  {
    "id": 1993,
    "package_name": "BayesPPD",
    "title": "Bayesian Power Prior Design",
    "description": "Bayesian power/type I error calculation and model fitting using \n  the power prior and the normalized power prior for generalized linear models.\n  Detailed examples of applying the package are available at <doi:10.32614/RJ-2023-016>.\n  Models for time-to-event outcomes are implemented in the R package 'BayesPPDSurv'.\n  The Bayesian clinical trial design methodology is described in Chen et al. (2011) \n  <doi:10.1111/j.1541-0420.2011.01561.x>, and Psioda and Ibrahim (2019) \n  <doi:10.1093/biostatistics/kxy009>. The normalized power prior is described in Duan et al. (2006) \n  <doi:10.1002/env.752> and Ibrahim et al. (2015) <doi:10.1002/sim.6728>. ",
    "version": "1.1.3",
    "maintainer": "Yueqi Shen <angieshen6@gmail.com>",
    "author": "Yueqi Shen [aut, cre],\n  Matthew A. Psioda [aut],\n  Joseph G. Ibrahim [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesPPD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesPPD Bayesian Power Prior Design Bayesian power/type I error calculation and model fitting using \n  the power prior and the normalized power prior for generalized linear models.\n  Detailed examples of applying the package are available at <doi:10.32614/RJ-2023-016>.\n  Models for time-to-event outcomes are implemented in the R package 'BayesPPDSurv'.\n  The Bayesian clinical trial design methodology is described in Chen et al. (2011) \n  <doi:10.1111/j.1541-0420.2011.01561.x>, and Psioda and Ibrahim (2019) \n  <doi:10.1093/biostatistics/kxy009>. The normalized power prior is described in Duan et al. (2006) \n  <doi:10.1002/env.752> and Ibrahim et al. (2015) <doi:10.1002/sim.6728>.   "
  },
  {
    "id": 2016,
    "package_name": "BayesXsrc",
    "title": "Distribution of the 'BayesX' C++ Sources",
    "description": "'BayesX' performs Bayesian inference in structured additive regression (STAR) models.\n\tThe R package BayesXsrc provides the 'BayesX' command line tool for easy installation.\n\tA convenient R interface is provided in package R2BayesX.",
    "version": "3.0-6",
    "maintainer": "Nikolaus Umlauf <Nikolaus.Umlauf@uibk.ac.at>",
    "author": "Nikolaus Umlauf [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2160-9803>),\n  Daniel Adler [aut],\n  Thomas Kneib [aut],\n  Stefan Lang [aut],\n  Achim Zeileis [aut] (ORCID: <https://orcid.org/0000-0003-0918-3766>)",
    "url": "https://www.uni-goettingen.de/de/bayesx/550513.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesXsrc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesXsrc Distribution of the 'BayesX' C++ Sources 'BayesX' performs Bayesian inference in structured additive regression (STAR) models.\n\tThe R package BayesXsrc provides the 'BayesX' command line tool for easy installation.\n\tA convenient R interface is provided in package R2BayesX.  "
  },
  {
    "id": 2023,
    "package_name": "BayesianMCPMod",
    "title": "Simulate, Evaluate, and Analyze Dose Finding Trials with\nBayesian MCPMod",
    "description": "Bayesian MCPMod (Fleischer et al. (2022)\n    <doi:10.1002/pst.2193>) is an innovative method that improves the\n    traditional MCPMod by systematically incorporating historical data,\n    such as previous placebo group data. This R package offers functions\n    for simulating, analyzing, and evaluating Bayesian MCPMod trials with\n    normally distributed endpoints.  It enables the assessment of trial\n    designs incorporating historical data across various true\n    dose-response relationships and sample sizes. Robust mixture prior\n    distributions, such as those derived with the Meta-Analytic-Predictive\n    approach (Schmidli et al. (2014) <doi:10.1111/biom.12242>), can be\n    specified for each dose group.  Resulting mixture posterior\n    distributions are used in the Bayesian Multiple Comparison Procedure\n    and modeling steps. The modeling step also includes a weighted model\n    averaging approach (Pinheiro et al. (2014) <doi:10.1002/sim.6052>).\n    Estimated dose-response relationships can be bootstrapped and\n    visualized.",
    "version": "1.2.0",
    "maintainer": "Stephan Wojciekowski <stephan.wojciekowski@boehringer-ingelheim.com>",
    "author": "Boehringer Ingelheim Pharma GmbH & Co. KG [cph, fnd],\n  Stephan Wojciekowski [aut, cre],\n  Lars Andersen [aut],\n  Jonas Schick [ctb],\n  Sebastian Bossert [aut]",
    "url": "https://boehringer-ingelheim.github.io/BayesianMCPMod/,\nhttps://github.com/Boehringer-Ingelheim/BayesianMCPMod",
    "bug_reports": "https://github.com/Boehringer-Ingelheim/BayesianMCPMod/issues",
    "repository": "https://cran.r-project.org/package=BayesianMCPMod",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesianMCPMod Simulate, Evaluate, and Analyze Dose Finding Trials with\nBayesian MCPMod Bayesian MCPMod (Fleischer et al. (2022)\n    <doi:10.1002/pst.2193>) is an innovative method that improves the\n    traditional MCPMod by systematically incorporating historical data,\n    such as previous placebo group data. This R package offers functions\n    for simulating, analyzing, and evaluating Bayesian MCPMod trials with\n    normally distributed endpoints.  It enables the assessment of trial\n    designs incorporating historical data across various true\n    dose-response relationships and sample sizes. Robust mixture prior\n    distributions, such as those derived with the Meta-Analytic-Predictive\n    approach (Schmidli et al. (2014) <doi:10.1111/biom.12242>), can be\n    specified for each dose group.  Resulting mixture posterior\n    distributions are used in the Bayesian Multiple Comparison Procedure\n    and modeling steps. The modeling step also includes a weighted model\n    averaging approach (Pinheiro et al. (2014) <doi:10.1002/sim.6052>).\n    Estimated dose-response relationships can be bootstrapped and\n    visualized.  "
  },
  {
    "id": 2046,
    "package_name": "BetaPASS",
    "title": "Calculate Power and Sample Size with Beta Regression",
    "description": "Power calculations are a critical component of any research study to determine the \n\tminimum sample size necessary to detect differences between multiple groups. \n\tResearchers often work with data taking the form of proportions that can be modeled with \n\ta beta distribution. Here we present an R package, 'BetaPASS', that perform power and \n\tsample size calculations for data following a beta distribution with comparative \n\tnonparametric output. This package allows flexibility with multiple options for link \n\tfunctions to fit the data and graphing functionality for visual comparisons.",
    "version": "1.1-2",
    "maintainer": "Jinpu Li <lijinp@health.missouri.edu>",
    "author": "Jinpu Li [aut, cre],\n  Ryan Knigge [aut],\n  Emily Leary [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BetaPASS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BetaPASS Calculate Power and Sample Size with Beta Regression Power calculations are a critical component of any research study to determine the \n\tminimum sample size necessary to detect differences between multiple groups. \n\tResearchers often work with data taking the form of proportions that can be modeled with \n\ta beta distribution. Here we present an R package, 'BetaPASS', that perform power and \n\tsample size calculations for data following a beta distribution with comparative \n\tnonparametric output. This package allows flexibility with multiple options for link \n\tfunctions to fit the data and graphing functionality for visual comparisons.  "
  },
  {
    "id": 2087,
    "package_name": "BioPred",
    "title": "An R Package for Biomarkers Analysis in Precision Medicine",
    "description": "Provides functions for training extreme gradient boosting model using propensity score A-learning and weight-learning methods. For further details, see Liu et al. (2024) <doi:10.1093/bioinformatics/btae592>.",
    "version": "1.0.2",
    "maintainer": "Zihuan Liu <zihuan.liu@abbvie.com>",
    "author": "Zihuan Liu [aut, cre],\n  Yan Sun [aut],\n  Xin Huang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BioPred",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BioPred An R Package for Biomarkers Analysis in Precision Medicine Provides functions for training extreme gradient boosting model using propensity score A-learning and weight-learning methods. For further details, see Liu et al. (2024) <doi:10.1093/bioinformatics/btae592>.  "
  },
  {
    "id": 2091,
    "package_name": "BioTIMEr",
    "title": "Tools to Use and Explore the 'BioTIME' Database",
    "description": "The 'BioTIME' database was first published in\n    2018 and inspired ideas, questions, project and research\n    article. To make it even more accessible, an R package\n    was created.\n    The 'BioTIMEr' package provides tools designed to interact with the\n    'BioTIME' database. The functions provided include the 'BioTIME' recommended\n    methods for preparing (gridding and rarefaction) time series data, a\n    selection of standard biodiversity metrics (including species richness,\n    numerical abundance and exponential Shannon) alongside examples on how to\n    display change over time. It also includes a sample subset of both the query\n    and meta data, the full versions of which are freely available on the 'BioTIME'\n    website <https://biotime.st-andrews.ac.uk/home.php>.",
    "version": "0.3.0",
    "maintainer": "Alban Sagouis <alban.sagouis@idiv.de>",
    "author": "Alban Sagouis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3827-1063>),\n  Faye Moyes [aut] (ORCID: <https://orcid.org/0000-0001-9687-0593>),\n  In\u00eas S. Martins [aut, rev] (ORCID:\n    <https://orcid.org/0000-0003-4328-7286>),\n  Shane A. Blowes [ctb] (ORCID: <https://orcid.org/0000-0001-6310-3670>),\n  Viviana Brambilla [ctb] (ORCID:\n    <https://orcid.org/0000-0002-0560-4693>),\n  Cher F. Y. Chow [ctb] (ORCID: <https://orcid.org/0000-0002-1020-8409>),\n  Ada Fontrodona-Eslava [ctb] (ORCID:\n    <https://orcid.org/0000-0001-7275-7174>),\n  Laura Ant\u00e3o [ctb, rev] (ORCID: <https://orcid.org/0000-0001-6612-9366>),\n  Jonathan M. Chase [fnd] (ORCID:\n    <https://orcid.org/0000-0001-5580-4303>),\n  Maria Dornelas [fnd, cph] (ORCID:\n    <https://orcid.org/0000-0003-2077-7055>),\n  Anne E. Magurran [fnd] (ORCID: <https://orcid.org/0000-0002-0036-2795>),\n  European Research Council grant AdG BioTIME 250189 [fnd],\n  European Research Council grant PoC BioCHANGE 727440 [fnd],\n  European Research Council grant AdG MetaCHANGE 101098020 [fnd],\n  The Leverhulme Centre for Anthropocene Biodiversity grant RC-2018-021\n    [fnd],\n  German Centre for Integrative Biodiversity Research (iDiv)\n    Halle-Jena-Leipzig [fnd] (ROR: <https://ror.org/01jty7g66>),\n  Martin Luther University Halle-Wittenberg [fnd] (ROR:\n    <https://ror.org/05gqaka33>),\n  University of St Andrews [fnd] (ROR: <https://ror.org/02wn5qz54>)",
    "url": "https://github.com/bioTIMEHub/BioTIMEr",
    "bug_reports": "https://github.com/bioTIMEHub/BioTIMEr/issues",
    "repository": "https://cran.r-project.org/package=BioTIMEr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BioTIMEr Tools to Use and Explore the 'BioTIME' Database The 'BioTIME' database was first published in\n    2018 and inspired ideas, questions, project and research\n    article. To make it even more accessible, an R package\n    was created.\n    The 'BioTIMEr' package provides tools designed to interact with the\n    'BioTIME' database. The functions provided include the 'BioTIME' recommended\n    methods for preparing (gridding and rarefaction) time series data, a\n    selection of standard biodiversity metrics (including species richness,\n    numerical abundance and exponential Shannon) alongside examples on how to\n    display change over time. It also includes a sample subset of both the query\n    and meta data, the full versions of which are freely available on the 'BioTIME'\n    website <https://biotime.st-andrews.ac.uk/home.php>.  "
  },
  {
    "id": 2093,
    "package_name": "BioVenn",
    "title": "Create Area-Proportional Venn Diagrams from Biological Lists",
    "description": "Creates an area-proportional Venn diagram of 2 or 3 circles. 'BioVenn' is the only R package that can automatically generate an accurate area-proportional Venn diagram by having only lists of (biological) identifiers as input. Also offers the option to map Entrez and/or Affymetrix IDs to Ensembl IDs. In SVG mode, text and numbers can be dragged and dropped. Based on the BioVenn web interface available at <https://www.biovenn.nl>. Hulsen (2021) <doi:10.3233/DS-210032>.",
    "version": "1.1.3",
    "maintainer": "Tim Hulsen <thulsen@gmail.com>",
    "author": "Tim Hulsen [aut, cre] (ORCID: <https://orcid.org/0000-0002-0208-8443>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BioVenn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BioVenn Create Area-Proportional Venn Diagrams from Biological Lists Creates an area-proportional Venn diagram of 2 or 3 circles. 'BioVenn' is the only R package that can automatically generate an accurate area-proportional Venn diagram by having only lists of (biological) identifiers as input. Also offers the option to map Entrez and/or Affymetrix IDs to Ensembl IDs. In SVG mode, text and numbers can be dragged and dropped. Based on the BioVenn web interface available at <https://www.biovenn.nl>. Hulsen (2021) <doi:10.3233/DS-210032>.  "
  },
  {
    "id": 2095,
    "package_name": "BioWorldR",
    "title": "A Curated Collection of Biodiversity and Species Datasets and\nUtilities",
    "description": "Provides a curated collection of biodiversity and species-related datasets (birds, plants, reptiles, turtles, mammals, bees, marine data and related biological measurements), together with small utilities to load and explore them.\n    The package gathers data sourced from public repositories (including Kaggle and well-known ecological/biological R packages) and standardizes access for researchers, educators, and data analysts working on biodiversity, biogeography, ecology and comparative biology.\n    It aims to simplify reproducible workflows by packaging commonly used example datasets and metadata so they can be easily inspected, visualized, and used for teaching, testing, and prototyping analyses.",
    "version": "0.1.0",
    "maintainer": "Juan David Monroy <monroyjuandavid773@gmail.com>",
    "author": "Juan David Monroy [aut, cre]",
    "url": "https://github.com/Monroy31039/BioWorld,\nhttps://Monroy31039.github.io/BioWorld/",
    "bug_reports": "https://github.com/Monroy31039/BioWorld/issues",
    "repository": "https://cran.r-project.org/package=BioWorldR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BioWorldR A Curated Collection of Biodiversity and Species Datasets and\nUtilities Provides a curated collection of biodiversity and species-related datasets (birds, plants, reptiles, turtles, mammals, bees, marine data and related biological measurements), together with small utilities to load and explore them.\n    The package gathers data sourced from public repositories (including Kaggle and well-known ecological/biological R packages) and standardizes access for researchers, educators, and data analysts working on biodiversity, biogeography, ecology and comparative biology.\n    It aims to simplify reproducible workflows by packaging commonly used example datasets and metadata so they can be easily inspected, visualized, and used for teaching, testing, and prototyping analyses.  "
  },
  {
    "id": 2096,
    "package_name": "BiocManager",
    "title": "Access the Bioconductor Project Package Repository",
    "description": "A convenient tool to install and update Bioconductor packages.",
    "version": "1.30.27",
    "maintainer": "Marcel Ramos <marcel.ramos@sph.cuny.edu>",
    "author": "Martin Morgan [aut] (ORCID: <https://orcid.org/0000-0002-5874-8148>),\n  Marcel Ramos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3242-0582>)",
    "url": "https://bioconductor.github.io/BiocManager/",
    "bug_reports": "https://github.com/Bioconductor/BiocManager/issues",
    "repository": "https://cran.r-project.org/package=BiocManager",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BiocManager Access the Bioconductor Project Package Repository A convenient tool to install and update Bioconductor packages.  "
  },
  {
    "id": 2132,
    "package_name": "Boom",
    "title": "Bayesian Object Oriented Modeling",
    "description": "A C++ library for Bayesian modeling, with an emphasis on Markov\n   chain Monte Carlo.  Although boom contains a few R utilities (mainly plotting\n   functions), its primary purpose is to install the BOOM C++ library on your\n   system so that other packages can link against it.",
    "version": "0.9.16",
    "maintainer": "Steven L. Scott <steve.the.bayesian@gmail.com>",
    "author": "Steven L. Scott [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Boom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Boom Bayesian Object Oriented Modeling A C++ library for Bayesian modeling, with an emphasis on Markov\n   chain Monte Carlo.  Although boom contains a few R utilities (mainly plotting\n   functions), its primary purpose is to install the BOOM C++ library on your\n   system so that other packages can link against it.  "
  },
  {
    "id": 2139,
    "package_name": "Boptbd",
    "title": "Bayesian Optimal Block Designs",
    "description": "Computes Bayesian A- and D-optimal block designs under the linear mixed effects model settings using block/array exchange algorithm of Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617> and Gemechu, Debusho and Haines (2025) <doi:10.5539/ijsp.v14n1p50> where the interest is in a \n\tcomparison of all possible elementary treatment contrasts. The package also provides an optional \n\tmethod of using the graphical user interface (GUI) R package 'tcltk' to ensure that it is user friendly.",
    "version": "1.0.7",
    "maintainer": "Dibaba Bayisa Gemechu <diboobayu@gmail.com>",
    "author": "Dibaba Bayisa Gemechu [aut, cre],\n  Legesse Kassa Debusho [aut],\n  Linda Haines [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Boptbd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Boptbd Bayesian Optimal Block Designs Computes Bayesian A- and D-optimal block designs under the linear mixed effects model settings using block/array exchange algorithm of Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617> and Gemechu, Debusho and Haines (2025) <doi:10.5539/ijsp.v14n1p50> where the interest is in a \n\tcomparison of all possible elementary treatment contrasts. The package also provides an optional \n\tmethod of using the graphical user interface (GUI) R package 'tcltk' to ensure that it is user friendly.  "
  },
  {
    "id": 2206,
    "package_name": "CBTF",
    "title": "Caught by the Fuzz! - A Minimalistic Fuzz-Test Runner",
    "description": "A simple runner for fuzz-testing functions in an R package's\n    public interface. Fuzz testing helps identify functions lacking sufficient\n    argument validation, and uncovers problematic inputs that, while valid by\n    function signature, may cause issues within the function body.",
    "version": "0.5.0",
    "maintainer": "Marco Colombo <mar.colombo13@gmail.com>",
    "author": "Marco Colombo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6672-0623>)",
    "url": "https://mcol.github.io/caught-by-the-fuzz/",
    "bug_reports": "https://github.com/mcol/caught-by-the-fuzz/issues",
    "repository": "https://cran.r-project.org/package=CBTF",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CBTF Caught by the Fuzz! - A Minimalistic Fuzz-Test Runner A simple runner for fuzz-testing functions in an R package's\n    public interface. Fuzz testing helps identify functions lacking sufficient\n    argument validation, and uncovers problematic inputs that, while valid by\n    function signature, may cause issues within the function body.  "
  },
  {
    "id": 2229,
    "package_name": "CDsampling",
    "title": "Constrained Sampling in Paid Research Studies",
    "description": "In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the 'CDsampling' package, which integrates optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy with limited model information. Our package offers functions for the computation of the Fisher information matrix under generalized linear models (including regular linear regression model) and multinomial logistic models.To demonstrate the applications, we also provide a simulated dataset and a real dataset embedded in the package. Yifei Huang, Liping Tong, and Jie Yang (2025)<doi:10.5705/ss.202022.0414>. ",
    "version": "0.1.6",
    "maintainer": "Yifei Huang <yhuan39@uic.edu>",
    "author": "Yifei Huang [aut, cre],\n  Liping Tong [aut],\n  Jie Yang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CDsampling",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CDsampling Constrained Sampling in Paid Research Studies In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the 'CDsampling' package, which integrates optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy with limited model information. Our package offers functions for the computation of the Fisher information matrix under generalized linear models (including regular linear regression model) and multinomial logistic models.To demonstrate the applications, we also provide a simulated dataset and a real dataset embedded in the package. Yifei Huang, Liping Tong, and Jie Yang (2025)<doi:10.5705/ss.202022.0414>.   "
  },
  {
    "id": 2235,
    "package_name": "CEoptim",
    "title": "Cross-Entropy R Package for Optimization",
    "description": "Optimization solver based on the Cross-Entropy method.",
    "version": "1.3",
    "maintainer": "Benoit Liquet <b.liquet@uq.edu.au>",
    "author": "Tim Benham and Qibin Duan and Dirk P. Kroese and Benoit Liquet",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CEoptim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CEoptim Cross-Entropy R Package for Optimization Optimization solver based on the Cross-Entropy method.  "
  },
  {
    "id": 2245,
    "package_name": "CGManalyzer",
    "title": "Continuous Glucose Monitoring Data Analyzer",
    "description": "Contains all of the functions necessary for the complete analysis of a continuous glucose monitoring study and can be applied to data measured by various existing 'CGM' devices such as 'FreeStyle Libre', 'Glutalor', 'Dexcom' and 'Medtronic CGM'. It reads a series of data files, is able to convert various formats of time stamps, can deal with missing values, calculates both regular statistics and nonlinear statistics, and conducts group comparison. It also displays results in a concise format. Also contains two unique features new to 'CGM' analysis: one is the implementation of strictly standard mean difference and the class of effect size; the other is the development of a new type of plot called antenna plot. It corresponds to 'Zhang XD'(2018)<doi:10.1093/bioinformatics/btx826>'s article 'CGManalyzer: an R package for analyzing continuous glucose monitoring studies'.",
    "version": "1.3.1",
    "maintainer": "Xinzheng Dong <dong.xinzheng@foxmail.com>",
    "author": "Xiaohua Douglas Zhang [aut, cph],\n  Dandan Wang [aut],\n  Zhaozhi Zhang [aut],\n  Madalena Costa [ctb],\n  Xinzheng Dong [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CGManalyzer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CGManalyzer Continuous Glucose Monitoring Data Analyzer Contains all of the functions necessary for the complete analysis of a continuous glucose monitoring study and can be applied to data measured by various existing 'CGM' devices such as 'FreeStyle Libre', 'Glutalor', 'Dexcom' and 'Medtronic CGM'. It reads a series of data files, is able to convert various formats of time stamps, can deal with missing values, calculates both regular statistics and nonlinear statistics, and conducts group comparison. It also displays results in a concise format. Also contains two unique features new to 'CGM' analysis: one is the implementation of strictly standard mean difference and the class of effect size; the other is the development of a new type of plot called antenna plot. It corresponds to 'Zhang XD'(2018)<doi:10.1093/bioinformatics/btx826>'s article 'CGManalyzer: an R package for analyzing continuous glucose monitoring studies'.  "
  },
  {
    "id": 2298,
    "package_name": "CMplot",
    "title": "Circle Manhattan Plot",
    "description": "Manhattan plot, a type of scatter plot, was widely used to display the association results. However, it is usually time-consuming and laborious for a non-specialist user to write scripts and adjust parameters of an elaborate plot. Moreover, the ever-growing traits measured have necessitated the integration of results from different Genome-wide association study researches. Circle Manhattan Plot is the first open R package that can lay out. Genome-wide association study P-value results in both traditional rectangular patterns, QQ-plot and novel circular ones. United in only one bull's eye style plot, association results from multiple traits can be compared interactively, thereby to reveal both similarities and differences between signals. Additional functions include: highlight signals, a group of SNPs, chromosome visualization and candidate genes around SNPs.",
    "version": "4.5.1",
    "maintainer": "LiLin-Yin <ylilin@163.com>",
    "author": "LiLin-Yin",
    "url": "https://github.com/YinLiLin/CMplot",
    "bug_reports": "https://github.com/YinLiLin/CMplot/issues/new",
    "repository": "https://cran.r-project.org/package=CMplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CMplot Circle Manhattan Plot Manhattan plot, a type of scatter plot, was widely used to display the association results. However, it is usually time-consuming and laborious for a non-specialist user to write scripts and adjust parameters of an elaborate plot. Moreover, the ever-growing traits measured have necessitated the integration of results from different Genome-wide association study researches. Circle Manhattan Plot is the first open R package that can lay out. Genome-wide association study P-value results in both traditional rectangular patterns, QQ-plot and novel circular ones. United in only one bull's eye style plot, association results from multiple traits can be compared interactively, thereby to reveal both similarities and differences between signals. Additional functions include: highlight signals, a group of SNPs, chromosome visualization and candidate genes around SNPs.  "
  },
  {
    "id": 2340,
    "package_name": "CRANsearcher",
    "title": "RStudio Addin for Searching Packages in CRAN Database Based on\nKeywords",
    "description": "One of the strengths of R is its vast package ecosystem. Indeed, R packages extend from visualization to Bayesian inference and from spatial analyses to pharmacokinetics (<https://cran.r-project.org/web/views/>). There is probably not an area of quantitative research that isn't represented by at least one R package. At the time of this writing, there are more than 10,000 active CRAN packages. Because of this massive ecosystem, it is important to have tools to search and learn about packages related to your personal R needs. For this reason, we developed an RStudio addin capable of searching available CRAN packages directly within RStudio.",
    "version": "1.0.0",
    "maintainer": "Agustin Calatroni <agustin_calatroni@rhoworld.com>",
    "author": "Becca Krouse [aut],\n  Agustin Calatroni [cre, aut]",
    "url": "https://github.com/RhoInc/CRANsearcher",
    "bug_reports": "https://github.com/RhoInc/CRANsearcher/issues",
    "repository": "https://cran.r-project.org/package=CRANsearcher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CRANsearcher RStudio Addin for Searching Packages in CRAN Database Based on\nKeywords One of the strengths of R is its vast package ecosystem. Indeed, R packages extend from visualization to Bayesian inference and from spatial analyses to pharmacokinetics (<https://cran.r-project.org/web/views/>). There is probably not an area of quantitative research that isn't represented by at least one R package. At the time of this writing, there are more than 10,000 active CRAN packages. Because of this massive ecosystem, it is important to have tools to search and learn about packages related to your personal R needs. For this reason, we developed an RStudio addin capable of searching available CRAN packages directly within RStudio.  "
  },
  {
    "id": 2351,
    "package_name": "CSESA",
    "title": "CRISPR-Based Salmonella Enterica Serotype Analyzer",
    "description": "Salmonella enterica is a major cause of bacterial food-borne disease worldwide. Serotype identification is the most commonly used typing method to characterize Salmonella isolates. However, experimental serotyping needs great cost on manpower and resources. Recently, we found that the newly incorporated spacer in the clustered regularly interspaced short palindromic repeat (CRISPR) could serve as an effective marker for typing of Salmonella. It was further revealed by Li et. al (2014) <doi:10.1128/JCM.00696-14> that recognized types based on the combination of two newly incorporated spacer in both CRISPR loci showed high accordance with serotypes. Here, we developed an R package 'CSESA' to predict the serotype based on this finding. Considering it\u2019s time saving and of high accuracy, we recommend to predict the serotypes of unknown Salmonella isolates using 'CSESA' before doing the traditional serotyping.",
    "version": "1.2.0",
    "maintainer": "Xia Zhang <zhangxia9403@gmail.com>",
    "author": "Xia Zhang [aut, cre],\n  Lang Yang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CSESA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CSESA CRISPR-Based Salmonella Enterica Serotype Analyzer Salmonella enterica is a major cause of bacterial food-borne disease worldwide. Serotype identification is the most commonly used typing method to characterize Salmonella isolates. However, experimental serotyping needs great cost on manpower and resources. Recently, we found that the newly incorporated spacer in the clustered regularly interspaced short palindromic repeat (CRISPR) could serve as an effective marker for typing of Salmonella. It was further revealed by Li et. al (2014) <doi:10.1128/JCM.00696-14> that recognized types based on the combination of two newly incorporated spacer in both CRISPR loci showed high accordance with serotypes. Here, we developed an R package 'CSESA' to predict the serotype based on this finding. Considering it\u2019s time saving and of high accuracy, we recommend to predict the serotypes of unknown Salmonella isolates using 'CSESA' before doing the traditional serotyping.  "
  },
  {
    "id": 2444,
    "package_name": "ChannelAttributionApp",
    "title": "Shiny Web Application for the Multichannel Attribution Problem",
    "description": "Shiny Web Application for the Multichannel Attribution Problem. It is a user-friendly graphical interface for package 'ChannelAttribution'.",
    "version": "1.3",
    "maintainer": "Davide Altomare <davide.altomare@gmail.com>",
    "author": "Davide Altomare",
    "url": "http://www.channelattribution.net",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ChannelAttributionApp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ChannelAttributionApp Shiny Web Application for the Multichannel Attribution Problem Shiny Web Application for the Multichannel Attribution Problem. It is a user-friendly graphical interface for package 'ChannelAttribution'.  "
  },
  {
    "id": 2460,
    "package_name": "ChoR",
    "title": "Chordalysis R Package",
    "description": "\n    Learning the structure of graphical models from datasets with thousands of variables.\n    More information about the research papers detailing the theory behind Chordalysis is available at\n    <http://www.francois-petitjean.com/Research> (KDD 2016, SDM 2015, ICDM 2014, ICDM 2013).\n    The R package development site is <https://github.com/HerrmannM/Monash-ChoR>.",
    "version": "0.0-4",
    "maintainer": "Matthieu Herrmann <matthieu.herrmann@monash.edu>",
    "author": "Fran\u00e7ois Petitjean [aut],\n  Matthieu Herrmann [aut, com, cre],\n  Christoph Bergmeir [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ChoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ChoR Chordalysis R Package \n    Learning the structure of graphical models from datasets with thousands of variables.\n    More information about the research papers detailing the theory behind Chordalysis is available at\n    <http://www.francois-petitjean.com/Research> (KDD 2016, SDM 2015, ICDM 2014, ICDM 2013).\n    The R package development site is <https://github.com/HerrmannM/Monash-ChoR>.  "
  },
  {
    "id": 2476,
    "package_name": "CircularSilhouette",
    "title": "Fast Silhouette on Circular or Linear Data Clusters",
    "description": "Calculating silhouette information for clusters on\n circular or linear data using fast algorithms. These algorithms run in\n linear time on sorted data, in contrast to quadratic time by the\n definition of silhouette. When used together with the fast and optimal\n circular clustering method FOCC (Debnath & Song 2021)\n <doi:10.1109/TCBB.2021.3077573> implemented in R package 'OptCirClust',\n circular silhouette can be maximized to find the optimal number of\n circular clusters; it can also be used to estimate the period of noisy\n periodical data.",
    "version": "0.0.1",
    "maintainer": "Joe Song <joemsong@cs.nmsu.edu>",
    "author": "Yinong Chen [aut] (ORCID: <https://orcid.org/0000-0003-1641-1712>),\n  Tathagata Debnath [aut] (ORCID:\n    <https://orcid.org/0000-0001-6445-275X>),\n  Andrew Cai [aut],\n  Joe Song [aut, cre] (ORCID: <https://orcid.org/0000-0002-6883-6547>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CircularSilhouette",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CircularSilhouette Fast Silhouette on Circular or Linear Data Clusters Calculating silhouette information for clusters on\n circular or linear data using fast algorithms. These algorithms run in\n linear time on sorted data, in contrast to quadratic time by the\n definition of silhouette. When used together with the fast and optimal\n circular clustering method FOCC (Debnath & Song 2021)\n <doi:10.1109/TCBB.2021.3077573> implemented in R package 'OptCirClust',\n circular silhouette can be maximized to find the optimal number of\n circular clusters; it can also be used to estimate the period of noisy\n periodical data.  "
  },
  {
    "id": 2589,
    "package_name": "ConcordanceTest",
    "title": "An Alternative to the Kruskal-Wallis Based on the Kendall Tau\nDistance",
    "description": "The Concordance Test is a non-parametric method for testing whether two o more samples originate from the same distribution. It extends the Kendall Tau correlation coefficient when there are only two groups. For details, see Alcaraz J., Anton-Sanchez L., Monge J.F. (2022) The Concordance Test, an Alternative to Kruskal-Wallis Based on the Kendall-tau Distance: An R Package. The R Journal 14, 26\u201353 <doi:10.32614/RJ-2022-039>.",
    "version": "1.0.3",
    "maintainer": "Laura Anton-Sanchez <l.anton@umh.es>",
    "author": "Javier Alcaraz [aut],\n  Laura Anton-Sanchez [aut, cre],\n  Juan Francisco Monge [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ConcordanceTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ConcordanceTest An Alternative to the Kruskal-Wallis Based on the Kendall Tau\nDistance The Concordance Test is a non-parametric method for testing whether two o more samples originate from the same distribution. It extends the Kendall Tau correlation coefficient when there are only two groups. For details, see Alcaraz J., Anton-Sanchez L., Monge J.F. (2022) The Concordance Test, an Alternative to Kruskal-Wallis Based on the Kendall-tau Distance: An R Package. The R Journal 14, 26\u201353 <doi:10.32614/RJ-2022-039>.  "
  },
  {
    "id": 2608,
    "package_name": "ConsRankClass",
    "title": "Classification and Clustering of Preference Rankings",
    "description": "Tree-based classification and soft-clustering method for preference rankings, with tools for external validation of fuzzy clustering, and Kemeny-equivalent augmented unfolding.\n    It contains the recursive partitioning algorithm for preference rankings, non-parametric tree-based method for a matrix of preference rankings as a response variable. It contains also the distribution-free soft clustering method for preference rankings, namely the K-median cluster component analysis (CCA). \n    The package depends on the 'ConsRank' R package.\n    Options for validate the tree-based method are both test-set procedure and V-fold cross validation.\n    The package contains the routines to compute the adjusted concordance index (a fuzzy version of the adjusted rand index) and the normalized degree of concordance (the corresponding fuzzy version of the rand index).\n    The package also contains routines to perform the Kemeny-equivalent augmented unfolding. The mds endine is the function 'sacofSym' from the package 'smacof'.\n    Essential references:\n    D'Ambrosio, A., Vera, J.F., and Heiser, W.J. (2021) <doi:10.1080/00273171.2021.1899892>;\n    D'Ambrosio, A., Amodio, S., Iorio, C., Pandolfo, G., and Siciliano, R. (2021) <doi:10.1007/s00357-020-09367-0>;\n    D'Ambrosio, A., and Heiser, W.J. (2019) <doi:10.1007/s41237-018-0069-5>;    \n    D'Ambrosio, A., and Heiser W.J. (2016) <doi:10.1007/s11336-016-9505-1>;\n    Hullermeier, E., Rifqi, M., Henzgen, S., and Senge, R. (2012) <doi:10.1109/TFUZZ.2011.2179303>;\n    Marden, J.J. <ISBN:0412995212>.",
    "version": "1.0.2",
    "maintainer": "Antonio D'Ambrosio <antdambr@unina.it>",
    "author": "Antonio D'Ambrosio [aut, cre]",
    "url": "https://www.r-project.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ConsRankClass",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ConsRankClass Classification and Clustering of Preference Rankings Tree-based classification and soft-clustering method for preference rankings, with tools for external validation of fuzzy clustering, and Kemeny-equivalent augmented unfolding.\n    It contains the recursive partitioning algorithm for preference rankings, non-parametric tree-based method for a matrix of preference rankings as a response variable. It contains also the distribution-free soft clustering method for preference rankings, namely the K-median cluster component analysis (CCA). \n    The package depends on the 'ConsRank' R package.\n    Options for validate the tree-based method are both test-set procedure and V-fold cross validation.\n    The package contains the routines to compute the adjusted concordance index (a fuzzy version of the adjusted rand index) and the normalized degree of concordance (the corresponding fuzzy version of the rand index).\n    The package also contains routines to perform the Kemeny-equivalent augmented unfolding. The mds endine is the function 'sacofSym' from the package 'smacof'.\n    Essential references:\n    D'Ambrosio, A., Vera, J.F., and Heiser, W.J. (2021) <doi:10.1080/00273171.2021.1899892>;\n    D'Ambrosio, A., Amodio, S., Iorio, C., Pandolfo, G., and Siciliano, R. (2021) <doi:10.1007/s00357-020-09367-0>;\n    D'Ambrosio, A., and Heiser, W.J. (2019) <doi:10.1007/s41237-018-0069-5>;    \n    D'Ambrosio, A., and Heiser W.J. (2016) <doi:10.1007/s11336-016-9505-1>;\n    Hullermeier, E., Rifqi, M., Henzgen, S., and Senge, R. (2012) <doi:10.1109/TFUZZ.2011.2179303>;\n    Marden, J.J. <ISBN:0412995212>.  "
  },
  {
    "id": 2621,
    "package_name": "CooccurrenceAffinity",
    "title": "Affinity in Co-Occurrence Data",
    "description": "Computes a novel metric of affinity between two entities based on their co-occurrence \n  (using binary presence/absence data). The metric and its MLE, alpha hat, were advanced in \n  Mainali, Slud, et al, 2021 <doi:10.1126/sciadv.abj9204>. Various types of confidence intervals and median interval\n  were developed in Mainali and Slud, 2022 <doi:10.1101/2022.11.01.514801>. The `finches` dataset is now\n  bundled internally (no longer pulled via the cooccur package, which has been dropped).",
    "version": "1.0.2",
    "maintainer": "Kumar Mainali <kpmainali@gmail.com>",
    "author": "Kumar Mainali [aut, cre],\n  Eric Slud [aut]",
    "url": "https://github.com/kpmainali/CooccurrenceAffinity",
    "bug_reports": "https://github.com/kpmainali/CooccurrenceAffinity/issues",
    "repository": "https://cran.r-project.org/package=CooccurrenceAffinity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CooccurrenceAffinity Affinity in Co-Occurrence Data Computes a novel metric of affinity between two entities based on their co-occurrence \n  (using binary presence/absence data). The metric and its MLE, alpha hat, were advanced in \n  Mainali, Slud, et al, 2021 <doi:10.1126/sciadv.abj9204>. Various types of confidence intervals and median interval\n  were developed in Mainali and Slud, 2022 <doi:10.1101/2022.11.01.514801>. The `finches` dataset is now\n  bundled internally (no longer pulled via the cooccur package, which has been dropped).  "
  },
  {
    "id": 2679,
    "package_name": "CustomDerivative",
    "title": "Pricing Various Types of Custom Derivatives",
    "description": "A versatile R package for creating and pricing custom derivatives to suit your financial needs.",
    "version": "0.1.1",
    "maintainer": "Amit Kumar Jha <jha.8@iitj.ac.in>",
    "author": "Amit Kumar Jha [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CustomDerivative",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CustomDerivative Pricing Various Types of Custom Derivatives A versatile R package for creating and pricing custom derivatives to suit your financial needs.  "
  },
  {
    "id": 2700,
    "package_name": "DAISIEprep",
    "title": "Extracts Phylogenetic Island Community Data from Phylogenetic\nTrees",
    "description": "Extracts colonisation and branching times of island\n    species to be used for analysis in the R package 'DAISIE'. It uses\n    phylogenetic and endemicity data to extract the separate island colonists\n    and store them.",
    "version": "1.0.1",
    "maintainer": "Joshua W. Lambert <joshua.lambert@lshtm.ac.uk>",
    "author": "Joshua W. Lambert [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5218-3046>),\n  Luis Valente [aut] (ORCID: <https://orcid.org/0000-0003-4247-8785>),\n  Pedro Santos Neves [aut] (ORCID:\n    <https://orcid.org/0000-0003-2561-4677>),\n  Lizzie Roeble [aut] (ORCID: <https://orcid.org/0000-0003-3664-4222>),\n  Theo Pannetier [aut] (ORCID: <https://orcid.org/0000-0002-8424-3573>)",
    "url": "https://github.com/joshwlambert/DAISIEprep,\nhttps://joshwlambert.github.io/DAISIEprep/",
    "bug_reports": "https://github.com/joshwlambert/DAISIEprep/issues",
    "repository": "https://cran.r-project.org/package=DAISIEprep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DAISIEprep Extracts Phylogenetic Island Community Data from Phylogenetic\nTrees Extracts colonisation and branching times of island\n    species to be used for analysis in the R package 'DAISIE'. It uses\n    phylogenetic and endemicity data to extract the separate island colonists\n    and store them.  "
  },
  {
    "id": 2715,
    "package_name": "DBR",
    "title": "Discrete Beta Regression",
    "description": "Bayesian Beta Regression, adapted for bounded discrete responses, commonly seen in survey responses.\n  Estimation is done via Markov Chain Monte Carlo sampling, using a Gibbs wrapper around univariate slice sampler \n  (Neal (2003) <DOI:10.1214/aos/1056562461>), as implemented in the R package MfUSampler \n  (Mahani and Sharabiani (2017) <DOI: 10.18637/jss.v078.c01>).",
    "version": "1.4.1",
    "maintainer": "Alireza Mahani <alireza.s.mahani@gmail.com>",
    "author": "Alireza Mahani [cre, aut],\n  Mansour Sharabiani [aut],\n  Alex Bottle [aut],\n  Cathy Price [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DBR Discrete Beta Regression Bayesian Beta Regression, adapted for bounded discrete responses, commonly seen in survey responses.\n  Estimation is done via Markov Chain Monte Carlo sampling, using a Gibbs wrapper around univariate slice sampler \n  (Neal (2003) <DOI:10.1214/aos/1056562461>), as implemented in the R package MfUSampler \n  (Mahani and Sharabiani (2017) <DOI: 10.18637/jss.v078.c01>).  "
  },
  {
    "id": 2796,
    "package_name": "DIZtools",
    "title": "Lightweight Utilities for 'DIZ' R Package Development",
    "description": "Lightweight utility functions used for the R package\n    development infrastructure inside the data integration centers ('DIZ')\n    to standardize and facilitate repetitive tasks such as setting up a\n    database connection or issuing notification messages and to avoid\n    redundancy.",
    "version": "1.0.3",
    "maintainer": "Jonathan M. Mang <jonathan.mang@uk-erlangen.de>",
    "author": "Jonathan M. Mang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0518-4710>),\n  Lorenz A. Kapsner [aut] (ORCID:\n    <https://orcid.org/0000-0003-1866-860X>),\n  MIRACUM - Medical Informatics in Research and Care in University\n    Medicine [fnd],\n  Universit\u00e4tsklinikum Erlangen, Germany [cph]",
    "url": "https://github.com/miracum/misc-diztools",
    "bug_reports": "https://github.com/miracum/misc-diztools/issues",
    "repository": "https://cran.r-project.org/package=DIZtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIZtools Lightweight Utilities for 'DIZ' R Package Development Lightweight utility functions used for the R package\n    development infrastructure inside the data integration centers ('DIZ')\n    to standardize and facilitate repetitive tasks such as setting up a\n    database connection or issuing notification messages and to avoid\n    redundancy.  "
  },
  {
    "id": 2797,
    "package_name": "DIZutils",
    "title": "Utilities for 'DIZ' R Package Development",
    "description": "Utility functions used for the R package development\n    infrastructure inside the data integration centers ('DIZ') to\n    standardize and facilitate repetitive tasks such as setting up a\n    database connection or issuing notification messages and to avoid\n    redundancy.",
    "version": "0.1.3",
    "maintainer": "Jonathan M. Mang <jonathan.mang@uk-erlangen.de>",
    "author": "Jonathan M. Mang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0518-4710>),\n  Lorenz A. Kapsner [aut] (ORCID:\n    <https://orcid.org/0000-0003-1866-860X>),\n  MIRACUM - Medical Informatics in Research and Care in University\n    Medicine [fnd],\n  Universit\u00e4tsklinikum Erlangen, Germany [cph]",
    "url": "https://github.com/miracum/misc-dizutils",
    "bug_reports": "https://github.com/miracum/misc-dizutils/issues",
    "repository": "https://cran.r-project.org/package=DIZutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIZutils Utilities for 'DIZ' R Package Development Utility functions used for the R package development\n    infrastructure inside the data integration centers ('DIZ') to\n    standardize and facilitate repetitive tasks such as setting up a\n    database connection or issuing notification messages and to avoid\n    redundancy.  "
  },
  {
    "id": 2810,
    "package_name": "DMCfun",
    "title": "Diffusion Model of Conflict (DMC) in Reaction Time Tasks",
    "description": "\n  DMC model simulation detailed in Ulrich, R., Schroeter, H., Leuthold, H., & Birngruber, T. (2015).\n  Automatic and controlled stimulus processing in conflict tasks: Superimposed diffusion processes and delta functions.\n  Cognitive Psychology, 78, 148-174. Ulrich et al. (2015) <doi:10.1016/j.cogpsych.2015.02.005>.\n  Decision processes within choice reaction-time (CRT) tasks are often modelled using evidence accumulation models (EAMs),\n  a variation of which is the Diffusion Decision Model (DDM, for a review, see Ratcliff & McKoon, 2008).\n  Ulrich et al. (2015) introduced a Diffusion Model for Conflict tasks (DMC). The DMC model combines common\n  features from within standard diffusion models with the addition of superimposed controlled and automatic activation.\n  The DMC model is used to explain distributional reaction time (and error rate) patterns in common behavioural\n  conflict-like tasks (e.g., Flanker task, Simon task). This R-package implements the DMC model and provides functionality\n  to fit the model to observed data. Further details are provided in the following paper: \n  Mackenzie, I.G., & Dudschig, C. (2021). DMCfun: An R package for fitting Diffusion Model of Conflict (DMC) to reaction \n  time and error rate data. Methods in Psychology, 100074. <doi:10.1016/j.metip.2021.100074>.",
    "version": "4.0.1",
    "maintainer": "Ian G. Mackenzie <ian.mackenzie@uni-tuebingen.de>",
    "author": "Ian G. Mackenzie [cre, aut],\n  Carolin Dudschig [aut]",
    "url": "https://github.com/igmmgi/DMCfun,\nhttps://CRAN.R-project.org/package=DMCfun,\nhttps://www.sciencedirect.com/science/article/pii/S259026012100031X",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DMCfun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DMCfun Diffusion Model of Conflict (DMC) in Reaction Time Tasks \n  DMC model simulation detailed in Ulrich, R., Schroeter, H., Leuthold, H., & Birngruber, T. (2015).\n  Automatic and controlled stimulus processing in conflict tasks: Superimposed diffusion processes and delta functions.\n  Cognitive Psychology, 78, 148-174. Ulrich et al. (2015) <doi:10.1016/j.cogpsych.2015.02.005>.\n  Decision processes within choice reaction-time (CRT) tasks are often modelled using evidence accumulation models (EAMs),\n  a variation of which is the Diffusion Decision Model (DDM, for a review, see Ratcliff & McKoon, 2008).\n  Ulrich et al. (2015) introduced a Diffusion Model for Conflict tasks (DMC). The DMC model combines common\n  features from within standard diffusion models with the addition of superimposed controlled and automatic activation.\n  The DMC model is used to explain distributional reaction time (and error rate) patterns in common behavioural\n  conflict-like tasks (e.g., Flanker task, Simon task). This R-package implements the DMC model and provides functionality\n  to fit the model to observed data. Further details are provided in the following paper: \n  Mackenzie, I.G., & Dudschig, C. (2021). DMCfun: An R package for fitting Diffusion Model of Conflict (DMC) to reaction \n  time and error rate data. Methods in Psychology, 100074. <doi:10.1016/j.metip.2021.100074>.  "
  },
  {
    "id": 2837,
    "package_name": "DQAgui",
    "title": "Graphical User Interface for Data Quality Assessment",
    "description": "A graphical user interface (GUI) to the functions implemented\n    in the R package 'DQAstats'. Publication: Mang et al. (2021)\n    <doi:10.1186/s12911-022-01961-z>.",
    "version": "0.2.6",
    "maintainer": "Lorenz A. Kapsner <lorenz.kapsner@gmail.com>",
    "author": "Lorenz A. Kapsner [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-1866-860X>),\n  Jonathan M. Mang [aut] (ORCID: <https://orcid.org/0000-0003-0518-4710>),\n  Helene K\u00f6ster [ctb],\n  MIRACUM - Medical Informatics in Research and Care in University\n    Medicine [fnd],\n  Universit\u00e4tsklinikum Erlangen [cph]",
    "url": "https://github.com/miracum/dqa-dqagui",
    "bug_reports": "https://github.com/miracum/dqa-dqagui/issues",
    "repository": "https://cran.r-project.org/package=DQAgui",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DQAgui Graphical User Interface for Data Quality Assessment A graphical user interface (GUI) to the functions implemented\n    in the R package 'DQAstats'. Publication: Mang et al. (2021)\n    <doi:10.1186/s12911-022-01961-z>.  "
  },
  {
    "id": 2857,
    "package_name": "DSI",
    "title": "'DataSHIELD' Interface",
    "description": "'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data. \n    This package defines the API that is to be implemented by 'DataSHIELD' compliant \n    data repositories.",
    "version": "1.8.0",
    "maintainer": "Yannick Marcon <yannick.marcon@obiba.org>",
    "author": "Yannick Marcon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0138-2023>),\n  Amadou Gaye [ctb] (ORCID: <https://orcid.org/0000-0002-1180-2792>),\n  Tim Cadman [ctb] (ORCID: <https://orcid.org/0000-0002-7682-5645>),\n  Paul Burton [ctb]",
    "url": "https://github.com/datashield/DSI/,\nhttps://datashield.github.io/DSI/, https://datashield.org/",
    "bug_reports": "https://github.com/datashield/DSI/issues",
    "repository": "https://cran.r-project.org/package=DSI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DSI 'DataSHIELD' Interface 'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data. \n    This package defines the API that is to be implemented by 'DataSHIELD' compliant \n    data repositories.  "
  },
  {
    "id": 2859,
    "package_name": "DSLite",
    "title": "'DataSHIELD' Implementation on Local Datasets",
    "description": "'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This 'DataSHIELD Interface' implementation is for analyzing datasets living\n    in the current R session. The purpose of this is primarily for lightweight\n    'DataSHIELD' analysis package development.",
    "version": "1.4.1",
    "maintainer": "Yannick Marcon <yannick.marcon@obiba.org>",
    "author": "Yannick Marcon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0138-2023>)",
    "url": "https://github.com/datashield/DSLite/,\nhttps://datashield.github.io/DSLite/, https://datashield.org/,\nhttps://doi.org/10.1093/ije/dyu188",
    "bug_reports": "https://github.com/datashield/DSLite/issues/",
    "repository": "https://cran.r-project.org/package=DSLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DSLite 'DataSHIELD' Implementation on Local Datasets 'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This 'DataSHIELD Interface' implementation is for analyzing datasets living\n    in the current R session. The purpose of this is primarily for lightweight\n    'DataSHIELD' analysis package development.  "
  },
  {
    "id": 2860,
    "package_name": "DSMolgenisArmadillo",
    "title": "'DataSHIELD' Client for 'MOLGENIS Armadillo'",
    "description": "'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This package is the 'DataSHIELD' interface implementation to analyze data\n    shared on a 'MOLGENIS Armadillo' server. 'MOLGENIS Armadillo' is a\n    light-weight 'DataSHIELD' server using a file store and an 'RServe' server.",
    "version": "3.0.2",
    "maintainer": "Mariska Slofstra <m.k.slofstra@umcg.nl>",
    "author": "Mariska Slofstra [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0400-0468>),\n  Sido Haakma [aut] (ORCID: <https://orcid.org/0000-0003-1278-9144>),\n  Tommy de Boer [aut] (ORCID: <https://orcid.org/0000-0002-4492-7225>),\n  Fleur Kelpin [aut] (ORCID: <https://orcid.org/0000-0003-1527-5130>),\n  MOLGENIS org [cph, fnd]",
    "url": "https://github.com/molgenis/molgenis-r-datashield/,\nhttps://molgenis.github.io/molgenis-r-datashield/",
    "bug_reports": "https://github.com/molgenis/molgenis-r-datashield/issues/",
    "repository": "https://cran.r-project.org/package=DSMolgenisArmadillo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DSMolgenisArmadillo 'DataSHIELD' Client for 'MOLGENIS Armadillo' 'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This package is the 'DataSHIELD' interface implementation to analyze data\n    shared on a 'MOLGENIS Armadillo' server. 'MOLGENIS Armadillo' is a\n    light-weight 'DataSHIELD' server using a file store and an 'RServe' server.  "
  },
  {
    "id": 2861,
    "package_name": "DSOpal",
    "title": "'DataSHIELD' Implementation for 'Opal'",
    "description": "'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This package is the 'DataSHIELD' interface implementation for 'Opal', which is\n    the data integration application for biobanks by 'OBiBa'. Participant data, once\n    collected from any data source, must be integrated and stored in a central\n    data repository under a uniform model. 'Opal' is such a central repository.\n    It can import, process, validate, query, analyze, report, and export data.\n    'Opal' is the reference implementation of the 'DataSHIELD' infrastructure.",
    "version": "1.5.0",
    "maintainer": "Yannick Marcon <yannick.marcon@obiba.org>",
    "author": "Yannick Marcon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0138-2023>),\n  Becca Wilson [ctb] (ORCID: <https://orcid.org/0000-0003-2294-593X>),\n  OBiBa group [cph]",
    "url": "https://github.com/datashield/DSOpal/,\nhttps://datashield.github.io/DSOpal/, https://www.obiba.org,\nhttps://www.obiba.org/pages/products/opal/,\nhttps://datashield.org/,\nhttps://academic.oup.com/ije/article/43/6/1929/707730,\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008880",
    "bug_reports": "https://github.com/datashield/DSOpal/issues/",
    "repository": "https://cran.r-project.org/package=DSOpal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DSOpal 'DataSHIELD' Implementation for 'Opal' 'DataSHIELD' is an infrastructure and series of R packages that \n    enables the remote and 'non-disclosive' analysis of sensitive research data.\n    This package is the 'DataSHIELD' interface implementation for 'Opal', which is\n    the data integration application for biobanks by 'OBiBa'. Participant data, once\n    collected from any data source, must be integrated and stored in a central\n    data repository under a uniform model. 'Opal' is such a central repository.\n    It can import, process, validate, query, analyze, report, and export data.\n    'Opal' is the reference implementation of the 'DataSHIELD' infrastructure.  "
  },
  {
    "id": 2882,
    "package_name": "DTSg",
    "title": "A Class for Working with Time Series Data Based on 'data.table'\nand 'R6' with Largely Optional Reference Semantics",
    "description": "Basic time series functionalities such as listing of missing\n    values, application of arbitrary aggregation as well as rolling (asymmetric)\n    window functions and automatic detection of periodicity. As it is mainly\n    based on 'data.table', it is fast and (in combination with the 'R6' package)\n    offers reference semantics. In addition to its native R6 interface, it\n    provides an S3 interface for those who prefer the latter. Finally yet\n    importantly, its functional approach allows for incorporating\n    functionalities from many other packages.",
    "version": "2.0.0",
    "maintainer": "Gerold Hepp <gisler@hepp.cc>",
    "author": "Gerold Hepp [aut, cre]",
    "url": "https://gisler.github.io/DTSg/",
    "bug_reports": "https://github.com/gisler/DTSg/issues",
    "repository": "https://cran.r-project.org/package=DTSg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DTSg A Class for Working with Time Series Data Based on 'data.table'\nand 'R6' with Largely Optional Reference Semantics Basic time series functionalities such as listing of missing\n    values, application of arbitrary aggregation as well as rolling (asymmetric)\n    window functions and automatic detection of periodicity. As it is mainly\n    based on 'data.table', it is fast and (in combination with the 'R6' package)\n    offers reference semantics. In addition to its native R6 interface, it\n    provides an S3 interface for those who prefer the latter. Finally yet\n    importantly, its functional approach allows for incorporating\n    functionalities from many other packages.  "
  },
  {
    "id": 2893,
    "package_name": "DYM",
    "title": "Did You Mean?",
    "description": "Add a \"Did You Mean\" feature to the R interactive. With this\n    package, error messages for misspelled input of variable names or package names\n    suggest what you really want to do in addition to notification of the mistake.",
    "version": "0.2",
    "maintainer": "Kosei Abe <mail@recyclebin.jp>",
    "author": "Kosei Abe [aut, cre], Richard Cotton [ctb]",
    "url": "",
    "bug_reports": "https://github.com/kos59125/DYM/issues",
    "repository": "https://cran.r-project.org/package=DYM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DYM Did You Mean? Add a \"Did You Mean\" feature to the R interactive. With this\n    package, error messages for misspelled input of variable names or package names\n    suggest what you really want to do in addition to notification of the mistake.  "
  },
  {
    "id": 2911,
    "package_name": "DataSetsVerse",
    "title": "A Metapackage for Thematic and Domain-Specific Datasets",
    "description": "A metapackage that brings together a curated collection \n    of R packages containing domain-specific datasets. It includes time series data, \n    educational metrics, crime records, medical datasets, and oncology research data. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to structured and well-documented datasets, this metapackage \n    facilitates reproducible research, data exploration, and teaching applications across \n    a wide range of domains.\n    Included packages:\n    - 'timeSeriesDataSets': Time series data from economics, finance, energy, and healthcare.\n    - 'educationR': Datasets related to education, learning outcomes, and school metrics.\n    - 'crimedatasets': Datasets on global and local crime and criminal behavior.\n    - 'MedDataSets': Datasets related to medicine, public health, treatments, and clinical trials.\n    - 'OncoDataSets': Datasets focused on cancer research, survival, genetics, and biomarkers.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/datasetsverse,\nhttps://lightbluetitan.github.io/datasetsverse/",
    "bug_reports": "https://github.com/lightbluetitan/datasetsverse/issues",
    "repository": "https://cran.r-project.org/package=DataSetsVerse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DataSetsVerse A Metapackage for Thematic and Domain-Specific Datasets A metapackage that brings together a curated collection \n    of R packages containing domain-specific datasets. It includes time series data, \n    educational metrics, crime records, medical datasets, and oncology research data. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to structured and well-documented datasets, this metapackage \n    facilitates reproducible research, data exploration, and teaching applications across \n    a wide range of domains.\n    Included packages:\n    - 'timeSeriesDataSets': Time series data from economics, finance, energy, and healthcare.\n    - 'educationR': Datasets related to education, learning outcomes, and school metrics.\n    - 'crimedatasets': Datasets on global and local crime and criminal behavior.\n    - 'MedDataSets': Datasets related to medicine, public health, treatments, and clinical trials.\n    - 'OncoDataSets': Datasets focused on cancer research, survival, genetics, and biomarkers.  "
  },
  {
    "id": 2948,
    "package_name": "DescTools",
    "title": "Tools for Descriptive Statistics",
    "description": "A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.",
    "version": "0.99.60",
    "maintainer": "Andri Signorell <andri@signorell.net>",
    "author": "Andri Signorell [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4311-1969>),\n  Ken Aho [ctb],\n  Andreas Alfons [ctb],\n  Nanina Anderegg [ctb],\n  Tomas Aragon [ctb],\n  Chandima Arachchige [ctb],\n  Antti Arppe [ctb],\n  Adrian Baddeley [ctb],\n  Kamil Barton [ctb],\n  Ben Bolker [ctb],\n  Hans W. Borchers [ctb],\n  Frederico Caeiro [ctb],\n  Stephane Champely [ctb],\n  Daniel Chessel [ctb],\n  Leanne Chhay [ctb],\n  Nicholas Cooper [ctb],\n  Clint Cummins [ctb],\n  Michael Dewey [ctb],\n  Harold C. Doran [ctb],\n  Stephane Dray [ctb],\n  Charles Dupont [ctb],\n  Dirk Eddelbuettel [ctb],\n  Claus Ekstrom [ctb],\n  Martin Elff [ctb],\n  Jeff Enos [ctb],\n  Richard W. Farebrother [ctb],\n  John Fox [ctb],\n  Romain Francois [ctb],\n  Michael Friendly [ctb],\n  Tal Galili [ctb],\n  Matthias Gamer [ctb],\n  Joseph L. Gastwirth [ctb],\n  Vilmantas Gegzna [ctb],\n  Yulia R. Gel [ctb],\n  Sereina Graber [ctb],\n  Juergen Gross [ctb],\n  Gabor Grothendieck [ctb],\n  Frank E. Harrell Jr [ctb],\n  Richard Heiberger [ctb],\n  Michael Hoehle [ctb],\n  Christian W. Hoffmann [ctb],\n  Soeren Hojsgaard [ctb],\n  Torsten Hothorn [ctb],\n  Markus Huerzeler [ctb],\n  Wallace W. Hui [ctb],\n  Pete Hurd [ctb],\n  Rob J. Hyndman [ctb],\n  Christopher Jackson [ctb],\n  Matthias Kohl [ctb],\n  Mikko Korpela [ctb],\n  Max Kuhn [ctb],\n  Detlew Labes [ctb],\n  Friederich Leisch [ctb],\n  Jim Lemon [ctb],\n  Dong Li [ctb],\n  Martin Maechler [ctb],\n  Arni Magnusson [ctb],\n  Ben Mainwaring [ctb],\n  Daniel Malter [ctb],\n  George Marsaglia [ctb],\n  John Marsaglia [ctb],\n  Alina Matei [ctb],\n  David Meyer [ctb],\n  Weiwen Miao [ctb],\n  Giovanni Millo [ctb],\n  Yongyi Min [ctb],\n  David Mitchell [ctb],\n  Cyril Flurin Moser [ctb],\n  Franziska Mueller [ctb],\n  Markus Naepflin [ctb],\n  Danielle Navarro [ctb],\n  Henric Nilsson [ctb],\n  Klaus Nordhausen [ctb],\n  Derek Ogle [ctb],\n  Hong Ooi [ctb],\n  Nick Parsons [ctb],\n  Sandrine Pavoine [ctb],\n  Tony Plate [ctb],\n  Luke Prendergast [ctb],\n  Roland Rapold [ctb],\n  William Revelle [ctb],\n  Tyler Rinker [ctb],\n  Brian D. Ripley [ctb],\n  Caroline Rodriguez [ctb],\n  Nathan Russell [ctb],\n  Nick Sabbe [ctb],\n  Ralph Scherer [ctb],\n  Venkatraman E. Seshan [ctb],\n  Michael Smithson [ctb],\n  Greg Snow [ctb],\n  Karline Soetaert [ctb],\n  Werner A. Stahel [ctb],\n  Alec Stephenson [ctb],\n  Mark Stevenson [ctb],\n  Ralf Stubner [ctb],\n  Matthias Templ [ctb],\n  Duncan Temple Lang [ctb],\n  Terry Therneau [ctb],\n  Yves Tille [ctb],\n  Luis Torgo [ctb],\n  Adrian Trapletti [ctb],\n  Joshua Ulrich [ctb],\n  Kevin Ushey [ctb],\n  Jeremy VanDerWal [ctb],\n  Bill Venables [ctb],\n  John Verzani [ctb],\n  Pablo J. Villacorta Iglesias [ctb],\n  Gregory R. Warnes [ctb],\n  Stefan Wellek [ctb],\n  Hadley Wickham [ctb],\n  Rand R. Wilcox [ctb],\n  Peter Wolf [ctb],\n  Daniel Wollschlaeger [ctb],\n  Joseph Wood [ctb],\n  Ying Wu [ctb],\n  Thomas Yee [ctb],\n  Achim Zeileis [ctb]",
    "url": "https://andrisignorell.github.io/DescTools/,\nhttps://github.com/AndriSignorell/DescTools/",
    "bug_reports": "https://github.com/AndriSignorell/DescTools/issues",
    "repository": "https://cran.r-project.org/package=DescTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DescTools Tools for Descriptive Statistics A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.  "
  },
  {
    "id": 3016,
    "package_name": "DoE.MIParray",
    "title": "Creation of Arrays by Mixed Integer Programming",
    "description": "'CRAN' packages 'DoE.base' and 'Rmosek' and non-'CRAN' package 'gurobi' are enhanced with functionality for the creation of optimized arrays for experimentation, where optimization is in terms of generalized minimum aberration. It is also possible to optimally extend existing arrays to larger run size. The package writes 'MPS' (Mathematical Programming System) files for use with any mixed integer optimization software that can process such files. If at least one of the commercial products 'Gurobi' or 'Mosek' (free academic licenses available for both) is available, the package also creates arrays by optimization. For installing 'Gurobi' and its R package 'gurobi', follow instructions at <https://support.gurobi.com/hc/en-us/articles/14462206790033-How-do-I-install-Gurobi-for-R>. For installing 'Mosek' and its R package 'Rmosek', follow instructions at <https://www.mosek.com/downloads/> and <https://docs.mosek.com/8.1/rmosek/install-interface.html>, or use the functionality in the stump CRAN R package 'Rmosek'.",
    "version": "1.0-2",
    "maintainer": "Ulrike Groemping <ulrike.groemping@bht-berlin.de>",
    "author": "Ulrike Groemping [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DoE.MIParray",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DoE.MIParray Creation of Arrays by Mixed Integer Programming 'CRAN' packages 'DoE.base' and 'Rmosek' and non-'CRAN' package 'gurobi' are enhanced with functionality for the creation of optimized arrays for experimentation, where optimization is in terms of generalized minimum aberration. It is also possible to optimally extend existing arrays to larger run size. The package writes 'MPS' (Mathematical Programming System) files for use with any mixed integer optimization software that can process such files. If at least one of the commercial products 'Gurobi' or 'Mosek' (free academic licenses available for both) is available, the package also creates arrays by optimization. For installing 'Gurobi' and its R package 'gurobi', follow instructions at <https://support.gurobi.com/hc/en-us/articles/14462206790033-How-do-I-install-Gurobi-for-R>. For installing 'Mosek' and its R package 'Rmosek', follow instructions at <https://www.mosek.com/downloads/> and <https://docs.mosek.com/8.1/rmosek/install-interface.html>, or use the functionality in the stump CRAN R package 'Rmosek'.  "
  },
  {
    "id": 3017,
    "package_name": "DoE.base",
    "title": "Full Factorials, Orthogonal Arrays and Base Utilities for DoE\nPackages",
    "description": "Creates full factorial experimental designs and designs based on orthogonal arrays for (industrial) experiments. Provides diverse quality criteria. Provides utility functions for the class design, which is also used by other packages for designed experiments.",
    "version": "1.2-5",
    "maintainer": "Ulrike Groemping <ulrike.groemping@bht-berlin.de>",
    "author": "Ulrike Groemping [aut, cre],\n  Boyko Amarov [ctb],\n  Hongquan Xu [ctb]",
    "url": "https://prof.bht-berlin.de/groemping/DoE/,\nhttps://prof.bht-berlin.de/groemping/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DoE.base",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DoE.base Full Factorials, Orthogonal Arrays and Base Utilities for DoE\nPackages Creates full factorial experimental designs and designs based on orthogonal arrays for (industrial) experiments. Provides diverse quality criteria. Provides utility functions for the class design, which is also used by other packages for designed experiments.  "
  },
  {
    "id": 3018,
    "package_name": "DoE.wrapper",
    "title": "Wrapper Package for Design of Experiments Functionality",
    "description": "Various kinds of designs for\n (industrial) experiments can be created. The package uses, and sometimes enhances,\n        design generation routines from other packages. \n        So far, response surface designs from package 'rsm', Latin hypercube\n        samples from packages 'lhs' and 'DiceDesign', and \n        D-optimal designs from package 'AlgDesign' have been implemented.",
    "version": "0.13",
    "maintainer": "Ulrike Groemping <ulrike.groemping@bht-berlin.de>",
    "author": "Ulrike Groemping [aut, cre],\n  Lenth Russ [ctb]",
    "url": "https://prof.bht-berlin.de/groemping/DoE/,\nhttps://prof.bht-berlin.de/groemping/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DoE.wrapper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DoE.wrapper Wrapper Package for Design of Experiments Functionality Various kinds of designs for\n (industrial) experiments can be created. The package uses, and sometimes enhances,\n        design generation routines from other packages. \n        So far, response surface designs from package 'rsm', Latin hypercube\n        samples from packages 'lhs' and 'DiceDesign', and \n        D-optimal designs from package 'AlgDesign' have been implemented.  "
  },
  {
    "id": 3170,
    "package_name": "EVI",
    "title": "Epidemic Volatility Index as an Early-Warning Tool",
    "description": "\n    This is an R package implementing the epidemic volatility index (EVI), as \n    discussed by Kostoulas et. al. (2021) and variations by Pateras et. al. (2023). EVI is a new, conceptually simple, early warning tool for oncoming epidemic waves. \n    EVI is based on the volatility of newly reported cases per unit of time,\n    ideally per day, and issues an early warning when the volatility change rate exceeds a threshold.",
    "version": "0.2.0-0",
    "maintainer": "Konstantinos Pateras <kostas.pateras@gmail.com>",
    "author": "Eletherios Meletis [aut],\n  Konstantinos Pateras [aut, cre],\n  Paolo Eusebi [aut],\n  Matt Denwood [aut],\n  Polychronis Kostoulas [aut]",
    "url": "https://www.nature.com/articles/s41598-021-02622-3",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EVI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EVI Epidemic Volatility Index as an Early-Warning Tool \n    This is an R package implementing the epidemic volatility index (EVI), as \n    discussed by Kostoulas et. al. (2021) and variations by Pateras et. al. (2023). EVI is a new, conceptually simple, early warning tool for oncoming epidemic waves. \n    EVI is based on the volatility of newly reported cases per unit of time,\n    ideally per day, and issues an early warning when the volatility change rate exceeds a threshold.  "
  },
  {
    "id": 3209,
    "package_name": "EgoCor",
    "title": "Simple Presentation of Estimated Exponential Semi-Variograms",
    "description": "User friendly interface based on the R package 'gstat' to fit\n    exponential parametric models to empirical semi-variograms in order to\n    model the spatial correlation structure of health data. Geo-located\n    health outcomes of survey participants may be used to model spatial\n    effects on health in an ego-centred approach.  The package contains a\n    range of functions to help explore the spatial structure of the data\n    as well as visualize the fit of exponential models for various\n    metaparameter combinations with respect to the number of lag intervals\n    and maximal distance.  Furthermore, the outcome of interest can be\n    adjusted for covariates by fitting a linear regression in a\n    preliminary step before the semi-variogram fitting process.",
    "version": "1.3.4",
    "maintainer": "Julia Dyck <j.dyck@uni-bielefeld.de>",
    "author": "Julia Dyck [aut, cre],\n  Odile Sauzet [aut],\n  Jan-Ole Koslik [aut]",
    "url": "https://github.com/julia-dyck/EgoCor",
    "bug_reports": "https://github.com/julia-dyck/EgoCor/issues",
    "repository": "https://cran.r-project.org/package=EgoCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EgoCor Simple Presentation of Estimated Exponential Semi-Variograms User friendly interface based on the R package 'gstat' to fit\n    exponential parametric models to empirical semi-variograms in order to\n    model the spatial correlation structure of health data. Geo-located\n    health outcomes of survey participants may be used to model spatial\n    effects on health in an ego-centred approach.  The package contains a\n    range of functions to help explore the spatial structure of the data\n    as well as visualize the fit of exponential models for various\n    metaparameter combinations with respect to the number of lag intervals\n    and maximal distance.  Furthermore, the outcome of interest can be\n    adjusted for covariates by fitting a linear regression in a\n    preliminary step before the semi-variogram fitting process.  "
  },
  {
    "id": 3234,
    "package_name": "EnvStats",
    "title": "Package for Environmental Statistics, Including US EPA Guidance",
    "description": "Graphical and statistical analyses of environmental data, with \n  focus on analyzing chemical concentrations and physical parameters, usually in \n  the context of mandated environmental monitoring.  Major environmental \n  statistical methods found in the literature and regulatory guidance documents, \n  with extensive help that explains what these methods do, how to use them, \n  and where to find them in the literature.  Numerous built-in data sets from \n  regulatory guidance documents and environmental statistics literature.  Includes \n  scripts reproducing analyses presented in the book \"EnvStats:  An R Package for \n  Environmental Statistics\" (Millard, 2013, Springer, ISBN 978-1-4614-8455-4, \n  <doi:10.1007/978-1-4614-8456-1>).",
    "version": "3.1.0",
    "maintainer": "Alexander Kowarik <alexander.kowarik@statistik.gv.at>",
    "author": "Steven P. Millard [aut],\n  Alexander Kowarik [ctb, cre] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>)",
    "url": "https://github.com/alexkowa/EnvStats,\nhttps://alexkowa.github.io/EnvStats/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EnvStats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EnvStats Package for Environmental Statistics, Including US EPA Guidance Graphical and statistical analyses of environmental data, with \n  focus on analyzing chemical concentrations and physical parameters, usually in \n  the context of mandated environmental monitoring.  Major environmental \n  statistical methods found in the literature and regulatory guidance documents, \n  with extensive help that explains what these methods do, how to use them, \n  and where to find them in the literature.  Numerous built-in data sets from \n  regulatory guidance documents and environmental statistics literature.  Includes \n  scripts reproducing analyses presented in the book \"EnvStats:  An R Package for \n  Environmental Statistics\" (Millard, 2013, Springer, ISBN 978-1-4614-8455-4, \n  <doi:10.1007/978-1-4614-8456-1>).  "
  },
  {
    "id": 3262,
    "package_name": "EstimDiagnostics",
    "title": "Diagnostic Tools and Unit Tests for Statistical Estimators",
    "description": "Extension of 'testthat' package to make unit tests on empirical distributions of estimators and functions for diagnostics of their finite-sample performance.",
    "version": "0.0.3",
    "maintainer": "Dmitry Otryakhin <d.otryakhin.acad@protonmail.ch>",
    "author": "Dmitry Otryakhin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4700-7221>)",
    "url": "https://gitlab.com/Dmitry_Otryakhin/diagnostics-and-tests-for-statistical-estimators",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=EstimDiagnostics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EstimDiagnostics Diagnostic Tools and Unit Tests for Statistical Estimators Extension of 'testthat' package to make unit tests on empirical distributions of estimators and functions for diagnostics of their finite-sample performance.  "
  },
  {
    "id": 3276,
    "package_name": "EventDetectR",
    "title": "Event Detection Framework",
    "description": "Detect events in time-series data. Combines multiple well-known R packages like 'forecast' and 'neuralnet' to deliver an easily configurable tool for multivariate event detection.",
    "version": "0.3.5",
    "maintainer": "Sowmya Chandrasekaran <sowzz.17@gmail.com>",
    "author": "Margarita Rebolledo [aut],\n  Sowmya Chandrasekaran [aut, cre],\n  Frederik Rehbach [aut],\n  Steffen Moritz [aut] (ORCID: <https://orcid.org/0000-0002-0085-1804>)",
    "url": "https://github.com/frehbach/EventDetectR",
    "bug_reports": "https://github.com/frehbach/EventDetectR/issues",
    "repository": "https://cran.r-project.org/package=EventDetectR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EventDetectR Event Detection Framework Detect events in time-series data. Combines multiple well-known R packages like 'forecast' and 'neuralnet' to deliver an easily configurable tool for multivariate event detection.  "
  },
  {
    "id": 3289,
    "package_name": "Exact",
    "title": "Unconditional Exact Test",
    "description": "Performs unconditional exact tests and power calculations for 2x2 contingency tables.\n  For comparing two independent proportions, performs Barnard's test (1945)\n  <doi:10.1038/156177a0> using the original CSM test (Barnard, 1947 <doi:10.1093/biomet/34.1-2.123>),\n  using Fisher's p-value referred to as Boschloo's test (1970) <doi:10.1111/j.1467-9574.1970.tb00104.x>,\n  or using a Z-statistic (Suissa and Shuster, 1985, <doi:10.2307/2981892>).\n  For comparing two binary proportions, performs unconditional exact test using McNemar's\n  Z-statistic (Berger and Sidik, 2003, <doi:10.1191/0962280203sm312ra>),\n  using McNemar's conditional p-value, using McNemar's Z-statistic with continuity correction,\n  or using CSM test.  Calculates confidence intervals for the difference in proportion.\n  This package interacts with pre-computed data available through the ExactData R package,\n  which is available in a 'drat' repository.\n  Install the ExactData R package from GitHub at <https://pcalhoun1.github.io/drat/>.\n  The ExactData R package is approximately 85 MB.",
    "version": "3.3",
    "maintainer": "Peter Calhoun <calhoun.peter@gmail.com>",
    "author": "Peter Calhoun [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Exact",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Exact Unconditional Exact Test Performs unconditional exact tests and power calculations for 2x2 contingency tables.\n  For comparing two independent proportions, performs Barnard's test (1945)\n  <doi:10.1038/156177a0> using the original CSM test (Barnard, 1947 <doi:10.1093/biomet/34.1-2.123>),\n  using Fisher's p-value referred to as Boschloo's test (1970) <doi:10.1111/j.1467-9574.1970.tb00104.x>,\n  or using a Z-statistic (Suissa and Shuster, 1985, <doi:10.2307/2981892>).\n  For comparing two binary proportions, performs unconditional exact test using McNemar's\n  Z-statistic (Berger and Sidik, 2003, <doi:10.1191/0962280203sm312ra>),\n  using McNemar's conditional p-value, using McNemar's Z-statistic with continuity correction,\n  or using CSM test.  Calculates confidence intervals for the difference in proportion.\n  This package interacts with pre-computed data available through the ExactData R package,\n  which is available in a 'drat' repository.\n  Install the ExactData R package from GitHub at <https://pcalhoun1.github.io/drat/>.\n  The ExactData R package is approximately 85 MB.  "
  },
  {
    "id": 3312,
    "package_name": "ExtMallows",
    "title": "An Extended Mallows Model and Its Hierarchical Version for\nRanked Data Aggregation",
    "description": "For multiple full/partial ranking lists, R package 'ExtMallows' can (1) detect whether the input ranking lists are over-correlated, and (2) use the Mallows model or extended Mallows model to integrate the ranking lists, and (3) use hierarchical extended Mallows model for rank integration if there are groups of over-correlated ranking lists.",
    "version": "0.1.0",
    "maintainer": "Han Li <hli@szu.edu.cn>",
    "author": "Han Li, Minxuan Xu, Jun S. Liu and Xiaodan Fan",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ExtMallows",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ExtMallows An Extended Mallows Model and Its Hierarchical Version for\nRanked Data Aggregation For multiple full/partial ranking lists, R package 'ExtMallows' can (1) detect whether the input ranking lists are over-correlated, and (2) use the Mallows model or extended Mallows model to integrate the ranking lists, and (3) use hierarchical extended Mallows model for rank integration if there are groups of over-correlated ranking lists.  "
  },
  {
    "id": 3335,
    "package_name": "FAVA",
    "title": "Quantify Compositional Variability Across Relative Abundance\nVectors",
    "description": "Implements the statistic FAVA, an Fst-based Assessment of Variability across \n  vectors of relative Abundances, as well as a suite of helper functions which enable the \n  visualization and statistical analysis of relative abundance data. The 'FAVA' R package \n  accompanies the paper, \u201cQuantifying compositional variability in microbial communities\n  with FAVA\u201d by Morrison, Xue, and Rosenberg (2025) <doi:10.1073/pnas.2413211122>.",
    "version": "1.0.9",
    "maintainer": "Maike Morrison <maike.morrison@gmail.com>",
    "author": "Maike Morrison [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0430-1401>)",
    "url": "https://maikemorrison.github.io/FAVA/,\nhttps://maikemorrison.github.io/FAVA/articles/microbiome_tutorial.html",
    "bug_reports": "https://github.com/MaikeMorrison/FAVA/issues",
    "repository": "https://cran.r-project.org/package=FAVA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FAVA Quantify Compositional Variability Across Relative Abundance\nVectors Implements the statistic FAVA, an Fst-based Assessment of Variability across \n  vectors of relative Abundances, as well as a suite of helper functions which enable the \n  visualization and statistical analysis of relative abundance data. The 'FAVA' R package \n  accompanies the paper, \u201cQuantifying compositional variability in microbial communities\n  with FAVA\u201d by Morrison, Xue, and Rosenberg (2025) <doi:10.1073/pnas.2413211122>.  "
  },
  {
    "id": 3440,
    "package_name": "FamEvent",
    "title": "Family Age-at-Onset Data Simulation and Penetrance Estimation",
    "description": "Simulates age-at-onset traits associated with a segregating major gene in family data \n     obtained from population-based, clinic-based, or multi-stage designs. Appropriate ascertainment \n     correction is utilized to estimate age-dependent penetrance functions either parametrically from \n     the fitted model or nonparametrically from the data. The Expectation and Maximization algorithm \n     can infer missing genotypes and carrier probabilities estimated from family's genotype and\n     phenotype information or from a fitted model. Plot functions include pedigrees of simulated \n     families and predicted penetrance curves based on specified parameter values.\n     For more information see Choi, Y.-H., Briollais, L., He, W. and Kopciuk, K. (2021) FamEvent: An \n     R Package for Generating and Modeling Time-to-Event Data in Family Designs, \n     Journal of Statistical Software 97 (7), 1-30.",
    "version": "3.2",
    "maintainer": "Yun-Hee Choi <yun-hee.choi@schulich.uwo.ca>",
    "author": "Yun-Hee Choi, Karen Kopciuk, Wenqing He, Laurent Briollais",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FamEvent",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FamEvent Family Age-at-Onset Data Simulation and Penetrance Estimation Simulates age-at-onset traits associated with a segregating major gene in family data \n     obtained from population-based, clinic-based, or multi-stage designs. Appropriate ascertainment \n     correction is utilized to estimate age-dependent penetrance functions either parametrically from \n     the fitted model or nonparametrically from the data. The Expectation and Maximization algorithm \n     can infer missing genotypes and carrier probabilities estimated from family's genotype and\n     phenotype information or from a fitted model. Plot functions include pedigrees of simulated \n     families and predicted penetrance curves based on specified parameter values.\n     For more information see Choi, Y.-H., Briollais, L., He, W. and Kopciuk, K. (2021) FamEvent: An \n     R Package for Generating and Modeling Time-to-Event Data in Family Designs, \n     Journal of Statistical Software 97 (7), 1-30.  "
  },
  {
    "id": 3458,
    "package_name": "FastUtils",
    "title": "Fast, Readable Utility Functions",
    "description": "A wide variety of tools for general data analysis, wrangling, spelling, statistics, visualizations, package development, and more. All functions have vectorized implementations whenever possible. Exported names are designed to be readable, with longer names possessing short aliases.",
    "version": "0.2.1",
    "maintainer": "Qile Yang <qile.yang@berkeley.edu>",
    "author": "Qile Yang [cre, aut, cph]",
    "url": "https://github.com/Qile0317/FastUtils,\nhttps://qile0317.github.io/FastUtils/",
    "bug_reports": "https://github.com/Qile0317/FastUtils/issues/",
    "repository": "https://cran.r-project.org/package=FastUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FastUtils Fast, Readable Utility Functions A wide variety of tools for general data analysis, wrangling, spelling, statistics, visualizations, package development, and more. All functions have vectorized implementations whenever possible. Exported names are designed to be readable, with longer names possessing short aliases.  "
  },
  {
    "id": 3465,
    "package_name": "FeatureTerminatoR",
    "title": "Feature Selection Engine to Remove Features with Minimal\nPredictive Power",
    "description": "The aim is to take in data.frame inputs and utilises methods, such as recursive feature engineering, to enable the features to be removed.\n    What this does differently from the other packages, is that it gives you the choice to remove the variables manually, or it automated this process.\n    Feature selection is a concept in machine learning, and statistical pipelines, whereby unimportant, or less predictive variables are eliminated from the analysis, see Boughaci (2018) <doi:10.1007/s40595-018-0107-y>. ",
    "version": "1.0.0",
    "maintainer": "Gary Hutson <hutsons-hacks@outlook.com>",
    "author": "Gary Hutson [aut, cre] (ORCID: <https://orcid.org/0000-0003-3534-6143>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FeatureTerminatoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FeatureTerminatoR Feature Selection Engine to Remove Features with Minimal\nPredictive Power The aim is to take in data.frame inputs and utilises methods, such as recursive feature engineering, to enable the features to be removed.\n    What this does differently from the other packages, is that it gives you the choice to remove the variables manually, or it automated this process.\n    Feature selection is a concept in machine learning, and statistical pipelines, whereby unimportant, or less predictive variables are eliminated from the analysis, see Boughaci (2018) <doi:10.1007/s40595-018-0107-y>.   "
  },
  {
    "id": 3473,
    "package_name": "FieldSimR",
    "title": "Simulation of Plot Errors and Phenotypes in Plant Breeding Field\nTrials",
    "description": "Simulates plot data in multi-environment field trials with one or more traits. \n  Its core function generates plot errors that capture spatial trend, random error (noise), \n  and extraneous variation, which are combined at a user-defined ratio. \n  Phenotypes can be generated by combining the plot errors with simulated genetic values that capture \n  genotype-by-environment (GxE) interaction using wrapper functions for the R package `AlphaSimR`.",
    "version": "1.4.0",
    "maintainer": "Christian Werner <werner.christian@proton.me>",
    "author": "Christian Werner [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9400-5061>),\n  Daniel Tolhurst [aut] (ORCID: <https://orcid.org/0000-0002-4787-080X>),\n  Jon Bancic [ctb]",
    "url": "https://github.com/crWerner/fieldsimr,\nhttps://crwerner.github.io/fieldsimr/",
    "bug_reports": "https://github.com/crWerner/fieldsimr/issues",
    "repository": "https://cran.r-project.org/package=FieldSimR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FieldSimR Simulation of Plot Errors and Phenotypes in Plant Breeding Field\nTrials Simulates plot data in multi-environment field trials with one or more traits. \n  Its core function generates plot errors that capture spatial trend, random error (noise), \n  and extraneous variation, which are combined at a user-defined ratio. \n  Phenotypes can be generated by combining the plot errors with simulated genetic values that capture \n  genotype-by-environment (GxE) interaction using wrapper functions for the R package `AlphaSimR`.  "
  },
  {
    "id": 3545,
    "package_name": "FuncMap",
    "title": "Hive Plots of R Package Function Calls",
    "description": "Analyzes the function calls in an R package and creates a hive plot of the calls, dividing them among functions that only make outgoing calls (sources), functions that have only incoming calls (sinks), and those that have both incoming calls and make outgoing calls (managers).  Function calls can be mapped by their absolute numbers, their normalized absolute numbers, or their rank.  FuncMap should be useful for comparing packages at a high level for their overall design.  Plus, it's just plain fun.  The hive plot concept was developed by Martin Krzywinski (www.hiveplot.com) and inspired this package.  Note: this package is maintained for historical reasons. HiveR is a full package for creating hive plots.",
    "version": "1.0.10",
    "maintainer": "Bryan A. Hanson <hanson@depauw.edu>",
    "author": "Bryan A. Hanson DePauw University, Greencastle Indiana USA",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FuncMap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FuncMap Hive Plots of R Package Function Calls Analyzes the function calls in an R package and creates a hive plot of the calls, dividing them among functions that only make outgoing calls (sources), functions that have only incoming calls (sinks), and those that have both incoming calls and make outgoing calls (managers).  Function calls can be mapped by their absolute numbers, their normalized absolute numbers, or their rank.  FuncMap should be useful for comparing packages at a high level for their overall design.  Plus, it's just plain fun.  The hive plot concept was developed by Martin Krzywinski (www.hiveplot.com) and inspired this package.  Note: this package is maintained for historical reasons. HiveR is a full package for creating hive plots.  "
  },
  {
    "id": 3555,
    "package_name": "FuzzyImputationTest",
    "title": "Imputation Procedures and Quality Tests for Fuzzy Data",
    "description": "Special procedures for the imputation of missing fuzzy numbers are still underdeveloped. The goal of the package is to provide the new d-imputation method (DIMP for short, Romaniuk, M. and Grzegorzewski, P. (2023) \"Fuzzy Data Imputation with DIMP and FGAIN\" RB/23/2023) and covert some classical ones applied in R packages ('missForest','miceRanger','knn') for use with fuzzy datasets. Additionally, specially tailored benchmarking tests are provided to check and compare these imputation procedures with fuzzy datasets.",
    "version": "0.5.2",
    "maintainer": "Maciej Romaniuk <mroman@ibspan.waw.pl>",
    "author": "Maciej Romaniuk [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-9649-396X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FuzzyImputationTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FuzzyImputationTest Imputation Procedures and Quality Tests for Fuzzy Data Special procedures for the imputation of missing fuzzy numbers are still underdeveloped. The goal of the package is to provide the new d-imputation method (DIMP for short, Romaniuk, M. and Grzegorzewski, P. (2023) \"Fuzzy Data Imputation with DIMP and FGAIN\" RB/23/2023) and covert some classical ones applied in R packages ('missForest','miceRanger','knn') for use with fuzzy datasets. Additionally, specially tailored benchmarking tests are provided to check and compare these imputation procedures with fuzzy datasets.  "
  },
  {
    "id": 3578,
    "package_name": "GALLO",
    "title": "Genomic Annotation in Livestock for Positional Candidate LOci",
    "description": "The accurate annotation of genes and Quantitative Trait Loci (QTLs) located within candidate markers and/or regions (haplotypes, windows, CNVs, etc) is a crucial step the most common genomic analyses performed in livestock, such as Genome-Wide Association Studies or transcriptomics. The Genomic Annotation in Livestock for positional candidate LOci (GALLO) is an R package designed to provide an intuitive and straightforward environment to annotate positional candidate genes and QTLs from high-throughput genetic studies in livestock. Moreover, GALLO allows the graphical visualization of gene and QTL annotation results, data comparison among different grouping factors (e.g., methods, breeds, tissues, statistical models, studies, etc.), and QTL enrichment in different livestock species including cattle, pigs, sheep, and chicken, among others.",
    "version": "1.5",
    "maintainer": "Pablo Fonseca <pfonseca@uoguelph.ca>",
    "author": "Pablo Fonseca [aut, cre],\n  Aroa Suarez-Vega [aut],\n  Gabriele Marras [aut],\n  Angela C\u00e1novas [aut]",
    "url": "<https://github.com/pablobio/GALLO>",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GALLO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GALLO Genomic Annotation in Livestock for Positional Candidate LOci The accurate annotation of genes and Quantitative Trait Loci (QTLs) located within candidate markers and/or regions (haplotypes, windows, CNVs, etc) is a crucial step the most common genomic analyses performed in livestock, such as Genome-Wide Association Studies or transcriptomics. The Genomic Annotation in Livestock for positional candidate LOci (GALLO) is an R package designed to provide an intuitive and straightforward environment to annotate positional candidate genes and QTLs from high-throughput genetic studies in livestock. Moreover, GALLO allows the graphical visualization of gene and QTL annotation results, data comparison among different grouping factors (e.g., methods, breeds, tissues, statistical models, studies, etc.), and QTL enrichment in different livestock species including cattle, pigs, sheep, and chicken, among others.  "
  },
  {
    "id": 3621,
    "package_name": "GENLIB",
    "title": "Genealogical Data Analysis",
    "description": "Genealogical data analysis including descriptive statistics (e.g., kinship and inbreeding coefficients) and gene-dropping simulations. See: \"GENLIB: an R package for the analysis of genealogical data\" Gauvin et al. (2015) <doi:10.1186/s12859-015-0581-5>.",
    "version": "1.1.10",
    "maintainer": "Marie-Helene Roy-Gagnon <r.genlib@gmail.com>",
    "author": "Louis Houde [aut],\n  Jean-Francois Lefebvre [aut],\n  Valery Roy-Lagace [aut],\n  Sebastien Lemieux [aut],\n  Michael J. Fromberger [ctb],\n  Jarno van der Kolk [ctb],\n  Mohan Rakesh [ctb],\n  Marie-Helene Roy-Gagnon [cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GENLIB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GENLIB Genealogical Data Analysis Genealogical data analysis including descriptive statistics (e.g., kinship and inbreeding coefficients) and gene-dropping simulations. See: \"GENLIB: an R package for the analysis of genealogical data\" Gauvin et al. (2015) <doi:10.1186/s12859-015-0581-5>.  "
  },
  {
    "id": 3644,
    "package_name": "GGIRread",
    "title": "Wearable Accelerometer Data File Readers",
    "description": "Reads data collected from wearable acceleratometers as used in sleep and physical activity research. Currently supports file formats: binary data from 'GENEActiv' <https://activinsights.com/>, .bin-format from GENEA devices (not for sale), and .cwa-format from 'Axivity' <https://axivity.com>. Further, it has functions for reading text files with epoch level aggregates from 'Actical', 'Fitbit', 'Actiwatch', 'ActiGraph', and 'PhilipsHealthBand'. Primarily designed to complement R package GGIR <https://CRAN.R-project.org/package=GGIR>.",
    "version": "1.0.7",
    "maintainer": "Vincent T van Hees <v.vanhees@accelting.com>",
    "author": "Vincent T van Hees [aut, cre],\n  Patrick Bos [aut] (ORCID: <https://orcid.org/0000-0002-6033-960X>),\n  Lena Kushleyeva [ctb],\n  Jing Hua Zhao [ctb],\n  Evgeny Mirkes [ctb],\n  Dan Jackson [ctb],\n  Jairo H Migueles [ctb],\n  Medical Research Council UK [cph, fnd],\n  Accelting [cph, fnd]",
    "url": "https://github.com/wadpac/GGIRread/",
    "bug_reports": "https://github.com/wadpac/GGIRread/issues",
    "repository": "https://cran.r-project.org/package=GGIRread",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GGIRread Wearable Accelerometer Data File Readers Reads data collected from wearable acceleratometers as used in sleep and physical activity research. Currently supports file formats: binary data from 'GENEActiv' <https://activinsights.com/>, .bin-format from GENEA devices (not for sale), and .cwa-format from 'Axivity' <https://axivity.com>. Further, it has functions for reading text files with epoch level aggregates from 'Actical', 'Fitbit', 'Actiwatch', 'ActiGraph', and 'PhilipsHealthBand'. Primarily designed to complement R package GGIR <https://CRAN.R-project.org/package=GGIR>.  "
  },
  {
    "id": 3648,
    "package_name": "GGally",
    "title": "Extension to 'ggplot2'",
    "description": "The R package 'ggplot2' is a plotting system based on the\n    grammar of graphics.  'GGally' extends 'ggplot2' by adding several\n    functions to reduce the complexity of combining geometric objects with\n    transformed data.  Some of these functions include a pairwise plot\n    matrix, a two group pairwise plot matrix, a parallel coordinates plot,\n    a survival plot, and several functions to plot networks.",
    "version": "2.4.0",
    "maintainer": "Barret Schloerke <schloerke@gmail.com>",
    "author": "Barret Schloerke [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9986-114X>),\n  Di Cook [aut, ths] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Joseph Larmarange [aut] (ORCID:\n    <https://orcid.org/0000-0001-7097-700X>),\n  Francois Briatte [aut],\n  Moritz Marbach [aut],\n  Edwin Thoen [aut],\n  Amos Elberg [aut],\n  Ott Toomet [ctb],\n  Jason Crowley [aut],\n  Heike Hofmann [ths] (ORCID: <https://orcid.org/0000-0001-6216-5183>),\n  Hadley Wickham [ths] (ORCID: <https://orcid.org/0000-0003-4757-117X>)",
    "url": "https://ggobi.github.io/ggally/, https://github.com/ggobi/ggally",
    "bug_reports": "https://github.com/ggobi/ggally/issues",
    "repository": "https://cran.r-project.org/package=GGally",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GGally Extension to 'ggplot2' The R package 'ggplot2' is a plotting system based on the\n    grammar of graphics.  'GGally' extends 'ggplot2' by adding several\n    functions to reduce the complexity of combining geometric objects with\n    transformed data.  Some of these functions include a pairwise plot\n    matrix, a two group pairwise plot matrix, a parallel coordinates plot,\n    a survival plot, and several functions to plot networks.  "
  },
  {
    "id": 3661,
    "package_name": "GISINTEGRATION",
    "title": "GIS Integration",
    "description": "Designed to facilitate the preprocessing and linking of GIS (Geographic Information System) databases\n  <https://www.sciencedirect.com/topics/computer-science/gis-database>,\n  the R package 'GISINTEGRATION' offers a robust solution for efficiently preparing  GIS data for advanced \n  spatial analyses. This package excels in simplifying intrica  procedures like data cleaning, normalization, \n  and format conversion, ensuring that the data are optimally primed for precise and thorough analysis.",
    "version": "1.0",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Leila Marvian Mashhad [aut, cre],\n  Sara Stewart [aut],\n  Steve Macfeelys [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GISINTEGRATION",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GISINTEGRATION GIS Integration Designed to facilitate the preprocessing and linking of GIS (Geographic Information System) databases\n  <https://www.sciencedirect.com/topics/computer-science/gis-database>,\n  the R package 'GISINTEGRATION' offers a robust solution for efficiently preparing  GIS data for advanced \n  spatial analyses. This package excels in simplifying intrica  procedures like data cleaning, normalization, \n  and format conversion, ensuring that the data are optimally primed for precise and thorough analysis.  "
  },
  {
    "id": 3676,
    "package_name": "GLMcat",
    "title": "Generalized Linear Models for Categorical Responses",
    "description": "In statistical modeling, there is a wide variety of regression models for categorical dependent variables (nominal or ordinal data); yet, there is no software embracing all these models together in a uniform and generalized format. Following the methodology proposed by Peyhardi, Trottier, and Gu\u00e9don (2015) <doi:10.1093/biomet/asv042>, we introduce 'GLMcat', an R package to estimate generalized linear models implemented under the unified specification (r, F, Z). Where r represents the ratio of probabilities (reference, cumulative, adjacent, or sequential), F the cumulative cdf function for the linkage, and Z, the design matrix. The package accompanies the paper \"GLMcat: An R Package for Generalized Linear Models for Categorical Responses\" in the Journal of Statistical Software, Volume 114, Issue 9 (see <doi:10.18637/jss.v114.i09>).",
    "version": "1.0.0",
    "maintainer": "Lorena Le\u00f3n <ylorenaleonv@gmail.com>",
    "author": "Lorena Le\u00f3n [aut, cre],\n  Jean Peyhardi [aut],\n  Catherine Trottier [aut]",
    "url": "https://github.com/ylleonv/GLMcat",
    "bug_reports": "https://github.com/ylleonv/GLMcat/issues",
    "repository": "https://cran.r-project.org/package=GLMcat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GLMcat Generalized Linear Models for Categorical Responses In statistical modeling, there is a wide variety of regression models for categorical dependent variables (nominal or ordinal data); yet, there is no software embracing all these models together in a uniform and generalized format. Following the methodology proposed by Peyhardi, Trottier, and Gu\u00e9don (2015) <doi:10.1093/biomet/asv042>, we introduce 'GLMcat', an R package to estimate generalized linear models implemented under the unified specification (r, F, Z). Where r represents the ratio of probabilities (reference, cumulative, adjacent, or sequential), F the cumulative cdf function for the linkage, and Z, the design matrix. The package accompanies the paper \"GLMcat: An R Package for Generalized Linear Models for Categorical Responses\" in the Journal of Statistical Software, Volume 114, Issue 9 (see <doi:10.18637/jss.v114.i09>).  "
  },
  {
    "id": 3718,
    "package_name": "GPUmatrix",
    "title": "Basic Linear Algebra with GPU",
    "description": "GPUs are great resources for data analysis, especially in statistics and linear algebra. Unfortunately, very few packages connect R to the GPU, and none of them are transparent enough to run the computations on the GPU without substantial changes to the code. The maintenance of these packages is cumbersome: several of the earlier attempts have been removed from their respective repositories. It would be desirable to have a properly maintained R package that takes advantage of the GPU with minimal changes to the existing code. We have developed the GPUmatrix package (available on CRAN). GPUmatrix mimics the behavior of the Matrix package and extends R to use the GPU for computations. It includes single(FP32) and double(FP64) precision data types, and provides support for sparse matrices. It is easy to learn, and requires very few code changes to perform the operations on the GPU. GPUmatrix relies on either the Torch or Tensorflow R packages to perform the GPU operations. We have demonstrated its usefulness for several statistical applications and machine learning applications: non-negative matrix factorization, logistic regression and general linear models. We have also included a comparison of GPU and CPU performance on different matrix operations.",
    "version": "1.0.2",
    "maintainer": "Cesar Lobato-Fernandez <clobatofern@unav.es>",
    "author": "Cesar Lobato-Fernandez [aut, cre],\n  Juan A.Ferrer-Bonsoms [aut],\n  Angel Rubio [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GPUmatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GPUmatrix Basic Linear Algebra with GPU GPUs are great resources for data analysis, especially in statistics and linear algebra. Unfortunately, very few packages connect R to the GPU, and none of them are transparent enough to run the computations on the GPU without substantial changes to the code. The maintenance of these packages is cumbersome: several of the earlier attempts have been removed from their respective repositories. It would be desirable to have a properly maintained R package that takes advantage of the GPU with minimal changes to the existing code. We have developed the GPUmatrix package (available on CRAN). GPUmatrix mimics the behavior of the Matrix package and extends R to use the GPU for computations. It includes single(FP32) and double(FP64) precision data types, and provides support for sparse matrices. It is easy to learn, and requires very few code changes to perform the operations on the GPU. GPUmatrix relies on either the Torch or Tensorflow R packages to perform the GPU operations. We have demonstrated its usefulness for several statistical applications and machine learning applications: non-negative matrix factorization, logistic regression and general linear models. We have also included a comparison of GPU and CPU performance on different matrix operations.  "
  },
  {
    "id": 3781,
    "package_name": "GWmodelVis",
    "title": "Visualization Tools for Geographically Weighted Models",
    "description": "\n    The increasing popularity of geographically weighted (GW) techniques has resulted in the development of several R packages, such as 'GWmodel'. To facilitate their usages, 'GWmodelVis' provides a 'shiny'-based interactive visualization toolkit for geographically weighted (GW) models.\n    It includes a number of visualization tools, including dynamic mapping of parameter surfaces, statistical visualization, sonification and exporting  videos via 'FFmpeg'. ",
    "version": "1.0.1",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "author": "Binbin Lu [aut, cre],\n  Huimei Wang [aut]",
    "url": "http://gwmodel.whu.edu.cn/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GWmodelVis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GWmodelVis Visualization Tools for Geographically Weighted Models \n    The increasing popularity of geographically weighted (GW) techniques has resulted in the development of several R packages, such as 'GWmodel'. To facilitate their usages, 'GWmodelVis' provides a 'shiny'-based interactive visualization toolkit for geographically weighted (GW) models.\n    It includes a number of visualization tools, including dynamic mapping of parameter surfaces, statistical visualization, sonification and exporting  videos via 'FFmpeg'.   "
  },
  {
    "id": 3908,
    "package_name": "HARplus",
    "title": "Enhanced R Package for 'GEMPACK' .har and .sl4 Files",
    "description": "Provides tools for processing and analyzing .har and .sl4 files, making it easier \n    for 'GEMPACK' users and 'GTAP' researchers to handle large economic datasets. \n    It simplifies the management of multiple experiment results, enabling faster \n    and more efficient comparisons without complexity. Users can extract, restructure, \n    and merge data seamlessly, ensuring compatibility across different tools. \n    The processed data can be exported and used in 'R', 'Stata', 'Python', 'Julia', or \n    any software that supports Text, CSV, or 'Excel' formats.",
    "version": "1.1.2",
    "maintainer": "Pattawee Puangchit <ppuangch@purdue.edu>",
    "author": "Pattawee Puangchit [aut, cre]",
    "url": "https://github.com/bodysbobb/HARplus/,\nhttps://www.pattawee-pp.com/HARplus/",
    "bug_reports": "https://github.com/bodysbobb/HARplus/issues/",
    "repository": "https://cran.r-project.org/package=HARplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HARplus Enhanced R Package for 'GEMPACK' .har and .sl4 Files Provides tools for processing and analyzing .har and .sl4 files, making it easier \n    for 'GEMPACK' users and 'GTAP' researchers to handle large economic datasets. \n    It simplifies the management of multiple experiment results, enabling faster \n    and more efficient comparisons without complexity. Users can extract, restructure, \n    and merge data seamlessly, ensuring compatibility across different tools. \n    The processed data can be exported and used in 'R', 'Stata', 'Python', 'Julia', or \n    any software that supports Text, CSV, or 'Excel' formats.  "
  },
  {
    "id": 3917,
    "package_name": "HCUPtools",
    "title": "Access and Work with HCUP Resources and Datasets",
    "description": "A comprehensive R package for accessing and working with publicly \n    available and free resources from the Agency for Healthcare Research and Quality \n    (AHRQ) Healthcare Cost and Utilization Project (HCUP). The package provides \n    streamlined access to HCUP's Clinical Classifications Software Refined (CCSR) \n    mapping files and Summary Trend Tables, enabling researchers and analysts to \n    efficiently map ICD-10-CM diagnosis codes and ICD-10-PCS procedure codes to \n    CCSR categories and access HCUP statistical reports. Key features include: \n    direct download from HCUP website, multiple output formats (long/wide/default), \n    cross-classification support, version management, citation generation, and \n    intelligent caching. The package does not redistribute HCUP data files but \n    facilitates direct download from the official HCUP website, ensuring users \n    always have access to the latest versions and maintain compliance with HCUP \n    data use policies. This package only accesses free public tools and reports; \n    it does NOT access HCUP databases (NIS, KID, SID, NEDS, etc.) that require \n    purchase. For more information, see <https://hcup-us.ahrq.gov/>.",
    "version": "1.0.0",
    "maintainer": "Vikrant Dev Rathore <rathore.vikrant@gmail.com>",
    "author": "Vikrant Dev Rathore [aut, cre]",
    "url": "https://github.com/vikrant31/HCUPtools,\nhttps://vikrant31.github.io/HCUPtools/",
    "bug_reports": "https://github.com/vikrant31/HCUPtools/issues",
    "repository": "https://cran.r-project.org/package=HCUPtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HCUPtools Access and Work with HCUP Resources and Datasets A comprehensive R package for accessing and working with publicly \n    available and free resources from the Agency for Healthcare Research and Quality \n    (AHRQ) Healthcare Cost and Utilization Project (HCUP). The package provides \n    streamlined access to HCUP's Clinical Classifications Software Refined (CCSR) \n    mapping files and Summary Trend Tables, enabling researchers and analysts to \n    efficiently map ICD-10-CM diagnosis codes and ICD-10-PCS procedure codes to \n    CCSR categories and access HCUP statistical reports. Key features include: \n    direct download from HCUP website, multiple output formats (long/wide/default), \n    cross-classification support, version management, citation generation, and \n    intelligent caching. The package does not redistribute HCUP data files but \n    facilitates direct download from the official HCUP website, ensuring users \n    always have access to the latest versions and maintain compliance with HCUP \n    data use policies. This package only accesses free public tools and reports; \n    it does NOT access HCUP databases (NIS, KID, SID, NEDS, etc.) that require \n    purchase. For more information, see <https://hcup-us.ahrq.gov/>.  "
  },
  {
    "id": 3930,
    "package_name": "HDMT",
    "title": "A Multiple Testing Procedure for High-Dimensional Mediation\nHypotheses",
    "description": "A multiple-testing procedure for high-dimensional mediation hypotheses. Mediation analysis is of rising interest in epidemiology and clinical trials. Among existing methods for mediation analyses, the popular joint significance (JS) test yields an overly conservative type I error rate and therefore low power. In the R package 'HDMT' we implement a multiple-testing procedure that accurately controls the family-wise error rate (FWER) and the false discovery rate (FDR) when using JS for testing high-dimensional mediation hypotheses. The core of our procedure is based on estimating the proportions of three component null hypotheses and deriving the corresponding mixture distribution of null p-values. Results of the data examples include better-behaved quantile-quantile plots and improved detection of novel mediation relationships on the role of DNA methylation in genetic regulation of gene expression. With increasing interest in mediation by molecular intermediaries such as gene expression, the proposed method addresses an unmet methodological challenge. Methods used in the package refer to James Y. Dai, Janet L. Stanford & Michael LeBlanc (2020) <doi:10.1080/01621459.2020.1765785>.",
    "version": "1.0.5",
    "maintainer": "James Dai <jdai@fredhutch.org>",
    "author": "James Dai [aut, cre],\n  Xiaoyu Wang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HDMT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HDMT A Multiple Testing Procedure for High-Dimensional Mediation\nHypotheses A multiple-testing procedure for high-dimensional mediation hypotheses. Mediation analysis is of rising interest in epidemiology and clinical trials. Among existing methods for mediation analyses, the popular joint significance (JS) test yields an overly conservative type I error rate and therefore low power. In the R package 'HDMT' we implement a multiple-testing procedure that accurately controls the family-wise error rate (FWER) and the false discovery rate (FDR) when using JS for testing high-dimensional mediation hypotheses. The core of our procedure is based on estimating the proportions of three component null hypotheses and deriving the corresponding mixture distribution of null p-values. Results of the data examples include better-behaved quantile-quantile plots and improved detection of novel mediation relationships on the role of DNA methylation in genetic regulation of gene expression. With increasing interest in mediation by molecular intermediaries such as gene expression, the proposed method addresses an unmet methodological challenge. Methods used in the package refer to James Y. Dai, Janet L. Stanford & Michael LeBlanc (2020) <doi:10.1080/01621459.2020.1765785>.  "
  },
  {
    "id": 3955,
    "package_name": "HIMA",
    "title": "High-Dimensional Mediation Analysis",
    "description": "Allows to estimate and test high-dimensional mediation effects based on advanced mediator screening and penalized regression techniques. Methods used in the package refer to Zhang H, Zheng Y, Hou L, Liu L, HIMA: An R Package for High-Dimensional Mediation Analysis. Journal of Data Science. (2025). <doi:10.6339/25-JDS1192>.",
    "version": "2.3.3",
    "maintainer": "Yinan Zheng <y-zheng@northwestern.edu>",
    "author": "Yinan Zheng [aut, cre] (ORCID: <https://orcid.org/0000-0002-2006-7320>),\n  Haixiang Zhang [aut],\n  Lifang Hou [aut],\n  Lei Liu [aut, cph]",
    "url": "https://github.com/YinanZheng/HIMA/",
    "bug_reports": "https://github.com/YinanZheng/HIMA/issues/",
    "repository": "https://cran.r-project.org/package=HIMA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HIMA High-Dimensional Mediation Analysis Allows to estimate and test high-dimensional mediation effects based on advanced mediator screening and penalized regression techniques. Methods used in the package refer to Zhang H, Zheng Y, Hou L, Liu L, HIMA: An R Package for High-Dimensional Mediation Analysis. Journal of Data Science. (2025). <doi:10.6339/25-JDS1192>.  "
  },
  {
    "id": 3969,
    "package_name": "HMMextra0s",
    "title": "Hidden Markov Models with Extra Zeros",
    "description": "Contains functions for hidden Markov models with observations having extra zeros as defined in the following two publications, Wang, T., Zhuang, J., Obara, K. and Tsuruoka, H. (2016) <doi:10.1111/rssc.12194>; Wang, T., Zhuang, J., Buckby, J., Obara, K. and Tsuruoka, H. (2018) <doi:10.1029/2017JB015360>. The observed response variable is either univariate or bivariate Gaussian conditioning on presence of events, and extra zeros mean that the response variable takes on the value zero if nothing is happening. Hence the response is modelled as a mixture distribution of a Bernoulli variable and a continuous variable. That is, if the Bernoulli variable takes on the value 1, then the response variable is Gaussian, and if the Bernoulli variable takes on the value 0, then the response is zero too. This package includes functions for simulation, parameter estimation, goodness-of-fit, the Viterbi algorithm, and plotting the classified 2-D data. Some of the functions in the package are based on those of the R package 'HiddenMarkov' by David Harte. This updated version has included an example dataset and R code examples to show how to transform the data into the objects needed in the main functions. We have also made changes to increase the speed of some of the functions.",
    "version": "1.1.0",
    "maintainer": "Ting Wang <ting.wang@otago.ac.nz>",
    "author": "Ting Wang, Wolfgang Hayek, and Alexander Pletzer",
    "url": "https://www.stats.otago.ac.nz/?people=ting_wang",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HMMextra0s",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HMMextra0s Hidden Markov Models with Extra Zeros Contains functions for hidden Markov models with observations having extra zeros as defined in the following two publications, Wang, T., Zhuang, J., Obara, K. and Tsuruoka, H. (2016) <doi:10.1111/rssc.12194>; Wang, T., Zhuang, J., Buckby, J., Obara, K. and Tsuruoka, H. (2018) <doi:10.1029/2017JB015360>. The observed response variable is either univariate or bivariate Gaussian conditioning on presence of events, and extra zeros mean that the response variable takes on the value zero if nothing is happening. Hence the response is modelled as a mixture distribution of a Bernoulli variable and a continuous variable. That is, if the Bernoulli variable takes on the value 1, then the response variable is Gaussian, and if the Bernoulli variable takes on the value 0, then the response is zero too. This package includes functions for simulation, parameter estimation, goodness-of-fit, the Viterbi algorithm, and plotting the classified 2-D data. Some of the functions in the package are based on those of the R package 'HiddenMarkov' by David Harte. This updated version has included an example dataset and R code examples to show how to transform the data into the objects needed in the main functions. We have also made changes to increase the speed of some of the functions.  "
  },
  {
    "id": 3980,
    "package_name": "HRW",
    "title": "Datasets, Functions and Scripts for Semiparametric Regression\nSupporting Harezlak, Ruppert & Wand (2018)",
    "description": "The book \"Semiparametric Regression with R\" by J. Harezlak, D. Ruppert & M.P. Wand (2018, Springer; ISBN: 978-1-4939-8851-8) makes use of datasets and scripts to explain semiparametric regression concepts. Each of the book's scripts are contained in this package as well as datasets that are not within other R packages. Functions that aid semiparametric regression analysis are also included.",
    "version": "1.0-5",
    "maintainer": "Matt P. Wand <matt.wand@uts.edu.au>",
    "author": "Jaroslaw Harezlak [aut],\n  David Ruppert [aut],\n  Matt P. Wand [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HRW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HRW Datasets, Functions and Scripts for Semiparametric Regression\nSupporting Harezlak, Ruppert & Wand (2018) The book \"Semiparametric Regression with R\" by J. Harezlak, D. Ruppert & M.P. Wand (2018, Springer; ISBN: 978-1-4939-8851-8) makes use of datasets and scripts to explain semiparametric regression concepts. Each of the book's scripts are contained in this package as well as datasets that are not within other R packages. Functions that aid semiparametric regression analysis are also included.  "
  },
  {
    "id": 4057,
    "package_name": "HybridMicrobiomes",
    "title": "Analysis of Host-Associated Microbiomes from Hybrid Organisms",
    "description": "A set of tools to analyze and visualize the relationships between host-associated microbiomes of hybrid organisms and those of their progenitor species. Though not necessary, installing the microViz package is recommended as a check for phyloseq objects. To install microViz from R Universe use the following command: install.packages(\"microViz\", repos = c(davidbarnett = \"https://david-barnett.r-universe.dev\", getOption(\"repos\"))). To install microViz from GitHub use the following commands: install.packages(\"devtools\") followed by devtools::install_github(\"david-barnett/microViz\").",
    "version": "0.1.1",
    "maintainer": "Sharon Bewick <sbewick@clemson.edu>",
    "author": "Benjamin Camper [aut],\n  Zachary Lauglin [ctb],\n  Daniel Malagon [ctb],\n  Robert Denton [ctb],\n  Sharon Bewick [aut, cre],\n  National Science Foundation Division of Integrative Organismal Systems\n    (award #2104605) [fnd],\n  Clemson University Support for Early Exploration and Development (CU\n    SEED) Grant [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HybridMicrobiomes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HybridMicrobiomes Analysis of Host-Associated Microbiomes from Hybrid Organisms A set of tools to analyze and visualize the relationships between host-associated microbiomes of hybrid organisms and those of their progenitor species. Though not necessary, installing the microViz package is recommended as a check for phyloseq objects. To install microViz from R Universe use the following command: install.packages(\"microViz\", repos = c(davidbarnett = \"https://david-barnett.r-universe.dev\", getOption(\"repos\"))). To install microViz from GitHub use the following commands: install.packages(\"devtools\") followed by devtools::install_github(\"david-barnett/microViz\").  "
  },
  {
    "id": 4073,
    "package_name": "IBDInfer",
    "title": "Design-Based Causal Inference Method for Incomplete Block\nDesigns",
    "description": "This R package implements methods for estimation and inference under Incomplete Block Designs and Balanced Incomplete Block Designs within a design-based finite-population framework. Based on 'Koo and Pashley' (2024) <arXiv:2405.19312>, it includes block-level estimators and extends to unit-level effects using 'Horvitz-Thompson' and 'H\u00e1jek' estimators. The package also provides asymptotic confidence intervals to support valid statistical inference.",
    "version": "0.0.1",
    "maintainer": "Taehyeon Koo <tk587@stat.rutgers.edu>",
    "author": "Taehyeon Koo [aut, cre],\n  Nicole Pashley [ctb]",
    "url": "https://github.com/taehyeonkoo/IBDInfer",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IBDInfer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IBDInfer Design-Based Causal Inference Method for Incomplete Block\nDesigns This R package implements methods for estimation and inference under Incomplete Block Designs and Balanced Incomplete Block Designs within a design-based finite-population framework. Based on 'Koo and Pashley' (2024) <arXiv:2405.19312>, it includes block-level estimators and extends to unit-level effects using 'Horvitz-Thompson' and 'H\u00e1jek' estimators. The package also provides asymptotic confidence intervals to support valid statistical inference.  "
  },
  {
    "id": 4123,
    "package_name": "IDSL.SUFA",
    "title": "Simplified UFA",
    "description": "A simplified version of the 'IDSL.UFA' package to calculate isotopic profiles and adduct formulas from molecular formulas with no dependency on other R packages for online tools and educational mass spectrometry courses. The 'IDSL.SUFA' package also provides an ancillary module to process user-defined adduct formulas.",
    "version": "1.3",
    "maintainer": "Dinesh Barupal <dinesh.barupal@mssm.edu>",
    "author": "Sadjad Fakouri-Baygi [aut] (ORCID:\n    <https://orcid.org/0000-0002-6864-6911>),\n  Dinesh Barupal [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-9954-8628>)",
    "url": "https://github.com/idslme/idsl.sufa",
    "bug_reports": "https://github.com/idslme/idsl.sufa/issues",
    "repository": "https://cran.r-project.org/package=IDSL.SUFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IDSL.SUFA Simplified UFA A simplified version of the 'IDSL.UFA' package to calculate isotopic profiles and adduct formulas from molecular formulas with no dependency on other R packages for online tools and educational mass spectrometry courses. The 'IDSL.SUFA' package also provides an ancillary module to process user-defined adduct formulas.  "
  },
  {
    "id": 4146,
    "package_name": "ILSM",
    "title": "Analyze Interconnection Structure of Tripartite Interaction\nNetworks",
    "description": "\n    In view of the analysis of the structural characteristics of the tripartite \n    network has been complete, however, there is still a lack of a unified \n    operation that can quickly obtain the corresponding characteristics of the \n    tripartite network. \n    To solve this insufficiency, 'ILSM' was designed for supporting calculating \n    such metrics of tripartite networks by functions of this R package.",
    "version": "1.1.0.1",
    "maintainer": "Weicheng Sun <sunwch2023@lzu.edu.cn>",
    "author": "Weicheng Sun [aut, cre],\n  Chuan Yan [aut],\n  Yangyang Zhao [aut]",
    "url": "https://github.com/WeichengSun/ILSM",
    "bug_reports": "https://github.com/WeichengSun/ILSM/issues",
    "repository": "https://cran.r-project.org/package=ILSM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ILSM Analyze Interconnection Structure of Tripartite Interaction\nNetworks \n    In view of the analysis of the structural characteristics of the tripartite \n    network has been complete, however, there is still a lack of a unified \n    operation that can quickly obtain the corresponding characteristics of the \n    tripartite network. \n    To solve this insufficiency, 'ILSM' was designed for supporting calculating \n    such metrics of tripartite networks by functions of this R package.  "
  },
  {
    "id": 4204,
    "package_name": "ISRaD",
    "title": "Tools and Data for the International Soil Radiocarbon Database",
    "description": "This is the central location for data and tools for the development,\n    maintenance, analysis, and deployment of the International Soil Radiocarbon Database\n    (ISRaD). ISRaD was developed as a collaboration between the U.S. Geological Survey\n    Powell Center and the Max Planck Institute for Biogeochemistry. This R package provides\n    tools for accessing and manipulating ISRaD data, compiling local data using the ISRaD\n    data structure, and simple query and reporting functions for ISRaD. For more detailed\n    information visit the ISRaD website at: <https://soilradiocarbon.org/>.",
    "version": "2.5.5",
    "maintainer": "Jeffrey Beem-Miller <jbeem@bgc-jena.mpg.de>",
    "author": "Alison Hoyt [aut],\n  Jeffrey Beem-Miller [aut, cre],\n  Shane Stoner [aut],\n  J. Grey Monroe [aut],\n  Caitlin Hicks-Pries [aut],\n  Paul A. Levine [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ISRaD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ISRaD Tools and Data for the International Soil Radiocarbon Database This is the central location for data and tools for the development,\n    maintenance, analysis, and deployment of the International Soil Radiocarbon Database\n    (ISRaD). ISRaD was developed as a collaboration between the U.S. Geological Survey\n    Powell Center and the Max Planck Institute for Biogeochemistry. This R package provides\n    tools for accessing and manipulating ISRaD data, compiling local data using the ISRaD\n    data structure, and simple query and reporting functions for ISRaD. For more detailed\n    information visit the ISRaD website at: <https://soilradiocarbon.org/>.  "
  },
  {
    "id": 4229,
    "package_name": "IncDTW",
    "title": "Incremental Calculation of Dynamic Time Warping",
    "description": "The Dynamic Time Warping (DTW) distance measure for time series allows non-linear alignments of time series to match  similar patterns in time series of different lengths and or different speeds. IncDTW is characterized by (1) the incremental calculation of DTW (reduces runtime complexity to a linear level for updating the DTW distance) - especially for life data streams or subsequence matching, (2) the vector based implementation of DTW which is faster because no matrices are allocated (reduces the space complexity from a quadratic to a linear level in the number of observations) - for all runtime intensive DTW computations, (3) the subsequence matching algorithm runDTW, that efficiently finds the k-NN to a query pattern in a long time series, and (4) C++ in the heart. For details about DTW see the original paper \"Dynamic programming algorithm optimization for spoken word recognition\" by Sakoe and Chiba (1978) <DOI:10.1109/TASSP.1978.1163055>. For details about this package, Dynamic Time Warping and Incremental Dynamic Time Warping please see \"IncDTW: An R Package for Incremental Calculation of Dynamic Time Warping\" by Leodolter et al. (2021) <doi:10.18637/jss.v099.i09>.",
    "version": "1.1.4.5",
    "maintainer": "Maximilian Leodolter <maximilian.leodolter@gmail.com>",
    "author": "Maximilian Leodolter [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IncDTW",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IncDTW Incremental Calculation of Dynamic Time Warping The Dynamic Time Warping (DTW) distance measure for time series allows non-linear alignments of time series to match  similar patterns in time series of different lengths and or different speeds. IncDTW is characterized by (1) the incremental calculation of DTW (reduces runtime complexity to a linear level for updating the DTW distance) - especially for life data streams or subsequence matching, (2) the vector based implementation of DTW which is faster because no matrices are allocated (reduces the space complexity from a quadratic to a linear level in the number of observations) - for all runtime intensive DTW computations, (3) the subsequence matching algorithm runDTW, that efficiently finds the k-NN to a query pattern in a long time series, and (4) C++ in the heart. For details about DTW see the original paper \"Dynamic programming algorithm optimization for spoken word recognition\" by Sakoe and Chiba (1978) <DOI:10.1109/TASSP.1978.1163055>. For details about this package, Dynamic Time Warping and Incremental Dynamic Time Warping please see \"IncDTW: An R Package for Incremental Calculation of Dynamic Time Warping\" by Leodolter et al. (2021) <doi:10.18637/jss.v099.i09>.  "
  },
  {
    "id": 4244,
    "package_name": "InfiniumPurify",
    "title": "Estimate and Account for Tumor Purity in Cancer Methylation Data\nAnalysis",
    "description": "The proportion of cancer cells in solid tumor sample, known as the tumor purity, has adverse impact on a variety of data analyses if not properly accounted for. We develop 'InfiniumPurify', which is a comprehensive R package for estimating and accounting for tumor purity based on DNA methylation Infinium 450k array data. 'InfiniumPurify' provides functionalities for tumor purity estimation. In addition, it can perform differential methylation detection and tumor sample clustering with the consideration of tumor purities. ",
    "version": "1.3.1",
    "maintainer": "Yufang Qin <yfqin@shou.edu.cn>",
    "author": "Yufang Qin",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=InfiniumPurify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "InfiniumPurify Estimate and Account for Tumor Purity in Cancer Methylation Data\nAnalysis The proportion of cancer cells in solid tumor sample, known as the tumor purity, has adverse impact on a variety of data analyses if not properly accounted for. We develop 'InfiniumPurify', which is a comprehensive R package for estimating and accounting for tumor purity based on DNA methylation Infinium 450k array data. 'InfiniumPurify' provides functionalities for tumor purity estimation. In addition, it can perform differential methylation detection and tumor sample clustering with the consideration of tumor purities.   "
  },
  {
    "id": 4286,
    "package_name": "IsoriX",
    "title": "Isoscape Computation and Inference of Spatial Origins using\nMixed Models",
    "description": "Building isoscapes using mixed models and inferring the geographic\n  origin of samples based on their isotopic ratios. This package is essentially a\n  simplified interface to several other packages which implements a new\n  statistical framework based on mixed models. It uses 'spaMM' for fitting and\n  predicting isoscapes, and assigning an organism's origin depending on its\n  isotopic ratio. 'IsoriX' also relies heavily on the package 'rasterVis' for\n  plotting the maps produced with 'terra' using 'lattice'.",
    "version": "0.9.3",
    "maintainer": "Alexandre Courtiol <alexandre.courtiol@gmail.com>",
    "author": "Alexandre Courtiol [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0637-2959>),\n  Fran\u00e7ois Rousset [aut] (ORCID: <https://orcid.org/0000-0003-4670-0371>),\n  Marie-Sophie Rohwaeder [aut],\n  Stephanie Kramer-Schadt [aut] (ORCID:\n    <https://orcid.org/0000-0002-9269-4446>)",
    "url": "https://github.com/courtiol/IsoriX,\nhttps://bookdown.org/content/782",
    "bug_reports": "https://github.com/courtiol/IsoriX/issues",
    "repository": "https://cran.r-project.org/package=IsoriX",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IsoriX Isoscape Computation and Inference of Spatial Origins using\nMixed Models Building isoscapes using mixed models and inferring the geographic\n  origin of samples based on their isotopic ratios. This package is essentially a\n  simplified interface to several other packages which implements a new\n  statistical framework based on mixed models. It uses 'spaMM' for fitting and\n  predicting isoscapes, and assigning an organism's origin depending on its\n  isotopic ratio. 'IsoriX' also relies heavily on the package 'rasterVis' for\n  plotting the maps produced with 'terra' using 'lattice'.  "
  },
  {
    "id": 4300,
    "package_name": "JICO",
    "title": "Joint and Individual Regression",
    "description": "An R package that implements the JICO algorithm [Wang, P., Wang, H., Li, Q., Shen, D., & Liu, Y. (2024). <Journal of Computational and Graphical Statistics, 33(3), 763-773>]. \n        It aims at solving the multi-group regression problem. The algorithm decomposes the responses from multiple groups into shared and group-specific\n        components, which are driven by low-rank approximations of joint and individual structures from the covariates respectively. ",
    "version": "0.1",
    "maintainer": "Peiyao Wang <peiyaow76@gmail.com>",
    "author": "Peiyao Wang [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=JICO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "JICO Joint and Individual Regression An R package that implements the JICO algorithm [Wang, P., Wang, H., Li, Q., Shen, D., & Liu, Y. (2024). <Journal of Computational and Graphical Statistics, 33(3), 763-773>]. \n        It aims at solving the multi-group regression problem. The algorithm decomposes the responses from multiple groups into shared and group-specific\n        components, which are driven by low-rank approximations of joint and individual structures from the covariates respectively.   "
  },
  {
    "id": 4352,
    "package_name": "KLINK",
    "title": "Kinship Analysis with Linked Markers",
    "description": "A 'shiny' application for forensic kinship testing, based on\n    the 'pedsuite' R packages. 'KLINK' is closely aligned with the (non-R)\n    software 'Familias' and 'FamLink', but offers several unique features,\n    including visualisations and automated report generation. The\n    calculation of likelihood ratios supports pairs of linked markers, and\n    all common mutation models.",
    "version": "1.1.0",
    "maintainer": "Magnus Dehli Vigeland <m.d.vigeland@medisin.uio.no>",
    "author": "Magnus Dehli Vigeland [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9134-4962>)",
    "url": "https://github.com/magnusdv/KLINK",
    "bug_reports": "https://github.com/magnusdv/KLINK/issues",
    "repository": "https://cran.r-project.org/package=KLINK",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KLINK Kinship Analysis with Linked Markers A 'shiny' application for forensic kinship testing, based on\n    the 'pedsuite' R packages. 'KLINK' is closely aligned with the (non-R)\n    software 'Familias' and 'FamLink', but offers several unique features,\n    including visualisations and automated report generation. The\n    calculation of likelihood ratios supports pairs of linked markers, and\n    all common mutation models.  "
  },
  {
    "id": 4379,
    "package_name": "KappaGUI",
    "title": "An R-Shiny Application for Calculating Cohen's and Fleiss' Kappa",
    "description": "Offers a graphical user interface for the evaluation of inter-rater agreement with Cohen's and Fleiss' Kappa. The calculation of kappa statistics is done using the R package 'irr', so that 'KappaGUI' is essentially a Shiny front-end for 'irr'.",
    "version": "2.0.2",
    "maintainer": "Fr\u00e9d\u00e9ric Santos <frederic.santos@u-bordeaux.fr>",
    "author": "Fr\u00e9d\u00e9ric Santos",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=KappaGUI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KappaGUI An R-Shiny Application for Calculating Cohen's and Fleiss' Kappa Offers a graphical user interface for the evaluation of inter-rater agreement with Cohen's and Fleiss' Kappa. The calculation of kappa statistics is done using the R package 'irr', so that 'KappaGUI' is essentially a Shiny front-end for 'irr'.  "
  },
  {
    "id": 4384,
    "package_name": "KenSyn",
    "title": "Knowledge Synthesis in Agriculture - From Experimental Network\nto Meta-Analysis",
    "description": "Demo and dataset accompaying the books :\n\tDe l'analyse des r\u00e9seaux exp\u00e9rimentaux \u00e0 la m\u00e9ta-analyse: M\u00e9thodes et applications avec le logiciel R pour les sciences agronomiques et environnementales (Published 2018-06-28, Quae, for french version) by David Makowski, Francois Piraux and Francois Brun - <https://www.quae.com/produit/1514/9782759228164/de-l-analyse-des-reseaux-experimentaux-a-la-meta-analyse>\n\tKnowledge Synthesis in Agriculture : from Experimental Network to Meta-Analysis (in preparation for 2018-06, Springer , for English version) by David Makowski, Francois Piraux and Francois Brun\n\tA full description of all the material is in both books.\n\tACKNOWLEDGMENTS : The French network \"RMT modeling and data analysis for agriculture\" (<http://www.modelia.org>) have contributed to the development of this R package. This project and network are lead by ACTA (French Technical Institute for Agriculture) and was funded by a grant from the Ministry of Agriculture and Fishing of France.",
    "version": "0.3",
    "maintainer": "Francois Brun (ACTA) <francois.brun@acta.asso.fr>",
    "author": "David Makowski (INRA) [aut],\n  Francois Piraux (Arvalis) [aut],\n  Francois Brun (ACTA) [aut, cre]",
    "url": "http://www.modelia.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=KenSyn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KenSyn Knowledge Synthesis in Agriculture - From Experimental Network\nto Meta-Analysis Demo and dataset accompaying the books :\n\tDe l'analyse des r\u00e9seaux exp\u00e9rimentaux \u00e0 la m\u00e9ta-analyse: M\u00e9thodes et applications avec le logiciel R pour les sciences agronomiques et environnementales (Published 2018-06-28, Quae, for french version) by David Makowski, Francois Piraux and Francois Brun - <https://www.quae.com/produit/1514/9782759228164/de-l-analyse-des-reseaux-experimentaux-a-la-meta-analyse>\n\tKnowledge Synthesis in Agriculture : from Experimental Network to Meta-Analysis (in preparation for 2018-06, Springer , for English version) by David Makowski, Francois Piraux and Francois Brun\n\tA full description of all the material is in both books.\n\tACKNOWLEDGMENTS : The French network \"RMT modeling and data analysis for agriculture\" (<http://www.modelia.org>) have contributed to the development of this R package. This project and network are lead by ACTA (French Technical Institute for Agriculture) and was funded by a grant from the Ministry of Agriculture and Fishing of France.  "
  },
  {
    "id": 4436,
    "package_name": "LCFdata",
    "title": "Data sets for package ``LMERConvenienceFunctions''",
    "description": "This package contains (1) event-related brain potential data recorded from 10 participants at electrodes Fz, Cz, Pz, and Oz (0--300 ms) in the context of Antoine Tremblay's PhD thesis (Tremblay, 2009); (2) ERP amplitudes at electrode Fz restricted to the 100 to 175 millisecond time window; and (3) plotting data generated from a linear mixed-effects model.",
    "version": "2.0",
    "maintainer": "Antoine Tremblay <trea26@gmail.com>",
    "author": "Antoine Tremblay, Department of Psychology, Dalhousie University",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LCFdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LCFdata Data sets for package ``LMERConvenienceFunctions'' This package contains (1) event-related brain potential data recorded from 10 participants at electrodes Fz, Cz, Pz, and Oz (0--300 ms) in the context of Antoine Tremblay's PhD thesis (Tremblay, 2009); (2) ERP amplitudes at electrode Fz restricted to the 100 to 175 millisecond time window; and (3) plotting data generated from a linear mixed-effects model.  "
  },
  {
    "id": 4459,
    "package_name": "LHD",
    "title": "Latin Hypercube Designs (LHDs)",
    "description": "Contains different algorithms and construction methods for optimal Latin hypercube designs (LHDs) with flexible sizes. Our package is comprehensive since it is capable of generating maximin distance LHDs, maximum projection LHDs, and orthogonal and nearly orthogonal LHDs. Detailed comparisons and summary of all the algorithms and construction methods in this package can be found at Hongzhi Wang, Qian Xiao and Abhyuday Mandal (2021) <doi:10.48550/arXiv.2010.09154>. This package is particularly useful in the area of Design and Analysis of Experiments (DAE). More specifically, design of computer experiments.",
    "version": "1.4.1",
    "maintainer": "Hongzhi Wang <wanghongzhi.ut@gmail.com>",
    "author": "Hongzhi Wang [aut, cre],\n  Qian Xiao [aut],\n  Abhyuday Mandal [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LHD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LHD Latin Hypercube Designs (LHDs) Contains different algorithms and construction methods for optimal Latin hypercube designs (LHDs) with flexible sizes. Our package is comprehensive since it is capable of generating maximin distance LHDs, maximum projection LHDs, and orthogonal and nearly orthogonal LHDs. Detailed comparisons and summary of all the algorithms and construction methods in this package can be found at Hongzhi Wang, Qian Xiao and Abhyuday Mandal (2021) <doi:10.48550/arXiv.2010.09154>. This package is particularly useful in the area of Design and Analysis of Experiments (DAE). More specifically, design of computer experiments.  "
  },
  {
    "id": 4466,
    "package_name": "LLMAgentR",
    "title": "Language Model Agents in R for AI Workflows and Research",
    "description": "Provides modular, graph-based agents powered by large language models (LLMs) for intelligent task execution in R. \n      Supports structured workflows for tasks such as forecasting, data visualization, feature engineering, data wrangling, data cleaning, 'SQL', code generation, weather reporting, and research-driven question answering. \n      Each agent performs iterative reasoning: recommending steps, generating R code, executing, debugging, and explaining results. \n      Includes built-in support for packages such as 'tidymodels', 'modeltime', 'plotly', 'ggplot2', and 'prophet'. Designed for analysts, developers, and teams building intelligent, reproducible AI workflows in R. \n      Compatible with LLM providers such as 'OpenAI', 'Anthropic', 'Groq', and 'Ollama'. Inspired by the Python package 'langagent'.",
    "version": "0.3.0",
    "maintainer": "Kwadwo Daddy Nyame Owusu Boakye <kwadwo.owusuboakye@outlook.com>",
    "author": "Kwadwo Daddy Nyame Owusu Boakye [aut, cre]",
    "url": "https://github.com/knowusuboaky/LLMAgentR,\nhttps://knowusuboaky.github.io/LLMAgentR/",
    "bug_reports": "https://github.com/knowusuboaky/LLMAgentR/issues",
    "repository": "https://cran.r-project.org/package=LLMAgentR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LLMAgentR Language Model Agents in R for AI Workflows and Research Provides modular, graph-based agents powered by large language models (LLMs) for intelligent task execution in R. \n      Supports structured workflows for tasks such as forecasting, data visualization, feature engineering, data wrangling, data cleaning, 'SQL', code generation, weather reporting, and research-driven question answering. \n      Each agent performs iterative reasoning: recommending steps, generating R code, executing, debugging, and explaining results. \n      Includes built-in support for packages such as 'tidymodels', 'modeltime', 'plotly', 'ggplot2', and 'prophet'. Designed for analysts, developers, and teams building intelligent, reproducible AI workflows in R. \n      Compatible with LLM providers such as 'OpenAI', 'Anthropic', 'Groq', and 'Ollama'. Inspired by the Python package 'langagent'.  "
  },
  {
    "id": 4471,
    "package_name": "LMD",
    "title": "A Self-Adaptive Approach for Demodulating Multi-Component Signal",
    "description": "Local Mean Decomposition is an iterative and self-adaptive approach for demodulating, processing, and analyzing multi-component amplitude modulated and frequency modulated signals. This R package is based on the approach suggested by Smith (2005) <doi:10.1098/rsif.2005.0058> and the 'Python' library 'PyLMD'.",
    "version": "1.2.1",
    "maintainer": "Shubhra Prakash <shubhraprakash279@gmail.com>",
    "author": "Shubhra Prakash [trl, aut, cre]",
    "url": "https://github.com/shubhra-opensource/LMD,\nhttps://shubhra-opensource.github.io/LMD/",
    "bug_reports": "https://github.com/shubhra-opensource/LMD/issues",
    "repository": "https://cran.r-project.org/package=LMD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LMD A Self-Adaptive Approach for Demodulating Multi-Component Signal Local Mean Decomposition is an iterative and self-adaptive approach for demodulating, processing, and analyzing multi-component amplitude modulated and frequency modulated signals. This R package is based on the approach suggested by Smith (2005) <doi:10.1098/rsif.2005.0058> and the 'Python' library 'PyLMD'.  "
  },
  {
    "id": 4475,
    "package_name": "LMMstar",
    "title": "Repeated Measurement Models for Discrete Times",
    "description": "Companion R package for the course \"Statistical analysis of correlated and repeated measurements for health science researchers\"\n\t     taught by the section of Biostatistics of the University of Copenhagen.\n\t     It implements linear mixed models where the model for the variance-covariance of the residuals is specified via patterns (compound symmetry, toeplitz, unstructured, ...).\n\t     Statistical inference for mean, variance, and correlation parameters is performed based on the observed information and a Satterthwaite approximation of the degrees of freedom.\n\t     Normalized residuals are provided to assess model misspecification.\n\t     Statistical inference can be performed for arbitrary linear or non-linear combination(s) of model coefficients.\n\t     Predictions can be computed conditional to covariates only or also to outcome values. ",
    "version": "1.1.0",
    "maintainer": "Brice Ozenne <brice.mh.ozenne@gmail.com>",
    "author": "Brice Ozenne [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9694-2956>),\n  Julie Forman [aut] (ORCID: <https://orcid.org/0000-0001-7368-0869>)",
    "url": "https://github.com/bozenne/LMMstar",
    "bug_reports": "https://github.com/bozenne/LMMstar/issues",
    "repository": "https://cran.r-project.org/package=LMMstar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LMMstar Repeated Measurement Models for Discrete Times Companion R package for the course \"Statistical analysis of correlated and repeated measurements for health science researchers\"\n\t     taught by the section of Biostatistics of the University of Copenhagen.\n\t     It implements linear mixed models where the model for the variance-covariance of the residuals is specified via patterns (compound symmetry, toeplitz, unstructured, ...).\n\t     Statistical inference for mean, variance, and correlation parameters is performed based on the observed information and a Satterthwaite approximation of the degrees of freedom.\n\t     Normalized residuals are provided to assess model misspecification.\n\t     Statistical inference can be performed for arbitrary linear or non-linear combination(s) of model coefficients.\n\t     Predictions can be computed conditional to covariates only or also to outcome values.   "
  },
  {
    "id": 4553,
    "package_name": "Latamverse",
    "title": "Latin American Data via 'RESTful' APIs and Curated Datasets",
    "description": "Brings together a comprehensive collection \n    of R packages providing access to API functions and curated datasets from Argentina, Brazil, \n    Chile, Colombia, and Peru. Includes real-time and historical data through public \n    'RESTful' APIs ('Nager.Date', World Bank API, REST Countries API, and country-specific APIs) and \n    extensive curated collections of open datasets covering economics, demographics, public health, \n    environmental data, political indicators, social metrics, and cultural information. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to Latin American data sources, facilitating \n    reproducible research, comparative analysis, and teaching applications focused \n    on these five major Latin American countries.\n    Included packages:\n    - 'ArgentinAPI': API functions and curated datasets for Argentina covering exchange rates, inflation, political figures, national holidays and more.\n    - 'BrazilDataAPI': API functions and curated datasets for Brazil covering postal codes, banks, economic indicators, holidays, company registrations and more.\n    - 'ChileDataAPI': API functions and curated datasets for Chile covering financial indicators ('UF', UTM, Dollar, Euro, Yen, Copper, Bitcoin, 'IPSA' index), holidays and more.\n    - 'ColombiAPI': API functions and curated datasets for Colombia covering geographic locations, cultural attractions, economic indicators, demographic data, national holidays and more.\n    - 'PeruAPIs': API functions and curated datasets for Peru covering economic indicators, demographics, national holidays, administrative divisions, electoral data, biodiversity and more.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    World Bank API <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    REST Countries API <https://restcountries.com/>,\n    'ArgentinaDatos' API <https://argentinadatos.com/>,\n    'BrasilAPI' <https://brasilapi.com.br/>,\n    'FINDIC' <https://findic.cl/>,\n    and API-Colombia <https://api-colombia.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/latamverse,\nhttps://lightbluetitan.github.io/latamverse/",
    "bug_reports": "https://github.com/lightbluetitan/latamverse/issues",
    "repository": "https://cran.r-project.org/package=Latamverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Latamverse Latin American Data via 'RESTful' APIs and Curated Datasets Brings together a comprehensive collection \n    of R packages providing access to API functions and curated datasets from Argentina, Brazil, \n    Chile, Colombia, and Peru. Includes real-time and historical data through public \n    'RESTful' APIs ('Nager.Date', World Bank API, REST Countries API, and country-specific APIs) and \n    extensive curated collections of open datasets covering economics, demographics, public health, \n    environmental data, political indicators, social metrics, and cultural information. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to Latin American data sources, facilitating \n    reproducible research, comparative analysis, and teaching applications focused \n    on these five major Latin American countries.\n    Included packages:\n    - 'ArgentinAPI': API functions and curated datasets for Argentina covering exchange rates, inflation, political figures, national holidays and more.\n    - 'BrazilDataAPI': API functions and curated datasets for Brazil covering postal codes, banks, economic indicators, holidays, company registrations and more.\n    - 'ChileDataAPI': API functions and curated datasets for Chile covering financial indicators ('UF', UTM, Dollar, Euro, Yen, Copper, Bitcoin, 'IPSA' index), holidays and more.\n    - 'ColombiAPI': API functions and curated datasets for Colombia covering geographic locations, cultural attractions, economic indicators, demographic data, national holidays and more.\n    - 'PeruAPIs': API functions and curated datasets for Peru covering economic indicators, demographics, national holidays, administrative divisions, electoral data, biodiversity and more.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    World Bank API <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    REST Countries API <https://restcountries.com/>,\n    'ArgentinaDatos' API <https://argentinadatos.com/>,\n    'BrasilAPI' <https://brasilapi.com.br/>,\n    'FINDIC' <https://findic.cl/>,\n    and API-Colombia <https://api-colombia.com/>.  "
  },
  {
    "id": 4608,
    "package_name": "LocalControl",
    "title": "Nonparametric Methods for Generating High Quality Comparative\nEffectiveness Evidence",
    "description": "Implements novel nonparametric approaches to address\n    biases and confounding when comparing treatments or exposures in\n    observational studies of outcomes. While designed and appropriate for use\n    in studies involving medicine and the life sciences, the package can be\n    used in other situations involving outcomes with multiple confounders.\n    The package implements a family of methods for non-parametric bias correction\n    when comparing treatments in observational studies, including survival\n    analysis settings, where competing risks and/or censoring may be present.\n    The approach extends to bias-corrected personalized predictions of treatment\n    outcome differences, and analysis of heterogeneity of treatment effect-sizes\n    across patient subgroups. For further details, please see: \n    Lauve NR, Nelson SJ, Young SS, Obenchain RL, Lambert CG. LocalControl:\n    An R Package for Comparative Safety and Effectiveness Research.\n    Journal of Statistical Software. 2020. p. 1\u201332. Available from <doi:10.18637/jss.v096.i04>.",
    "version": "1.1.4",
    "maintainer": "Christophe G. Lambert <cglambert@salud.unm.edu>",
    "author": "Nicolas R. Lauve [aut] (ORCID: <https://orcid.org/0000-0002-9348-0319>),\n  Stuart J. Nelson [aut] (ORCID: <https://orcid.org/0000-0002-8756-0179>),\n  S. Stanley Young [aut] (ORCID: <https://orcid.org/0000-0001-9449-5478>),\n  Robert L. Obenchain [aut] (ORCID:\n    <https://orcid.org/0000-0002-8395-1666>),\n  Melania Pintilie [ctb],\n  Martin Kutz [ctb],\n  Christophe G. Lambert [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1994-2893>)",
    "url": "https://github.com/OHDSI/LocalControl",
    "bug_reports": "https://github.com/OHDSI/LocalControl/issues",
    "repository": "https://cran.r-project.org/package=LocalControl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LocalControl Nonparametric Methods for Generating High Quality Comparative\nEffectiveness Evidence Implements novel nonparametric approaches to address\n    biases and confounding when comparing treatments or exposures in\n    observational studies of outcomes. While designed and appropriate for use\n    in studies involving medicine and the life sciences, the package can be\n    used in other situations involving outcomes with multiple confounders.\n    The package implements a family of methods for non-parametric bias correction\n    when comparing treatments in observational studies, including survival\n    analysis settings, where competing risks and/or censoring may be present.\n    The approach extends to bias-corrected personalized predictions of treatment\n    outcome differences, and analysis of heterogeneity of treatment effect-sizes\n    across patient subgroups. For further details, please see: \n    Lauve NR, Nelson SJ, Young SS, Obenchain RL, Lambert CG. LocalControl:\n    An R Package for Comparative Safety and Effectiveness Research.\n    Journal of Statistical Software. 2020. p. 1\u201332. Available from <doi:10.18637/jss.v096.i04>.  "
  },
  {
    "id": 4646,
    "package_name": "MAKL",
    "title": "Multiple Approximate Kernel Learning (MAKL)",
    "description": "R package associated with the Multiple Approximate Kernel Learning (MAKL) algorithm proposed in <doi:10.1093/bioinformatics/btac241>. The algorithm fits multiple approximate kernel learning (MAKL) models that are fast, scalable and interpretable. ",
    "version": "1.0.1",
    "maintainer": "Ayy\u00fcce Beg\u00fcm Bekta\u015f <ayyucebektas17@ku.edu.tr>",
    "author": "Ayy\u00fcce Beg\u00fcm Bekta\u015f [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1432-9056>),\n  Mehmet G\u00f6nen [aut] (ORCID: <https://orcid.org/0000-0002-2483-075X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MAKL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MAKL Multiple Approximate Kernel Learning (MAKL) R package associated with the Multiple Approximate Kernel Learning (MAKL) algorithm proposed in <doi:10.1093/bioinformatics/btac241>. The algorithm fits multiple approximate kernel learning (MAKL) models that are fast, scalable and interpretable.   "
  },
  {
    "id": 4676,
    "package_name": "MBESS",
    "title": "The MBESS R Package",
    "description": "Implements methods that are useful in designing research studies and analyzing data, with \n\tparticular emphasis on methods that are developed for or used within the behavioral, \n\teducational, and social sciences (broadly defined). That being said, many of the methods \n\timplemented within MBESS are applicable to a wide variety of disciplines. MBESS has a \n\tsuite of functions for a variety of related topics, such as effect sizes, confidence intervals \n\tfor effect sizes (including standardized effect sizes and noncentral effect sizes), sample size\n\tplanning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and \n\tminimum-risk point estimation perspectives), mediation analysis, various properties of \n\tdistributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally \n\tan acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became\n\tmore general and now contains methods applicable and used in a wide variety of fields and is an \n\torphan acronym, in the sense that what was an acronym is now literally its name. MBESS has \n\tgreatly benefited from others, see <https://www3.nd.edu/~kkelley/r-packages.html> for a detailed \n\tlist of those that have contributed and other details.",
    "version": "4.9.41",
    "maintainer": "Ken Kelley <kkelley@nd.edu>",
    "author": "Ken Kelley [aut, cre]",
    "url": "https://www3.nd.edu/~kkelley/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MBESS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MBESS The MBESS R Package Implements methods that are useful in designing research studies and analyzing data, with \n\tparticular emphasis on methods that are developed for or used within the behavioral, \n\teducational, and social sciences (broadly defined). That being said, many of the methods \n\timplemented within MBESS are applicable to a wide variety of disciplines. MBESS has a \n\tsuite of functions for a variety of related topics, such as effect sizes, confidence intervals \n\tfor effect sizes (including standardized effect sizes and noncentral effect sizes), sample size\n\tplanning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and \n\tminimum-risk point estimation perspectives), mediation analysis, various properties of \n\tdistributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally \n\tan acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became\n\tmore general and now contains methods applicable and used in a wide variety of fields and is an \n\torphan acronym, in the sense that what was an acronym is now literally its name. MBESS has \n\tgreatly benefited from others, see <https://www3.nd.edu/~kkelley/r-packages.html> for a detailed \n\tlist of those that have contributed and other details.  "
  },
  {
    "id": 4752,
    "package_name": "MGMS2",
    "title": "'MGMS2' for Polymicrobial Samples",
    "description": "A glycolipid mass spectrometry technology has the potential to accurately identify individual bacterial species from polymicrobial samples. To develop bacterial identification algorithms (e.g. machine learning) using this glycolipid technology, it is necessary to generate a large number of various in-silico polymicrobial mass spectra that are similar to real mass spectra. 'MGMS2' (Membrane Glycolipid Mass Spectrum Simulator) generates such in-silico mass spectra, considering errors in m/z (mass-to-charge ratio) and variances of intensity values, occasions of missing signature ions, and noise peaks. It estimates summary statistics of monomicrobial mass spectra for each strain or species and simulates polymicrobial glycolipid mass spectra using the summary statistics of monomicrobial mass spectra. References: Ryu, S.Y., Wendt, G.A., Chandler, C.E., Ernst, R.K. and Goodlett, D.R. (2019) <doi:10.1021/acs.analchem.9b03340> \"Model-based Spectral Library Approach for Bacterial Identification via Membrane Glycolipids.\" Gibb, S. and Strimmer, K. (2012) <doi:10.1093/bioinformatics/bts447> \"MALDIquant: a versatile R package for the analysis of mass spectrometry data.\"",
    "version": "1.0.2",
    "maintainer": "George Wendt <gwendt@unr.edu>",
    "author": "So Young Ryu [aut] (ORCID: <https://orcid.org/0000-0003-2347-7015>),\n  George Wendt [cre] (ORCID: <https://orcid.org/0000-0003-3608-9601>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MGMS2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MGMS2 'MGMS2' for Polymicrobial Samples A glycolipid mass spectrometry technology has the potential to accurately identify individual bacterial species from polymicrobial samples. To develop bacterial identification algorithms (e.g. machine learning) using this glycolipid technology, it is necessary to generate a large number of various in-silico polymicrobial mass spectra that are similar to real mass spectra. 'MGMS2' (Membrane Glycolipid Mass Spectrum Simulator) generates such in-silico mass spectra, considering errors in m/z (mass-to-charge ratio) and variances of intensity values, occasions of missing signature ions, and noise peaks. It estimates summary statistics of monomicrobial mass spectra for each strain or species and simulates polymicrobial glycolipid mass spectra using the summary statistics of monomicrobial mass spectra. References: Ryu, S.Y., Wendt, G.A., Chandler, C.E., Ernst, R.K. and Goodlett, D.R. (2019) <doi:10.1021/acs.analchem.9b03340> \"Model-based Spectral Library Approach for Bacterial Identification via Membrane Glycolipids.\" Gibb, S. and Strimmer, K. (2012) <doi:10.1093/bioinformatics/bts447> \"MALDIquant: a versatile R package for the analysis of mass spectrometry data.\"  "
  },
  {
    "id": 4816,
    "package_name": "MMAD",
    "title": "An R Package of Minorization-Maximization Algorithm via the\nAssembly--Decomposition Technology",
    "description": "The minorization-maximization (MM) algorithm is a powerful tool for maximizing nonconcave target function. However, for most existing MM algorithms, the surrogate function in the minorization step is constructed in a case-specific manner and requires manual programming. To address this limitation, we develop the R package MMAD, which systematically integrates the assembly--decomposition technology in the MM framework. This new package provides a comprehensive computational toolkit for one-stop inference of complex target functions, including function construction, evaluation, minorization and optimization via MM algorithm. By representing the target function through a hierarchical composition of assembly functions, we design a hierarchical algorithmic structure that supports both bottom-up operations (construction, evaluation) and top-down operation (minorization).",
    "version": "2.0",
    "maintainer": "Jiaqi Gu <jiaqigu@usf.edu>",
    "author": "Jiaqi Gu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MMAD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MMAD An R Package of Minorization-Maximization Algorithm via the\nAssembly--Decomposition Technology The minorization-maximization (MM) algorithm is a powerful tool for maximizing nonconcave target function. However, for most existing MM algorithms, the surrogate function in the minorization step is constructed in a case-specific manner and requires manual programming. To address this limitation, we develop the R package MMAD, which systematically integrates the assembly--decomposition technology in the MM framework. This new package provides a comprehensive computational toolkit for one-stop inference of complex target functions, including function construction, evaluation, minorization and optimization via MM algorithm. By representing the target function through a hierarchical composition of assembly functions, we design a hierarchical algorithmic structure that supports both bottom-up operations (construction, evaluation) and top-down operation (minorization).  "
  },
  {
    "id": 4832,
    "package_name": "MNP",
    "title": "Fitting the Multinomial Probit Model",
    "description": "Fits the Bayesian multinomial probit model via Markov chain\n Monte Carlo.  The multinomial probit model is often used to analyze \n the discrete choices made by individuals recorded in survey data. \n Examples where the multinomial probit model may be useful include the \n analysis of product choice by consumers in market research and the \n analysis of candidate or party choice by voters in electoral studies.  \n The MNP package can also fit the model with different choice sets for \n each individual, and complete or partial individual choice orderings \n of the available alternatives from the choice set. The estimation is\n based on the efficient marginal data augmentation algorithm that is \n developed by Imai and van Dyk (2005). \"A Bayesian Analysis of the \n Multinomial Probit Model Using the Data Augmentation.\" Journal of \n Econometrics, Vol. 124, No. 2 (February), pp. 311-334. \n <doi:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in \n Imai and van Dyk (2005). \"MNP: R Package for Fitting the Multinomial \n Probit Model.\"  Journal of Statistical Software, Vol. 14, No. 3 (May), \n pp. 1-32. <doi:10.18637/jss.v014.i03>.",
    "version": "3.1-5",
    "maintainer": "Kosuke Imai <imai@harvard.edu>",
    "author": "Kosuke Imai [aut, cre],\n  David van Dyk [aut],\n  Hubert Jin [ctb]",
    "url": "https://github.com/kosukeimai/MNP",
    "bug_reports": "https://github.com/kosukeimai/MNP/issues",
    "repository": "https://cran.r-project.org/package=MNP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MNP Fitting the Multinomial Probit Model Fits the Bayesian multinomial probit model via Markov chain\n Monte Carlo.  The multinomial probit model is often used to analyze \n the discrete choices made by individuals recorded in survey data. \n Examples where the multinomial probit model may be useful include the \n analysis of product choice by consumers in market research and the \n analysis of candidate or party choice by voters in electoral studies.  \n The MNP package can also fit the model with different choice sets for \n each individual, and complete or partial individual choice orderings \n of the available alternatives from the choice set. The estimation is\n based on the efficient marginal data augmentation algorithm that is \n developed by Imai and van Dyk (2005). \"A Bayesian Analysis of the \n Multinomial Probit Model Using the Data Augmentation.\" Journal of \n Econometrics, Vol. 124, No. 2 (February), pp. 311-334. \n <doi:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in \n Imai and van Dyk (2005). \"MNP: R Package for Fitting the Multinomial \n Probit Model.\"  Journal of Statistical Software, Vol. 14, No. 3 (May), \n pp. 1-32. <doi:10.18637/jss.v014.i03>.  "
  },
  {
    "id": 4842,
    "package_name": "MOQA",
    "title": "Basic Quality Data Assurance for Epidemiological Research",
    "description": "With the provision of several tools and templates the MOSAIC project (DFG-Grant Number HO 1937/2-1) supports the implementation of a central data management in epidemiological research projects. The 'MOQA' package enables epidemiologists with none or low experience in R to generate basic data quality reports for a wide range of application scenarios. See <https://mosaic-greifswald.de/> for more information. Please read and cite the corresponding open access publication (using the former package-name) in METHODS OF INFORMATION IN MEDICINE by M. Bialke, H. Rau, T. Schwaneberg, R. Walk, T. Bahls and W. Hoffmann (2017) <doi:10.3414/ME16-01-0123>. <https://methods.schattauer.de/en/contents/most-recent-articles/issue/2483/issue/special/manuscript/27573/show.html>.",
    "version": "2.0.0",
    "maintainer": "Martin Bialke <mosaic-projekt@uni-greifswald.de>",
    "author": "Martin Bialke <mosaic-projekt@uni-greifswald.de>, Thea Schwaneberg <thea.schwaneberg@uni-greifswald.de>, Rene Walk <rene.walk@uni-greifswald.de>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MOQA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MOQA Basic Quality Data Assurance for Epidemiological Research With the provision of several tools and templates the MOSAIC project (DFG-Grant Number HO 1937/2-1) supports the implementation of a central data management in epidemiological research projects. The 'MOQA' package enables epidemiologists with none or low experience in R to generate basic data quality reports for a wide range of application scenarios. See <https://mosaic-greifswald.de/> for more information. Please read and cite the corresponding open access publication (using the former package-name) in METHODS OF INFORMATION IN MEDICINE by M. Bialke, H. Rau, T. Schwaneberg, R. Walk, T. Bahls and W. Hoffmann (2017) <doi:10.3414/ME16-01-0123>. <https://methods.schattauer.de/en/contents/most-recent-articles/issue/2483/issue/special/manuscript/27573/show.html>.  "
  },
  {
    "id": 4844,
    "package_name": "MOsemiind",
    "title": "Marshall-Olkin Shock Models with Semi-Independent Time",
    "description": "Provides tools for analyzing Marshall-Olkin shock models semi-independent time.\n    It includes interactive 'shiny' applications for exploring copula-based dependence \n    structures, along with functions for modeling and visualization. The methods are \n    based on Mijanovic and Popovic (2024, submitted) \"An R package for Marshall-Olkin \n    shock models with semi-independent times.\"",
    "version": "0.1.0",
    "maintainer": "Andjela Mijanovic <andjela.m@ucg.ac.me>",
    "author": "Andjela Mijanovic [aut, cre],\n  Bozidar Popovic [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MOsemiind",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MOsemiind Marshall-Olkin Shock Models with Semi-Independent Time Provides tools for analyzing Marshall-Olkin shock models semi-independent time.\n    It includes interactive 'shiny' applications for exploring copula-based dependence \n    structures, along with functions for modeling and visualization. The methods are \n    based on Mijanovic and Popovic (2024, submitted) \"An R package for Marshall-Olkin \n    shock models with semi-independent times.\"  "
  },
  {
    "id": 4951,
    "package_name": "ManifoldOptim",
    "title": "An R Interface to the 'ROPTLIB' Library for Riemannian Manifold\nOptimization",
    "description": "An R interface to version 0.3 of the 'ROPTLIB' optimization library\n    (see <https://www.math.fsu.edu/~whuang2/> for more information). Optimize real-\n    valued functions over manifolds such as Stiefel, Grassmann, and Symmetric\n    Positive Definite matrices. For details see Martin et. al. (2020) <doi:10.18637/jss.v093.i01>. \n    Note that the optional ldr package used in some of this package's examples can be obtained from either JSS \n    <https://www.jstatsoft.org/index.php/jss/article/view/v061i03/2886> or from the CRAN archives \n    <https://cran.r-project.org/src/contrib/Archive/ldr/ldr_1.3.3.tar.gz>.",
    "version": "1.0.1",
    "maintainer": "Sean R. Martin <sean.martin@jhuapl.edu>",
    "author": "Kofi P. Adragni [aut, cph],\n  Sean R. Martin [aut, cre, cph],\n  Andrew M. Raim [aut, cph],\n  Wen Huang [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ManifoldOptim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ManifoldOptim An R Interface to the 'ROPTLIB' Library for Riemannian Manifold\nOptimization An R interface to version 0.3 of the 'ROPTLIB' optimization library\n    (see <https://www.math.fsu.edu/~whuang2/> for more information). Optimize real-\n    valued functions over manifolds such as Stiefel, Grassmann, and Symmetric\n    Positive Definite matrices. For details see Martin et. al. (2020) <doi:10.18637/jss.v093.i01>. \n    Note that the optional ldr package used in some of this package's examples can be obtained from either JSS \n    <https://www.jstatsoft.org/index.php/jss/article/view/v061i03/2886> or from the CRAN archives \n    <https://cran.r-project.org/src/contrib/Archive/ldr/ldr_1.3.3.tar.gz>.  "
  },
  {
    "id": 4954,
    "package_name": "MantaID",
    "title": "A Machine-Learning Based Tool to Automate the Identification of\nBiological Database IDs",
    "description": "The number of biological databases is growing rapidly, but different databases use different IDs to refer to the same biological entity. The inconsistency in IDs impedes the integration of various types of biological data. To resolve the problem, we developed 'MantaID', a data-driven, machine-learning based approach that automates identifying IDs on a large scale. The 'MantaID' model's prediction accuracy was proven to be 99%, and it correctly and effectively predicted 100,000 ID entries within two minutes. 'MantaID' supports the discovery and exploitation of ID patterns from large quantities of databases. (e.g., up to 542 biological databases). An easy-to-use freely available open-source software R package, a user-friendly web application, and API were also developed for 'MantaID' to improve applicability. To our knowledge, 'MantaID' is the first tool that enables an automatic, quick, accurate, and comprehensive identification of large quantities of IDs, and can therefore be used as a starting point to facilitate the complex assimilation and aggregation of biological data across diverse databases.",
    "version": "1.0.4",
    "maintainer": "Zhengpeng Zeng <molaison@foxmail.com>",
    "author": "Zhengpeng Zeng [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0001-7919-209X>),\n  Longfei Mao [aut, cph] (ORCID: <https://orcid.org/0000-0003-0759-0501>),\n  Feng Yu [aut] (ORCID: <https://orcid.org/0000-0002-5221-281X>),\n  Jiamin Hu [ctb] (ORCID: <https://orcid.org/0000-0003-3030-2117>),\n  Xiting Wang [ctb] (ORCID: <https://orcid.org/0009-0009-5235-0006>)",
    "url": "https://molaison.github.io/MantaID/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MantaID",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MantaID A Machine-Learning Based Tool to Automate the Identification of\nBiological Database IDs The number of biological databases is growing rapidly, but different databases use different IDs to refer to the same biological entity. The inconsistency in IDs impedes the integration of various types of biological data. To resolve the problem, we developed 'MantaID', a data-driven, machine-learning based approach that automates identifying IDs on a large scale. The 'MantaID' model's prediction accuracy was proven to be 99%, and it correctly and effectively predicted 100,000 ID entries within two minutes. 'MantaID' supports the discovery and exploitation of ID patterns from large quantities of databases. (e.g., up to 542 biological databases). An easy-to-use freely available open-source software R package, a user-friendly web application, and API were also developed for 'MantaID' to improve applicability. To our knowledge, 'MantaID' is the first tool that enables an automatic, quick, accurate, and comprehensive identification of large quantities of IDs, and can therefore be used as a starting point to facilitate the complex assimilation and aggregation of biological data across diverse databases.  "
  },
  {
    "id": 4972,
    "package_name": "MatTransMix",
    "title": "Clustering with Matrix Gaussian and Matrix Transformation\nMixture Models",
    "description": "Provides matrix Gaussian mixture models, matrix transformation mixture models and their model-based clustering results. The parsimonious models of the mean matrices and variance covariance matrices are implemented with a total of 196 variations. For more information, please check: Xuwen Zhu, Shuchismita Sarkar, and Volodymyr Melnykov (2021), \"MatTransMix: an R package for matrix model-based clustering and parsimonious mixture modeling\",  <doi:10.1007/s00357-021-09401-9>.",
    "version": "0.1.18",
    "maintainer": "Xuwen Zhu <xzhu20@ua.edu>",
    "author": "Xuwen Zhu [aut, cre],\n  Volodymyr Melnykov [aut],\n  Shuchismita Sarkar [ctb],\n  Michael Hutt [ctb, cph],\n  Stephen Moshier [ctb, cph],\n  Rouben Rostamian [ctb, cph],\n  Carl Edward Rasmussen [ctb, cph],\n  Dianne Cook [ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MatTransMix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MatTransMix Clustering with Matrix Gaussian and Matrix Transformation\nMixture Models Provides matrix Gaussian mixture models, matrix transformation mixture models and their model-based clustering results. The parsimonious models of the mean matrices and variance covariance matrices are implemented with a total of 196 variations. For more information, please check: Xuwen Zhu, Shuchismita Sarkar, and Volodymyr Melnykov (2021), \"MatTransMix: an R package for matrix model-based clustering and parsimonious mixture modeling\",  <doi:10.1007/s00357-021-09401-9>.  "
  },
  {
    "id": 4998,
    "package_name": "MedDataSets",
    "title": "Comprehensive Medical, Disease, Treatment, and Drug Datasets",
    "description": "Provides an extensive collection of datasets related to medicine, \n    diseases, treatments, drugs, and public health. This package covers topics \n    such as drug effectiveness, vaccine trials, survival rates, \n    infectious disease outbreaks, and medical treatments. The included datasets \n    span various health conditions, including AIDS, cancer, bacterial infections, \n    and COVID-19, along with information on pharmaceuticals and vaccines. These \n    datasets are sourced from the R ecosystem and other R packages, remaining \n    unaltered to ensure data integrity. This package serves as a valuable \n    resource for researchers, analysts, and healthcare professionals interested \n    in conducting medical and public health data analysis in R.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/meddatasets",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MedDataSets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MedDataSets Comprehensive Medical, Disease, Treatment, and Drug Datasets Provides an extensive collection of datasets related to medicine, \n    diseases, treatments, drugs, and public health. This package covers topics \n    such as drug effectiveness, vaccine trials, survival rates, \n    infectious disease outbreaks, and medical treatments. The included datasets \n    span various health conditions, including AIDS, cancer, bacterial infections, \n    and COVID-19, along with information on pharmaceuticals and vaccines. These \n    datasets are sourced from the R ecosystem and other R packages, remaining \n    unaltered to ensure data integrity. This package serves as a valuable \n    resource for researchers, analysts, and healthcare professionals interested \n    in conducting medical and public health data analysis in R.  "
  },
  {
    "id": 5037,
    "package_name": "MetricGraph",
    "title": "Random Fields on Metric Graphs",
    "description": "Facilitates creation and manipulation of metric graphs, such as street or river networks. Further facilitates operations and visualizations of data on metric graphs, and the creation of a large class of random fields and stochastic partial differential equations on such spaces. These random fields can be used for simulation, prediction and inference. In particular, linear mixed effects models including random field components can be fitted to data based on computationally efficient sparse matrix representations. Interfaces to the R packages 'INLA' and 'inlabru' are also provided, which facilitate working with Bayesian statistical models on metric graphs. The main references for the methods are Bolin, Simas and Wallin (2024) <doi:10.3150/23-BEJ1647>, Bolin, Kovacs, Kumar and Simas (2023) <doi:10.1090/mcom/3929> and Bolin, Simas and Wallin (2023) <doi:10.48550/arXiv.2304.03190> and <doi:10.48550/arXiv.2304.10372>.",
    "version": "1.5.0",
    "maintainer": "David Bolin <davidbolin@gmail.com>",
    "author": "David Bolin [cre, aut],\n  Alexandre Simas [aut],\n  Jonas Wallin [aut]",
    "url": "https://davidbolin.github.io/MetricGraph/",
    "bug_reports": "https://github.com/davidbolin/MetricGraph/issues",
    "repository": "https://cran.r-project.org/package=MetricGraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MetricGraph Random Fields on Metric Graphs Facilitates creation and manipulation of metric graphs, such as street or river networks. Further facilitates operations and visualizations of data on metric graphs, and the creation of a large class of random fields and stochastic partial differential equations on such spaces. These random fields can be used for simulation, prediction and inference. In particular, linear mixed effects models including random field components can be fitted to data based on computationally efficient sparse matrix representations. Interfaces to the R packages 'INLA' and 'inlabru' are also provided, which facilitate working with Bayesian statistical models on metric graphs. The main references for the methods are Bolin, Simas and Wallin (2024) <doi:10.3150/23-BEJ1647>, Bolin, Kovacs, Kumar and Simas (2023) <doi:10.1090/mcom/3929> and Bolin, Simas and Wallin (2023) <doi:10.48550/arXiv.2304.03190> and <doi:10.48550/arXiv.2304.10372>.  "
  },
  {
    "id": 5045,
    "package_name": "MiRNAQCD",
    "title": "Micro-RNA Quality Control and Diagnosis",
    "description": "A complete and dedicated analytical toolbox for quality control and diagnosis based on subject-related measurements of micro-RNA (miRNA) expressions. The package consists of a set of functions that allow to train, optimize and use a Bayesian classifier that relies on multiplets of measured miRNA expressions. The package also implements the quality control tools required to preprocess input datasets. In addition, the package provides a function to carry out a statistical analysis of miRNA expressions, which can give insights to improve the classifier's performance. The method implemented in the package was first introduced in L. Ricci, V. Del Vescovo, C. Cantaloni, M. Grasso, M. Barbareschi and M. A. Denti, \"Statistical analysis of a Bayesian classifier based on the expression of miRNAs\", BMC Bioinformatics 16:287, 2015 <doi:10.1186/s12859-015-0715-9>. The package is thoroughly described in M. Castelluzzo, A. Perinelli, S. Detassis, M. A. Denti and L. Ricci, \"MiRNA-QC-and-Diagnosis: An R package for diagnosis based on MiRNA expression\", SoftwareX 12:100569, 2020 <doi:10.1016/j.softx.2020.100569>. Please cite both these works if you use the package for your analysis. DISCLAIMER: The software in this package is for general research purposes only and is thus provided WITHOUT ANY WARRANTY. It is NOT intended to form the basis of clinical decisions. Please refer to the GNU General Public License 3.0 (GPLv3) for further information.",
    "version": "1.1.3",
    "maintainer": "Alessio Perinelli <alessio.perinelli@unitn.it>",
    "author": "Michele Castelluzzo [aut],\n  Alessio Perinelli [cre],\n  Simone Detassis [aut],\n  Michela Alessandra Denti [aut],\n  Leonardo Ricci [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MiRNAQCD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MiRNAQCD Micro-RNA Quality Control and Diagnosis A complete and dedicated analytical toolbox for quality control and diagnosis based on subject-related measurements of micro-RNA (miRNA) expressions. The package consists of a set of functions that allow to train, optimize and use a Bayesian classifier that relies on multiplets of measured miRNA expressions. The package also implements the quality control tools required to preprocess input datasets. In addition, the package provides a function to carry out a statistical analysis of miRNA expressions, which can give insights to improve the classifier's performance. The method implemented in the package was first introduced in L. Ricci, V. Del Vescovo, C. Cantaloni, M. Grasso, M. Barbareschi and M. A. Denti, \"Statistical analysis of a Bayesian classifier based on the expression of miRNAs\", BMC Bioinformatics 16:287, 2015 <doi:10.1186/s12859-015-0715-9>. The package is thoroughly described in M. Castelluzzo, A. Perinelli, S. Detassis, M. A. Denti and L. Ricci, \"MiRNA-QC-and-Diagnosis: An R package for diagnosis based on MiRNA expression\", SoftwareX 12:100569, 2020 <doi:10.1016/j.softx.2020.100569>. Please cite both these works if you use the package for your analysis. DISCLAIMER: The software in this package is for general research purposes only and is thus provided WITHOUT ANY WARRANTY. It is NOT intended to form the basis of clinical decisions. Please refer to the GNU General Public License 3.0 (GPLv3) for further information.  "
  },
  {
    "id": 5050,
    "package_name": "MicroMacroMultilevel",
    "title": "Micro-Macro Multilevel Modeling",
    "description": "Most multilevel methodologies can only model macro-micro\n    multilevel situations in an unbiased way, wherein group-level predictors\n    (e.g., city temperature) are used to predict an individual-level\n    outcome variable (e.g., citizen personality). In contrast,\n    this R package enables researchers to model micro-macro situations, wherein\n    individual-level (micro) predictors (and other group-level predictors) are\n    used to predict a group-level (macro) outcome variable in an unbiased way.",
    "version": "0.4.0",
    "maintainer": "Nancy R Xu <nancyranxu@gmail.com>",
    "author": "Jackson G Lu [aut],\n  Elizabeth Page-Gould [aut],\n  Nancy R Xu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MicroMacroMultilevel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MicroMacroMultilevel Micro-Macro Multilevel Modeling Most multilevel methodologies can only model macro-micro\n    multilevel situations in an unbiased way, wherein group-level predictors\n    (e.g., city temperature) are used to predict an individual-level\n    outcome variable (e.g., citizen personality). In contrast,\n    this R package enables researchers to model micro-macro situations, wherein\n    individual-level (micro) predictors (and other group-level predictors) are\n    used to predict a group-level (macro) outcome variable in an unbiased way.  "
  },
  {
    "id": 5066,
    "package_name": "MiscMetabar",
    "title": "Miscellaneous Functions for Metabarcoding Analysis",
    "description": "Facilitate the description, transformation, exploration, and reproducibility of metabarcoding analyses. 'MiscMetabar' is mainly built on top of the 'phyloseq', 'dada2' and 'targets' R packages. It helps to build reproducible and robust bioinformatics pipelines in R. 'MiscMetabar' makes ecological analysis of alpha and beta-diversity easier, more reproducible and more powerful by integrating a large number of tools. Important features are described in Taudi\u00e8re A. (2023) <doi:10.21105/joss.06038>.",
    "version": "0.14.4",
    "maintainer": "Adrien Taudi\u00e8re <adrien.taudiere@zaclys.net>",
    "author": "Adrien Taudi\u00e8re [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1088-1182>)",
    "url": "https://github.com/adrientaudiere/MiscMetabar,\nhttps://adrientaudiere.github.io/MiscMetabar/",
    "bug_reports": "https://github.com/adrientaudiere/MiscMetabar/issues",
    "repository": "https://cran.r-project.org/package=MiscMetabar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MiscMetabar Miscellaneous Functions for Metabarcoding Analysis Facilitate the description, transformation, exploration, and reproducibility of metabarcoding analyses. 'MiscMetabar' is mainly built on top of the 'phyloseq', 'dada2' and 'targets' R packages. It helps to build reproducible and robust bioinformatics pipelines in R. 'MiscMetabar' makes ecological analysis of alpha and beta-diversity easier, more reproducible and more powerful by integrating a large number of tools. Important features are described in Taudi\u00e8re A. (2023) <doi:10.21105/joss.06038>.  "
  },
  {
    "id": 5068,
    "package_name": "MissMech",
    "title": "Testing Homoscedasticity, Multivariate Normality, and Missing\nCompletely at Random",
    "description": "To test whether the missing data mechanism, in a set of incompletely observed data, is one of missing completely at random (MCAR). \n    For detailed description see Jamshidian, M. Jalal, S., and Jansen, C. (2014). \"MissMech: An R Package for Testing Homoscedasticity, Multivariate Normality, and Missing Completely at Random (MCAR)\", Journal of Statistical Software, 56(6), 1-31. <https://www.jstatsoft.org/v56/i06/> <doi:10.18637/jss.v056.i06>.",
    "version": "1.0.4",
    "maintainer": "Mao Kobayashi <kobamao.jp@gmail.com>",
    "author": "Mortaza Jamshidian [aut],\n  Siavash Jalal [aut],\n  Camden Jansen [aut],\n  Mao Kobayashi [cre]",
    "url": "https://github.com/indenkun/MissMech",
    "bug_reports": "https://github.com/indenkun/MissMech/issues",
    "repository": "https://cran.r-project.org/package=MissMech",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MissMech Testing Homoscedasticity, Multivariate Normality, and Missing\nCompletely at Random To test whether the missing data mechanism, in a set of incompletely observed data, is one of missing completely at random (MCAR). \n    For detailed description see Jamshidian, M. Jalal, S., and Jansen, C. (2014). \"MissMech: An R Package for Testing Homoscedasticity, Multivariate Normality, and Missing Completely at Random (MCAR)\", Journal of Statistical Software, 56(6), 1-31. <https://www.jstatsoft.org/v56/i06/> <doi:10.18637/jss.v056.i06>.  "
  },
  {
    "id": 5113,
    "package_name": "MonoPhy",
    "title": "Explore Monophyly of Taxonomic Groups in a Phylogeny",
    "description": "Requires rooted phylogeny as input and creates a table of genera, their monophyly-status, which taxa cause problems in monophyly etc. Different information can be extracted from the output and a plot function allows visualization of the results in a number of ways. \n \"MonoPhy: a simple R package to find and visualize monophyly issues.\" Schwery, O. & O'Meara, B.C. (2016) <doi:10.7717/peerj-cs.56>.",
    "version": "1.3.2",
    "maintainer": "Orlando Schwery <schwery.macroevo@pm.me>",
    "author": "Orlando Schwery [aut, cre],\n  Brian C. O'Meara [aut, ctb],\n  Peter Cowman [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MonoPhy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MonoPhy Explore Monophyly of Taxonomic Groups in a Phylogeny Requires rooted phylogeny as input and creates a table of genera, their monophyly-status, which taxa cause problems in monophyly etc. Different information can be extracted from the output and a plot function allows visualization of the results in a number of ways. \n \"MonoPhy: a simple R package to find and visualize monophyly issues.\" Schwery, O. & O'Meara, B.C. (2016) <doi:10.7717/peerj-cs.56>.  "
  },
  {
    "id": 5119,
    "package_name": "MonteCarloSEM",
    "title": "Monte Carlo Data Simulation Package",
    "description": "Monte Carlo simulation allows testing different conditions given to the correct structural equation models. This package runs Monte Carlo simulations under different conditions (such as sample size or normality of data). Within the package data sets can be simulated and run based on the given model.\n  First, continuous and normal data sets are generated based on the given model. Later Fleishman's power method (1978) <DOI:10.1007/BF02293811> is used to add non-normality if exists. \n  When data generation is completed (or when generated data sets are given) model test can also be run.\n  Please cite as \"Or\u00e7an, F. (2021). MonteCarloSEM: An R Package to Simulate Data for SEM. International Journal of Assessment Tools in Education, 8 (3), 704-713.\"",
    "version": "0.0.8",
    "maintainer": "Fatih Orcan <fatihorcan84@gmail.com>",
    "author": "Fatih Orcan [aut, cre] (ORCID: <https://orcid.org/0000-0003-1727-0456>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MonteCarloSEM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MonteCarloSEM Monte Carlo Data Simulation Package Monte Carlo simulation allows testing different conditions given to the correct structural equation models. This package runs Monte Carlo simulations under different conditions (such as sample size or normality of data). Within the package data sets can be simulated and run based on the given model.\n  First, continuous and normal data sets are generated based on the given model. Later Fleishman's power method (1978) <DOI:10.1007/BF02293811> is used to add non-normality if exists. \n  When data generation is completed (or when generated data sets are given) model test can also be run.\n  Please cite as \"Or\u00e7an, F. (2021). MonteCarloSEM: An R Package to Simulate Data for SEM. International Journal of Assessment Tools in Education, 8 (3), 704-713.\"  "
  },
  {
    "id": 5127,
    "package_name": "MplusAutomation",
    "title": "An R Package for Facilitating Large-Scale Latent Variable\nAnalyses in Mplus",
    "description": "Leverages the R language to automate latent variable model estimation\n\tand interpretation using 'Mplus', a powerful latent variable modeling program\n\tdeveloped by Muthen and Muthen (<https://www.statmodel.com>). Specifically, this package\n    provides routines for creating related groups of models, running batches of\n    models, and extracting and tabulating model parameters and fit statistics.",
    "version": "1.2",
    "maintainer": "Michael Hallquist <michael.hallquist@gmail.com>",
    "author": "Michael Hallquist [aut, cre],\n  Joshua Wiley [aut],\n  Caspar van Lissa [ctb],\n  Daniel Morillo [ctb]",
    "url": "https://michaelhallquist.github.io/MplusAutomation/",
    "bug_reports": "https://github.com/michaelhallquist/MplusAutomation/issues",
    "repository": "https://cran.r-project.org/package=MplusAutomation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MplusAutomation An R Package for Facilitating Large-Scale Latent Variable\nAnalyses in Mplus Leverages the R language to automate latent variable model estimation\n\tand interpretation using 'Mplus', a powerful latent variable modeling program\n\tdeveloped by Muthen and Muthen (<https://www.statmodel.com>). Specifically, this package\n    provides routines for creating related groups of models, running batches of\n    models, and extracting and tabulating model parameters and fit statistics.  "
  },
  {
    "id": 5128,
    "package_name": "MplusLGM",
    "title": "Automate Latent Growth Mixture Modelling in 'Mplus'",
    "description": "Provide a suite of functions for conducting and automating Latent Growth Modeling (LGM) in 'Mplus', including Growth Curve Model (GCM), Growth-Based Trajectory Model (GBTM) and Latent Class Growth Analysis (LCGA). \n  The package builds upon the capabilities of the 'MplusAutomation' package (Hallquist & Wiley, 2018) to streamline large-scale latent variable analyses. \n  \u201cMplusAutomation: An R Package for Facilitating Large-Scale Latent Variable Analyses in Mplus.\u201d Structural Equation Modeling, 25(4), 621\u2013638. <doi:10.1080/10705511.2017.1402334>\n  The workflow implemented in this package follows the recommendations outlined in Van Der Nest et al. (2020). \n  \u201cAn Overview of Mixture Modeling for Latent Evolutions in Longitudinal Data: Modeling Approaches, Fit Statistics, and Software.\u201d Advances in Life Course Research, 43, Article 100323. <doi:10.1016/j.alcr.2019.100323>. ",
    "version": "1.0.0",
    "maintainer": "Olivier Percie du Sert <olivier.perciedusert@mail.mcgill.ca>",
    "author": "Olivier Percie du Sert [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-6283-2529>),\n  Joshua Unrau [aut]",
    "url": "https://github.com/OlivierPDS/MplusLGM",
    "bug_reports": "https://github.com/OlivierPDS/MplusLGM/issues",
    "repository": "https://cran.r-project.org/package=MplusLGM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MplusLGM Automate Latent Growth Mixture Modelling in 'Mplus' Provide a suite of functions for conducting and automating Latent Growth Modeling (LGM) in 'Mplus', including Growth Curve Model (GCM), Growth-Based Trajectory Model (GBTM) and Latent Class Growth Analysis (LCGA). \n  The package builds upon the capabilities of the 'MplusAutomation' package (Hallquist & Wiley, 2018) to streamline large-scale latent variable analyses. \n  \u201cMplusAutomation: An R Package for Facilitating Large-Scale Latent Variable Analyses in Mplus.\u201d Structural Equation Modeling, 25(4), 621\u2013638. <doi:10.1080/10705511.2017.1402334>\n  The workflow implemented in this package follows the recommendations outlined in Van Der Nest et al. (2020). \n  \u201cAn Overview of Mixture Modeling for Latent Evolutions in Longitudinal Data: Modeling Approaches, Fit Statistics, and Software.\u201d Advances in Life Course Research, 43, Article 100323. <doi:10.1016/j.alcr.2019.100323>.   "
  },
  {
    "id": 5202,
    "package_name": "NBR",
    "title": "Network-Based R-Statistics using Mixed Effects Models",
    "description": "An implementation of network-based statistics in R using mixed effects models.\n    Theoretical background for Network-Based Statistics can be found in Zalesky et al. (2010)\n    <doi:10.1016/j.neuroimage.2010.06.041>. For Mixed Effects Models check the\n    R package <https://CRAN.R-project.org/package=nlme>.",
    "version": "0.1.5",
    "maintainer": "Zeus Gracia-Tabuenca <zgtabuenca@comunidad.unam.mx>",
    "author": "Zeus Gracia-Tabuenca [aut, cre],\n  Sarael Alcauter [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NBR Network-Based R-Statistics using Mixed Effects Models An implementation of network-based statistics in R using mixed effects models.\n    Theoretical background for Network-Based Statistics can be found in Zalesky et al. (2010)\n    <doi:10.1016/j.neuroimage.2010.06.041>. For Mixed Effects Models check the\n    R package <https://CRAN.R-project.org/package=nlme>.  "
  },
  {
    "id": 5211,
    "package_name": "NCmisc",
    "title": "Miscellaneous Functions for Creating Adaptive Functions and\nScripts",
    "description": "A set of handy functions. Includes a versatile one line progress bar, one \n line function timer with detailed output, time delay function, text histogram, object \n preview, CRAN package search, simpler package installer, Linux command install check, \n a flexible Mode function, top function, simulation of correlated data, and more.",
    "version": "1.2.0",
    "maintainer": "Nicholas Cooper <njcooper@gmx.co.uk>",
    "author": "Nicholas Cooper",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NCmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NCmisc Miscellaneous Functions for Creating Adaptive Functions and\nScripts A set of handy functions. Includes a versatile one line progress bar, one \n line function timer with detailed output, time delay function, text histogram, object \n preview, CRAN package search, simpler package installer, Linux command install check, \n a flexible Mode function, top function, simulation of correlated data, and more.  "
  },
  {
    "id": 5249,
    "package_name": "NMVANOVA",
    "title": "Novice Model Variation ANOVA",
    "description": "Due to 'Rstudio's' status as open source software, we believe it will be utilized frequently for future data analysis by users whom lack formal training or experience with 'R'. The 'NMVANOVA' (Novice Model Variation ANOVA) a streamlined variation of experimental design functions that allows novice 'Rstudio' users to perform different model variations one-way analysis of variance without downloading  multiple libraries or packages. Users can easily manipulate the data block, and needed inputs so that users only have to plugin the four designed variables/values.",
    "version": "1.1.0",
    "maintainer": "Joseph Lipoff <josephlipoff@msn.com>",
    "author": "Joseph V. Lipoff, Will Pauls, Kaylin C. Dobbs, Jordan L. Jensen, Kevin Woods, Evan T. Johnson, Benjamin F. Timson, Scott D. Zimmerman,and Paul Plummer",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NMVANOVA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NMVANOVA Novice Model Variation ANOVA Due to 'Rstudio's' status as open source software, we believe it will be utilized frequently for future data analysis by users whom lack formal training or experience with 'R'. The 'NMVANOVA' (Novice Model Variation ANOVA) a streamlined variation of experimental design functions that allows novice 'Rstudio' users to perform different model variations one-way analysis of variance without downloading  multiple libraries or packages. Users can easily manipulate the data block, and needed inputs so that users only have to plugin the four designed variables/values.  "
  },
  {
    "id": 5256,
    "package_name": "NNbenchmark",
    "title": "Datasets and Functions to Benchmark Neural Network Packages",
    "description": "Datasets and functions to benchmark (convergence, speed, ease of use) R packages dedicated to regression with neural networks (no classification in this version). The templates for the tested packages are available in the R, R Markdown and HTML formats at <https://github.com/pkR-pkR/NNbenchmarkTemplates> and <https://theairbend3r.github.io/NNbenchmarkWeb/index.html>. The submitted article to the R-Journal can be read at <https://www.inmodelia.com/gsoc2020.html>.",
    "version": "3.2.0",
    "maintainer": "Patrice Kiener <rpackages@inmodelia.com>",
    "author": "Patrice Kiener [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0505-9920>),\n  Christophe Dutang [aut] (ORCID:\n    <https://orcid.org/0000-0001-6732-1501>),\n  Salsabila Mahdi [aut] (ORCID: <https://orcid.org/0000-0002-2559-4154>),\n  Akshaj Verma [aut] (ORCID: <https://orcid.org/0000-0002-3936-0033>),\n  Yifu Yan [ctb]",
    "url": "https://github.com/pkR-pkR/NNbenchmark",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NNbenchmark",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NNbenchmark Datasets and Functions to Benchmark Neural Network Packages Datasets and functions to benchmark (convergence, speed, ease of use) R packages dedicated to regression with neural networks (no classification in this version). The templates for the tested packages are available in the R, R Markdown and HTML formats at <https://github.com/pkR-pkR/NNbenchmarkTemplates> and <https://theairbend3r.github.io/NNbenchmarkWeb/index.html>. The submitted article to the R-Journal can be read at <https://www.inmodelia.com/gsoc2020.html>.  "
  },
  {
    "id": 5290,
    "package_name": "NasdaqDataLink",
    "title": "API Wrapper for Nasdaq Data Link",
    "description": "Functions for interacting directly with the Nasdaq Data Link API to offer data in a number of formats usable in R, downloading a zip with all data from a Nasdaq Data Link database, and the ability to search. This R package uses the Nasdaq Data Link API. For more information go to <https://docs.data.nasdaq.com/>. For more help on the package itself go to <https://data.nasdaq.com/tools/r>.",
    "version": "1.0.0",
    "maintainer": "Jamie Couture <jamie.couture@nasdaq.com>",
    "author": "Jamie Couture [cre],\n  Eric Vautour [aut],\n  Nasdaq Data Link. [cph]",
    "url": "https://github.com/nasdaq/data-link-r",
    "bug_reports": "https://github.com/nasdaq/data-link-r/issues",
    "repository": "https://cran.r-project.org/package=NasdaqDataLink",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NasdaqDataLink API Wrapper for Nasdaq Data Link Functions for interacting directly with the Nasdaq Data Link API to offer data in a number of formats usable in R, downloading a zip with all data from a Nasdaq Data Link database, and the ability to search. This R package uses the Nasdaq Data Link API. For more information go to <https://docs.data.nasdaq.com/>. For more help on the package itself go to <https://data.nasdaq.com/tools/r>.  "
  },
  {
    "id": 5300,
    "package_name": "NestMRMC",
    "title": "Single Reader Between-Cases AUC Estimator in Nested Data",
    "description": "This R package provides a calculation of between-cases AUC estimate, corresponding covariance, and variance estimate in the nested data problem.  Also, the package has the function to simulate the nested data. The calculated between-cases AUC estimate is used to evaluate the reader's diagnostic performance in clinical tasks with nested data. For more details on the above methods, please refer to the paper by H Du, S Wen, Y Guo, F Jin, BD Gallas (2022) <doi:10.1177/09622802221111539>. ",
    "version": "1.0",
    "maintainer": "Hongfei Du <hongfei@gwmail.gwu.edu>",
    "author": "Hongfei Du [aut, cre] (ORCID: <https://orcid.org/0000-0002-0633-594X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NestMRMC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NestMRMC Single Reader Between-Cases AUC Estimator in Nested Data This R package provides a calculation of between-cases AUC estimate, corresponding covariance, and variance estimate in the nested data problem.  Also, the package has the function to simulate the nested data. The calculated between-cases AUC estimate is used to evaluate the reader's diagnostic performance in clinical tasks with nested data. For more details on the above methods, please refer to the paper by H Du, S Wen, Y Guo, F Jin, BD Gallas (2022) <doi:10.1177/09622802221111539>.   "
  },
  {
    "id": 5321,
    "package_name": "NetworkComparr",
    "title": "Statistical Comparison of Networks",
    "description": "A permutation-based hypothesis test for statistical comparison of two networks based on the invariance measures of the R package 'NetworkComparisonTest' by van Borkulo et al. (2022), <doi:10.1037/met0000476>: network structure invariance, global strength invariance, edge invariance, and various centrality measures. Edgelists from dependent or independent samples are used as input. These edgelists are generated from concept maps and summed into two comparable group networks. The networks can be directed or undirected.",
    "version": "0.0.0.9",
    "maintainer": "Lara Trani <lara.trani@rptu.de>",
    "author": "Lara Trani [aut, cre] (ORCID: <https://orcid.org/0000-0002-8517-7168>),\n  Maike Sauer [aut] (ORCID: <https://orcid.org/0000-0002-1418-1194>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NetworkComparr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NetworkComparr Statistical Comparison of Networks A permutation-based hypothesis test for statistical comparison of two networks based on the invariance measures of the R package 'NetworkComparisonTest' by van Borkulo et al. (2022), <doi:10.1037/met0000476>: network structure invariance, global strength invariance, edge invariance, and various centrality measures. Edgelists from dependent or independent samples are used as input. These edgelists are generated from concept maps and summed into two comparable group networks. The networks can be directed or undirected.  "
  },
  {
    "id": 5371,
    "package_name": "OCSdata",
    "title": "Download Data from the 'Open Case Studies' Repository",
    "description": "\n    Provides functions to access and download data from the 'Open Case Studies' <https://www.opencasestudies.org/> \n    repositories on 'GitHub' <https://github.com/opencasestudies>. Different functions enable \n    users to grab the data they need at different sections in the case study, as well as \n    download the whole case study repository. All the user needs to do is input the name of \n    the case study being worked on. The package relies on the httr::GET() function to access\n    files through the 'GitHub' API. The functions usethis::use_zip() and usethis::create_from_github() \n    are used to clone and/or download the case study repositories. To cite an individual case study,\n    please see the respective 'README' file at <https://github.com/opencasestudies/>.\n    <https://github.com/opencasestudies/ocs-bp-rural-and-urban-obesity> \n    <https://github.com/opencasestudies/ocs-bp-air-pollution>\n    <https://github.com/opencasestudies/ocs-bp-vaping-case-study>\n    <https://github.com/opencasestudies/ocs-bp-opioid-rural-urban>\n    <https://github.com/opencasestudies/ocs-bp-RTC-wrangling>\n    <https://github.com/opencasestudies/ocs-bp-RTC-analysis>\n    <https://github.com/opencasestudies/ocs-bp-youth-disconnection>\n    <https://github.com/opencasestudies/ocs-bp-youth-mental-health>\n    <https://github.com/opencasestudies/ocs-bp-school-shootings-dashboard>\n    <https://github.com/opencasestudies/ocs-bp-co2-emissions>\n    <https://github.com/opencasestudies/ocs-bp-diet>.",
    "version": "1.0.2",
    "maintainer": "Carrie Wright <cwrigh60@jhu.edu>",
    "author": "Michael Breshock [aut],\n  Carrie Wright [aut, cre, ths] (ORCID:\n    <https://orcid.org/0000-0003-1325-6067>),\n  Stephanie Hicks [aut] (ORCID: <https://orcid.org/0000-0002-7858-0231>),\n  Leah Jager [ctb] (ORCID: <https://orcid.org/0000-0003-3362-2298>),\n  John Muschelli [ctb] (ORCID: <https://orcid.org/0000-0001-6469-1750>),\n  Margaret Taub [ctb] (ORCID: <https://orcid.org/0000-0001-8008-618X>)",
    "url": "https://github.com/opencasestudies/OCSdata,\nhttps://doi.org/10.5281/zenodo.5214347,\nhttps://www.opencasestudies.org/",
    "bug_reports": "https://github.com/opencasestudies/OCSdata/issues",
    "repository": "https://cran.r-project.org/package=OCSdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OCSdata Download Data from the 'Open Case Studies' Repository \n    Provides functions to access and download data from the 'Open Case Studies' <https://www.opencasestudies.org/> \n    repositories on 'GitHub' <https://github.com/opencasestudies>. Different functions enable \n    users to grab the data they need at different sections in the case study, as well as \n    download the whole case study repository. All the user needs to do is input the name of \n    the case study being worked on. The package relies on the httr::GET() function to access\n    files through the 'GitHub' API. The functions usethis::use_zip() and usethis::create_from_github() \n    are used to clone and/or download the case study repositories. To cite an individual case study,\n    please see the respective 'README' file at <https://github.com/opencasestudies/>.\n    <https://github.com/opencasestudies/ocs-bp-rural-and-urban-obesity> \n    <https://github.com/opencasestudies/ocs-bp-air-pollution>\n    <https://github.com/opencasestudies/ocs-bp-vaping-case-study>\n    <https://github.com/opencasestudies/ocs-bp-opioid-rural-urban>\n    <https://github.com/opencasestudies/ocs-bp-RTC-wrangling>\n    <https://github.com/opencasestudies/ocs-bp-RTC-analysis>\n    <https://github.com/opencasestudies/ocs-bp-youth-disconnection>\n    <https://github.com/opencasestudies/ocs-bp-youth-mental-health>\n    <https://github.com/opencasestudies/ocs-bp-school-shootings-dashboard>\n    <https://github.com/opencasestudies/ocs-bp-co2-emissions>\n    <https://github.com/opencasestudies/ocs-bp-diet>.  "
  },
  {
    "id": 5390,
    "package_name": "OPI",
    "title": "Open Perimetry Interface",
    "description": "Implementation of the Open Perimetry Interface (OPI) for simulating and controlling visual field machines using R. The OPI is a standard for interfacing with visual field testing machines (perimeters) first started as an open source project with support of Haag-Streit in 2010. It specifies basic functions that allow many visual field tests to be constructed. As of February 2022 it is fully implemented on the Haag-Streit Octopus 900 and 'CrewT ImoVifa' ('Topcon Tempo') with partial implementations on the Centervue Compass, Kowa AP 7000 and Android phones. It also has a cousin: the R package 'visualFields', which has tools for analysing and manipulating visual field data.",
    "version": "3.0.5",
    "maintainer": "Andrew Turpin <andrew.turpin@lei.org.au>",
    "author": "Andrew Turpin [cre, aut, cph] (ORCID: 0000-0003-2559-8769),\n  David Lawson [ctb, cph],\n  Ivan Marin-Franch [ctb, cph],\n  Matthias Muller [ctb],\n  Jonathan Denniss [ctb, cph],\n  Astrid Zeman [ctb],\n  Giovanni Montesano [ctb]",
    "url": "https://opi.lei.org.au/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OPI Open Perimetry Interface Implementation of the Open Perimetry Interface (OPI) for simulating and controlling visual field machines using R. The OPI is a standard for interfacing with visual field testing machines (perimeters) first started as an open source project with support of Haag-Streit in 2010. It specifies basic functions that allow many visual field tests to be constructed. As of February 2022 it is fully implemented on the Haag-Streit Octopus 900 and 'CrewT ImoVifa' ('Topcon Tempo') with partial implementations on the Centervue Compass, Kowa AP 7000 and Android phones. It also has a cousin: the R package 'visualFields', which has tools for analysing and manipulating visual field data.  "
  },
  {
    "id": 5395,
    "package_name": "OPTtesting",
    "title": "Optimal Testing",
    "description": "Optimal testing under general dependence. The R package implements procedures proposed in Wang, Han, and Tong (2022). The package includes parameter estimation procedures, the computation for the posterior probabilities, and the testing procedure.",
    "version": "1.0.0",
    "maintainer": "Lijia Wang <lijiawan@usc.edu>",
    "author": "Lijia Wang [aut, cre, cph],\n  Xu Han [aut],\n  Xin Tong [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OPTtesting",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OPTtesting Optimal Testing Optimal testing under general dependence. The R package implements procedures proposed in Wang, Han, and Tong (2022). The package includes parameter estimation procedures, the computation for the posterior probabilities, and the testing procedure.  "
  },
  {
    "id": 5407,
    "package_name": "OSLdecomposition",
    "title": "Signal Component Analysis for Optically Stimulated Luminescence",
    "description": "Function library for the identification and separation of exponentially\n    decaying signal components in continuous-wave optically stimulated luminescence measurements.\n    A special emphasis is laid on luminescence dating with quartz, which is known for\n    systematic errors due to signal components with unequal physical behaviour.\n    Also, this package enables an easy to use signal decomposition of\n    data sets imported and analysed with the R package 'Luminescence'.\n    This includes the optional automatic creation of HTML reports. Further information and tutorials\n    can be found at <https://luminescence.de>.",
    "version": "1.1.0",
    "maintainer": "Dirk Mittelstra\u00df <dirk.mittelstrass@luminescence.de>",
    "author": "Dirk Mittelstra\u00df [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9567-8791>),\n  Sebastian Kreutzer [aut] (ORCID:\n    <https://orcid.org/0000-0002-0734-2199>),\n  Christoph Schmidt [aut] (ORCID:\n    <https://orcid.org/0000-0002-2309-3209>),\n  Jan Beyer [ths] (ORCID: <https://orcid.org/0000-0002-1403-395X>),\n  Johannes Heitmann [ths],\n  Arno Straessner [ths] (ORCID: <https://orcid.org/0000-0003-2460-6659>)",
    "url": "",
    "bug_reports": "https://github.com/DirkMittelstrass/OSLdecomposition/issues",
    "repository": "https://cran.r-project.org/package=OSLdecomposition",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OSLdecomposition Signal Component Analysis for Optically Stimulated Luminescence Function library for the identification and separation of exponentially\n    decaying signal components in continuous-wave optically stimulated luminescence measurements.\n    A special emphasis is laid on luminescence dating with quartz, which is known for\n    systematic errors due to signal components with unequal physical behaviour.\n    Also, this package enables an easy to use signal decomposition of\n    data sets imported and analysed with the R package 'Luminescence'.\n    This includes the optional automatic creation of HTML reports. Further information and tutorials\n    can be found at <https://luminescence.de>.  "
  },
  {
    "id": 5422,
    "package_name": "OasisR",
    "title": "Outright Tool for the Analysis of Spatial Inequalities and\nSegregation",
    "description": "A comprehensive set of indexes and tests for social segregation analysis,\n              as described in Tivadar (2019) - 'OasisR': An R Package to Bring Some Order\n              to the World of Segregation Measurement <doi:10.18637/jss.v089.i07>.\n              The package  is the most complete existing tool and it clarifies\n              many ambiguities and errors regarding the definition of segregation\n              indices. Additionally, 'OasisR' introduces several resampling methods\n              that enable testing their statistical significance\n              (randomization tests, bootstrapping, and jackknife methods).",
    "version": "3.1.1",
    "maintainer": "Mihai Tivadar <mihai.tivadar@inrae.fr>",
    "author": "Mihai Tivadar [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OasisR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OasisR Outright Tool for the Analysis of Spatial Inequalities and\nSegregation A comprehensive set of indexes and tests for social segregation analysis,\n              as described in Tivadar (2019) - 'OasisR': An R Package to Bring Some Order\n              to the World of Segregation Measurement <doi:10.18637/jss.v089.i07>.\n              The package  is the most complete existing tool and it clarifies\n              many ambiguities and errors regarding the definition of segregation\n              indices. Additionally, 'OasisR' introduces several resampling methods\n              that enable testing their statistical significance\n              (randomization tests, bootstrapping, and jackknife methods).  "
  },
  {
    "id": 5487,
    "package_name": "OptimalDesign",
    "title": "A Toolbox for Computing Efficient Designs of Experiments",
    "description": "Algorithms for D-, A-, I-, and c-optimal designs. For more details, see the package description. Some of the functions in this package require the 'gurobi' software and its accompanying R package. For their installation, please follow the instructions at <https://www.gurobi.com> and the file gurobi_inst.txt, respectively.",
    "version": "1.0.3",
    "maintainer": "Lenka Filova <optimaldesignr@gmail.com>",
    "author": "Radoslav Harman [aut],\n  Lenka Filova [aut, cre]",
    "url": "http://www.iam.fmph.uniba.sk/design/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OptimalDesign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OptimalDesign A Toolbox for Computing Efficient Designs of Experiments Algorithms for D-, A-, I-, and c-optimal designs. For more details, see the package description. Some of the functions in this package require the 'gurobi' software and its accompanying R package. For their installation, please follow the instructions at <https://www.gurobi.com> and the file gurobi_inst.txt, respectively.  "
  },
  {
    "id": 5509,
    "package_name": "OutliersLearn",
    "title": "Educational Outlier Package with Common Outlier Detection\nAlgorithms",
    "description": "Provides implementations of some of the most important outlier detection algorithms. \n    Includes a tutorial mode option that shows a description of each algorithm and provides \n    a step-by-step execution explanation of how it identifies outliers from the given data \n    with the specified input parameters. References include the works of Azzedine Boukerche, \n    Lining Zheng, and Omar Alfandi (2020) <doi:10.1145/3381028>, Abir Smiti (2020) \n    <doi:10.1016/j.cosrev.2020.100306>, and Xiaogang Su, Chih-Ling Tsai (2011) \n    <doi:10.1002/widm.19>.",
    "version": "1.0.0",
    "maintainer": "Andres Missiego Manjon <andres.missiego@edu.uah.es>",
    "author": "Andres Missiego Manjon [aut, cre],\n        Juan Jose Cuadrado Gallego [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=OutliersLearn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "OutliersLearn Educational Outlier Package with Common Outlier Detection\nAlgorithms Provides implementations of some of the most important outlier detection algorithms. \n    Includes a tutorial mode option that shows a description of each algorithm and provides \n    a step-by-step execution explanation of how it identifies outliers from the given data \n    with the specified input parameters. References include the works of Azzedine Boukerche, \n    Lining Zheng, and Omar Alfandi (2020) <doi:10.1145/3381028>, Abir Smiti (2020) \n    <doi:10.1016/j.cosrev.2020.100306>, and Xiaogang Su, Chih-Ling Tsai (2011) \n    <doi:10.1002/widm.19>.  "
  },
  {
    "id": 5526,
    "package_name": "PAS",
    "title": "Polygenic Analysis System (PAS)",
    "description": "An R package for polygenic trait analysis. ",
    "version": "1.2.5",
    "maintainer": "Zhiqiu Hu <zhiqiu.hu@gmail.com>",
    "author": "Zhiqiu Hu; Shizhong Xu; Zhiquan Wang; Rongcai Yang",
    "url": "http://statgen.ucr.edu, http://www.ualberta.ca/~zhiqiu1",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PAS Polygenic Analysis System (PAS) An R package for polygenic trait analysis.   "
  },
  {
    "id": 5541,
    "package_name": "PBSmodelling",
    "title": "GUI Tools Made Easy: Interact with Models and Explore Data",
    "description": "Provides software to facilitate the design, testing, and operation\n   of computer models. It focuses particularly on tools that make it easy to\n   construct and edit a customized graphical user interface ('GUI'). Although our\n   simplified 'GUI' language depends heavily on the R interface to the 'Tcl/Tk'\n   package, a user does not need to know 'Tcl/Tk'. Examples illustrate models\n   built with other R packages, including 'PBSmapping', 'PBSddesolve', and 'BRugs'. \n   A complete user's guide 'PBSmodelling-UG.pdf' shows how to use this package\n   effectively.",
    "version": "2.70.2",
    "maintainer": "Nick Fisch <nick.fisch@dfo-mpo.gc.ca>",
    "author": "Jon T. Schnute [aut],\n  Alex Couture-Beil [aut],\n  Rowan Haigh [aut],\n  Nicholas Boers [aut],\n  Anisa Egeli [aut],\n  A. R. Kronlund [ctb],\n  Steve Martell [ctb],\n  Norm Olsen [ctb],\n  Nick Fisch [cre]",
    "url": "https://github.com/pbs-software/pbs-modelling",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PBSmodelling",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PBSmodelling GUI Tools Made Easy: Interact with Models and Explore Data Provides software to facilitate the design, testing, and operation\n   of computer models. It focuses particularly on tools that make it easy to\n   construct and edit a customized graphical user interface ('GUI'). Although our\n   simplified 'GUI' language depends heavily on the R interface to the 'Tcl/Tk'\n   package, a user does not need to know 'Tcl/Tk'. Examples illustrate models\n   built with other R packages, including 'PBSmapping', 'PBSddesolve', and 'BRugs'. \n   A complete user's guide 'PBSmodelling-UG.pdf' shows how to use this package\n   effectively.  "
  },
  {
    "id": 5555,
    "package_name": "PCMBase",
    "title": "Simulation and Likelihood Calculation of Phylogenetic\nComparative Models",
    "description": "Phylogenetic comparative methods represent models of continuous trait \n  data associated with the tips of a phylogenetic tree. Examples of such models \n  are Gaussian continuous time branching stochastic processes such as Brownian \n  motion (BM) and Ornstein-Uhlenbeck (OU) processes, which regard the data at the \n  tips of the tree as an observed (final) state of a Markov process starting from \n  an initial state at the root and evolving along the branches of the tree. The \n  PCMBase R package provides a general framework for manipulating such models. \n  This framework consists of an application programming interface for specifying \n  data and model parameters, and efficient algorithms for simulating trait evolution \n  under a model and calculating the likelihood of model parameters for an assumed\n  model and trait data. The package implements a growing collection of models, \n  which currently includes BM, OU, BM/OU with jumps, two-speed OU as well as mixed \n  Gaussian models, in which different types of the above models can be associated \n  with different branches of the tree. The PCMBase package is limited to \n  trait-simulation and likelihood calculation of (mixed) Gaussian phylogenetic \n  models. The PCMFit package provides functionality for inference of \n  these models to tree and trait data. The package web-site \n  <https://venelin.github.io/PCMBase/>\n  provides access to the documentation and other resources. ",
    "version": "1.2.15",
    "maintainer": "Venelin Mitov <vmitov@gmail.com>",
    "author": "Venelin Mitov [aut, cre, cph] (<a\n    href=\"https://venelin.github.io\">venelin.github.io</a>),\n  Krzysztof Bartoszek [ctb],\n  Georgios Asimomitis [ctb],\n  Tanja Stadler [ths]",
    "url": "https://venelin.github.io/PCMBase/, https://venelin.github.io",
    "bug_reports": "https://github.com/venelin/PCMBase/issues",
    "repository": "https://cran.r-project.org/package=PCMBase",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PCMBase Simulation and Likelihood Calculation of Phylogenetic\nComparative Models Phylogenetic comparative methods represent models of continuous trait \n  data associated with the tips of a phylogenetic tree. Examples of such models \n  are Gaussian continuous time branching stochastic processes such as Brownian \n  motion (BM) and Ornstein-Uhlenbeck (OU) processes, which regard the data at the \n  tips of the tree as an observed (final) state of a Markov process starting from \n  an initial state at the root and evolving along the branches of the tree. The \n  PCMBase R package provides a general framework for manipulating such models. \n  This framework consists of an application programming interface for specifying \n  data and model parameters, and efficient algorithms for simulating trait evolution \n  under a model and calculating the likelihood of model parameters for an assumed\n  model and trait data. The package implements a growing collection of models, \n  which currently includes BM, OU, BM/OU with jumps, two-speed OU as well as mixed \n  Gaussian models, in which different types of the above models can be associated \n  with different branches of the tree. The PCMBase package is limited to \n  trait-simulation and likelihood calculation of (mixed) Gaussian phylogenetic \n  models. The PCMFit package provides functionality for inference of \n  these models to tree and trait data. The package web-site \n  <https://venelin.github.io/PCMBase/>\n  provides access to the documentation and other resources.   "
  },
  {
    "id": 5634,
    "package_name": "PNAR",
    "title": "Poisson Network Autoregressive Models",
    "description": "Quasi likelihood-based methods for estimating linear and log-linear Poisson Network Autoregression models with p lags and covariates. Tools for testing the linearity versus several non-linear alternatives. Tools for simulation of multivariate count distributions, from linear and non-linear PNAR models, by using a specific copula construction. References include: Armillotta, M. and K. Fokianos (2023). \"Nonlinear network autoregression\". Annals of Statistics, 51(6): 2526--2552. <doi:10.1214/23-AOS2345>. Armillotta, M. and K. Fokianos (2024). \"Count network autoregression\". Journal of Time Series Analysis, 45(4): 584--612. <doi:10.1111/jtsa.12728>. Armillotta, M., Tsagris, M. and Fokianos, K. (2024). \"Inference for Network Count Time Series with the R Package PNAR\". The R Journal, 15/4: 255--269. <doi:10.32614/RJ-2023-094>.",
    "version": "1.7",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "author": "Michail Tsagris [aut, cre],\n  Mirko Armillotta [aut, cph],\n  Konstantinos Fokianos [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PNAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PNAR Poisson Network Autoregressive Models Quasi likelihood-based methods for estimating linear and log-linear Poisson Network Autoregression models with p lags and covariates. Tools for testing the linearity versus several non-linear alternatives. Tools for simulation of multivariate count distributions, from linear and non-linear PNAR models, by using a specific copula construction. References include: Armillotta, M. and K. Fokianos (2023). \"Nonlinear network autoregression\". Annals of Statistics, 51(6): 2526--2552. <doi:10.1214/23-AOS2345>. Armillotta, M. and K. Fokianos (2024). \"Count network autoregression\". Journal of Time Series Analysis, 45(4): 584--612. <doi:10.1111/jtsa.12728>. Armillotta, M., Tsagris, M. and Fokianos, K. (2024). \"Inference for Network Count Time Series with the R Package PNAR\". The R Journal, 15/4: 255--269. <doi:10.32614/RJ-2023-094>.  "
  },
  {
    "id": 5734,
    "package_name": "PaRe",
    "title": "A Way to Perform Code Review or QA on Other Packages",
    "description": "Reviews other packages during code review by looking at their\n    dependencies, code style, code complexity, and how internally defined\n    functions interact with one another.",
    "version": "0.1.15",
    "maintainer": "Maarten van Kessel <m.l.vankessel@erasmusmc.nl>",
    "author": "Maarten van Kessel [aut, cre] (ORCID:\n    <https://orcid.org/0009-0006-8832-6030>)",
    "url": "https://github.com/darwin-eu-dev/PaRe",
    "bug_reports": "https://github.com/darwin-eu-dev/PaRe/issues",
    "repository": "https://cran.r-project.org/package=PaRe",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PaRe A Way to Perform Code Review or QA on Other Packages Reviews other packages during code review by looking at their\n    dependencies, code style, code complexity, and how internally defined\n    functions interact with one another.  "
  },
  {
    "id": 5740,
    "package_name": "PakPC",
    "title": "'shiny' App to Analyze Pakistan's Population Census Data",
    "description": "Provides tools for analyzing Pakistan's Population Censuses data via the 'PakPC2023' and 'PakPC2017' R packages. Designed for researchers, policymakers, and professionals, the app enables in-depth numerical and graphical analysis, including detailed cross-tabulations and insights. With diverse statistical models and visualization options, it supports informed decision-making in social and economic policy. This tool enhances users' ability to explore and interpret census data, providing valuable insights for effective planning and analysis across various fields.",
    "version": "0.3.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5923-1714>),\n  Muhammad Arfan Dilber [ctb],\n  Zahid Asghar [ctb]",
    "url": "https://myaseen208.com/PakPC/\nhttps://myaseen208.shinyapps.io/PakPC/\nhttps://CRAN.R-project.org/package=PakPC",
    "bug_reports": "https://github.com/myaseen208/PakPC/issues",
    "repository": "https://cran.r-project.org/package=PakPC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPC 'shiny' App to Analyze Pakistan's Population Census Data Provides tools for analyzing Pakistan's Population Censuses data via the 'PakPC2023' and 'PakPC2017' R packages. Designed for researchers, policymakers, and professionals, the app enables in-depth numerical and graphical analysis, including detailed cross-tabulations and insights. With diverse statistical models and visualization options, it supports informed decision-making in social and economic policy. This tool enhances users' ability to explore and interpret census data, providing valuable insights for effective planning and analysis across various fields.  "
  },
  {
    "id": 5761,
    "package_name": "ParDNAcopy",
    "title": "Parallel implementation of the \"segment\" function of package\n\"DNAcopy\"",
    "description": "Parallelized version of the \"segment\" function from Bioconductor package \"DNAcopy\", utilizing multi-core computation on host CPU",
    "version": "2.0",
    "maintainer": "Guoli Sun <guolisun87@gmail.com>",
    "author": "Alex Krasnitz, Guoli Sun",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ParDNAcopy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ParDNAcopy Parallel implementation of the \"segment\" function of package\n\"DNAcopy\" Parallelized version of the \"segment\" function from Bioconductor package \"DNAcopy\", utilizing multi-core computation on host CPU  "
  },
  {
    "id": 5809,
    "package_name": "PhageCocktail",
    "title": "Design of the Best Phage Cocktail",
    "description": "There are 4 possible methods: \"ExhaustiveSearch\"; \"ExhaustivePhi\";    \"ClusteringSearch\"; and \"ClusteringPhi\". \n    \"ExhaustiveSearch\"--> gives you the best phage cocktail from a phage-bacteria\n\tinfection network. It checks different phage cocktail sizes from 1 to 7 and\n\tonly stops before if it lyses all bacteria. Other option is when users have\n\tdecided not to obtain a phage cocktail size higher than a limit value.\n    \"ExhaustivePhi\"--> firstly, it finds Phi out. Phi is a formula\n\tindicating the necessary phage cocktail size. Phi needs nestedness temperature\n\tand fill, which are internally calculated. This function will only look for the\n\tbest combination (phage cocktail) with a Phi size.\n    \"ClusteringSearch\"--> firstly, an agglomerative hierarchical clustering using\n\tWard's algorithm is calculated for phages. They will be clustered according to\n\tbacteria lysed by them. PhageCocktail() chooses how many clusters are needed in\n\torder to select 1 phage per cluster. Using the phages selected during the\n\tclustering, it checks different phage cocktail sizes from 1 to 7 and only stops\n\tbefore if it lyses all bacteria. Other option is when users have decided not to\n\tobtain a phage cocktail size higher than a limit value.\n    \"ClusteringPhi\"--> firstly, an agglomerative hierarchical clustering using Ward's\n\talgorithm is calculated for phages. They will be clustered according to bacteria\n\tlysed by them. PhageCocktail() chooses how many clusters are needed in order to\n\tselect 1 phage per cluster. Once the function has one phage per cluster, it\n\tcalculates Phi. If the number of clusters is less than Phi number, it will be\n\tchanged to obtain, as minimum, this quantity of candidates (phages). Then, it\n\tcalculates the best combination of Phi phages using those selected during the\n\tclustering with Ward algorithm.\n\t  If you use PhageCocktail, please cite it as:\n  \"PhageCocktail: An R Package to Design Phage Cocktails from Experimental \n  Phage-Bacteria Infection Networks\". Mar\u00eda Victoria D\u00edaz-Gali\u00e1n, Miguel A. \n  Vega-Rodr\u00edguez, Felipe Molina. Computer Methods and Programs in Biomedicine,\n  221, 106865, Elsevier Ireland, Clare, Ireland, 2022, pp. 1-9, ISSN: 0169-2607.\n  <doi:10.1016/j.cmpb.2022.106865>.",
    "version": "1.0.3",
    "maintainer": "Maria Victoria Diaz-Galian <mvdiazgalian@unex.es>",
    "author": "Maria Victoria Diaz-Galian [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2543-6081>),\n  Miguel A. Vega-Rodriguez [aut] (ORCID:\n    <https://orcid.org/0000-0002-3003-758X>),\n  Felipe Molina [aut] (ORCID: <https://orcid.org/0000-0002-9167-7097>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PhageCocktail",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PhageCocktail Design of the Best Phage Cocktail There are 4 possible methods: \"ExhaustiveSearch\"; \"ExhaustivePhi\";    \"ClusteringSearch\"; and \"ClusteringPhi\". \n    \"ExhaustiveSearch\"--> gives you the best phage cocktail from a phage-bacteria\n\tinfection network. It checks different phage cocktail sizes from 1 to 7 and\n\tonly stops before if it lyses all bacteria. Other option is when users have\n\tdecided not to obtain a phage cocktail size higher than a limit value.\n    \"ExhaustivePhi\"--> firstly, it finds Phi out. Phi is a formula\n\tindicating the necessary phage cocktail size. Phi needs nestedness temperature\n\tand fill, which are internally calculated. This function will only look for the\n\tbest combination (phage cocktail) with a Phi size.\n    \"ClusteringSearch\"--> firstly, an agglomerative hierarchical clustering using\n\tWard's algorithm is calculated for phages. They will be clustered according to\n\tbacteria lysed by them. PhageCocktail() chooses how many clusters are needed in\n\torder to select 1 phage per cluster. Using the phages selected during the\n\tclustering, it checks different phage cocktail sizes from 1 to 7 and only stops\n\tbefore if it lyses all bacteria. Other option is when users have decided not to\n\tobtain a phage cocktail size higher than a limit value.\n    \"ClusteringPhi\"--> firstly, an agglomerative hierarchical clustering using Ward's\n\talgorithm is calculated for phages. They will be clustered according to bacteria\n\tlysed by them. PhageCocktail() chooses how many clusters are needed in order to\n\tselect 1 phage per cluster. Once the function has one phage per cluster, it\n\tcalculates Phi. If the number of clusters is less than Phi number, it will be\n\tchanged to obtain, as minimum, this quantity of candidates (phages). Then, it\n\tcalculates the best combination of Phi phages using those selected during the\n\tclustering with Ward algorithm.\n\t  If you use PhageCocktail, please cite it as:\n  \"PhageCocktail: An R Package to Design Phage Cocktails from Experimental \n  Phage-Bacteria Infection Networks\". Mar\u00eda Victoria D\u00edaz-Gali\u00e1n, Miguel A. \n  Vega-Rodr\u00edguez, Felipe Molina. Computer Methods and Programs in Biomedicine,\n  221, 106865, Elsevier Ireland, Clare, Ireland, 2022, pp. 1-9, ISSN: 0169-2607.\n  <doi:10.1016/j.cmpb.2022.106865>.  "
  },
  {
    "id": 5863,
    "package_name": "PointedSDMs",
    "title": "Fit Models Derived from Point Processes to Species Distributions\nusing 'inlabru'",
    "description": "Integrated species distribution modeling is a rising field in quantitative ecology thanks to significant rises in the quantity of data available, increases in computational speed and the proven benefits of using such models. \n  Despite this, the general software to help ecologists construct such models in an easy-to-use framework is lacking. \n  We therefore introduce the R package 'PointedSDMs': which provides the tools to help ecologists set up integrated models and perform inference on them.\n  There are also functions within the package to help run spatial cross-validation for model selection, as well as generic plotting and predicting functions.\n  An introduction to these methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O\u2019Hara (2020) <doi:10.1016/j.tree.2019.08.006>.",
    "version": "2.1.4",
    "maintainer": "Philip Mostert <philip.s.mostert@ntnu.no>",
    "author": "Philip Mostert [aut, cre],\n  Bob O'hara [aut]",
    "url": "https://github.com/PhilipMostert/PointedSDMs",
    "bug_reports": "https://github.com/PhilipMostert/PointedSDMs/issues",
    "repository": "https://cran.r-project.org/package=PointedSDMs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PointedSDMs Fit Models Derived from Point Processes to Species Distributions\nusing 'inlabru' Integrated species distribution modeling is a rising field in quantitative ecology thanks to significant rises in the quantity of data available, increases in computational speed and the proven benefits of using such models. \n  Despite this, the general software to help ecologists construct such models in an easy-to-use framework is lacking. \n  We therefore introduce the R package 'PointedSDMs': which provides the tools to help ecologists set up integrated models and perform inference on them.\n  There are also functions within the package to help run spatial cross-validation for model selection, as well as generic plotting and predicting functions.\n  An introduction to these methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O\u2019Hara (2020) <doi:10.1016/j.tree.2019.08.006>.  "
  },
  {
    "id": 5938,
    "package_name": "ProbeDeveloper",
    "title": "Develop Hybridization Probes",
    "description": "Hybridization probes for target sequences can be made based on melting temperature value calculated by R package 'TmCalculator' <https://CRAN.R-project.org/package=TmCalculator> and methods extended from Beliveau, B. J.,(2018) <doi:10.1073/pnas.1714530115>, and those hybridization probes can be used to capture specific target regions in fluorescence in situ hybridization and next generation sequence experiments.",
    "version": "1.1.0",
    "maintainer": "Junhui Li <junhuili@cau.edu.cn>",
    "author": "Junhui Li",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ProbeDeveloper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ProbeDeveloper Develop Hybridization Probes Hybridization probes for target sequences can be made based on melting temperature value calculated by R package 'TmCalculator' <https://CRAN.R-project.org/package=TmCalculator> and methods extended from Beliveau, B. J.,(2018) <doi:10.1073/pnas.1714530115>, and those hybridization probes can be used to capture specific target regions in fluorescence in situ hybridization and next generation sequence experiments.  "
  },
  {
    "id": 5954,
    "package_name": "ProteinPCA",
    "title": "Principal Component Analysis (PCA) Tool on Protein Expression\nData",
    "description": "Analysis of protein expression data can be done through Principal Component Analysis (PCA), and this R package is designed to streamline the analysis. This package enables users to perform PCA and it generates biplot and scree plot for advanced graphical visualization. Optionally, it supports grouping/clustering visualization with PCA loadings and confidence ellipses. With this R package, researchers can quickly explore complex protein datasets, interpret variance contributions, and visualize sample clustering through intuitive biplots. For more details, see Jolliffe (2001) <doi:10.1007/b98835>, Gabriel (1971) <doi:10.1093/biomet/58.3.453>, Zhang et al. (2024) <doi:10.1038/s41467-024-53239-9>, and Anandan et al. (2022) <doi:10.1038/s41598-022-07781-5>.",
    "version": "0.1.1",
    "maintainer": "Paul Angelo C. Manlapaz <pacmanlapaz@gmail.com>",
    "author": "Paul Angelo C. Manlapaz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1203-2064>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ProteinPCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ProteinPCA Principal Component Analysis (PCA) Tool on Protein Expression\nData Analysis of protein expression data can be done through Principal Component Analysis (PCA), and this R package is designed to streamline the analysis. This package enables users to perform PCA and it generates biplot and scree plot for advanced graphical visualization. Optionally, it supports grouping/clustering visualization with PCA loadings and confidence ellipses. With this R package, researchers can quickly explore complex protein datasets, interpret variance contributions, and visualize sample clustering through intuitive biplots. For more details, see Jolliffe (2001) <doi:10.1007/b98835>, Gabriel (1971) <doi:10.1093/biomet/58.3.453>, Zhang et al. (2024) <doi:10.1038/s41467-024-53239-9>, and Anandan et al. (2022) <doi:10.1038/s41598-022-07781-5>.  "
  },
  {
    "id": 5982,
    "package_name": "QBMS",
    "title": "Query the Breeding Management System(s)",
    "description": "This R package assists breeders in linking data systems with their analytic pipelines, \n    a crucial step in digitizing breeding processes. It supports querying and retrieving \n    phenotypic and genotypic data from systems like 'EBS' <https://ebs.excellenceinbreeding.org/>, \n    'BMS' <https://bmspro.io>, 'BreedBase' <https://breedbase.org>,\n    'GIGWA' <https://github.com/SouthGreenPlatform/Gigwa2> (using 'BrAPI' <https://brapi.org> calls),\n    , and 'Germinate' <https://germinateplatform.github.io/get-germinate/>. \n    Extra helper functions support environmental data sources, including \n    'TerraClimate' <https://www.climatologylab.org/terraclimate.html> and 'FAO' \n    'HWSDv2' <https://gaez.fao.org/pages/hwsd> soil database. ",
    "version": "2.0.0",
    "maintainer": "Khaled Al-Shamaa <k.el-shamaa@cgiar.org>",
    "author": "Khaled Al-Shamaa [aut, cre],\n  Mariano Omar Crimi [ctb],\n  Zakaria Kehel [ctb],\n  Johan Aparicio [ctb],\n  ICARDA [cph]",
    "url": "https://icarda.github.io/QBMS/",
    "bug_reports": "https://github.com/icarda/QBMS/issues",
    "repository": "https://cran.r-project.org/package=QBMS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QBMS Query the Breeding Management System(s) This R package assists breeders in linking data systems with their analytic pipelines, \n    a crucial step in digitizing breeding processes. It supports querying and retrieving \n    phenotypic and genotypic data from systems like 'EBS' <https://ebs.excellenceinbreeding.org/>, \n    'BMS' <https://bmspro.io>, 'BreedBase' <https://breedbase.org>,\n    'GIGWA' <https://github.com/SouthGreenPlatform/Gigwa2> (using 'BrAPI' <https://brapi.org> calls),\n    , and 'Germinate' <https://germinateplatform.github.io/get-germinate/>. \n    Extra helper functions support environmental data sources, including \n    'TerraClimate' <https://www.climatologylab.org/terraclimate.html> and 'FAO' \n    'HWSDv2' <https://gaez.fao.org/pages/hwsd> soil database.   "
  },
  {
    "id": 6022,
    "package_name": "Qindex.data",
    "title": "Data for Package 'Qindex'",
    "description": "Example data used in package 'Qindex'.",
    "version": "0.1.3",
    "maintainer": "Tingting Zhan <tingtingzhan@gmail.com>",
    "author": "Tingting Zhan [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9971-4844>),\n  Misung Yi [aut, cph] (ORCID: <https://orcid.org/0000-0002-4007-5408>),\n  Inna Chervoneva [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-9104-4505>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Qindex.data",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Qindex.data Data for Package 'Qindex' Example data used in package 'Qindex'.  "
  },
  {
    "id": 6034,
    "package_name": "Quandl",
    "title": "API Wrapper for Quandl.com",
    "description": "Functions for interacting directly with the Quandl API to offer data in a number of formats usable in R, downloading a zip with all data from a Quandl database, and the ability to search. This R package uses the Quandl API. For more information go to <https://docs.quandl.com>. For more help on the package itself go to <https://www.quandl.com/tools/r>.",
    "version": "2.11.0",
    "maintainer": "Dave Dotson <dave@quandl.com>",
    "author": "Dave Dotson [cre],\n  Raymond McTaggart [aut],\n  Gergely Daroczi [aut],\n  Clement Leung [aut],\n  Quandl Inc. [cph]",
    "url": "https://github.com/quandl/quandl-r",
    "bug_reports": "https://github.com/quandl/quandl-r/issues",
    "repository": "https://cran.r-project.org/package=Quandl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Quandl API Wrapper for Quandl.com Functions for interacting directly with the Quandl API to offer data in a number of formats usable in R, downloading a zip with all data from a Quandl database, and the ability to search. This R package uses the Quandl API. For more information go to <https://docs.quandl.com>. For more help on the package itself go to <https://www.quandl.com/tools/r>.  "
  },
  {
    "id": 6053,
    "package_name": "R.methodsS3",
    "title": "S3 Methods Simplified",
    "description": "Methods that simplify the setup of S3 generic functions and S3 methods.  Major effort has been made in making definition of methods as simple as possible with a minimum of maintenance for package developers.  For example, generic functions are created automatically, if missing, and naming conflict are automatically solved, if possible.  The method setMethodS3() is a good start for those who in the future may want to migrate to S4.  This is a cross-platform package implemented in pure R that generates standard S3 methods.",
    "version": "1.8.2",
    "maintainer": "Henrik Bengtsson <henrikb@braju.com>",
    "author": "Henrik Bengtsson [aut, cre, cph]",
    "url": "https://github.com/HenrikBengtsson/R.methodsS3",
    "bug_reports": "https://github.com/HenrikBengtsson/R.methodsS3/issues",
    "repository": "https://cran.r-project.org/package=R.methodsS3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R.methodsS3 S3 Methods Simplified Methods that simplify the setup of S3 generic functions and S3 methods.  Major effort has been made in making definition of methods as simple as possible with a minimum of maintenance for package developers.  For example, generic functions are created automatically, if missing, and naming conflict are automatically solved, if possible.  The method setMethodS3() is a good start for those who in the future may want to migrate to S4.  This is a cross-platform package implemented in pure R that generates standard S3 methods.  "
  },
  {
    "id": 6054,
    "package_name": "R.oo",
    "title": "R Object-Oriented Programming with or without References",
    "description": "Methods and classes for object-oriented programming in R with or without references.  Large effort has been made on making definition of methods as simple as possible with a minimum of maintenance for package developers.  The package has been developed since 2001 and is now considered very stable.  This is a cross-platform package implemented in pure R that defines standard S3 classes without any tricks.",
    "version": "1.27.1",
    "maintainer": "Henrik Bengtsson <henrikb@braju.com>",
    "author": "Henrik Bengtsson [aut, cre, cph]",
    "url": "https://henrikbengtsson.github.io/R.oo/,\nhttps://github.com/HenrikBengtsson/R.oo",
    "bug_reports": "https://github.com/HenrikBengtsson/R.oo/issues",
    "repository": "https://cran.r-project.org/package=R.oo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R.oo R Object-Oriented Programming with or without References Methods and classes for object-oriented programming in R with or without references.  Large effort has been made on making definition of methods as simple as possible with a minimum of maintenance for package developers.  The package has been developed since 2001 and is now considered very stable.  This is a cross-platform package implemented in pure R that defines standard S3 classes without any tricks.  "
  },
  {
    "id": 6055,
    "package_name": "R.rsp",
    "title": "Dynamic Generation of Scientific Reports",
    "description": "The RSP markup language makes any text-based document come alive.  RSP provides a powerful markup for controlling the content and output of LaTeX, HTML, Markdown, AsciiDoc, Sweave and knitr documents (and more), e.g. 'Today's date is <%=Sys.Date()%>'.  Contrary to many other literate programming languages, with RSP it is straightforward to loop over mixtures of code and text sections, e.g. in month-by-month summaries.  RSP has also several preprocessing directives for incorporating static and dynamic contents of external files (local or online) among other things.  Functions rstring() and rcat() make it easy to process RSP strings, rsource() sources an RSP file as it was an R script, while rfile() compiles it (even online) into its final output format, e.g. rfile('report.tex.rsp') generates 'report.pdf' and rfile('report.md.rsp') generates 'report.html'.  RSP is ideal for self-contained scientific reports and R package vignettes.  It's easy to use - if you know how to write an R script, you'll be up and running within minutes.",
    "version": "0.46.0",
    "maintainer": "Henrik Bengtsson <henrikb@braju.com>",
    "author": "Henrik Bengtsson [aut, cre, cph]",
    "url": "https://henrikbengtsson.github.io/R.rsp/,\nhttps://github.com/HenrikBengtsson/R.rsp",
    "bug_reports": "https://github.com/HenrikBengtsson/R.rsp/issues",
    "repository": "https://cran.r-project.org/package=R.rsp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R.rsp Dynamic Generation of Scientific Reports The RSP markup language makes any text-based document come alive.  RSP provides a powerful markup for controlling the content and output of LaTeX, HTML, Markdown, AsciiDoc, Sweave and knitr documents (and more), e.g. 'Today's date is <%=Sys.Date()%>'.  Contrary to many other literate programming languages, with RSP it is straightforward to loop over mixtures of code and text sections, e.g. in month-by-month summaries.  RSP has also several preprocessing directives for incorporating static and dynamic contents of external files (local or online) among other things.  Functions rstring() and rcat() make it easy to process RSP strings, rsource() sources an RSP file as it was an R script, while rfile() compiles it (even online) into its final output format, e.g. rfile('report.tex.rsp') generates 'report.pdf' and rfile('report.md.rsp') generates 'report.html'.  RSP is ideal for self-contained scientific reports and R package vignettes.  It's easy to use - if you know how to write an R script, you'll be up and running within minutes.  "
  },
  {
    "id": 6057,
    "package_name": "R.utils",
    "title": "Various Programming Utilities",
    "description": "Utility functions useful when programming and developing R packages.",
    "version": "2.13.0",
    "maintainer": "Henrik Bengtsson <henrikb@braju.com>",
    "author": "Henrik Bengtsson [aut, cre, cph]",
    "url": "https://henrikbengtsson.github.io/R.utils/,\nhttps://github.com/HenrikBengtsson/R.utils",
    "bug_reports": "https://github.com/HenrikBengtsson/R.utils/issues",
    "repository": "https://cran.r-project.org/package=R.utils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R.utils Various Programming Utilities Utility functions useful when programming and developing R packages.  "
  },
  {
    "id": 6081,
    "package_name": "R6causal",
    "title": "R6 Class for Structural Causal Models",
    "description": "The implemented R6 class 'SCM' aims to simplify working with structural causal models. The missing data mechanism can be defined as a part of the structural model. The class contains methods for 1) defining a structural causal model via functions, text or conditional probability tables, 2) printing basic information on the model, 3) plotting the graph for the model using packages 'igraph' or 'qgraph', 4) simulating data from the model, 5) applying an intervention, 6) checking the identifiability of a query using the R packages 'causaleffect' and 'dosearch', 7) defining the missing data mechanism, 8) simulating incomplete data from the model according to the specified missing data mechanism and 9) checking the identifiability in a missing data problem using the R package 'dosearch'. In addition, there are functions for running experiments and doing counterfactual inference using simulation.",
    "version": "0.8.3",
    "maintainer": "Juha Karvanen <juha.karvanen@iki.fi>",
    "author": "Juha Karvanen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5530-769X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=R6causal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R6causal R6 Class for Structural Causal Models The implemented R6 class 'SCM' aims to simplify working with structural causal models. The missing data mechanism can be defined as a part of the structural model. The class contains methods for 1) defining a structural causal model via functions, text or conditional probability tables, 2) printing basic information on the model, 3) plotting the graph for the model using packages 'igraph' or 'qgraph', 4) simulating data from the model, 5) applying an intervention, 6) checking the identifiability of a query using the R packages 'causaleffect' and 'dosearch', 7) defining the missing data mechanism, 8) simulating incomplete data from the model according to the specified missing data mechanism and 9) checking the identifiability in a missing data problem using the R package 'dosearch'. In addition, there are functions for running experiments and doing counterfactual inference using simulation.  "
  },
  {
    "id": 6083,
    "package_name": "RAC",
    "title": "R Package for Aqua Culture",
    "description": "Solves the individual bioenergetic balance for different aquaculture sea fish (Sea Bream and Sea Bass; Brigolin et al., 2014 <doi:10.3354/aei00093>) and shellfish (Mussel and Clam; Brigolin et al., 2009 <doi:10.1016/j.ecss.2009.01.029>; Solidoro et al., 2000 <doi:10.3354/meps199137>). Allows for spatialized model runs and population simulations.",
    "version": "1.5.5",
    "maintainer": "Baldan D. <damiano.baldan91@gmail.com>",
    "author": "Baldan D. [aut, cre],\n  Palazzo D. [ctb],\n  Porporato E.M.D [ctb],\n  Brigolin D. [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RAC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RAC R Package for Aqua Culture Solves the individual bioenergetic balance for different aquaculture sea fish (Sea Bream and Sea Bass; Brigolin et al., 2014 <doi:10.3354/aei00093>) and shellfish (Mussel and Clam; Brigolin et al., 2009 <doi:10.1016/j.ecss.2009.01.029>; Solidoro et al., 2000 <doi:10.3354/meps199137>). Allows for spatialized model runs and population simulations.  "
  },
  {
    "id": 6091,
    "package_name": "RAMpath",
    "title": "Structural Equation Modeling Using the Reticular Action Model\n(RAM) Notation",
    "description": "We rewrite of RAMpath software developed by John McArdle and Steven Boker as an R package. In addition to performing regular SEM analysis through the R package lavaan, RAMpath has unique features.  First, it can generate path diagrams according to a given model. Second, it can display path tracing rules through path diagrams and decompose total effects into their respective direct and indirect effects as well as decompose variance and covariance into individual bridges. Furthermore, RAMpath can fit dynamic system models automatically based on latent change scores and generate vector field plots based upon results obtained from a bivariate dynamic system. Starting version 0.4, RAMpath can conduct power analysis for both univariate and bivariate latent change score models.",
    "version": "0.5.1",
    "maintainer": "Zhiyong Zhang <zzhang4@nd.edu>",
    "author": "Zhiyong Zhang, Jack McArdle, Aki Hamagami, & Kevin Grimm",
    "url": "https://nd.psychstat.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RAMpath",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RAMpath Structural Equation Modeling Using the Reticular Action Model\n(RAM) Notation We rewrite of RAMpath software developed by John McArdle and Steven Boker as an R package. In addition to performing regular SEM analysis through the R package lavaan, RAMpath has unique features.  First, it can generate path diagrams according to a given model. Second, it can display path tracing rules through path diagrams and decompose total effects into their respective direct and indirect effects as well as decompose variance and covariance into individual bridges. Furthermore, RAMpath can fit dynamic system models automatically based on latent change scores and generate vector field plots based upon results obtained from a bivariate dynamic system. Starting version 0.4, RAMpath can conduct power analysis for both univariate and bivariate latent change score models.  "
  },
  {
    "id": 6103,
    "package_name": "RApiDatetime",
    "title": "R API for 'Date' and 'Datetime'",
    "description": "Access to the C-level R date and 'datetime' code is provided for\n C-level API use by other packages via registration of native functions.\n Client packages simply include a single header 'RApiDatetime.h' provided\n by this package, and also 'import' it.  The R Core group is the original\n author of the code made available with slight modifications by this package. ",
    "version": "0.0.9",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel",
    "url": "https://github.com/eddelbuettel/rapidatetime,\nhttps://dirk.eddelbuettel.com/code/rapidatetime.html",
    "bug_reports": "https://github.com/eddelbuettel/rapidatetime/issues",
    "repository": "https://cran.r-project.org/package=RApiDatetime",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RApiDatetime R API for 'Date' and 'Datetime' Access to the C-level R date and 'datetime' code is provided for\n C-level API use by other packages via registration of native functions.\n Client packages simply include a single header 'RApiDatetime.h' provided\n by this package, and also 'import' it.  The R Core group is the original\n author of the code made available with slight modifications by this package.   "
  },
  {
    "id": 6104,
    "package_name": "RApiSerialize",
    "title": "R API Serialization",
    "description": "Access to the internal R serialization code is provided for\n use by other packages at the C function level by using the registration of\n native function mechanism. Client packages simply include a single header\n file RApiSerializeAPI.h provided by this package. This packages builds on\n the Rhpc package by Ei-ji Nakama and Junji Nakano which also includes a\n (partial) copy of the file src/main/serialize.c from R itself. The R Core\n group is the original author of the serialization code made available by\n this package.",
    "version": "0.1.4",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Ei-ji Nakama [aut] (Code in package Rhpc),\n  Junji Nakano [aut] (Code in package Rhpc),\n  R Core [aut] (Code in R file src/main/serialize.c)",
    "url": "https://github.com/eddelbuettel/rapiserialize,\nhttps://dirk.eddelbuettel.com/code/rapiserialize.html",
    "bug_reports": "https://github.com/eddelbuettel/rapiserialize/issues",
    "repository": "https://cran.r-project.org/package=RApiSerialize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RApiSerialize R API Serialization Access to the internal R serialization code is provided for\n use by other packages at the C function level by using the registration of\n native function mechanism. Client packages simply include a single header\n file RApiSerializeAPI.h provided by this package. This packages builds on\n the Rhpc package by Ei-ji Nakama and Junji Nakano which also includes a\n (partial) copy of the file src/main/serialize.c from R itself. The R Core\n group is the original author of the serialization code made available by\n this package.  "
  },
  {
    "id": 6106,
    "package_name": "RAthena",
    "title": "Connect to 'AWS Athena' using 'Boto3' ('DBI' Interface)",
    "description": "Designed to be compatible with the R package 'DBI' (Database Interface)\n    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.\n    To do this 'Python' 'Boto3' Software Development Kit ('SDK')\n    <https://boto3.amazonaws.com/v1/documentation/api/latest/index.html> is used as a driver.",
    "version": "2.6.3",
    "maintainer": "Dyfan Jones <dyfan.r.jones@gmail.com>",
    "author": "Dyfan Jones [aut, cre]",
    "url": "https://dyfanjones.github.io/RAthena/,\nhttps://github.com/DyfanJones/RAthena",
    "bug_reports": "https://github.com/DyfanJones/RAthena/issues",
    "repository": "https://cran.r-project.org/package=RAthena",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RAthena Connect to 'AWS Athena' using 'Boto3' ('DBI' Interface) Designed to be compatible with the R package 'DBI' (Database Interface)\n    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.\n    To do this 'Python' 'Boto3' Software Development Kit ('SDK')\n    <https://boto3.amazonaws.com/v1/documentation/api/latest/index.html> is used as a driver.  "
  },
  {
    "id": 6163,
    "package_name": "REBayes",
    "title": "Empirical Bayes Estimation and Inference",
    "description": "Kiefer-Wolfowitz maximum likelihood estimation for mixture models\n    and some other density estimation and regression methods based on convex\n    optimization.  See Koenker and Gu (2017) REBayes: An R Package for Empirical\n    Bayes Mixture Methods, Journal of Statistical Software, 82, 1--26, \n    <DOI:10.18637/jss.v082.i08>.",
    "version": "2.59",
    "maintainer": "Roger Koenker <rkoenker@uiuc.edu>",
    "author": "Roger Koenker [aut, cre],\n  Jiaying Gu [ctb],\n  Ivan Mizera [ctb]",
    "url": "https://www.r-project.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=REBayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REBayes Empirical Bayes Estimation and Inference Kiefer-Wolfowitz maximum likelihood estimation for mixture models\n    and some other density estimation and regression methods based on convex\n    optimization.  See Koenker and Gu (2017) REBayes: An R Package for Empirical\n    Bayes Mixture Methods, Journal of Statistical Software, 82, 1--26, \n    <DOI:10.18637/jss.v082.i08>.  "
  },
  {
    "id": 6166,
    "package_name": "REDCapDM",
    "title": "'REDCap' Data Management",
    "description": "REDCap Data Management - 'REDCap' (Research Electronic Data CAPture; <https://projectredcap.org>) is a web application developed at Vanderbilt University, designed for creating and managing online surveys and databases and the REDCap API is an interface that allows external applications to connect to REDCap remotely, and is used to programmatically retrieve or modify project data or settings within REDCap, such as importing or exporting data. REDCapDM is an R package that allows users to manage data exported directly from REDCap or using an API connection. This package includes several functions designed for pre-processing data, generating reports of queries such as outliers or missing values, and following up on previously identified queries. ",
    "version": "1.0.0",
    "maintainer": "Jo\u00e3o Carmezim <jcarmezim@igtp.cat>",
    "author": "Jo\u00e3o Carmezim [aut, cre],\n  Pau Satorra [aut],\n  Judith Pe\u00f1afiel [aut],\n  Esther Garc\u00eda [aut],\n  Nat\u00e0lia Pallar\u00e8s [aut],\n  Cristian Teb\u00e9 [aut]",
    "url": "https://bruigtp.github.io/REDCapDM/,\nhttps://doi.org/10.1186/s12874-024-02178-6",
    "bug_reports": "https://github.com/bruigtp/REDCapDM/issues",
    "repository": "https://cran.r-project.org/package=REDCapDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REDCapDM 'REDCap' Data Management REDCap Data Management - 'REDCap' (Research Electronic Data CAPture; <https://projectredcap.org>) is a web application developed at Vanderbilt University, designed for creating and managing online surveys and databases and the REDCap API is an interface that allows external applications to connect to REDCap remotely, and is used to programmatically retrieve or modify project data or settings within REDCap, such as importing or exporting data. REDCapDM is an R package that allows users to manage data exported directly from REDCap or using an API connection. This package includes several functions designed for pre-processing data, generating reports of queries such as outliers or missing values, and following up on previously identified queries.   "
  },
  {
    "id": 6181,
    "package_name": "REPTILE",
    "title": "Regulatory DNA Element Prediction",
    "description": "Predicting regulatory DNA elements based on epigenomic signatures. This package is more of a set of building blocks than a direct solution. REPTILE regulatory prediction pipeline is built on this R package. See <https://github.com/yupenghe/REPTILE> for more information.",
    "version": "1.0",
    "maintainer": "Yupeng He <yupeng.he.bioinfo@gmail.com>",
    "author": "Yupeng He",
    "url": "https://github.com/yupenghe/REPTILE",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=REPTILE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REPTILE Regulatory DNA Element Prediction Predicting regulatory DNA elements based on epigenomic signatures. This package is more of a set of building blocks than a direct solution. REPTILE regulatory prediction pipeline is built on this R package. See <https://github.com/yupenghe/REPTILE> for more information.  "
  },
  {
    "id": 6209,
    "package_name": "RGENERATE",
    "title": "Tools to Generate Vector Time Series",
    "description": "A method 'generate()' is implemented in this package for the random\n    generation of vector time series according to models obtained by 'RMAWGEN',\n    'vars' or other packages.  This package was created to generalize the\n    algorithms of the 'RMAWGEN' package for the analysis and generation of any\n    environmental vector time series.",
    "version": "1.3.8",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>)",
    "url": "https://github.com/ecor/RGENERATE",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RGENERATE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RGENERATE Tools to Generate Vector Time Series A method 'generate()' is implemented in this package for the random\n    generation of vector time series according to models obtained by 'RMAWGEN',\n    'vars' or other packages.  This package was created to generalize the\n    algorithms of the 'RMAWGEN' package for the analysis and generation of any\n    environmental vector time series.  "
  },
  {
    "id": 6216,
    "package_name": "RGenetics",
    "title": "R packages for genetics research",
    "description": "R packages for genetics research",
    "version": "0.1",
    "maintainer": "Felix Yanhui Fan <nolanfyh@gmail.com>",
    "author": "Felix Yanhui Fan <nolanfyh@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RGenetics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RGenetics R packages for genetics research R packages for genetics research  "
  },
  {
    "id": 6255,
    "package_name": "RKEAjars",
    "title": "R/KEA Interface Jars",
    "description": "External jars required for package RKEA.",
    "version": "5.0-4",
    "maintainer": "Kurt Hornik <Kurt.Hornik@R-project.org>",
    "author": "Kurt Hornik [aut, cre] (ORCID: <https://orcid.org/0000-0003-4198-9911>),\n  Eibe Frank [ctb, cph] (KEA Java library),\n  Olena Medelyan [ctb, cph] (KEA Java library),\n  The Apache Software Foundation [ctb, cph] (Apache Commons Logging and\n    Apache Jena Java libraries),\n  International Business Machines Corporation and others [ctb, cph]\n    (International Components for Unicode for Java (ICU4J)),\n  Martin Porter [ctb, cph] (Snowball base),\n  Richard Boulton [ctb, cph] (Snowball Java library),\n  University of Waikato [ctb, cph] (Weka Java library)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RKEAjars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RKEAjars R/KEA Interface Jars External jars required for package RKEA.  "
  },
  {
    "id": 6270,
    "package_name": "RLumShiny",
    "title": "'Shiny' Applications for the R Package 'Luminescence'",
    "description": "A collection of 'shiny' applications for the R package\n 'Luminescence'. These mainly, but not exclusively, include applications for\n plotting chronometric data from e.g. luminescence or radiocarbon dating. It\n further provides access to bootstraps tooltip and popover functionality and\n contains the 'jscolor.js' library with a custom 'shiny' output binding.",
    "version": "0.2.5",
    "maintainer": "Christoph Burow <christoph.burow@gmx.net>",
    "author": "Christoph Burow [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5023-4046>),\n  Urs Tilmann Wolpert [aut],\n  Sebastian Kreutzer [aut] (ORCID:\n    <https://orcid.org/0000-0002-0734-2199>),\n  Marco Colombo [aut] (ORCID: <https://orcid.org/0000-0001-6672-0623>),\n  R Luminescence Package Team [ctb],\n  Jan Odvarko [cph] (jscolor.js in www/jscolor),\n  AnalytixWare [cph] (ShinySky package),\n  RStudio [cph] (chooser_inputBinding.js in www/ and chooser.R in R/)",
    "url": "https://tzerk.github.io/RLumShiny/",
    "bug_reports": "https://github.com/tzerk/RLumShiny/issues",
    "repository": "https://cran.r-project.org/package=RLumShiny",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RLumShiny 'Shiny' Applications for the R Package 'Luminescence' A collection of 'shiny' applications for the R package\n 'Luminescence'. These mainly, but not exclusively, include applications for\n plotting chronometric data from e.g. luminescence or radiocarbon dating. It\n further provides access to bootstraps tooltip and popover functionality and\n contains the 'jscolor.js' library with a custom 'shiny' output binding.  "
  },
  {
    "id": 6282,
    "package_name": "RMOAjars",
    "title": "External jars Required for Package RMOA",
    "description": "External jars required for package RMOA. RMOA is a framework to\n    build data stream models on top of MOA (Massive Online Analysis -\n    <https://moa.cms.waikato.ac.nz/>). The jar files are put in this R package, the modelling logic can be found in the RMOA package.",
    "version": "1.2.0",
    "maintainer": "Jan Wijffels <jwijffels@bnosac.be>",
    "author": "See file AUTHORS",
    "url": "https://moa.cms.waikato.ac.nz/, https://github.com/jwijffels/RMOA",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RMOAjars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RMOAjars External jars Required for Package RMOA External jars required for package RMOA. RMOA is a framework to\n    build data stream models on top of MOA (Massive Online Analysis -\n    <https://moa.cms.waikato.ac.nz/>). The jar files are put in this R package, the modelling logic can be found in the RMOA package.  "
  },
  {
    "id": 6298,
    "package_name": "RMediation",
    "title": "Mediation Analysis Confidence Intervals",
    "description": "Computes confidence intervals for nonlinear functions of model \n    parameters (e.g., product of k coefficients) in single-level and multilevel \n    structural equation models. Methods include the distribution of the product, \n    Monte Carlo simulation, and bootstrap methods. It also performs the Model-Based \n    Constrained Optimization (MBCO) procedure for hypothesis testing of indirect \n    effects.\n    References:\n    Tofighi, D., and MacKinnon, D. P. (2011). RMediation: An R package for mediation \n    analysis confidence intervals. Behavior Research Methods, 43, 692-700. \n    <doi:10.3758/s13428-011-0076-x>;\n    Tofighi, D., and Kelley, K. (2020). Improved inference in mediation analysis: Introducing the model-based constrained optimization procedure. \n    Psychological Methods, 25(4), 496-515. <doi:10.1037/met0000259>;\n    Tofighi, D. (2020). Bootstrap Model-Based Constrained Optimization Tests of \n    Indirect Effects. Frontiers in Psychology, 10, 2989. \n    <doi:10.3389/fpsyg.2019.02989>.",
    "version": "1.3.0",
    "maintainer": "Davood Tofighi <dtofighi@gmail.com>",
    "author": "Davood Tofighi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8523-7776>)",
    "url": "https://data-wise.github.io/rmediation/,\nhttps://github.com/data-wise/rmediation",
    "bug_reports": "https://github.com/data-wise/rmediation/issues",
    "repository": "https://cran.r-project.org/package=RMediation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RMediation Mediation Analysis Confidence Intervals Computes confidence intervals for nonlinear functions of model \n    parameters (e.g., product of k coefficients) in single-level and multilevel \n    structural equation models. Methods include the distribution of the product, \n    Monte Carlo simulation, and bootstrap methods. It also performs the Model-Based \n    Constrained Optimization (MBCO) procedure for hypothesis testing of indirect \n    effects.\n    References:\n    Tofighi, D., and MacKinnon, D. P. (2011). RMediation: An R package for mediation \n    analysis confidence intervals. Behavior Research Methods, 43, 692-700. \n    <doi:10.3758/s13428-011-0076-x>;\n    Tofighi, D., and Kelley, K. (2020). Improved inference in mediation analysis: Introducing the model-based constrained optimization procedure. \n    Psychological Methods, 25(4), 496-515. <doi:10.1037/met0000259>;\n    Tofighi, D. (2020). Bootstrap Model-Based Constrained Optimization Tests of \n    Indirect Effects. Frontiers in Psychology, 10, 2989. \n    <doi:10.3389/fpsyg.2019.02989>.  "
  },
  {
    "id": 6340,
    "package_name": "ROpenCVLite",
    "title": "Helper Package for Installing OpenCV with R",
    "description": "Installs 'OpenCV' for use by other packages. 'OpenCV' <https://opencv.org/> \n    is library of programming functions mainly aimed at real-time computer \n    vision. This 'Lite' version installs the stable base version of 'OpenCV' and \n    some of its experimental externally contributed modules. It does not provide \n    R bindings directly. ",
    "version": "4.110.0",
    "maintainer": "Simon Garnier <garnier@njit.edu>",
    "author": "Simon Garnier [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3886-3974>),\n  Muschelli John [ctb]",
    "url": "https://swarm-lab.github.io/ROpenCVLite/,\nhttps://github.com/swarm-lab/ROpenCVLite",
    "bug_reports": "https://github.com/swarm-lab/ROpenCVLite/issues",
    "repository": "https://cran.r-project.org/package=ROpenCVLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ROpenCVLite Helper Package for Installing OpenCV with R Installs 'OpenCV' for use by other packages. 'OpenCV' <https://opencv.org/> \n    is library of programming functions mainly aimed at real-time computer \n    vision. This 'Lite' version installs the stable base version of 'OpenCV' and \n    some of its experimental externally contributed modules. It does not provide \n    R bindings directly.   "
  },
  {
    "id": 6353,
    "package_name": "RPPASPACE",
    "title": "Reverse-Phase Protein Array Super Position and Concentration\nEvaluation",
    "description": "Provides tools for the analysis of reverse-phase protein arrays (RPPAs), which are also known as 'tissue lysate arrays' or simply 'lysate arrays'. The package's primary purpose is to input a set of quantification files representing dilution series of samples and control points taken from scanned RPPA slides and determine a relative log concentration value for each valid dilution series present in each slide and provide graphical visualization of the input and output data and their relationships. Other optional features include generation of quality control scores for judging the quality of the input data, spatial adjustment of sample points based on controls added to the slides, and various types of normalization of calculated values across a set of slides. The package was derived from a previous package named SuperCurve. For a detailed description of data inputs and outputs, usage  information, and a list of related papers describing methods used in the package please review the vignette 'Guide_to_RPPASPACE'. 'RPPA SPACE: an R package for normalization and quantitation of Reverse-Phase Protein Array data'. Bioinformatics Nov 15;38(22):5131-5133. <doi: 10.1093/bioinformatics/btac665>.",
    "version": "1.0.10",
    "maintainer": "James M. Melott <jmmelott@mdanderson.org>",
    "author": "James M. Melott [aut, cre],\n  Paul L. Roebuck [aut],\n  Kevin R. Coombes [aut],\n  Zhenlin Ju [aut],\n  Huma Shehwana [aut],\n  Shwetha V. Kumar [aut],\n  E. Shannon Neeley [aut],\n  Corwin Joy [aut],\n  Jianhua Hu [aut],\n  Keith A. Baggerly [aut],\n  Rehan Akbani [aut],\n  Mary A. Rohrdanz [ctb],\n  Chris Wakefield [ctb],\n  Doris R. Siwak [ctb],\n  Yiling Lu [ctb],\n  Bradley M. Broom [ctb],\n  John N. Weinstein [ctb],\n  Gordon B. Mills [ctb]",
    "url": "https://pubmed.ncbi.nlm.nih.gov/36205581,\nhttps://github.com/MD-Anderson-Bioinformatics/rppaspace,\nhttps://bioinformatics.mdanderson.org/public-software/rppaspace/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RPPASPACE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RPPASPACE Reverse-Phase Protein Array Super Position and Concentration\nEvaluation Provides tools for the analysis of reverse-phase protein arrays (RPPAs), which are also known as 'tissue lysate arrays' or simply 'lysate arrays'. The package's primary purpose is to input a set of quantification files representing dilution series of samples and control points taken from scanned RPPA slides and determine a relative log concentration value for each valid dilution series present in each slide and provide graphical visualization of the input and output data and their relationships. Other optional features include generation of quality control scores for judging the quality of the input data, spatial adjustment of sample points based on controls added to the slides, and various types of normalization of calculated values across a set of slides. The package was derived from a previous package named SuperCurve. For a detailed description of data inputs and outputs, usage  information, and a list of related papers describing methods used in the package please review the vignette 'Guide_to_RPPASPACE'. 'RPPA SPACE: an R package for normalization and quantitation of Reverse-Phase Protein Array data'. Bioinformatics Nov 15;38(22):5131-5133. <doi: 10.1093/bioinformatics/btac665>.  "
  },
  {
    "id": 6385,
    "package_name": "RRreg",
    "title": "Correlation and Regression Analyses for Randomized Response Data",
    "description": "\n    Univariate and multivariate methods to analyze randomized response \n    (RR) survey designs (e.g., Warner, S. L. (1965). Randomized response: A \n    survey technique for eliminating evasive answer bias. Journal of the \n    American Statistical Association, 60, 63\u201369, <doi:10.2307/2283137>). \n    Besides univariate estimates of true proportions, RR variables can be used \n    for correlations, as dependent variable in a logistic regression (with or \n    without random effects), or as predictors in a linear regression\n    (Heck, D. W., & Moshagen, M. (2018). RRreg: An R package for correlation and \n    regression analyses of randomized response data. Journal of Statistical \n    Software, 85(2), 1\u201329, <doi:10.18637/jss.v085.i02>). For simulations and \n    the estimation of statistical power, RR data can be generated according to \n    several models. The implemented methods also allow to test the link between \n    continuous covariates and dishonesty in cheating paradigms such as the \n    coin-toss or dice-roll task (Moshagen, M., & Hilbig, B. E. (2017). \n    The statistical analysis of cheating paradigms. Behavior Research Methods, \n    49, 724\u2013732, <doi:10.3758/s13428-016-0729-x>).",
    "version": "0.7.6",
    "maintainer": "Daniel W. Heck <daniel.heck@uni-marburg.de>",
    "author": "Daniel W. Heck [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-6302-9252>),\n  Morten Moshagen [ctb]",
    "url": "https://github.com/danheck/RRreg",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RRreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RRreg Correlation and Regression Analyses for Randomized Response Data \n    Univariate and multivariate methods to analyze randomized response \n    (RR) survey designs (e.g., Warner, S. L. (1965). Randomized response: A \n    survey technique for eliminating evasive answer bias. Journal of the \n    American Statistical Association, 60, 63\u201369, <doi:10.2307/2283137>). \n    Besides univariate estimates of true proportions, RR variables can be used \n    for correlations, as dependent variable in a logistic regression (with or \n    without random effects), or as predictors in a linear regression\n    (Heck, D. W., & Moshagen, M. (2018). RRreg: An R package for correlation and \n    regression analyses of randomized response data. Journal of Statistical \n    Software, 85(2), 1\u201329, <doi:10.18637/jss.v085.i02>). For simulations and \n    the estimation of statistical power, RR data can be generated according to \n    several models. The implemented methods also allow to test the link between \n    continuous covariates and dishonesty in cheating paradigms such as the \n    coin-toss or dice-roll task (Moshagen, M., & Hilbig, B. E. (2017). \n    The statistical analysis of cheating paradigms. Behavior Research Methods, \n    49, 724\u2013732, <doi:10.3758/s13428-016-0729-x>).  "
  },
  {
    "id": 6391,
    "package_name": "RSCAT",
    "title": "Shadow-Test Approach to Computerized Adaptive Testing",
    "description": "As an advanced approach to computerized adaptive testing (CAT), \n  shadow testing (van der Linden(2005) <doi:10.1007/0-387-29054-0>) dynamically \n  assembles entire shadow tests as a part of \n  selecting items throughout the testing process.\n  Selecting items from shadow tests guarantees the compliance of all content \n  constraints defined by the blueprint. 'RSCAT' is an R package for the \n  shadow-test approach to CAT. The objective of \n  'RSCAT' is twofold: 1) Enhancing the effectiveness of shadow-test CAT simulation;\n  2) Contributing to the academic and scientific community for CAT research.\n  RSCAT is currently designed for dichotomous items based on the three-parameter logistic (3PL) model.",
    "version": "1.1.3",
    "maintainer": "Bingnan Jiang <bnjiangece@gmail.com>",
    "author": "Bingnan Jiang [aut, cre],\n  ACT, Inc. [cph]",
    "url": "",
    "bug_reports": "https://github.com/act-org/RSCAT/issues",
    "repository": "https://cran.r-project.org/package=RSCAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSCAT Shadow-Test Approach to Computerized Adaptive Testing As an advanced approach to computerized adaptive testing (CAT), \n  shadow testing (van der Linden(2005) <doi:10.1007/0-387-29054-0>) dynamically \n  assembles entire shadow tests as a part of \n  selecting items throughout the testing process.\n  Selecting items from shadow tests guarantees the compliance of all content \n  constraints defined by the blueprint. 'RSCAT' is an R package for the \n  shadow-test approach to CAT. The objective of \n  'RSCAT' is twofold: 1) Enhancing the effectiveness of shadow-test CAT simulation;\n  2) Contributing to the academic and scientific community for CAT research.\n  RSCAT is currently designed for dichotomous items based on the three-parameter logistic (3PL) model.  "
  },
  {
    "id": 6421,
    "package_name": "RSurveillance",
    "title": "Design and Analysis of Disease Surveillance Activities",
    "description": "A range of functions for the design and\n    analysis of disease surveillance activities. These functions were\n    originally developed for animal health surveillance activities but can be\n    equally applied to aquatic animal, wildlife, plant and human health\n    surveillance activities. Utilities are included for sample size calculation\n    and analysis of representative surveys for disease freedom, risk-based\n    studies for disease freedom and for prevalence estimation.\n    This package is based on Cameron A., Conraths F., Frohlich A., Schauer B.,\n    Schulz K., Sergeant E., Sonnenburg J., Staubach C. (2015). R package of \n    functions for risk-based surveillance. Deliverable 6.24, WP 6 - Decision \n    making tools for implementing risk-based surveillance, Grant Number \n    no. 310806, RISKSUR (<https://www.fp7-risksur.eu/sites/default/files/documents/Deliverables/RISKSUR_%28310806%29_D6.24.pdf>). \n    Many of the 'RSurveillance' functions are incorporated into the 'epitools'\n    website: Sergeant, ESG, 2019. Epitools epidemiological calculators. \n    Ausvet Pty Ltd. Available at: <http://epitools.ausvet.com.au>.",
    "version": "0.2.1",
    "maintainer": "Rohan Sadler <rohan.sadler@ausvet.com.au>",
    "author": "Evan Sergeant",
    "url": "https://github.com/roStats/RSurveillance",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RSurveillance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSurveillance Design and Analysis of Disease Surveillance Activities A range of functions for the design and\n    analysis of disease surveillance activities. These functions were\n    originally developed for animal health surveillance activities but can be\n    equally applied to aquatic animal, wildlife, plant and human health\n    surveillance activities. Utilities are included for sample size calculation\n    and analysis of representative surveys for disease freedom, risk-based\n    studies for disease freedom and for prevalence estimation.\n    This package is based on Cameron A., Conraths F., Frohlich A., Schauer B.,\n    Schulz K., Sergeant E., Sonnenburg J., Staubach C. (2015). R package of \n    functions for risk-based surveillance. Deliverable 6.24, WP 6 - Decision \n    making tools for implementing risk-based surveillance, Grant Number \n    no. 310806, RISKSUR (<https://www.fp7-risksur.eu/sites/default/files/documents/Deliverables/RISKSUR_%28310806%29_D6.24.pdf>). \n    Many of the 'RSurveillance' functions are incorporated into the 'epitools'\n    website: Sergeant, ESG, 2019. Epitools epidemiological calculators. \n    Ausvet Pty Ltd. Available at: <http://epitools.ausvet.com.au>.  "
  },
  {
    "id": 6441,
    "package_name": "RViennaCL",
    "title": "'ViennaCL' C++ Header Files",
    "description": "'ViennaCL' is a free open-source linear algebra library \n  for computations on many-core architectures (GPUs, MIC) and \n  multi-core CPUs. The library is written in C++ and supports 'CUDA', \n  'OpenCL', and 'OpenMP' (including switches at runtime). \n  I have placed these libraries in this package as a more efficient \n  distribution system for CRAN. The idea is that you can write a package \n  that depends on the 'ViennaCL' library and yet you do not need to \n  distribute a copy of this code with your package.",
    "version": "1.7.1.8",
    "maintainer": "Charles Determan Jr <cdetermanjr@gmail.com>",
    "author": "Charles Determan Jr.",
    "url": "http://github.com/cdeterman/RViennaCL",
    "bug_reports": "http://github.com/cdeterman/RViennaCL/issues/new",
    "repository": "https://cran.r-project.org/package=RViennaCL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RViennaCL 'ViennaCL' C++ Header Files 'ViennaCL' is a free open-source linear algebra library \n  for computations on many-core architectures (GPUs, MIC) and \n  multi-core CPUs. The library is written in C++ and supports 'CUDA', \n  'OpenCL', and 'OpenMP' (including switches at runtime). \n  I have placed these libraries in this package as a more efficient \n  distribution system for CRAN. The idea is that you can write a package \n  that depends on the 'ViennaCL' library and yet you do not need to \n  distribute a copy of this code with your package.  "
  },
  {
    "id": 6445,
    "package_name": "RWekajars",
    "title": "R/Weka Interface Jars",
    "description": "External jars required for package 'RWeka'.",
    "version": "3.9.3-2",
    "maintainer": "Kurt Hornik <Kurt.Hornik@R-project.org>",
    "author": "Kurt Hornik [aut, cre] (ORCID: <https://orcid.org/0000-0003-4198-9911>),\n  University of Waikato [ctb, cph] (Weka Java library)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RWekajars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RWekajars R/Weka Interface Jars External jars required for package 'RWeka'.  "
  },
  {
    "id": 6451,
    "package_name": "RWsearch",
    "title": "Lazy Search in R Packages, Task Views, CRAN, the Web. All-in-One\nDownload",
    "description": "Search by keywords in R packages, task views, CRAN, the web and display the results in the console or in txt, html or pdf files. Download the package documentation (html index, README, NEWS, pdf manual, vignettes, source code, binaries) with a single instruction. Visualize the package dependencies and CRAN checks. Compare the package versions, unload and install the packages and their dependencies in a safe order. Explore CRAN archives. Use the above functions for task view maintenance. Access web search engines from the console thanks to 80+ bookmarks. All functions accept standard and non-standard evaluation.",
    "version": "5.2.6",
    "maintainer": "Patrice Kiener <rpackages@inmodelia.com>",
    "author": "Patrice Kiener [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0505-9920>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RWsearch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RWsearch Lazy Search in R Packages, Task Views, CRAN, the Web. All-in-One\nDownload Search by keywords in R packages, task views, CRAN, the web and display the results in the console or in txt, html or pdf files. Download the package documentation (html index, README, NEWS, pdf manual, vignettes, source code, binaries) with a single instruction. Visualize the package dependencies and CRAN checks. Compare the package versions, unload and install the packages and their dependencies in a safe order. Explore CRAN archives. Use the above functions for task view maintenance. Access web search engines from the console thanks to 80+ bookmarks. All functions accept standard and non-standard evaluation.  "
  },
  {
    "id": 6517,
    "package_name": "RcmdrMisc",
    "title": "R Commander Miscellaneous Functions",
    "description": "\n  Various statistical, graphics, and data-management functions used by the Rcmdr package in the R Commander GUI for R.  ",
    "version": "2.9-2",
    "maintainer": "John Fox <jfox@mcmaster.ca>",
    "author": "John Fox [aut, cre],\n  Manuel Marquez [aut],\n  Robert Muenchen [ctb],\n  Dan Putler [ctb]",
    "url": "https://cran.r-project.org/package=RcmdrMisc,\nhttps://github.com/RCmdr-Project/rcmdrmisc",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrMisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrMisc R Commander Miscellaneous Functions \n  Various statistical, graphics, and data-management functions used by the Rcmdr package in the R Commander GUI for R.    "
  },
  {
    "id": 6555,
    "package_name": "RcppBessel",
    "title": "Bessel Functions Rcpp Interface",
    "description": "Exports an 'Rcpp' interface for the Bessel functions in the 'Bessel' package, which can then be called from the 'C++' code of other packages. For the original 'Fortran' implementation of these functions see Amos (1995) <doi:10.1145/212066.212078>.  ",
    "version": "1.0.0",
    "maintainer": "Alexios Galanos <alexios@4dscape.com>",
    "author": "Alexios Galanos [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9308-0457>),\n  Martin Maechler [aut] (Author of the Bessel R package, ORCID:\n    <https://orcid.org/0000-0002-8685-9910>),\n  Donald E. Amos [aut] (Original author of the zbsubs Fortran code,\n    Sandia National Laboratories)",
    "url": "https://github.com/alexiosg/RcppBessel",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcppBessel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppBessel Bessel Functions Rcpp Interface Exports an 'Rcpp' interface for the Bessel functions in the 'Bessel' package, which can then be called from the 'C++' code of other packages. For the original 'Fortran' implementation of these functions see Amos (1995) <doi:10.1145/212066.212078>.    "
  },
  {
    "id": 6569,
    "package_name": "RcppDate",
    "title": "'date' C++ Header Library for Date and Time Functionality",
    "description": "A header-only C++ library is provided with support\n for dates, time zones, ISO weeks, Julian dates, and Islamic dates.\n 'date' offers extensive date and time functionality for the C++11,\n C++14 and C++17 standards and was written by Howard Hinnant and released \n under the MIT license. A slightly modified version has been accepted\n (along with 'tz.h') as part of C++20. This package regroups all\n header files from the upstream repository by Howard Hinnant so that\n other R packages can use them in their C++ code. At present, few of\n the types have explicit 'Rcpp' wrappers though these may be added as\n needed. ",
    "version": "0.0.6",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Howard Hinnant [aut] (author of 'date' library)",
    "url": "https://github.com/eddelbuettel/rcppdate,\nhttps://dirk.eddelbuettel.com/code/rcpp.date.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppdate/issues",
    "repository": "https://cran.r-project.org/package=RcppDate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppDate 'date' C++ Header Library for Date and Time Functionality A header-only C++ library is provided with support\n for dates, time zones, ISO weeks, Julian dates, and Islamic dates.\n 'date' offers extensive date and time functionality for the C++11,\n C++14 and C++17 standards and was written by Howard Hinnant and released \n under the MIT license. A slightly modified version has been accepted\n (along with 'tz.h') as part of C++20. This package regroups all\n header files from the upstream repository by Howard Hinnant so that\n other R packages can use them in their C++ code. At present, few of\n the types have explicit 'Rcpp' wrappers though these may be added as\n needed.   "
  },
  {
    "id": 6570,
    "package_name": "RcppDist",
    "title": "'Rcpp' Integration of Additional Probability Distributions",
    "description": "The 'Rcpp' package provides a C++ library to make it easier\n    to use C++ with R. R and 'Rcpp' provide functions for a variety of\n    statistical distributions. Several R packages make functions\n    available to R for additional statistical distributions. However,\n    to access these functions from C++ code, a costly call to the R\n    functions must be made. 'RcppDist' provides a header-only C++ library\n    with functions for additional statistical distributions that can be\n    called from C++ when writing code using 'Rcpp' or 'RcppArmadillo'.\n    Functions are available that return a 'NumericVector' as well as\n    doubles, and for multivariate or matrix distributions, 'Armadillo'\n    vectors and matrices. 'RcppDist' provides functions for the following\n    distributions: the four parameter beta distribution; the location-\n    scale t distribution; the truncated normal distribution; the\n    truncated t distribution; a truncated location-scale t distribution;\n    the triangle distribution; the multivariate normal distribution*;\n    the multivariate t distribution*; the Wishart distribution*; and\n    the inverse Wishart distribution*. Distributions marked with an\n    asterisk rely on 'RcppArmadillo'.",
    "version": "0.1.1.1",
    "maintainer": "JB Duck-Mayr <j.duckmayr@gmail.com>",
    "author": "JB Duck-Mayr [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2231-1294>)",
    "url": "https://github.com/duckmayr/RcppDist",
    "bug_reports": "https://github.com/duckmayr/RcppDist/issues",
    "repository": "https://cran.r-project.org/package=RcppDist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppDist 'Rcpp' Integration of Additional Probability Distributions The 'Rcpp' package provides a C++ library to make it easier\n    to use C++ with R. R and 'Rcpp' provide functions for a variety of\n    statistical distributions. Several R packages make functions\n    available to R for additional statistical distributions. However,\n    to access these functions from C++ code, a costly call to the R\n    functions must be made. 'RcppDist' provides a header-only C++ library\n    with functions for additional statistical distributions that can be\n    called from C++ when writing code using 'Rcpp' or 'RcppArmadillo'.\n    Functions are available that return a 'NumericVector' as well as\n    doubles, and for multivariate or matrix distributions, 'Armadillo'\n    vectors and matrices. 'RcppDist' provides functions for the following\n    distributions: the four parameter beta distribution; the location-\n    scale t distribution; the truncated normal distribution; the\n    truncated t distribution; a truncated location-scale t distribution;\n    the triangle distribution; the multivariate normal distribution*;\n    the multivariate t distribution*; the Wishart distribution*; and\n    the inverse Wishart distribution*. Distributions marked with an\n    asterisk rely on 'RcppArmadillo'.  "
  },
  {
    "id": 6579,
    "package_name": "RcppGSL",
    "title": "'Rcpp' Integration for 'GNU GSL' Vectors and Matrices",
    "description": "'Rcpp' integration for 'GNU GSL' vectors and matrices\n The 'GNU Scientific Library' (or 'GSL') is a collection of numerical routines for\n scientific computing. It is particularly useful for C and C++ programs as it\n provides a standard C interface to a wide range of mathematical routines. There\n are over 1000 functions in total with an extensive test suite. The 'RcppGSL'\n package provides an easy-to-use interface between 'GSL' data structures and\n R using concepts from 'Rcpp' which is itself a package that eases the\n interfaces between R and C++. This package also serves as a prime example of\n how to build a package that uses 'Rcpp' to connect to another third-party\n library. The 'autoconf' script, 'inline' plugin and example package can all\n be used as a stanza to  write a similar package against another library.",
    "version": "0.3.13",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel and Romain Francois",
    "url": "https://github.com/eddelbuettel/rcppgsl,\nhttps://dirk.eddelbuettel.com/code/rcpp.gsl.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppgsl/issues",
    "repository": "https://cran.r-project.org/package=RcppGSL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppGSL 'Rcpp' Integration for 'GNU GSL' Vectors and Matrices 'Rcpp' integration for 'GNU GSL' vectors and matrices\n The 'GNU Scientific Library' (or 'GSL') is a collection of numerical routines for\n scientific computing. It is particularly useful for C and C++ programs as it\n provides a standard C interface to a wide range of mathematical routines. There\n are over 1000 functions in total with an extensive test suite. The 'RcppGSL'\n package provides an easy-to-use interface between 'GSL' data structures and\n R using concepts from 'Rcpp' which is itself a package that eases the\n interfaces between R and C++. This package also serves as a prime example of\n how to build a package that uses 'Rcpp' to connect to another third-party\n library. The 'autoconf' script, 'inline' plugin and example package can all\n be used as a stanza to  write a similar package against another library.  "
  },
  {
    "id": 6589,
    "package_name": "RcppMeCab",
    "title": "'rcpp' Wrapper for 'mecab' Library",
    "description": "R package based on 'Rcpp' for 'MeCab': Yet Another Part-of-Speech and Morphological Analyzer. \n\tThe purpose of this package is providing a seamless developing and analyzing environment for CJK texts.\n\tThis package utilizes parallel programming for providing highly efficient text preprocessing 'posParallel()' function.\n\tFor installation, please refer to README.md file.",
    "version": "0.0.1.2",
    "maintainer": "Junhewk Kim <junhewk.kim@gmail.com>",
    "author": "Junhewk Kim [aut, cre],\n  Taku Kudo [aut]",
    "url": "",
    "bug_reports": "https://github.com/junhewk/RcppMeCab/issues",
    "repository": "https://cran.r-project.org/package=RcppMeCab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppMeCab 'rcpp' Wrapper for 'mecab' Library R package based on 'Rcpp' for 'MeCab': Yet Another Part-of-Speech and Morphological Analyzer. \n\tThe purpose of this package is providing a seamless developing and analyzing environment for CJK texts.\n\tThis package utilizes parallel programming for providing highly efficient text preprocessing 'posParallel()' function.\n\tFor installation, please refer to README.md file.  "
  },
  {
    "id": 6590,
    "package_name": "RcppMsgPack",
    "title": "'MsgPack' C++ Header Files and Interface Functions for R",
    "description": "'MsgPack' header files are provided for use by R packages, along \n with the ability to access, create and alter 'MsgPack' objects directly from R.\n 'MsgPack' is an efficient binary serialization format. It lets you exchange\n data among multiple languages like 'JSON' but it is faster and smaller.\n Small integers are encoded into a single byte, and typical short strings\n require only one extra byte in addition to the strings themselves. This\n package provides headers from the 'msgpack-c' implementation for C and\n C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers\n are licensed under the Boost Software License (Version 1.0); the code added\n by this package as well the R integration are licensed under the GPL (>= 2).\n See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders\n and contributors to 'msgpack-c'.  ",
    "version": "0.2.4",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Travers Ching [aut],\n  MsgPack Authors [aut] (Authors of included MsgPack)",
    "url": "https://github.com/eddelbuettel/rcppmsgpack,\nhttps://dirk.eddelbuettel.com/code/rcpp.msgpack.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppmsgpack/issues",
    "repository": "https://cran.r-project.org/package=RcppMsgPack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppMsgPack 'MsgPack' C++ Header Files and Interface Functions for R 'MsgPack' header files are provided for use by R packages, along \n with the ability to access, create and alter 'MsgPack' objects directly from R.\n 'MsgPack' is an efficient binary serialization format. It lets you exchange\n data among multiple languages like 'JSON' but it is faster and smaller.\n Small integers are encoded into a single byte, and typical short strings\n require only one extra byte in addition to the strings themselves. This\n package provides headers from the 'msgpack-c' implementation for C and\n C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers\n are licensed under the Boost Software License (Version 1.0); the code added\n by this package as well the R integration are licensed under the GPL (>= 2).\n See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders\n and contributors to 'msgpack-c'.    "
  },
  {
    "id": 6596,
    "package_name": "RcppQuantuccia",
    "title": "R Bindings to the Calendaring Functionality of 'QuantLib'",
    "description": "'QuantLib' bindings are provided for R using 'Rcpp' via an updated\n variant of the header-only 'Quantuccia' project (put together initially by Peter\n Caspers) offering an essential subset of 'QuantLib' (and now maintained separately\n for the calendaring subset). See the included file 'AUTHORS' for a full list of\n contributors to both 'QuantLib' and 'Quantuccia'. Note that this package provided\n an initial viability proof, current work is done (via approximately quarterly releases\n tracking 'QuantLib') in the smaller package 'qlcal' which is generally preferred.",
    "version": "0.1.3",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  QuantLib Authors [aut]",
    "url": "https://github.com/eddelbuettel/rcppquantuccia,\nhttps://dirk.eddelbuettel.com/code/rcpp.quantuccia.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppquantuccia/issues",
    "repository": "https://cran.r-project.org/package=RcppQuantuccia",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppQuantuccia R Bindings to the Calendaring Functionality of 'QuantLib' 'QuantLib' bindings are provided for R using 'Rcpp' via an updated\n variant of the header-only 'Quantuccia' project (put together initially by Peter\n Caspers) offering an essential subset of 'QuantLib' (and now maintained separately\n for the calendaring subset). See the included file 'AUTHORS' for a full list of\n contributors to both 'QuantLib' and 'Quantuccia'. Note that this package provided\n an initial viability proof, current work is done (via approximately quarterly releases\n tracking 'QuantLib') in the smaller package 'qlcal' which is generally preferred.  "
  },
  {
    "id": 6601,
    "package_name": "RcppSpdlog",
    "title": "R and C++ Interfaces to 'spdlog' C++ Header Library for Logging",
    "description": "The mature and widely-used C++ logging library 'spdlog' by Gabi Melman provides\n many desirable features. This package bundles these header files for easy use by R packages\n from both their R and C or C++ code. Explicit use via 'LinkingTo:' is also supported. Also\n see the 'spdl' package which enhanced this package with a consistent R and C++ interface.",
    "version": "0.0.23",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Gabi Melman [aut] (Author of spdlog),\n  Victor Zverovic [aut] (Author of fmt)",
    "url": "https://github.com/eddelbuettel/rcppspdlog,\nhttps://eddelbuettel.github.io/rcppspdlog/,\nhttps://dirk.eddelbuettel.com/code/rcpp.spdlog.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppspdlog/issues",
    "repository": "https://cran.r-project.org/package=RcppSpdlog",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppSpdlog R and C++ Interfaces to 'spdlog' C++ Header Library for Logging The mature and widely-used C++ logging library 'spdlog' by Gabi Melman provides\n many desirable features. This package bundles these header files for easy use by R packages\n from both their R and C or C++ code. Explicit use via 'LinkingTo:' is also supported. Also\n see the 'spdl' package which enhanced this package with a consistent R and C++ interface.  "
  },
  {
    "id": 6608,
    "package_name": "RcppXsimd",
    "title": "Xsimd C++ Header-Only Library Files",
    "description": "This header-only library provides modern, portable C++ wrappers for SIMD\n    intrinsics and parallelized, optimized math implementations (SSE, AVX, NEON, AVX512).\n    By placing this library in this package, we offer an efficient distribution system for\n    Xsimd <https://github.com/xtensor-stack/xsimd> for R packages using CRAN.",
    "version": "7.1.6-1",
    "maintainer": "Marc A. Suchard <msuchard@ucla.edu>",
    "author": "Marc A. Suchard [aut, cre],\n  Andrew J. Holbrook [aut],\n  Observational Health Data Sciences and Informatics [cph],\n  Johan Mabille [cph, ctb] (author and copyright holder of Xsimd library\n    under a BSD-3 license),\n  Sylvain Corlay [cph, ctb] (author and copyright holder of Xsimd library\n    under a BSD-3 license),\n  Alexander J. Lee [cph, ctb] (author and copyright holder of\n    FeatureDetector library under a CC0 1.0 license)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcppXsimd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppXsimd Xsimd C++ Header-Only Library Files This header-only library provides modern, portable C++ wrappers for SIMD\n    intrinsics and parallelized, optimized math implementations (SSE, AVX, NEON, AVX512).\n    By placing this library in this package, we offer an efficient distribution system for\n    Xsimd <https://github.com/xtensor-stack/xsimd> for R packages using CRAN.  "
  },
  {
    "id": 6610,
    "package_name": "RcppZiggurat",
    "title": "'Rcpp' Integration of Different \"Ziggurat\" Normal RNG\nImplementations",
    "description": "The Ziggurat generator for normally distributed random\n numbers, originally proposed by Marsaglia and Tsang (2000,\n <doi:10.18637/jss.v005.i08>) has been improved upon a few times\n starting with Leong et al (2005, <doi:10.18637/jss.v012.i07>).\n This package provides an aggregation in order to compare different\n implementations in order to provide a 'faster but good enough'\n alternative for use with R and C++ code. See the 'zigg' package\n for a lighter implementation for much easier use in other packages.",
    "version": "0.1.8",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>)",
    "url": "https://github.com/eddelbuettel/rcppziggurat,\nhttps://dirk.eddelbuettel.com/code/rcpp.ziggurat.html",
    "bug_reports": "https://github.com/eddelbuettel/rcppziggurat/issues",
    "repository": "https://cran.r-project.org/package=RcppZiggurat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcppZiggurat 'Rcpp' Integration of Different \"Ziggurat\" Normal RNG\nImplementations The Ziggurat generator for normally distributed random\n numbers, originally proposed by Marsaglia and Tsang (2000,\n <doi:10.18637/jss.v005.i08>) has been improved upon a few times\n starting with Leong et al (2005, <doi:10.18637/jss.v012.i07>).\n This package provides an aggregation in order to compare different\n implementations in order to provide a 'faster but good enough'\n alternative for use with R and C++ code. See the 'zigg' package\n for a lighter implementation for much easier use in other packages.  "
  },
  {
    "id": 6616,
    "package_name": "Rd2roxygen",
    "title": "Convert Rd to 'Roxygen' Documentation",
    "description": "Functions to convert Rd to 'roxygen' documentation. It can parse an\n    Rd file to a list, create the 'roxygen' documentation and update the original\n    R script (e.g. the one containing the definition of the function)\n    accordingly. This package also provides utilities that can help developers\n    build packages using 'roxygen' more easily. The 'formatR' package can be used\n    to reformat the R code in the examples sections so that the code will be\n    more readable.",
    "version": "1.17",
    "maintainer": "Yihui Xie <xie@yihui.name>",
    "author": "Hadley Wickham [aut],\n  Yihui Xie [aut, cre] (ORCID: <https://orcid.org/0000-0003-0645-5666>)",
    "url": "https://github.com/yihui/Rd2roxygen",
    "bug_reports": "https://github.com/yihui/Rd2roxygen/issues",
    "repository": "https://cran.r-project.org/package=Rd2roxygen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rd2roxygen Convert Rd to 'Roxygen' Documentation Functions to convert Rd to 'roxygen' documentation. It can parse an\n    Rd file to a list, create the 'roxygen' documentation and update the original\n    R script (e.g. the one containing the definition of the function)\n    accordingly. This package also provides utilities that can help developers\n    build packages using 'roxygen' more easily. The 'formatR' package can be used\n    to reformat the R code in the examples sections so that the code will be\n    more readable.  "
  },
  {
    "id": 6621,
    "package_name": "Rdpack",
    "title": "Update and Manipulate Rd Documentation Objects",
    "description": "Functions for manipulation of R documentation objects,\n    including functions reprompt() and ereprompt() for updating 'Rd'\n    documentation for functions, methods and classes; 'Rd' macros for\n    citations and import of references from 'bibtex' files for use in\n    'Rd' files and 'roxygen2' comments; 'Rd' macros for evaluating and\n    inserting snippets of 'R' code and the results of its evaluation or\n    creating graphics on the fly; and many functions for manipulation of\n    references and Rd files.",
    "version": "2.6.4",
    "maintainer": "Georgi N. Boshnakov <georgi.boshnakov@manchester.ac.uk>",
    "author": "Georgi N. Boshnakov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2839-346X>),\n  Duncan Murdoch [ctb]",
    "url": "https://geobosh.github.io/Rdpack/ (doc),\nhttps://github.com/GeoBosh/Rdpack (devel)",
    "bug_reports": "https://github.com/GeoBosh/Rdpack/issues",
    "repository": "https://cran.r-project.org/package=Rdpack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rdpack Update and Manipulate Rd Documentation Objects Functions for manipulation of R documentation objects,\n    including functions reprompt() and ereprompt() for updating 'Rd'\n    documentation for functions, methods and classes; 'Rd' macros for\n    citations and import of references from 'bibtex' files for use in\n    'Rd' files and 'roxygen2' comments; 'Rd' macros for evaluating and\n    inserting snippets of 'R' code and the results of its evaluation or\n    creating graphics on the fly; and many functions for manipulation of\n    references and Rd files.  "
  },
  {
    "id": 6679,
    "package_name": "ReporterScore",
    "title": "Generalized Reporter Score-Based Enrichment Analysis for Omics\nData",
    "description": "Inspired by the classic 'RSA', we developed the improved 'Generalized Reporter \n    Score-based Analysis (GRSA)' method, implemented in the R package 'ReporterScore', along \n    with comprehensive visualization methods and pathway databases. 'GRSA' is a threshold-free \n    method that works well with all types of biomedical features, such as genes, chemical compounds, \n    and microbial species. Importantly, the 'GRSA' supports multi-group and longitudinal experimental \n    designs, because of the included multi-group-compatible statistical methods. ",
    "version": "0.1.9",
    "maintainer": "Chen Peng <pengchen2001@zju.edu.cn>",
    "author": "Chen Peng [aut, cre] (ORCID: <https://orcid.org/0000-0002-9449-7606>)",
    "url": "https://github.com/Asa12138/ReporterScore",
    "bug_reports": "https://github.com/Asa12138/ReporterScore/issues",
    "repository": "https://cran.r-project.org/package=ReporterScore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ReporterScore Generalized Reporter Score-Based Enrichment Analysis for Omics\nData Inspired by the classic 'RSA', we developed the improved 'Generalized Reporter \n    Score-based Analysis (GRSA)' method, implemented in the R package 'ReporterScore', along \n    with comprehensive visualization methods and pathway databases. 'GRSA' is a threshold-free \n    method that works well with all types of biomedical features, such as genes, chemical compounds, \n    and microbial species. Importantly, the 'GRSA' supports multi-group and longitudinal experimental \n    designs, because of the included multi-group-compatible statistical methods.   "
  },
  {
    "id": 6680,
    "package_name": "Require",
    "title": "Installing and Loading R Packages for Reproducible Workflows",
    "description": "A single key function, 'Require' that makes rerun-tolerant\n    versions of 'install.packages' and `require` for CRAN packages, packages\n    no longer on CRAN (i.e., archived), specific versions of packages, \n    and GitHub packages. This approach is developed to create reproducible \n    workflows that are flexible and fast enough to use while in development stages,\n    while able to build snapshots once a stable package collection is found. \n    As with other functions in a reproducible workflow, this package \n    emphasizes functions that return the same result whether it is \n    the first or subsequent times running the function, with subsequent times being\n    sufficiently fast that they can be run every time without undue waiting burden on \n    the user or developer.",
    "version": "1.0.1",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "author": "Eliot J B McIntire [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6914-8316>),\n  Alex M Chubaty [ctb] (ORCID: <https://orcid.org/0000-0001-7146-8135>),\n  Her Majesty the Queen in Right of Canada, as represented by the\n    Minister of Natural Resources Canada [cph]",
    "url": "https://Require.predictiveecology.org,\nhttps://github.com/PredictiveEcology/Require",
    "bug_reports": "https://github.com/PredictiveEcology/Require/issues",
    "repository": "https://cran.r-project.org/package=Require",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Require Installing and Loading R Packages for Reproducible Workflows A single key function, 'Require' that makes rerun-tolerant\n    versions of 'install.packages' and `require` for CRAN packages, packages\n    no longer on CRAN (i.e., archived), specific versions of packages, \n    and GitHub packages. This approach is developed to create reproducible \n    workflows that are flexible and fast enough to use while in development stages,\n    while able to build snapshots once a stable package collection is found. \n    As with other functions in a reproducible workflow, this package \n    emphasizes functions that return the same result whether it is \n    the first or subsequent times running the function, with subsequent times being\n    sufficiently fast that they can be run every time without undue waiting burden on \n    the user or developer.  "
  },
  {
    "id": 6690,
    "package_name": "ResultModelManager",
    "title": "Result Model Manager",
    "description": "Database data model management utilities for R packages in the Observational Health Data Sciences and\n    Informatics programme. 'ResultModelManager' provides utility functions to allow package\n    maintainers to migrate existing SQL database models, export and import results in consistent patterns.",
    "version": "0.6.2",
    "maintainer": "Jamie Gilbert <gilbert@ohdsi.org>",
    "author": "Jamie Gilbert [aut, cre]",
    "url": "https://github.com/OHDSI/ResultModelManager,\nhttps://ohdsi.github.io/ResultModelManager/",
    "bug_reports": "https://github.com/OHDSI/ResultModelManager/issues",
    "repository": "https://cran.r-project.org/package=ResultModelManager",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ResultModelManager Result Model Manager Database data model management utilities for R packages in the Observational Health Data Sciences and\n    Informatics programme. 'ResultModelManager' provides utility functions to allow package\n    maintainers to migrate existing SQL database models, export and import results in consistent patterns.  "
  },
  {
    "id": 6697,
    "package_name": "RfEmpImp",
    "title": "Multiple Imputation using Chained Random Forests",
    "description": "An R package for multiple imputation using chained random forests.\n    Implemented methods can handle missing data in mixed types of variables by\n    using prediction-based or node-based conditional distributions constructed\n    using random forests. For prediction-based imputation, the method based on\n    the empirical distribution of out-of-bag prediction errors of random forests\n    and the method based on normality assumption for prediction errors of random\n    forests are provided for imputing continuous variables. And the method based\n    on predicted probabilities is provided for imputing categorical variables.\n    For node-based imputation, the method based on the conditional distribution\n    formed by the predicting nodes of random forests, and the method based on\n    proximity measures of random forests are provided. More details of the\n    statistical methods can be found in Hong et al. (2020) <arXiv:2004.14823>.",
    "version": "2.1.8",
    "maintainer": "Shangzhi Hong <shangzhi-hong@hotmail.com>",
    "author": "Shangzhi Hong [aut, cre],\n  Henry S. Lynn [ths]",
    "url": "https://github.com/shangzhi-hong/RfEmpImp",
    "bug_reports": "https://github.com/shangzhi-hong/RfEmpImp/issues",
    "repository": "https://cran.r-project.org/package=RfEmpImp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RfEmpImp Multiple Imputation using Chained Random Forests An R package for multiple imputation using chained random forests.\n    Implemented methods can handle missing data in mixed types of variables by\n    using prediction-based or node-based conditional distributions constructed\n    using random forests. For prediction-based imputation, the method based on\n    the empirical distribution of out-of-bag prediction errors of random forests\n    and the method based on normality assumption for prediction errors of random\n    forests are provided for imputing continuous variables. And the method based\n    on predicted probabilities is provided for imputing categorical variables.\n    For node-based imputation, the method based on the conditional distribution\n    formed by the predicting nodes of random forests, and the method based on\n    proximity measures of random forests are provided. More details of the\n    statistical methods can be found in Hong et al. (2020) <arXiv:2004.14823>.  "
  },
  {
    "id": 6699,
    "package_name": "Rfast",
    "title": "A Collection of Efficient and Extremely Fast R Functions",
    "description": "A collection of fast (utility) functions for data analysis. Column and row wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 <doi:10.7287/peerj.preprints.26605v1>. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771--780. <doi:10.6339/JDS.201810_16(4).00006>. c) Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2020). Extremely Efficient Permutation and Bootstrap Hypothesis Tests Using Hypothesis Tests Using R. Journal of Modern Applied Statistical Methods, 18(2), eP2898. <doi:10.48550/arXiv.1806.10947>. d) Tsagris M., Papadakis M., Alenazi A. and Alzeley O. (2024). Computationally Efficient Outlier Detection for High-Dimensional Data Using the MDP Algorithm. Computation, 12(9): 185. <doi:10.3390/computation12090185>. e) Tsagris M. and Papadakis M. (2025). Fast and light-weight energy statistics using the R package Rfast. <doi:10.48550/arXiv.2501.02849>.",
    "version": "2.1.5.2",
    "maintainer": "Manos Papadakis <rfastofficial@gmail.com>",
    "author": "Manos Papadakis [aut, cre, cph],\n  Michail Tsagris [aut],\n  Marios Dimitriadis [aut],\n  Stefanos Fafalios [aut],\n  Matteo Fasiolo [aut],\n  Morgan Jacob [ctb],\n  Giorgos Borboudakis [aut],\n  John Burkardt [aut],\n  Changliang Zou [aut]",
    "url": "https://github.com/RfastOfficial/Rfast",
    "bug_reports": "https://github.com/RfastOfficial/Rfast/issues",
    "repository": "https://cran.r-project.org/package=Rfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rfast A Collection of Efficient and Extremely Fast R Functions A collection of fast (utility) functions for data analysis. Column and row wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 <doi:10.7287/peerj.preprints.26605v1>. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771--780. <doi:10.6339/JDS.201810_16(4).00006>. c) Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2020). Extremely Efficient Permutation and Bootstrap Hypothesis Tests Using Hypothesis Tests Using R. Journal of Modern Applied Statistical Methods, 18(2), eP2898. <doi:10.48550/arXiv.1806.10947>. d) Tsagris M., Papadakis M., Alenazi A. and Alzeley O. (2024). Computationally Efficient Outlier Detection for High-Dimensional Data Using the MDP Algorithm. Computation, 12(9): 185. <doi:10.3390/computation12090185>. e) Tsagris M. and Papadakis M. (2025). Fast and light-weight energy statistics using the R package Rfast. <doi:10.48550/arXiv.2501.02849>.  "
  },
  {
    "id": 6753,
    "package_name": "RnavGraphImageData",
    "title": "Image Data Used in the Loon Package Demos",
    "description": "Image data used as examples in the loon R package.",
    "version": "0.0.4",
    "maintainer": "Adrian Waddell <adrian@waddell.ch>",
    "author": "Adrian Waddell [aut, cre],\n  R. Wayne Oldford [aut]",
    "url": "http://waddella.github.io/loon/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RnavGraphImageData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RnavGraphImageData Image Data Used in the Loon Package Demos Image data used as examples in the loon R package.  "
  },
  {
    "id": 6793,
    "package_name": "RootscanR",
    "title": "Stitching and Analyzing Root Scans",
    "description": "Minirhizotrons are widely used to observe and explore roots and\n    their growth. This package provides the means to stitch images and \n    divide them into depth layers.\n    Please note that this R package was developed alongside the following \n    manuscript:\n    Stitching root scans and extracting depth layer information -- a workflow \n    and practical examples, S. Kersting, L. Kn\u00fcver, and M. Fischer.\n    The manuscript is currently in preparation and should be citet as soon as \n    it is available.\n    This project was supported by the project ArtIGROW, which is a part of the\n    WIR!-Alliance ArtIFARM \u2013  Artificial Intelligence in Farming funded by the\n    German Federal Ministry of Research, Technology and Space (No. 03WIR4805).",
    "version": "0.0.1",
    "maintainer": "Sophie Kersting <sophie.kersting@uni-greifswald.de>",
    "author": "Sophie Kersting [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1038-9246>),\n  Linda Kn\u00fcver [aut],\n  Mareike Fischer [aut] (ORCID: <https://orcid.org/0000-0002-9429-0859>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RootscanR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RootscanR Stitching and Analyzing Root Scans Minirhizotrons are widely used to observe and explore roots and\n    their growth. This package provides the means to stitch images and \n    divide them into depth layers.\n    Please note that this R package was developed alongside the following \n    manuscript:\n    Stitching root scans and extracting depth layer information -- a workflow \n    and practical examples, S. Kersting, L. Kn\u00fcver, and M. Fischer.\n    The manuscript is currently in preparation and should be citet as soon as \n    it is available.\n    This project was supported by the project ArtIGROW, which is a part of the\n    WIR!-Alliance ArtIFARM \u2013  Artificial Intelligence in Farming funded by the\n    German Federal Ministry of Research, Technology and Space (No. 03WIR4805).  "
  },
  {
    "id": 6812,
    "package_name": "Rraven",
    "title": "Connecting R and 'Raven' Sound Analysis Software",
    "description": "A tool to exchange data between R and 'Raven' sound analysis software (Cornell Lab of Ornithology). Functions work on data formats compatible with the R package 'warbleR'.",
    "version": "1.0.16",
    "maintainer": "Marcelo Araya-Salas <marcelo.araya@ucr.ac.cr>",
    "author": "Marcelo Araya-Salas [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3594-619X>)",
    "url": "https://github.com/maRce10/Rraven",
    "bug_reports": "https://github.com/maRce10/Rraven/issues",
    "repository": "https://cran.r-project.org/package=Rraven",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rraven Connecting R and 'Raven' Sound Analysis Software A tool to exchange data between R and 'Raven' sound analysis software (Cornell Lab of Ornithology). Functions work on data formats compatible with the R package 'warbleR'.  "
  },
  {
    "id": 6827,
    "package_name": "RsqMed",
    "title": "Total Mediation Effect Size Measure for High-Dimensional\nMediators",
    "description": "An implementation of calculating the R-squared measure as a total mediation effect size measure and its confidence interval for moderate- or high-dimensional mediator models. It gives an option to filter out non-mediators using variable selection methods. The original R package is directly related to the paper Yang et al (2021) \"Estimation of mediation effect for high-dimensional omics mediators with application to the Framingham Heart Study\" <doi:10.1101/774877>. The new version contains a choice of using cross-fitting, which is computationally faster. The details of the cross-fitting method are available in the paper Xu et al (2023) \"Speeding up interval estimation for R2-based mediation effect of high-dimensional mediators via cross-fitting\" <doi:10.1101/2023.02.06.527391>.",
    "version": "1.1",
    "maintainer": "Tianzhong Yang <yang3704@umn.edu>",
    "author": "Tianzhong Yang [aut, cre],\n  Chunlin Li [aut],\n  Zhichao Xu [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RsqMed",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RsqMed Total Mediation Effect Size Measure for High-Dimensional\nMediators An implementation of calculating the R-squared measure as a total mediation effect size measure and its confidence interval for moderate- or high-dimensional mediator models. It gives an option to filter out non-mediators using variable selection methods. The original R package is directly related to the paper Yang et al (2021) \"Estimation of mediation effect for high-dimensional omics mediators with application to the Framingham Heart Study\" <doi:10.1101/774877>. The new version contains a choice of using cross-fitting, which is computationally faster. The details of the cross-fitting method are available in the paper Xu et al (2023) \"Speeding up interval estimation for R2-based mediation effect of high-dimensional mediators via cross-fitting\" <doi:10.1101/2023.02.06.527391>.  "
  },
  {
    "id": 6842,
    "package_name": "Rtwobitlib",
    "title": "'2bit' 'C' Library",
    "description": "A trimmed down copy of the \"kent-core source tree\"\n\tturned into a 'C' library for manipulation of '.2bit' files.\n\tSee <https://genome.ucsc.edu/FAQ/FAQformat.html#format7>\n\tfor a quick overview of the '2bit' format. The \"kent-core source tree\"\n\tcan be found here: <https://github.com/ucscGenomeBrowser/kent-core/>.\n\tOnly the '.c' and '.h' files from the source tree that are related\n\tto manipulation of '.2bit' files were kept. Note that the package\n\tis primarily useful to developers of other R packages who wish\n\tto use the '2bit' 'C' library in their own 'C'/'C++' code.",
    "version": "0.3.10",
    "maintainer": "Herv\u00e9 Pag\u00e8s <hpages.on.github@gmail.com>",
    "author": "Herv\u00e9 Pag\u00e8s [aut, cre],\n  UC Regents [cph] (all the '.c' and '.h' files in src/kent/)",
    "url": "https://github.com/hpages/Rtwobitlib",
    "bug_reports": "https://github.com/hpages/Rtwobitlib/issues",
    "repository": "https://cran.r-project.org/package=Rtwobitlib",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rtwobitlib '2bit' 'C' Library A trimmed down copy of the \"kent-core source tree\"\n\tturned into a 'C' library for manipulation of '.2bit' files.\n\tSee <https://genome.ucsc.edu/FAQ/FAQformat.html#format7>\n\tfor a quick overview of the '2bit' format. The \"kent-core source tree\"\n\tcan be found here: <https://github.com/ucscGenomeBrowser/kent-core/>.\n\tOnly the '.c' and '.h' files from the source tree that are related\n\tto manipulation of '.2bit' files were kept. Note that the package\n\tis primarily useful to developers of other R packages who wish\n\tto use the '2bit' 'C' library in their own 'C'/'C++' code.  "
  },
  {
    "id": 6865,
    "package_name": "SALTSampler",
    "title": "Efficient Sampling on the Simplex",
    "description": "The SALTSampler package facilitates Monte Carlo Markov Chain (MCMC)\n    sampling of random variables on a simplex. A Self-Adjusting Logit Transform\n    (SALT) proposal is used so that sampling is still efficient even in difficult\n    cases, such as those in high dimensions or with parameters that differ by orders\n    of magnitude. Special care is also taken to maintain accuracy even when some\n    coordinates approach 0 or 1 numerically. Diagnostic and graphic functions are\n    included in the package, enabling easy assessment of the convergence and mixing\n    of the chain within the constrained space.",
    "version": "1.1.0",
    "maintainer": "Scott Vander Wiel <scottv@lanl.gov>",
    "author": "Hannah Director, Scott Vander Wiel, James Gattiker",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SALTSampler",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SALTSampler Efficient Sampling on the Simplex The SALTSampler package facilitates Monte Carlo Markov Chain (MCMC)\n    sampling of random variables on a simplex. A Self-Adjusting Logit Transform\n    (SALT) proposal is used so that sampling is still efficient even in difficult\n    cases, such as those in high dimensions or with parameters that differ by orders\n    of magnitude. Special care is also taken to maintain accuracy even when some\n    coordinates approach 0 or 1 numerically. Diagnostic and graphic functions are\n    included in the package, enabling easy assessment of the convergence and mixing\n    of the chain within the constrained space.  "
  },
  {
    "id": 7010,
    "package_name": "SLCARE",
    "title": "Semiparametric Latent Class Analysis of Recurrent Events",
    "description": "Efficient R package for latent class analysis of recurrent events, based on the semiparametric multiplicative intensity model by Zhao et al. (2022) <doi:10.1111/rssb.12499>. SLCARE returns estimates for non-functional model parameters along with the associated variance estimates and p-values. Visualization tools are provided to depict the estimated functional model parameters and related functional quantities of interest. SLCARE also delivers a model checking plot to help assess the adequacy of the fitted model.",
    "version": "1.2.0",
    "maintainer": "Qi Yu <qi.yu2@emory.edu>",
    "author": "Qi Yu [aut, cre],\n  Limin Peng [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SLCARE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SLCARE Semiparametric Latent Class Analysis of Recurrent Events Efficient R package for latent class analysis of recurrent events, based on the semiparametric multiplicative intensity model by Zhao et al. (2022) <doi:10.1111/rssb.12499>. SLCARE returns estimates for non-functional model parameters along with the associated variance estimates and p-values. Visualization tools are provided to depict the estimated functional model parameters and related functional quantities of interest. SLCARE also delivers a model checking plot to help assess the adequacy of the fitted model.  "
  },
  {
    "id": 7011,
    "package_name": "SLDAssay",
    "title": "Software for Analyzing Limiting Dilution Assays",
    "description": "Calculates maximum likelihood estimate, exact and asymptotic confidence intervals, and exact and asymptotic goodness of fit p-values for concentration of infectious units from serial limiting dilution assays. This package uses the likelihood equation, exact goodness of fit p-values, and exact confidence intervals described in Meyers et al. (1994) <http://jcm.asm.org/content/32/3/732.full.pdf>. This software is also implemented as a web application through the Shiny R package <https://iupm.shinyapps.io/sldassay/>.",
    "version": "1.8",
    "maintainer": "Ilana Trumble <itrumble@unc.edu>",
    "author": "Michael Hudgens, Ilana Trumble, Andrew Allmon",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SLDAssay",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SLDAssay Software for Analyzing Limiting Dilution Assays Calculates maximum likelihood estimate, exact and asymptotic confidence intervals, and exact and asymptotic goodness of fit p-values for concentration of infectious units from serial limiting dilution assays. This package uses the likelihood equation, exact goodness of fit p-values, and exact confidence intervals described in Meyers et al. (1994) <http://jcm.asm.org/content/32/3/732.full.pdf>. This software is also implemented as a web application through the Shiny R package <https://iupm.shinyapps.io/sldassay/>.  "
  },
  {
    "id": 7021,
    "package_name": "SLPresElection",
    "title": "Presidential Election Data of \"Sri Lanka\" from 1982 to 2015",
    "description": "Presidential Election data of \"Sri Lanka\"\" is stored in Pdf\n    files, through Pdf scraping they are converted into data-frames and\n    stored in this R package.",
    "version": "1.0.0",
    "maintainer": "Amalan Mahendran <amalan0595@gmail.com>",
    "author": "Amalan Mahendran [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0643-9052>)",
    "url": "https://github.com/Amalan-ConStat/SLPresElection,\nhttps://amalan-constat.github.io/SLPresElection/index.html",
    "bug_reports": "https://github.com/Amalan-ConStat/SLPresElection/issues",
    "repository": "https://cran.r-project.org/package=SLPresElection",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SLPresElection Presidential Election Data of \"Sri Lanka\" from 1982 to 2015 Presidential Election data of \"Sri Lanka\"\" is stored in Pdf\n    files, through Pdf scraping they are converted into data-frames and\n    stored in this R package.  "
  },
  {
    "id": 7053,
    "package_name": "SNPfiltR",
    "title": "Interactively Filter SNP Datasets",
    "description": "Is designed to interactively and reproducibly visualize and filter SNP\n\t(single-nucleotide polymorphism) datasets. This R-based implementation of SNP\n\tand genotype filters facilitates \n\tan interactive and iterative SNP filtering pipeline, which can be documented\n\treproducibly via 'rmarkdown'. 'SNPfiltR' contains functions for visualizing \n\tvarious quality and missing data metrics for a SNP dataset, and then filtering\n\tthe dataset based on user specified cutoffs.\n\tAll functions take 'vcfR' objects as input, which can easily be\n\tgenerated by reading standard vcf (variant call format) files into R using \n\tthe R package 'vcfR' authored by Knaus and Gr\u00fcnwald (2017) <doi:10.1111/1755-0998.12549>. \n\tEach 'SNPfiltR' function can return a newly filtered 'vcfR' object, which can then be\n\twritten to a local directory in standard vcf format using the 'vcfR' package,\n\tfor downstream population genetic and phylogenetic analyses.",
    "version": "1.0.7",
    "maintainer": "Devon DeRaad <devonderaad@gmail.com>",
    "author": "Devon DeRaad [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3105-985X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SNPfiltR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SNPfiltR Interactively Filter SNP Datasets Is designed to interactively and reproducibly visualize and filter SNP\n\t(single-nucleotide polymorphism) datasets. This R-based implementation of SNP\n\tand genotype filters facilitates \n\tan interactive and iterative SNP filtering pipeline, which can be documented\n\treproducibly via 'rmarkdown'. 'SNPfiltR' contains functions for visualizing \n\tvarious quality and missing data metrics for a SNP dataset, and then filtering\n\tthe dataset based on user specified cutoffs.\n\tAll functions take 'vcfR' objects as input, which can easily be\n\tgenerated by reading standard vcf (variant call format) files into R using \n\tthe R package 'vcfR' authored by Knaus and Gr\u00fcnwald (2017) <doi:10.1111/1755-0998.12549>. \n\tEach 'SNPfiltR' function can return a newly filtered 'vcfR' object, which can then be\n\twritten to a local directory in standard vcf format using the 'vcfR' package,\n\tfor downstream population genetic and phylogenetic analyses.  "
  },
  {
    "id": 7104,
    "package_name": "SQI",
    "title": "Soil Quality Index",
    "description": "The overall performance of soil ecosystem services and productivity greatly relies on soil health, making it a crucial indicator. The evaluation of soil physical, chemical, and biological parameters is necessary to determine the overall soil quality index. In our package, three commonly used methods, including linear scoring, regression-based, and principal component-based soil quality indexing, are employed to calculate the soil quality index. This package has been developed using concept of Bastida et al. (2008) and Doran and Parkin (1994) <doi:10.1016/j.geoderma.2008.08.007> <doi:10.2136/sssaspecpub35.c1>.  ",
    "version": "0.1.0",
    "maintainer": "Dr. Owais Ali Wani <owaisaliwani@skuastkashmir.ac.in>",
    "author": "Dr. Owais Ali Wani [aut, cre],\n  Dr. Faaique Nazir [aut],\n  Dr. Syed Sheraz Mahdi [aut],\n  Dr. Shabir Bangroo [aut],\n  Dr. A Raouf Malik [aut],\n  Dr. Shahnawaz Rasool Dar [aut],\n  Dr. Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SQI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SQI Soil Quality Index The overall performance of soil ecosystem services and productivity greatly relies on soil health, making it a crucial indicator. The evaluation of soil physical, chemical, and biological parameters is necessary to determine the overall soil quality index. In our package, three commonly used methods, including linear scoring, regression-based, and principal component-based soil quality indexing, are employed to calculate the soil quality index. This package has been developed using concept of Bastida et al. (2008) and Doran and Parkin (1994) <doi:10.1016/j.geoderma.2008.08.007> <doi:10.2136/sssaspecpub35.c1>.    "
  },
  {
    "id": 7108,
    "package_name": "SQMtools",
    "title": "Analyze Results Generated by the 'SqueezeMeta' Pipeline",
    "description": "'SqueezeMeta' is a versatile pipeline for the automated analysis of metagenomics/metatranscriptomics data (<https://github.com/jtamames/SqueezeMeta>). This package provides functions loading 'SqueezeMeta' results into R, filtering them based on different criteria, and visualizing the results using basic plots. The 'SqueezeMeta' project (and any subsets of it generated by the different filtering functions) is parsed into a single object, whose different components (e.g. tables with the taxonomic or functional composition across samples, contig/gene abundance profiles) can be easily analyzed using other R packages such as 'vegan' or 'DESeq2'. The methods in this package are further described in Puente-S\u00e1nchez et al., (2020) <doi:10.1186/s12859-020-03703-2>.",
    "version": "1.7.2",
    "maintainer": "Fernando Puente-S\u00e1nchez <fernando.puente.sanchez@slu.se>",
    "author": "Fernando Puente-S\u00e1nchez [aut, cre],\n  Natalia Garc\u00eda-Garc\u00eda [aut]",
    "url": "https://github.com/jtamames/SqueezeMeta",
    "bug_reports": "https://github.com/jtamames/SqueezeMeta/issues",
    "repository": "https://cran.r-project.org/package=SQMtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SQMtools Analyze Results Generated by the 'SqueezeMeta' Pipeline 'SqueezeMeta' is a versatile pipeline for the automated analysis of metagenomics/metatranscriptomics data (<https://github.com/jtamames/SqueezeMeta>). This package provides functions loading 'SqueezeMeta' results into R, filtering them based on different criteria, and visualizing the results using basic plots. The 'SqueezeMeta' project (and any subsets of it generated by the different filtering functions) is parsed into a single object, whose different components (e.g. tables with the taxonomic or functional composition across samples, contig/gene abundance profiles) can be easily analyzed using other R packages such as 'vegan' or 'DESeq2'. The methods in this package are further described in Puente-S\u00e1nchez et al., (2020) <doi:10.1186/s12859-020-03703-2>.  "
  },
  {
    "id": 7123,
    "package_name": "SSHAARP",
    "title": "Searching Shared HLA Amino Acid Residue Prevalence",
    "description": "Processes amino acid alignments produced by the 'IPD-IMGT/HLA (Immuno Polymorphism-ImMunoGeneTics/Human Leukocyte Antigen) Database' to identify user-defined amino acid residue motifs shared across HLA alleles, HLA alleles, or HLA haplotypes, and calculates frequencies based on HLA allele frequency data. 'SSHAARP' (Searching Shared HLA Amino Acid Residue Prevalence) uses 'Generic Mapping Tools (GMT)' software and the 'GMT' R package to generate global frequency heat maps that illustrate the distribution of each user-defined map around the globe. 'SSHAARP' analyzes the allele frequency data described by Solberg et al. (2008) <doi:10.1016/j.humimm.2008.05.001>, a global set of 497 population samples from 185 published datasets, representing 66,800 individuals total. Users may also specify their own datasets, but file conventions must follow the prebundled Solberg dataset, or the mock haplotype dataset.",
    "version": "2.0.8",
    "maintainer": "Livia Tran <livia.tran@ucsf.edu>",
    "author": "Livia Tran [aut, cre],\n  Steven Mack [aut],\n  Josh Bredeweg [ctb],\n  Dale Steinhardt [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SSHAARP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SSHAARP Searching Shared HLA Amino Acid Residue Prevalence Processes amino acid alignments produced by the 'IPD-IMGT/HLA (Immuno Polymorphism-ImMunoGeneTics/Human Leukocyte Antigen) Database' to identify user-defined amino acid residue motifs shared across HLA alleles, HLA alleles, or HLA haplotypes, and calculates frequencies based on HLA allele frequency data. 'SSHAARP' (Searching Shared HLA Amino Acid Residue Prevalence) uses 'Generic Mapping Tools (GMT)' software and the 'GMT' R package to generate global frequency heat maps that illustrate the distribution of each user-defined map around the globe. 'SSHAARP' analyzes the allele frequency data described by Solberg et al. (2008) <doi:10.1016/j.humimm.2008.05.001>, a global set of 497 population samples from 185 published datasets, representing 66,800 individuals total. Users may also specify their own datasets, but file conventions must follow the prebundled Solberg dataset, or the mock haplotype dataset.  "
  },
  {
    "id": 7132,
    "package_name": "SSP",
    "title": "Simulated Sampling Procedure for Community Ecology",
    "description": "The Simulation-based Sampling Protocol (SSP) is an R package designed to estimate sampling effort in studies of ecological communities. It is based on the concept of pseudo-multivariate standard error (MultSE) (Anderson & Santana-Garcon, 2015, <doi:10.1111/ele.12385>) and the simulation of ecological data. The theoretical background is described in Guerra-Castro et al. (2020, <doi:10.1111/ecog.05284>).",
    "version": "1.1.0",
    "maintainer": "Edlin Guerra-Castro <edlinguerra@gmail.com>",
    "author": "Edlin Guerra-Castro [aut, cre],\n  Maite Mascaro [aut],\n  Nuno Simoes [aut],\n  Juan Cruz-Motta [aut],\n  Juan Cajas [aut]",
    "url": "https://github.com/edlinguerra/SSP",
    "bug_reports": "https://github.com/edlinguerra/SSP/issues",
    "repository": "https://cran.r-project.org/package=SSP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SSP Simulated Sampling Procedure for Community Ecology The Simulation-based Sampling Protocol (SSP) is an R package designed to estimate sampling effort in studies of ecological communities. It is based on the concept of pseudo-multivariate standard error (MultSE) (Anderson & Santana-Garcon, 2015, <doi:10.1111/ele.12385>) and the simulation of ecological data. The theoretical background is described in Guerra-Castro et al. (2020, <doi:10.1111/ecog.05284>).  "
  },
  {
    "id": 7145,
    "package_name": "STATcubeR",
    "title": "R Interface for the 'STATcube' REST API and Open Government Data",
    "description": "Import data from the 'STATcube' REST API or from the open data\n    portal of Statistics Austria. This package includes a client for API\n    requests as well as parsing utilities for data which originates from\n    'STATcube'. Documentation about 'STATcubeR' is provided by several vignettes \n    included in the package as well as on the public 'pkgdown' page at \n    <https://statistikat.github.io/STATcubeR/>.",
    "version": "1.0.0",
    "maintainer": "Bernhard Meindl <Bernhard.Meindl@statistik.gv.at>",
    "author": "Bernhard Meindl [ctb, cre],\n  Alexander Kowarik [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>),\n  Gregor de Cillia [aut]",
    "url": "https://statistikat.github.io/STATcubeR/,\nhttps://github.com/statistikat/STATcubeR",
    "bug_reports": "https://github.com/statistikat/STATcubeR/issues",
    "repository": "https://cran.r-project.org/package=STATcubeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STATcubeR R Interface for the 'STATcube' REST API and Open Government Data Import data from the 'STATcube' REST API or from the open data\n    portal of Statistics Austria. This package includes a client for API\n    requests as well as parsing utilities for data which originates from\n    'STATcube'. Documentation about 'STATcubeR' is provided by several vignettes \n    included in the package as well as on the public 'pkgdown' page at \n    <https://statistikat.github.io/STATcubeR/>.  "
  },
  {
    "id": 7147,
    "package_name": "STCCGEV",
    "title": "Conditional Copula Model for Crop Yield Forecasting",
    "description": "Provides functions to model and forecast crop yields using a spatial temporal conditional copula approach. \n    The package incorporates extreme weather covariates and Bayesian Structural Time Series models to analyze crop \n    yield dependencies across multiple regions. Includes tools for fitting, simulating, and visualizing results. \n    This method build upon established R packages, including 'Hofert' 'et' 'al'. (2025) <doi:10.32614/CRAN.package.copula>, \n    'Scott' (2024) <doi:10.32614/CRAN.package.bsts>, and 'Stephenson' 'et' 'al'. (2024) <doi:10.32614/CRAN.package.evd>.",
    "version": "1.0.0",
    "maintainer": "Yongkun Li <yongkun.li@concordia.ca>",
    "author": "Marie Michaelides [aut],\n  M\u00e9lina Mailhot [aut],\n  Yongkun Li [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=STCCGEV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STCCGEV Conditional Copula Model for Crop Yield Forecasting Provides functions to model and forecast crop yields using a spatial temporal conditional copula approach. \n    The package incorporates extreme weather covariates and Bayesian Structural Time Series models to analyze crop \n    yield dependencies across multiple regions. Includes tools for fitting, simulating, and visualizing results. \n    This method build upon established R packages, including 'Hofert' 'et' 'al'. (2025) <doi:10.32614/CRAN.package.copula>, \n    'Scott' (2024) <doi:10.32614/CRAN.package.bsts>, and 'Stephenson' 'et' 'al'. (2024) <doi:10.32614/CRAN.package.evd>.  "
  },
  {
    "id": 7148,
    "package_name": "STCYP",
    "title": "Spatio-Temporal Crop Yield Prediction",
    "description": "Provides crop yield and meteorological data for Ontario, Canada. \n  Includes functions for fitting and predicting data using spatio-temporal models, as well as\n  tools for visualizing the results. The package builds upon existing R packages, including\n  'copula' (Hofert et al., 2025) <doi:10.32614/CRAN.package.copula>, and\n  'bsts' (Scott, 2024) <doi:10.32614/CRAN.package.bsts>.",
    "version": "1.0.0",
    "maintainer": "Yongkun Li <yongkun.li@concordia.ca>",
    "author": "Marie Michaelides [aut],\n  M\u00e9lina Mailhot [aut],\n  Yongkun Li [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=STCYP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "STCYP Spatio-Temporal Crop Yield Prediction Provides crop yield and meteorological data for Ontario, Canada. \n  Includes functions for fitting and predicting data using spatio-temporal models, as well as\n  tools for visualizing the results. The package builds upon existing R packages, including\n  'copula' (Hofert et al., 2025) <doi:10.32614/CRAN.package.copula>, and\n  'bsts' (Scott, 2024) <doi:10.32614/CRAN.package.bsts>.  "
  },
  {
    "id": 7183,
    "package_name": "SamplingStrata",
    "title": "Optimal Stratification of Sampling Frames for Multipurpose\nSampling Surveys",
    "description": "Tools for the optimization of stratified sampling design. It determines a stratification of a sampling frame that minimizes sample cost while satisfying precision constraints in a multivariate and multidomain context. The approach relies on a genetic algorithm; each candidate partition of the frame is an individual whose fitness is evaluated via the Bethel-Chromy allocation to meet target precisions. Functions support analysis of optimization results, labeling of the frame with new strata, and drawing a sample according to the optimal allocation. Algorithmic components adapt code from the 'genalg' package. See M. Ballin and G. Barcaroli (2020) \"R package SamplingStrata: new developments and extension to Spatial Sampling\" <doi:10.48550/arXiv.2004.09366>.",
    "version": "1.5-5",
    "maintainer": "Giulio Barcaroli <gbarcaroli@gmail.com>",
    "author": "Giulio Barcaroli [aut, cre],\n  Marco Ballin [aut],\n  Hanjo Odendaal [aut],\n  Daniela Pagliuca [aut],\n  Egon Willighagen [aut],\n  Diego Zardetto [aut]",
    "url": "https://barcaroli.github.io/SamplingStrata/,\nhttps://github.com/barcaroli/SamplingStrata/",
    "bug_reports": "https://github.com/barcaroli/SamplingStrata/issues",
    "repository": "https://cran.r-project.org/package=SamplingStrata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SamplingStrata Optimal Stratification of Sampling Frames for Multipurpose\nSampling Surveys Tools for the optimization of stratified sampling design. It determines a stratification of a sampling frame that minimizes sample cost while satisfying precision constraints in a multivariate and multidomain context. The approach relies on a genetic algorithm; each candidate partition of the frame is an individual whose fitness is evaluated via the Bethel-Chromy allocation to meet target precisions. Functions support analysis of optimization results, labeling of the frame with new strata, and drawing a sample according to the optimal allocation. Algorithmic components adapt code from the 'genalg' package. See M. Ballin and G. Barcaroli (2020) \"R package SamplingStrata: new developments and extension to Spatial Sampling\" <doi:10.48550/arXiv.2004.09366>.  "
  },
  {
    "id": 7263,
    "package_name": "ShinyWizard",
    "title": "An Interactive Wizard to Design, Build, and Deploy R Packages\nDemo Presentation",
    "description": "Design, build, and deploy R packages demo presentations by an interactive wizard. Set up unique title, logo and themes. Add personalized tabs exposing applicability. And deploy as a part of a package or an independent app. ",
    "version": "1.1.3.11",
    "maintainer": "Rafal Urniaz <rafal.urniaz@cantab.net>",
    "author": "Rafal Urniaz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0192-2165>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ShinyWizard",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ShinyWizard An Interactive Wizard to Design, Build, and Deploy R Packages\nDemo Presentation Design, build, and deploy R packages demo presentations by an interactive wizard. Set up unique title, logo and themes. Add personalized tabs exposing applicability. And deploy as a part of a package or an independent app.   "
  },
  {
    "id": 7287,
    "package_name": "SimCorrMix",
    "title": "Simulation of Correlated Data with Multiple Variable Types\nIncluding Continuous and Count Mixture Distributions",
    "description": "Generate continuous (normal, non-normal, or mixture distributions), binary, ordinal, \n    and count (regular or zero-inflated, Poisson or Negative Binomial) variables with a specified \n    correlation matrix, or one continuous variable with a mixture distribution.  This package can \n    be used to simulate data sets that mimic real-world clinical or genetic data sets (i.e., \n    plasmodes, as in Vaughan et al., 2009 <DOI:10.1016/j.csda.2008.02.032>).  The methods \n    extend those found in the 'SimMultiCorrData' R package.  Standard normal variables with an \n    imposed intermediate correlation matrix are transformed to generate the desired distributions.  \n    Continuous variables are simulated using either Fleishman (1978)'s third order \n    <DOI:10.1007/BF02293811> or Headrick (2002)'s fifth order \n    <DOI:10.1016/S0167-9473(02)00072-5> polynomial transformation method (the power method \n    transformation, PMT).  Non-mixture distributions require the user to specify mean, variance, \n    skewness, standardized kurtosis, and standardized fifth and sixth cumulants.  Mixture \n    distributions require these inputs for the component distributions plus the mixing \n    probabilities.  Simulation occurs at the component level for continuous mixture \n    distributions.  The target correlation matrix is specified in terms of correlations with \n    components of continuous mixture variables.  These components are transformed into the \n    desired mixture variables using random multinomial variables based on the mixing \n    probabilities.  However, the package provides functions to approximate expected correlations \n    with continuous mixture variables given target correlations with the components. Binary and \n    ordinal variables are simulated using a modification of ordsample() in package 'GenOrd'.  \n    Count variables are simulated using the inverse CDF method.  There are two simulation \n    pathways which calculate intermediate correlations involving count variables differently.  \n    Correlation Method 1 adapts Yahav and Shmueli's 2012 method <DOI:10.1002/asmb.901> and \n    performs best with large count variable means and positive correlations or small means and \n    negative correlations.  Correlation Method 2 adapts Barbiero and Ferrari's 2015 \n    modification of the 'GenOrd' package <DOI:10.1002/asmb.2072> and performs best under the \n    opposite scenarios.  The optional error loop may be used to improve the accuracy of the \n    final correlation matrix.  The package also contains functions to calculate the \n    standardized cumulants of continuous mixture distributions, check parameter inputs, \n    calculate feasible correlation boundaries, and summarize and plot simulated variables.",
    "version": "0.1.1",
    "maintainer": "Allison Cynthia Fialkowski <allijazz@uab.edu>",
    "author": "Allison Cynthia Fialkowski",
    "url": "https://github.com/AFialkowski/SimCorrMix",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SimCorrMix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimCorrMix Simulation of Correlated Data with Multiple Variable Types\nIncluding Continuous and Count Mixture Distributions Generate continuous (normal, non-normal, or mixture distributions), binary, ordinal, \n    and count (regular or zero-inflated, Poisson or Negative Binomial) variables with a specified \n    correlation matrix, or one continuous variable with a mixture distribution.  This package can \n    be used to simulate data sets that mimic real-world clinical or genetic data sets (i.e., \n    plasmodes, as in Vaughan et al., 2009 <DOI:10.1016/j.csda.2008.02.032>).  The methods \n    extend those found in the 'SimMultiCorrData' R package.  Standard normal variables with an \n    imposed intermediate correlation matrix are transformed to generate the desired distributions.  \n    Continuous variables are simulated using either Fleishman (1978)'s third order \n    <DOI:10.1007/BF02293811> or Headrick (2002)'s fifth order \n    <DOI:10.1016/S0167-9473(02)00072-5> polynomial transformation method (the power method \n    transformation, PMT).  Non-mixture distributions require the user to specify mean, variance, \n    skewness, standardized kurtosis, and standardized fifth and sixth cumulants.  Mixture \n    distributions require these inputs for the component distributions plus the mixing \n    probabilities.  Simulation occurs at the component level for continuous mixture \n    distributions.  The target correlation matrix is specified in terms of correlations with \n    components of continuous mixture variables.  These components are transformed into the \n    desired mixture variables using random multinomial variables based on the mixing \n    probabilities.  However, the package provides functions to approximate expected correlations \n    with continuous mixture variables given target correlations with the components. Binary and \n    ordinal variables are simulated using a modification of ordsample() in package 'GenOrd'.  \n    Count variables are simulated using the inverse CDF method.  There are two simulation \n    pathways which calculate intermediate correlations involving count variables differently.  \n    Correlation Method 1 adapts Yahav and Shmueli's 2012 method <DOI:10.1002/asmb.901> and \n    performs best with large count variable means and positive correlations or small means and \n    negative correlations.  Correlation Method 2 adapts Barbiero and Ferrari's 2015 \n    modification of the 'GenOrd' package <DOI:10.1002/asmb.2072> and performs best under the \n    opposite scenarios.  The optional error loop may be used to improve the accuracy of the \n    final correlation matrix.  The package also contains functions to calculate the \n    standardized cumulants of continuous mixture distributions, check parameter inputs, \n    calculate feasible correlation boundaries, and summarize and plot simulated variables.  "
  },
  {
    "id": 7290,
    "package_name": "SimEngine",
    "title": "A Modular Framework for Statistical Simulations in R",
    "description": "An open-source R package for structuring, maintaining, running, and debugging statistical simulations on both local and cluster-based computing environments.See full documentation at <https://avi-kenny.github.io/SimEngine/>.",
    "version": "1.4.0",
    "maintainer": "Avi Kenny <avi.kenny@gmail.com>",
    "author": "Avi Kenny [aut, cre],\n  Charles Wolock [aut]",
    "url": "https://avi-kenny.github.io/SimEngine/",
    "bug_reports": "https://github.com/Avi-Kenny/SimEngine/issues",
    "repository": "https://cran.r-project.org/package=SimEngine",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimEngine A Modular Framework for Statistical Simulations in R An open-source R package for structuring, maintaining, running, and debugging statistical simulations on both local and cluster-based computing environments.See full documentation at <https://avi-kenny.github.io/SimEngine/>.  "
  },
  {
    "id": 7358,
    "package_name": "SoundexBR",
    "title": "Phonetic-Coding for Portuguese",
    "description": "The SoundexBR package provides an algorithm for decoding names\n    into phonetic codes, as pronounced in Portuguese. The goal is for\n    homophones to be encoded to the same representation so that they can be\n    matched despite minor differences in spelling. The algorithm mainly encodes\n    consonants; a vowel will not be encoded unless it is the first letter. The\n    soundex code resultant consists of a four digits long string composed by\n    one letter followed by three numerical digits: the letter is the first\n    letter of the name, and the digits encode the remaining consonants.",
    "version": "1.2",
    "maintainer": "Daniel Marcelino <dmarcelino@live.com>",
    "author": "Daniel Marcelino",
    "url": "",
    "bug_reports": "http://github.com/danielmarcelino/soundexBR",
    "repository": "https://cran.r-project.org/package=SoundexBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SoundexBR Phonetic-Coding for Portuguese The SoundexBR package provides an algorithm for decoding names\n    into phonetic codes, as pronounced in Portuguese. The goal is for\n    homophones to be encoded to the same representation so that they can be\n    matched despite minor differences in spelling. The algorithm mainly encodes\n    consonants; a vowel will not be encoded unless it is the first letter. The\n    soundex code resultant consists of a four digits long string composed by\n    one letter followed by three numerical digits: the letter is the first\n    letter of the name, and the digits encode the remaining consonants.  "
  },
  {
    "id": 7438,
    "package_name": "StAMPP",
    "title": "Statistical Analysis of Mixed Ploidy Populations",
    "description": "Allows users to calculate pairwise Nei's Genetic Distances (Nei 1972), pairwise Fixation\n Indexes (Fst) (Weir & Cockerham 1984) and also Genomic Relationship matrixes following Yang et al. (2010) in mixed and single\n ploidy populations. Bootstrapping across loci is implemented during Fst calculation to generate confidence intervals and p-values\n around pairwise Fst values. StAMPP utilises SNP genotype data of any ploidy level (with the ability to handle missing data) and is coded to  \n utilise multithreading where available to allow efficient analysis of large datasets. StAMPP is able to handle genotype data from genlight objects \n allowing integration with other packages such adegenet.\n Please refer to LW Pembleton, NOI Cogan & JW Forster, 2013, Molecular Ecology Resources, 13(5), 946-952. <doi:10.1111/1755-0998.12129> for the appropriate citation and user manual. Thank you in advance.",
    "version": "1.6.3",
    "maintainer": "LW Pembleton <lwpembleton@gmail.com>",
    "author": "LW Pembleton",
    "url": "https://github.com/lpembleton/StAMPP",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StAMPP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StAMPP Statistical Analysis of Mixed Ploidy Populations Allows users to calculate pairwise Nei's Genetic Distances (Nei 1972), pairwise Fixation\n Indexes (Fst) (Weir & Cockerham 1984) and also Genomic Relationship matrixes following Yang et al. (2010) in mixed and single\n ploidy populations. Bootstrapping across loci is implemented during Fst calculation to generate confidence intervals and p-values\n around pairwise Fst values. StAMPP utilises SNP genotype data of any ploidy level (with the ability to handle missing data) and is coded to  \n utilise multithreading where available to allow efficient analysis of large datasets. StAMPP is able to handle genotype data from genlight objects \n allowing integration with other packages such adegenet.\n Please refer to LW Pembleton, NOI Cogan & JW Forster, 2013, Molecular Ecology Resources, 13(5), 946-952. <doi:10.1111/1755-0998.12129> for the appropriate citation and user manual. Thank you in advance.  "
  },
  {
    "id": 7481,
    "package_name": "StrathE2E2",
    "title": "End-to-End Marine Food Web Model",
    "description": "A dynamic model of \n    the big-picture, whole ecosystem effects of hydrodynamics, \n\ttemperature, nutrients, and fishing on continental shelf marine \n\tfood webs. The package is described in: Heath, M.R., \n\tSpeirs, D.C., Thurlbeck, I. and Wilson, R.J. (2020) \n\t<doi:10.1111/2041-210X.13510> StrathE2E2: An R package \n\tfor modelling the dynamics of marine food webs and \n\tfisheries. 8pp.",
    "version": "3.3.0",
    "maintainer": "Michael Heath <m.heath@strath.ac.uk>",
    "author": "Michael Heath [aut],\n    Ian Thurlbeck [ctb]",
    "url": "https://gitlab.com/MarineResourceModelling/StrathE2E/StrathE2E2,\nhttps://marineresourcemodelling.gitlab.io/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StrathE2E2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StrathE2E2 End-to-End Marine Food Web Model A dynamic model of \n    the big-picture, whole ecosystem effects of hydrodynamics, \n\ttemperature, nutrients, and fishing on continental shelf marine \n\tfood webs. The package is described in: Heath, M.R., \n\tSpeirs, D.C., Thurlbeck, I. and Wilson, R.J. (2020) \n\t<doi:10.1111/2041-210X.13510> StrathE2E2: An R package \n\tfor modelling the dynamics of marine food webs and \n\tfisheries. 8pp.  "
  },
  {
    "id": 7493,
    "package_name": "StructureMC",
    "title": "Structured Matrix Completion",
    "description": "Provides an efficient method to recover the missing block of an approximately low-rank matrix. Current literature on matrix completion focuses primarily on independent sampling models under which the individual observed entries are sampled independently. Motivated by applications in genomic data integration, we propose a new framework of structured matrix completion (SMC) to treat structured missingness by design [Cai T, Cai TT, Zhang A (2016) <doi:10.1080/01621459.2015.1021005>]. Specifically, our proposed method aims at efficient matrix recovery when a subset of the rows and columns of an approximately low-rank matrix are observed. The main function in our package, smc.FUN(), is for recovery of the missing block A22 of an approximately low-rank matrix A given the other blocks A11, A12, A21.",
    "version": "1.0",
    "maintainer": "Yifu Liu <2012johnnyliu@gmail.com>",
    "author": "Yifu Liu and Anru Zhang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StructureMC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StructureMC Structured Matrix Completion Provides an efficient method to recover the missing block of an approximately low-rank matrix. Current literature on matrix completion focuses primarily on independent sampling models under which the individual observed entries are sampled independently. Motivated by applications in genomic data integration, we propose a new framework of structured matrix completion (SMC) to treat structured missingness by design [Cai T, Cai TT, Zhang A (2016) <doi:10.1080/01621459.2015.1021005>]. Specifically, our proposed method aims at efficient matrix recovery when a subset of the rows and columns of an approximately low-rank matrix are observed. The main function in our package, smc.FUN(), is for recovery of the missing block A22 of an approximately low-rank matrix A given the other blocks A11, A12, A21.  "
  },
  {
    "id": 7511,
    "package_name": "SuperGauss",
    "title": "Superfast Likelihood Inference for Stationary Gaussian Time\nSeries",
    "description": "Likelihood evaluations for stationary Gaussian time series are typically obtained via the Durbin-Levinson algorithm, which scales as O(n^2) in the number of time series observations.  This package provides a \"superfast\" O(n log^2 n) algorithm written in C++, crossing over with Durbin-Levinson around n = 300.  Efficient implementations of the score and Hessian functions are also provided, leading to superfast versions of inference algorithms such as Newton-Raphson and Hamiltonian Monte Carlo.  The C++ code provides a Toeplitz matrix class packaged as a header-only library, to simplify low-level usage in other packages and outside of R.",
    "version": "2.0.4",
    "maintainer": "Martin Lysy <mlysy@uwaterloo.ca>",
    "author": "Yun Ling [aut],\n  Martin Lysy [aut, cre]",
    "url": "https://github.com/mlysy/SuperGauss",
    "bug_reports": "https://github.com/mlysy/SuperGauss/issues",
    "repository": "https://cran.r-project.org/package=SuperGauss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SuperGauss Superfast Likelihood Inference for Stationary Gaussian Time\nSeries Likelihood evaluations for stationary Gaussian time series are typically obtained via the Durbin-Levinson algorithm, which scales as O(n^2) in the number of time series observations.  This package provides a \"superfast\" O(n log^2 n) algorithm written in C++, crossing over with Durbin-Levinson around n = 300.  Efficient implementations of the score and Hessian functions are also provided, leading to superfast versions of inference algorithms such as Newton-Raphson and Hamiltonian Monte Carlo.  The C++ code provides a Toeplitz matrix class packaged as a header-only library, to simplify low-level usage in other packages and outside of R.  "
  },
  {
    "id": 7541,
    "package_name": "SurveyCC",
    "title": "Canonical Correlation for Survey Data",
    "description": "Performs canonical correlation for survey data, including \n  multiple tests of significance for secondary canonical correlations. \n  A key feature of this package is that it incorporates survey data structure \n  directly in a novel test of significance via a sequence of simple linear \n  regression models on the canonical variates. See reference - Cruz-Cano, \n  Cohen, and Mead-Morse (2024) \"Canonical Correlation Analysis of Survey data: the SurveyCC R package\" \n  The R Journal under review.",
    "version": "0.2.1",
    "maintainer": "Raul Cruz-Cano <raulcruz@iu.edu>",
    "author": "Raul Cruz-Cano [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7715-1198>)",
    "url": "https://github.com/237triangle/SurveyCC",
    "bug_reports": "https://github.com/237triangle/SurveyCC/issues",
    "repository": "https://cran.r-project.org/package=SurveyCC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SurveyCC Canonical Correlation for Survey Data Performs canonical correlation for survey data, including \n  multiple tests of significance for secondary canonical correlations. \n  A key feature of this package is that it incorporates survey data structure \n  directly in a novel test of significance via a sequence of simple linear \n  regression models on the canonical variates. See reference - Cruz-Cano, \n  Cohen, and Mead-Morse (2024) \"Canonical Correlation Analysis of Survey data: the SurveyCC R package\" \n  The R Journal under review.  "
  },
  {
    "id": 7596,
    "package_name": "TDIagree",
    "title": "Assessment of Agreement using the Total Deviation Index",
    "description": "The total deviation index (TDI) is an unscaled statistical measure used to evaluate the deviation between paired quantitative measurements when assessing the extent of agreement between different raters. It describes a boundary such that a large specified proportion of the differences in paired measurements are within the boundary (Lin, 2000) <https://pubmed.ncbi.nlm.nih.gov/10641028/>.\n    This R package implements some methodologies existing in the literature for TDI estimation and inference in the case of two raters.",
    "version": "0.2.0",
    "maintainer": "Anna Felip-Badia <annafelipibadia@gmail.com>",
    "author": "Anna Felip-Badia [aut, cre] (ORCID:\n    <https://orcid.org/0009-0002-8751-5228>),\n  Sara Perez-Jaume [aut] (ORCID: <https://orcid.org/0000-0002-9805-4810>),\n  Josep L Carrasco [aut] (ORCID: <https://orcid.org/0000-0003-1184-0753>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TDIagree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TDIagree Assessment of Agreement using the Total Deviation Index The total deviation index (TDI) is an unscaled statistical measure used to evaluate the deviation between paired quantitative measurements when assessing the extent of agreement between different raters. It describes a boundary such that a large specified proportion of the differences in paired measurements are within the boundary (Lin, 2000) <https://pubmed.ncbi.nlm.nih.gov/10641028/>.\n    This R package implements some methodologies existing in the literature for TDI estimation and inference in the case of two raters.  "
  },
  {
    "id": 7599,
    "package_name": "TDSTNN",
    "title": "Time Delay Spatio Temporal Neural Network",
    "description": "STARMA (Space-Time Autoregressive Moving Average) models are commonly utilized in modeling and forecasting spatiotemporal time series data. However, the intricate nonlinear dynamics observed in many space-time rainfall patterns often exceed the capabilities of conventional STARMA models. This R package enables the fitting of Time Delay Spatio-Temporal Neural Networks, which are adept at handling such complex nonlinear dynamics efficiently. For detailed methodology, please refer to Saha et al. (2020) <doi:10.1007/s00704-020-03374-2>.",
    "version": "0.1.0",
    "maintainer": "Mrinmoy Ray <mrinmoy4848@gmail.com>",
    "author": "Mrinmoy Ray [aut, cre],\n  Rajeev Ranjan Kumar [aut, ctb],\n  Kanchan Sinha [aut, ctb],\n  K. N. Singh [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TDSTNN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TDSTNN Time Delay Spatio Temporal Neural Network STARMA (Space-Time Autoregressive Moving Average) models are commonly utilized in modeling and forecasting spatiotemporal time series data. However, the intricate nonlinear dynamics observed in many space-time rainfall patterns often exceed the capabilities of conventional STARMA models. This R package enables the fitting of Time Delay Spatio-Temporal Neural Networks, which are adept at handling such complex nonlinear dynamics efficiently. For detailed methodology, please refer to Saha et al. (2020) <doi:10.1007/s00704-020-03374-2>.  "
  },
  {
    "id": 7604,
    "package_name": "TEQR",
    "title": "Target Equivalence Range Design",
    "description": "The TEQR package contains software to calculate the operating characteristics for the TEQR and the ACT designs.The TEQR (toxicity equivalence range) design is a toxicity based cumulative cohort design with added safety rules. The ACT (Activity constrained for toxicity) design  is also a cumulative cohort design with additional safety rules. The unique feature of this design is that dose is escalated based on lack of activity rather than on lack of toxicity and is de-escalated only if an unacceptable level of toxicity is experienced.",
    "version": "6.0-0",
    "maintainer": "M. Suzette Blanchard <sblanchard@coh.org>",
    "author": "M. Suzette Blanchard",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TEQR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TEQR Target Equivalence Range Design The TEQR package contains software to calculate the operating characteristics for the TEQR and the ACT designs.The TEQR (toxicity equivalence range) design is a toxicity based cumulative cohort design with added safety rules. The ACT (Activity constrained for toxicity) design  is also a cumulative cohort design with additional safety rules. The unique feature of this design is that dose is escalated based on lack of activity rather than on lack of toxicity and is de-escalated only if an unacceptable level of toxicity is experienced.  "
  },
  {
    "id": 7613,
    "package_name": "TH.data",
    "title": "TH's Data Archive",
    "description": "Contains data sets used in other packages Torsten Hothorn\n  maintains.",
    "version": "1.1-5",
    "maintainer": "Torsten Hothorn <Torsten.Hothorn@R-project.org>",
    "author": "Torsten Hothorn [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TH.data",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TH.data TH's Data Archive Contains data sets used in other packages Torsten Hothorn\n  maintains.  "
  },
  {
    "id": 7670,
    "package_name": "TSLSTMplus",
    "title": "Long-Short Term Memory for Time-Series Forecasting, Enhanced",
    "description": "The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Customizable configurations for the model are allowed, improving the capabilities and usability of this model compared to other packages. This package is based on 'keras' and 'tensorflow' modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.",
    "version": "1.0.6",
    "maintainer": "Jaime Pizarroso Gonzalo <jpizarroso@comillas.edu>",
    "author": "Jaime Pizarroso Gonzalo [aut, ctb, cre],\n  Antonio Mu\u00f1oz San Roque [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSLSTMplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSLSTMplus Long-Short Term Memory for Time-Series Forecasting, Enhanced The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Customizable configurations for the model are allowed, improving the capabilities and usability of this model compared to other packages. This package is based on 'keras' and 'tensorflow' modules and the algorithm of Paul and Garai (2021) <doi:10.1007/s00500-021-06087-4>.  "
  },
  {
    "id": 7688,
    "package_name": "TTAinterfaceTrendAnalysis",
    "title": "Temporal Trend Analysis Graphical Interface",
    "description": "This interface was created to develop a standard procedure \n to analyse temporal trend in the framework of the OSPAR convention.\n The analysis process run through 4 successive steps : 1) manipulate your data, 2)\n select the parameters you want to analyse, 3) build your regulated \n time series, 4) perform diagnosis and analysis and 5) read the results. \n Statistical analysis call other package function such as Kendall tests\n or cusum() function.",
    "version": "1.5.11",
    "maintainer": "David DEVREKER <David.Devreker@ifremer.fr>",
    "author": "David DEVREKER [aut, cre],\n  Alain LEFEBVRE [aut]",
    "url": "https://CRAN.R-project.org/package=TTAinterfaceTrendAnalysis",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TTAinterfaceTrendAnalysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TTAinterfaceTrendAnalysis Temporal Trend Analysis Graphical Interface This interface was created to develop a standard procedure \n to analyse temporal trend in the framework of the OSPAR convention.\n The analysis process run through 4 successive steps : 1) manipulate your data, 2)\n select the parameters you want to analyse, 3) build your regulated \n time series, 4) perform diagnosis and analysis and 5) read the results. \n Statistical analysis call other package function such as Kendall tests\n or cusum() function.  "
  },
  {
    "id": 7691,
    "package_name": "TTR.PGM",
    "title": "Thornley Transport Resistance Plant Growth Model",
    "description": "An implementation of the Thornley transport resistance plant growth model. The package can be used to simulate plant growth as forced by climate system variables. The package provides methods for formatting forcing variables, simulating growth dynamics and calibrating model parameters. For more information see Higgins et al. (2025) TTR.PGM: An R package for modelling the distributions and dynamics of plants using the Thornley transport resistance plant growth model. Methods in Ecology and Evolution. in press.",
    "version": "1.0.0",
    "maintainer": "Steven Higgins <steven.higgins@uni-bayreuth.de>",
    "author": "Steven Higgins [aut, cre, cph],\n  Arne Burkhardt [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TTR.PGM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TTR.PGM Thornley Transport Resistance Plant Growth Model An implementation of the Thornley transport resistance plant growth model. The package can be used to simulate plant growth as forced by climate system variables. The package provides methods for formatting forcing variables, simulating growth dynamics and calibrating model parameters. For more information see Higgins et al. (2025) TTR.PGM: An R package for modelling the distributions and dynamics of plants using the Thornley transport resistance plant growth model. Methods in Ecology and Evolution. in press.  "
  },
  {
    "id": 7694,
    "package_name": "TUGLab",
    "title": "A Laboratory for TU Games",
    "description": "Cooperative game theory models decision-making situations in\n    which a group of agents, called players, may achieve certain benefits\n    by cooperating to reach an optimal outcome. It has great potential in\n    different fields, since it offers a scenario to analyze and solve\n    problems in which cooperation is essential to achieve a common goal.\n    The 'TUGLab' (Transferable Utility Games Laboratory) R package\n    contains a set of scripts that could serve as a helpful complement to\n    the books and other materials used in courses on cooperative game\n    theory, and also as a practical tool for researchers working in this\n    field. The 'TUGLab' project was born in 2006 trying to highlight the\n    geometrical aspects of the theory of cooperative games for 3 and 4\n    players. 'TUGlabWeb' is an online platform on which the basic\n    functions of 'TUGLab' are implemented, and it is being used all over\n    the world as a resource in degree, master's and doctoral programs.\n    This package is an extension of the first versions and enables users\n    to work with games in general (computational restrictions aside). The\n    user can check properties of games, compute well-known games and\n    calculate several set-valued and single-valued solutions such as the\n    core, the Shapley value, the nucleolus or the core-center. The package\n    also illustrates how the Shapley value flexibly adapts to various\n    cooperative game settings, including weighted players and coalitions,\n    a priori unions, and restricted communication structures. In keeping\n    with the original philosophy of the first versions, special emphasis\n    is placed on the graphical representation of the solution concepts for\n    3 and 4 players.",
    "version": "0.0.1",
    "maintainer": "\u00c1lvaro de Prado Saborido <alvarodepradosaborido@gmail.com>",
    "author": "\u00c1lvaro de Prado Saborido [aut, cre] (Departamento de Estat\u00edstica e\n    Investigaci\u00f3n Operativa. Universidade de Vigo. Spain),\n  Alejandro Bern\u00e1rdez Ferrad\u00e1s [ctb] (ORCID:\n    <https://orcid.org/0009-0006-0960-3555>, SiDOR. Departamento de\n    Estat\u00edstica e Investigaci\u00f3n Operativa. Universidade de Vigo.\n    CITMAga. Spain),\n  Miguel \u00c1ngel Mir\u00e1s Calvo [aut] (ORCID:\n    <https://orcid.org/0000-0001-7247-1926>, RGEAF. Departamento de\n    Matem\u00e1ticas. Universidade de Vigo. Spain),\n  Iago N\u00fa\u00f1ez Lugilde [aut] (ORCID:\n    <https://orcid.org/0000-0003-3382-0737>, Departamento de\n    Matem\u00e1ticas. MODES. Universidade da Coru\u00f1a. Spain),\n  Carmen Quinteiro Sandomingo [aut] (ORCID:\n    <https://orcid.org/0000-0002-2711-1945>, Departamento de\n    Matem\u00e1ticas. Universidade de Vigo. Spain),\n  Estela S\u00e1nchez Rodr\u00edguez [aut] (ORCID:\n    <https://orcid.org/0000-0002-0933-6411>, SiDOR. Departamento de\n    Estat\u00edstica e Investigaci\u00f3n Operativa. Universidade de Vigo.\n    CITMAga. Spain),\n  MCIN/AEI/10.13039/501100011033 [fnd] (Project PID2021-124030NB-C33.\n    ERDF A way of making Europe/EU)",
    "url": "http://tuglabweb.uvigo.es/TUGlabWEB2/index.php,\nhttps://mmiras.webs.uvigo.es/TUGlab/",
    "bug_reports": "https://github.com/esanchez-coder/TUGLab/issues",
    "repository": "https://cran.r-project.org/package=TUGLab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TUGLab A Laboratory for TU Games Cooperative game theory models decision-making situations in\n    which a group of agents, called players, may achieve certain benefits\n    by cooperating to reach an optimal outcome. It has great potential in\n    different fields, since it offers a scenario to analyze and solve\n    problems in which cooperation is essential to achieve a common goal.\n    The 'TUGLab' (Transferable Utility Games Laboratory) R package\n    contains a set of scripts that could serve as a helpful complement to\n    the books and other materials used in courses on cooperative game\n    theory, and also as a practical tool for researchers working in this\n    field. The 'TUGLab' project was born in 2006 trying to highlight the\n    geometrical aspects of the theory of cooperative games for 3 and 4\n    players. 'TUGlabWeb' is an online platform on which the basic\n    functions of 'TUGLab' are implemented, and it is being used all over\n    the world as a resource in degree, master's and doctoral programs.\n    This package is an extension of the first versions and enables users\n    to work with games in general (computational restrictions aside). The\n    user can check properties of games, compute well-known games and\n    calculate several set-valued and single-valued solutions such as the\n    core, the Shapley value, the nucleolus or the core-center. The package\n    also illustrates how the Shapley value flexibly adapts to various\n    cooperative game settings, including weighted players and coalitions,\n    a priori unions, and restricted communication structures. In keeping\n    with the original philosophy of the first versions, special emphasis\n    is placed on the graphical representation of the solution concepts for\n    3 and 4 players.  "
  },
  {
    "id": 7736,
    "package_name": "TestDesign",
    "title": "Optimal Test Design Approach to Fixed and Adaptive Test\nConstruction",
    "description": "Uses the optimal test design approach by Birnbaum (1968, ISBN:9781593119348) and\n    van der Linden (2018) <doi:10.1201/9781315117430> to construct fixed, adaptive, and parallel tests.\n    Supports the following mixed-integer programming (MIP) solver packages: 'Rsymphony',\n    'highs', 'gurobi', 'lpSolve', and 'Rglpk'. The 'gurobi' package is not available from CRAN; see <https://www.gurobi.com/downloads/>.",
    "version": "1.7.0",
    "maintainer": "Seung W. Choi <schoi@austin.utexas.edu>",
    "author": "Seung W. Choi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4777-5420>),\n  Sangdon Lim [aut] (ORCID: <https://orcid.org/0000-0002-2988-014X>)",
    "url": "https://choi-phd.github.io/TestDesign/ (documentation)",
    "bug_reports": "https://github.com/choi-phd/TestDesign/issues/",
    "repository": "https://cran.r-project.org/package=TestDesign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TestDesign Optimal Test Design Approach to Fixed and Adaptive Test\nConstruction Uses the optimal test design approach by Birnbaum (1968, ISBN:9781593119348) and\n    van der Linden (2018) <doi:10.1201/9781315117430> to construct fixed, adaptive, and parallel tests.\n    Supports the following mixed-integer programming (MIP) solver packages: 'Rsymphony',\n    'highs', 'gurobi', 'lpSolve', and 'Rglpk'. The 'gurobi' package is not available from CRAN; see <https://www.gurobi.com/downloads/>.  "
  },
  {
    "id": 7745,
    "package_name": "Tex4exams",
    "title": "Generating 'Sweave' Code for 'R/exams' Questions in Mathematics",
    "description": "When using the R package  'exams'  to write mathematics questions in 'Sweave' files, the output of a lot of R functions need to be adjusted for display in mathematical formulas. Specifically, the functions were accumulated when writing questions for the  topics of the mathematics courses College Algebra, Precalculus, Calculus, Differential Equations, Introduction to Probability, and Linear Algebra.  The output of the developed functions can be used in 'Sweave' files. ",
    "version": "0.1.2",
    "maintainer": "Qingwen Hu <huqwen@gmail.com>",
    "author": "Qingwen Hu [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0482-5873>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Tex4exams",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Tex4exams Generating 'Sweave' Code for 'R/exams' Questions in Mathematics When using the R package  'exams'  to write mathematics questions in 'Sweave' files, the output of a lot of R functions need to be adjusted for display in mathematical formulas. Specifically, the functions were accumulated when writing questions for the  topics of the mathematics courses College Algebra, Precalculus, Calculus, Differential Equations, Introduction to Probability, and Linear Algebra.  The output of the developed functions can be used in 'Sweave' files.   "
  },
  {
    "id": 7774,
    "package_name": "TimeVizPro",
    "title": "Dynamic Data Explorer: Visualize and Forecast with 'TimeVizPro'",
    "description": "Unleash the power of time-series data visualization with ease using our package. Designed with simplicity \n in mind, it offers three key features through the 'shiny' package output. The first tab shows time- series \n charts with forecasts, allowing users to visualize trends and changes effortlessly. The second one displays \n Averages per country presented in tables with accompanying sparklines, providing a quick and attractive \n overview of the data. The last tab presents A customizable world map colored based on user-defined \n variables for any chosen number of countries, offering an advanced visual approach to understanding \n geographical data distributions. This package operates with just a few simple arguments, enabling users \n to conduct sophisticated analyses without the need for complex programming skills. Transform your \n time-series data analysis experience with our user-friendly tool. ",
    "version": "1.0.1",
    "maintainer": "Leila Marvian Mashhad <Leila.marveian@gmail.com>",
    "author": "Hossein Hassani [aut],\n  Fernando Cantu Bazaldua [aut],\n  Leila Marvian Mashhad [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TimeVizPro",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TimeVizPro Dynamic Data Explorer: Visualize and Forecast with 'TimeVizPro' Unleash the power of time-series data visualization with ease using our package. Designed with simplicity \n in mind, it offers three key features through the 'shiny' package output. The first tab shows time- series \n charts with forecasts, allowing users to visualize trends and changes effortlessly. The second one displays \n Averages per country presented in tables with accompanying sparklines, providing a quick and attractive \n overview of the data. The last tab presents A customizable world map colored based on user-defined \n variables for any chosen number of countries, offering an advanced visual approach to understanding \n geographical data distributions. This package operates with just a few simple arguments, enabling users \n to conduct sophisticated analyses without the need for complex programming skills. Transform your \n time-series data analysis experience with our user-friendly tool.   "
  },
  {
    "id": 7776,
    "package_name": "TipDatingBeast",
    "title": "Using Tip Dates with Phylogenetic Trees in BEAST",
    "description": "Assists performing tip-dating of phylogenetic trees with BEAST \n    BEAST is a popular software for phylogenetic analysis.\n    The package assists the implementation of various phylogenetic tip-\n\tdating tests using BEAST. It contains two main functions.\n\tThe first one allows preparing date randomization analyses, \n\twhich assess the temporal signal of a data set. \n\tThe second function allows performing leave-one-out analyses,\n\twhich test for the consistency between independent calibration sequences\n\tand allow pinpointing those leading to potential bias.\n\tThe included tutorial provides detailed step-by-step instructions.\n\tAn expanded description of the package can be found in article:\n\tRieux, A. and Khatchikian, C.E. (2017), \n\tTIPDATINGBEAST: an R package to assist the implementation of phylogenetic\n\ttip-dating tests using BEAST. Molecular Ecology Resources, 17: 608-613.\n\t<onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12603>.",
    "version": "1.1-0",
    "maintainer": "Camilo Khatchikian <ckhatchikian@gmail.com>",
    "author": "Adrien Rieux, Camilo Khatchikian",
    "url": "https://www.r-project.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TipDatingBeast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TipDatingBeast Using Tip Dates with Phylogenetic Trees in BEAST Assists performing tip-dating of phylogenetic trees with BEAST \n    BEAST is a popular software for phylogenetic analysis.\n    The package assists the implementation of various phylogenetic tip-\n\tdating tests using BEAST. It contains two main functions.\n\tThe first one allows preparing date randomization analyses, \n\twhich assess the temporal signal of a data set. \n\tThe second function allows performing leave-one-out analyses,\n\twhich test for the consistency between independent calibration sequences\n\tand allow pinpointing those leading to potential bias.\n\tThe included tutorial provides detailed step-by-step instructions.\n\tAn expanded description of the package can be found in article:\n\tRieux, A. and Khatchikian, C.E. (2017), \n\tTIPDATINGBEAST: an R package to assist the implementation of phylogenetic\n\ttip-dating tests using BEAST. Molecular Ecology Resources, 17: 608-613.\n\t<onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12603>.  "
  },
  {
    "id": 7797,
    "package_name": "TransGraph",
    "title": "Transfer Graph Learning",
    "description": "Transfer learning, aiming to use auxiliary domains to help improve learning of the target domain of interest when multiple heterogeneous datasets are available, has been a hot topic in statistical machine learning. The recent transfer learning methods with statistical guarantees mainly focus on the overall parameter transfer for supervised models in the ideal case with the informative auxiliary domains with overall similarity. In contrast, transfer learning for unsupervised graph learning is in its infancy and largely follows the idea of overall parameter transfer as for supervised learning. \n             In this package, the transfer learning for several complex graphical models is implemented, including Tensor Gaussian graphical models, non-Gaussian directed acyclic graph (DAG), and Gaussian graphical mixture models. Notably, this package promotes local transfer at node-level and subgroup-level in DAG structural learning and Gaussian graphical mixture models, respectively, which are more flexible and robust than the existing overall parameter transfer. As by-products, transfer learning for undirected graphical model (precision matrix) via D-trace loss, transfer learning for mean vector estimation, and single non-Gaussian learning via topological layer method are also included in this package. \n             Moreover, the aggregation of auxiliary information is an important issue in transfer learning, and this package provides multiple user-friendly aggregation methods, including sample weighting, similarity weighting, and most informative selection.    \n             (Note: the transfer for tensor GGM has been temporarily removed in the current version as its dependent R package Tlasso has been archived. The historical version TransGraph_1.0.0.tar.gz can be downloaded at <https://cran.r-project.org/src/contrib/Archive/TransGraph/>)\n             Reference: \n             Ren, M., Zhen Y., and Wang J. (2024) <https://jmlr.org/papers/v25/22-1313.html> \"Transfer learning for tensor graphical models\".    \n             Ren, M., He X., and Wang J. (2023) <doi:10.48550/arXiv.2310.10239> \"Structural transfer learning of non-Gaussian DAG\".    \n             Zhao, R., He X., and Wang J. (2022) <https://jmlr.org/papers/v23/21-1173.html> \"Learning linear non-Gaussian directed acyclic graph with diverging number of nodes\".",
    "version": "1.1.0",
    "maintainer": "Mingyang Ren <renmingyang17@mails.ucas.ac.cn>",
    "author": "Mingyang Ren [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8061-9940>),\n  Ruixuan Zhao [aut],\n  Xin He [aut],\n  Junhui Wang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TransGraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TransGraph Transfer Graph Learning Transfer learning, aiming to use auxiliary domains to help improve learning of the target domain of interest when multiple heterogeneous datasets are available, has been a hot topic in statistical machine learning. The recent transfer learning methods with statistical guarantees mainly focus on the overall parameter transfer for supervised models in the ideal case with the informative auxiliary domains with overall similarity. In contrast, transfer learning for unsupervised graph learning is in its infancy and largely follows the idea of overall parameter transfer as for supervised learning. \n             In this package, the transfer learning for several complex graphical models is implemented, including Tensor Gaussian graphical models, non-Gaussian directed acyclic graph (DAG), and Gaussian graphical mixture models. Notably, this package promotes local transfer at node-level and subgroup-level in DAG structural learning and Gaussian graphical mixture models, respectively, which are more flexible and robust than the existing overall parameter transfer. As by-products, transfer learning for undirected graphical model (precision matrix) via D-trace loss, transfer learning for mean vector estimation, and single non-Gaussian learning via topological layer method are also included in this package. \n             Moreover, the aggregation of auxiliary information is an important issue in transfer learning, and this package provides multiple user-friendly aggregation methods, including sample weighting, similarity weighting, and most informative selection.    \n             (Note: the transfer for tensor GGM has been temporarily removed in the current version as its dependent R package Tlasso has been archived. The historical version TransGraph_1.0.0.tar.gz can be downloaded at <https://cran.r-project.org/src/contrib/Archive/TransGraph/>)\n             Reference: \n             Ren, M., Zhen Y., and Wang J. (2024) <https://jmlr.org/papers/v25/22-1313.html> \"Transfer learning for tensor graphical models\".    \n             Ren, M., He X., and Wang J. (2023) <doi:10.48550/arXiv.2310.10239> \"Structural transfer learning of non-Gaussian DAG\".    \n             Zhao, R., He X., and Wang J. (2022) <https://jmlr.org/papers/v23/21-1173.html> \"Learning linear non-Gaussian directed acyclic graph with diverging number of nodes\".  "
  },
  {
    "id": 7841,
    "package_name": "TukeyC",
    "title": "Conventional Tukey Test",
    "description": "Provides tools to perform multiple comparison analyses, based on the well-known Tukey's \"Honestly Significant Difference\" (HSD) test. In models involving interactions, 'TukeyC' stands out from other R packages by implementing intuitive and easy-to-use functions. In addition to accommodating traditional R methods such as lm() and aov(), it has also been extended to objects of the lmer() class, that is, mixed models with fixed effects. For more details see Tukey (1949) <doi:10.2307/3001913>.",
    "version": "1.3-43",
    "maintainer": "Ivan Bezerra Allaman <ivanalaman@gmail.com>",
    "author": "Jose Claudio Faria [aut],\n  Enio G. Jelihovschi [aut],\n  Ivan Bezerra Allaman [aut, cre]",
    "url": "https://github.com/jcfaria/TukeyC",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TukeyC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TukeyC Conventional Tukey Test Provides tools to perform multiple comparison analyses, based on the well-known Tukey's \"Honestly Significant Difference\" (HSD) test. In models involving interactions, 'TukeyC' stands out from other R packages by implementing intuitive and easy-to-use functions. In addition to accommodating traditional R methods such as lm() and aov(), it has also been extended to objects of the lmer() class, that is, mixed models with fixed effects. For more details see Tukey (1949) <doi:10.2307/3001913>.  "
  },
  {
    "id": 7930,
    "package_name": "VDSM",
    "title": "Visualization of Distribution of Selected Model",
    "description": "Although model selection is ubiquitous in scientific discovery, the stability and uncertainty of the selected model is often hard to evaluate. How to characterize the random behavior of the model selection procedure is the key to understand and quantify the model selection uncertainty. This R package offers several graphical tools to visualize the distribution of the selected model. For example, Gplot(), Hplot(), VDSM_scatterplot() and VDSM_heatmap(). To the best of our knowledge, this is the first attempt to visualize such a distribution. About what distribution of selected model is and how it work please see Qin,Y.and Wang,L. (2021) \"Visualization of Model Selection Uncertainty\" <https://homepages.uc.edu/~qinyn/VDSM/VDSM.html>.",
    "version": "0.1.1",
    "maintainer": "Linna Wang <wang2l9@mail.uc.edu>",
    "author": "Linna Wang [aut, cre],\n  Yichen Qin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VDSM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VDSM Visualization of Distribution of Selected Model Although model selection is ubiquitous in scientific discovery, the stability and uncertainty of the selected model is often hard to evaluate. How to characterize the random behavior of the model selection procedure is the key to understand and quantify the model selection uncertainty. This R package offers several graphical tools to visualize the distribution of the selected model. For example, Gplot(), Hplot(), VDSM_scatterplot() and VDSM_heatmap(). To the best of our knowledge, this is the first attempt to visualize such a distribution. About what distribution of selected model is and how it work please see Qin,Y.and Wang,L. (2021) \"Visualization of Model Selection Uncertainty\" <https://homepages.uc.edu/~qinyn/VDSM/VDSM.html>.  "
  },
  {
    "id": 7938,
    "package_name": "VGAMextra",
    "title": "Additions and Extensions of the 'VGAM' Package",
    "description": "Extending the functionalities of the 'VGAM' package with\n         additional functions and datasets. At present, 'VGAMextra'\n         comprises new family functions (ffs) to estimate several time\n         series models by maximum likelihood using Fisher scoring, \n         unlike popular packages in CRAN relying on optim(), including\n         ARMA-GARCH-like models, the Order-(p, d, q) ARIMAX model (non-\n         seasonal), the Order-(p) VAR model, error correction models\n         for cointegrated time series, and ARMA-structures with Student-t \n         errors. For independent data, new ffs to estimate the inverse-\n         Weibull, the inverse-gamma, the generalized beta of the second\n         kind and the general multivariate normal distributions are\n         available. In addition, 'VGAMextra' incorporates new VGLM-links\n         for the mean-function, and the quantile-function (as an alternative\n         to ordinary quantile modelling) of several 1-parameter distributions,\n         that are compatible with the class of VGLM/VGAM family functions.\n         Currently, only fixed-effects models are implemented. All functions\n         are subject to change; see the NEWS for further details on the\n         latest changes.",
    "version": "0.0-9",
    "maintainer": "Victor Miranda <victor.miranda@aut.ac.nz>",
    "author": "Victor Miranda [aut, cre, cph],\n  Thomas Yee [ctb, ths, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=VGAMextra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "VGAMextra Additions and Extensions of the 'VGAM' Package Extending the functionalities of the 'VGAM' package with\n         additional functions and datasets. At present, 'VGAMextra'\n         comprises new family functions (ffs) to estimate several time\n         series models by maximum likelihood using Fisher scoring, \n         unlike popular packages in CRAN relying on optim(), including\n         ARMA-GARCH-like models, the Order-(p, d, q) ARIMAX model (non-\n         seasonal), the Order-(p) VAR model, error correction models\n         for cointegrated time series, and ARMA-structures with Student-t \n         errors. For independent data, new ffs to estimate the inverse-\n         Weibull, the inverse-gamma, the generalized beta of the second\n         kind and the general multivariate normal distributions are\n         available. In addition, 'VGAMextra' incorporates new VGLM-links\n         for the mean-function, and the quantile-function (as an alternative\n         to ordinary quantile modelling) of several 1-parameter distributions,\n         that are compatible with the class of VGLM/VGAM family functions.\n         Currently, only fixed-effects models are implemented. All functions\n         are subject to change; see the NEWS for further details on the\n         latest changes.  "
  },
  {
    "id": 7977,
    "package_name": "ViSiElse",
    "title": "A Visual Tool for Behavior Analysis over Time",
    "description": "A graphical R package designed to visualize behavioral observations over time. Based on raw time data extracted from video recorded sessions of experimental observations, ViSiElse grants a global overview of a process by combining the visualization of multiple actions timestamps for all participants in a single graph. Individuals and/or group behavior can easily be assessed. Supplementary features allow users to further inspect their data by adding summary statistics (mean, standard deviation, quantile or statistical test) and/or time constraints to assess the accuracy of the realized actions.",
    "version": "1.2.2",
    "maintainer": "Elodie Garnier <e.garnier30@gmail.com>",
    "author": "Nastasia Fouret [aut, cph],\n  Mederic Descoins [aut, cph],\n  Elodie Garnier [aut, cre, cph],\n  CEPOI - EA 7388 [cph]",
    "url": "https://github.com/Re2SimLab/ViSiElse",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ViSiElse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ViSiElse A Visual Tool for Behavior Analysis over Time A graphical R package designed to visualize behavioral observations over time. Based on raw time data extracted from video recorded sessions of experimental observations, ViSiElse grants a global overview of a process by combining the visualization of multiple actions timestamps for all participants in a single graph. Individuals and/or group behavior can easily be assessed. Supplementary features allow users to further inspect their data by adding summary statistics (mean, standard deviation, quantile or statistical test) and/or time constraints to assess the accuracy of the realized actions.  "
  },
  {
    "id": 7996,
    "package_name": "W2CWM2C",
    "title": "A Graphical Tool for Wavelet (Cross) Correlation and Wavelet\nMultiple (Cross) Correlation Analysis",
    "description": "Set of functions that improves the graphical presentations of the functions: wave.correlation and spin.correlation (waveslim package, Whitcher 2012) and the wave.multiple.correlation and wave.multiple.cross.correlation (wavemulcor package, Fernandez-Macho 2012b). The plot outputs (heatmaps) can be displayed in the screen or can be saved as PNG or JPG images or as PDF or EPS formats. The W2CWM2C package also helps to handle the (input data) multivariate time series easily as a list of N elements (times series) and provides a multivariate data set (dataexample) to exemplify its use. A description of the package was published in a scientific paper: Polanco-Martinez and Fernandez-Macho (2014), <doi:10.1109/MCSE.2014.96>. ",
    "version": "2.2",
    "maintainer": "Josue M. Polanco-Martinez <josue.m.polanco@gmail.com>",
    "author": "Josue M. Polanco-Martinez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7164-0185>)",
    "url": "https://github.com/jomopo/W2CWM2C",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=W2CWM2C",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "W2CWM2C A Graphical Tool for Wavelet (Cross) Correlation and Wavelet\nMultiple (Cross) Correlation Analysis Set of functions that improves the graphical presentations of the functions: wave.correlation and spin.correlation (waveslim package, Whitcher 2012) and the wave.multiple.correlation and wave.multiple.cross.correlation (wavemulcor package, Fernandez-Macho 2012b). The plot outputs (heatmaps) can be displayed in the screen or can be saved as PNG or JPG images or as PDF or EPS formats. The W2CWM2C package also helps to handle the (input data) multivariate time series easily as a list of N elements (times series) and provides a multivariate data set (dataexample) to exemplify its use. A description of the package was published in a scientific paper: Polanco-Martinez and Fernandez-Macho (2014), <doi:10.1109/MCSE.2014.96>.   "
  },
  {
    "id": 8048,
    "package_name": "WaverideR",
    "title": "Extracting Signals from Wavelet Spectra",
    "description": "The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.",
    "version": "0.4.1",
    "maintainer": "Michiel Arts <michiel.arts@stratigraphy.eu>",
    "author": "Michiel Arts [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3181-4608>)",
    "url": "https://github.com/stratigraphy/WaverideR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaverideR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaverideR Extracting Signals from Wavelet Spectra The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.  "
  },
  {
    "id": 8055,
    "package_name": "WebGestaltR",
    "title": "Gene Set Analysis Toolkit WebGestaltR",
    "description": "The web version WebGestalt <https://www.webgestalt.org> supports 12 organisms, 354 gene identifiers and 321,251 function categories. Users can upload the data and functional categories with their own gene identifiers. In addition to the Over-Representation Analysis, WebGestalt also supports Gene Set Enrichment Analysis and Network Topology Analysis. The user-friendly output report allows interactive and efficient exploration of enrichment results. The WebGestaltR package not only supports all above functions but also can be integrated into other pipeline or simultaneously analyze multiple gene lists.",
    "version": "0.4.6",
    "maintainer": "Yuxing Liao <yuxingliao@gmail.com>",
    "author": "Jing Wang [aut],\n  Yuxing Liao [aut, cre],\n  Eric Jaehnig [ctb],\n  Zhiao Shi [ctb],\n  Quanhu Sheng [ctb]",
    "url": "https://github.com/bzhanglab/WebGestaltR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WebGestaltR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WebGestaltR Gene Set Analysis Toolkit WebGestaltR The web version WebGestalt <https://www.webgestalt.org> supports 12 organisms, 354 gene identifiers and 321,251 function categories. Users can upload the data and functional categories with their own gene identifiers. In addition to the Over-Representation Analysis, WebGestalt also supports Gene Set Enrichment Analysis and Network Topology Analysis. The user-friendly output report allows interactive and efficient exploration of enrichment results. The WebGestaltR package not only supports all above functions but also can be integrated into other pipeline or simultaneously analyze multiple gene lists.  "
  },
  {
    "id": 8061,
    "package_name": "WeightIt",
    "title": "Weighting for Covariate Balance in Observational Studies",
    "description": "Generates balancing weights for causal effect estimation in observational studies with\n             binary, multi-category, or continuous point or longitudinal treatments by easing and\n             extending the functionality of several R packages and providing in-house estimation methods.\n             Available methods include those that rely on parametric modeling, optimization, and machine learning. Also\n             allows for assessment of weights and checking of covariate balance by interfacing directly\n             with the 'cobalt' package. Methods for estimating weighted regression models that take into account \n             uncertainty in the estimation of the weights via M-estimation or bootstrapping are available. See the vignette \"Installing Supporting Packages\" for instructions on how\n             to install any package 'WeightIt' uses, including those that may not be on CRAN.",
    "version": "1.5.1",
    "maintainer": "Noah Greifer <noah.greifer@gmail.com>",
    "author": "Noah Greifer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3067-7154>)",
    "url": "https://ngreifer.github.io/WeightIt/,\nhttps://github.com/ngreifer/WeightIt",
    "bug_reports": "https://github.com/ngreifer/WeightIt/issues",
    "repository": "https://cran.r-project.org/package=WeightIt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WeightIt Weighting for Covariate Balance in Observational Studies Generates balancing weights for causal effect estimation in observational studies with\n             binary, multi-category, or continuous point or longitudinal treatments by easing and\n             extending the functionality of several R packages and providing in-house estimation methods.\n             Available methods include those that rely on parametric modeling, optimization, and machine learning. Also\n             allows for assessment of weights and checking of covariate balance by interfacing directly\n             with the 'cobalt' package. Methods for estimating weighted regression models that take into account \n             uncertainty in the estimation of the weights via M-estimation or bootstrapping are available. See the vignette \"Installing Supporting Packages\" for instructions on how\n             to install any package 'WeightIt' uses, including those that may not be on CRAN.  "
  },
  {
    "id": 8122,
    "package_name": "Ymisc",
    "title": "Miscellaneous Functions",
    "description": "The Author's personal R Package that contains miscellaneous functions. \n    The current version of package contains miscellaneous functions for brain data \n    to compute Asymmetry Index (AI) and bilateral (L+R) measures and reshape the data.",
    "version": "0.1.0",
    "maintainer": "Yoo Ri Hwang <yrhwang89@gmail.com>",
    "author": "Yoo Ri Hwang [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Ymisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Ymisc Miscellaneous Functions The Author's personal R Package that contains miscellaneous functions. \n    The current version of package contains miscellaneous functions for brain data \n    to compute Asymmetry Index (AI) and bilateral (L+R) measures and reshape the data.  "
  },
  {
    "id": 8139,
    "package_name": "ZeBook",
    "title": "Working with Dynamic Models for Agriculture and Environment",
    "description": "R package accompanying the book Working with dynamic models for agriculture and environment, by Daniel Wallach (INRA), David Makowski (INRA), James W. Jones (U.of Florida), Francois Brun (ACTA). 3rd edition 2018-09-27.",
    "version": "1.1",
    "maintainer": "Francois Brun <francois.brun@acta.asso.fr>",
    "author": "Francois Brun (ACTA), David Makowski (INRA), Daniel Wallach (INRA), James W. Jones (U.of Florida).",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ZeBook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ZeBook Working with Dynamic Models for Agriculture and Environment R package accompanying the book Working with dynamic models for agriculture and environment, by Daniel Wallach (INRA), David Makowski (INRA), James W. Jones (U.of Florida), Francois Brun (ACTA). 3rd edition 2018-09-27.  "
  },
  {
    "id": 8141,
    "package_name": "ZillowR",
    "title": "R Interface to Zillow Real Estate and Mortgage Data API",
    "description": "Zillow, an online real estate company, provides real estate\n    and mortgage data for the United States through a REST API. The\n    ZillowR package provides an R function for each API service, making it\n    easy to make API calls and process the response into convenient,\n    R-friendly data structures.  See\n    <https://www.zillow.com/howto/api/APIOverview.htm> for the Zillow API\n    Documentation. NOTE: Zillow deprecated their API on 2021-09-30, and\n    this package is now deprecated as a result.",
    "version": "1.0.0",
    "maintainer": "Justin Brantley <fascinatingfingers@icloud.com>",
    "author": "Justin Brantley [aut, cre]",
    "url": "https://fascinatingfingers.gitlab.io/zillowr,\nhttps://gitlab.com/fascinatingfingers/zillowr",
    "bug_reports": "https://gitlab.com/fascinatingfingers/zillowr/-/issues",
    "repository": "https://cran.r-project.org/package=ZillowR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ZillowR R Interface to Zillow Real Estate and Mortgage Data API Zillow, an online real estate company, provides real estate\n    and mortgage data for the United States through a REST API. The\n    ZillowR package provides an R function for each API service, making it\n    easy to make API calls and process the response into convenient,\n    R-friendly data structures.  See\n    <https://www.zillow.com/howto/api/APIOverview.htm> for the Zillow API\n    Documentation. NOTE: Zillow deprecated their API on 2021-09-30, and\n    this package is now deprecated as a result.  "
  },
  {
    "id": 8144,
    "package_name": "aIc",
    "title": "Testing for Compositional Pathologies in Datasets",
    "description": "A set of tests for compositional pathologies. Tests for coherence of correlations with aIc.coherent() as suggested by (Erb et al. (2020) <doi:10.1016/j.acags.2020.100026>),  compositional dominance of distance with aIc.dominant(), compositional perturbation invariance with aIc.perturb() as suggested by (Aitchison (1992) <doi:10.1007/BF00891269>) and singularity of the covariation matrix with aIc.singular(). Currently tests five data transformations: prop, clr, TMM, TMMwsp, and RLE from the R packages 'ALDEx2', 'edgeR' and 'DESeq2' (Fernandes et al (2014) <doi:10.1186/2049-2618-2-15>, Anders et al. (2013)<doi:10.1038/nprot.2013.099>).",
    "version": "1.0",
    "maintainer": "Greg Gloor <ggloor@uwo.ca>",
    "author": "Greg Gloor",
    "url": "https://github.com/ggloor/aIc",
    "bug_reports": "https://github.com/ggloor/aIc/issues",
    "repository": "https://cran.r-project.org/package=aIc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aIc Testing for Compositional Pathologies in Datasets A set of tests for compositional pathologies. Tests for coherence of correlations with aIc.coherent() as suggested by (Erb et al. (2020) <doi:10.1016/j.acags.2020.100026>),  compositional dominance of distance with aIc.dominant(), compositional perturbation invariance with aIc.perturb() as suggested by (Aitchison (1992) <doi:10.1007/BF00891269>) and singularity of the covariation matrix with aIc.singular(). Currently tests five data transformations: prop, clr, TMM, TMMwsp, and RLE from the R packages 'ALDEx2', 'edgeR' and 'DESeq2' (Fernandes et al (2014) <doi:10.1186/2049-2618-2-15>, Anders et al. (2013)<doi:10.1038/nprot.2013.099>).  "
  },
  {
    "id": 8148,
    "package_name": "aNCA",
    "title": "(Pre-)Clinical NCA in a Dynamic Shiny App",
    "description": "An interactive 'shiny' application for performing non-compartmental analysis (NCA) on\n  pre-clinical and clinical pharmacokinetic data. The package builds on 'PKNCA' for core estimators and provides interactive visualizations, CDISC\n  outputs ('ADNCA', 'PP', 'ADPP') and configurable TLGs (tables, listings, and graphs). Typical use cases include exploratory\n  analysis, validation, reporting or teaching/demonstration of NCA methods. Methods and core\n  estimators are described in Denney, Duvvuri, and Buckeridge (2015) \"Simple, Automatic\n  Noncompartmental Analysis: The PKNCA R Package\" <doi:10.1007/s10928-015-9432-2>.",
    "version": "0.1.0",
    "maintainer": "Valentin Legras <anca.pharmaverse@gmail.com>",
    "author": "Ercan Suekuer [aut] (ORCID: <https://orcid.org/0009-0001-1626-1526>),\n  Gerardo Jose Rodriguez [aut] (ORCID:\n    <https://orcid.org/0000-0003-1413-0060>),\n  Pascal Baertschi [aut] (ORCID: <https://orcid.org/0000-0002-6533-0399>),\n  Jana Spinner [aut] (ORCID: <https://orcid.org/0009-0009-2197-9530>),\n  Mateusz Kolomanski [aut] (ORCID:\n    <https://orcid.org/0000-0001-7424-3919>),\n  Lucy Aspridis [aut] (ORCID: <https://orcid.org/0009-0003-1300-3622>),\n  Valentin Legras [aut, cre],\n  F. Hoffmann-La Roche AG [cph, fnd]",
    "url": "https://pharmaverse.github.io/aNCA/,\nhttps://github.com/pharmaverse/aNCA",
    "bug_reports": "https://github.com/pharmaverse/aNCA/issues",
    "repository": "https://cran.r-project.org/package=aNCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aNCA (Pre-)Clinical NCA in a Dynamic Shiny App An interactive 'shiny' application for performing non-compartmental analysis (NCA) on\n  pre-clinical and clinical pharmacokinetic data. The package builds on 'PKNCA' for core estimators and provides interactive visualizations, CDISC\n  outputs ('ADNCA', 'PP', 'ADPP') and configurable TLGs (tables, listings, and graphs). Typical use cases include exploratory\n  analysis, validation, reporting or teaching/demonstration of NCA methods. Methods and core\n  estimators are described in Denney, Duvvuri, and Buckeridge (2015) \"Simple, Automatic\n  Noncompartmental Analysis: The PKNCA R Package\" <doi:10.1007/s10928-015-9432-2>.  "
  },
  {
    "id": 8166,
    "package_name": "abdiv",
    "title": "Alpha and Beta Diversity Measures",
    "description": "A collection of measures for measuring ecological diversity.\n  Ecological diversity comes in two flavors: alpha diversity measures the\n  diversity within a single site or sample, and beta diversity measures the\n  diversity across two sites or samples. This package overlaps considerably\n  with other R packages such as 'vegan', 'gUniFrac', 'betapart', and 'fossil'.\n  We also include a wide range of functions that are implemented in software\n  outside the R ecosystem, such as 'scipy', 'Mothur', and 'scikit-bio'.  The\n  implementations here are designed to be basic and clear to the reader.",
    "version": "0.2.0",
    "maintainer": "Kyle Bittinger <kylebittinger@gmail.com>",
    "author": "Kyle Bittinger [aut, cre]",
    "url": "https://github.com/kylebittinger/abdiv",
    "bug_reports": "https://github.com/kylebittinger/abdiv/issues",
    "repository": "https://cran.r-project.org/package=abdiv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "abdiv Alpha and Beta Diversity Measures A collection of measures for measuring ecological diversity.\n  Ecological diversity comes in two flavors: alpha diversity measures the\n  diversity within a single site or sample, and beta diversity measures the\n  diversity across two sites or samples. This package overlaps considerably\n  with other R packages such as 'vegan', 'gUniFrac', 'betapart', and 'fossil'.\n  We also include a wide range of functions that are implemented in software\n  outside the R ecosystem, such as 'scipy', 'Mothur', and 'scikit-bio'.  The\n  implementations here are designed to be basic and clear to the reader.  "
  },
  {
    "id": 8177,
    "package_name": "abn",
    "title": "Modelling Multivariate Data with Additive Bayesian Networks",
    "description": "The 'abn' R package facilitates Bayesian network analysis, a\n    probabilistic graphical model that derives from empirical data a\n    directed acyclic graph (DAG). This DAG describes the dependency\n    structure between random variables. The R package 'abn' provides\n    routines to help determine optimal Bayesian network models for a given\n    data set. These models are used to identify statistical dependencies\n    in messy, complex data. Their additive formulation is equivalent to\n    multivariate generalised linear modelling, including mixed models with\n    independent and identically distributed (iid) random effects. The core\n    functionality of the 'abn' package revolves around model selection,\n    also known as structure discovery. It supports both exact and\n    heuristic structure learning algorithms and does not restrict the data\n    distribution of parent-child combinations, providing flexibility in\n    model creation and analysis. The 'abn' package uses Laplace\n    approximations for metric estimation and includes wrappers to the\n    'INLA' package. It also employs 'JAGS' for data simulation purposes.\n    For more resources and information, visit the 'abn' website.",
    "version": "3.1.12",
    "maintainer": "Matteo Delucchi <matteo.delucchi@math.uzh.ch>",
    "author": "Matteo Delucchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9327-1496>),\n  Reinhard Furrer [aut] (ORCID: <https://orcid.org/0000-0002-6319-2332>),\n  Gilles Kratzer [aut] (ORCID: <https://orcid.org/0000-0002-5929-8935>),\n  Fraser Iain Lewis [aut] (ORCID:\n    <https://orcid.org/0000-0003-4580-2712>),\n  Jonas I. Liechti [ctb] (ORCID: <https://orcid.org/0000-0003-3447-3060>),\n  Marta Pittavino [ctb] (ORCID: <https://orcid.org/0000-0002-1232-1034>),\n  Kalina Cherneva [ctb]",
    "url": "https://r-bayesian-networks.org/,\nhttps://github.com/furrer-lab/abn",
    "bug_reports": "https://github.com/furrer-lab/abn/issues",
    "repository": "https://cran.r-project.org/package=abn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "abn Modelling Multivariate Data with Additive Bayesian Networks The 'abn' R package facilitates Bayesian network analysis, a\n    probabilistic graphical model that derives from empirical data a\n    directed acyclic graph (DAG). This DAG describes the dependency\n    structure between random variables. The R package 'abn' provides\n    routines to help determine optimal Bayesian network models for a given\n    data set. These models are used to identify statistical dependencies\n    in messy, complex data. Their additive formulation is equivalent to\n    multivariate generalised linear modelling, including mixed models with\n    independent and identically distributed (iid) random effects. The core\n    functionality of the 'abn' package revolves around model selection,\n    also known as structure discovery. It supports both exact and\n    heuristic structure learning algorithms and does not restrict the data\n    distribution of parent-child combinations, providing flexibility in\n    model creation and analysis. The 'abn' package uses Laplace\n    approximations for metric estimation and includes wrappers to the\n    'INLA' package. It also employs 'JAGS' for data simulation purposes.\n    For more resources and information, visit the 'abn' website.  "
  },
  {
    "id": 8180,
    "package_name": "abseil",
    "title": "'C++' Header Files from 'Abseil'",
    "description": "Wraps the 'Abseil' 'C++' library for use by R packages.\n    Original files are from <https://github.com/abseil/abseil-cpp>.\n    Patches are located at\n    <https://github.com/doccstat/abseil-r/tree/main/local/patches>.",
    "version": "2023.8.2.1",
    "maintainer": "Xingchi Li <anthony.li@stat.tamu.edu>",
    "author": "Xingchi Li [ctb, cre, cph] (ORCID:\n    <https://orcid.org/0009-0006-2493-0853>),\n  Abseil Team [aut, cph]",
    "url": "https://abseil.xingchi.li, https://github.com/doccstat/abseil-r",
    "bug_reports": "https://github.com/doccstat/abseil-r/issues",
    "repository": "https://cran.r-project.org/package=abseil",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "abseil 'C++' Header Files from 'Abseil' Wraps the 'Abseil' 'C++' library for use by R packages.\n    Original files are from <https://github.com/abseil/abseil-cpp>.\n    Patches are located at\n    <https://github.com/doccstat/abseil-r/tree/main/local/patches>.  "
  },
  {
    "id": 8197,
    "package_name": "accrual",
    "title": "Bayesian Accrual Prediction",
    "description": "Participant recruitment for medical research is challenging. Slow accrual leads to delays in research. Accrual monitoring during the process of recruitment is critical. Researchers need reliable tools to manage the accrual rate. We developed a Bayesian method that integrates the researcher's experience with previous trials and data from the current study, providing reliable predictions on accrual rate for clinical studies. For more details and background on these methodologies, see the publications of Byron, Stephen and Susan (2008) <doi:10.1002/sim.3128>, and Yu et al. (2015) <doi:10.1002/sim.6359>. In this R package, Bayesian accrual prediction functions are presented, which can be easily used by statisticians and clinical researchers.",
    "version": "1.4",
    "maintainer": "Junhao Liu <liujunhao2008@gmail.com>",
    "author": "Junhao Liu [aut, cre] (Maintainer),\n  Yu Jiang [aut] (Original author),\n  Cen Wu [aut],\n  Steve Simon [aut],\n  Matthew S. Mayo [aut],\n  Rama Raghavan [aut],\n  Byron J. Gajewski [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=accrual",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "accrual Bayesian Accrual Prediction Participant recruitment for medical research is challenging. Slow accrual leads to delays in research. Accrual monitoring during the process of recruitment is critical. Researchers need reliable tools to manage the accrual rate. We developed a Bayesian method that integrates the researcher's experience with previous trials and data from the current study, providing reliable predictions on accrual rate for clinical studies. For more details and background on these methodologies, see the publications of Byron, Stephen and Susan (2008) <doi:10.1002/sim.3128>, and Yu et al. (2015) <doi:10.1002/sim.6359>. In this R package, Bayesian accrual prediction functions are presented, which can be easily used by statisticians and clinical researchers.  "
  },
  {
    "id": 8238,
    "package_name": "ada",
    "title": "The R Package Ada for Stochastic Boosting",
    "description": "Performs discrete, real, and gentle boost under both exponential and \n             logistic loss on a given data set.  The package ada provides a straightforward, \n             well-documented, and broad boosting routine for classification, ideally suited \n             for small to moderate-sized data sets.",
    "version": "2.0-5",
    "maintainer": "Mark Culp <mvculp@mail.wvu.edu>",
    "author": "Mark Culp, Kjell Johnson, and George Michailidis",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ada",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ada The R Package Ada for Stochastic Boosting Performs discrete, real, and gentle boost under both exponential and \n             logistic loss on a given data set.  The package ada provides a straightforward, \n             well-documented, and broad boosting routine for classification, ideally suited \n             for small to moderate-sized data sets.  "
  },
  {
    "id": 8243,
    "package_name": "adagio",
    "title": "Discrete and Global Optimization Routines",
    "description": "\n    The R package 'adagio' will provide methods and algorithms for\n    (discrete) optimization, e.g. knapsack and subset sum procedures,\n\tderivative-free Nelder-Mead and Hooke-Jeeves minimization, and\n\tsome (evolutionary) global optimization functions.",
    "version": "0.9.2",
    "maintainer": "Hans W. Borchers <hwborchers@googlemail.com>",
    "author": "Hans W. Borchers [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=adagio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adagio Discrete and Global Optimization Routines \n    The R package 'adagio' will provide methods and algorithms for\n    (discrete) optimization, e.g. knapsack and subset sum procedures,\n\tderivative-free Nelder-Mead and Hooke-Jeeves minimization, and\n\tsome (evolutionary) global optimization functions.  "
  },
  {
    "id": 8246,
    "package_name": "adaplots",
    "title": "Ada-Plot and Uda-Plot for Assessing Distributional Attributes\nand Normality",
    "description": "The centralized empirical cumulative average deviation function is utilized to develop\n             both Ada-plot and Uda-plot as alternatives to Ad-plot and Ud-plot introduced by the author.\n             Analogous to Ad-plot, Ada-plot can identify symmetry, skewness, and outliers of the data\n             distribution. The Uda-plot is as exceptional as Ud-plot in assessing normality. The d-value \n             that quantifies the degree of proximity between the Uda-plot and the graph of the estimated \n             normal density function helps guide to make decisions on confirmation of normality. Extreme \n             values in the data can be eliminated using the 1.5IQR rule to create its robust version if user\n             demands. Full description of the methodology can be found in the article by Wijesuriya (2025a)\n             <doi:10.1080/03610926.2025.2558108>. Further, the development of Ad-plot and Ud-plot is \n             contained in both article and the 'adplots' R package by Wijesuriya (2025b & 2025c) \n             <doi:10.1080/03610926.2024.2440583> and <doi:10.32614/CRAN.package.adplots>.",
    "version": "0.1.0",
    "maintainer": "Uditha Amarananda Wijesuriya <u.wijesuriya@usi.edu>",
    "author": "Uditha Amarananda Wijesuriya [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=adaplots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adaplots Ada-Plot and Uda-Plot for Assessing Distributional Attributes\nand Normality The centralized empirical cumulative average deviation function is utilized to develop\n             both Ada-plot and Uda-plot as alternatives to Ad-plot and Ud-plot introduced by the author.\n             Analogous to Ad-plot, Ada-plot can identify symmetry, skewness, and outliers of the data\n             distribution. The Uda-plot is as exceptional as Ud-plot in assessing normality. The d-value \n             that quantifies the degree of proximity between the Uda-plot and the graph of the estimated \n             normal density function helps guide to make decisions on confirmation of normality. Extreme \n             values in the data can be eliminated using the 1.5IQR rule to create its robust version if user\n             demands. Full description of the methodology can be found in the article by Wijesuriya (2025a)\n             <doi:10.1080/03610926.2025.2558108>. Further, the development of Ad-plot and Ud-plot is \n             contained in both article and the 'adplots' R package by Wijesuriya (2025b & 2025c) \n             <doi:10.1080/03610926.2024.2440583> and <doi:10.32614/CRAN.package.adplots>.  "
  },
  {
    "id": 8257,
    "package_name": "adaptr",
    "title": "Adaptive Trial Simulator",
    "description": "Package that simulates adaptive (multi-arm, multi-stage) clinical\n    trials using adaptive stopping, adaptive arm dropping, and/or adaptive\n    randomisation. Developed as part of the INCEPT (Intensive Care Platform\n    Trial) project (<https://incept.dk/>), primarily supported by a grant\n    from Sygeforsikringen \"danmark\" (<https://www.sygeforsikring.dk/>).",
    "version": "1.4.0",
    "maintainer": "Anders Granholm <andersgran@gmail.com>",
    "author": "Anders Granholm [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5799-7655>),\n  Benjamin Skov Kaas-Hansen [aut] (ORCID:\n    <https://orcid.org/0000-0003-1023-0371>),\n  Aksel Karl Georg Jensen [ctb] (ORCID:\n    <https://orcid.org/0000-0002-1459-0465>),\n  Theis Lange [ctb] (ORCID: <https://orcid.org/0000-0001-6807-8347>)",
    "url": "https://inceptdk.github.io/adaptr/,\nhttps://github.com/INCEPTdk/adaptr/, https://incept.dk/",
    "bug_reports": "https://github.com/INCEPTdk/adaptr/issues/",
    "repository": "https://cran.r-project.org/package=adaptr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adaptr Adaptive Trial Simulator Package that simulates adaptive (multi-arm, multi-stage) clinical\n    trials using adaptive stopping, adaptive arm dropping, and/or adaptive\n    randomisation. Developed as part of the INCEPT (Intensive Care Platform\n    Trial) project (<https://incept.dk/>), primarily supported by a grant\n    from Sygeforsikringen \"danmark\" (<https://www.sygeforsikring.dk/>).  "
  },
  {
    "id": 8284,
    "package_name": "adelie",
    "title": "Group Lasso and Elastic Net Solver for Generalized Linear Models",
    "description": "Extremely efficient procedures for fitting the entire group lasso and group elastic net regularization path for GLMs, multinomial, the Cox model and multi-task Gaussian models. Similar to the R package 'glmnet' in scope of models, and in computational speed.  This package provides  R bindings to the C++ code underlying the corresponding Python package 'adelie'. These bindings offer a general purpose group elastic net solver, \n    a wide range of matrix classes that can exploit special structure \n    to allow large-scale inputs, and an assortment of \n    generalized linear model classes for fitting various types of data. \n    The package is an implementation of Yang, J. and Hastie, T. (2024) <doi:10.48550/arXiv.2405.08631>.",
    "version": "1.0.8",
    "maintainer": "Trevor Hastie <hastie@stanford.edu>",
    "author": "James Yang [aut, cph],\n  Trevor Hastie [aut, cph, cre],\n  Balasubramanian Narasimhan [aut]",
    "url": "https://github.com/JamesYang007/adelie-r",
    "bug_reports": "https://github.com/JamesYang007/adelie-r/issues",
    "repository": "https://cran.r-project.org/package=adelie",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adelie Group Lasso and Elastic Net Solver for Generalized Linear Models Extremely efficient procedures for fitting the entire group lasso and group elastic net regularization path for GLMs, multinomial, the Cox model and multi-task Gaussian models. Similar to the R package 'glmnet' in scope of models, and in computational speed.  This package provides  R bindings to the C++ code underlying the corresponding Python package 'adelie'. These bindings offer a general purpose group elastic net solver, \n    a wide range of matrix classes that can exploit special structure \n    to allow large-scale inputs, and an assortment of \n    generalized linear model classes for fitting various types of data. \n    The package is an implementation of Yang, J. and Hastie, T. (2024) <doi:10.48550/arXiv.2405.08631>.  "
  },
  {
    "id": 8327,
    "package_name": "adsoRptionMCMC",
    "title": "Bayesian Estimation of Adsorption Isotherms via MCMC",
    "description": "\n  Provides tools for Bayesian parameter estimation of adsorption isotherm models using Markov Chain Monte Carlo (MCMC) methods. \n  This package enables users to fit non-linear and linear adsorption isotherm models\u2014Freundlich, Langmuir, and Temkin\u2014within a \n  probabilistic framework, capturing uncertainty and parameter correlations. It provides posterior summaries, 95% credible intervals, \n  convergence diagnostics (Gelman-Rubin), and visualizations through trace and density plots. With this R package, researchers can \n  rigorously analyze adsorption behavior in environmental and chemical systems using robust Bayesian inference. For more details, \n  see Gilks et al. (1995) <doi:10.1201/b14835>, and Gamerman & Lopes (2006) <doi:10.1201/9781482296426>.",
    "version": "0.1.0",
    "maintainer": "Paul Angelo C. Manlapaz <pacmanlapaz@gmail.com>",
    "author": "Paul Angelo C. Manlapaz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1203-2064>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=adsoRptionMCMC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adsoRptionMCMC Bayesian Estimation of Adsorption Isotherms via MCMC \n  Provides tools for Bayesian parameter estimation of adsorption isotherm models using Markov Chain Monte Carlo (MCMC) methods. \n  This package enables users to fit non-linear and linear adsorption isotherm models\u2014Freundlich, Langmuir, and Temkin\u2014within a \n  probabilistic framework, capturing uncertainty and parameter correlations. It provides posterior summaries, 95% credible intervals, \n  convergence diagnostics (Gelman-Rubin), and visualizations through trace and density plots. With this R package, researchers can \n  rigorously analyze adsorption behavior in environmental and chemical systems using robust Bayesian inference. For more details, \n  see Gilks et al. (1995) <doi:10.1201/b14835>, and Gamerman & Lopes (2006) <doi:10.1201/9781482296426>.  "
  },
  {
    "id": 8354,
    "package_name": "afttest",
    "title": "Model Diagnostics for Accelerated Failure Time Models",
    "description": "A collection of model checking methods for semiparametric \n    accelerated failure time (AFT) models under the rank-based approach. For the \n    (computational) efficiency, Gehan's weight is used. It provides functions to \n    verify whether the observed data fit the specific model assumptions such as \n    a functional form of each covariate, a link function, and an omnibus test. \n    The p-value offered in this package is based on the Kolmogorov-type supremum \n    test and the variance of the proposed test statistics is estimated through \n    the re-sampling method. Furthermore, a graphical technique to compare the \n    shape of the observed residual to a number of the approximated realizations \n    is provided. See the following references; A general model-checking \n    procedure for semiparametric accelerated failure time models, Statistics and \n    Computing, 34 (3), 117 <doi:10.1007/s11222-024-10431-7>; Diagnostics for \n    semiparametric accelerated failure time models with R package 'afttest', \n    arXiv, <doi:10.48550/arXiv.2511.09823>.",
    "version": "4.5.1",
    "maintainer": "Woojung Bae <matt.woojung@gmail.com>",
    "author": "Woojung Bae [aut, cre] (ORCID: <https://orcid.org/0000-0001-6760-9900>),\n  Dongrak Choi [aut] (ORCID: <https://orcid.org/0000-0003-3280-3329>),\n  Jun Yan [aut] (ORCID: <https://orcid.org/0000-0003-4401-7296>),\n  Sangwook Kang [aut] (ORCID: <https://orcid.org/0000-0003-2658-481X>)",
    "url": "https://github.com/WooJungBae/afttest",
    "bug_reports": "https://github.com/WooJungBae/afttest/issues",
    "repository": "https://cran.r-project.org/package=afttest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "afttest Model Diagnostics for Accelerated Failure Time Models A collection of model checking methods for semiparametric \n    accelerated failure time (AFT) models under the rank-based approach. For the \n    (computational) efficiency, Gehan's weight is used. It provides functions to \n    verify whether the observed data fit the specific model assumptions such as \n    a functional form of each covariate, a link function, and an omnibus test. \n    The p-value offered in this package is based on the Kolmogorov-type supremum \n    test and the variance of the proposed test statistics is estimated through \n    the re-sampling method. Furthermore, a graphical technique to compare the \n    shape of the observed residual to a number of the approximated realizations \n    is provided. See the following references; A general model-checking \n    procedure for semiparametric accelerated failure time models, Statistics and \n    Computing, 34 (3), 117 <doi:10.1007/s11222-024-10431-7>; Diagnostics for \n    semiparametric accelerated failure time models with R package 'afttest', \n    arXiv, <doi:10.48550/arXiv.2511.09823>.  "
  },
  {
    "id": 8373,
    "package_name": "agricolaeplotr",
    "title": "Visualization of Design of Experiments from the 'agricolae'\nPackage",
    "description": "Visualization of Design of Experiments from the 'agricolae' package with 'ggplot2' framework\n    The user provides an experiment design from the 'agricolae' package, calls the corresponding function and will receive a \n    visualization with 'ggplot2' based functions that are specific for each design. As there are many different designs, each design is tested on its type.\n    The output can be modified with standard 'ggplot2' commands or with other packages with 'ggplot2' function extensions.",
    "version": "0.6.1",
    "maintainer": "Jens Harbers <jensharbers@gmail.com>",
    "author": "Jens Harbers [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6634-623X>)",
    "url": "https://github.com/jensharbers/agricolaeplotr",
    "bug_reports": "https://github.com/jensharbers/agricolaeplotr/issues",
    "repository": "https://cran.r-project.org/package=agricolaeplotr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "agricolaeplotr Visualization of Design of Experiments from the 'agricolae'\nPackage Visualization of Design of Experiments from the 'agricolae' package with 'ggplot2' framework\n    The user provides an experiment design from the 'agricolae' package, calls the corresponding function and will receive a \n    visualization with 'ggplot2' based functions that are specific for each design. As there are many different designs, each design is tested on its type.\n    The output can be modified with standard 'ggplot2' commands or with other packages with 'ggplot2' function extensions.  "
  },
  {
    "id": 8376,
    "package_name": "agriutilities",
    "title": "Utilities for Data Analysis in Agriculture",
    "description": "Utilities designed to make the analysis of field trials easier and\n more accessible for everyone working in plant breeding. It provides a simple\n and intuitive interface for conducting single and multi-environmental trial\n analysis, with minimal coding required. Whether you're a beginner or an\n experienced user, 'agriutilities' will help you quickly and easily carry out\n complex analyses with confidence. With built-in functions for fitting Linear\n Mixed Models, 'agriutilities' is the ideal choice for anyone who wants to save\n time and focus on interpreting their results.\n Some of the functions require the R package 'asreml' for the 'ASReml' software,\n this can be obtained upon purchase from 'VSN' international <https://vsni.co.uk/software/asreml-r/>.",
    "version": "1.2.2",
    "maintainer": "Johan Aparicio <johanstevenapa@gmail.com>",
    "author": "Johan Aparicio [aut, cre],\n  Alexia Bornhorst [aut],\n  The Alliance of Bioversity International and CIAT [cph]",
    "url": "https://github.com/AparicioJohan/agriutilities,\nhttps://apariciojohan.github.io/agriutilities/",
    "bug_reports": "https://github.com/AparicioJohan/agriutilities/issues",
    "repository": "https://cran.r-project.org/package=agriutilities",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "agriutilities Utilities for Data Analysis in Agriculture Utilities designed to make the analysis of field trials easier and\n more accessible for everyone working in plant breeding. It provides a simple\n and intuitive interface for conducting single and multi-environmental trial\n analysis, with minimal coding required. Whether you're a beginner or an\n experienced user, 'agriutilities' will help you quickly and easily carry out\n complex analyses with confidence. With built-in functions for fitting Linear\n Mixed Models, 'agriutilities' is the ideal choice for anyone who wants to save\n time and focus on interpreting their results.\n Some of the functions require the R package 'asreml' for the 'ASReml' software,\n this can be obtained upon purchase from 'VSN' international <https://vsni.co.uk/software/asreml-r/>.  "
  },
  {
    "id": 8456,
    "package_name": "altadata",
    "title": "API Wrapper for Altadata.io",
    "description": "Functions for interacting directly with the 'ALTADATA' API. With this R package, developers can build applications around the 'ALTADATA' API without having to deal with accessing and managing requests and responses. 'ALTADATA' is a curated data marketplace for more information go to <https://www.altadata.io>.",
    "version": "0.1.1",
    "maintainer": "Emre Durukan <emredurukan@altadata.io>",
    "author": "Emre Durukan [aut, cre],\n  ALTADATA Inc. [cph]",
    "url": "https://github.com/altabering/altadata-r",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=altadata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "altadata API Wrapper for Altadata.io Functions for interacting directly with the 'ALTADATA' API. With this R package, developers can build applications around the 'ALTADATA' API without having to deal with accessing and managing requests and responses. 'ALTADATA' is a curated data marketplace for more information go to <https://www.altadata.io>.  "
  },
  {
    "id": 8458,
    "package_name": "altdoc",
    "title": "Package Documentation Websites with 'Quarto', 'Docsify',\n'Docute', or 'MkDocs'",
    "description": "This is a simple and powerful package to create, render, preview,\n    and deploy documentation websites for 'R' packages. It is a lightweight and\n    flexible alternative to 'pkgdown', with support for many documentation\n    generators, including 'Quarto', 'Docute', 'Docsify', and 'MkDocs'.",
    "version": "0.7.0",
    "maintainer": "Etienne Bacher <etienne.bacher@protonmail.com>",
    "author": "Etienne Bacher [aut, cre, cph],\n  Vincent Arel-Bundock [aut] (ORCID:\n    <https://orcid.org/0000-0003-2042-7063>)",
    "url": "https://altdoc.etiennebacher.com,\nhttps://github.com/etiennebacher/altdoc",
    "bug_reports": "https://github.com/etiennebacher/altdoc/issues",
    "repository": "https://cran.r-project.org/package=altdoc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "altdoc Package Documentation Websites with 'Quarto', 'Docsify',\n'Docute', or 'MkDocs' This is a simple and powerful package to create, render, preview,\n    and deploy documentation websites for 'R' packages. It is a lightweight and\n    flexible alternative to 'pkgdown', with support for many documentation\n    generators, including 'Quarto', 'Docute', 'Docsify', and 'MkDocs'.  "
  },
  {
    "id": 8485,
    "package_name": "amregtest",
    "title": "Runs Allelematch Regression Tests",
    "description": "Automates regression testing of package 'allelematch'. Over\n    2500 tests covers all functions in 'allelematch', reproduces the\n    examples from the documentation and includes negative tests. The\n    implementation is based on 'testthat'.",
    "version": "1.0.5",
    "maintainer": "Torvald Staxler <torvald.staxler@telia.com>",
    "author": "Department of Wildlife, Fish and Environmental Studies at Swedish\n    University of Agricultural Sciences [cph],\n  G\u00f6ran Spong [cph] (Senior Lecturer at the Department of Wildlife, Fish\n    and Environmental Studies),\n  Paul Galpern [ctb] (Author of the excellent package 'allelematch' from\n    which the five amExample data files have been copied under MIT\n    license),\n  Torvald Staxler [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=amregtest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "amregtest Runs Allelematch Regression Tests Automates regression testing of package 'allelematch'. Over\n    2500 tests covers all functions in 'allelematch', reproduces the\n    examples from the documentation and includes negative tests. The\n    implementation is based on 'testthat'.  "
  },
  {
    "id": 8527,
    "package_name": "anticlust",
    "title": "Subset Partitioning via Anticlustering",
    "description": "The method of anticlustering partitions a pool of elements into groups (i.e., anticlusters) with the goal of maximizing between-group similarity or within-group heterogeneity. The anticlustering approach thereby reverses the logic of cluster analysis that strives for high within-group homogeneity and clear separation between groups.  Computationally, anticlustering is accomplished by maximizing instead of minimizing a clustering objective function, such as the intra-cluster variance (used in k-means clustering) or the sum of pairwise distances within clusters. The main function anticlustering() gives access to optimal and heuristic anticlustering methods described in Papenberg and Klau (2021; <doi:10.1037/met0000301>), Brusco et al. (2020; <doi:10.1111/bmsp.12186>), Papenberg (2024;  <doi:10.1111/bmsp.12315>), Papenberg, Wang, et al. (2025; <doi:10.1016/j.crmeth.2025.101137>), Papenberg, Breuer, et al. (2025; <doi:10.1017/psy.2025.10052>), and Yang et al. (2022; <doi:10.1016/j.ejor.2022.02.003>). The optimal algorithms require that an integer linear programming solver is installed. This package will install 'lpSolve' (<https://cran.r-project.org/package=lpSolve>) as a default solver, but it is also possible to use the package 'Rglpk' (<https://cran.r-project.org/package=Rglpk>), which requires the GNU linear programming kit (<https://www.gnu.org/software/glpk/glpk.html>), the package 'Rsymphony' (<https://cran.r-project.org/package=Rsymphony>), which requires the SYMPHONY ILP solver (<https://github.com/coin-or/SYMPHONY>), or the commercial solver Gurobi, which provides its own R package that is not available via CRAN (<https://www.gurobi.com/downloads/>). 'Rglpk', 'Rsymphony', 'gurobi' and their system dependencies have to be manually installed by the user because they are only suggested dependencies. Full access to the bicriterion anticlustering method proposed by Brusco et al. (2020) is given via the function bicriterion_anticlustering(), while kplus_anticlustering() implements the full functionality of the k-plus anticlustering approach proposed by Papenberg (2024). Some other functions are available to solve classical clustering problems. The function balanced_clustering() applies a cluster analysis under size constraints, i.e., creates equal-sized clusters. The function matching() can be used for (unrestricted, bipartite, or K-partite) matching. The function wce() can be used optimally solve the (weighted) cluster editing problem, also known as correlation clustering, clique partitioning problem or transitivity clustering.",
    "version": "0.8.13",
    "maintainer": "Martin Papenberg <martin.papenberg@hhu.de>",
    "author": "Martin Papenberg [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9900-4268>),\n  Meik Michalke [ctb] (centroid based clustering algorithm),\n  Gunnar W. Klau [ths],\n  Juliane V. Nagel [ctb] (package logo),\n  Martin Breuer [ctb] (Bicriterion algorithm by Brusco et al.),\n  Marie L. Schaper [ctb] (Example data set),\n  Max Diekhoff [ctb] (Optimal maximum dispersion algorithm),\n  Hannah Hengelbrock [ctb] (TPSDP heuristic by Yang et al.)",
    "url": "https://github.com/m-Py/anticlust,\nhttps://m-py.github.io/anticlust/",
    "bug_reports": "https://github.com/m-Py/anticlust/issues",
    "repository": "https://cran.r-project.org/package=anticlust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "anticlust Subset Partitioning via Anticlustering The method of anticlustering partitions a pool of elements into groups (i.e., anticlusters) with the goal of maximizing between-group similarity or within-group heterogeneity. The anticlustering approach thereby reverses the logic of cluster analysis that strives for high within-group homogeneity and clear separation between groups.  Computationally, anticlustering is accomplished by maximizing instead of minimizing a clustering objective function, such as the intra-cluster variance (used in k-means clustering) or the sum of pairwise distances within clusters. The main function anticlustering() gives access to optimal and heuristic anticlustering methods described in Papenberg and Klau (2021; <doi:10.1037/met0000301>), Brusco et al. (2020; <doi:10.1111/bmsp.12186>), Papenberg (2024;  <doi:10.1111/bmsp.12315>), Papenberg, Wang, et al. (2025; <doi:10.1016/j.crmeth.2025.101137>), Papenberg, Breuer, et al. (2025; <doi:10.1017/psy.2025.10052>), and Yang et al. (2022; <doi:10.1016/j.ejor.2022.02.003>). The optimal algorithms require that an integer linear programming solver is installed. This package will install 'lpSolve' (<https://cran.r-project.org/package=lpSolve>) as a default solver, but it is also possible to use the package 'Rglpk' (<https://cran.r-project.org/package=Rglpk>), which requires the GNU linear programming kit (<https://www.gnu.org/software/glpk/glpk.html>), the package 'Rsymphony' (<https://cran.r-project.org/package=Rsymphony>), which requires the SYMPHONY ILP solver (<https://github.com/coin-or/SYMPHONY>), or the commercial solver Gurobi, which provides its own R package that is not available via CRAN (<https://www.gurobi.com/downloads/>). 'Rglpk', 'Rsymphony', 'gurobi' and their system dependencies have to be manually installed by the user because they are only suggested dependencies. Full access to the bicriterion anticlustering method proposed by Brusco et al. (2020) is given via the function bicriterion_anticlustering(), while kplus_anticlustering() implements the full functionality of the k-plus anticlustering approach proposed by Papenberg (2024). Some other functions are available to solve classical clustering problems. The function balanced_clustering() applies a cluster analysis under size constraints, i.e., creates equal-sized clusters. The function matching() can be used for (unrestricted, bipartite, or K-partite) matching. The function wce() can be used optimally solve the (weighted) cluster editing problem, also known as correlation clustering, clique partitioning problem or transitivity clustering.  "
  },
  {
    "id": 8571,
    "package_name": "approxOT",
    "title": "Approximate and Exact Optimal Transport Methods",
    "description": "R and C++ functions to perform exact and \n  approximate optimal transport. All C++ methods can be linked \n  to other R packages via their header files. ",
    "version": "1.2",
    "maintainer": "Eric Dunipace <edunipace@mail.harvard.edu>",
    "author": "Eric Dunipace [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8909-213X>),\n  Andrew Johnson [ctb] (ORCID: <https://orcid.org/0000-0001-7000-8065>),\n  Espen Bernton [ctb] ('Hilbert Sort' adapted from their code),\n  Mathieu Gerber [ctb] ('Hilbert Sort' adapted from their code),\n  Pierre Jacob [ctb] ('Hilbert Sort' adapted from their code),\n  Dominic Schuhmacher [ctb] ('Shortsimplex' optimal transport method\n    adapted from their code),\n  Nicolas Bonneel [ctb] ('network simplex' algorithm adapted from their\n    code)",
    "url": "https://github.com/ericdunipace/approxOT",
    "bug_reports": "https://github.com/ericdunipace/approxOT/issues",
    "repository": "https://cran.r-project.org/package=approxOT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "approxOT Approximate and Exact Optimal Transport Methods R and C++ functions to perform exact and \n  approximate optimal transport. All C++ methods can be linked \n  to other R packages via their header files.   "
  },
  {
    "id": 8582,
    "package_name": "aqp",
    "title": "Algorithms for Quantitative Pedology",
    "description": "The Algorithms for Quantitative Pedology (AQP) project was started in 2009 to organize a loosely-related set of concepts and source code on the topic of soil profile visualization, aggregation, and classification into this package (aqp). Over the past 8 years, the project has grown into a suite of related R packages that enhance and simplify the quantitative analysis of soil profile data. Central to the AQP project is a new vocabulary of specialized functions and data structures that can accommodate the inherent complexity of soil profile information; freeing the scientist to focus on ideas rather than boilerplate data processing tasks <doi:10.1016/j.cageo.2012.10.020>. These functions and data structures have been extensively tested and documented, applied to projects involving hundreds of thousands of soil profiles, and deeply integrated into widely used tools such as SoilWeb <https://casoilresource.lawr.ucdavis.edu/soilweb-apps>. Components of the AQP project (aqp, soilDB, sharpshootR, soilReports packages) serve an important role in routine data analysis within the USDA-NRCS Soil Science Division. The AQP suite of R packages offer a convenient platform for bridging the gap between pedometric theory and practice.",
    "version": "2.2-1",
    "maintainer": "Dylan Beaudette <dylan.beaudette@usda.gov>",
    "author": "Dylan Beaudette [aut, cre],\n  Pierre Roudier [aut, ctb],\n  Andrew Brown [aut, ctb]",
    "url": "https://ncss-tech.github.io/aqp/, https://ncss-tech.github.io/AQP/",
    "bug_reports": "https://github.com/ncss-tech/aqp/issues",
    "repository": "https://cran.r-project.org/package=aqp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aqp Algorithms for Quantitative Pedology The Algorithms for Quantitative Pedology (AQP) project was started in 2009 to organize a loosely-related set of concepts and source code on the topic of soil profile visualization, aggregation, and classification into this package (aqp). Over the past 8 years, the project has grown into a suite of related R packages that enhance and simplify the quantitative analysis of soil profile data. Central to the AQP project is a new vocabulary of specialized functions and data structures that can accommodate the inherent complexity of soil profile information; freeing the scientist to focus on ideas rather than boilerplate data processing tasks <doi:10.1016/j.cageo.2012.10.020>. These functions and data structures have been extensively tested and documented, applied to projects involving hundreds of thousands of soil profiles, and deeply integrated into widely used tools such as SoilWeb <https://casoilresource.lawr.ucdavis.edu/soilweb-apps>. Components of the AQP project (aqp, soilDB, sharpshootR, soilReports packages) serve an important role in routine data analysis within the USDA-NRCS Soil Science Division. The AQP suite of R packages offer a convenient platform for bridging the gap between pedometric theory and practice.  "
  },
  {
    "id": 8595,
    "package_name": "arcgisutils",
    "title": "R-ArcGIS Bridge Utility Functions",
    "description": "Developer oriented utility functions designed to be used as\n    the building blocks of R packages that work with ArcGIS Location\n    Services. It provides functionality for authorization, Esri JSON\n    construction and parsing, as well as other utilities pertaining to\n    geometry and Esri type conversions. To support 'ArcGIS Pro' users,\n    authorization can be done via 'arcgisbinding'. Installation\n    instructions for 'arcgisbinding' can be found at\n    <https://developers.arcgis.com/r-bridge/installation/>.",
    "version": "0.4.0",
    "maintainer": "Josiah Parry <josiah.parry@gmail.com>",
    "author": "Josiah Parry [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9910-865X>),\n  Kenneth Vernon [ctb] (ORCID: <https://orcid.org/0000-0003-0098-5092>),\n  Martha Bass [ctb] (ORCID: <https://orcid.org/0009-0004-0268-5426>),\n  Eli Pousson [ctb] (ORCID: <https://orcid.org/0000-0001-8280-1706>)",
    "url": "https://github.com/R-ArcGIS/arcgisutils,\nhttps://developers.arcgis.com/r-bridge/api-reference/arcgisutils/",
    "bug_reports": "https://github.com/R-ArcGIS/arcgisutils/issues",
    "repository": "https://cran.r-project.org/package=arcgisutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arcgisutils R-ArcGIS Bridge Utility Functions Developer oriented utility functions designed to be used as\n    the building blocks of R packages that work with ArcGIS Location\n    Services. It provides functionality for authorization, Esri JSON\n    construction and parsing, as well as other utilities pertaining to\n    geometry and Esri type conversions. To support 'ArcGIS Pro' users,\n    authorization can be done via 'arcgisbinding'. Installation\n    instructions for 'arcgisbinding' can be found at\n    <https://developers.arcgis.com/r-bridge/installation/>.  "
  },
  {
    "id": 8598,
    "package_name": "archeofrag",
    "title": "Spatial Analysis in Archaeology from Refitting Fragments",
    "description": "Methods to analyse spatial units in archaeology from the relationships between refitting fragmented objects scattered in these units (e.g. stratigraphic layers). Graphs are used to model archaeological observations. The package is mainly based on the 'igraph' package for graph analysis. Functions can: 1) create, manipulate, visualise, and simulate fragmentation graphs, 2) measure the cohesion and admixture of archaeological spatial units, and 3) characterise the topology of a specific set of refitting relationships. A series of published empirical datasets is included. Documentation about 'archeofrag' is provided by a vignette and by the accompanying scientific papers: Plutniak (2021, Journal of Archaeological Science, <doi:10.1016/j.jas.2021.105501>) and Plutniak (2022, Journal of Open Source Software, <doi:10.21105/joss.04335>). This package is complemented by the 'archeofrag.gui' R package, a companion GUI application available at <https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/>.",
    "version": "1.2.3",
    "maintainer": "Sebastien Plutniak <sebastien.plutniak@posteo.net>",
    "author": "Sebastien Plutniak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6674-3806>)",
    "url": "https://github.com/sebastien-plutniak/archeofrag",
    "bug_reports": "https://github.com/sebastien-plutniak/archeofrag/issues",
    "repository": "https://cran.r-project.org/package=archeofrag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "archeofrag Spatial Analysis in Archaeology from Refitting Fragments Methods to analyse spatial units in archaeology from the relationships between refitting fragmented objects scattered in these units (e.g. stratigraphic layers). Graphs are used to model archaeological observations. The package is mainly based on the 'igraph' package for graph analysis. Functions can: 1) create, manipulate, visualise, and simulate fragmentation graphs, 2) measure the cohesion and admixture of archaeological spatial units, and 3) characterise the topology of a specific set of refitting relationships. A series of published empirical datasets is included. Documentation about 'archeofrag' is provided by a vignette and by the accompanying scientific papers: Plutniak (2021, Journal of Archaeological Science, <doi:10.1016/j.jas.2021.105501>) and Plutniak (2022, Journal of Open Source Software, <doi:10.21105/joss.04335>). This package is complemented by the 'archeofrag.gui' R package, a companion GUI application available at <https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/>.  "
  },
  {
    "id": 8603,
    "package_name": "archiDART",
    "title": "Plant Root System Architecture Analysis Using DART and RSML\nFiles",
    "description": "Analysis of complex plant root system architectures (RSA) using the output files created by Data Analysis of Root Tracings (DART), an open-access software dedicated to the study of plant root architecture and development across time series (Le Bot et al (2010) \"DART: a software to analyse root system architecture and development from captured images\", Plant and Soil, <DOI:10.1007/s11104-009-0005-2>), and RSA data encoded with the Root System Markup Language (RSML) (Lobet et al (2015) \"Root System Markup Language: toward a unified root architecture description language\", Plant Physiology, <DOI:10.1104/pp.114.253625>). More information can be found in Delory et al (2016) \"archiDART: an R package for the automated computation of plant root architectural traits\", Plant and Soil, <DOI:10.1007/s11104-015-2673-4>.",
    "version": "3.4",
    "maintainer": "Benjamin M Delory <Benjamin.Delory@leuphana.de>",
    "author": "Benjamin M Delory, Caroline Baudson, Yves Brostaux, Guillaume Lobet, Patrick du Jardin, Loic Pages, Pierre Delaplace ",
    "url": "https://archidart.github.io/",
    "bug_reports": "https://github.com/archiDART/archidart/issues",
    "repository": "https://cran.r-project.org/package=archiDART",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "archiDART Plant Root System Architecture Analysis Using DART and RSML\nFiles Analysis of complex plant root system architectures (RSA) using the output files created by Data Analysis of Root Tracings (DART), an open-access software dedicated to the study of plant root architecture and development across time series (Le Bot et al (2010) \"DART: a software to analyse root system architecture and development from captured images\", Plant and Soil, <DOI:10.1007/s11104-009-0005-2>), and RSA data encoded with the Root System Markup Language (RSML) (Lobet et al (2015) \"Root System Markup Language: toward a unified root architecture description language\", Plant Physiology, <DOI:10.1104/pp.114.253625>). More information can be found in Delory et al (2016) \"archiDART: an R package for the automated computation of plant root architectural traits\", Plant and Soil, <DOI:10.1007/s11104-015-2673-4>.  "
  },
  {
    "id": 8619,
    "package_name": "arfima",
    "title": "Fractional ARIMA (and Other Long Memory) Time Series Modeling",
    "description": "Simulates, fits, and predicts long-memory and anti-persistent\n\ttime series, possibly mixed with ARMA, regression, transfer-function\n\tcomponents.\n\tExact methods (MLE, forecasting, simulation) are used.\n\tBug reports should be done via GitHub (at\n\t<https://github.com/JQVeenstra/arfima>), where the development version\n\tof this package lives; it can be installed using devtools.",
    "version": "1.8-2",
    "maintainer": "JQ Veenstra <jqveenstra@gmail.com>",
    "author": "JQ Veenstra [aut, cre] (Justin),\n  A.I. McLeod [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=arfima",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arfima Fractional ARIMA (and Other Long Memory) Time Series Modeling Simulates, fits, and predicts long-memory and anti-persistent\n\ttime series, possibly mixed with ARMA, regression, transfer-function\n\tcomponents.\n\tExact methods (MLE, forecasting, simulation) are used.\n\tBug reports should be done via GitHub (at\n\t<https://github.com/JQVeenstra/arfima>), where the development version\n\tof this package lives; it can be installed using devtools.  "
  },
  {
    "id": 8639,
    "package_name": "aroma.apd",
    "title": "A Probe-Level Data File Format Used by 'aroma.affymetrix'\n[deprecated]",
    "description": "DEPRECATED. Do not start building new projects based on this package. (The (in-house) APD file format was initially developed to store Affymetrix probe-level data, e.g. normalized CEL intensities.  Chip types can be added to APD file and similar to methods in the affxparser package, this package provides methods to read APDs organized by units (probesets).  In addition, the probe elements can be arranged optimally such that the elements are guaranteed to be read in order when, for instance, data is read unit by unit.  This speeds up the read substantially.  This package is supporting the Aroma framework and should not be used elsewhere.)",
    "version": "0.7.1",
    "maintainer": "Henrik Bengtsson <henrikb@braju.com>",
    "author": "Henrik Bengtsson [aut, cre, cph]",
    "url": "https://www.aroma-project.org/,\nhttps://github.com/HenrikBengtsson/aroma.apd",
    "bug_reports": "https://github.com/HenrikBengtsson/aroma.apd/issues",
    "repository": "https://cran.r-project.org/package=aroma.apd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aroma.apd A Probe-Level Data File Format Used by 'aroma.affymetrix'\n[deprecated] DEPRECATED. Do not start building new projects based on this package. (The (in-house) APD file format was initially developed to store Affymetrix probe-level data, e.g. normalized CEL intensities.  Chip types can be added to APD file and similar to methods in the affxparser package, this package provides methods to read APDs organized by units (probesets).  In addition, the probe elements can be arranged optimally such that the elements are guaranteed to be read in order when, for instance, data is read unit by unit.  This speeds up the read substantially.  This package is supporting the Aroma framework and should not be used elsewhere.)  "
  },
  {
    "id": 8670,
    "package_name": "ashapesampler",
    "title": "Generating Alpha Shapes",
    "description": "Understanding morphological variation is an important task in many applications. Recent studies in computational biology have focused on developing computational tools for the task of sub-image selection which aims at identifying structural features that best describe the variation between classes of shapes. A major part in assessing the utility of these approaches is to demonstrate their performance on both simulated and real datasets. However, when creating a model for shape statistics, real data can be difficult to access and the sample sizes for these data are often small due to them being expensive to collect. Meanwhile, the landscape of current shape simulation methods has been mostly limited to approaches that use black-box inference---making it difficult to systematically assess the power and calibration of sub-image models. In this R package, we introduce the alpha-shape sampler: a probabilistic framework for simulating realistic 2D and 3D shapes based on probability distributions which can be learned from real data or explicitly stated by the user. The 'ashapesampler' package supports two mechanisms for sampling shapes in two and three dimensions. The first, empirically sampling based on an existing data set, was highlighted in the original main text of the paper. The second, probabilistic sampling from a known distribution, is the computational implementation of the theory derived in that paper. Work based on Winn-Nunez et al. (2024) <doi:10.1101/2024.01.09.574919>.",
    "version": "1.0.0",
    "maintainer": "Emily Winn-Nunez <emily_winn-nunez@brown.edu>",
    "author": "Emily Winn-Nunez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6759-5406>),\n  Lorin Crawford [aut] (ORCID: <https://orcid.org/0000-0003-0178-8242>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ashapesampler",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ashapesampler Generating Alpha Shapes Understanding morphological variation is an important task in many applications. Recent studies in computational biology have focused on developing computational tools for the task of sub-image selection which aims at identifying structural features that best describe the variation between classes of shapes. A major part in assessing the utility of these approaches is to demonstrate their performance on both simulated and real datasets. However, when creating a model for shape statistics, real data can be difficult to access and the sample sizes for these data are often small due to them being expensive to collect. Meanwhile, the landscape of current shape simulation methods has been mostly limited to approaches that use black-box inference---making it difficult to systematically assess the power and calibration of sub-image models. In this R package, we introduce the alpha-shape sampler: a probabilistic framework for simulating realistic 2D and 3D shapes based on probability distributions which can be learned from real data or explicitly stated by the user. The 'ashapesampler' package supports two mechanisms for sampling shapes in two and three dimensions. The first, empirically sampling based on an existing data set, was highlighted in the original main text of the paper. The second, probabilistic sampling from a known distribution, is the computational implementation of the theory derived in that paper. Work based on Winn-Nunez et al. (2024) <doi:10.1101/2024.01.09.574919>.  "
  },
  {
    "id": 8671,
    "package_name": "ashr",
    "title": "Methods for Adaptive Shrinkage, using Empirical Bayes",
    "description": "The R package 'ashr' implements an Empirical Bayes\n    approach for large-scale hypothesis testing and false discovery\n    rate (FDR) estimation based on the methods proposed in\n    M. Stephens, 2016, \"False discovery rates: a new deal\",\n    <DOI:10.1093/biostatistics/kxw041>. These methods can be applied\n    whenever two sets of summary statistics---estimated effects and\n    standard errors---are available, just as 'qvalue' can be applied\n    to previously computed p-values. Two main interfaces are\n    provided: ash(), which is more user-friendly; and ash.workhorse(),\n    which has more options and is geared toward advanced users. The\n    ash() and ash.workhorse() also provides a flexible modeling\n    interface that can accommodate a variety of likelihoods (e.g.,\n    normal, Poisson) and mixture priors (e.g., uniform, normal).",
    "version": "2.2-63",
    "maintainer": "Peter Carbonetto <pcarbo@uchicago.edu>",
    "author": "Matthew Stephens [aut],\n  Peter Carbonetto [aut, cre],\n  Chaoxing Dai [ctb],\n  David Gerard [aut],\n  Mengyin Lu [aut],\n  Lei Sun [aut],\n  Jason Willwerscheid [aut],\n  Nan Xiao [aut],\n  Mazon Zeng [ctb]",
    "url": "https://github.com/stephens999/ashr",
    "bug_reports": "https://github.com/stephens999/ashr/issues",
    "repository": "https://cran.r-project.org/package=ashr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ashr Methods for Adaptive Shrinkage, using Empirical Bayes The R package 'ashr' implements an Empirical Bayes\n    approach for large-scale hypothesis testing and false discovery\n    rate (FDR) estimation based on the methods proposed in\n    M. Stephens, 2016, \"False discovery rates: a new deal\",\n    <DOI:10.1093/biostatistics/kxw041>. These methods can be applied\n    whenever two sets of summary statistics---estimated effects and\n    standard errors---are available, just as 'qvalue' can be applied\n    to previously computed p-values. Two main interfaces are\n    provided: ash(), which is more user-friendly; and ash.workhorse(),\n    which has more options and is geared toward advanced users. The\n    ash() and ash.workhorse() also provides a flexible modeling\n    interface that can accommodate a variety of likelihoods (e.g.,\n    normal, Poisson) and mixture priors (e.g., uniform, normal).  "
  },
  {
    "id": 8695,
    "package_name": "aster2",
    "title": "Aster Models",
    "description": "Aster models are exponential family regression models for life\n    history analysis.  They are like generalized linear models except that\n    elements of the response vector can have different families (e. g.,\n    some Bernoulli, some Poisson, some zero-truncated Poisson, some normal)\n    and can be dependent, the dependence indicated by a graphical structure.\n    Discrete time survival analysis, zero-inflated Poisson regression, and\n    generalized linear models that are exponential family (e. g., logistic\n    regression and Poisson regression with log link) are special cases.\n    Main use is for data in which there is survival over discrete time periods\n    and there is additional data about what happens conditional on survival\n    (e. g., number of offspring).  Uses the exponential family canonical\n    parameterization (aster transform of usual parameterization).\n    Unlike the aster package, this package does dependence groups (nodes of\n    the graph need not be conditionally independent given their predecessor\n    node), including multinomial and two-parameter normal as families.  Thus\n    this package also generalizes mark-capture-recapture analysis.",
    "version": "0.3-2",
    "maintainer": "Charles J. Geyer <geyer@umn.edu>",
    "author": "Charles J. Geyer [aut, cre]",
    "url": "https://www.stat.umn.edu/geyer/aster/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aster2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aster2 Aster Models Aster models are exponential family regression models for life\n    history analysis.  They are like generalized linear models except that\n    elements of the response vector can have different families (e. g.,\n    some Bernoulli, some Poisson, some zero-truncated Poisson, some normal)\n    and can be dependent, the dependence indicated by a graphical structure.\n    Discrete time survival analysis, zero-inflated Poisson regression, and\n    generalized linear models that are exponential family (e. g., logistic\n    regression and Poisson regression with log link) are special cases.\n    Main use is for data in which there is survival over discrete time periods\n    and there is additional data about what happens conditional on survival\n    (e. g., number of offspring).  Uses the exponential family canonical\n    parameterization (aster transform of usual parameterization).\n    Unlike the aster package, this package does dependence groups (nodes of\n    the graph need not be conditionally independent given their predecessor\n    node), including multinomial and two-parameter normal as families.  Thus\n    this package also generalizes mark-capture-recapture analysis.  "
  },
  {
    "id": 8705,
    "package_name": "asympTest",
    "title": "A Simple R Package for Classical Parametric Statistical Tests\nand Confidence Intervals in Large Samples",
    "description": "One and two sample mean and variance\n tests (differences and ratios) are considered.\n The test statistics are all expressed in the same\n form as the Student t-test, which facilitates their\n presentation in the classroom. This contribution\n also fills the gap of a robust (to non-normality)\n alternative to the chi-square single variance test\n for large samples, since no such procedure is implemented\n in standard statistical software.",
    "version": "0.1.4",
    "maintainer": "Pierre Lafaye de Micheaux <lafaye@unsw.edu.au>",
    "author": "Cqls Team",
    "url": "https://www.r-project.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=asympTest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "asympTest A Simple R Package for Classical Parametric Statistical Tests\nand Confidence Intervals in Large Samples One and two sample mean and variance\n tests (differences and ratios) are considered.\n The test statistics are all expressed in the same\n form as the Student t-test, which facilitates their\n presentation in the classroom. This contribution\n also fills the gap of a robust (to non-normality)\n alternative to the chi-square single variance test\n for large samples, since no such procedure is implemented\n in standard statistical software.  "
  },
  {
    "id": 8718,
    "package_name": "attachment",
    "title": "Deal with Dependencies",
    "description": "Manage dependencies during package development. This can\n    retrieve all dependencies that are used in \".R\" files in the \"R/\"\n    directory, in \".Rmd\" files in \"vignettes/\" directory and in 'roxygen2'\n    documentation of functions. There is a function to update the\n    \"DESCRIPTION\" file of your package with 'CRAN' packages or any other\n    remote package.  All functions to retrieve dependencies of \".R\"\n    scripts and \".Rmd\" or \".qmd\" files can be used independently of a\n    package development.",
    "version": "0.4.5",
    "maintainer": "Vincent Guyader <vincent@thinkr.fr>",
    "author": "Vincent Guyader [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-0671-9270>),\n  S\u00e9bastien Rochette [aut] (ORCID:\n    <https://orcid.org/0000-0002-1565-9313>, previous maintainer),\n  Murielle Delmotte [aut] (ORCID:\n    <https://orcid.org/0000-0002-1339-2424>),\n  Swann Floc'hlay [aut] (ORCID: <https://orcid.org/0000-0003-1477-830X>),\n  ThinkR [cph, fnd]",
    "url": "https://thinkr-open.github.io/attachment/,\nhttps://github.com/ThinkR-open/attachment",
    "bug_reports": "https://github.com/ThinkR-open/attachment/issues",
    "repository": "https://cran.r-project.org/package=attachment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "attachment Deal with Dependencies Manage dependencies during package development. This can\n    retrieve all dependencies that are used in \".R\" files in the \"R/\"\n    directory, in \".Rmd\" files in \"vignettes/\" directory and in 'roxygen2'\n    documentation of functions. There is a function to update the\n    \"DESCRIPTION\" file of your package with 'CRAN' packages or any other\n    remote package.  All functions to retrieve dependencies of \".R\"\n    scripts and \".Rmd\" or \".qmd\" files can be used independently of a\n    package development.  "
  },
  {
    "id": 8736,
    "package_name": "authoritative",
    "title": "Parse and Deduplicate Author Names",
    "description": "Utilities to parse authors fields from DESCRIPTION files and\n    general purpose functions to deduplicate names in database, beyond the\n    specific case of R package authors.",
    "version": "0.2.0",
    "maintainer": "Hugo Gruson <hugo.gruson+R@normalesup.org>",
    "author": "Hugo Gruson [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4094-1476>),\n  Chris Hartgerink [rev] (ORCID: <https://orcid.org/0000-0003-1050-6809>),\n  data.org [fnd] (until version 0.2.0 included)",
    "url": "https://github.com/Bisaloo/authoritative,\nhttps://hugogruson.fr/authoritative/",
    "bug_reports": "https://github.com/Bisaloo/authoritative/issues",
    "repository": "https://cran.r-project.org/package=authoritative",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "authoritative Parse and Deduplicate Author Names Utilities to parse authors fields from DESCRIPTION files and\n    general purpose functions to deduplicate names in database, beyond the\n    specific case of R package authors.  "
  },
  {
    "id": 8750,
    "package_name": "autogam",
    "title": "Automate the Creation of Generalized Additive Models (GAMs)",
    "description": "This wrapper package for 'mgcv' makes it easier to create high-performing Generalized Additive Models (GAMs). With its central function autogam(), by entering just a dataset and the name of the outcome column as inputs, 'AutoGAM' tries to automate the procedure of configuring a highly accurate GAM which performs at reasonably high speed, even for large datasets.",
    "version": "0.1.0",
    "maintainer": "Chitu Okoli <Chitu.Okoli@skema.edu>",
    "author": "Chitu Okoli [aut, cre] (ORCID: <https://orcid.org/0000-0001-5574-7572>)",
    "url": "https://github.com/tripartio/autogam,\nhttps://tripartio.github.io/autogam/",
    "bug_reports": "https://github.com/tripartio/autogam/issues",
    "repository": "https://cran.r-project.org/package=autogam",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "autogam Automate the Creation of Generalized Additive Models (GAMs) This wrapper package for 'mgcv' makes it easier to create high-performing Generalized Additive Models (GAMs). With its central function autogam(), by entering just a dataset and the name of the outcome column as inputs, 'AutoGAM' tries to automate the procedure of configuring a highly accurate GAM which performs at reasonably high speed, even for large datasets.  "
  },
  {
    "id": 8755,
    "package_name": "autoimport",
    "title": "Automatic Generation of @importFrom Tags",
    "description": "A toolbox to read all R files inside a package and\n    automatically generate @importFrom 'roxygen2' tags in the right place. \n    Includes a 'shiny' application to review the changes before applying them.",
    "version": "0.1.1",
    "maintainer": "Dan Chaltiel <dan.chaltiel@gmail.com>",
    "author": "Dan Chaltiel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3488-779X>)",
    "url": "https://github.com/DanChaltiel/autoimport,\nhttps://danchaltiel.github.io/autoimport/",
    "bug_reports": "https://github.com/DanChaltiel/autoimport/issues",
    "repository": "https://cran.r-project.org/package=autoimport",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "autoimport Automatic Generation of @importFrom Tags A toolbox to read all R files inside a package and\n    automatically generate @importFrom 'roxygen2' tags in the right place. \n    Includes a 'shiny' application to review the changes before applying them.  "
  },
  {
    "id": 8757,
    "package_name": "automagic",
    "title": "Automagically Document and Install Packages Necessary to Run R\nCode",
    "description": "Parse R code in a given directory for R packages and attempt to install them from CRAN or GitHub. Optionally use a dependencies file for tighter control over which package versions to install.",
    "version": "0.5.1",
    "maintainer": "Cole Brokamp <cole.brokamp@gmail.com>",
    "author": "Cole Brokamp [aut, cre],\n  Steph Locke [ctb]",
    "url": "https://github.com/cole-brokamp/automagic",
    "bug_reports": "https://github.com/cole-brokamp/automagic/issues",
    "repository": "https://cran.r-project.org/package=automagic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "automagic Automagically Document and Install Packages Necessary to Run R\nCode Parse R code in a given directory for R packages and attempt to install them from CRAN or GitHub. Optionally use a dependencies file for tighter control over which package versions to install.  "
  },
  {
    "id": 8798,
    "package_name": "awsMethods",
    "title": "Class and Methods Definitions for Packages 'aws', 'adimpro',\n'fmri', 'dwi'",
    "description": "Defines the method extract and provides 'openMP' support as needed in several packages.",
    "version": "1.1-1",
    "maintainer": "Joerg Polzehl <joerg.polzehl@wias-berlin.de>",
    "author": "Joerg Polzehl [aut, cre],\n  Felix Anker [ctb]",
    "url": "http://www.wias-berlin.de/software/imaging/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=awsMethods",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "awsMethods Class and Methods Definitions for Packages 'aws', 'adimpro',\n'fmri', 'dwi' Defines the method extract and provides 'openMP' support as needed in several packages.  "
  },
  {
    "id": 8809,
    "package_name": "babelgene",
    "title": "Gene Orthologs for Model Organisms in a Tidy Data Format",
    "description": "Genomic analysis of model organisms frequently requires the\n    use of databases based on human data or making comparisons to\n    patient-derived resources. This requires harmonization of gene names\n    into the same gene space. The 'babelgene' R package converts between\n    human and non-human gene orthologs/homologs. The package integrates\n    orthology assertion predictions sourced from multiple databases as\n    compiled by the HGNC Comparison of Orthology Predictions (HCOP)\n    (Wright et al. 2005 <doi:10.1007/s00335-005-0103-2>, Eyre et al. 2007\n    <doi:10.1093/bib/bbl030>, Seal et al. 2011 <doi:10.1093/nar/gkq892>).",
    "version": "22.9",
    "maintainer": "Igor Dolgalev <igor.dolgalev@nyumc.org>",
    "author": "Igor Dolgalev [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4451-126X>)",
    "url": "https://igordot.github.io/babelgene/",
    "bug_reports": "https://github.com/igordot/babelgene/issues",
    "repository": "https://cran.r-project.org/package=babelgene",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "babelgene Gene Orthologs for Model Organisms in a Tidy Data Format Genomic analysis of model organisms frequently requires the\n    use of databases based on human data or making comparisons to\n    patient-derived resources. This requires harmonization of gene names\n    into the same gene space. The 'babelgene' R package converts between\n    human and non-human gene orthologs/homologs. The package integrates\n    orthology assertion predictions sourced from multiple databases as\n    compiled by the HGNC Comparison of Orthology Predictions (HCOP)\n    (Wright et al. 2005 <doi:10.1007/s00335-005-0103-2>, Eyre et al. 2007\n    <doi:10.1093/bib/bbl030>, Seal et al. 2011 <doi:10.1093/nar/gkq892>).  "
  },
  {
    "id": 8825,
    "package_name": "badger",
    "title": "Badge for R Package",
    "description": "Query information and generate badge for using in README and GitHub Pages.",
    "version": "0.2.5",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6485-8781>),\n  Gregor de Cillia [ctb],\n  Dirk Eddelbuettel [ctb],\n  Ma\u00eblle Salmon [ctb],\n  Robrecht Cannoodt [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3641-729X>, github: rcannood),\n  Alexander Rossell Hayes [ctb] (ORCID:\n    <https://orcid.org/0000-0001-9412-0457>, github: rossellhayes),\n  Waldir Leoncio [ctb],\n  Matthew Schuelke [ctb] (ORCID: <https://orcid.org/0000-0001-5755-1725>,\n    github: the-mad-statter)",
    "url": "https://github.com/GuangchuangYu/badger",
    "bug_reports": "https://github.com/GuangchuangYu/badger/issues",
    "repository": "https://cran.r-project.org/package=badger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "badger Badge for R Package Query information and generate badge for using in README and GitHub Pages.  "
  },
  {
    "id": 8843,
    "package_name": "bamlss",
    "title": "Bayesian Additive Models for Location, Scale, and Shape (and\nBeyond)",
    "description": "Infrastructure for estimating probabilistic distributional regression models in a Bayesian framework.\n  The distribution parameters may capture location, scale, shape, etc. and every parameter may depend\n  on complex additive terms (fixed, random, smooth, spatial, etc.) similar to a generalized additive model.\n  The conceptual and computational framework is introduced in Umlauf, Klein, Zeileis (2019)\n  <doi:10.1080/10618600.2017.1407325> and the R package in Umlauf, Klein, Simon, Zeileis (2021)\n  <doi:10.18637/jss.v100.i04>.",
    "version": "1.2-5",
    "maintainer": "Nikolaus Umlauf <Nikolaus.Umlauf@uibk.ac.at>",
    "author": "Nikolaus Umlauf [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2160-9803>),\n  Nadja Klein [aut] (ORCID: <https://orcid.org/0000-0002-5072-5347>),\n  Achim Zeileis [aut] (ORCID: <https://orcid.org/0000-0003-0918-3766>),\n  Meike Koehler [ctb],\n  Thorsten Simon [aut] (ORCID: <https://orcid.org/0000-0002-3778-7738>),\n  Stanislaus Stadlmann [ctb],\n  Alexander Volkmann [ctb] (ORCID:\n    <https://orcid.org/0000-0001-5028-8098>)",
    "url": "http://www.bamlss.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bamlss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bamlss Bayesian Additive Models for Location, Scale, and Shape (and\nBeyond) Infrastructure for estimating probabilistic distributional regression models in a Bayesian framework.\n  The distribution parameters may capture location, scale, shape, etc. and every parameter may depend\n  on complex additive terms (fixed, random, smooth, spatial, etc.) similar to a generalized additive model.\n  The conceptual and computational framework is introduced in Umlauf, Klein, Zeileis (2019)\n  <doi:10.1080/10618600.2017.1407325> and the R package in Umlauf, Klein, Simon, Zeileis (2021)\n  <doi:10.18637/jss.v100.i04>.  "
  },
  {
    "id": 8851,
    "package_name": "bandsfdp",
    "title": "Compute Upper Prediction Bounds on the FDP in Competition-Based\nSetups",
    "description": "Implements functions that calculate upper prediction \n  bounds on the false discovery proportion (FDP) in the list of discoveries \n  returned by competition-based setups, implementing Ebadi et al. (2022)\n  <arXiv:2302.11837>. Such setups include target-decoy competition (TDC) \n  in computational mass spectrometry and the knockoff construction in linear \n  regression (note this package typically uses the terminology of TDC). Included \n  is the standardized (TDC-SB) and uniform (TDC-UB) bound on TDC's FDP, and the \n  simultaneous standardized and uniform bands. Requires \n  pre-computed Monte Carlo statistics available at \n  <https://github.com/uni-Arya/fdpbandsdata>. This data can be downloaded by\n  running the command 'devtools::install_github(\"uni-Arya/fdpbandsdata\")' in R\n  and restarting R after installation. The size of this data is roughly 81Mb.",
    "version": "1.1.0",
    "maintainer": "Arya Ebadi <aeba3842@uni.sydney.edu.au>",
    "author": "Arya Ebadi [aut, cre],\n  Dong Luo [aut],\n  Jack Freestone [aut],\n  William Stafford Noble [aut],\n  Uri Keich [aut] (ORCID: <https://orcid.org/0000-0002-3209-5011>)",
    "url": "https://github.com/uni-Arya/bandsfdp",
    "bug_reports": "https://github.com/uni-Arya/bandsfdp/issues",
    "repository": "https://cran.r-project.org/package=bandsfdp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bandsfdp Compute Upper Prediction Bounds on the FDP in Competition-Based\nSetups Implements functions that calculate upper prediction \n  bounds on the false discovery proportion (FDP) in the list of discoveries \n  returned by competition-based setups, implementing Ebadi et al. (2022)\n  <arXiv:2302.11837>. Such setups include target-decoy competition (TDC) \n  in computational mass spectrometry and the knockoff construction in linear \n  regression (note this package typically uses the terminology of TDC). Included \n  is the standardized (TDC-SB) and uniform (TDC-UB) bound on TDC's FDP, and the \n  simultaneous standardized and uniform bands. Requires \n  pre-computed Monte Carlo statistics available at \n  <https://github.com/uni-Arya/fdpbandsdata>. This data can be downloaded by\n  running the command 'devtools::install_github(\"uni-Arya/fdpbandsdata\")' in R\n  and restarting R after installation. The size of this data is roughly 81Mb.  "
  },
  {
    "id": 8864,
    "package_name": "barry",
    "title": "Your Go-to Motif Accountant",
    "description": "Provides the 'C++' header-only library 'barry' for use in R packages. \n 'barry' is a 'C++' template library for counting sufficient statistics on binary \n arrays and building discrete exponential-family models. It provides tools for \n sparse arrays, user-defined count statistics, support set constraints, \n power set generation, and includes modules for Discrete Exponential Family Models \n (DEFMs) and network statistics. By placing these headers in this package, we \n offer an efficient distribution system for CRAN as replication of this code in \n the sources of other packages is avoided. This package follows the same \n approach as the 'BH' package which provides 'Boost' headers for R packages.",
    "version": "0.2.1",
    "maintainer": "George Vega Yon <g.vegayon@gmail.com>",
    "author": "George Vega Yon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3171-0844>)",
    "url": "https://github.com/USCbiostats/barryr,\nhttps://uscbiostats.github.io/barryr/",
    "bug_reports": "https://github.com/USCbiostats/barryr/issues",
    "repository": "https://cran.r-project.org/package=barry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "barry Your Go-to Motif Accountant Provides the 'C++' header-only library 'barry' for use in R packages. \n 'barry' is a 'C++' template library for counting sufficient statistics on binary \n arrays and building discrete exponential-family models. It provides tools for \n sparse arrays, user-defined count statistics, support set constraints, \n power set generation, and includes modules for Discrete Exponential Family Models \n (DEFMs) and network statistics. By placing these headers in this package, we \n offer an efficient distribution system for CRAN as replication of this code in \n the sources of other packages is avoided. This package follows the same \n approach as the 'BH' package which provides 'Boost' headers for R packages.  "
  },
  {
    "id": 8867,
    "package_name": "bartMan",
    "title": "Create Visualisations for BART Models",
    "description": "Investigating and visualising Bayesian Additive Regression Tree (BART) (Chipman, H. A., George, E. I., & McCulloch, R. E. 2010) <doi:10.1214/09-AOAS285> model fits.  We construct conventional plots to analyze a model\u2019s performance and stability  as well as create new tree-based plots to analyze variable importance, interaction, and tree structure.  We employ Value Suppressing Uncertainty Palettes (VSUP) to construct heatmaps that display variable importance  and interactions jointly using colour scale to represent posterior uncertainty.  Our visualisations are designed to work with the most popular BART R packages available, namely 'BART' Rodney Sparapani and Charles Spanbauer and Robert McCulloch 2021 <doi:10.18637/jss.v097.i01>,  'dbarts'  (Vincent Dorie 2023) <https://CRAN.R-project.org/package=dbarts>,  and 'bartMachine' (Adam Kapelner and Justin Bleich 2016) <doi:10.18637/jss.v070.i04>.",
    "version": "0.2.1",
    "maintainer": "Alan Inglis <alan.inglis@mu.ie>",
    "author": "Alan Inglis [aut, cre],\n  Andrew Parnell [aut],\n  Catherine Hurley [aut],\n  Claus Wilke [ctb] (Developer of VSUP script)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bartMan",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bartMan Create Visualisations for BART Models Investigating and visualising Bayesian Additive Regression Tree (BART) (Chipman, H. A., George, E. I., & McCulloch, R. E. 2010) <doi:10.1214/09-AOAS285> model fits.  We construct conventional plots to analyze a model\u2019s performance and stability  as well as create new tree-based plots to analyze variable importance, interaction, and tree structure.  We employ Value Suppressing Uncertainty Palettes (VSUP) to construct heatmaps that display variable importance  and interactions jointly using colour scale to represent posterior uncertainty.  Our visualisations are designed to work with the most popular BART R packages available, namely 'BART' Rodney Sparapani and Charles Spanbauer and Robert McCulloch 2021 <doi:10.18637/jss.v097.i01>,  'dbarts'  (Vincent Dorie 2023) <https://CRAN.R-project.org/package=dbarts>,  and 'bartMachine' (Adam Kapelner and Justin Bleich 2016) <doi:10.18637/jss.v070.i04>.  "
  },
  {
    "id": 8868,
    "package_name": "bartXViz",
    "title": "Visualization of BART and BARP using SHAP",
    "description": "Complex machine learning models are often difficult to interpret. Shapley values serve as a powerful tool to understand and explain why a model makes a particular prediction. This package computes variable contributions using permutation-based Shapley values for Bayesian Additive Regression Trees (BART) and its extension with Post-Stratification (BARP). The permutation-based SHAP method proposed by Strumbel and Kononenko (2014) <doi:10.1007/s10115-013-0679-x> is grounded in data obtained via MCMC sampling. Similar to the BART model introduced by Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>, this package leverages Bayesian posterior samples generated during model estimation, allowing variable contributions to be computed without requiring additional sampling. The BART model is designed to work with the following R packages: 'BART' <doi:10.18637/jss.v097.i01>, 'bartMachine' <doi:10.18637/jss.v070.i04>, and 'dbarts' <https://CRAN.R-project.org/package=dbarts>. For XGBoost and baseline adjustments, the approach by Lundberg et al. (2020) <doi:10.1038/s42256-019-0138-9> is also considered. The BARP model proposed by Bisbee (2019) <doi:10.1017/S0003055419000480> was implemented with reference to <https://github.com/jbisbee1/BARP> and is designed to work with modified functions based on that implementation. BARP extends post-stratification by computing variable contributions within each stratum defined by stratifying variables. The resulting Shapley values are visualized through both global and local explanation methods.",
    "version": "1.0.8",
    "maintainer": "Dong-eun Lee <ldongeun.leel@gmail.com>",
    "author": "Dong-eun Lee [aut, cre],\n  Eun-Kyung Lee [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bartXViz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bartXViz Visualization of BART and BARP using SHAP Complex machine learning models are often difficult to interpret. Shapley values serve as a powerful tool to understand and explain why a model makes a particular prediction. This package computes variable contributions using permutation-based Shapley values for Bayesian Additive Regression Trees (BART) and its extension with Post-Stratification (BARP). The permutation-based SHAP method proposed by Strumbel and Kononenko (2014) <doi:10.1007/s10115-013-0679-x> is grounded in data obtained via MCMC sampling. Similar to the BART model introduced by Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>, this package leverages Bayesian posterior samples generated during model estimation, allowing variable contributions to be computed without requiring additional sampling. The BART model is designed to work with the following R packages: 'BART' <doi:10.18637/jss.v097.i01>, 'bartMachine' <doi:10.18637/jss.v070.i04>, and 'dbarts' <https://CRAN.R-project.org/package=dbarts>. For XGBoost and baseline adjustments, the approach by Lundberg et al. (2020) <doi:10.1038/s42256-019-0138-9> is also considered. The BARP model proposed by Bisbee (2019) <doi:10.1017/S0003055419000480> was implemented with reference to <https://github.com/jbisbee1/BARP> and is designed to work with modified functions based on that implementation. BARP extends post-stratification by computing variable contributions within each stratum defined by stratifying variables. The resulting Shapley values are visualized through both global and local explanation methods.  "
  },
  {
    "id": 8895,
    "package_name": "batata",
    "title": "Managing Packages Removal and Installation",
    "description": "\n    Allows the user to manage easily R packages removal and installation. It offers many functions to display installed packages according to\n    specific dates and removes them if needed. The user is always prompted when running the removal functions in order to confirm\n    the required action. It also provides functions that will install 'Github' starred R packages whether available on 'CRAN' or not. ",
    "version": "0.2.1",
    "maintainer": "Mohamed El Fodil Ihaddaden <ihaddaden.fodeil@gmail.com>",
    "author": "Mohamed El Fodil Ihaddaden",
    "url": "https://github.com/feddelegrand7/batata",
    "bug_reports": "https://github.com/feddelegrand7/batata/issues",
    "repository": "https://cran.r-project.org/package=batata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "batata Managing Packages Removal and Installation \n    Allows the user to manage easily R packages removal and installation. It offers many functions to display installed packages according to\n    specific dates and removes them if needed. The user is always prompted when running the removal functions in order to confirm\n    the required action. It also provides functions that will install 'Github' starred R packages whether available on 'CRAN' or not.   "
  },
  {
    "id": 8905,
    "package_name": "batteryreduction",
    "title": "An R Package for Data Reduction by Battery Reduction",
    "description": "Battery reduction is a method used in data reduction. It uses Gram-Schmidt orthogonal rotations to find out a subset of variables best representing the original set of variables.    ",
    "version": "0.1.1",
    "maintainer": "Chunqiao Luo <chunqiaoluo@gmail.com>",
    "author": "Chunqiao Luo [aut, cre],\n  Ralph D'Agostino [aut] (This package is derived from Battery Reduction\n    Macro at http://www.lexjansen.com/nesug/nesug92/NESUG92090.pdf)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=batteryreduction",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "batteryreduction An R Package for Data Reduction by Battery Reduction Battery reduction is a method used in data reduction. It uses Gram-Schmidt orthogonal rotations to find out a subset of variables best representing the original set of variables.      "
  },
  {
    "id": 8960,
    "package_name": "bayesvl",
    "title": "Visually Learning the Graphical Structure of Bayesian Networks\nand Performing MCMC with 'Stan'",
    "description": "Provides users with its associated functions for pedagogical purposes in visually learning Bayesian networks and Markov chain Monte Carlo (MCMC) computations. It enables users to: a) Create and examine the (starting) graphical structure of Bayesian networks; b) Create random Bayesian networks using a dataset with customized constraints; c) Generate Stan code for structures of Bayesian networks for sampling the data and learning parameters; d) Plot the network graphs; e) Perform Markov chain Monte Carlo computations and produce graphs for posteriors checks. The package refers to one reference item, which describes the methods and algorithms: Vuong, Quan-Hoang and La, Viet-Phuong (2019) <doi:10.31219/osf.io/w5dx6> The 'bayesvl' R package. Open Science Framework (May 18).",
    "version": "1.0.0",
    "maintainer": "Viet-Phuong La <lvphuong@gmail.com>",
    "author": "Viet-Phuong La [aut, cre],\n  Quan-Hoang Vuong [aut]",
    "url": "https://github.com/sshpa/bayesvl",
    "bug_reports": "https://github.com/sshpa/bayesvl/issues",
    "repository": "https://cran.r-project.org/package=bayesvl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesvl Visually Learning the Graphical Structure of Bayesian Networks\nand Performing MCMC with 'Stan' Provides users with its associated functions for pedagogical purposes in visually learning Bayesian networks and Markov chain Monte Carlo (MCMC) computations. It enables users to: a) Create and examine the (starting) graphical structure of Bayesian networks; b) Create random Bayesian networks using a dataset with customized constraints; c) Generate Stan code for structures of Bayesian networks for sampling the data and learning parameters; d) Plot the network graphs; e) Perform Markov chain Monte Carlo computations and produce graphs for posteriors checks. The package refers to one reference item, which describes the methods and algorithms: Vuong, Quan-Hoang and La, Viet-Phuong (2019) <doi:10.31219/osf.io/w5dx6> The 'bayesvl' R package. Open Science Framework (May 18).  "
  },
  {
    "id": 8962,
    "package_name": "baygel",
    "title": "Bayesian Shrinkage Estimators for Precision Matrices in Gaussian\nGraphical Models",
    "description": "This R package offers block Gibbs samplers for the Bayesian (adaptive) graphical lasso, ridge, and naive elastic net priors. These samplers facilitate the simulation of the posterior distribution of precision matrices for Gaussian distributed data and were originally proposed by: Wang (2012) <doi:10.1214/12-BA729>; Smith et al. (2022) <doi:10.48550/arXiv.2210.16290> and Smith et al. (2023) <doi:10.48550/arXiv.2306.14199>, respectively.",
    "version": "0.3.0",
    "maintainer": "Jarod Smith <jarodsmith706@gmail.com>",
    "author": "Jarod Smith [aut, cre] (ORCID: <https://orcid.org/0000-0003-4235-6147>),\n  Mohammad Arashi [aut] (ORCID: <https://orcid.org/0000-0002-5881-9241>),\n  Andriette Bekker [aut] (ORCID: <https://orcid.org/0000-0003-4793-5674>)",
    "url": "https://github.com/Jarod-Smithy/baygel",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=baygel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "baygel Bayesian Shrinkage Estimators for Precision Matrices in Gaussian\nGraphical Models This R package offers block Gibbs samplers for the Bayesian (adaptive) graphical lasso, ridge, and naive elastic net priors. These samplers facilitate the simulation of the posterior distribution of precision matrices for Gaussian distributed data and were originally proposed by: Wang (2012) <doi:10.1214/12-BA729>; Smith et al. (2022) <doi:10.48550/arXiv.2210.16290> and Smith et al. (2023) <doi:10.48550/arXiv.2306.14199>, respectively.  "
  },
  {
    "id": 9047,
    "package_name": "bestridge",
    "title": "A Comprehensive R Package for Best Subset Selection",
    "description": "The bestridge package is designed to provide a one-stand service for users to successfully carry out best ridge regression in various complex situations via the primal dual active set algorithm proposed by Wen, C., Zhang, A., Quan, S. and Wang, X. (2020) <doi:10.18637/jss.v094.i04>. This package allows users to perform the regression, classification, count regression and censored regression for (ultra) high dimensional data, and it also supports advanced usages like group variable selection and nuisance variable selection.",
    "version": "1.0.7",
    "maintainer": "Liyuan Hu <huly5@mail2.sysu.edu.cn>",
    "author": "Liyuan Hu [aut, cre] (ORCID: <https://orcid.org/0000-0003-2064-8990>),\n  Jin Zhu [aut] (ORCID: <https://orcid.org/0000-0001-8550-5822>),\n  Junxian Zhu [aut],\n  Kangkang Jiang [aut],\n  Yanhang Zhang [aut],\n  Xueqin Wang [aut] (ORCID: <https://orcid.org/0000-0001-5205-9950>),\n  Canhong Wen [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bestridge",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bestridge A Comprehensive R Package for Best Subset Selection The bestridge package is designed to provide a one-stand service for users to successfully carry out best ridge regression in various complex situations via the primal dual active set algorithm proposed by Wen, C., Zhang, A., Quan, S. and Wang, X. (2020) <doi:10.18637/jss.v094.i04>. This package allows users to perform the regression, classification, count regression and censored regression for (ultra) high dimensional data, and it also supports advanced usages like group variable selection and nuisance variable selection.  "
  },
  {
    "id": 9065,
    "package_name": "bezier",
    "title": "Toolkit for Bezier Curves and Splines",
    "description": "The bezier package is a toolkit for working with Bezier curves and splines. The package provides functions for point generation, arc length estimation, degree elevation and curve fitting.",
    "version": "1.1.2",
    "maintainer": "Aaron Olsen <aarolsen@gmail.com>",
    "author": "Aaron Olsen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bezier",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bezier Toolkit for Bezier Curves and Splines The bezier package is a toolkit for working with Bezier curves and splines. The package provides functions for point generation, arc length estimation, degree elevation and curve fitting.  "
  },
  {
    "id": 9079,
    "package_name": "bgmm",
    "title": "Gaussian Mixture Modeling Algorithms and the Belief-Based\nMixture Modeling",
    "description": "Two partially supervised mixture modeling methods: \n        soft-label and belief-based modeling are implemented.\n        For completeness, we equipped the package also with the\n        functionality of unsupervised, semi- and fully supervised\n        mixture modeling.  The package can be applied also to selection\n        of the best-fitting from a set of models with different\n        component numbers or constraints on their structures.\n        For detailed introduction see:\n        Przemyslaw Biecek, Ewa Szczurek, Martin Vingron, Jerzy\n        Tiuryn (2012), The R Package bgmm: Mixture Modeling with\n        Uncertain Knowledge, Journal of Statistical Software \n        <doi:10.18637/jss.v047.i03>.",
    "version": "1.8.5",
    "maintainer": "Przemyslaw Biecek <Przemyslaw.Biecek@gmail.com>",
    "author": "Przemyslaw Biecek \\& Ewa Szczurek",
    "url": "http://bgmm.molgen.mpg.de/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bgmm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bgmm Gaussian Mixture Modeling Algorithms and the Belief-Based\nMixture Modeling Two partially supervised mixture modeling methods: \n        soft-label and belief-based modeling are implemented.\n        For completeness, we equipped the package also with the\n        functionality of unsupervised, semi- and fully supervised\n        mixture modeling.  The package can be applied also to selection\n        of the best-fitting from a set of models with different\n        component numbers or constraints on their structures.\n        For detailed introduction see:\n        Przemyslaw Biecek, Ewa Szczurek, Martin Vingron, Jerzy\n        Tiuryn (2012), The R Package bgmm: Mixture Modeling with\n        Uncertain Knowledge, Journal of Statistical Software \n        <doi:10.18637/jss.v047.i03>.  "
  },
  {
    "id": 9124,
    "package_name": "bignum",
    "title": "Arbitrary-Precision Integer and Floating-Point Mathematics",
    "description": "Classes for storing and manipulating arbitrary-precision\n    integer vectors and high-precision floating-point vectors. These\n    extend the range and precision of the 'integer' and 'double' data\n    types found in R. This package utilizes the 'Boost.Multiprecision' C++\n    library. It is specifically designed to work well with the 'tidyverse'\n    collection of R packages.",
    "version": "0.3.2",
    "maintainer": "David Hall <david.hall.physics@gmail.com>",
    "author": "David Hall [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2193-0480>)",
    "url": "https://davidchall.github.io/bignum/,\nhttps://github.com/davidchall/bignum",
    "bug_reports": "https://github.com/davidchall/bignum/issues",
    "repository": "https://cran.r-project.org/package=bignum",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bignum Arbitrary-Precision Integer and Floating-Point Mathematics Classes for storing and manipulating arbitrary-precision\n    integer vectors and high-precision floating-point vectors. These\n    extend the range and precision of the 'integer' and 'double' data\n    types found in R. This package utilizes the 'Boost.Multiprecision' C++\n    library. It is specifically designed to work well with the 'tidyverse'\n    collection of R packages.  "
  },
  {
    "id": 9125,
    "package_name": "bigparallelr",
    "title": "Easy Parallel Tools",
    "description": "Utility functions for easy parallelism in R. Include some reexports\n    from other packages, utility functions for splitting and parallelizing over\n    blocks, and choosing and setting the number of cores used.",
    "version": "0.3.2",
    "maintainer": "Florian Priv\u00e9 <florian.prive.21@gmail.com>",
    "author": "Florian Priv\u00e9 [aut, cre]",
    "url": "https://github.com/privefl/bigparallelr",
    "bug_reports": "https://github.com/privefl/bigparallelr/issues",
    "repository": "https://cran.r-project.org/package=bigparallelr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bigparallelr Easy Parallel Tools Utility functions for easy parallelism in R. Include some reexports\n    from other packages, utility functions for splitting and parallelizing over\n    blocks, and choosing and setting the number of cores used.  "
  },
  {
    "id": 9150,
    "package_name": "binaryRL",
    "title": "Reinforcement Learning Tools for Two-Alternative Forced Choice\nTasks",
    "description": "Tools for building Rescorla-Wagner Models for Two-Alternative \n  Forced Choice tasks, commonly employed in psychological research. \n  Most concepts and ideas within this R package are referenced from \n  Sutton and Barto (2018) <ISBN:9780262039246>. \n  The package allows for the intuitive definition of RL models using simple \n  if-else statements and three basic models built into this R package are \n  referenced from \n  Niv et al. (2012)<doi:10.1523/JNEUROSCI.5498-10.2012>. \n  Our approach to constructing and evaluating these computational models \n  is informed by the guidelines proposed in \n  Wilson & Collins (2019) <doi:10.7554/eLife.49547>. \n  Example datasets included with the package are sourced from the work of\n  Mason et al. (2024) <doi:10.3758/s13423-023-02415-x>.",
    "version": "0.9.8",
    "maintainer": "YuKi <hmz1969a@gmail.com>",
    "author": "YuKi [aut, cre] (ORCID: <https://orcid.org/0009-0000-1378-1318>)",
    "url": "https://yuki-961004.github.io/binaryRL/",
    "bug_reports": "https://github.com/yuki-961004/binaryRL/issues",
    "repository": "https://cran.r-project.org/package=binaryRL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "binaryRL Reinforcement Learning Tools for Two-Alternative Forced Choice\nTasks Tools for building Rescorla-Wagner Models for Two-Alternative \n  Forced Choice tasks, commonly employed in psychological research. \n  Most concepts and ideas within this R package are referenced from \n  Sutton and Barto (2018) <ISBN:9780262039246>. \n  The package allows for the intuitive definition of RL models using simple \n  if-else statements and three basic models built into this R package are \n  referenced from \n  Niv et al. (2012)<doi:10.1523/JNEUROSCI.5498-10.2012>. \n  Our approach to constructing and evaluating these computational models \n  is informed by the guidelines proposed in \n  Wilson & Collins (2019) <doi:10.7554/eLife.49547>. \n  Example datasets included with the package are sourced from the work of\n  Mason et al. (2024) <doi:10.3758/s13423-023-02415-x>.  "
  },
  {
    "id": 9177,
    "package_name": "bioC.logs",
    "title": "BioConductor Package Downloads Stats",
    "description": "Download stats reported from the BioConductor.org stats website.",
    "version": "1.2.1",
    "maintainer": "Marcelo Ponce <m.ponce@utoronto.ca>",
    "author": "Marcelo Ponce [aut, cre]",
    "url": "https://github.com/mponce0/bioC.logs",
    "bug_reports": "https://github.com/mponce0/bioC.logs/issues",
    "repository": "https://cran.r-project.org/package=bioC.logs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bioC.logs BioConductor Package Downloads Stats Download stats reported from the BioConductor.org stats website.  "
  },
  {
    "id": 9201,
    "package_name": "bioseq",
    "title": "A Toolbox for Manipulating Biological Sequences",
    "description": "Classes and functions to work with biological sequences (DNA, RNA and amino acid sequences).\n    Implements S3 infrastructure to work with biological sequences as described in Keck (2020) <doi:10.1111/2041-210X.13490>.\n    Provides a collection of functions to perform biological conversion among classes\n    (transcription, translation) and basic operations on sequences\n    (detection, selection and replacement based on positions or patterns).\n    The package also provides functions to import and export sequences from and to other package formats.",
    "version": "0.1.5",
    "maintainer": "Francois Keck <francois.keck@gmail.com>",
    "author": "Francois Keck [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-3323-4167>)",
    "url": "https://fkeck.github.io/bioseq/",
    "bug_reports": "https://github.com/fkeck/bioseq/issues",
    "repository": "https://cran.r-project.org/package=bioseq",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bioseq A Toolbox for Manipulating Biological Sequences Classes and functions to work with biological sequences (DNA, RNA and amino acid sequences).\n    Implements S3 infrastructure to work with biological sequences as described in Keck (2020) <doi:10.1111/2041-210X.13490>.\n    Provides a collection of functions to perform biological conversion among classes\n    (transcription, translation) and basic operations on sequences\n    (detection, selection and replacement based on positions or patterns).\n    The package also provides functions to import and export sequences from and to other package formats.  "
  },
  {
    "id": 9204,
    "package_name": "biostat3",
    "title": "Utility Functions, Datasets and Extended Examples for Survival\nAnalysis",
    "description": "Utility functions, datasets and extended examples for survival analysis. This extends a range of other packages, some simple wrappers for time-to-event analyses, datasets, and extensive examples in HTML with R scripts. The package also supports the course Biostatistics III entitled \"Survival analysis for epidemiologists in R\".",
    "version": "0.2.3",
    "maintainer": "Mark Clements <mark.clements@ki.se>",
    "author": "Annika Tillander [ctb],\n  Andreas Karlsson [aut],\n  Johan Zetterqvist [ctb],\n  Peter Strom [ctb],\n  Benedicte Delcoigne [ctb],\n  Mark Clements [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=biostat3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "biostat3 Utility Functions, Datasets and Extended Examples for Survival\nAnalysis Utility functions, datasets and extended examples for survival analysis. This extends a range of other packages, some simple wrappers for time-to-event analyses, datasets, and extensive examples in HTML with R scripts. The package also supports the course Biostatistics III entitled \"Survival analysis for epidemiologists in R\".  "
  },
  {
    "id": 9220,
    "package_name": "birtr",
    "title": "The R Package for \"The Basics of Item Response Theory Using R\"",
    "description": "R functions for \"The Basics of Item Response Theory Using R\" by Frank B. Baker and Seock-Ho Kim (Springer, 2017, ISBN-13: 978-3-319-54204-1) including iccplot(), icccal(), icc(), iccfit(), groupinv(), tcc(), ability(), tif(), and rasch().  For example, iccplot() plots an item characteristic curve under the two-parameter logistic model.",
    "version": "1.0.0",
    "maintainer": "Seock-Ho Kim <shkim@uga.edu>",
    "author": "Seock-Ho Kim [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=birtr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "birtr The R Package for \"The Basics of Item Response Theory Using R\" R functions for \"The Basics of Item Response Theory Using R\" by Frank B. Baker and Seock-Ho Kim (Springer, 2017, ISBN-13: 978-3-319-54204-1) including iccplot(), icccal(), icc(), iccfit(), groupinv(), tcc(), ability(), tif(), and rasch().  For example, iccplot() plots an item characteristic curve under the two-parameter logistic model.  "
  },
  {
    "id": 9304,
    "package_name": "bnpa",
    "title": "Bayesian Networks & Path Analysis",
    "description": "This project aims to enable the method of Path Analysis to infer causalities \n             from data. For this we propose a hybrid approach, which uses Bayesian network \n             structure learning algorithms from data to create the input file for creation of a \n             PA model. The process is performed in a semi-automatic way by our intermediate \n             algorithm, allowing novice researchers to create and evaluate their own PA models\n             from a data set. The references used for this project are: \n             Koller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press. <doi:10.1017/S0269888910000275>. \n             Nagarajan, R., Scutari, M., & L\u00e8bre, S. (2013). Bayesian networks in r. Springer, 122, 125-127. Scutari, M., & Denis, J. B. <doi:10.1007/978-1-4614-6446-4>.\n             Scutari M (2010). Bayesian networks: with examples in R. Chapman and Hall/CRC. <doi:10.1201/b17065>. \n             Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling. Journal of Statistical Software, 48(2), 1 - 36. <doi:10.18637/jss.v048.i02>.",
    "version": "0.3.0",
    "maintainer": "Elias Carvalho <ecacarva@gmail.com>",
    "author": "Elias Carvalho, Joao R N Vissoci, Luciano Andrade, Wagner Machado, Emerson P Cabrera, Julio C Nievola",
    "url": "https://sites.google.com/site/bnparp/.",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bnpa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bnpa Bayesian Networks & Path Analysis This project aims to enable the method of Path Analysis to infer causalities \n             from data. For this we propose a hybrid approach, which uses Bayesian network \n             structure learning algorithms from data to create the input file for creation of a \n             PA model. The process is performed in a semi-automatic way by our intermediate \n             algorithm, allowing novice researchers to create and evaluate their own PA models\n             from a data set. The references used for this project are: \n             Koller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press. <doi:10.1017/S0269888910000275>. \n             Nagarajan, R., Scutari, M., & L\u00e8bre, S. (2013). Bayesian networks in r. Springer, 122, 125-127. Scutari, M., & Denis, J. B. <doi:10.1007/978-1-4614-6446-4>.\n             Scutari M (2010). Bayesian networks: with examples in R. Chapman and Hall/CRC. <doi:10.1201/b17065>. \n             Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling. Journal of Statistical Software, 48(2), 1 - 36. <doi:10.18637/jss.v048.i02>.  "
  },
  {
    "id": 9307,
    "package_name": "bnviewer",
    "title": "Bayesian Networks Interactive Visualization and Explainable\nArtificial Intelligence",
    "description": "Bayesian networks provide an intuitive framework for probabilistic reasoning \n             and its graphical nature can be interpreted quite clearly. Graph based methods \n             of machine learning are becoming more popular because they offer a richer model \n             of knowledge that can be understood by a human in a graphical format. The 'bnviewer' \n             is an R Package that allows the interactive visualization of Bayesian Networks. \n             The aim of this package is to improve the Bayesian Networks visualization over \n             the basic and static views offered by existing packages.",
    "version": "0.1.6",
    "maintainer": "Robson Fernandes <robson.fernandes@usp.br>",
    "author": "Robson Fernandes [aut, cre, cph]",
    "url": "http://robsonfernandes.net/bnviewer/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bnviewer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bnviewer Bayesian Networks Interactive Visualization and Explainable\nArtificial Intelligence Bayesian networks provide an intuitive framework for probabilistic reasoning \n             and its graphical nature can be interpreted quite clearly. Graph based methods \n             of machine learning are becoming more popular because they offer a richer model \n             of knowledge that can be understood by a human in a graphical format. The 'bnviewer' \n             is an R Package that allows the interactive visualization of Bayesian Networks. \n             The aim of this package is to improve the Bayesian Networks visualization over \n             the basic and static views offered by existing packages.  "
  },
  {
    "id": 9324,
    "package_name": "boodd",
    "title": "Functions for the Book \"Bootstrap for Dependent Data, with an R\nPackage\"",
    "description": "Companion package, functions, data sets, examples for the book \n        Patrice Bertail and Anna Dudek (2025), Bootstrap for Dependent Data, with an R package (by Bernard Desgraupes and Karolina Marek) - submitted.\n    Kreiss, J.-P. and Paparoditis, E. (2003) <doi:10.1214/aos/1074290332>\n    Politis, D.N., and White, H. (2004) <doi:10.1081/ETC-120028836>\n    Patton, A., Politis, D.N., and White, H. (2009) <doi:10.1080/07474930802459016>\n    Tsybakov, A. B. (2018) <doi:10.1007/b13794>\n    Bickel, P., and Sakov, A. (2008) <doi:10.1214/18-AOS1803>\n    G\u00f6tze, F. and Ra\u010dkauskas, A. (2001) <doi:10.1214/lnms/1215090074>\n    Politis, D. N., Romano, J. P., & Wolf, M. (1999, ISBN:978-0-387-98854-2)\n    Carlstein E. (1986) <doi:10.1214/aos/1176350057>\n    K\u00fcnsch, H. (1989) <doi:10.1214/aos/1176347265>\n    Liu, R. and Singh, K. (1992) <https://www.stat.purdue.edu/docs/research/tech-reports/1991/tr91-07.pdf>\n    Politis, D.N. and Romano, J.P. (1994) <doi:10.1080/01621459.1994.10476870>\n    Politis, D.N. and Romano, J.P. (1992) <https://www.stat.purdue.edu/docs/research/tech-reports/1991/tr91-07.pdf>\n    Patrice Bertail, Anna E. Dudek. (2022) <doi:10.3150/23-BEJ1683>\n    Dudek, A.E., Le\u015bkow, J., Paparoditis, E. and Politis, D. (2014a) <https://ideas.repec.org/a/bla/jtsera/v35y2014i2p89-114.html>\n    Beran, R. (1997) <doi:10.1023/A:1003114420352>\n    B. Efron, and Tibshirani, R. (1993, ISBN:9780429246593)\n    Bickel, P. J., G\u00f6tze, F. and van Zwet, W. R. (1997) <doi:10.1007/978-1-4614-1314-1_17>\n    A. C. Davison, D. Hinkley (1997) <doi:10.2307/1271471>\n    Falk, M., & Reiss, R. D. (1989) <doi:10.1007/BF00354758>\n    Lahiri, S. N. (2003) <doi:10.1007/978-1-4757-3803-2>\n    Shimizu, K. .(2017) <doi:10.1007/978-3-8348-9778-7>\n    Park, J.Y. (2003) <doi:10.1111/1468-0262.00471>\n    Kirch, C. and Politis, D. N. (2011) <doi:10.48550/arXiv.1211.4732>\n    Bertail, P. and Dudek, A.E. (2024) <doi:10.3150/23-BEJ1683>\n    Dudek, A. E. (2015) <doi:10.1007/s00184-014-0505-9>\n    Dudek, A. E. (2018) <doi:10.1080/10485252.2017.1404060>\n    Bertail, P., Cl\u00e9men\u00e7on, S. (2006a) <https://ideas.repec.org/p/crs/wpaper/2004-47.html>\n    Bertail, P. and Cl\u00e9men\u00e7on, S. (2006, ISBN:978-0-387-36062-1)\n    Radulovi\u0107, D. (2006) <doi:10.1007/BF02603005>\n    Bertail, P. Politis, D. N. Rhomari, N. (2000) <doi:10.1080/02331880008802701>\n    Nordman, D.J. Lahiri, S.N.(2004) <doi:10.1214/009053604000000779>\n    Politis, D.N. Romano, J.P. (1993) <doi:10.1006/jmva.1993.1085>\n    Hurvich, C. M. and Zeger, S. L. (1987, ISBN:978-1-4612-0099-4)\n    Bertail, P. and Dudek, A. (2021) <doi:10.1214/20-EJS1787>\n    Bertail, P., Cl\u00e9men\u00e7on, S. and Tressou, J. (2015) <doi:10.1111/jtsa.12105>\n    Asmussen, S. (1987) <doi:10.1007/978-3-662-11657-9>\n    Efron, B. (1979) <doi:10.1214/aos/1176344552>\n    Gray, H., Schucany, W. and Watkins, T. (1972) <doi:10.2307/2335521>\n    Quenouille, M.H. (1949) <doi:10.1111/j.2517-6161.1949.tb00023.x>\n    Quenouille, M. H. (1956) <doi:10.2307/2332914>\n    Prakasa Rao, B. L. S. and Kulperger, R. J. (1989) <https://www.jstor.org/stable/25050735>\n    Rajarshi, M.B. (1990) <doi:10.1007/BF00050835>\n    Dudek, A.E. Maiz, S. and Elbadaoui, M. (2014) <doi:10.1016/j.sigpro.2014.04.022>\n    Beran R. (1986) <doi:10.1214/aos/1176349847>\n    Maritz, J. S. and Jarrett, R. G. (1978) <doi:10.2307/2286545>\n    Bertail, P., Politis, D., Romano, J. (1999) <doi:10.2307/2670177>\n    Bertail, P. and Cl\u00e9men\u00e7on, S. (2006b) <doi:10.1007/0-387-36062-X_1>\n    Radulovi\u0107, D. (2004) <doi:10.1007/BF02603005>\n    Hurd, H.L., Miamee, A.G. (2007) <doi:10.1002/9780470182833>\n    B\u00fchlmann, P. (1997) <doi:10.2307/3318584>\n    Choi, E., Hall, P. (2000) <doi:10.1111/1467-9868.00244>\n    Efron, B., Tibshirani, R. (1993, ISBN:9780429246593)\n    Bertail, P., Cl\u00e9men\u00e7on, S. and Tressou, J. (2009) <doi:10.1007/s10687-009-0081-y>\n    Bertail, P., Medina-Garay, A., De Lima-Medina, F. and Jales, I. (2024) <doi:10.1080/02331888.2024.2344670>.",
    "version": "0.1",
    "maintainer": "Karolina Marek <karolina.marek10@gmail.com>",
    "author": "Patrice Bertail [aut, ctb],\n  Bernard Desgraupes [aut],\n  Anna Dudek [aut, ctb],\n  Karolina Marek [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=boodd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "boodd Functions for the Book \"Bootstrap for Dependent Data, with an R\nPackage\" Companion package, functions, data sets, examples for the book \n        Patrice Bertail and Anna Dudek (2025), Bootstrap for Dependent Data, with an R package (by Bernard Desgraupes and Karolina Marek) - submitted.\n    Kreiss, J.-P. and Paparoditis, E. (2003) <doi:10.1214/aos/1074290332>\n    Politis, D.N., and White, H. (2004) <doi:10.1081/ETC-120028836>\n    Patton, A., Politis, D.N., and White, H. (2009) <doi:10.1080/07474930802459016>\n    Tsybakov, A. B. (2018) <doi:10.1007/b13794>\n    Bickel, P., and Sakov, A. (2008) <doi:10.1214/18-AOS1803>\n    G\u00f6tze, F. and Ra\u010dkauskas, A. (2001) <doi:10.1214/lnms/1215090074>\n    Politis, D. N., Romano, J. P., & Wolf, M. (1999, ISBN:978-0-387-98854-2)\n    Carlstein E. (1986) <doi:10.1214/aos/1176350057>\n    K\u00fcnsch, H. (1989) <doi:10.1214/aos/1176347265>\n    Liu, R. and Singh, K. (1992) <https://www.stat.purdue.edu/docs/research/tech-reports/1991/tr91-07.pdf>\n    Politis, D.N. and Romano, J.P. (1994) <doi:10.1080/01621459.1994.10476870>\n    Politis, D.N. and Romano, J.P. (1992) <https://www.stat.purdue.edu/docs/research/tech-reports/1991/tr91-07.pdf>\n    Patrice Bertail, Anna E. Dudek. (2022) <doi:10.3150/23-BEJ1683>\n    Dudek, A.E., Le\u015bkow, J., Paparoditis, E. and Politis, D. (2014a) <https://ideas.repec.org/a/bla/jtsera/v35y2014i2p89-114.html>\n    Beran, R. (1997) <doi:10.1023/A:1003114420352>\n    B. Efron, and Tibshirani, R. (1993, ISBN:9780429246593)\n    Bickel, P. J., G\u00f6tze, F. and van Zwet, W. R. (1997) <doi:10.1007/978-1-4614-1314-1_17>\n    A. C. Davison, D. Hinkley (1997) <doi:10.2307/1271471>\n    Falk, M., & Reiss, R. D. (1989) <doi:10.1007/BF00354758>\n    Lahiri, S. N. (2003) <doi:10.1007/978-1-4757-3803-2>\n    Shimizu, K. .(2017) <doi:10.1007/978-3-8348-9778-7>\n    Park, J.Y. (2003) <doi:10.1111/1468-0262.00471>\n    Kirch, C. and Politis, D. N. (2011) <doi:10.48550/arXiv.1211.4732>\n    Bertail, P. and Dudek, A.E. (2024) <doi:10.3150/23-BEJ1683>\n    Dudek, A. E. (2015) <doi:10.1007/s00184-014-0505-9>\n    Dudek, A. E. (2018) <doi:10.1080/10485252.2017.1404060>\n    Bertail, P., Cl\u00e9men\u00e7on, S. (2006a) <https://ideas.repec.org/p/crs/wpaper/2004-47.html>\n    Bertail, P. and Cl\u00e9men\u00e7on, S. (2006, ISBN:978-0-387-36062-1)\n    Radulovi\u0107, D. (2006) <doi:10.1007/BF02603005>\n    Bertail, P. Politis, D. N. Rhomari, N. (2000) <doi:10.1080/02331880008802701>\n    Nordman, D.J. Lahiri, S.N.(2004) <doi:10.1214/009053604000000779>\n    Politis, D.N. Romano, J.P. (1993) <doi:10.1006/jmva.1993.1085>\n    Hurvich, C. M. and Zeger, S. L. (1987, ISBN:978-1-4612-0099-4)\n    Bertail, P. and Dudek, A. (2021) <doi:10.1214/20-EJS1787>\n    Bertail, P., Cl\u00e9men\u00e7on, S. and Tressou, J. (2015) <doi:10.1111/jtsa.12105>\n    Asmussen, S. (1987) <doi:10.1007/978-3-662-11657-9>\n    Efron, B. (1979) <doi:10.1214/aos/1176344552>\n    Gray, H., Schucany, W. and Watkins, T. (1972) <doi:10.2307/2335521>\n    Quenouille, M.H. (1949) <doi:10.1111/j.2517-6161.1949.tb00023.x>\n    Quenouille, M. H. (1956) <doi:10.2307/2332914>\n    Prakasa Rao, B. L. S. and Kulperger, R. J. (1989) <https://www.jstor.org/stable/25050735>\n    Rajarshi, M.B. (1990) <doi:10.1007/BF00050835>\n    Dudek, A.E. Maiz, S. and Elbadaoui, M. (2014) <doi:10.1016/j.sigpro.2014.04.022>\n    Beran R. (1986) <doi:10.1214/aos/1176349847>\n    Maritz, J. S. and Jarrett, R. G. (1978) <doi:10.2307/2286545>\n    Bertail, P., Politis, D., Romano, J. (1999) <doi:10.2307/2670177>\n    Bertail, P. and Cl\u00e9men\u00e7on, S. (2006b) <doi:10.1007/0-387-36062-X_1>\n    Radulovi\u0107, D. (2004) <doi:10.1007/BF02603005>\n    Hurd, H.L., Miamee, A.G. (2007) <doi:10.1002/9780470182833>\n    B\u00fchlmann, P. (1997) <doi:10.2307/3318584>\n    Choi, E., Hall, P. (2000) <doi:10.1111/1467-9868.00244>\n    Efron, B., Tibshirani, R. (1993, ISBN:9780429246593)\n    Bertail, P., Cl\u00e9men\u00e7on, S. and Tressou, J. (2009) <doi:10.1007/s10687-009-0081-y>\n    Bertail, P., Medina-Garay, A., De Lima-Medina, F. and Jales, I. (2024) <doi:10.1080/02331888.2024.2344670>.  "
  },
  {
    "id": 9331,
    "package_name": "boot.heterogeneity",
    "title": "A Bootstrap-Based Heterogeneity Test for Meta-Analysis",
    "description": "Implements a bootstrap-based heterogeneity test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (or) in meta-analysis studies. Depending on the presence of moderators, this Monte Carlo based test can be implemented in the random- or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihoods, so installation of R package 'metafor' is required. This approach refers to the studies of Anscombe (1956) <doi:10.2307/2332926>, Haldane (1940) <doi:10.2307/2332614>, Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009). ",
    "version": "1.1.5",
    "maintainer": "Ge Jiang <gejiang2@illinois.edu>",
    "author": "Ge Jiang [aut, cre],\n  Han Du [aut],\n  Zijun Ke [ctb]",
    "url": "https://github.com/gabriellajg/boot.heterogeneity/",
    "bug_reports": "https://github.com/gabriellajg/boot.heterogeneity/issues",
    "repository": "https://cran.r-project.org/package=boot.heterogeneity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "boot.heterogeneity A Bootstrap-Based Heterogeneity Test for Meta-Analysis Implements a bootstrap-based heterogeneity test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (or) in meta-analysis studies. Depending on the presence of moderators, this Monte Carlo based test can be implemented in the random- or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihoods, so installation of R package 'metafor' is required. This approach refers to the studies of Anscombe (1956) <doi:10.2307/2332926>, Haldane (1940) <doi:10.2307/2332614>, Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009).   "
  },
  {
    "id": 9356,
    "package_name": "bossR",
    "title": "Biomarker Optimal Segmentation System",
    "description": "The Biomarker Optimal Segmentation System R package, 'bossR', is designed for precision medicine, helping to identify individual traits using biomarkers. It focuses on determining the most effective cutoff value for a continuous biomarker, which is crucial for categorizing patients into two groups with distinctly different clinical outcomes. The package simultaneously finds the optimal cutoff from given candidate values and tests its significance. Simulation studies demonstrate that 'bossR' offers statistical power and false positive control non-inferior to the permutation approach (considered the gold standard in this field), while being hundreds of times faster. ",
    "version": "1.0.4",
    "maintainer": "Xuekui Zhang <ubcxzhang@gmail.com>",
    "author": "Liuyi Lan [aut],\n  Xing Li [aut] (ORCID: <https://orcid.org/0000-0002-4186-7909>),\n  Xuanjin Cheng [aut],\n  Xuekui Zhang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4728-2343>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bossR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bossR Biomarker Optimal Segmentation System The Biomarker Optimal Segmentation System R package, 'bossR', is designed for precision medicine, helping to identify individual traits using biomarkers. It focuses on determining the most effective cutoff value for a continuous biomarker, which is crucial for categorizing patients into two groups with distinctly different clinical outcomes. The package simultaneously finds the optimal cutoff from given candidate values and tests its significance. Simulation studies demonstrate that 'bossR' offers statistical power and false positive control non-inferior to the permutation approach (considered the gold standard in this field), while being hundreds of times faster.   "
  },
  {
    "id": 9408,
    "package_name": "breakaway",
    "title": "Species Richness Estimation and Modeling",
    "description": "Understanding the drivers of microbial diversity is an important frontier of microbial ecology, and investigating the diversity of samples from microbial ecosystems is a common step in any microbiome analysis. 'breakaway' is the premier package for statistical analysis of microbial diversity. 'breakaway' implements the latest and greatest estimates of species richness, described in Willis and Bunge (2015) <doi:10.1111/biom.12332>, Willis et al. (2017) <doi:10.1111/rssc.12206>, and Willis (2016) <arXiv:1604.02598>, as well as the most commonly used estimates, including the objective Bayes approach described in Barger and Bunge (2010) <doi:10.1214/10-BA527>.",
    "version": "4.8.4",
    "maintainer": "Amy D Willis <adwillis@uw.edu>",
    "author": "Amy D Willis [aut, cre],\n  Bryan D Martin [aut],\n  Pauline Trinh [aut],\n  Sarah Teichman [aut],\n  David Clausen [aut],\n  Kathryn Barger [aut],\n  John Bunge [aut]",
    "url": "https://adw96.github.io/breakaway/",
    "bug_reports": "https://github.com/adw96/breakaway/issues",
    "repository": "https://cran.r-project.org/package=breakaway",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "breakaway Species Richness Estimation and Modeling Understanding the drivers of microbial diversity is an important frontier of microbial ecology, and investigating the diversity of samples from microbial ecosystems is a common step in any microbiome analysis. 'breakaway' is the premier package for statistical analysis of microbial diversity. 'breakaway' implements the latest and greatest estimates of species richness, described in Willis and Bunge (2015) <doi:10.1111/biom.12332>, Willis et al. (2017) <doi:10.1111/rssc.12206>, and Willis (2016) <arXiv:1604.02598>, as well as the most commonly used estimates, including the objective Bayes approach described in Barger and Bunge (2010) <doi:10.1214/10-BA527>.  "
  },
  {
    "id": 9428,
    "package_name": "brms.mmrm",
    "title": "Bayesian MMRMs using 'brms'",
    "description": "The mixed model for repeated measures (MMRM) is a popular\n  model for longitudinal clinical trial data with continuous endpoints,\n  and 'brms' is a powerful and versatile package for fitting Bayesian\n  regression models.  The 'brms.mmrm' R package leverages 'brms' to run\n  MMRMs, and it supports a simplified interfaced to reduce difficulty\n  and align with the best practices of the life sciences.  References:\n  B\u00fcrkner (2017) <doi:10.18637/jss.v080.i01>, Mallinckrodt (2008)\n  <doi:10.1177/009286150804200402>.",
    "version": "1.1.1",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1878-3253>),\n  Kevin Kunzmann [aut] (ORCID: <https://orcid.org/0000-0002-1140-7143>),\n  Yoni Sidi [aut],\n  Christian Stock [aut] (ORCID: <https://orcid.org/0000-0002-3493-3234>),\n  Eli Lilly and Company [cph, fnd],\n  Boehringer Ingelheim Pharma GmbH & Co. KG [cph, fnd]",
    "url": "https://openpharma.github.io/brms.mmrm/,\nhttps://github.com/openpharma/brms.mmrm",
    "bug_reports": "https://github.com/openpharma/brms.mmrm/issues",
    "repository": "https://cran.r-project.org/package=brms.mmrm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "brms.mmrm Bayesian MMRMs using 'brms' The mixed model for repeated measures (MMRM) is a popular\n  model for longitudinal clinical trial data with continuous endpoints,\n  and 'brms' is a powerful and versatile package for fitting Bayesian\n  regression models.  The 'brms.mmrm' R package leverages 'brms' to run\n  MMRMs, and it supports a simplified interfaced to reduce difficulty\n  and align with the best practices of the life sciences.  References:\n  B\u00fcrkner (2017) <doi:10.18637/jss.v080.i01>, Mallinckrodt (2008)\n  <doi:10.1177/009286150804200402>.  "
  },
  {
    "id": 9432,
    "package_name": "brolgar",
    "title": "Browse Over Longitudinal Data Graphically and Analytically in R",
    "description": "Provides a framework of tools to summarise, visualise, and explore \n  longitudinal data. It builds upon the tidy time series data frames used in the\n  'tsibble' package, and is designed to integrate within the 'tidyverse', and\n  'tidyverts' (for time series) ecosystems. The methods implemented include \n  calculating features for understanding longitudinal data, including \n  calculating summary statistics such as quantiles, medians, and numeric ranges,\n  sampling individual series, identifying individual series representative of a \n  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are\n  fully described in the paper \"brolgar: An R package to Browse Over \n  Longitudinal Data Graphically and Analytically in R\", Nicholas Tierney, \n  Dianne Cook, Tania Prvan (2020) <doi:10.32614/RJ-2022-023>.",
    "version": "1.0.2",
    "maintainer": "Nicholas Tierney <nicholas.tierney@gmail.com>",
    "author": "Nicholas Tierney [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1460-8722>),\n  Di Cook [aut] (ORCID: <https://orcid.org/0000-0002-3813-7155>),\n  Tania Prvan [aut],\n  Stuart Lee [ctb],\n  Earo Wang [ctb]",
    "url": "https://github.com/njtierney/brolgar,\nhttps://brolgar.njtierney.com/, http://brolgar.njtierney.com/",
    "bug_reports": "https://github.com/njtierney/brolgar/issues",
    "repository": "https://cran.r-project.org/package=brolgar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "brolgar Browse Over Longitudinal Data Graphically and Analytically in R Provides a framework of tools to summarise, visualise, and explore \n  longitudinal data. It builds upon the tidy time series data frames used in the\n  'tsibble' package, and is designed to integrate within the 'tidyverse', and\n  'tidyverts' (for time series) ecosystems. The methods implemented include \n  calculating features for understanding longitudinal data, including \n  calculating summary statistics such as quantiles, medians, and numeric ranges,\n  sampling individual series, identifying individual series representative of a \n  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are\n  fully described in the paper \"brolgar: An R package to Browse Over \n  Longitudinal Data Graphically and Analytically in R\", Nicholas Tierney, \n  Dianne Cook, Tania Prvan (2020) <doi:10.32614/RJ-2022-023>.  "
  },
  {
    "id": 9451,
    "package_name": "bsitar",
    "title": "Bayesian Super Imposition by Translation and Rotation Growth\nCurve Analysis",
    "description": "The Super Imposition by Translation and Rotation (SITAR) model \n    is a shape-invariant nonlinear mixed effect model that fits a natural cubic \n    spline mean curve to the growth data and aligns individual-specific growth \n    curves to the underlying mean curve via a set of random effects (see Cole, \n    2010 <doi:10.1093/ije/dyq115> for details). The non-Bayesian version of the \n    SITAR model can be fit by using the already available R package 'sitar'. While \n    the 'sitar' package allows modelling of a single outcome only, the 'bsitar' \n    package offers great flexibility in fitting models of varying complexities, \n    including joint modelling of multiple outcomes such as height and weight \n    (multivariate model). Additionally, the 'bsitar' package allows for the simultaneous  \n    analysis of an outcome separately for subgroups defined by a factor variable such \n    as gender. This is achieved by fitting separate models for each subgroup \n    (for example males and females for gender variable). An advantage of this approach \n    is that posterior draws for each subgroup are part of a single model object, \n    making it possible to compare coefficients across subgroups and test hypotheses. \n    Since the 'bsitar' package is a front-end to the R package 'brms', it offers excellent \n    support for post-processing of posterior draws via various functions that are \n    directly available from the 'brms' package. In addition, the 'bsitar' package \n    includes various customized functions that allow for the visualization of distance \n    (increase in size with age) and velocity (change in growth rate as a function of age), \n    as well as the estimation of growth spurt parameters such as age at peak growth velocity  \n    and peak growth velocity.",
    "version": "0.3.2",
    "maintainer": "Satpal Sandhu <satpal.sandhu@bristol.ac.uk>",
    "author": "Satpal Sandhu [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-8539-6897>)",
    "url": "https://github.com/Sandhu-SS/bsitar",
    "bug_reports": "https://github.com/Sandhu-SS/bsitar/issues",
    "repository": "https://cran.r-project.org/package=bsitar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsitar Bayesian Super Imposition by Translation and Rotation Growth\nCurve Analysis The Super Imposition by Translation and Rotation (SITAR) model \n    is a shape-invariant nonlinear mixed effect model that fits a natural cubic \n    spline mean curve to the growth data and aligns individual-specific growth \n    curves to the underlying mean curve via a set of random effects (see Cole, \n    2010 <doi:10.1093/ije/dyq115> for details). The non-Bayesian version of the \n    SITAR model can be fit by using the already available R package 'sitar'. While \n    the 'sitar' package allows modelling of a single outcome only, the 'bsitar' \n    package offers great flexibility in fitting models of varying complexities, \n    including joint modelling of multiple outcomes such as height and weight \n    (multivariate model). Additionally, the 'bsitar' package allows for the simultaneous  \n    analysis of an outcome separately for subgroups defined by a factor variable such \n    as gender. This is achieved by fitting separate models for each subgroup \n    (for example males and females for gender variable). An advantage of this approach \n    is that posterior draws for each subgroup are part of a single model object, \n    making it possible to compare coefficients across subgroups and test hypotheses. \n    Since the 'bsitar' package is a front-end to the R package 'brms', it offers excellent \n    support for post-processing of posterior draws via various functions that are \n    directly available from the 'brms' package. In addition, the 'bsitar' package \n    includes various customized functions that allow for the visualization of distance \n    (increase in size with age) and velocity (change in growth rate as a function of age), \n    as well as the estimation of growth spurt parameters such as age at peak growth velocity  \n    and peak growth velocity.  "
  },
  {
    "id": 9467,
    "package_name": "bsvarSIGNs",
    "title": "Bayesian SVARs with Sign, Zero, and Narrative Restrictions",
    "description": "Implements state-of-the-art algorithms for the Bayesian analysis of Structural Vector Autoregressions (SVARs) identified by sign, zero, and narrative restrictions. The core model is based on a flexible Vector Autoregression with estimated hyper-parameters of the Minnesota prior and the dummy observation priors as in Giannone, Lenza, Primiceri (2015) <doi:10.1162/REST_a_00483>. The sign restrictions are implemented employing the methods proposed by Rubio-Ram\u00edrez, Waggoner & Zha (2010) <doi:10.1111/j.1467-937X.2009.00578.x>, while identification through sign and zero restrictions follows the approach developed by Arias, Rubio-Ram\u00edrez, & Waggoner (2018) <doi:10.3982/ECTA14468>. Furthermore, our tool provides algorithms for identification via sign and narrative restrictions, in line with the methods introduced by Antol\u00edn-D\u00edaz and Rubio-Ram\u00edrez (2018) <doi:10.1257/aer.20161852>. Users can also estimate a model with sign, zero, and narrative restrictions imposed at once. The package facilitates predictive and structural analyses using impulse responses, forecast error variance and historical decompositions, forecasting and conditional forecasting, as well as analyses of structural shocks and fitted values. All this is complemented by colourful plots, user-friendly summary functions, and comprehensive documentation including the vignette by Wang & Wo\u017aniak (2024) <doi:10.48550/arXiv.2501.16711>. The 'bsvarSIGNs' package is aligned regarding objects, workflows, and code structure with the R package 'bsvars' by Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars>, and they constitute an integrated toolset. It was granted the Di Cook Open-Source Statistical Software Award by the Statistical Society of Australia in 2024.",
    "version": "2.0",
    "maintainer": "Xiaolei Wang <adamwang15@gmail.com>",
    "author": "Xiaolei Wang [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-6192-9061>),\n  Tomasz Wo\u017aniak [aut] (ORCID: <https://orcid.org/0000-0003-2212-2378>)",
    "url": "https://bsvars.org/bsvarSIGNs/",
    "bug_reports": "https://github.com/bsvars/bsvarSIGNs/issues",
    "repository": "https://cran.r-project.org/package=bsvarSIGNs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsvarSIGNs Bayesian SVARs with Sign, Zero, and Narrative Restrictions Implements state-of-the-art algorithms for the Bayesian analysis of Structural Vector Autoregressions (SVARs) identified by sign, zero, and narrative restrictions. The core model is based on a flexible Vector Autoregression with estimated hyper-parameters of the Minnesota prior and the dummy observation priors as in Giannone, Lenza, Primiceri (2015) <doi:10.1162/REST_a_00483>. The sign restrictions are implemented employing the methods proposed by Rubio-Ram\u00edrez, Waggoner & Zha (2010) <doi:10.1111/j.1467-937X.2009.00578.x>, while identification through sign and zero restrictions follows the approach developed by Arias, Rubio-Ram\u00edrez, & Waggoner (2018) <doi:10.3982/ECTA14468>. Furthermore, our tool provides algorithms for identification via sign and narrative restrictions, in line with the methods introduced by Antol\u00edn-D\u00edaz and Rubio-Ram\u00edrez (2018) <doi:10.1257/aer.20161852>. Users can also estimate a model with sign, zero, and narrative restrictions imposed at once. The package facilitates predictive and structural analyses using impulse responses, forecast error variance and historical decompositions, forecasting and conditional forecasting, as well as analyses of structural shocks and fitted values. All this is complemented by colourful plots, user-friendly summary functions, and comprehensive documentation including the vignette by Wang & Wo\u017aniak (2024) <doi:10.48550/arXiv.2501.16711>. The 'bsvarSIGNs' package is aligned regarding objects, workflows, and code structure with the R package 'bsvars' by Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvars>, and they constitute an integrated toolset. It was granted the Di Cook Open-Source Statistical Software Award by the Statistical Society of Australia in 2024.  "
  },
  {
    "id": 9468,
    "package_name": "bsvars",
    "title": "Bayesian Estimation of Structural Vector Autoregressive Models",
    "description": "Provides fast and efficient procedures for Bayesian analysis of Structural Vector Autoregressions. This package estimates a wide range of models, including homo-, heteroskedastic, and non-normal specifications. Structural models can be identified by adjustable exclusion restrictions, time-varying volatility, or non-normality. They all include a flexible three-level equation-specific local-global hierarchical prior distribution for the estimated level of shrinkage for autoregressive and structural parameters. Additionally, the package facilitates predictive and structural analyses such as impulse responses, forecast error variance and historical decompositions, forecasting, verification of heteroskedasticity, non-normality, and hypotheses on autoregressive parameters, as well as analyses of structural shocks, volatilities, and fitted values. Beautiful plots, informative summary functions, and extensive documentation including the vignette by Wo\u017aniak (2024) <doi:10.48550/arXiv.2410.15090> complement all this. The implemented techniques align closely with those presented in L\u00fctkepohl, Shang, Uzeda, & Wo\u017aniak (2024) <doi:10.48550/arXiv.2404.11057>, L\u00fctkepohl & Wo\u017aniak (2020) <doi:10.1016/j.jedc.2020.103862>, and Song & Wo\u017aniak (2021) <doi:10.1093/acrefore/9780190625979.013.174>. The 'bsvars' package is aligned regarding objects, workflows, and code structure with the R package 'bsvarSIGNs' by Wang & Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they constitute an integrated toolset.",
    "version": "3.2",
    "maintainer": "Tomasz Wo\u017aniak <wozniak.tom@pm.me>",
    "author": "Tomasz Wo\u017aniak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2212-2378>)",
    "url": "https://bsvars.org/bsvars/",
    "bug_reports": "https://github.com/bsvars/bsvars/issues",
    "repository": "https://cran.r-project.org/package=bsvars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bsvars Bayesian Estimation of Structural Vector Autoregressive Models Provides fast and efficient procedures for Bayesian analysis of Structural Vector Autoregressions. This package estimates a wide range of models, including homo-, heteroskedastic, and non-normal specifications. Structural models can be identified by adjustable exclusion restrictions, time-varying volatility, or non-normality. They all include a flexible three-level equation-specific local-global hierarchical prior distribution for the estimated level of shrinkage for autoregressive and structural parameters. Additionally, the package facilitates predictive and structural analyses such as impulse responses, forecast error variance and historical decompositions, forecasting, verification of heteroskedasticity, non-normality, and hypotheses on autoregressive parameters, as well as analyses of structural shocks, volatilities, and fitted values. Beautiful plots, informative summary functions, and extensive documentation including the vignette by Wo\u017aniak (2024) <doi:10.48550/arXiv.2410.15090> complement all this. The implemented techniques align closely with those presented in L\u00fctkepohl, Shang, Uzeda, & Wo\u017aniak (2024) <doi:10.48550/arXiv.2404.11057>, L\u00fctkepohl & Wo\u017aniak (2020) <doi:10.1016/j.jedc.2020.103862>, and Song & Wo\u017aniak (2021) <doi:10.1093/acrefore/9780190625979.013.174>. The 'bsvars' package is aligned regarding objects, workflows, and code structure with the R package 'bsvarSIGNs' by Wang & Wo\u017aniak (2024) <doi:10.32614/CRAN.package.bsvarSIGNs>, and they constitute an integrated toolset.  "
  },
  {
    "id": 9549,
    "package_name": "calendRio",
    "title": "'calendR' Fork with Additional Features (Backwards Compatible)",
    "description": "Fork of 'calendR' R package to generate ready to print\n  calendars with 'ggplot2' (see <https://r-coder.com/calendar-plot-r/>)\n  with additional features (backwards compatible).\n  'calendRio' provides a 'calendR()' function that serves as a drop-in\n  replacement for the upstream version but allows for additional\n  parameters unlocking extra functionality.",
    "version": "0.2.1",
    "maintainer": "Marcel Schilling <foss@mschilli.com>",
    "author": "Jos\u00e9 Carlos Soage Gonz\u00e1lez [aut, cph],\n  Natalia P\u00e9rez Veiga [aut, cph],\n  Marcel Schilling [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0002-3453-7792>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=calendRio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "calendRio 'calendR' Fork with Additional Features (Backwards Compatible) Fork of 'calendR' R package to generate ready to print\n  calendars with 'ggplot2' (see <https://r-coder.com/calendar-plot-r/>)\n  with additional features (backwards compatible).\n  'calendRio' provides a 'calendR()' function that serves as a drop-in\n  replacement for the upstream version but allows for additional\n  parameters unlocking extra functionality.  "
  },
  {
    "id": 9551,
    "package_name": "calibmsm",
    "title": "Calibration Plots for the Transition Probabilities from\nMultistate Models",
    "description": "Assess the calibration of an existing (i.e. previously developed) multistate\n  model through calibration plots. \n  Calibration is assessed using one of three methods. 1) Calibration methods for \n  binary logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 2) Calibration methods for \n  multinomial logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 3) Pseudo-values estimated using \n  the Aalen-Johansen estimator of observed risk. All methods are applied in conjunction\n  with landmarking when required. These calibration plots evaluate the calibration \n  (in a validation cohort of interest) of the transition probabilities estimated from an \n  existing multistate model. While package development has focused on multistate \n  models, calibration plots can be produced for any model which utilises information \n  post baseline to update predictions (e.g. dynamic models); competing risks models; \n  or standard single outcome survival models, where predictions can be made at \n  any landmark time. Please see Pate et al. (2024) <doi:10.1002/sim.10094>\n  and Pate et al. (2024) <https://alexpate30.github.io/calibmsm/articles/Overview.html>.",
    "version": "1.1.3",
    "maintainer": "Alexander Pate <alexander.pate@manchester.ac.uk>",
    "author": "Alexander Pate [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0849-3458>),\n  Glen P Martin [fnd, rev] (ORCID:\n    <https://orcid.org/0000-0002-3410-9472>)",
    "url": "https://github.com/alexpate30/calibmsm,\nhttps://alexpate30.github.io/calibmsm/",
    "bug_reports": "https://github.com/alexpate30/calibmsm/issues",
    "repository": "https://cran.r-project.org/package=calibmsm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "calibmsm Calibration Plots for the Transition Probabilities from\nMultistate Models Assess the calibration of an existing (i.e. previously developed) multistate\n  model through calibration plots. \n  Calibration is assessed using one of three methods. 1) Calibration methods for \n  binary logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 2) Calibration methods for \n  multinomial logistic regression models applied at a fixed time point in conjunction \n  with inverse probability of censoring weights. 3) Pseudo-values estimated using \n  the Aalen-Johansen estimator of observed risk. All methods are applied in conjunction\n  with landmarking when required. These calibration plots evaluate the calibration \n  (in a validation cohort of interest) of the transition probabilities estimated from an \n  existing multistate model. While package development has focused on multistate \n  models, calibration plots can be produced for any model which utilises information \n  post baseline to update predictions (e.g. dynamic models); competing risks models; \n  or standard single outcome survival models, where predictions can be made at \n  any landmark time. Please see Pate et al. (2024) <doi:10.1002/sim.10094>\n  and Pate et al. (2024) <https://alexpate30.github.io/calibmsm/articles/Overview.html>.  "
  },
  {
    "id": 9569,
    "package_name": "campsis",
    "title": "Generic PK/PD Simulation Platform CAMPSIS",
    "description": "A generic, easy-to-use and intuitive\n    pharmacokinetic/pharmacodynamic (PK/PD) simulation platform based on R\n    packages 'rxode2' and 'mrgsolve'. CAMPSIS provides an abstraction\n    layer over the underlying processes of writing a PK/PD model,\n    assembling a custom dataset and running a simulation. CAMPSIS has a\n    strong dependency to the R package 'campsismod', which allows to\n    read/write a model from/to files and adapt it further on the fly in\n    the R environment. Package 'campsis' allows the user to assemble a\n    dataset in an intuitive manner. Once the user\u2019s dataset is ready, the\n    package is in charge of preparing the simulation, calling 'rxode2' or\n    'mrgsolve' (at the user's choice) and returning the results, for the\n    given model, dataset and desired simulation settings.",
    "version": "1.7.0",
    "maintainer": "Nicolas Luyckx <nicolas.luyckx@calvagone.com>",
    "author": "Nicolas Luyckx [aut, cre]",
    "url": "https://github.com/Calvagone/campsis,\nhttps://calvagone.github.io/,\nhttps://calvagone.github.io/campsis.doc/",
    "bug_reports": "https://github.com/Calvagone/campsis/issues",
    "repository": "https://cran.r-project.org/package=campsis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "campsis Generic PK/PD Simulation Platform CAMPSIS A generic, easy-to-use and intuitive\n    pharmacokinetic/pharmacodynamic (PK/PD) simulation platform based on R\n    packages 'rxode2' and 'mrgsolve'. CAMPSIS provides an abstraction\n    layer over the underlying processes of writing a PK/PD model,\n    assembling a custom dataset and running a simulation. CAMPSIS has a\n    strong dependency to the R package 'campsismod', which allows to\n    read/write a model from/to files and adapt it further on the fly in\n    the R environment. Package 'campsis' allows the user to assemble a\n    dataset in an intuitive manner. Once the user\u2019s dataset is ready, the\n    package is in charge of preparing the simulation, calling 'rxode2' or\n    'mrgsolve' (at the user's choice) and returning the results, for the\n    given model, dataset and desired simulation settings.  "
  },
  {
    "id": 9584,
    "package_name": "canvasXpress.data",
    "title": "Datasets for the 'canvasXpress' Package",
    "description": "Contains the prepared data that is needed for the 'shiny' application examples in the \n    'canvasXpress' package.  This package also includes datasets used for automated 'testthat' tests.\n    Scotto L, Narayan G, Nandula SV, Arias-Pulido H et al. (2008) <doi:10.1002/gcc.20577>.\n    Davis S, Meltzer PS (2007) <doi:10.1093/bioinformatics/btm254>.",
    "version": "1.34.2",
    "maintainer": "Connie Brett <connie@aggregate-genius.com>",
    "author": "Isaac Neuhaus [aut],\n  Connie Brett [aut, cre],\n  Ger Inberg [aut]",
    "url": "https://github.com/neuhausi/canvasXpress.data",
    "bug_reports": "https://github.com/neuhausi/canvasXpress.data/issues",
    "repository": "https://cran.r-project.org/package=canvasXpress.data",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "canvasXpress.data Datasets for the 'canvasXpress' Package Contains the prepared data that is needed for the 'shiny' application examples in the \n    'canvasXpress' package.  This package also includes datasets used for automated 'testthat' tests.\n    Scotto L, Narayan G, Nandula SV, Arias-Pulido H et al. (2008) <doi:10.1002/gcc.20577>.\n    Davis S, Meltzer PS (2007) <doi:10.1093/bioinformatics/btm254>.  "
  },
  {
    "id": 9592,
    "package_name": "captain",
    "title": "Running 'git' Pre-Commit Hooks",
    "description": "Git hook scripts are useful for identifying simple issues before submission to code review. 'captain' (hook) is an R package to manage and run git pre-commit hooks.",
    "version": "1.1.1",
    "maintainer": "Alex Yahiaoui Martinez <yahiaoui-martinez.alex@outlook.com>",
    "author": "Alex Yahiaoui Martinez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5315-675X>)",
    "url": "https://github.com/alexym1/captain,\nhttps://alexym1.github.io/captain/",
    "bug_reports": "https://github.com/alexym1/captain/issues",
    "repository": "https://cran.r-project.org/package=captain",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "captain Running 'git' Pre-Commit Hooks Git hook scripts are useful for identifying simple issues before submission to code review. 'captain' (hook) is an R package to manage and run git pre-commit hooks.  "
  },
  {
    "id": 9617,
    "package_name": "cargo",
    "title": "Develop R Packages using Rust",
    "description": "A framework is provided to develop R packages using 'Rust' <https://www.rust-lang.org/> with\n minimal overhead, and more wrappers are easily added. Help is provided to use 'Cargo' <https://doc.rust-lang.org/cargo/> in a manner\n consistent with CRAN policies. 'Rust' code can also be embedded directly in an R script. The package is not official, affiliated with,\n nor endorsed by the Rust project.",
    "version": "0.4.9",
    "maintainer": "David B. Dahl <dahl@stat.byu.edu>",
    "author": "David B. Dahl [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8173-1547>)",
    "url": "https://github.com/dbdahl/cargo-framework (repository)",
    "bug_reports": "https://github.com/dbdahl/cargo-framework/issues",
    "repository": "https://cran.r-project.org/package=cargo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cargo Develop R Packages using Rust A framework is provided to develop R packages using 'Rust' <https://www.rust-lang.org/> with\n minimal overhead, and more wrappers are easily added. Help is provided to use 'Cargo' <https://doc.rust-lang.org/cargo/> in a manner\n consistent with CRAN policies. 'Rust' code can also be embedded directly in an R script. The package is not official, affiliated with,\n nor endorsed by the Rust project.  "
  },
  {
    "id": 9624,
    "package_name": "cartographer",
    "title": "Turn Place Names into Map Data",
    "description": "A tool for easily matching spatial data when you have a list of\n    place/region names. You might have a data frame that came from a\n    spreadsheet tracking some data by suburb or state. This package can\n    convert it into a spatial data frame ready for plotting. The actual map\n    data is provided by other packages (or your own code).",
    "version": "0.2.1",
    "maintainer": "Carl Suster <Carl.Suster@health.nsw.gov.au>",
    "author": "Carl Suster [aut, cre] (ORCID: <https://orcid.org/0000-0001-7021-9380>),\n  Western Sydney Local Health District, NSW Health [cph]",
    "url": "https://github.com/cidm-ph/cartographer,\nhttps://cidm-ph.github.io/cartographer/",
    "bug_reports": "https://github.com/cidm-ph/cartographer/issues",
    "repository": "https://cran.r-project.org/package=cartographer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cartographer Turn Place Names into Map Data A tool for easily matching spatial data when you have a list of\n    place/region names. You might have a data frame that came from a\n    spreadsheet tracking some data by suburb or state. This package can\n    convert it into a spatial data frame ready for plotting. The actual map\n    data is provided by other packages (or your own code).  "
  },
  {
    "id": 9652,
    "package_name": "catfun",
    "title": "Categorical Data Analysis",
    "description": "Includes wrapper functions around existing functions for the analysis of categorical data and introduces functions for calculating risk differences and matched odds ratios. R currently supports a wide variety of tools for the analysis of categorical data. However, many functions are spread across a variety of packages with differing syntax and poor compatibility with each another. prop_test() combines the functions binom.test(), prop.test() and BinomCI() into one output. prop_power() allows for power and sample size calculations for both balanced and unbalanced designs. riskdiff() is used for calculating risk differences and matched_or() is used for calculating matched odds ratios. For further information on methods used that are not documented in other packages see Nathan Mantel and William Haenszel (1959) <doi:10.1093/jnci/22.4.719> and Alan Agresti (2002) <ISBN:0-471-36093-7>. ",
    "version": "0.1.4",
    "maintainer": "Nick Williams <ntwilliams.personal@gmail.com>",
    "author": "Nick Williams",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=catfun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "catfun Categorical Data Analysis Includes wrapper functions around existing functions for the analysis of categorical data and introduces functions for calculating risk differences and matched odds ratios. R currently supports a wide variety of tools for the analysis of categorical data. However, many functions are spread across a variety of packages with differing syntax and poor compatibility with each another. prop_test() combines the functions binom.test(), prop.test() and BinomCI() into one output. prop_power() allows for power and sample size calculations for both balanced and unbalanced designs. riskdiff() is used for calculating risk differences and matched_or() is used for calculating matched odds ratios. For further information on methods used that are not documented in other packages see Nathan Mantel and William Haenszel (1959) <doi:10.1093/jnci/22.4.719> and Alan Agresti (2002) <ISBN:0-471-36093-7>.   "
  },
  {
    "id": 9739,
    "package_name": "ceas",
    "title": "Cellular Energetics Analysis Software",
    "description": "Measuring cellular energetics is essential to understanding a\n    matrix\u2019s (e.g. cell, tissue or biofluid) metabolic state. The Agilent\n    Seahorse machine is a common method to measure real-time cellular\n    energetics, but existing analysis tools are highly manual or lack\n    functionality. The Cellular Energetics Analysis Software (ceas) R package\n    fills this analytical gap by providing modular and automated Seahorse data\n    analysis and visualization using the methods described by Mookerjee et al.\n    (2017) <doi:10.1074/jbc.m116.774471>.",
    "version": "1.3.0",
    "maintainer": "Rachel House <rachel.house@vai.org>",
    "author": "Rachel House [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2176-0431>),\n  James P. Eapen [aut] (ORCID: <https://orcid.org/0000-0001-6016-3598>),\n  Hui Shen [fnd] (ORCID: <https://orcid.org/0000-0001-9767-4084>),\n  Carrie R. Graveel [fnd] (ORCID:\n    <https://orcid.org/0000-0001-7251-5642>),\n  Matthew R. Steensma [fnd] (ORCID:\n    <https://orcid.org/0000-0002-9003-6730>),\n  Van Andel Institute [cph]",
    "url": "https://jamespeapen.github.io/ceas/,\nhttps://github.com/jamespeapen/ceas/",
    "bug_reports": "https://github.com/jamespeapen/ceas/issues/",
    "repository": "https://cran.r-project.org/package=ceas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ceas Cellular Energetics Analysis Software Measuring cellular energetics is essential to understanding a\n    matrix\u2019s (e.g. cell, tissue or biofluid) metabolic state. The Agilent\n    Seahorse machine is a common method to measure real-time cellular\n    energetics, but existing analysis tools are highly manual or lack\n    functionality. The Cellular Energetics Analysis Software (ceas) R package\n    fills this analytical gap by providing modular and automated Seahorse data\n    analysis and visualization using the methods described by Mookerjee et al.\n    (2017) <doi:10.1074/jbc.m116.774471>.  "
  },
  {
    "id": 9810,
    "package_name": "changer",
    "title": "Change R Package Name",
    "description": "Changing the name of an existing R package is annoying but common task especially in the early stages of package development. This package (mostly) automates this task.",
    "version": "0.0.5",
    "maintainer": "Jouni Helske <jouni.helske@iki.fi>",
    "author": "Jouni Helske [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7130-793X>)",
    "url": "https://github.com/helske/changer",
    "bug_reports": "https://github.com/helske/changer/issues",
    "repository": "https://cran.r-project.org/package=changer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "changer Change R Package Name Changing the name of an existing R package is annoying but common task especially in the early stages of package development. This package (mostly) automates this task.  "
  },
  {
    "id": 9818,
    "package_name": "chatAI4R",
    "title": "Chat-Based Interactive Artificial Intelligence for R",
    "description": "The Large Language Model (LLM) represents a groundbreaking advancement \n    in data science and programming, and also allows us to extend the world of R. \n    A seamless interface for integrating the 'OpenAI' Web APIs into R is provided in this package. \n    This package leverages LLM-based AI techniques, enabling efficient knowledge discovery and data analysis \n    (see 'OpenAI' Web APIs details <https://openai.com/blog/openai-api>).\n    The previous functions such as seamless translation and image generation have been moved \n    to other packages 'deepRstudio' and 'stableDiffusion4R'.",
    "version": "0.3.6",
    "maintainer": "Satoshi Kume <satoshi.kume.1984@gmail.com>",
    "author": "Satoshi Kume [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7481-2843>)",
    "url": "https://kumes.github.io/chatAI4R/,\nhttps://github.com/kumeS/chatAI4R",
    "bug_reports": "https://github.com/kumeS/chatAI4R/issues",
    "repository": "https://cran.r-project.org/package=chatAI4R",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "chatAI4R Chat-Based Interactive Artificial Intelligence for R The Large Language Model (LLM) represents a groundbreaking advancement \n    in data science and programming, and also allows us to extend the world of R. \n    A seamless interface for integrating the 'OpenAI' Web APIs into R is provided in this package. \n    This package leverages LLM-based AI techniques, enabling efficient knowledge discovery and data analysis \n    (see 'OpenAI' Web APIs details <https://openai.com/blog/openai-api>).\n    The previous functions such as seamless translation and image generation have been moved \n    to other packages 'deepRstudio' and 'stableDiffusion4R'.  "
  },
  {
    "id": 9840,
    "package_name": "chem16S",
    "title": "Chemical Metrics for Microbial Communities",
    "description": "Combines taxonomic classifications of high-throughput 16S rRNA\n  gene sequences with reference proteomes of archaeal and bacterial taxa to\n  generate amino acid compositions of community reference proteomes. Calculates\n  chemical metrics including carbon oxidation state ('Zc'), stoichiometric\n  oxidation and hydration state ('nO2' and 'nH2O'), H/C, N/C, O/C, and S/C\n  ratios, grand average of hydropathicity ('GRAVY'), isoelectric point ('pI'),\n  protein length, and average molecular weight of amino acid residues. Uses\n  precomputed reference proteomes for archaea and bacteria derived from the\n  Genome Taxonomy Database ('GTDB'). Also includes reference proteomes derived\n  from the NCBI Reference Sequence ('RefSeq') database and manual mapping from\n  the 'RDP Classifier' training set to 'RefSeq' taxonomy as described by Dick and\n  Tan (2023) <doi:10.1007/s00248-022-01988-9>. Processes taxonomic\n  classifications in 'RDP Classifier' format or OTU tables in 'phyloseq-class'\n  objects from the Bioconductor package 'phyloseq'.",
    "version": "1.2.0",
    "maintainer": "Jeffrey Dick <j3ffdick@gmail.com>",
    "author": "Jeffrey Dick [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0687-5890>)",
    "url": "https://github.com/jedick/chem16S",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=chem16S",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "chem16S Chemical Metrics for Microbial Communities Combines taxonomic classifications of high-throughput 16S rRNA\n  gene sequences with reference proteomes of archaeal and bacterial taxa to\n  generate amino acid compositions of community reference proteomes. Calculates\n  chemical metrics including carbon oxidation state ('Zc'), stoichiometric\n  oxidation and hydration state ('nO2' and 'nH2O'), H/C, N/C, O/C, and S/C\n  ratios, grand average of hydropathicity ('GRAVY'), isoelectric point ('pI'),\n  protein length, and average molecular weight of amino acid residues. Uses\n  precomputed reference proteomes for archaea and bacteria derived from the\n  Genome Taxonomy Database ('GTDB'). Also includes reference proteomes derived\n  from the NCBI Reference Sequence ('RefSeq') database and manual mapping from\n  the 'RDP Classifier' training set to 'RefSeq' taxonomy as described by Dick and\n  Tan (2023) <doi:10.1007/s00248-022-01988-9>. Processes taxonomic\n  classifications in 'RDP Classifier' format or OTU tables in 'phyloseq-class'\n  objects from the Bioconductor package 'phyloseq'.  "
  },
  {
    "id": 9875,
    "package_name": "chores",
    "title": "A Collection of Large Language Model Assistants",
    "description": "Provides a collection of ergonomic large language model assistants \n    designed to help you complete repetitive, hard-to-automate tasks quickly. \n    After selecting some code, press the keyboard shortcut you've chosen to \n    trigger the package app, select an assistant, and watch your chore be \n    carried out. While the package ships with a number of chore helpers for R \n    package development, users can create custom helpers just by writing some\n    instructions in a markdown file.",
    "version": "0.3.0",
    "maintainer": "Simon Couch <simon.couch@posit.co>",
    "author": "Simon Couch [aut, cre] (ORCID: <https://orcid.org/0000-0001-5676-5107>),\n  Posit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://github.com/simonpcouch/chores,\nhttps://simonpcouch.github.io/chores/",
    "bug_reports": "https://github.com/simonpcouch/chores/issues",
    "repository": "https://cran.r-project.org/package=chores",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "chores A Collection of Large Language Model Assistants Provides a collection of ergonomic large language model assistants \n    designed to help you complete repetitive, hard-to-automate tasks quickly. \n    After selecting some code, press the keyboard shortcut you've chosen to \n    trigger the package app, select an assistant, and watch your chore be \n    carried out. While the package ships with a number of chore helpers for R \n    package development, users can create custom helpers just by writing some\n    instructions in a markdown file.  "
  },
  {
    "id": 9877,
    "package_name": "choroplethrAdmin1",
    "title": "Contains an Administrative-Level-1 Map of the World",
    "description": "Contains an administrative-level-1 map of the world.\n    Administrative-level-1 is the generic term for the largest sub-national\n    subdivision of a country. This package was created for use with the\n    choroplethr package.",
    "version": "1.1.1",
    "maintainer": "Ari Lamstein <ari@lamsteinconsulting.com>",
    "author": "Ari Lamstein <ari@lamsteinconsulting.com>",
    "url": "http://www.arilamstein.com/open-source",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=choroplethrAdmin1",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "choroplethrAdmin1 Contains an Administrative-Level-1 Map of the World Contains an administrative-level-1 map of the world.\n    Administrative-level-1 is the generic term for the largest sub-national\n    subdivision of a country. This package was created for use with the\n    choroplethr package.  "
  },
  {
    "id": 9992,
    "package_name": "clinify",
    "title": "Clinical Table Styling Tools and Utilities",
    "description": "The primary motivation of this package is to take the things that are great about the R packages 'flextable' <https://davidgohel.github.io/flextable/> and 'officer' <https://davidgohel.github.io/officer/>, take the standard and complex pieces of formatting clinical tables for regulatory use, and simplify the tedious pieces. ",
    "version": "0.3.0",
    "maintainer": "Mike Stackhouse <mike.stackhouse@atorusresearch.com>",
    "author": "Mike Stackhouse [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6030-723X>),\n  Ross Didenko [aut],\n  Yevhenii Boiko [aut],\n  Marat Zakirov [ctb],\n  Roman Rogoza [ctb],\n  Atorus Research, Inc. [cph],\n  Incyte Corporation [cph]",
    "url": "https://atorus-research.github.io/clinify/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=clinify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clinify Clinical Table Styling Tools and Utilities The primary motivation of this package is to take the things that are great about the R packages 'flextable' <https://davidgohel.github.io/flextable/> and 'officer' <https://davidgohel.github.io/officer/>, take the standard and complex pieces of formatting clinical tables for regulatory use, and simplify the tedious pieces.   "
  },
  {
    "id": 10049,
    "package_name": "clustermole",
    "title": "Unbiased Single-Cell Transcriptomic Data Cell Type\nIdentification",
    "description": "Assignment of cell type labels to single-cell RNA sequencing (scRNA-seq) clusters is often a time-consuming process that involves manual inspection of the cluster marker genes complemented with a detailed literature search. This is especially challenging when unexpected or poorly described populations are present. The clustermole R package provides methods to query thousands of human and mouse cell identity markers sourced from a variety of databases.",
    "version": "1.1.1",
    "maintainer": "Igor Dolgalev <igor.dolgalev@nyumc.org>",
    "author": "Igor Dolgalev [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4451-126X>)",
    "url": "https://igordot.github.io/clustermole/",
    "bug_reports": "https://github.com/igordot/clustermole/issues",
    "repository": "https://cran.r-project.org/package=clustermole",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clustermole Unbiased Single-Cell Transcriptomic Data Cell Type\nIdentification Assignment of cell type labels to single-cell RNA sequencing (scRNA-seq) clusters is often a time-consuming process that involves manual inspection of the cluster marker genes complemented with a detailed literature search. This is especially challenging when unexpected or poorly described populations are present. The clustermole R package provides methods to query thousands of human and mouse cell identity markers sourced from a variety of databases.  "
  },
  {
    "id": 10098,
    "package_name": "cnd",
    "title": "Create and Register Conditions",
    "description": "An interface for creating new condition generators objects.  \n    Generators are special functions that can be saved in registries and linked\n    to other functions.  Utilities for documenting your generators, and new\n    conditions is provided for package development.",
    "version": "0.1.1",
    "maintainer": "Jordan Mark Barbone <jmbarbone@gmail.com>",
    "author": "Jordan Mark Barbone [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-9788-3628>)",
    "url": "https://jmbarbone.github.io/cnd/, https://github.com/jmbarbone/cnd",
    "bug_reports": "https://github.com/jmbarbone/cnd/issues",
    "repository": "https://cran.r-project.org/package=cnd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cnd Create and Register Conditions An interface for creating new condition generators objects.  \n    Generators are special functions that can be saved in registries and linked\n    to other functions.  Utilities for documenting your generators, and new\n    conditions is provided for package development.  "
  },
  {
    "id": 10115,
    "package_name": "cocor",
    "title": "Comparing Correlations",
    "description": "Statistical tests for the comparison between two correlations based on either independent or dependent groups. Dependent correlations can either be overlapping or nonoverlapping. A web interface is available on the website <http://comparingcorrelations.org>. A plugin for the R GUI and IDE RKWard is included. Please install RKWard from <https://rkward.kde.org> to use this feature. The respective R package 'rkward' cannot be installed directly from a repository, as it is a part of RKWard.",
    "version": "1.1-4",
    "maintainer": "Birk Diedenhofen <mail@birkdiedenhofen.de>",
    "author": "Birk Diedenhofen [aut, cre]",
    "url": "http://comparingcorrelations.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cocor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cocor Comparing Correlations Statistical tests for the comparison between two correlations based on either independent or dependent groups. Dependent correlations can either be overlapping or nonoverlapping. A web interface is available on the website <http://comparingcorrelations.org>. A plugin for the R GUI and IDE RKWard is included. Please install RKWard from <https://rkward.kde.org> to use this feature. The respective R package 'rkward' cannot be installed directly from a repository, as it is a part of RKWard.  "
  },
  {
    "id": 10119,
    "package_name": "cocron",
    "title": "Statistical Comparisons of Two or more Alpha Coefficients",
    "description": "Statistical tests for the comparison between two or more alpha\n    coefficients based on either dependent or independent groups of individuals.\n    A web interface is available at http://comparingcronbachalphas.org. A plugin\n    for the R GUI and IDE RKWard is included. Please install RKWard from https://\n    rkward.kde.org to use this feature. The respective R package 'rkward' cannot be\n    installed directly from a repository, as it is a part of RKWard.",
    "version": "1.0-1",
    "maintainer": "Birk Diedenhofen <mail@birkdiedenhofen.de>",
    "author": "Birk Diedenhofen [aut, cre]",
    "url": "http://comparingcronbachalphas.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cocron",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cocron Statistical Comparisons of Two or more Alpha Coefficients Statistical tests for the comparison between two or more alpha\n    coefficients based on either dependent or independent groups of individuals.\n    A web interface is available at http://comparingcronbachalphas.org. A plugin\n    for the R GUI and IDE RKWard is included. Please install RKWard from https://\n    rkward.kde.org to use this feature. The respective R package 'rkward' cannot be\n    installed directly from a repository, as it is a part of RKWard.  "
  },
  {
    "id": 10136,
    "package_name": "codewhere",
    "title": "Find the Location of an R Package's Code",
    "description": "Find the location of the code for an R package based on the package's name or string representation.\n    Checks on 'CRAN' based on information in the 'URL' field or 'BioConductor' and 'GitHub' based on constructing \n    a URL, and verifies all paths via testing for a successful response. This can be useful when automating static \n    code analysis based on a list of package names, and similar tasks.",
    "version": "0.1.1",
    "maintainer": "Nic Crane <thisisnic@gmail.com>",
    "author": "Nic Crane [aut, cre, cph]",
    "url": "https://thisisnic.github.io/codewhere/,\nhttps://github.com/thisisnic/codewhere/",
    "bug_reports": "https://github.com/thisisnic/codewhere/issues",
    "repository": "https://cran.r-project.org/package=codewhere",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "codewhere Find the Location of an R Package's Code Find the location of the code for an R package based on the package's name or string representation.\n    Checks on 'CRAN' based on information in the 'URL' field or 'BioConductor' and 'GitHub' based on constructing \n    a URL, and verifies all paths via testing for a successful response. This can be useful when automating static \n    code analysis based on a list of package names, and similar tasks.  "
  },
  {
    "id": 10149,
    "package_name": "coffee",
    "title": "Chronological Ordering for Fossils and Environmental Events",
    "description": "While individual calibrated radiocarbon dates can span several centuries, combining multiple dates together with any chronological constraints can make a chronology much more robust and precise. This package uses Bayesian methods to enforce the chronological ordering of radiocarbon and other dates, for example for trees with multiple radiocarbon dates spaced at exactly known intervals (e.g., 10 annual rings). For methods see Christen 2003 <doi:10.11141/ia.13.2>. Another example is sites where the relative chronological position of the dates is taken into account - the ages of dates further down a site must be older than those of dates further up (Buck, Kenworthy, Litton and Smith 1991 <doi:10.1017/S0003598X00080534>; Nicholls and Jones 2001 <doi:10.1111/1467-9876.00250>). The paper accompanying this R package is Blaauw et al. 2024 <doi:10.1017/RDC.2024.56>.",
    "version": "0.4.3",
    "maintainer": "Maarten Blaauw <maarten.blaauw@qub.ac.uk>",
    "author": "Maarten Blaauw [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5680-1515>),\n  Marco A. Aquino Lopez [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-5076-7205>),\n  J. Andres Christen [aut, ctb, cph] (ORCID:\n    <https://orcid.org/0000-0002-5795-4345>)",
    "url": "https://github.com/Maarten14C/coffee",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=coffee",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "coffee Chronological Ordering for Fossils and Environmental Events While individual calibrated radiocarbon dates can span several centuries, combining multiple dates together with any chronological constraints can make a chronology much more robust and precise. This package uses Bayesian methods to enforce the chronological ordering of radiocarbon and other dates, for example for trees with multiple radiocarbon dates spaced at exactly known intervals (e.g., 10 annual rings). For methods see Christen 2003 <doi:10.11141/ia.13.2>. Another example is sites where the relative chronological position of the dates is taken into account - the ages of dates further down a site must be older than those of dates further up (Buck, Kenworthy, Litton and Smith 1991 <doi:10.1017/S0003598X00080534>; Nicholls and Jones 2001 <doi:10.1111/1467-9876.00250>). The paper accompanying this R package is Blaauw et al. 2024 <doi:10.1017/RDC.2024.56>.  "
  },
  {
    "id": 10170,
    "package_name": "collections",
    "title": "High Performance Container Data Types",
    "description": "Provides high performance container data types such\n    as queues, stacks, deques, dicts and ordered dicts. Benchmarks\n    <https://randy3k.github.io/collections/articles/benchmark.html> have\n    shown that these containers are asymptotically more efficient than\n    those offered by other packages.",
    "version": "0.3.9",
    "maintainer": "Randy Lai <randy.cs.lai@gmail.com>",
    "author": "Randy Lai [aut, cre],\n  Andrea Mazzoleni [cph] (tommy hash table library),\n  Yann Collet [cph] (xxhash algorithm)",
    "url": "https://github.com/randy3k/collections/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=collections",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "collections High Performance Container Data Types Provides high performance container data types such\n    as queues, stacks, deques, dicts and ordered dicts. Benchmarks\n    <https://randy3k.github.io/collections/articles/benchmark.html> have\n    shown that these containers are asymptotically more efficient than\n    those offered by other packages.  "
  },
  {
    "id": 10173,
    "package_name": "collidr",
    "title": "Check for Namespace Collisions Across Packages and Functions on\nCRAN",
    "description": "Check for namespace collisions between a string input (your function or package name) \n    and half a million packages and functions on CRAN.",
    "version": "0.1.3",
    "maintainer": "Steve Condylios <steve.condylios@gmail.com>",
    "author": "Steve Condylios [aut, cre] (<https://orcid.org/0000-0003-0599-844X>)",
    "url": "https://github.com/collidrpackage/collidr",
    "bug_reports": "https://github.com/collidrpackage/collidr/issues",
    "repository": "https://cran.r-project.org/package=collidr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "collidr Check for Namespace Collisions Across Packages and Functions on\nCRAN Check for namespace collisions between a string input (your function or package name) \n    and half a million packages and functions on CRAN.  "
  },
  {
    "id": 10191,
    "package_name": "colorfast",
    "title": "Fast Conversion of R Colors to Color Component Values and Native\nPacked Integer Format",
    "description": "Color values in R are often represented as strings of hexadecimal\n    colors or named colors.  This package offers fast conversion of \n    these color representations to either an array of red/green/blue/alpha values\n    or to the packed integer format used in native raster objects.  Functions\n    for conversion are also exported at the 'C' level for use in other packages.\n    This fast conversion\n    of colors is implemented using an order-preserving minimal perfect hash\n    derived from Majewski et al (1996) \"A Family of Perfect Hashing Methods\" \n    <doi:10.1093/comjnl/39.6.547>.",
    "version": "1.0.1",
    "maintainer": "Mike Cheng <mikefc@coolbutuseless.com>",
    "author": "Mike Cheng [aut, cre, cph]",
    "url": "https://github.com/coolbutuseless/colorfast",
    "bug_reports": "https://github.com/coolbutuseless/colorfast/issues",
    "repository": "https://cran.r-project.org/package=colorfast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "colorfast Fast Conversion of R Colors to Color Component Values and Native\nPacked Integer Format Color values in R are often represented as strings of hexadecimal\n    colors or named colors.  This package offers fast conversion of \n    these color representations to either an array of red/green/blue/alpha values\n    or to the packed integer format used in native raster objects.  Functions\n    for conversion are also exported at the 'C' level for use in other packages.\n    This fast conversion\n    of colors is implemented using an order-preserving minimal perfect hash\n    derived from Majewski et al (1996) \"A Family of Perfect Hashing Methods\" \n    <doi:10.1093/comjnl/39.6.547>.  "
  },
  {
    "id": 10232,
    "package_name": "commonsMath",
    "title": "JAR Files of the Apache Commons Mathematics Library",
    "description": "'Java' JAR files for the Apache Commons Mathematics Library for use by users and other packages.",
    "version": "1.2.8",
    "maintainer": "David B. Dahl <dahl@stat.byu.edu>",
    "author": "David B. Dahl [cre] (ORCID: <https://orcid.org/0000-0002-8173-1547>),\n  The Apache Software Foundation [aut, cph]",
    "url": "https://github.com/dbdahl/commonsMath",
    "bug_reports": "https://github.com/dbdahl/commonsMath/issues",
    "repository": "https://cran.r-project.org/package=commonsMath",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "commonsMath JAR Files of the Apache Commons Mathematics Library 'Java' JAR files for the Apache Commons Mathematics Library for use by users and other packages.  "
  },
  {
    "id": 10244,
    "package_name": "compareMCMCs",
    "title": "Compare MCMC Efficiency from 'nimble' and/or Other MCMC Engines",
    "description": "Manages comparison of MCMC performance metrics from multiple MCMC algorithms. These may come from different MCMC configurations using the 'nimble' package or from other packages. Plug-ins for JAGS via 'rjags' and Stan via 'rstan' are provided. It is possible to write plug-ins for other packages. Performance metrics are held in an MCMCresult class along with samples and timing data. It is easy to apply new performance metrics. Reports are generated as html pages with figures comparing sets of runs. It is possible to configure the html pages, including providing new figure components.",
    "version": "0.6.0",
    "maintainer": "Perry de Valpine <pdevalpine@berkeley.edu>",
    "author": "Perry de Valpine [aut, cre],\n  Sally Paganin [aut],\n  Daniel Turek [aut],\n  Christopher Paciorek [aut]",
    "url": "https://github.com/nimble-dev/compareMCMCs",
    "bug_reports": "https://github.com/nimble-dev/compareMCMCs/issues",
    "repository": "https://cran.r-project.org/package=compareMCMCs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "compareMCMCs Compare MCMC Efficiency from 'nimble' and/or Other MCMC Engines Manages comparison of MCMC performance metrics from multiple MCMC algorithms. These may come from different MCMC configurations using the 'nimble' package or from other packages. Plug-ins for JAGS via 'rjags' and Stan via 'rstan' are provided. It is possible to write plug-ins for other packages. Performance metrics are held in an MCMCresult class along with samples and timing data. It is easy to apply new performance metrics. Reports are generated as html pages with figures comparing sets of runs. It is possible to configure the html pages, including providing new figure components.  "
  },
  {
    "id": 10286,
    "package_name": "conditionalProbNspades",
    "title": "Conditional Probabilities of Distributions Across Hearts Hands",
    "description": "Provides some tabulated data to be be referred to in a discussion in a vignette accompanying my upcoming R package 'playWholeHandDriverPassParams'. In addition to that specific purpose, these may also provide data and illustrate some computational approaches that are relevant to card games like hearts or bridge.This package refers to authentic data from Gregory Stoll <https://gregstoll.com/~gregstoll/bridge/math.html>, and details of performing the probability calculations from Jeremy L. Martin <https://jlmartin.ku.edu/~jlmartin/bridge/basics.pdf>.",
    "version": "1.0",
    "maintainer": "Barry Zeeberg <barryz2013@gmail.com>",
    "author": "Barry Zeeberg [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=conditionalProbNspades",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "conditionalProbNspades Conditional Probabilities of Distributions Across Hearts Hands Provides some tabulated data to be be referred to in a discussion in a vignette accompanying my upcoming R package 'playWholeHandDriverPassParams'. In addition to that specific purpose, these may also provide data and illustrate some computational approaches that are relevant to card games like hearts or bridge.This package refers to authentic data from Gregory Stoll <https://gregstoll.com/~gregstoll/bridge/math.html>, and details of performing the probability calculations from Jeremy L. Martin <https://jlmartin.ku.edu/~jlmartin/bridge/basics.pdf>.  "
  },
  {
    "id": 10306,
    "package_name": "confintr",
    "title": "Confidence Intervals",
    "description": "Calculates classic and/or bootstrap confidence intervals for\n    many parameters such as the population mean, variance, interquartile\n    range (IQR), median absolute deviation (MAD), skewness, kurtosis,\n    Cramer's V, odds ratio, R-squared, quantiles (incl. median),\n    proportions, different types of correlation measures, difference in\n    means, quantiles and medians. Many of the classic confidence intervals\n    are described in Smithson, M. (2003, ISBN: 978-0761924999). Bootstrap\n    confidence intervals are calculated with the R package 'boot'. Both\n    one- and two-sided intervals are supported.",
    "version": "1.0.2",
    "maintainer": "Michael Mayer <mayermichael79@gmail.com>",
    "author": "Michael Mayer [aut, cre]",
    "url": "https://github.com/mayer79/confintr",
    "bug_reports": "https://github.com/mayer79/confintr/issues",
    "repository": "https://cran.r-project.org/package=confintr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "confintr Confidence Intervals Calculates classic and/or bootstrap confidence intervals for\n    many parameters such as the population mean, variance, interquartile\n    range (IQR), median absolute deviation (MAD), skewness, kurtosis,\n    Cramer's V, odds ratio, R-squared, quantiles (incl. median),\n    proportions, different types of correlation measures, difference in\n    means, quantiles and medians. Many of the classic confidence intervals\n    are described in Smithson, M. (2003, ISBN: 978-0761924999). Bootstrap\n    confidence intervals are calculated with the R package 'boot'. Both\n    one- and two-sided intervals are supported.  "
  },
  {
    "id": 10316,
    "package_name": "conjoint",
    "title": "An Implementation of Conjoint Analysis Method",
    "description": "This is a simple R package that allows to measure the stated preferences using traditional conjoint analysis method.",
    "version": "1.42",
    "maintainer": "Tomasz Bartlomowicz <tomasz.bartlomowicz@ue.wroc.pl>",
    "author": "Andrzej Bak [aut],\n  Tomasz Bartlomowicz [aut, cre]",
    "url": "https://github.com/packagesR/conjoint",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=conjoint",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "conjoint An Implementation of Conjoint Analysis Method This is a simple R package that allows to measure the stated preferences using traditional conjoint analysis method.  "
  },
  {
    "id": 10330,
    "package_name": "conquestr",
    "title": "An R Package to Extend 'ACER ConQuest'",
    "description": "Extends 'ACER ConQuest' through a family of functions\n    designed to improve graphical outputs and help with advanced analysis\n    (e.g., differential item functioning).  Allows R users to call \n    'ACER ConQuest' from within R and read 'ACER ConQuest' System Files\n    (generated by the command `put` <https://conquestmanual.acer.org/s4-00.html#put>).\n    Requires 'ACER ConQuest' version 5.40 or later. \n    A demonstration version can be downloaded from <https://shop.acer.org/acer-conquest-5.html>.",
    "version": "1.5.5",
    "maintainer": "Dan Cloney <dan.cloney@acer.org>",
    "author": "Dan Cloney [aut, cre] (ORCID: <https://orcid.org/0000-0002-2130-237X>),\n  Ray Adams [aut]",
    "url": "https://www.acer.org/au/conquest, https://conquestmanual.acer.org,\nhttps://shop.acer.org/acer-conquest-5.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=conquestr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "conquestr An R Package to Extend 'ACER ConQuest' Extends 'ACER ConQuest' through a family of functions\n    designed to improve graphical outputs and help with advanced analysis\n    (e.g., differential item functioning).  Allows R users to call \n    'ACER ConQuest' from within R and read 'ACER ConQuest' System Files\n    (generated by the command `put` <https://conquestmanual.acer.org/s4-00.html#put>).\n    Requires 'ACER ConQuest' version 5.40 or later. \n    A demonstration version can be downloaded from <https://shop.acer.org/acer-conquest-5.html>.  "
  },
  {
    "id": 10401,
    "package_name": "coreSim",
    "title": "Core Functionality for Simulating Quantities of Interest from\nGeneralised Linear Models",
    "description": "Core functions for simulating quantities of interest\n    from generalised linear models (GLM). This package will form the backbone of\n    a series of other packages that improve the interpretation of GLM estimates.",
    "version": "0.2.4",
    "maintainer": "Christopher Gandrud <christopher.gandrud@gmail.com>",
    "author": "Christopher Gandrud [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/christophergandrud/coreSim/issues",
    "repository": "https://cran.r-project.org/package=coreSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "coreSim Core Functionality for Simulating Quantities of Interest from\nGeneralised Linear Models Core functions for simulating quantities of interest\n    from generalised linear models (GLM). This package will form the backbone of\n    a series of other packages that improve the interpretation of GLM estimates.  "
  },
  {
    "id": 10469,
    "package_name": "covatest",
    "title": "Tests on Properties of Space-Time Covariance Functions",
    "description": "Tests on properties of space-time covariance functions.\n    Tests on symmetry, separability and for assessing \n    different forms of non-separability are available. Moreover tests on \n    some classes of covariance functions, such that the classes of \n    product-sum models, Gneiting models and integrated product models have \n    been provided.  It is the companion R package to the papers of  \n    Cappello, C., De Iaco, S., Posa, D., 2018, Testing the type of non-separability \n    and some classes of space-time covariance function models <doi:10.1007/s00477-017-1472-2>\n    and Cappello, C., De Iaco, S., Posa, D., 2020, covatest: an R package for\n    selecting a class of space-time covariance functions <doi:10.18637/jss.v094.i01>.",
    "version": "1.2.4",
    "maintainer": "Sandra De Iaco <sandra.deiaco@unisalento.it>",
    "author": "Sandra De Iaco [aut, cre],\n  Claudia Cappello [aut],\n  Donato Posa [aut],\n  Sabrina Maggio [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=covatest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "covatest Tests on Properties of Space-Time Covariance Functions Tests on properties of space-time covariance functions.\n    Tests on symmetry, separability and for assessing \n    different forms of non-separability are available. Moreover tests on \n    some classes of covariance functions, such that the classes of \n    product-sum models, Gneiting models and integrated product models have \n    been provided.  It is the companion R package to the papers of  \n    Cappello, C., De Iaco, S., Posa, D., 2018, Testing the type of non-separability \n    and some classes of space-time covariance function models <doi:10.1007/s00477-017-1472-2>\n    and Cappello, C., De Iaco, S., Posa, D., 2020, covatest: an R package for\n    selecting a class of space-time covariance functions <doi:10.18637/jss.v094.i01>.  "
  },
  {
    "id": 10523,
    "package_name": "cpp4r",
    "title": "Header-Only 'C++' and 'R' Interface",
    "description": "Provides a header only, 'C++' interface to 'R' with enhancements over 'cpp11'. Enforces copy-on-write\n    semantics consistent with 'R' behavior. Offers native support for ALTREP objects, 'UTF-8' string handling, modern \n    'C++11' features and idioms, and reduced memory requirements. Allows for vendoring, making it useful for restricted\n    environments. Compared to 'cpp11', it adds support for converting 'C++' maps to 'R' lists, 'Roxygen' documentation\n    directly in 'C++' code, proper handling of matrix attributes, support for nullable external pointers, bidirectional\n    copy of complex number types, flexibility in type conversions, use of nullable pointers, and various performance\n    optimizations.",
    "version": "0.4.0",
    "maintainer": "Mauricio Vargas Sepulveda <m.vargas.sepulveda@gmail.com>",
    "author": "Mauricio Vargas Sepulveda [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1017-7574>),\n  Posit Software, PBC [aut] (Original cpp11 package)",
    "url": "https://cpp4r.org, https://github.com/pachadotdev/cpp4r",
    "bug_reports": "https://github.com/pachadotdev/cpp4r/issues",
    "repository": "https://cran.r-project.org/package=cpp4r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cpp4r Header-Only 'C++' and 'R' Interface Provides a header only, 'C++' interface to 'R' with enhancements over 'cpp11'. Enforces copy-on-write\n    semantics consistent with 'R' behavior. Offers native support for ALTREP objects, 'UTF-8' string handling, modern \n    'C++11' features and idioms, and reduced memory requirements. Allows for vendoring, making it useful for restricted\n    environments. Compared to 'cpp11', it adds support for converting 'C++' maps to 'R' lists, 'Roxygen' documentation\n    directly in 'C++' code, proper handling of matrix attributes, support for nullable external pointers, bidirectional\n    copy of complex number types, flexibility in type conversions, use of nullable pointers, and various performance\n    optimizations.  "
  },
  {
    "id": 10550,
    "package_name": "crc32c",
    "title": "Cyclic Redundancy Check with CPU-Specific Acceleration",
    "description": "Hardware-based support for 'CRC32C' cyclic redundancy checksum function\n  is made available for 'x86_64' systems with 'SSE2' support as well as for 'arm64', \n  and detected at build-time via 'cmake' with a software-based fallback.  This\n  functionality is exported at the 'C'-language level for use by other packages.\n  'CRC32C' is described in 'RFC 3270' at <https://datatracker.ietf.org/doc/html/rfc3720>\n  and is based on 'Castagnoli et al' <doi:10.1109/26.231911>.",
    "version": "0.0.3",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  The CRC32C Authors [aut] (See file src/crc32c/AUTHORS)",
    "url": "https://github.com/google/crc32c,\nhttps://github.com/eddelbuettel/crc32c",
    "bug_reports": "https://github.com/eddelbuettel/crc32c/issues",
    "repository": "https://cran.r-project.org/package=crc32c",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crc32c Cyclic Redundancy Check with CPU-Specific Acceleration Hardware-based support for 'CRC32C' cyclic redundancy checksum function\n  is made available for 'x86_64' systems with 'SSE2' support as well as for 'arm64', \n  and detected at build-time via 'cmake' with a software-based fallback.  This\n  functionality is exported at the 'C'-language level for use by other packages.\n  'CRC32C' is described in 'RFC 3270' at <https://datatracker.ietf.org/doc/html/rfc3720>\n  and is based on 'Castagnoli et al' <doi:10.1109/26.231911>.  "
  },
  {
    "id": 10558,
    "package_name": "crew",
    "title": "A Distributed Worker Launcher Framework",
    "description": "In computationally demanding analysis projects,\n  statisticians and data scientists asynchronously\n  deploy long-running tasks to distributed systems,\n  ranging from traditional clusters to cloud services.\n  The 'NNG'-powered 'mirai' R package by Gao (2023)\n  <doi:10.5281/zenodo.7912722> is a sleek\n  and sophisticated scheduler that\n  efficiently processes these intense workloads.\n  The 'crew' package extends 'mirai' with a unifying\n  interface for third-party worker launchers.\n  Inspiration also comes from packages.\n  'future' by Bengtsson (2021) <doi:10.32614/RJ-2021-048>,\n  'rrq' by FitzJohn and Ashton (2023) <https://github.com/mrc-ide/rrq>,\n  'clustermq' by Schubert (2019) <doi:10.1093/bioinformatics/btz284>),\n  and 'batchtools' by Lang, Bischel, and Surmann (2017)\n  <doi:10.21105/joss.00135>.",
    "version": "1.3.0",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1878-3253>),\n  Daniel Woodie [ctb],\n  Eli Lilly and Company [cph, fnd]",
    "url": "https://wlandau.github.io/crew/, https://github.com/wlandau/crew",
    "bug_reports": "https://github.com/wlandau/crew/issues",
    "repository": "https://cran.r-project.org/package=crew",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crew A Distributed Worker Launcher Framework In computationally demanding analysis projects,\n  statisticians and data scientists asynchronously\n  deploy long-running tasks to distributed systems,\n  ranging from traditional clusters to cloud services.\n  The 'NNG'-powered 'mirai' R package by Gao (2023)\n  <doi:10.5281/zenodo.7912722> is a sleek\n  and sophisticated scheduler that\n  efficiently processes these intense workloads.\n  The 'crew' package extends 'mirai' with a unifying\n  interface for third-party worker launchers.\n  Inspiration also comes from packages.\n  'future' by Bengtsson (2021) <doi:10.32614/RJ-2021-048>,\n  'rrq' by FitzJohn and Ashton (2023) <https://github.com/mrc-ide/rrq>,\n  'clustermq' by Schubert (2019) <doi:10.1093/bioinformatics/btz284>),\n  and 'batchtools' by Lang, Bischel, and Surmann (2017)\n  <doi:10.21105/joss.00135>.  "
  },
  {
    "id": 10687,
    "package_name": "cucumber",
    "title": "Behavior-Driven Development for R",
    "description": "Write executable specifications in a natural language that describes how your code should behave.\n    Write specifications in feature files using 'Gherkin' language and execute them using functions implemented in R.\n    Use them as an extension to your 'testthat' tests to provide a high level description of how your code works.",
    "version": "2.1.1",
    "maintainer": "Jakub Sobolewski <jakupsob@gmail.com>",
    "author": "Jakub Sobolewski [aut, cre]",
    "url": "https://github.com/jakubsob/cucumber,\nhttps://jakubsobolewski.com/cucumber/",
    "bug_reports": "https://github.com/jakubsob/cucumber/issues",
    "repository": "https://cran.r-project.org/package=cucumber",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cucumber Behavior-Driven Development for R Write executable specifications in a natural language that describes how your code should behave.\n    Write specifications in feature files using 'Gherkin' language and execute them using functions implemented in R.\n    Use them as an extension to your 'testthat' tests to provide a high level description of how your code works.  "
  },
  {
    "id": 10710,
    "package_name": "custom.gauss.quad",
    "title": "Custom Made Gauss Quadrature Nodes and Weights",
    "description": "\n    Use the high-precision arithmetic provided by the R package 'Rmpfr' \n    to compute a custom-made Gauss quadrature nodes and weights, \n    with up to 33 nodes, using a moment-based method via moment \n    determinants. Paul Kabaila (2022) <arXiv:2211.04729>.",
    "version": "1.0.0",
    "maintainer": "Paul Kabaila <p.kabaila@latrobe.edu.au>",
    "author": "Paul Kabaila [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9205-668X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=custom.gauss.quad",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "custom.gauss.quad Custom Made Gauss Quadrature Nodes and Weights \n    Use the high-precision arithmetic provided by the R package 'Rmpfr' \n    to compute a custom-made Gauss quadrature nodes and weights, \n    with up to 33 nodes, using a moment-based method via moment \n    determinants. Paul Kabaila (2022) <arXiv:2211.04729>.  "
  },
  {
    "id": 10719,
    "package_name": "cvAUC",
    "title": "Cross-Validated Area Under the ROC Curve Confidence Intervals",
    "description": "Tools for working with and evaluating cross-validated area under the ROC curve (AUC) estimators.  The primary functions of the package are ci.cvAUC and ci.pooled.cvAUC, which report cross-validated AUC and compute confidence intervals for cross-validated AUC estimates based on influence curves for i.i.d. and pooled repeated measures data, respectively.  One benefit to using influence curve based confidence intervals is that they require much less computation time than bootstrapping methods.  The utility functions, AUC and cvAUC, are simple wrappers for functions from the ROCR package.",
    "version": "1.1.4",
    "maintainer": "Erin LeDell <oss@ledell.org>",
    "author": "Erin LeDell, Maya Petersen, Mark van der Laan",
    "url": "https://github.com/ledell/cvAUC",
    "bug_reports": "https://github.com/ledell/cvAUC/issues",
    "repository": "https://cran.r-project.org/package=cvAUC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cvAUC Cross-Validated Area Under the ROC Curve Confidence Intervals Tools for working with and evaluating cross-validated area under the ROC curve (AUC) estimators.  The primary functions of the package are ci.cvAUC and ci.pooled.cvAUC, which report cross-validated AUC and compute confidence intervals for cross-validated AUC estimates based on influence curves for i.i.d. and pooled repeated measures data, respectively.  One benefit to using influence curve based confidence intervals is that they require much less computation time than bootstrapping methods.  The utility functions, AUC and cvAUC, are simple wrappers for functions from the ROCR package.  "
  },
  {
    "id": 10804,
    "package_name": "dartR.base",
    "title": "Analysing 'SNP' and 'Silicodart' Data - Basic Functions",
    "description": "Facilitates the import and analysis of 'SNP' (single nucleotide 'polymorphism') \n    and 'silicodart' (presence/absence) data. The main focus is on data generated by 'DarT' \n    (Diversity Arrays Technology), however, data from other sequencing platforms can be used \n    once 'SNP' or related fragment presence/absence data from any source is imported. Genetic \n    datasets are stored in a derived 'genlight' format (package 'adegenet'), that allows for \n    a very compact storage of data and metadata. Functions are available for \n    importing and exporting of 'SNP' and 'silicodart' data, for reporting on and \n    filtering on various criteria (e.g. 'callrate', 'heterozygosity', 'reproducibility', \n    maximum allele frequency). Additional functions are available for visualization \n    (e.g. Principle Coordinate Analysis) and creating a spatial representation \n    using maps. 'dartR.base' is the 'base' package of the 'dartRverse' suits of packages. \n    To install the other packages, we recommend to install the 'dartRverse' package, that \n    supports the installation of all packages in the 'dartRverse'.\n    If you want to cite 'dartR', you find the information by typing citation('dartR.base')\n    in the console.",
    "version": "1.0.7",
    "maintainer": "Bernd Gruber <bernd.gruber@canberra.edu.au>",
    "author": "Bernd Gruber [aut, cre],\n  Arthur Georges [aut],\n  Jose L. Mijangos [aut],\n  Carlo Pacioni [aut],\n  Diana Robledo-Ruiz [aut],\n  Peter J. Unmack [ctb],\n  Oliver Berry [ctb],\n  Lindsay V. Clark [ctb],\n  Floriaan Devloo-Delva [ctb],\n  Eric Archer [ctb],\n  Ching Ching Lau [ctb]",
    "url": "https://green-striped-gecko.github.io/dartR/",
    "bug_reports": "https://groups.google.com/g/dartr?pli=1",
    "repository": "https://cran.r-project.org/package=dartR.base",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dartR.base Analysing 'SNP' and 'Silicodart' Data - Basic Functions Facilitates the import and analysis of 'SNP' (single nucleotide 'polymorphism') \n    and 'silicodart' (presence/absence) data. The main focus is on data generated by 'DarT' \n    (Diversity Arrays Technology), however, data from other sequencing platforms can be used \n    once 'SNP' or related fragment presence/absence data from any source is imported. Genetic \n    datasets are stored in a derived 'genlight' format (package 'adegenet'), that allows for \n    a very compact storage of data and metadata. Functions are available for \n    importing and exporting of 'SNP' and 'silicodart' data, for reporting on and \n    filtering on various criteria (e.g. 'callrate', 'heterozygosity', 'reproducibility', \n    maximum allele frequency). Additional functions are available for visualization \n    (e.g. Principle Coordinate Analysis) and creating a spatial representation \n    using maps. 'dartR.base' is the 'base' package of the 'dartRverse' suits of packages. \n    To install the other packages, we recommend to install the 'dartRverse' package, that \n    supports the installation of all packages in the 'dartRverse'.\n    If you want to cite 'dartR', you find the information by typing citation('dartR.base')\n    in the console.  "
  },
  {
    "id": 10808,
    "package_name": "dartR.sexlinked",
    "title": "Analysing SNP Data to Identify Sex-Linked Markers",
    "description": "Identifies, filters and exports sex linked markers using 'SNP' \n    (single nucleotide polymorphism) data. To install the other packages, we \n    recommend to install the 'dartRverse' package, that supports the installation of all packages in the 'dartRverse'.\n    If you want understand the applied rational to identify sexlinked markers \n    and/or want to cite 'dartR.sexlinked', you find the information by typing \n    citation('dartR.sexlinked') in the console.",
    "version": "1.0.5",
    "maintainer": "Diana Robledo-Ruiz <diana.robledoruiz1@monash.edu>",
    "author": "Diana Robledo-Ruiz [aut, cre],\n  Floriaan Devloo-Delva [aut],\n  Bernd Gruber [aut],\n  Arthur Georges [aut],\n  Jose L. Mijangos [aut],\n  Carlo Pacioni [aut],\n  Peter J. Unmack [ctb],\n  Oliver Berry [ctb]",
    "url": "https://green-striped-gecko.github.io/dartR/",
    "bug_reports": "https://groups.google.com/g/dartr?pli=1",
    "repository": "https://cran.r-project.org/package=dartR.sexlinked",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dartR.sexlinked Analysing SNP Data to Identify Sex-Linked Markers Identifies, filters and exports sex linked markers using 'SNP' \n    (single nucleotide polymorphism) data. To install the other packages, we \n    recommend to install the 'dartRverse' package, that supports the installation of all packages in the 'dartRverse'.\n    If you want understand the applied rational to identify sexlinked markers \n    and/or want to cite 'dartR.sexlinked', you find the information by typing \n    citation('dartR.sexlinked') in the console.  "
  },
  {
    "id": 10861,
    "package_name": "dateback",
    "title": "Collect and Install R Packages on a Specified Date with\nDependencies",
    "description": "Works as a virtual CRAN snapshot for source packages.\n    It automatically downloads and installs 'tar.gz' files with dependencies,\n    all of which were available on a specific day.",
    "version": "1.0.5",
    "maintainer": "Ryota Suzuki <suzuki@ef-prime.com>",
    "author": "Ryota Suzuki <suzuki@ef-prime.com>",
    "url": "https://github.com/r-suzuki/dateback",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dateback",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dateback Collect and Install R Packages on a Specified Date with\nDependencies Works as a virtual CRAN snapshot for source packages.\n    It automatically downloads and installs 'tar.gz' files with dependencies,\n    all of which were available on a specific day.  "
  },
  {
    "id": 10881,
    "package_name": "dbarts",
    "title": "Discrete Bayesian Additive Regression Trees Sampler",
    "description": "Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/Metropolis-Hastings sampler. Also serves as a drop-in replacement for package 'BayesTree'.",
    "version": "0.9-32",
    "maintainer": "Vincent Dorie <vdorie@gmail.com>",
    "author": "Vincent Dorie [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9576-3064>),\n  Hugh Chipman [aut],\n  Robert McCulloch [aut],\n  Armon Dadgar [ctb] (adaptive radix tree),\n  R Core Team [ctb] (basis of RNG),\n  Guido U Draheim [ctb] (ax_check_compile_flag.m4),\n  Maarten Bosmans [ctb] (ax_check_compile_flag.m4),\n  Christophe Tournayre [ctb] (ax_compiler_ext.m4, ax_ext.m4),\n  Michael Petch [ctb] (ax_compiler_ext.m4, ax_ext.m4,\n    ax_gcc_x86_avx_xgetbv.m4, ax_gcc_x86_cpuid.m4),\n  Rafael de Lucena Valle [ctb] (ax_compiler_ext.m4, ax_ext.m4),\n  Steven G. Johnson [ctb] (ax_compiler_vendor.m4, ax_gcc_x86_cpuid.m4,\n    ax_pthread.m4, ORCID: <https://orcid.org/0000-0001-7327-4967>),\n  Matteo Frigo [ctb] (ax_compiler_vendor.m4, ax_gcc_x86_cpuid.m4),\n  John Zaitseff [ctb] (ax_compiler_vendor.m4),\n  Todd Veldhuizen [ctb] (ax_cxx_namespace_std.m4),\n  Luc Maisonobe [ctb] (ax_cxx_namespace_std.m4),\n  Scott Pakin [ctb] (ax_func_posix_memalign.m4, ORCID:\n    <https://orcid.org/0000-0002-5220-1985>),\n  Daniel Richard G. [ctb] (ax_pthread.m4)",
    "url": "https://github.com/vdorie/dbarts",
    "bug_reports": "https://github.com/vdorie/dbarts/issues",
    "repository": "https://cran.r-project.org/package=dbarts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dbarts Discrete Bayesian Additive Regression Trees Sampler Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/Metropolis-Hastings sampler. Also serves as a drop-in replacement for package 'BayesTree'.  "
  },
  {
    "id": 10908,
    "package_name": "dcmle",
    "title": "Hierarchical Models Made Easy with Data Cloning",
    "description": "S4 classes around infrastructure provided by the\n    'coda' and 'dclone' packages to make package development easy as a breeze\n    with data cloning for hierarchical models.",
    "version": "0.4-2",
    "maintainer": "Peter Solymos <psolymos@gmail.com>",
    "author": "Peter Solymos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7337-1740>)",
    "url": "https://groups.google.com/forum/#!forum/dclone-users,\nhttps://datacloning.org, https://github.com/datacloning/dcmle",
    "bug_reports": "https://github.com/datacloning/dcmle/issues",
    "repository": "https://cran.r-project.org/package=dcmle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dcmle Hierarchical Models Made Easy with Data Cloning S4 classes around infrastructure provided by the\n    'coda' and 'dclone' packages to make package development easy as a breeze\n    with data cloning for hierarchical models.  "
  },
  {
    "id": 10965,
    "package_name": "deepdep",
    "title": "Visualise and Explore the Deep Dependencies of R Packages",
    "description": "Provides tools for exploration of R package dependencies. \n    The main deepdep() function allows to acquire deep dependencies of any package and plot them in an elegant way.\n    It also adds some popularity measures for the packages e.g. in the form of download count through the 'cranlogs' package. \n    Uses the CRAN metadata database <http://crandb.r-pkg.org> and Bioconductor metadata <https://bioconductor.org>.\n    Other data acquire functions are: get_dependencies(), get_downloads() and get_description(). \n    The deepdep_shiny() function runs shiny application that helps to produce a nice 'deepdep' plot. ",
    "version": "0.4.4",
    "maintainer": "Dominik Rafacz <dominikrafacz@gmail.com>",
    "author": "Dominik Rafacz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0925-1909>),\n  Hubert Baniecki [aut],\n  Szymon Maksymiuk [aut],\n  Laura Bakala [aut],\n  Dirk Eddelbuettel [ctb]",
    "url": "https://dominikrafacz.github.io/deepdep/,\nhttps://github.com/DominikRafacz/deepdep",
    "bug_reports": "https://github.com/DominikRafacz/deepdep/issues",
    "repository": "https://cran.r-project.org/package=deepdep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deepdep Visualise and Explore the Deep Dependencies of R Packages Provides tools for exploration of R package dependencies. \n    The main deepdep() function allows to acquire deep dependencies of any package and plot them in an elegant way.\n    It also adds some popularity measures for the packages e.g. in the form of download count through the 'cranlogs' package. \n    Uses the CRAN metadata database <http://crandb.r-pkg.org> and Bioconductor metadata <https://bioconductor.org>.\n    Other data acquire functions are: get_dependencies(), get_downloads() and get_description(). \n    The deepdep_shiny() function runs shiny application that helps to produce a nice 'deepdep' plot.   "
  },
  {
    "id": 10992,
    "package_name": "deltaPlotR",
    "title": "Identification of Dichotomous Differential Item Functioning\n(DIF) using Angoff's Delta Plot Method",
    "description": "The deltaPlotR package implements Angoff's Delta Plot method to detect dichotomous DIF. Several detection thresholds are included, either from multivariate normality assumption or by prior determination. Item purification is supported (Magis and Facon (2014) <doi:10.18637/jss.v059.c01>).",
    "version": "1.6",
    "maintainer": "David Magis <david.magis@ulg.ac.be>",
    "author": "David Magis (U Liege), Bruno Facon (Univ Lille-Nord de France)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=deltaPlotR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deltaPlotR Identification of Dichotomous Differential Item Functioning\n(DIF) using Angoff's Delta Plot Method The deltaPlotR package implements Angoff's Delta Plot method to detect dichotomous DIF. Several detection thresholds are included, either from multivariate normality assumption or by prior determination. Item purification is supported (Magis and Facon (2014) <doi:10.18637/jss.v059.c01>).  "
  },
  {
    "id": 11003,
    "package_name": "demulticoder",
    "title": "Simultaneous Analysis of Multiplexed Metabarcodes",
    "description": "A comprehensive set of wrapper functions for the analysis of multiplex metabarcode data. It includes robust wrappers for 'Cutadapt' and 'DADA2' to trim primers, filter reads, perform amplicon sequence variant (ASV) inference, and assign taxonomy. The package can handle single metabarcode datasets, datasets with two pooled metabarcodes, or multiple datasets simultaneously. The final output is a matrix per metabarcode, containing both ASV abundance data and associated taxonomic assignments. An optional function converts these matrices into 'phyloseq' and 'taxmap' objects. For more information on 'DADA2', including information on how DADA2 infers samples sequences, see Callahan et al. (2016) <doi:10.1038/nmeth.3869>. For more details on the demulticoder R package see Sudermann et al. (2025) <doi:10.1094/PHYTO-02-25-0043-FI>.",
    "version": "0.1.2",
    "maintainer": "Martha A. Sudermann <sudermam@oregonstate.edu>",
    "author": "Martha A. Sudermann [aut, cre, cph],\n  Zachary S. L Foster [aut],\n  Samantha Dawson [aut],\n  Hung Phan [aut],\n  Jeff H. Chang [aut],\n  Niklaus Gr\u00fcnwald [aut, cph]",
    "url": "https://grunwaldlab.github.io/demulticoder/,\nhttps://github.com/grunwaldlab/demulticoder",
    "bug_reports": "https://github.com/grunwaldlab/demulticoder/issues",
    "repository": "https://cran.r-project.org/package=demulticoder",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "demulticoder Simultaneous Analysis of Multiplexed Metabarcodes A comprehensive set of wrapper functions for the analysis of multiplex metabarcode data. It includes robust wrappers for 'Cutadapt' and 'DADA2' to trim primers, filter reads, perform amplicon sequence variant (ASV) inference, and assign taxonomy. The package can handle single metabarcode datasets, datasets with two pooled metabarcodes, or multiple datasets simultaneously. The final output is a matrix per metabarcode, containing both ASV abundance data and associated taxonomic assignments. An optional function converts these matrices into 'phyloseq' and 'taxmap' objects. For more information on 'DADA2', including information on how DADA2 infers samples sequences, see Callahan et al. (2016) <doi:10.1038/nmeth.3869>. For more details on the demulticoder R package see Sudermann et al. (2025) <doi:10.1094/PHYTO-02-25-0043-FI>.  "
  },
  {
    "id": 11009,
    "package_name": "dendrometry",
    "title": "Forest Estimations and Dendrometric Computations",
    "description": "Computation of dendrometric and structural parameters from forest inventory data. The objective is to provide a user-friendly R package for researchers, ecologists, foresters, statisticians, loggers and other persons who deal with forest inventory data. The package includes advanced distribution fitting capabilities with multiple estimation methods (Maximum Likelihood, Maximum Product Spacing with ties correction methods following Cheng & Amin (1983), and Method of Moments) for probability distributions commonly used in forestry. Visualization tools with confidence bands using delta method and parametric bootstrap are provided for three-parameter Weibull distribution fitting to diameter data. Useful conversion of angle value from degree to radian, conversion from angle to slope (in percentage) and their reciprocals as well as principal angle determination are also included. Position and dispersion parameters usually found in forest studies are implemented. The package contains Fibonacci series, its extensions and the Golden Number computation. Useful references are Arcadius Y. J. Akossou, Soufianou Arzouma, Eloi Y. Attakpa, No\u00ebl H. Fonton and Kouami Kokou (2013) <doi:10.3390/d5010099>, W. Bonou, R. Glele Kaka\u00ef, A.E. Assogbadjo, H.N. Fonton, B. Sinsin (2009) <doi:10.1016/j.foreco.2009.05.032>, R. C. H. Cheng and N. A. K. Amin (1983) <doi:10.1111/j.2517-6161.1983.tb01268.x>, and R. C. H. Cheng and M. A. Stephens (1989) <doi:10.1093/biomet/76.2.385>.",
    "version": "0.0.4",
    "maintainer": "Narcisse Yehouenou <narcisstar211@gmail.com>",
    "author": "Narcisse Yehouenou [aut, cre],\n  Information and Communication Technology for you ONG (ICT4U-ONG) [fnd]",
    "url": "",
    "bug_reports": "https://github.com/narcisstar/dendrometry-issues/issues",
    "repository": "https://cran.r-project.org/package=dendrometry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dendrometry Forest Estimations and Dendrometric Computations Computation of dendrometric and structural parameters from forest inventory data. The objective is to provide a user-friendly R package for researchers, ecologists, foresters, statisticians, loggers and other persons who deal with forest inventory data. The package includes advanced distribution fitting capabilities with multiple estimation methods (Maximum Likelihood, Maximum Product Spacing with ties correction methods following Cheng & Amin (1983), and Method of Moments) for probability distributions commonly used in forestry. Visualization tools with confidence bands using delta method and parametric bootstrap are provided for three-parameter Weibull distribution fitting to diameter data. Useful conversion of angle value from degree to radian, conversion from angle to slope (in percentage) and their reciprocals as well as principal angle determination are also included. Position and dispersion parameters usually found in forest studies are implemented. The package contains Fibonacci series, its extensions and the Golden Number computation. Useful references are Arcadius Y. J. Akossou, Soufianou Arzouma, Eloi Y. Attakpa, No\u00ebl H. Fonton and Kouami Kokou (2013) <doi:10.3390/d5010099>, W. Bonou, R. Glele Kaka\u00ef, A.E. Assogbadjo, H.N. Fonton, B. Sinsin (2009) <doi:10.1016/j.foreco.2009.05.032>, R. C. H. Cheng and N. A. K. Amin (1983) <doi:10.1111/j.2517-6161.1983.tb01268.x>, and R. C. H. Cheng and M. A. Stephens (1989) <doi:10.1093/biomet/76.2.385>.  "
  },
  {
    "id": 11012,
    "package_name": "denim",
    "title": "Generate and Simulate Deterministic Compartmental Models",
    "description": "R package to build and simulate deterministic compartmental models that can be non-Markovian. Length of stay in each compartment can be defined to follow a parametric distribution (d_exponential(), d_gamma(), d_weibull(), d_lognormal()) or a non-parametric distribution (nonparametric()). Other supported types of transition from one compartment to another includes fixed transition (constant()), multinomial (multinomial()), fixed transition probability (transprob()).",
    "version": "1.2.2",
    "maintainer": "Anh Phan <anhptq@oucru.org>",
    "author": "Thinh Ong [aut, cph] (ORCID: <https://orcid.org/0000-0001-6772-9291>),\n  Anh Phan [aut, cre] (ORCID: <https://orcid.org/0009-0000-2129-435X>),\n  Marc Choisy [aut] (ORCID: <https://orcid.org/0000-0002-5187-6390>),\n  Niels Lohman [ctb],\n  Bjoern Hoehrmann [ctb],\n  Florian Loitsch [ctb],\n  Ingo Berg [ctb]",
    "url": "https://drthinhong.com/denim/, https://github.com/thinhong/denim",
    "bug_reports": "https://github.com/thinhong/denim/issues",
    "repository": "https://cran.r-project.org/package=denim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "denim Generate and Simulate Deterministic Compartmental Models R package to build and simulate deterministic compartmental models that can be non-Markovian. Length of stay in each compartment can be defined to follow a parametric distribution (d_exponential(), d_gamma(), d_weibull(), d_lognormal()) or a non-parametric distribution (nonparametric()). Other supported types of transition from one compartment to another includes fixed transition (constant()), multinomial (multinomial()), fixed transition probability (transprob()).  "
  },
  {
    "id": 11034,
    "package_name": "deps",
    "title": "Dependency Management with 'roxygen'-Style Comments",
    "description": "Manage your source code dependencies\n  by decorating your existing R code with special,\n  'roxygen'-style comments.",
    "version": "0.4.0",
    "maintainer": "Peter Solymos <peter@analythium.io>",
    "author": "Peter Solymos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7337-1740>),\n  Analythium Solutions Inc. [cph, fnd]",
    "url": "https://hub.analythium.io/deps/,\nhttps://github.com/analythium/deps",
    "bug_reports": "https://github.com/analythium/deps/issues",
    "repository": "https://cran.r-project.org/package=deps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deps Dependency Management with 'roxygen'-Style Comments Manage your source code dependencies\n  by decorating your existing R code with special,\n  'roxygen'-style comments.  "
  },
  {
    "id": 11045,
    "package_name": "descstatsr",
    "title": "Descriptive Univariate Statistics",
    "description": "It generates summary statistics on the input dataset using different descriptive univariate \n    statistical measures on entire data or at a group level. Though there are other packages which does \n    similar job but each of these are deficient in one form or other, in the measures generated, in\n    treating numeric, character and date variables alike, no functionality to view these measures on a\n    group level or the way the output is represented. Given the foremost role of the descriptive statistics\n    in any of the exploratory data analysis or solution development, there is a need for a more constructive, \n    structured and refined version over these packages. This is the idea behind the package and it brings \n    together all the required descriptive measures to give an initial understanding of the data quality, \n    distribution in a faster,easier and elaborative way.The function brings an additional capability to be \n    able to generate these statistical measures on the entire dataset or at a group level. It calculates measures \n    of central tendency (mean, median), distribution (count, proportion), dispersion (min, max, quantile, \n    standard deviation, variance) and shape (skewness, kurtosis). Addition to these measures, it provides information on \n    the data type, count on no. of rows, unique entries and percentage of missing entries. More importantly the measures \n    are generated based on the data types as required by them,rather than applying numerical measures on character and \n    data variables and vice versa. Output as a dataframe object gives a very neat representation, which often is useful \n    when working with a large number of columns. It can easily be exported as csv and analyzed further or presented as a \n    summary report for the data.",
    "version": "0.1.0",
    "maintainer": "Harish Kumar <kadamatiharish@gmail.com>",
    "author": "Harish Kumar",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=descstatsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "descstatsr Descriptive Univariate Statistics It generates summary statistics on the input dataset using different descriptive univariate \n    statistical measures on entire data or at a group level. Though there are other packages which does \n    similar job but each of these are deficient in one form or other, in the measures generated, in\n    treating numeric, character and date variables alike, no functionality to view these measures on a\n    group level or the way the output is represented. Given the foremost role of the descriptive statistics\n    in any of the exploratory data analysis or solution development, there is a need for a more constructive, \n    structured and refined version over these packages. This is the idea behind the package and it brings \n    together all the required descriptive measures to give an initial understanding of the data quality, \n    distribution in a faster,easier and elaborative way.The function brings an additional capability to be \n    able to generate these statistical measures on the entire dataset or at a group level. It calculates measures \n    of central tendency (mean, median), distribution (count, proportion), dispersion (min, max, quantile, \n    standard deviation, variance) and shape (skewness, kurtosis). Addition to these measures, it provides information on \n    the data type, count on no. of rows, unique entries and percentage of missing entries. More importantly the measures \n    are generated based on the data types as required by them,rather than applying numerical measures on character and \n    data variables and vice versa. Output as a dataframe object gives a very neat representation, which often is useful \n    when working with a large number of columns. It can easily be exported as csv and analyzed further or presented as a \n    summary report for the data.  "
  },
  {
    "id": 11061,
    "package_name": "details",
    "title": "Create Details HTML Tag for Markdown and Package Documentation",
    "description": "Create a details HTML tag around R objects to place\n    in a Markdown, 'Rmarkdown' and 'roxygen2' documentation.",
    "version": "0.4.0",
    "maintainer": "Jonathan Sidi <yonicd@gmail.com>",
    "author": "Jonathan Sidi [aut, cre]",
    "url": "https://github.com/yonicd/details",
    "bug_reports": "https://github.com/yonicd/details/issues",
    "repository": "https://cran.r-project.org/package=details",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "details Create Details HTML Tag for Markdown and Package Documentation Create a details HTML tag around R objects to place\n    in a Markdown, 'Rmarkdown' and 'roxygen2' documentation.  "
  },
  {
    "id": 11062,
    "package_name": "detect",
    "title": "Analyzing Wildlife Data with Detection Error",
    "description": "Models for analyzing site occupancy and count data models\n  with detection error, including \n  single-visit based models (Lele et al. 2012 <doi:10.1093/jpe/rtr042>, \n  Moreno et al. 2010 <doi:10.1890/09-1073.1>,\n  Solymos et al. 2012 <doi:10.1002/env.1149>,\n  Denes et al. 2016 <doi:10.1111/1365-2664.12818>),\n  conditional distance sampling and time-removal models (QPAD)\n  (Solymos et al. 2013 <doi:10.1111/2041-210X.12106>,\n  Solymos et al. 2018 <doi:10.1650/CONDOR-18-32.1>),\n  and single bin QPAD (SQPAD) models\n  (Lele & Solymos 2025).\n  Package development was supported by the\n  Alberta Biodiversity Monitoring Institute\n  and the Boreal Avian Modelling Project.",
    "version": "0.5-0",
    "maintainer": "Peter Solymos <psolymos@gmail.com>",
    "author": "Peter Solymos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7337-1740>),\n  Monica Moreno [aut],\n  Subhash R. Lele [aut],\n  Steven L. Van Wilgenburg [ctb]",
    "url": "https://github.com/psolymos/detect",
    "bug_reports": "https://github.com/psolymos/detect/issues",
    "repository": "https://cran.r-project.org/package=detect",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "detect Analyzing Wildlife Data with Detection Error Models for analyzing site occupancy and count data models\n  with detection error, including \n  single-visit based models (Lele et al. 2012 <doi:10.1093/jpe/rtr042>, \n  Moreno et al. 2010 <doi:10.1890/09-1073.1>,\n  Solymos et al. 2012 <doi:10.1002/env.1149>,\n  Denes et al. 2016 <doi:10.1111/1365-2664.12818>),\n  conditional distance sampling and time-removal models (QPAD)\n  (Solymos et al. 2013 <doi:10.1111/2041-210X.12106>,\n  Solymos et al. 2018 <doi:10.1650/CONDOR-18-32.1>),\n  and single bin QPAD (SQPAD) models\n  (Lele & Solymos 2025).\n  Package development was supported by the\n  Alberta Biodiversity Monitoring Institute\n  and the Boreal Avian Modelling Project.  "
  },
  {
    "id": 11078,
    "package_name": "devianLM",
    "title": "Detecting Extremal Values in a Normal Linear Model",
    "description": "Provides a method to detect values poorly explained by a Gaussian linear model. The procedure is based on the maximum of the absolute value of the studentized residuals, which is a parameter-free statistic. This approach generalizes several procedures used to detect abnormal values during longitudinal monitoring of biological markers. For methodological details, see: Berthelot G., Sauli\u00e8re G., Dedecker J. (2025). \"DEViaN-LM An R Package for Detecting Abnormal Values in the Gaussian Linear Model\". HAL Id: hal-05230549. <https://hal.science/hal-05230549>. ",
    "version": "1.0.7",
    "maintainer": "Geoffroy Berthelot <geoffroy.berthelot@insep.fr>",
    "author": "Guillaume Sauliere [aut] (ORCID:\n    <https://orcid.org/0000-0001-8263-6456>),\n  Geoffroy Berthelot [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4036-6114>),\n  J\u00e9r\u00f4me Dedecker [aut] (ORCID: <https://orcid.org/0000-0002-8838-0356>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=devianLM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "devianLM Detecting Extremal Values in a Normal Linear Model Provides a method to detect values poorly explained by a Gaussian linear model. The procedure is based on the maximum of the absolute value of the studentized residuals, which is a parameter-free statistic. This approach generalizes several procedures used to detect abnormal values during longitudinal monitoring of biological markers. For methodological details, see: Berthelot G., Sauli\u00e8re G., Dedecker J. (2025). \"DEViaN-LM An R Package for Detecting Abnormal Values in the Gaussian Linear Model\". HAL Id: hal-05230549. <https://hal.science/hal-05230549>.   "
  },
  {
    "id": 11124,
    "package_name": "diceplot",
    "title": "High Dimensional Categorical Data Visualization",
    "description": "Easy visualization for datasets with more than two categorical variables and additional continuous variables. The package is particularly useful for exploring complex categorical data in the context of pathway analysis across multiple conditions. This package is now in maintenance-only mode and kept for legacy compatibility; for new projects and active development, please use the successor package 'ggdiceplot' (see <https://github.com/maflot/ggdiceplot> and <https://dice-and-domino-plot.readthedocs.io/en/latest/>).",
    "version": "0.2.2",
    "maintainer": "Matthias Flotho <matthias.flotho@ccb.uni-saarland.de>",
    "author": "Matthias Flotho [aut, cre] (ORCID:\n    <https://orcid.org/0009-0006-4374-0801>)",
    "url": "https://dice-and-domino-plot.readthedocs.io/en/latest/,\nhttps://github.com/maflot/Diceplot",
    "bug_reports": "https://github.com/maflot/Diceplot/issues",
    "repository": "https://cran.r-project.org/package=diceplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diceplot High Dimensional Categorical Data Visualization Easy visualization for datasets with more than two categorical variables and additional continuous variables. The package is particularly useful for exploring complex categorical data in the context of pathway analysis across multiple conditions. This package is now in maintenance-only mode and kept for legacy compatibility; for new projects and active development, please use the successor package 'ggdiceplot' (see <https://github.com/maflot/ggdiceplot> and <https://dice-and-domino-plot.readthedocs.io/en/latest/>).  "
  },
  {
    "id": 11143,
    "package_name": "diffeRenTES",
    "title": "Computation of TES-Based Cell Differentiation Trees",
    "description": "Computes the ATM (Attractor Transition Matrix) structure and\n    the tree-like structure describing the cell differentiation process\n    (based on the Threshold Ergodic Set concept introduced by Serra and\n    Villani), starting from the Boolean networks with synchronous updating\n    scheme of the 'BoolNet' R package. TESs (Threshold Ergodic Sets) are\n    the mathematical abstractions that represent the different cell types\n    arising during ontogenesis. TESs and the powerful model of biological\n    differentiation based on Boolean networks to which it belongs have\n    been firstly described in \"A Dynamical Model of Genetic Networks for\n    Cell Differentiation\" Villani M, Barbieri A, Serra R (2011) A\n    Dynamical Model of Genetic Networks for Cell Differentiation. PLOS ONE\n    6(3): e17703.",
    "version": "0.3.2",
    "maintainer": "Michele Braccini <braccini.michele@gmail.com>",
    "author": "Michele Braccini <braccini.michele@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=diffeRenTES",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diffeRenTES Computation of TES-Based Cell Differentiation Trees Computes the ATM (Attractor Transition Matrix) structure and\n    the tree-like structure describing the cell differentiation process\n    (based on the Threshold Ergodic Set concept introduced by Serra and\n    Villani), starting from the Boolean networks with synchronous updating\n    scheme of the 'BoolNet' R package. TESs (Threshold Ergodic Sets) are\n    the mathematical abstractions that represent the different cell types\n    arising during ontogenesis. TESs and the powerful model of biological\n    differentiation based on Boolean networks to which it belongs have\n    been firstly described in \"A Dynamical Model of Genetic Networks for\n    Cell Differentiation\" Villani M, Barbieri A, Serra R (2011) A\n    Dynamical Model of Genetic Networks for Cell Differentiation. PLOS ONE\n    6(3): e17703.  "
  },
  {
    "id": 11152,
    "package_name": "diffval",
    "title": "Vegetation Patterns",
    "description": "Find, visualize and explore patterns of differential taxa in\n    vegetation data (namely in a phytosociological table), using the\n    Differential Value (DiffVal). Patterns are searched through\n    mathematical optimization algorithms. Ultimately, Total Differential\n    Value (TDV) optimization aims at obtaining classifications of\n    vegetation data based on differential taxa, as in the traditional\n    geobotanical approach (Monteiro-Henriques 2025,\n    <doi:10.3897/VCS.140466>). The Gurobi optimizer, as well\n    as the R package 'gurobi', can be installed from\n    <https://www.gurobi.com/products/gurobi-optimizer/>.  The useful\n    vignette Gurobi Installation Guide, from package 'prioritizr', can be\n    found here:\n    <https://prioritizr.net/articles/gurobi_installation_guide.html>.",
    "version": "1.2.0",
    "maintainer": "Tiago Monteiro-Henriques <tmh.dev@icloud.com>",
    "author": "Tiago Monteiro-Henriques [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4206-0699>),\n  Jorge Orestes Cerdeira [aut] (ORCID:\n    <https://orcid.org/0000-0002-3814-7660>),\n  Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia, Portugal [fnd]\n    (<https://www.fct.pt/>)",
    "url": "https://point-veg.gitlab.io/diffval/",
    "bug_reports": "https://gitlab.com/point-veg/diffval/-/issues",
    "repository": "https://cran.r-project.org/package=diffval",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diffval Vegetation Patterns Find, visualize and explore patterns of differential taxa in\n    vegetation data (namely in a phytosociological table), using the\n    Differential Value (DiffVal). Patterns are searched through\n    mathematical optimization algorithms. Ultimately, Total Differential\n    Value (TDV) optimization aims at obtaining classifications of\n    vegetation data based on differential taxa, as in the traditional\n    geobotanical approach (Monteiro-Henriques 2025,\n    <doi:10.3897/VCS.140466>). The Gurobi optimizer, as well\n    as the R package 'gurobi', can be installed from\n    <https://www.gurobi.com/products/gurobi-optimizer/>.  The useful\n    vignette Gurobi Installation Guide, from package 'prioritizr', can be\n    found here:\n    <https://prioritizr.net/articles/gurobi_installation_guide.html>.  "
  },
  {
    "id": 11159,
    "package_name": "dimRed",
    "title": "A Framework for Dimensionality Reduction",
    "description": "A collection of dimensionality reduction\n    techniques from R packages and a common\n    interface for calling the methods.",
    "version": "0.2.7",
    "maintainer": "Guido Kraemer <guido.kraemer@uni-leipzig.de>",
    "author": "Guido Kraemer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4865-5041>)",
    "url": "https://www.guido-kraemer.com/software/dimred/",
    "bug_reports": "https://github.com/gdkrmr/dimRed/issues",
    "repository": "https://cran.r-project.org/package=dimRed",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dimRed A Framework for Dimensionality Reduction A collection of dimensionality reduction\n    techniques from R packages and a common\n    interface for calling the methods.  "
  },
  {
    "id": 11168,
    "package_name": "dipsaus",
    "title": "A Dipping Sauce for Data Analysis and Visualizations",
    "description": "Works as an \"add-on\" to packages like 'shiny', 'future', as well as \n    'rlang', and provides utility functions. Just like dipping sauce adding \n    flavors to potato chips or pita bread, 'dipsaus' for data analysis and \n    visualizations adds handy functions and enhancements to popular packages. \n    The goal is to provide simple solutions that are frequently asked for \n    online, such as how to synchronize 'shiny' inputs without freezing the app,\n    or how to get memory size on 'Linux' or 'MacOS' system. The enhancements \n    roughly fall into these four categories: 1. 'shiny' input widgets; 2. \n    high-performance computing using the 'future' package; 3. \n    modify R calls and convert among numbers, strings, and other objects. 4. \n    utility functions to get system information such like CPU chip-set, memory \n    limit, etc.",
    "version": "0.3.2",
    "maintainer": "Zhengjia Wang <dipterix.wang@gmail.com>",
    "author": "Zhengjia Wang [aut, cre],\n  John Magnotti [ctb] (Contributed to `rutabaga.R`),\n  Xiang Zhang [ctb] (Contributed to `rutabaga.R`)",
    "url": "https://github.com/dipterix/dipsaus, https://dipterix.org/dipsaus/",
    "bug_reports": "https://github.com/dipterix/dipsaus/issues",
    "repository": "https://cran.r-project.org/package=dipsaus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dipsaus A Dipping Sauce for Data Analysis and Visualizations Works as an \"add-on\" to packages like 'shiny', 'future', as well as \n    'rlang', and provides utility functions. Just like dipping sauce adding \n    flavors to potato chips or pita bread, 'dipsaus' for data analysis and \n    visualizations adds handy functions and enhancements to popular packages. \n    The goal is to provide simple solutions that are frequently asked for \n    online, such as how to synchronize 'shiny' inputs without freezing the app,\n    or how to get memory size on 'Linux' or 'MacOS' system. The enhancements \n    roughly fall into these four categories: 1. 'shiny' input widgets; 2. \n    high-performance computing using the 'future' package; 3. \n    modify R calls and convert among numbers, strings, and other objects. 4. \n    utility functions to get system information such like CPU chip-set, memory \n    limit, etc.  "
  },
  {
    "id": 11170,
    "package_name": "dipw",
    "title": "Debiased Inverse Propensity Score Weighting",
    "description": "Estimation of the average treatment effect when controlling for\n    high-dimensional confounders using debiased inverse propensity score\n    weighting (DIPW). DIPW relies on the propensity score following a sparse\n    logistic regression model, but the regression curves are not required to be\n    estimable. Despite this, our package also allows the users to estimate \n    the regression curves and take the estimated curves as input to our\n    methods. Details of the methodology can be found in Yuhao Wang and\n    Rajen D. Shah (2020) \"Debiased Inverse Propensity Score Weighting for\n    Estimation of Average Treatment Effects with High-Dimensional Confounders\"\n    <arXiv:2011.08661>. The package relies on the optimisation\n    software 'MOSEK' <https://www.mosek.com/> which must be installed separately;\n    see the documentation for 'Rmosek'. ",
    "version": "0.1.0",
    "maintainer": "Yuhao Wang <yuhaow.thu@gmail.com>",
    "author": "Yuhao Wang [cre, aut],\n  Rajen Shah [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dipw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dipw Debiased Inverse Propensity Score Weighting Estimation of the average treatment effect when controlling for\n    high-dimensional confounders using debiased inverse propensity score\n    weighting (DIPW). DIPW relies on the propensity score following a sparse\n    logistic regression model, but the regression curves are not required to be\n    estimable. Despite this, our package also allows the users to estimate \n    the regression curves and take the estimated curves as input to our\n    methods. Details of the methodology can be found in Yuhao Wang and\n    Rajen D. Shah (2020) \"Debiased Inverse Propensity Score Weighting for\n    Estimation of Average Treatment Effects with High-Dimensional Confounders\"\n    <arXiv:2011.08661>. The package relies on the optimisation\n    software 'MOSEK' <https://www.mosek.com/> which must be installed separately;\n    see the documentation for 'Rmosek'.   "
  },
  {
    "id": 11205,
    "package_name": "dispRity",
    "title": "Measuring Disparity",
    "description": "A modular package for measuring disparity (multidimensional space occupancy). Disparity can be calculated from any matrix defining a multidimensional space. The package provides a set of implemented metrics to measure properties of the space and allows users to provide and test their own metrics. The package also provides functions for looking at disparity in a serial way (e.g. disparity through time) or per groups as well as visualising the results. Finally, this package provides several statistical tests for disparity analysis.",
    "version": "1.9",
    "maintainer": "Thomas Guillerme <guillert@tcd.ie>",
    "author": "Thomas Guillerme [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4325-1275>),\n  Mark Puttick [aut, cph],\n  Jack Hatfield [aut, cph]",
    "url": "https://github.com/TGuillerme/dispRity",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dispRity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dispRity Measuring Disparity A modular package for measuring disparity (multidimensional space occupancy). Disparity can be calculated from any matrix defining a multidimensional space. The package provides a set of implemented metrics to measure properties of the space and allows users to provide and test their own metrics. The package also provides functions for looking at disparity in a serial way (e.g. disparity through time) or per groups as well as visualising the results. Finally, this package provides several statistical tests for disparity analysis.  "
  },
  {
    "id": 11211,
    "package_name": "disposables",
    "title": "Create Disposable R Packages for Testing",
    "description": "Create disposable R packages for testing.\n    You can create, install and load multiple R packages with a single\n    function call, and then unload, uninstall and destroy them with another\n    function call. This is handy when testing how some R code or an R package\n    behaves with respect to other packages.",
    "version": "1.0.3",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi",
    "url": "https://github.com/gaborcsardi/disposables",
    "bug_reports": "https://github.com/gaborcsardi/disposables/issues",
    "repository": "https://cran.r-project.org/package=disposables",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "disposables Create Disposable R Packages for Testing Create disposable R packages for testing.\n    You can create, install and load multiple R packages with a single\n    function call, and then unload, uninstall and destroy them with another\n    function call. This is handy when testing how some R code or an R package\n    behaves with respect to other packages.  "
  },
  {
    "id": 11231,
    "package_name": "distops",
    "title": "Usual Operations for Distance Matrices in R",
    "description": "It provides the subset operator for dist objects and a function to\n    compute medoid(s) that are fully parallelized leveraging the 'RcppParallel'\n    package. It also provides functions for package developers to easily\n    implement their own parallelized dist() function using a custom 'C++'-based\n    distance function.",
    "version": "0.1.0",
    "maintainer": "Aymeric Stamm <aymeric.stamm@cnrs.fr>",
    "author": "Aymeric Stamm [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8725-3654>)",
    "url": "https://github.com/lmjl-alea/distops,\nhttps://lmjl-alea.github.io/distops/",
    "bug_reports": "https://github.com/lmjl-alea/distops/issues",
    "repository": "https://cran.r-project.org/package=distops",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "distops Usual Operations for Distance Matrices in R It provides the subset operator for dist objects and a function to\n    compute medoid(s) that are fully parallelized leveraging the 'RcppParallel'\n    package. It also provides functions for package developers to easily\n    implement their own parallelized dist() function using a custom 'C++'-based\n    distance function.  "
  },
  {
    "id": 11250,
    "package_name": "diversityForest",
    "title": "Innovative Complex Split Procedures in Random Forests Through\nCandidate Split Sampling",
    "description": "Implementation of three methods based on the diversity forest (DF) algorithm \n  (Hornung, 2022, <doi:10.1007/s42979-021-00920-1>), a split-finding approach that \n  enables complex split procedures in random forests.\n  The package includes:\n    1. Interaction forests (IFs) (Hornung & Boulesteix, 2022, <doi:10.1016/j.csda.2022.107460>): \n    Model quantitative and qualitative interaction effects using bivariable splitting. \n    Come with the Effect Importance Measure (EIM), which can be used to identify variable \n    pairs that have well-interpretable quantitative and qualitative interaction effects \n    with high predictive relevance.\n\t2. Two random forest-based variable importance measures (VIMs) for multi-class outcomes: \n\tthe class-focused VIM, which ranks covariates by their ability to distinguish individual \n\toutcome classes from the others, and the discriminatory VIM, which measures overall \n\tcovariate influence irrespective of class-specific relevance.\n    3. The basic form of diversity forests that uses conventional univariable, binary \n    splitting (Hornung, 2022).\n  Except for the multi-class VIMs, all methods support categorical, metric, and survival \n  outcomes. The package includes visualization tools for interpreting the identified \n  covariate effects.\n  Built as a fork of the 'ranger' R package (main author: Marvin N. Wright), which \n  implements random forests using an efficient C++ implementation.",
    "version": "0.6.0",
    "maintainer": "Roman Hornung <hornung@ibe.med.uni-muenchen.de>",
    "author": "Roman Hornung [aut, cre],\n  Marvin N. Wright [ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=diversityForest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diversityForest Innovative Complex Split Procedures in Random Forests Through\nCandidate Split Sampling Implementation of three methods based on the diversity forest (DF) algorithm \n  (Hornung, 2022, <doi:10.1007/s42979-021-00920-1>), a split-finding approach that \n  enables complex split procedures in random forests.\n  The package includes:\n    1. Interaction forests (IFs) (Hornung & Boulesteix, 2022, <doi:10.1016/j.csda.2022.107460>): \n    Model quantitative and qualitative interaction effects using bivariable splitting. \n    Come with the Effect Importance Measure (EIM), which can be used to identify variable \n    pairs that have well-interpretable quantitative and qualitative interaction effects \n    with high predictive relevance.\n\t2. Two random forest-based variable importance measures (VIMs) for multi-class outcomes: \n\tthe class-focused VIM, which ranks covariates by their ability to distinguish individual \n\toutcome classes from the others, and the discriminatory VIM, which measures overall \n\tcovariate influence irrespective of class-specific relevance.\n    3. The basic form of diversity forests that uses conventional univariable, binary \n    splitting (Hornung, 2022).\n  Except for the multi-class VIMs, all methods support categorical, metric, and survival \n  outcomes. The package includes visualization tools for interpreting the identified \n  covariate effects.\n  Built as a fork of the 'ranger' R package (main author: Marvin N. Wright), which \n  implements random forests using an efficient C++ implementation.  "
  },
  {
    "id": 11258,
    "package_name": "diyar",
    "title": "Record Linkage and Epidemiological Case Definitions in 'R'",
    "description": "An R package for iterative and batched record linkage, \n    and applying epidemiological case definitions.\n    'diyar' can be used for deterministic and probabilistic record linkage, \n    or multistage record linkage combining both approaches.\n    It features the implementation of nested match criteria, and mechanisms to \n    address missing data and conflicting matches during stepwise record linkage.\n    Case definitions are implemented by assigning records to groups based on \n    match criteria such as person or place, and overlapping time or duration of \n    events e.g. sample collection dates or periods of hospital stays.\n    Matching records are assigned a unique group ID. Index and duplicate records \n    are removed or further analyses as required.  ",
    "version": "0.5.1",
    "maintainer": "Olisaeloka Nsonwu <olisa.nsonwu@gmail.com>",
    "author": "Olisaeloka Nsonwu",
    "url": "https://olisansonwu.github.io/diyar/index.html",
    "bug_reports": "https://github.com/OlisaNsonwu/diyar/issues",
    "repository": "https://cran.r-project.org/package=diyar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "diyar Record Linkage and Epidemiological Case Definitions in 'R' An R package for iterative and batched record linkage, \n    and applying epidemiological case definitions.\n    'diyar' can be used for deterministic and probabilistic record linkage, \n    or multistage record linkage combining both approaches.\n    It features the implementation of nested match criteria, and mechanisms to \n    address missing data and conflicting matches during stepwise record linkage.\n    Case definitions are implemented by assigning records to groups based on \n    match criteria such as person or place, and overlapping time or duration of \n    events e.g. sample collection dates or periods of hospital stays.\n    Matching records are assigned a unique group ID. Index and duplicate records \n    are removed or further analyses as required.    "
  },
  {
    "id": 11270,
    "package_name": "dlstats",
    "title": "Download Stats of R Packages",
    "description": "Monthly download stats of 'CRAN' and 'Bioconductor' packages.\n\t     Download stats of 'CRAN' packages is from the 'RStudio' 'CRAN mirror', see <https://cranlogs.r-pkg.org:443>.\n\t     'Bioconductor' package download stats is at <https://bioconductor.org/packages/stats/>.",
    "version": "0.1.7",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre]",
    "url": "https://github.com/GuangchuangYu/dlstats",
    "bug_reports": "https://github.com/GuangchuangYu/dlstats/issues",
    "repository": "https://cran.r-project.org/package=dlstats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dlstats Download Stats of R Packages Monthly download stats of 'CRAN' and 'Bioconductor' packages.\n\t     Download stats of 'CRAN' packages is from the 'RStudio' 'CRAN mirror', see <https://cranlogs.r-pkg.org:443>.\n\t     'Bioconductor' package download stats is at <https://bioconductor.org/packages/stats/>.  "
  },
  {
    "id": 11312,
    "package_name": "doctest",
    "title": "Generate Tests from Examples Using 'roxygen' and 'testthat'",
    "description": "Creates 'testthat' tests from 'roxygen' examples using simple tags.",
    "version": "0.3.0",
    "maintainer": "David Hugh-Jones <davidhughjones@gmail.com>",
    "author": "David Hugh-Jones [aut, cre]",
    "url": "https://hughjonesd.github.io/doctest/",
    "bug_reports": "https://github.com/hughjonesd/doctest/issues",
    "repository": "https://cran.r-project.org/package=doctest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "doctest Generate Tests from Examples Using 'roxygen' and 'testthat' Creates 'testthat' tests from 'roxygen' examples using simple tags.  "
  },
  {
    "id": 11314,
    "package_name": "document",
    "title": "Run 'roxygen2' on (Chunks of) Single Code Files",
    "description": "Have you ever been tempted to create 'roxygen2'-style documentation\n    comments for one of your functions that was not part of one of your\n    packages (yet)?\n    This is exactly what this package is about: running 'roxygen2' on\n    (chunks of) a single code file.",
    "version": "4.0.1",
    "maintainer": "Andreas Dominik Cullmann <fvafrcu@mailbox.org>",
    "author": "Andreas Dominik Cullmann [aut, cre]",
    "url": "https://gitlab.com/fvafrcu/document",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=document",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "document Run 'roxygen2' on (Chunks of) Single Code Files Have you ever been tempted to create 'roxygen2'-style documentation\n    comments for one of your functions that was not part of one of your\n    packages (yet)?\n    This is exactly what this package is about: running 'roxygen2' on\n    (chunks of) a single code file.  "
  },
  {
    "id": 11383,
    "package_name": "dreamerr",
    "title": "Error Handling Made Easy",
    "description": "Set of tools to facilitate package development and make R a more user-friendly place. Mostly for developers (or anyone who writes/shares functions). Provides a simple, powerful and flexible way to check the arguments passed to functions. \n    The developer can easily describe the type of argument needed. If the user provides a wrong argument, then an informative error message is prompted with the requested type and the problem clearly stated--saving the user a lot of time in debugging. ",
    "version": "1.5.0",
    "maintainer": "Laurent Berge <laurent.berge@u-bordeaux.fr>",
    "author": "Laurent Berge [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/lrberge/dreamerr/issues",
    "repository": "https://cran.r-project.org/package=dreamerr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dreamerr Error Handling Made Easy Set of tools to facilitate package development and make R a more user-friendly place. Mostly for developers (or anyone who writes/shares functions). Provides a simple, powerful and flexible way to check the arguments passed to functions. \n    The developer can easily describe the type of argument needed. If the user provides a wrong argument, then an informative error message is prompted with the requested type and the problem clearly stated--saving the user a lot of time in debugging.   "
  },
  {
    "id": 11390,
    "package_name": "drimmR",
    "title": "Estimation, Simulation and Reliability of Drifting Markov Models",
    "description": "Performs the drifting Markov models (DMM) which are \n    non-homogeneous Markov models designed for modeling the heterogeneities of\n    sequences in a more flexible way than homogeneous Markov chains or even \n    hidden Markov models. In this context, we developed an R package dedicated to \n    the estimation, simulation and the exact computation of associated reliability \n    of drifting Markov models. The implemented methods are described in\n    Vergne, N. (2008), <doi:10.2202/1544-6115.1326> and\n    Barbu, V.S., Vergne, N. (2019) <doi:10.1007/s11009-018-9682-8> .",
    "version": "1.0.1",
    "maintainer": "Nicolas Vergne <nicolas.vergne@univ-rouen.fr>",
    "author": "Vlad Stefan Barbu [aut],\n  Geoffray Brelurut [ctb],\n  Annthomy Gilles [ctb],\n  Arnaud Lefebvre [ctb],\n  Corentin Lothode [aut],\n  Victor Mataigne [ctb],\n  Alexandre Seiller [aut],\n  Nicolas Vergne [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=drimmR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "drimmR Estimation, Simulation and Reliability of Drifting Markov Models Performs the drifting Markov models (DMM) which are \n    non-homogeneous Markov models designed for modeling the heterogeneities of\n    sequences in a more flexible way than homogeneous Markov chains or even \n    hidden Markov models. In this context, we developed an R package dedicated to \n    the estimation, simulation and the exact computation of associated reliability \n    of drifting Markov models. The implemented methods are described in\n    Vergne, N. (2008), <doi:10.2202/1544-6115.1326> and\n    Barbu, V.S., Vergne, N. (2019) <doi:10.1007/s11009-018-9682-8> .  "
  },
  {
    "id": 11410,
    "package_name": "dsb",
    "title": "Normalize & Denoise Droplet Single Cell Protein Data (CITE-Seq)",
    "description": "This lightweight R package provides a method for normalizing and denoising protein expression data from droplet based single cell experiments. Raw protein Unique Molecular Index (UMI) counts from sequencing DNA-conjugated antibody derived tags (ADT) in droplets (e.g. 'CITE-seq') have substantial measurement noise. Our experiments and computational modeling revealed two major components of this noise: 1) protein-specific noise originating from ambient, unbound antibody encapsulated in droplets that can be accurately inferred via the expected protein counts detected in empty droplets, and 2) droplet/cell-specific noise revealed via the shared variance component associated with isotype antibody controls and background protein counts in each cell. This package normalizes and removes both of these sources of noise from raw protein data derived from methods such as 'CITE-seq', 'REAP-seq', 'ASAP-seq', 'TEA-seq', 'proteogenomic' data from the Mission Bio platform, etc. See the vignette for tutorials on how to integrate dsb with 'Seurat' and 'Bioconductor' and how to use dsb in 'Python'. Please see our paper Mul\u00e8 M.P., Martins A.J., and Tsang J.S. Nature Communications 2022 <https://www.nature.com/articles/s41467-022-29356-8> for more details on the method.",
    "version": "2.0.1",
    "maintainer": "Matthew Mul\u00e8 <mattmule@gmail.com>",
    "author": "Matthew Mul\u00e8 [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8457-2716>),\n  Andrew Martins [aut] (ORCID: <https://orcid.org/0000-0002-1832-1924>),\n  John Tsang [pdr] (ORCID: <https://orcid.org/0000-0003-3186-3047>)",
    "url": "https://github.com/niaid/dsb",
    "bug_reports": "https://github.com/niaid/dsb/issues",
    "repository": "https://cran.r-project.org/package=dsb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dsb Normalize & Denoise Droplet Single Cell Protein Data (CITE-Seq) This lightweight R package provides a method for normalizing and denoising protein expression data from droplet based single cell experiments. Raw protein Unique Molecular Index (UMI) counts from sequencing DNA-conjugated antibody derived tags (ADT) in droplets (e.g. 'CITE-seq') have substantial measurement noise. Our experiments and computational modeling revealed two major components of this noise: 1) protein-specific noise originating from ambient, unbound antibody encapsulated in droplets that can be accurately inferred via the expected protein counts detected in empty droplets, and 2) droplet/cell-specific noise revealed via the shared variance component associated with isotype antibody controls and background protein counts in each cell. This package normalizes and removes both of these sources of noise from raw protein data derived from methods such as 'CITE-seq', 'REAP-seq', 'ASAP-seq', 'TEA-seq', 'proteogenomic' data from the Mission Bio platform, etc. See the vignette for tutorials on how to integrate dsb with 'Seurat' and 'Bioconductor' and how to use dsb in 'Python'. Please see our paper Mul\u00e8 M.P., Martins A.J., and Tsang J.S. Nature Communications 2022 <https://www.nature.com/articles/s41467-022-29356-8> for more details on the method.  "
  },
  {
    "id": 11426,
    "package_name": "dssd",
    "title": "Distance Sampling Survey Design",
    "description": "Creates survey designs for distance sampling surveys. These\n    designs can be assessed for various effort and coverage statistics.\n    Once the user is satisfied with the design characteristics they can \n    generate a set of transects to use in their distance sampling survey.\n    Many of the designs implemented in this R package were first made \n    available in our 'Distance' for Windows software and are detailed in \n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, \n    ISBN-13: 978-0199225873). Find out more about estimating animal/plant \n    abundance with distance sampling at <https://distancesampling.org/>. ",
    "version": "1.0.3",
    "maintainer": "Laura Marshall <lhm@st-andrews.ac.uk>",
    "author": "Laura Marshall [aut, cre],\n  Rexstad Eric [ctb]",
    "url": "",
    "bug_reports": "https://github.com/DistanceDevelopment/dssd/issues",
    "repository": "https://cran.r-project.org/package=dssd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dssd Distance Sampling Survey Design Creates survey designs for distance sampling surveys. These\n    designs can be assessed for various effort and coverage statistics.\n    Once the user is satisfied with the design characteristics they can \n    generate a set of transects to use in their distance sampling survey.\n    Many of the designs implemented in this R package were first made \n    available in our 'Distance' for Windows software and are detailed in \n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, \n    ISBN-13: 978-0199225873). Find out more about estimating animal/plant \n    abundance with distance sampling at <https://distancesampling.org/>.   "
  },
  {
    "id": 11465,
    "package_name": "dverse",
    "title": "Document a Universe of Packages",
    "description": "Creates a data frame containing the metadata associated with\n    the documentation of a collection of R packages. It allows for linking\n    topic names to their corresponding documentation online. If you\n    maintain a universe meta-package, it helps create a comprehensive\n    reference for its website.",
    "version": "0.2.0",
    "maintainer": "Mauro Lepore <maurolepore@gmail.com>",
    "author": "Mauro Lepore [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1986-7988>)",
    "url": "https://github.com/maurolepore/dverse,\nhttps://maurolepore.github.io/dverse/",
    "bug_reports": "https://github.com/maurolepore/dverse/issues",
    "repository": "https://cran.r-project.org/package=dverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dverse Document a Universe of Packages Creates a data frame containing the metadata associated with\n    the documentation of a collection of R packages. It allows for linking\n    topic names to their corresponding documentation online. If you\n    maintain a universe meta-package, it helps create a comprehensive\n    reference for its website.  "
  },
  {
    "id": 11500,
    "package_name": "dynr",
    "title": "Dynamic Models with Regime-Switching",
    "description": "Intensive longitudinal data have become increasingly prevalent in\n    various scientific disciplines. Many such data sets are noisy, multivariate,\n    and multi-subject in nature. The change functions may also be continuous,\n    or continuous but interspersed with periods of discontinuities (i.e.,\n    showing regime switches). The package 'dynr' (Dynamic Modeling in R) is an\n    R package that implements a set of computationally efficient algorithms for\n    handling a broad class of linear and nonlinear discrete- and continuous-time\n    models with regime-switching properties under the constraint of linear\n    Gaussian measurement functions. The discrete-time models can generally\n    take on the form of a state-space or difference equation model. The\n    continuous-time models are generally expressed as a set of ordinary or\n    stochastic differential equations. All estimation and computations are\n    performed in C, but users are provided with the option to specify the\n    model of interest via a set of simple and easy-to-learn model specification\n    functions in R. Model fitting can be performed using single-subject time\n    series data or multiple-subject longitudinal data. Ou, Hunter, & Chow\n    (2019) <doi:10.32614%2FRJ-2019-012> provided a detailed introduction to the\n    interface and more information on the algorithms.",
    "version": "0.1.16-114",
    "maintainer": "Michael D. Hunter <mike.dynr@gmail.com>",
    "author": "Lu Ou [aut],\n  Michael D. Hunter [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3651-6709>),\n  Sy-Miin Chow [aut] (ORCID: <https://orcid.org/0000-0003-1938-027X>),\n  Linying Ji [aut],\n  Meng Chen [aut],\n  Hui-Ju Hung [aut],\n  Jungmin Lee [aut],\n  Yanling Li [aut],\n  Jonathan Park [aut],\n  Massachusetts Institute of Technology [cph],\n  S. G. Johnson [cph],\n  Benoit Scherrer [cph],\n  Dieter Kraft [cph]",
    "url": "https://dynrr.github.io/, https://github.com/mhunter1/dynr",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dynr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dynr Dynamic Models with Regime-Switching Intensive longitudinal data have become increasingly prevalent in\n    various scientific disciplines. Many such data sets are noisy, multivariate,\n    and multi-subject in nature. The change functions may also be continuous,\n    or continuous but interspersed with periods of discontinuities (i.e.,\n    showing regime switches). The package 'dynr' (Dynamic Modeling in R) is an\n    R package that implements a set of computationally efficient algorithms for\n    handling a broad class of linear and nonlinear discrete- and continuous-time\n    models with regime-switching properties under the constraint of linear\n    Gaussian measurement functions. The discrete-time models can generally\n    take on the form of a state-space or difference equation model. The\n    continuous-time models are generally expressed as a set of ordinary or\n    stochastic differential equations. All estimation and computations are\n    performed in C, but users are provided with the option to specify the\n    model of interest via a set of simple and easy-to-learn model specification\n    functions in R. Model fitting can be performed using single-subject time\n    series data or multiple-subject longitudinal data. Ou, Hunter, & Chow\n    (2019) <doi:10.32614%2FRJ-2019-012> provided a detailed introduction to the\n    interface and more information on the algorithms.  "
  },
  {
    "id": 11535,
    "package_name": "earthdatalogin",
    "title": "NASA 'EarthData' Access Utilities",
    "description": "Providing easy, portable access to NASA 'EarthData' products\n  through the use of bearer tokens. Much of NASA's public data catalogs hosted\n  and maintained by its 12 Distributed Active Archive Centers ('DAACs') are\n  now made available on the Amazon Web Services 'S3' storage.  However, \n  accessing this data through the standard 'S3' API is restricted to only to \n  compute resources running inside 'us-west-2' Data Center in Portland, Oregon,\n  which allows NASA to avoid being charged data egress rates. This package\n  provides public access to the data from any networked device by using the \n  'EarthData' login application programming interface (API),\n  <https://www.earthdata.nasa.gov/data/earthdata-login>,\n  providing convenient authentication and access to cloud-hosted NASA 'EarthData'\n  products. This makes access to a wide range of earth observation data from \n  any location straight forward and compatible with R packages that are \n  widely used with cloud native earth observation data (such as 'terra',\n  'sf', etc.)",
    "version": "0.0.3",
    "maintainer": "Carl Boettiger <cboettig@gmail.com>",
    "author": "Carl Boettiger [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1642-628X>),\n  Luis L\u00f3pez [aut] (ORCID: <https://orcid.org/0000-0003-4896-3263>),\n  Yuvi Panda [aut],\n  Bri Lind [aut] (ORCID: <https://orcid.org/0000-0002-5306-9963>),\n  Andy Teucher [ctb] (ORCID: <https://orcid.org/0000-0002-7840-692X>),\n  Openscapes [fnd]",
    "url": "https://boettiger-lab.github.io/earthdatalogin/,\nhttps://github.com/boettiger-lab/earthdatalogin",
    "bug_reports": "https://github.com/boettiger-lab/earthdatalogin/issues",
    "repository": "https://cran.r-project.org/package=earthdatalogin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "earthdatalogin NASA 'EarthData' Access Utilities Providing easy, portable access to NASA 'EarthData' products\n  through the use of bearer tokens. Much of NASA's public data catalogs hosted\n  and maintained by its 12 Distributed Active Archive Centers ('DAACs') are\n  now made available on the Amazon Web Services 'S3' storage.  However, \n  accessing this data through the standard 'S3' API is restricted to only to \n  compute resources running inside 'us-west-2' Data Center in Portland, Oregon,\n  which allows NASA to avoid being charged data egress rates. This package\n  provides public access to the data from any networked device by using the \n  'EarthData' login application programming interface (API),\n  <https://www.earthdata.nasa.gov/data/earthdata-login>,\n  providing convenient authentication and access to cloud-hosted NASA 'EarthData'\n  products. This makes access to a wide range of earth observation data from \n  any location straight forward and compatible with R packages that are \n  widely used with cloud native earth observation data (such as 'terra',\n  'sf', etc.)  "
  },
  {
    "id": 11539,
    "package_name": "easy.utils",
    "title": "Frequently Used Functions for Easy R Programming",
    "description": "Some utility functions for validation and data manipulation. These functions can be helpful to reduce internal codes everywhere in package development.",
    "version": "0.1.0",
    "maintainer": "Yuchen Li <ycli1995@outlook.com>",
    "author": "Yuchen Li [aut, cre]",
    "url": "https://github.com/ycli1995/easy.utils",
    "bug_reports": "https://github.com/ycli1995/easy.utils/issues",
    "repository": "https://cran.r-project.org/package=easy.utils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "easy.utils Frequently Used Functions for Easy R Programming Some utility functions for validation and data manipulation. These functions can be helpful to reduce internal codes everywhere in package development.  "
  },
  {
    "id": 11547,
    "package_name": "easyRef",
    "title": "Easy Reference Generation for R Packages",
    "description": "Generate citations and references for R packages from CRAN or Bioconductor.\n    Supports RIS and BibTeX formats with automatic DOI retrieval from GitHub repositories\n    and published papers. Includes command-line interface for batch processing.",
    "version": "0.1.0",
    "maintainer": "Rasmus Rydbirk <rrydbirk@outlook.dk>",
    "author": "Rasmus Rydbirk [aut, cre]",
    "url": "https://github.com/rrydbirk/easyRef",
    "bug_reports": "https://github.com/rrydbirk/easyRef/issues",
    "repository": "https://cran.r-project.org/package=easyRef",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "easyRef Easy Reference Generation for R Packages Generate citations and references for R packages from CRAN or Bioconductor.\n    Supports RIS and BibTeX formats with automatic DOI retrieval from GitHub repositories\n    and published papers. Includes command-line interface for batch processing.  "
  },
  {
    "id": 11564,
    "package_name": "easypower",
    "title": "Sample Size Estimation for Experimental Designs",
    "description": "Power analysis is used in the estimation of sample sizes for\n    experimental designs. Most programs and R packages will only output the highest\n    recommended sample size to the user. Often the user input can be complicated\n    and computing multiple power analyses for different treatment comparisons can\n    be time consuming. This package simplifies the user input and allows the user\n    to view all of the sample size recommendations or just the ones they want to see.\n    The calculations used to calculate the recommended sample sizes are from the\n    'pwr' package.",
    "version": "1.0.2",
    "maintainer": "Aaron McGarvey <amcgarvey271@gmail.com>",
    "author": "Aaron McGarvey",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=easypower",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "easypower Sample Size Estimation for Experimental Designs Power analysis is used in the estimation of sample sizes for\n    experimental designs. Most programs and R packages will only output the highest\n    recommended sample size to the user. Often the user input can be complicated\n    and computing multiple power analyses for different treatment comparisons can\n    be time consuming. This package simplifies the user input and allows the user\n    to view all of the sample size recommendations or just the ones they want to see.\n    The calculations used to calculate the recommended sample sizes are from the\n    'pwr' package.  "
  },
  {
    "id": 11623,
    "package_name": "economiccomplexity",
    "title": "Computational Methods for Economic Complexity",
    "description": "A wrapper of different methods from Linear Algebra for the equations\n  introduced in The Atlas of Economic Complexity and related literature. This\n  package provides standard matrix and graph output that can be used seamlessly\n  with other packages. See <doi:10.21105/joss.01866> for a summary\n  of these methods and its evolution in literature.",
    "version": "2.0.0",
    "maintainer": "Mauricio Vargas Sepulveda <m.sepulveda@mail.utoronto.ca>",
    "author": "Mauricio Vargas Sepulveda [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1017-7574>),\n  Carlo Bottai [ctb] (improved the eigenvalues calculation),\n  Diego Kozlowski [ctb] (provided initial RCA function used up to v0.2.4),\n  Nico Pintar [rev] (suggested improvements to special cases in\n    eigenvalues calculation),\n  The World Bank [dtc] (World GDP per capita dataset),\n  Open Trade Statistics [dtc] (World Trade dataset)",
    "url": "https://pacha.dev/economiccomplexity/",
    "bug_reports": "https://github.com/pachadotdev/economiccomplexity/issues/",
    "repository": "https://cran.r-project.org/package=economiccomplexity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "economiccomplexity Computational Methods for Economic Complexity A wrapper of different methods from Linear Algebra for the equations\n  introduced in The Atlas of Economic Complexity and related literature. This\n  package provides standard matrix and graph output that can be used seamlessly\n  with other packages. See <doi:10.21105/joss.01866> for a summary\n  of these methods and its evolution in literature.  "
  },
  {
    "id": 11625,
    "package_name": "econullnetr",
    "title": "Null Model Analysis for Ecological Networks",
    "description": "Null models to analyse ecological networks (e.g. food webs, \n    flower-visitation networks, seed-dispersal networks) and detect resource \n    preferences or non-random interactions among network nodes. Tools are \n    provided to run null models, test for and plot preferences, plot and \n    analyse bipartite networks, and export null model results in a form \n    compatible with other network analysis packages. The underlying null model \n    was developed by Agusti et al. (2003) Molecular Ecology \n    <doi:10.1046/j.1365-294X.2003.02014.x> and the full application to \n    ecological networks by Vaughan et al. (2018) econullnetr: an R package \n    using null models to analyse the structure of ecological networks and \n    identify resource selection. Methods in Ecology & Evolution, \n    <doi:10.1111/2041-210X.12907>.",
    "version": "0.2.2",
    "maintainer": "Ian Vaughan <vaughanip@cardiff.ac.uk>",
    "author": "Ian Vaughan [aut, cre] (ORCID: <https://orcid.org/0000-0002-7263-3822>)",
    "url": "",
    "bug_reports": "https://github.com/ivaughan/econullnetr/issues",
    "repository": "https://cran.r-project.org/package=econullnetr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "econullnetr Null Model Analysis for Ecological Networks Null models to analyse ecological networks (e.g. food webs, \n    flower-visitation networks, seed-dispersal networks) and detect resource \n    preferences or non-random interactions among network nodes. Tools are \n    provided to run null models, test for and plot preferences, plot and \n    analyse bipartite networks, and export null model results in a form \n    compatible with other network analysis packages. The underlying null model \n    was developed by Agusti et al. (2003) Molecular Ecology \n    <doi:10.1046/j.1365-294X.2003.02014.x> and the full application to \n    ecological networks by Vaughan et al. (2018) econullnetr: an R package \n    using null models to analyse the structure of ecological networks and \n    identify resource selection. Methods in Ecology & Evolution, \n    <doi:10.1111/2041-210X.12907>.  "
  },
  {
    "id": 11764,
    "package_name": "emdi",
    "title": "Estimating and Mapping Disaggregated Indicators",
    "description": "Functions that support estimating, assessing and mapping regional\n    disaggregated indicators. So far, estimation methods comprise direct estimation,\n    the model-based unit-level approach Empirical Best Prediction (see \"Small area\n    estimation of poverty indicators\" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), \n    the area-level model (see \"Estimates of income for small places: An \n    application of James-Stein procedures to Census Data\" by Fay and Herriot (1979) \n    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance \n    estimation methods, log and arcsin transformation, spatial, robust and measurement \n    error models), as well as their precision estimates. The assessment of the used model\n    is supported by a summary and diagnostic plots. For a suitable presentation of\n    estimates, map plots can be easily created. Furthermore, results can easily be\n    exported to excel. For a detailed description of the package and the methods used\n    see \"The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators\" \n    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette \n    \"A Framework for Producing Small Area Estimates Based on Area-Level Models in R\".",
    "version": "2.2.3",
    "maintainer": "Soeren Pannier <soeren.pannier@fu-berlin.de>",
    "author": "Sylvia Harmening [aut],\n  Ann-Kristin Kreutzmann [aut],\n  Soeren Pannier [aut, cre],\n  Felix Skarke [aut],\n  Natalia Rojas-Perilla [aut],\n  Nicola Salvati [aut],\n  Timo Schmid [aut],\n  Matthias Templ [aut],\n  Nikos Tzavidis [aut],\n  Nora W\u00fcrz [aut]",
    "url": "https://github.com/SoerenPannier/emdi",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=emdi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "emdi Estimating and Mapping Disaggregated Indicators Functions that support estimating, assessing and mapping regional\n    disaggregated indicators. So far, estimation methods comprise direct estimation,\n    the model-based unit-level approach Empirical Best Prediction (see \"Small area\n    estimation of poverty indicators\" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), \n    the area-level model (see \"Estimates of income for small places: An \n    application of James-Stein procedures to Census Data\" by Fay and Herriot (1979) \n    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance \n    estimation methods, log and arcsin transformation, spatial, robust and measurement \n    error models), as well as their precision estimates. The assessment of the used model\n    is supported by a summary and diagnostic plots. For a suitable presentation of\n    estimates, map plots can be easily created. Furthermore, results can easily be\n    exported to excel. For a detailed description of the package and the methods used\n    see \"The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators\" \n    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette \n    \"A Framework for Producing Small Area Estimates Based on Area-Level Models in R\".  "
  },
  {
    "id": 11776,
    "package_name": "empichar",
    "title": "Evaluates the Empirical Characteristic Function for Multivariate\nSamples",
    "description": "Evaluates the empirical characteristic function of univariate and multivariate samples.\n    This package uses 'RcppArmadillo' for fast evaluation. It is also possible to export the code to be used in other packages at 'C++' level.",
    "version": "1.0.1",
    "maintainer": "Guillermo Basulto-Elias <guillermobasulto@gmail.com>",
    "author": "Guillermo Basulto-Elias [aut, cre]",
    "url": "https://github.com/gbasulto/empichar",
    "bug_reports": "https://github.com/gbasulto/empichar/issues",
    "repository": "https://cran.r-project.org/package=empichar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "empichar Evaluates the Empirical Characteristic Function for Multivariate\nSamples Evaluates the empirical characteristic function of univariate and multivariate samples.\n    This package uses 'RcppArmadillo' for fast evaluation. It is also possible to export the code to be used in other packages at 'C++' level.  "
  },
  {
    "id": 11829,
    "package_name": "eodhdR2",
    "title": "Official R API for Fetching Data from 'EODHD'",
    "description": "Second and backward-incompatible version of R package 'eodhd' <https://eodhd.com/>, extended with a cache and quota system, \n also offering functions for cleaning and aggregating the financial data. ",
    "version": "0.5.2",
    "maintainer": "Marcelo S. Perlin <marceloperlin@gmail.com>",
    "author": "Marcelo S. Perlin [aut, cre, ctr],\n  Unicorn Data Services [cph]",
    "url": "https://github.com/EodHistoricalData/R-Library-for-financial-data-2024",
    "bug_reports": "https://github.com/EodHistoricalData/R-Library-for-financial-data-2024/issues",
    "repository": "https://cran.r-project.org/package=eodhdR2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eodhdR2 Official R API for Fetching Data from 'EODHD' Second and backward-incompatible version of R package 'eodhd' <https://eodhd.com/>, extended with a cache and quota system, \n also offering functions for cleaning and aggregating the financial data.   "
  },
  {
    "id": 11862,
    "package_name": "epiworldRShiny",
    "title": "A 'shiny' Wrapper of the R Package 'epiworldR'",
    "description": "R 'shiny' web apps for epidemiological Agent-Based Models. It provides a user-friendly interface to the Agent-Based Modeling (ABM) R package 'epiworldR' (Meyer et al., 2023) <DOI:10.21105/joss.05781>. Some of the main features of the package include the Susceptible-Infected-Susceptible (SIS), Susceptible-Infected-Recovered (SIR), and Susceptible-Exposed-Infected-Recovered (SEIR) models. 'epiworldRShiny' provides a web-based user interface for running various epidemiological ABMs, simulating interventions, and visualizing results interactively.",
    "version": "0.2.3",
    "maintainer": "Andrew Pulsipher <pulsipher.a@gmail.com>",
    "author": "George Vega Yon [aut] (ORCID: <https://orcid.org/0000-0002-3171-0844>),\n  Derek Meyer [aut] (ORCID: <https://orcid.org/0009-0005-1350-6988>),\n  Andrew Pulsipher [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0773-3210>),\n  Centers for Disease Control and Prevention [fnd] (Award number\n    1U01CK000585; 75D30121F00003),\n  Lindsay Keegan [ctb] (ORCID: <https://orcid.org/0000-0002-8526-3007>),\n  Karim Khader [ctb] (ORCID: <https://orcid.org/0000-0002-7206-8077>),\n  Damon Toth [ctb] (ORCID: <https://orcid.org/0000-0001-7393-4814>),\n  Randon Gruninger [ctb],\n  Matthew Samore [ctb] (ORCID: <https://orcid.org/0000-0002-4862-9196>),\n  Jay Love [ctb] (ORCID: <https://orcid.org/0000-0002-9371-2466>),\n  Kristina Stratford [ctb]",
    "url": "https://github.com/UofUEpiBio/epiworldRShiny/,\nhttps://uofuepibio.github.io/epiworldRShiny/,",
    "bug_reports": "https://github.com/UofUEpiBio/epiworldRShiny/issues/",
    "repository": "https://cran.r-project.org/package=epiworldRShiny",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epiworldRShiny A 'shiny' Wrapper of the R Package 'epiworldR' R 'shiny' web apps for epidemiological Agent-Based Models. It provides a user-friendly interface to the Agent-Based Modeling (ABM) R package 'epiworldR' (Meyer et al., 2023) <DOI:10.21105/joss.05781>. Some of the main features of the package include the Susceptible-Infected-Susceptible (SIS), Susceptible-Infected-Recovered (SIR), and Susceptible-Exposed-Infected-Recovered (SEIR) models. 'epiworldRShiny' provides a web-based user interface for running various epidemiological ABMs, simulating interventions, and visualizing results interactively.  "
  },
  {
    "id": 11883,
    "package_name": "equatags",
    "title": "Equations to 'XML'",
    "description": "Provides function to transform latex math expressions \n into format 'HTML' or 'Office Open XML Math'. The 'XML' \n result can then be included in 'HTML', 'Microsoft Word' \n documents or 'Microsoft PowerPoint' presentations by using \n a 'Markdown' document or the R package 'officer'. ",
    "version": "0.2.2",
    "maintainer": "David Gohel <david.gohel@ardata.fr>",
    "author": "David Gohel [aut, cre],\n  ArData [cph]",
    "url": "",
    "bug_reports": "https://github.com/ardata-fr/equatags/issues",
    "repository": "https://cran.r-project.org/package=equatags",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "equatags Equations to 'XML' Provides function to transform latex math expressions \n into format 'HTML' or 'Office Open XML Math'. The 'XML' \n result can then be included in 'HTML', 'Microsoft Word' \n documents or 'Microsoft PowerPoint' presentations by using \n a 'Markdown' document or the R package 'officer'.   "
  },
  {
    "id": 12013,
    "package_name": "evt0",
    "title": "Mean of Order P, Peaks over Random Threshold Hill and High\nQuantile Estimates",
    "description": "The R package proposes extreme value index estimators for heavy tailed models \n             by mean of order p <DOI:10.1016/j.csda.2012.07.019>, peaks over random threshold\n             <DOI:10.57805/revstat.v4i3.37> and a bias-reduced estimator \n             <DOI:10.1080/00949655.2010.547196>.\n\t     The package also computes moment, generalised Hill <DOI:10.2307/3318416> \n\t     and mixed moment estimates for the extreme value index.\n\t     High quantiles and value at risk estimators based on these estimators are implemented.",
    "version": "1.1.5",
    "maintainer": "Leo Belzile <belzilel@gmail.com>",
    "author": "Leo Belzile [cre] (ORCID: <https://orcid.org/0000-0002-9135-014X>),\n  B. G. Manjunath [aut] (ORCID: <https://orcid.org/0000-0003-2687-0138>),\n  Frederico Caeiro [aut] (ORCID: <https://orcid.org/0000-0001-8628-7281>),\n  Maria Ivette. Gomes [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2903-6993>),\n  Maria Isabel Fraga Alves [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3824-2403>)",
    "url": "",
    "bug_reports": "https://github.com/lbelzile/evt0/issues/",
    "repository": "https://cran.r-project.org/package=evt0",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "evt0 Mean of Order P, Peaks over Random Threshold Hill and High\nQuantile Estimates The R package proposes extreme value index estimators for heavy tailed models \n             by mean of order p <DOI:10.1016/j.csda.2012.07.019>, peaks over random threshold\n             <DOI:10.57805/revstat.v4i3.37> and a bias-reduced estimator \n             <DOI:10.1080/00949655.2010.547196>.\n\t     The package also computes moment, generalised Hill <DOI:10.2307/3318416> \n\t     and mixed moment estimates for the extreme value index.\n\t     High quantiles and value at risk estimators based on these estimators are implemented.  "
  },
  {
    "id": 12027,
    "package_name": "exampletestr",
    "title": "Help for Writing Unit Tests Based on Function Examples",
    "description": "Take the examples written in your documentation of functions\n    and use them to create shells (skeletons which must be manually\n    completed by the user) of test files to be tested with the 'testthat'\n    package. Sort of like python 'doctests' for R.",
    "version": "1.7.3",
    "maintainer": "Rory Nolan <rorynoolan@gmail.com>",
    "author": "Rory Nolan [aut, cre] (ORCID: <https://orcid.org/0000-0002-5239-4043>),\n  Sergi Padilla-Parra [ths] (ORCID:\n    <https://orcid.org/0000-0002-8010-9481>),\n  Thomas Quinn [rev] (ORCID: <https://orcid.org/0000-0003-0286-6329>),\n  Laurent Gatto [rev] (ORCID: <https://orcid.org/0000-0002-1520-2268>)",
    "url": "https://rorynolan.github.io/exampletestr/,\nhttps://github.com/rorynolan/exampletestr#readme",
    "bug_reports": "https://github.com/rorynolan/exampletestr/issues",
    "repository": "https://cran.r-project.org/package=exampletestr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exampletestr Help for Writing Unit Tests Based on Function Examples Take the examples written in your documentation of functions\n    and use them to create shells (skeletons which must be manually\n    completed by the user) of test files to be tested with the 'testthat'\n    package. Sort of like python 'doctests' for R.  "
  },
  {
    "id": 12053,
    "package_name": "experiment",
    "title": "R Package for Designing and Analyzing Randomized Experiments",
    "description": "Provides various statistical methods for\n  designing and analyzing randomized experiments. One functionality\n  of the package is the implementation of randomized-block and\n  matched-pair designs based on possibly multivariate pre-treatment\n  covariates. The package also provides the tools to analyze various\n  randomized experiments including cluster randomized experiments,\n  two-stage randomized experiments, randomized experiments with \n  noncompliance, and randomized experiments with missing data.",
    "version": "1.2.1",
    "maintainer": "Kosuke Imai <imai@harvard.edu>",
    "author": "Kosuke Imai [aut, cre],\n  Zhichao Jiang [aut]",
    "url": "https://github.com/kosukeimai/experiment",
    "bug_reports": "https://github.com/kosukeimai/experiment/issues",
    "repository": "https://cran.r-project.org/package=experiment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "experiment R Package for Designing and Analyzing Randomized Experiments Provides various statistical methods for\n  designing and analyzing randomized experiments. One functionality\n  of the package is the implementation of randomized-block and\n  matched-pair designs based on possibly multivariate pre-treatment\n  covariates. The package also provides the tools to analyze various\n  randomized experiments including cluster randomized experiments,\n  two-stage randomized experiments, randomized experiments with \n  noncompliance, and randomized experiments with missing data.  "
  },
  {
    "id": 12060,
    "package_name": "exploratory",
    "title": "A Tool for Large-Scale Exploratory Analyses",
    "description": "Conduct numerous exploratory analyses in an instant with a \n    point-and-click interface. With one simple command, this tool \n    launches a Shiny App on the local machine. Drag and drop variables \n    in a data set to categorize them as possible independent, \n    dependent, moderating, or mediating variables. Then run dozens \n    (or hundreds) of analyses instantly to uncover any statistically \n    significant relationships among variables. Any relationship \n    thus uncovered should be tested in follow-up studies. \n    This tool is designed only to facilitate exploratory \n    analyses and should NEVER be used for p-hacking. Many of \n    the functions used in this package are previous versions of functions\n    in the R Packages 'kim' and 'ezr'.\n    Selected References:\n    Chang et al. (2021) <https://CRAN.R-project.org/package=shiny>.\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Kim (2023) <https://jinkim.science/docs/kim.pdf>.\n    Kim (2021) <doi:10.5281/zenodo.4619237>.\n    Kim (2020) <https://CRAN.R-project.org/package=ezr>.\n    Simmons et al. (2011) <doi:10.1177/0956797611417632>\n    Tingley et al. (2019) <https://CRAN.R-project.org/package=mediation>.\n    Wickham et al. (2020) <https://CRAN.R-project.org/package=ggplot2>.",
    "version": "0.3.31",
    "maintainer": "Jin Kim <jin.m.kim@yale.edu>",
    "author": "Jin Kim [aut, cre] (ORCID: <https://orcid.org/0000-0002-5013-3958>)",
    "url": "https://exploratoryonly.com",
    "bug_reports": "https://github.com/jinkim3/exploratory/issues",
    "repository": "https://cran.r-project.org/package=exploratory",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exploratory A Tool for Large-Scale Exploratory Analyses Conduct numerous exploratory analyses in an instant with a \n    point-and-click interface. With one simple command, this tool \n    launches a Shiny App on the local machine. Drag and drop variables \n    in a data set to categorize them as possible independent, \n    dependent, moderating, or mediating variables. Then run dozens \n    (or hundreds) of analyses instantly to uncover any statistically \n    significant relationships among variables. Any relationship \n    thus uncovered should be tested in follow-up studies. \n    This tool is designed only to facilitate exploratory \n    analyses and should NEVER be used for p-hacking. Many of \n    the functions used in this package are previous versions of functions\n    in the R Packages 'kim' and 'ezr'.\n    Selected References:\n    Chang et al. (2021) <https://CRAN.R-project.org/package=shiny>.\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Kim (2023) <https://jinkim.science/docs/kim.pdf>.\n    Kim (2021) <doi:10.5281/zenodo.4619237>.\n    Kim (2020) <https://CRAN.R-project.org/package=ezr>.\n    Simmons et al. (2011) <doi:10.1177/0956797611417632>\n    Tingley et al. (2019) <https://CRAN.R-project.org/package=mediation>.\n    Wickham et al. (2020) <https://CRAN.R-project.org/package=ggplot2>.  "
  },
  {
    "id": 12066,
    "package_name": "expss",
    "title": "Tables, Labels and Some Useful Functions from Spreadsheets and\n'SPSS' Statistics",
    "description": "Package computes and displays tables with support for 'SPSS'-style \n        labels, multiple and nested banners, weights, multiple-response variables \n        and significance testing. There are facilities for nice output of tables \n        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods \n        for labelled variables add value labels support to base R functions and to \n        some functions from other packages. Additionally, the package brings \n        popular data transformation functions from 'SPSS' Statistics and 'Excel': \n        'RECODE', 'COUNT', 'COUNTIF', 'VLOOKUP' and etc. \n        These functions are very useful for data processing in marketing research \n        surveys. Package intended to help people to move data \n        processing from 'Excel' and 'SPSS' to R.",
    "version": "0.11.7",
    "maintainer": "Gregory Demin <gdemin@gmail.com>",
    "author": "Gregory Demin [aut, cre],\n  Sebastian Jeworutzki [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2671-5253>),\n  Dan Chaltiel [ctb],\n  John Williams [ctb],\n  Tom Elliott [ctb]",
    "url": "https://gdemin.github.io/expss/",
    "bug_reports": "https://github.com/gdemin/expss/issues",
    "repository": "https://cran.r-project.org/package=expss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "expss Tables, Labels and Some Useful Functions from Spreadsheets and\n'SPSS' Statistics Package computes and displays tables with support for 'SPSS'-style \n        labels, multiple and nested banners, weights, multiple-response variables \n        and significance testing. There are facilities for nice output of tables \n        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods \n        for labelled variables add value labels support to base R functions and to \n        some functions from other packages. Additionally, the package brings \n        popular data transformation functions from 'SPSS' Statistics and 'Excel': \n        'RECODE', 'COUNT', 'COUNTIF', 'VLOOKUP' and etc. \n        These functions are very useful for data processing in marketing research \n        surveys. Package intended to help people to move data \n        processing from 'Excel' and 'SPSS' to R.  "
  },
  {
    "id": 12141,
    "package_name": "fabletools",
    "title": "Core Tools for Packages in the 'fable' Framework",
    "description": "Provides tools, helpers and data structures for\n    developing models and time series functions for 'fable' and extension\n    packages. These tools support a consistent and tidy interface for time\n    series modelling and analysis.",
    "version": "0.5.1",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>),\n  Rob Hyndman [aut],\n  Earo Wang [aut] (ORCID: <https://orcid.org/0000-0001-6448-5260>),\n  Di Cook [ctb],\n  George Athanasopoulos [ctb],\n  David Holt [ctb]",
    "url": "https://fabletools.tidyverts.org/,\nhttps://github.com/tidyverts/fabletools",
    "bug_reports": "https://github.com/tidyverts/fabletools/issues",
    "repository": "https://cran.r-project.org/package=fabletools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fabletools Core Tools for Packages in the 'fable' Framework Provides tools, helpers and data structures for\n    developing models and time series functions for 'fable' and extension\n    packages. These tools support a consistent and tidy interface for time\n    series modelling and analysis.  "
  },
  {
    "id": 12155,
    "package_name": "factoextra",
    "title": "Extract and Visualize the Results of Multivariate Data Analyses",
    "description": "Provides some easy-to-use functions to extract and visualize the\n    output of multivariate data analyses, including 'PCA' (Principal Component\n    Analysis), 'CA' (Correspondence Analysis), 'MCA' (Multiple Correspondence\n    Analysis), 'FAMD' (Factor Analysis of Mixed Data), 'MFA' (Multiple Factor Analysis) and 'HMFA' (Hierarchical Multiple\n    Factor Analysis) functions from different R packages. It contains also functions\n    for simplifying some clustering analysis steps and provides 'ggplot2' - based\n    elegant data visualization.",
    "version": "1.0.7",
    "maintainer": "Alboukadel Kassambara <alboukadel.kassambara@gmail.com>",
    "author": "Alboukadel Kassambara [aut, cre],\n  Fabian Mundt [aut]",
    "url": "http://www.sthda.com/english/rpkgs/factoextra",
    "bug_reports": "https://github.com/kassambara/factoextra/issues",
    "repository": "https://cran.r-project.org/package=factoextra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "factoextra Extract and Visualize the Results of Multivariate Data Analyses Provides some easy-to-use functions to extract and visualize the\n    output of multivariate data analyses, including 'PCA' (Principal Component\n    Analysis), 'CA' (Correspondence Analysis), 'MCA' (Multiple Correspondence\n    Analysis), 'FAMD' (Factor Analysis of Mixed Data), 'MFA' (Multiple Factor Analysis) and 'HMFA' (Hierarchical Multiple\n    Factor Analysis) functions from different R packages. It contains also functions\n    for simplifying some clustering analysis steps and provides 'ggplot2' - based\n    elegant data visualization.  "
  },
  {
    "id": 12178,
    "package_name": "fake",
    "title": "Flexible Data Simulation Using the Multivariate Normal\nDistribution",
    "description": "This R package can be used to generate artificial data conditionally on pre-specified (simulated or user-defined) relationships between the variables and/or observations. Each observation is drawn from a multivariate Normal distribution where the mean vector and covariance matrix reflect the desired relationships. Outputs can be used to evaluate the performances of variable selection, graphical modelling, or clustering approaches by comparing the true and estimated structures (B Bodinier et al (2021) <arXiv:2106.02521>).",
    "version": "1.4.0",
    "maintainer": "Barbara Bodinier <barbara.bodinier@gmail.com>",
    "author": "Barbara Bodinier [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fake",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fake Flexible Data Simulation Using the Multivariate Normal\nDistribution This R package can be used to generate artificial data conditionally on pre-specified (simulated or user-defined) relationships between the variables and/or observations. Each observation is drawn from a multivariate Normal distribution where the mean vector and covariance matrix reflect the desired relationships. Outputs can be used to evaluate the performances of variable selection, graphical modelling, or clustering approaches by comparing the true and estimated structures (B Bodinier et al (2021) <arXiv:2106.02521>).  "
  },
  {
    "id": 12179,
    "package_name": "fakemake",
    "title": "Mock the Unix Make Utility",
    "description": "Use R as a minimal build system. This might come in\n    handy if you are developing R packages and can not use a proper build\n    system. Stay away if you can (use a proper build system).",
    "version": "1.11.1",
    "maintainer": "Andreas Dominik Cullmann <fvafrcu@mailbox.org>",
    "author": "Andreas Dominik Cullmann [aut, cre]",
    "url": "https://gitlab.com/fvafrcu/fakemake",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fakemake",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fakemake Mock the Unix Make Utility Use R as a minimal build system. This might come in\n    handy if you are developing R packages and can not use a proper build\n    system. Stay away if you can (use a proper build system).  "
  },
  {
    "id": 12188,
    "package_name": "famish",
    "title": "Flexibly Tune Families of Probability Distributions",
    "description": "Fits probability distributions to data and plugs into the\n    'probaverse' suite of R packages so distribution objects are ready for\n    further manipulation and evaluation. Supports methods such as maximum\n    likelihood and L-moments, and provides diagnostics including empirical\n    ranking and quantile score.",
    "version": "0.2.0",
    "maintainer": "Vincenzo Coia <vincenzo.coia@gmail.com>",
    "author": "Vincenzo Coia [aut, cre, cph]",
    "url": "https://famish.probaverse.com/,\nhttps://github.com/probaverse/famish/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=famish",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "famish Flexibly Tune Families of Probability Distributions Fits probability distributions to data and plugs into the\n    'probaverse' suite of R packages so distribution objects are ready for\n    further manipulation and evaluation. Supports methods such as maximum\n    likelihood and L-moments, and provides diagnostics including empirical\n    ranking and quantile score.  "
  },
  {
    "id": 12248,
    "package_name": "fastlogitME",
    "title": "Basic Marginal Effects for Logit Models",
    "description": "Calculates marginal effects based on logistic model objects such as 'glm' or 'speedglm' at the average (default) or at given values using finite differences. It also returns confidence intervals for said marginal effects and the p-values, which can easily be used as input in stargazer. The function only returns the essentials and is therefore much faster but not as detailed as other functions available to calculate marginal effects. As a result, it is highly suitable for large datasets for which other packages may require too much time or calculating power.",
    "version": "0.1.0",
    "maintainer": "Mathieu Steijn <m.p.a.steijn@uu.nl>",
    "author": "Mathieu Steijn",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fastlogitME",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastlogitME Basic Marginal Effects for Logit Models Calculates marginal effects based on logistic model objects such as 'glm' or 'speedglm' at the average (default) or at given values using finite differences. It also returns confidence intervals for said marginal effects and the p-values, which can easily be used as input in stargazer. The function only returns the essentials and is therefore much faster but not as detailed as other functions available to calculate marginal effects. As a result, it is highly suitable for large datasets for which other packages may require too much time or calculating power.  "
  },
  {
    "id": 12250,
    "package_name": "fastmatrix",
    "title": "Fast Computation of some Matrices Useful in Statistics",
    "description": "Small set of functions designed to speed up the computation of certain \n  matrix operations that are commonly used in statistics and econometrics. It provides \n  efficient implementations for the computation of several structured matrices, matrix \n  decompositions and statistical procedures, many of which have minimal memory overhead.\n  Furthermore, the package provides interfaces to C code callable by another C code \n  from other R packages.",
    "version": "0.6-4",
    "maintainer": "Felipe Osorio <faosorios.stat@gmail.com>",
    "author": "Felipe Osorio [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4675-5201>),\n  Alonso Ogueda [aut]",
    "url": "https://github.com/faosorios/fastmatrix",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fastmatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastmatrix Fast Computation of some Matrices Useful in Statistics Small set of functions designed to speed up the computation of certain \n  matrix operations that are commonly used in statistics and econometrics. It provides \n  efficient implementations for the computation of several structured matrices, matrix \n  decompositions and statistical procedures, many of which have minimal memory overhead.\n  Furthermore, the package provides interfaces to C code callable by another C code \n  from other R packages.  "
  },
  {
    "id": 12311,
    "package_name": "fdapace",
    "title": "Functional Data Analysis and Empirical Dynamics",
    "description": "A versatile package that provides implementation of various\n    methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this\n    package is Functional Principal Component Analysis (FPCA), a key technique for\n    functional data analysis, for sparsely or densely sampled random trajectories\n    and time courses, via the Principal Analysis by Conditional Estimation\n    (PACE) algorithm. This core algorithm yields covariance and mean functions,\n    eigenfunctions and principal component (scores), for both functional data and\n    derivatives, for both dense (functional) and sparse (longitudinal) sampling designs.\n    For sparse designs, it provides fitted continuous trajectories with confidence bands,\n    even for subjects with very few longitudinal observations. PACE is a viable and\n    flexible alternative to random effects modeling of longitudinal data. There is also a\n    Matlab version (PACE) that contains some methods not available on fdapace and vice\n    versa. Updates to fdapace were supported by grants from NIH Echo and NSF DMS-1712864 and DMS-2014626. \n    Please cite our package if you use it (You may run the command citation(\"fdapace\") to get the citation format and bibtex entry).\n    References: Wang, J.L., Chiou, J., M\u00fcller, H.G. (2016) <doi:10.1146/annurev-statistics-041715-033624>; Chen, K., Zhang, X., Petersen, A., M\u00fcller, H.G. (2017) <doi:10.1007/s12561-015-9137-5>.",
    "version": "0.6.0",
    "maintainer": "Yidong Zhou <ydzhou@ucdavis.edu>",
    "author": "Yidong Zhou [cre, aut] (ORCID: <https://orcid.org/0000-0003-1423-1857>),\n  Han Chen [aut],\n  Su I Iao [aut],\n  Poorbita Kundu [aut],\n  Hang Zhou [aut],\n  Satarupa Bhattacharjee [aut],\n  Cody Carroll [aut] (ORCID: <https://orcid.org/0000-0003-3525-8653>),\n  Yaqing Chen [aut],\n  Xiongtao Dai [aut],\n  Jianing Fan [aut],\n  Alvaro Gajardo [aut],\n  Pantelis Z. Hadjipantelis [aut],\n  Kyunghee Han [aut],\n  Hao Ji [aut],\n  Changbo Zhu [aut],\n  Paromita Dubey [ctb],\n  Shu-Chin Lin [ctb],\n  Hans-Georg M\u00fcller [cph, ths, aut],\n  Jane-Ling Wang [cph, ths, aut]",
    "url": "https://github.com/functionaldata/tPACE",
    "bug_reports": "https://github.com/functionaldata/tPACE/issues",
    "repository": "https://cran.r-project.org/package=fdapace",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fdapace Functional Data Analysis and Empirical Dynamics A versatile package that provides implementation of various\n    methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this\n    package is Functional Principal Component Analysis (FPCA), a key technique for\n    functional data analysis, for sparsely or densely sampled random trajectories\n    and time courses, via the Principal Analysis by Conditional Estimation\n    (PACE) algorithm. This core algorithm yields covariance and mean functions,\n    eigenfunctions and principal component (scores), for both functional data and\n    derivatives, for both dense (functional) and sparse (longitudinal) sampling designs.\n    For sparse designs, it provides fitted continuous trajectories with confidence bands,\n    even for subjects with very few longitudinal observations. PACE is a viable and\n    flexible alternative to random effects modeling of longitudinal data. There is also a\n    Matlab version (PACE) that contains some methods not available on fdapace and vice\n    versa. Updates to fdapace were supported by grants from NIH Echo and NSF DMS-1712864 and DMS-2014626. \n    Please cite our package if you use it (You may run the command citation(\"fdapace\") to get the citation format and bibtex entry).\n    References: Wang, J.L., Chiou, J., M\u00fcller, H.G. (2016) <doi:10.1146/annurev-statistics-041715-033624>; Chen, K., Zhang, X., Petersen, A., M\u00fcller, H.G. (2017) <doi:10.1007/s12561-015-9137-5>.  "
  },
  {
    "id": 12318,
    "package_name": "fdm2id",
    "title": "Data Mining and R Programming for Beginners",
    "description": "Contains functions to simplify the use of data mining methods (classification, regression, clustering, etc.), for students and beginners in R programming. Various R packages are used and wrappers are built around the main functions, to standardize the use of data mining methods (input/output): it brings a certain loss of flexibility, but also a gain of simplicity. The package name came from the French \"Fouille de Donn\u00e9es en Master 2 Informatique D\u00e9cisionnelle\".",
    "version": "0.9.9",
    "maintainer": "Alexandre Blansch\u00e9 <alexandre.blansche@univ-lorraine.fr>",
    "author": "Alexandre Blansch\u00e9 [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fdm2id",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fdm2id Data Mining and R Programming for Beginners Contains functions to simplify the use of data mining methods (classification, regression, clustering, etc.), for students and beginners in R programming. Various R packages are used and wrappers are built around the main functions, to standardize the use of data mining methods (input/output): it brings a certain loss of flexibility, but also a gain of simplicity. The package name came from the French \"Fouille de Donn\u00e9es en Master 2 Informatique D\u00e9cisionnelle\".  "
  },
  {
    "id": 12364,
    "package_name": "fgeo",
    "title": "Analyze Forest Diversity and Dynamics",
    "description": "To help you access, transform, analyze, and\n    visualize ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to install and load the entire package-collection with a\n    single R command, and provides convenient ways to find relevant\n    documentation. Most commonly, you should not worry about the\n    individual packages that make up the package-collection as you can\n    access all features via this package. To learn more about ForestGEO\n    visit <http://www.forestgeo.si.edu/>.",
    "version": "1.1.4",
    "maintainer": "Mauro Lepore <maurolepore@gmail.com>",
    "author": "Mauro Lepore [aut, ctr, cre] (ORCID:\n    <https://orcid.org/0000-0002-1986-7988>),\n  Gabriel Arellano [aut, rev],\n  Richard Condit [aut],\n  Stuart Davies [aut, rev],\n  Matteo Detto [aut],\n  Erika Gonzalez-Akre [aut, rev] (ORCID:\n    <https://orcid.org/0000-0001-8305-6672>),\n  Pamela Hall [aut],\n  Kyle Harms [aut],\n  Valentine Herrmann [aut, rev] (ORCID:\n    <https://orcid.org/0000-0002-4519-481X>),\n  Aaron Hogan [rev] (ORCID: <https://orcid.org/0000-0001-9806-3074>),\n  Bier Kraichak [rev],\n  David Kenfack [aut, rev],\n  Lauren Krizel [rev],\n  Suzanne Lao [aut, rev],\n  Sean McMahon [aut, rev],\n  Haley Overstreet [rev],\n  Sabrina Russo [aut, rev],\n  Cara Scalpone [rev] (ORCID: <https://orcid.org/0000-0001-8448-2147>),\n  Kristina Anderson-Teixeira [aut, rev],\n  Graham Zemunik [aut, rev],\n  Daniel Zuleta [aut, rev],\n  CTFS-ForestGEO [cph, fnd]",
    "url": "http://forestgeo.github.io/fgeo, https://github.com/forestgeo/fgeo",
    "bug_reports": "https://github.com/forestgeo/fgeo/issues",
    "repository": "https://cran.r-project.org/package=fgeo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fgeo Analyze Forest Diversity and Dynamics To help you access, transform, analyze, and\n    visualize ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to install and load the entire package-collection with a\n    single R command, and provides convenient ways to find relevant\n    documentation. Most commonly, you should not worry about the\n    individual packages that make up the package-collection as you can\n    access all features via this package. To learn more about ForestGEO\n    visit <http://www.forestgeo.si.edu/>.  "
  },
  {
    "id": 12365,
    "package_name": "fgeo.analyze",
    "title": "Analyze ForestGEO Data",
    "description": "To help you access, transform, analyze, and\n    visualize ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to implement analyses of plot species distributions,\n    topography, demography, and biomass. It also includes a torus\n    translation test to determine habitat associations of tree species as\n    described by Zuleta et al. (2018) <doi:10.1007/s11104-018-3878-0>. To\n    learn more about ForestGEO visit <https://forestgeo.si.edu/>.",
    "version": "1.1.15",
    "maintainer": "Mauro Lepore <maurolepore@gmail.com>",
    "author": "Mauro Lepore [aut, ctr, cre] (ORCID:\n    <https://orcid.org/0000-0002-1986-7988>),\n  Gabriel Arellano [aut, rev],\n  Richard Condit [aut],\n  Matteo Detto [aut],\n  Kyle Harms [aut],\n  Suzanne Lao [aut, rev],\n  KangMin Ngo [rev],\n  Haley Overstreet [rev],\n  Sabrina Russo [aut, rev],\n  Daniel Zuleta [aut, rev],\n  CTFS-ForestGEO [cph]",
    "url": "https://github.com/forestgeo/fgeo.analyze",
    "bug_reports": "https://github.com/forestgeo/fgeo.analyze/issues",
    "repository": "https://cran.r-project.org/package=fgeo.analyze",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fgeo.analyze Analyze ForestGEO Data To help you access, transform, analyze, and\n    visualize ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to implement analyses of plot species distributions,\n    topography, demography, and biomass. It also includes a torus\n    translation test to determine habitat associations of tree species as\n    described by Zuleta et al. (2018) <doi:10.1007/s11104-018-3878-0>. To\n    learn more about ForestGEO visit <https://forestgeo.si.edu/>.  "
  },
  {
    "id": 12366,
    "package_name": "fgeo.plot",
    "title": "Plot ForestGEO Data",
    "description": "To help you access, transform, analyze, and visualize\n    ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to plot ForestGEO data. To learn more about ForestGEO visit\n    <https://forestgeo.si.edu/>.",
    "version": "1.1.11",
    "maintainer": "Mauro Lepore <maurolepore@gmail.com>",
    "author": "Mauro Lepore [aut, ctr, cre] (ORCID:\n    <https://orcid.org/0000-0002-1986-7988>),\n  CTFS-ForestGEO [cph, fnd]",
    "url": "https://github.com/forestgeo/fgeo.plot,\nhttps://forestgeo.github.io/fgeo.plot/",
    "bug_reports": "https://github.com/forestgeo/fgeo.plot/issues",
    "repository": "https://cran.r-project.org/package=fgeo.plot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fgeo.plot Plot ForestGEO Data To help you access, transform, analyze, and visualize\n    ForestGEO data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to plot ForestGEO data. To learn more about ForestGEO visit\n    <https://forestgeo.si.edu/>.  "
  },
  {
    "id": 12367,
    "package_name": "fgeo.tool",
    "title": "Import and Manipulate 'ForestGEO' Data",
    "description": "To help you access, transform, analyze, and visualize\n    'ForestGEO' data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to easily import, filter, and modify 'ForestGEO' data. To\n    learn more about 'ForestGEO' visit <https://forestgeo.si.edu/>.",
    "version": "1.2.10",
    "maintainer": "Mauro Lepore <maurolepore@gmail.com>",
    "author": "Mauro Lepore [aut, ctr, cre] (ORCID:\n    <https://orcid.org/0000-0002-1986-7988>),\n  Richard Condit [aut],\n  Suzanne Lao [aut],\n  Anudeep Singh [aut],\n  CTFS-ForestGEO [cph, fnd]",
    "url": "https://forestgeo.github.io/fgeo.tool/,\nhttps://github.com/forestgeo/fgeo.tool",
    "bug_reports": "https://github.com/forestgeo/fgeo.tool/issues",
    "repository": "https://cran.r-project.org/package=fgeo.tool",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fgeo.tool Import and Manipulate 'ForestGEO' Data To help you access, transform, analyze, and visualize\n    'ForestGEO' data, we developed a collection of R packages\n    (<https://forestgeo.github.io/fgeo/>). This package, in particular,\n    helps you to easily import, filter, and modify 'ForestGEO' data. To\n    learn more about 'ForestGEO' visit <https://forestgeo.si.edu/>.  "
  },
  {
    "id": 12446,
    "package_name": "fitODBODRshiny",
    "title": "'Shiny' Application for R Package 'fitODBOD'",
    "description": "For binomial outcome data Alternate Binomial Distributions\n    and Binomial Mixture Distributions are fitted when overdispersion is\n    available.",
    "version": "1.0.2",
    "maintainer": "Amalan Mahendran <amalan0595@gmail.com>",
    "author": "Amalan Mahendran [cre, aut]",
    "url": "https://github.com/Amalan-ConStat/fitODBODRshiny,https://amalan-con-stat.shinyapps.io/fitODBODRshiny/",
    "bug_reports": "https://github.com/Amalan-ConStat/fitODBODRshiny/issues",
    "repository": "https://cran.r-project.org/package=fitODBODRshiny",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitODBODRshiny 'Shiny' Application for R Package 'fitODBOD' For binomial outcome data Alternate Binomial Distributions\n    and Binomial Mixture Distributions are fitted when overdispersion is\n    available.  "
  },
  {
    "id": 12448,
    "package_name": "fitPoly",
    "title": "Genotype Calling for Bi-Allelic Marker Assays",
    "description": "Genotyping assays for bi-allelic markers (e.g. SNPs) produce\n\tsignal intensities for the two alleles. 'fitPoly' assigns genotypes \n\t(allele dosages) to a collection of polyploid samples based on these\n\tsignal intensities. 'fitPoly' replaces the older package 'fitTetra' that was\n\tlimited (a.o.) to only tetraploid populations whereas 'fitPoly' accepts any\n\tploidy level. Reference: Voorrips RE, Gort G, Vosman B (2011)\n\t<doi:10.1186/1471-2105-12-172>. \n\tNew functions added on conversion of data from SNP array software formats, \n\tdrawing of XY-scatterplots with or without genotype colors,\n    checking against expected F1 segregation patterns,\n    comparing results from two different assays (probes) for the same SNP,\n    recovery from a saveMarkerModels() crash.",
    "version": "4.0.0",
    "maintainer": "Giorgio Tumino <giorgio.tumino@wur.nl>",
    "author": "Roeland E. Voorrips [aut],\n  Gerrit Gort [aut],\n  Alejandro Therese Navarro [aut],\n  Giorgio Tumino [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fitPoly",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitPoly Genotype Calling for Bi-Allelic Marker Assays Genotyping assays for bi-allelic markers (e.g. SNPs) produce\n\tsignal intensities for the two alleles. 'fitPoly' assigns genotypes \n\t(allele dosages) to a collection of polyploid samples based on these\n\tsignal intensities. 'fitPoly' replaces the older package 'fitTetra' that was\n\tlimited (a.o.) to only tetraploid populations whereas 'fitPoly' accepts any\n\tploidy level. Reference: Voorrips RE, Gort G, Vosman B (2011)\n\t<doi:10.1186/1471-2105-12-172>. \n\tNew functions added on conversion of data from SNP array software formats, \n\tdrawing of XY-scatterplots with or without genotype colors,\n    checking against expected F1 segregation patterns,\n    comparing results from two different assays (probes) for the same SNP,\n    recovery from a saveMarkerModels() crash.  "
  },
  {
    "id": 12450,
    "package_name": "fitbitViz",
    "title": "'Fitbit' Visualizations",
    "description": "Connection to the 'Fitbit' Web API <https://dev.fitbit.com/build/reference/web-api/> by including 'ggplot2' Visualizations, 'Leaflet' and 3-dimensional 'Rayshader' Maps. The 3-dimensional 'Rayshader' Map requires the installation of the 'CopernicusDEM' R package which includes the 30- and 90-meter elevation data.",
    "version": "1.0.7",
    "maintainer": "Lampros Mouselimis <mouselimislampros@gmail.com>",
    "author": "Lampros Mouselimis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8024-1546>)",
    "url": "https://github.com/mlampros/fitbitViz",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fitbitViz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitbitViz 'Fitbit' Visualizations Connection to the 'Fitbit' Web API <https://dev.fitbit.com/build/reference/web-api/> by including 'ggplot2' Visualizations, 'Leaflet' and 3-dimensional 'Rayshader' Maps. The 3-dimensional 'Rayshader' Map requires the installation of the 'CopernicusDEM' R package which includes the 30- and 90-meter elevation data.  "
  },
  {
    "id": 12457,
    "package_name": "fitscape",
    "title": "Classes for Fitness Landscapes and Seascapes",
    "description": "Convenient classes to model fitness landscapes and fitness\n    seascapes. A low-level package with which most users will not interact but\n    upon which other packages modeling fitness landscapes and fitness seascapes\n    will depend.",
    "version": "0.1.0",
    "maintainer": "Raoul Wadhwa <raoulwadhwa@gmail.com>",
    "author": "Raoul Wadhwa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0503-9580>),\n  Jacob Scott [aut] (ORCID: <https://orcid.org/0000-0003-2971-7673>)",
    "url": "https://github.com/rrrlw/fitscape",
    "bug_reports": "https://github.com/rrrlw/fitscape/issues",
    "repository": "https://cran.r-project.org/package=fitscape",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitscape Classes for Fitness Landscapes and Seascapes Convenient classes to model fitness landscapes and fitness\n    seascapes. A low-level package with which most users will not interact but\n    upon which other packages modeling fitness landscapes and fitness seascapes\n    will depend.  "
  },
  {
    "id": 12459,
    "package_name": "fitur",
    "title": "Fit Univariate Distributions",
    "description": "Wrapper for computing parameters for univariate distributions using MLE. It creates an object that stores d, p, q, r functions as well as parameters and statistics for diagnostics. Currently supports automated fitting from base and actuar packages. A manually fitting distribution fitting function is included to support directly specifying parameters for any distribution from ancillary packages.",
    "version": "0.6.2",
    "maintainer": "Thomas Roh <thomas@roh.engineering>",
    "author": "Thomas Roh [aut, cre]",
    "url": "https://github.com/tomroh/fitur",
    "bug_reports": "https://github.com/tomroh/fitur/issues",
    "repository": "https://cran.r-project.org/package=fitur",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitur Fit Univariate Distributions Wrapper for computing parameters for univariate distributions using MLE. It creates an object that stores d, p, q, r functions as well as parameters and statistics for diagnostics. Currently supports automated fitting from base and actuar packages. A manually fitting distribution fitting function is included to support directly specifying parameters for any distribution from ancillary packages.  "
  },
  {
    "id": 12488,
    "package_name": "fledge",
    "title": "Smoother Change Tracking and Versioning for R Packages",
    "description": "Streamlines the process of updating changelogs (NEWS.md)\n    and versioning R packages developed in git repositories.",
    "version": "0.1.4",
    "maintainer": "Kirill M\u00fcller <kirill@cynkra.com>",
    "author": "Kirill M\u00fcller [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1416-3412>),\n  Patrick Schratz [aut] (ORCID: <https://orcid.org/0000-0003-0748-6624>),\n  Ma\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>)",
    "url": "https://fledge.cynkra.com/, https://github.com/cynkra/fledge",
    "bug_reports": "https://github.com/cynkra/fledge/issues",
    "repository": "https://cran.r-project.org/package=fledge",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fledge Smoother Change Tracking and Versioning for R Packages Streamlines the process of updating changelogs (NEWS.md)\n    and versioning R packages developed in git repositories.  "
  },
  {
    "id": 12519,
    "package_name": "flippant",
    "title": "Dithionite Scramblase Assay Analysis",
    "description": "The lipid scrambling activity of protein extracts and purified\n    scramblases is often determined using a fluorescence-based assay involving\n    many manual steps. flippant offers an integrated solution for the analysis\n    and publication-grade graphical presentation of dithionite scramblase\n    assays, as well as a platform for review, dissemination and extension of the\n    strategies it employs. The package's name derives from a play on the fact\n    that lipid scrambling is also sometimes referred to as 'flipping'.\n    The package is originally published as Cotton, R.J., Ploier, B., Goren,\n    M.A., Menon, A.K., and Graumann, J. (2017). \"flippant\u2013An R package for the\n    automated analysis of fluorescence-based scramblase assays.\" BMC\n    Bioinformatics 18, 146. <DOI:10.1186/s12859-017-1542-y>.",
    "version": "1.5.7",
    "maintainer": "Johannes Graumann <johannes.graumann@uni-marburg.de>",
    "author": "Johannes Graumann [cre, aut],\n  Richard Cotton [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=flippant",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "flippant Dithionite Scramblase Assay Analysis The lipid scrambling activity of protein extracts and purified\n    scramblases is often determined using a fluorescence-based assay involving\n    many manual steps. flippant offers an integrated solution for the analysis\n    and publication-grade graphical presentation of dithionite scramblase\n    assays, as well as a platform for review, dissemination and extension of the\n    strategies it employs. The package's name derives from a play on the fact\n    that lipid scrambling is also sometimes referred to as 'flipping'.\n    The package is originally published as Cotton, R.J., Ploier, B., Goren,\n    M.A., Menon, A.K., and Graumann, J. (2017). \"flippant\u2013An R package for the\n    automated analysis of fluorescence-based scramblase assays.\" BMC\n    Bioinformatics 18, 146. <DOI:10.1186/s12859-017-1542-y>.  "
  },
  {
    "id": 12562,
    "package_name": "fnets",
    "title": "Factor-Adjusted Network Estimation and Forecasting for\nHigh-Dimensional Time Series",
    "description": "Implements methods for network estimation and forecasting of high-dimensional time series \n    exhibiting strong serial and cross-sectional correlations under a factor-adjusted vector autoregressive model.\n    See Barigozzi, Cho and Owens (2024+) <doi:10.1080/07350015.2023.2257270> for further descriptions of FNETS methodology and \n    Owens, Cho and Barigozzi (2024+) <arXiv:2301.11675> accompanying the R package.",
    "version": "0.1.6",
    "maintainer": "Haeran Cho <haeran.cho@bristol.ac.uk>",
    "author": "Matteo Barigozzi [aut],\n  Haeran Cho [cre, aut],\n  Dom Owens [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fnets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fnets Factor-Adjusted Network Estimation and Forecasting for\nHigh-Dimensional Time Series Implements methods for network estimation and forecasting of high-dimensional time series \n    exhibiting strong serial and cross-sectional correlations under a factor-adjusted vector autoregressive model.\n    See Barigozzi, Cho and Owens (2024+) <doi:10.1080/07350015.2023.2257270> for further descriptions of FNETS methodology and \n    Owens, Cho and Barigozzi (2024+) <arXiv:2301.11675> accompanying the R package.  "
  },
  {
    "id": 12565,
    "package_name": "foghorn",
    "title": "Summarize CRAN Check Results in the Terminal",
    "description": "The CRAN check results and where your package stands in the\n    CRAN submission queue in your R terminal.",
    "version": "1.6.1",
    "maintainer": "Francois Michonneau <francois.michonneau@gmail.com>",
    "author": "Francois Michonneau [aut, cre],\n  Ben Bolker [ctb]",
    "url": "https://fmichonneau.github.io/foghorn/,\nhttps://github.com/fmichonneau/foghorn",
    "bug_reports": "https://github.com/fmichonneau/foghorn/issues",
    "repository": "https://cran.r-project.org/package=foghorn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "foghorn Summarize CRAN Check Results in the Terminal The CRAN check results and where your package stands in the\n    CRAN submission queue in your R terminal.  "
  },
  {
    "id": 12589,
    "package_name": "forecastML",
    "title": "Time Series Forecasting with Machine Learning Methods",
    "description": "The purpose of 'forecastML' is to simplify the process of multi-step-ahead forecasting with standard machine learning algorithms. 'forecastML' supports lagged, dynamic, static, and grouping features for modeling single and grouped numeric or factor/sequence time series. In addition, simple wrapper functions are used to support model-building with most R packages. This approach to forecasting is inspired by Bergmeir, Hyndman, and Koo's (2018) paper \"A note on the validity of cross-validation for evaluating autoregressive time series prediction\" <doi:10.1016/j.csda.2017.11.003>.",
    "version": "0.9.0",
    "maintainer": "Nickalus Redell <nickalusredell@gmail.com>",
    "author": "Nickalus Redell",
    "url": "https://github.com/nredell/forecastML/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=forecastML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forecastML Time Series Forecasting with Machine Learning Methods The purpose of 'forecastML' is to simplify the process of multi-step-ahead forecasting with standard machine learning algorithms. 'forecastML' supports lagged, dynamic, static, and grouping features for modeling single and grouped numeric or factor/sequence time series. In addition, simple wrapper functions are used to support model-building with most R packages. This approach to forecasting is inspired by Bergmeir, Hyndman, and Koo's (2018) paper \"A note on the validity of cross-validation for evaluating autoregressive time series prediction\" <doi:10.1016/j.csda.2017.11.003>.  "
  },
  {
    "id": 12598,
    "package_name": "forestGYM",
    "title": "Forest Growth and Yield Model Based on Clutter Model",
    "description": "The Clutter model is a significant forest growth simulation tool. Grounded on individual trees and comprehensively considering factors such as competition among trees and the impact of environmental elements on growth, it can accurately reflect the growth process of forest stands. It can be applied in areas like forest resource management, harvesting planning, and ecological research. With the help of the Clutter model, people can better understand the dynamic changes of forests and provide a scientific basis for rational forest management and protecting the ecological environment. This R package can effectively realize the construction of forest growth and harvest models based on the Clutter model and achieve optimized forest management.References: Farias A, Soares C, Leite H et al(2021)<doi:10.1007/s10342-021-01380-1>. Guera O, Silva J, Ferreira R, et al(2019)<doi:10.1590/2179-8087.038117>.",
    "version": "1.0.0",
    "maintainer": "Zongzheng Chai <chaizz@126.com>",
    "author": "Zongzheng Chai [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0530-0040>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=forestGYM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forestGYM Forest Growth and Yield Model Based on Clutter Model The Clutter model is a significant forest growth simulation tool. Grounded on individual trees and comprehensively considering factors such as competition among trees and the impact of environmental elements on growth, it can accurately reflect the growth process of forest stands. It can be applied in areas like forest resource management, harvesting planning, and ecological research. With the help of the Clutter model, people can better understand the dynamic changes of forests and provide a scientific basis for rational forest management and protecting the ecological environment. This R package can effectively realize the construction of forest growth and harvest models based on the Clutter model and achieve optimized forest management.References: Farias A, Soares C, Leite H et al(2021)<doi:10.1007/s10342-021-01380-1>. Guera O, Silva J, Ferreira R, et al(2019)<doi:10.1590/2179-8087.038117>.  "
  },
  {
    "id": 12625,
    "package_name": "forplo",
    "title": "Flexible Forest Plots",
    "description": "Simplifies the creation and customization of forest plots (alternatively called dot-and-whisker plots). Input classes accepted by 'forplo' are data.frame, matrix, lm, glm, and coxph. 'forplo' was written in base R and does not depend on other packages.",
    "version": "0.2.5",
    "maintainer": "\"Vincent ten Cate, PhD\" <vincent10kd@gmail.com>",
    "author": "Vincent ten Cate, PhD [cre, aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=forplo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forplo Flexible Forest Plots Simplifies the creation and customization of forest plots (alternatively called dot-and-whisker plots). Input classes accepted by 'forplo' are data.frame, matrix, lm, glm, and coxph. 'forplo' was written in base R and does not depend on other packages.  "
  },
  {
    "id": 12655,
    "package_name": "fqacalc",
    "title": "Calculate Floristic Quality Assessment Metrics",
    "description": "A collection of functions for calculating Floristic Quality\n    Assessment (FQA) metrics using regional FQA databases that have been\n    approved or approved with reservations as ecological planning models\n    by the U.S. Army Corps of Engineers (USACE). For information on FQA\n    see Spyreas (2019) <doi:10.1002/ecs2.2825>. These databases are stored\n    in a sister R package, 'fqadata'. Both packages were developed for the\n    USACE by the U.S. Army Engineer Research and Development Center\u2019s\n    Environmental Laboratory.",
    "version": "1.1.1",
    "maintainer": "Todd Swannack <tswannack@gmail.com>",
    "author": "Iris Foxfoot [aut],\n  Todd Swannack [cre],\n  U.S. Army Engineer Research and Development Center [cph, fnd]",
    "url": "https://github.com/EcoModTeam/fqacalc",
    "bug_reports": "https://github.com/EcoModTeam/fqacalc/issues",
    "repository": "https://cran.r-project.org/package=fqacalc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fqacalc Calculate Floristic Quality Assessment Metrics A collection of functions for calculating Floristic Quality\n    Assessment (FQA) metrics using regional FQA databases that have been\n    approved or approved with reservations as ecological planning models\n    by the U.S. Army Corps of Engineers (USACE). For information on FQA\n    see Spyreas (2019) <doi:10.1002/ecs2.2825>. These databases are stored\n    in a sister R package, 'fqadata'. Both packages were developed for the\n    USACE by the U.S. Army Engineer Research and Development Center\u2019s\n    Environmental Laboratory.  "
  },
  {
    "id": 12656,
    "package_name": "fqadata",
    "title": "Contains Regional Floristic Quality Assessment Databases",
    "description": "Contains regional Floristic Quality Assessment databases that\n    have been approved or approved with reservations by the U.S. Army\n    Corps of Engineers (USACE). Paired with the 'fqacalc' R package, these\n    data sets allow for Floristic Quality Assessment metrics to be\n    calculated. For information on FQA see Spyreas (2019)\n    <doi:10.1002/ecs2.2825>. Both packages were developed for the USACE by\n    the U.S.  Army Engineer Research and Development Center's\n    Environmental Laboratory.",
    "version": "1.1.1",
    "maintainer": "Todd Swannack <tswannack@gmail.com>",
    "author": "Iris Foxfoot [aut],\n  Todd Swannack [cre],\n  U.S. Army Engineer Research and Development Center [cph, fnd]",
    "url": "https://github.com/EcoModTeam/fqadata",
    "bug_reports": "https://github.com/EcoModTeam/fqadata/issues",
    "repository": "https://cran.r-project.org/package=fqadata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fqadata Contains Regional Floristic Quality Assessment Databases Contains regional Floristic Quality Assessment databases that\n    have been approved or approved with reservations by the U.S. Army\n    Corps of Engineers (USACE). Paired with the 'fqacalc' R package, these\n    data sets allow for Floristic Quality Assessment metrics to be\n    calculated. For information on FQA see Spyreas (2019)\n    <doi:10.1002/ecs2.2825>. Both packages were developed for the USACE by\n    the U.S.  Army Engineer Research and Development Center's\n    Environmental Laboratory.  "
  },
  {
    "id": 12675,
    "package_name": "frailtypack",
    "title": "Shared, Joint (Generalized) Frailty Models; Surrogate Endpoints",
    "description": "The following several classes of frailty models using a\n    penalized likelihood estimation on the hazard function but also a\n    parametric estimation can be fit using this R package: 1) A shared\n    frailty model (with gamma or log-normal frailty distribution) and Cox\n    proportional hazard model. Clustered and recurrent survival times can\n    be studied.  2) Additive frailty models for proportional hazard models\n    with two correlated random effects (intercept random effect with\n    random slope).  3) Nested frailty models for hierarchically clustered\n    data (with 2 levels of clustering) by including two iid gamma random\n    effects.  4) Joint frailty models in the context of the joint\n    modelling for recurrent events with terminal event for clustered data\n    or not. A joint frailty model for two semi-competing risks and\n    clustered data is also proposed.  5) Joint general frailty models in\n    the context of the joint modelling for recurrent events with terminal\n    event data with two independent frailty terms.  6) Joint Nested\n    frailty models in the context of the joint modelling for recurrent\n    events with terminal event, for hierarchically clustered data (with\n    two levels of clustering) by including two iid gamma random effects.\n    7) Multivariate joint frailty models for two types of recurrent events\n    and a terminal event.  8) Joint models for longitudinal data and a\n    terminal event.  9) Trivariate joint models for longitudinal data,\n    recurrent events and a terminal event.  10) Joint frailty models for\n    the validation of surrogate endpoints in multiple randomized clinical\n    trials with failure-time and/or longitudinal endpoints with the\n    possibility to use a mediation analysis model.  11) Conditional and\n    Marginal two-part joint models for longitudinal semicontinuous data\n    and a terminal event.  12) Joint frailty-copula models for the\n    validation of surrogate endpoints in multiple randomized clinical\n    trials with failure-time endpoints.  13) Generalized shared and joint\n    frailty models for recurrent and terminal events. Proportional hazards\n    (PH), additive hazard (AH), proportional odds (PO) and probit models\n    are available in a fully parametric framework. For PH and AH models,\n    it is possible to consider type-varying coefficients and flexible\n    semiparametric hazard function.  Prediction values are available (for\n    a terminal event or for a new recurrent event). Left-truncated (not\n    for Joint model), right-censored data, interval-censored data (only\n    for Cox proportional hazard and shared frailty model) and strata are\n    allowed. In each model, the random effects have the gamma or normal\n    distribution. Now, you can also consider time-varying covariates\n    effects in Cox, shared and joint frailty models (1-5). The package\n    includes concordance measures for Cox proportional hazards models and\n    for shared frailty models.  14) Competing Joint Frailty Model: A\n    single type of recurrent event and two terminal events.  15) functions \n    to compute power and sample size for four Gamma-frailty-based designs: \n    Shared Frailty Models, Nested Frailty Models, Joint Frailty Models, and \n    General Joint Frailty Models. Each design includes two primary functions: a \n    power function, which computes power given a specified sample size; \n    and a sample size function, which computes the required sample size to achieve \n    a specified power. 16) Weibull Illness-Death model with or without shared frailty\n    between transitions. Left-truncated and right-censored data are allowed. \n    17) Weibull Competing risks model with or without shared frailty between the \n    transitions. Left-truncated and right-censored data are allowed. Moreover, the package can be used with its shiny\n    application, in a local mode or by following the link below.",
    "version": "3.8.0",
    "maintainer": "Virginie Rondeau <virginie.rondeau@u-bordeaux.fr>",
    "author": "Virginie Rondeau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7109-4831>),\n  Juan R. Gonzalez [aut],\n  Yassin Mazroui [aut],\n  Audrey Mauguen [aut],\n  Amadou Diakite [aut],\n  Alexandre Laurent [aut],\n  Myriam Lopez [aut],\n  Agnieszka Krol [aut],\n  Casimir L. Sofeu [aut],\n  Julien Dumerc [aut],\n  Denis Rustand [aut],\n  Jocelyn Chauvet [aut],\n  Quentin Le Coent [aut],\n  Romain Pierlot [aut],\n  Lacey Etzkorn [aut],\n  Derek Dinart [aut],\n  Adrien Oru\u00e9 [aut],\n  Ayoub Bifenzi [aut],\n  Viviane Philipps [aut],\n  David Hill [cph],\n  John Burkardt [cph],\n  Alan Genz [cph],\n  Ashwith J. Rego [cph]",
    "url": "https://virginie1rondeau.wixsite.com/virginierondeau/software-frailtypack\nhttps://frailtypack-pkg.shinyapps.io/shiny_frailtypack/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=frailtypack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "frailtypack Shared, Joint (Generalized) Frailty Models; Surrogate Endpoints The following several classes of frailty models using a\n    penalized likelihood estimation on the hazard function but also a\n    parametric estimation can be fit using this R package: 1) A shared\n    frailty model (with gamma or log-normal frailty distribution) and Cox\n    proportional hazard model. Clustered and recurrent survival times can\n    be studied.  2) Additive frailty models for proportional hazard models\n    with two correlated random effects (intercept random effect with\n    random slope).  3) Nested frailty models for hierarchically clustered\n    data (with 2 levels of clustering) by including two iid gamma random\n    effects.  4) Joint frailty models in the context of the joint\n    modelling for recurrent events with terminal event for clustered data\n    or not. A joint frailty model for two semi-competing risks and\n    clustered data is also proposed.  5) Joint general frailty models in\n    the context of the joint modelling for recurrent events with terminal\n    event data with two independent frailty terms.  6) Joint Nested\n    frailty models in the context of the joint modelling for recurrent\n    events with terminal event, for hierarchically clustered data (with\n    two levels of clustering) by including two iid gamma random effects.\n    7) Multivariate joint frailty models for two types of recurrent events\n    and a terminal event.  8) Joint models for longitudinal data and a\n    terminal event.  9) Trivariate joint models for longitudinal data,\n    recurrent events and a terminal event.  10) Joint frailty models for\n    the validation of surrogate endpoints in multiple randomized clinical\n    trials with failure-time and/or longitudinal endpoints with the\n    possibility to use a mediation analysis model.  11) Conditional and\n    Marginal two-part joint models for longitudinal semicontinuous data\n    and a terminal event.  12) Joint frailty-copula models for the\n    validation of surrogate endpoints in multiple randomized clinical\n    trials with failure-time endpoints.  13) Generalized shared and joint\n    frailty models for recurrent and terminal events. Proportional hazards\n    (PH), additive hazard (AH), proportional odds (PO) and probit models\n    are available in a fully parametric framework. For PH and AH models,\n    it is possible to consider type-varying coefficients and flexible\n    semiparametric hazard function.  Prediction values are available (for\n    a terminal event or for a new recurrent event). Left-truncated (not\n    for Joint model), right-censored data, interval-censored data (only\n    for Cox proportional hazard and shared frailty model) and strata are\n    allowed. In each model, the random effects have the gamma or normal\n    distribution. Now, you can also consider time-varying covariates\n    effects in Cox, shared and joint frailty models (1-5). The package\n    includes concordance measures for Cox proportional hazards models and\n    for shared frailty models.  14) Competing Joint Frailty Model: A\n    single type of recurrent event and two terminal events.  15) functions \n    to compute power and sample size for four Gamma-frailty-based designs: \n    Shared Frailty Models, Nested Frailty Models, Joint Frailty Models, and \n    General Joint Frailty Models. Each design includes two primary functions: a \n    power function, which computes power given a specified sample size; \n    and a sample size function, which computes the required sample size to achieve \n    a specified power. 16) Weibull Illness-Death model with or without shared frailty\n    between transitions. Left-truncated and right-censored data are allowed. \n    17) Weibull Competing risks model with or without shared frailty between the \n    transitions. Left-truncated and right-censored data are allowed. Moreover, the package can be used with its shiny\n    application, in a local mode or by following the link below.  "
  },
  {
    "id": 12712,
    "package_name": "fromhere",
    "title": "File Paths Relative to Project Roots",
    "description": "Provides a set of helper functions for constructing file paths \n    relative to the root of various types of projects, such as R packages, Git\n    repositories, and more. File paths are specified with function arguments,\n    or `$` to navigate into folders to specific files supported by \n    auto-completion.",
    "version": "0.1.0",
    "maintainer": "Mitchell O'Hara-Wild <mail@mitchelloharawild.com>",
    "author": "Mitchell O'Hara-Wild [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6729-7695>)",
    "url": "https://github.com/mitchelloharawild/fromhere",
    "bug_reports": "https://github.com/mitchelloharawild/fromhere/issues",
    "repository": "https://cran.r-project.org/package=fromhere",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fromhere File Paths Relative to Project Roots Provides a set of helper functions for constructing file paths \n    relative to the root of various types of projects, such as R packages, Git\n    repositories, and more. File paths are specified with function arguments,\n    or `$` to navigate into folders to specific files supported by \n    auto-completion.  "
  },
  {
    "id": 12721,
    "package_name": "fsdaR",
    "title": "Robust Data Analysis Through Monitoring and Dynamic\nVisualization",
    "description": "Provides interface to the 'MATLAB' toolbox 'Flexible Statistical Data Analysis\n    (FSDA)' which is comprehensive and computationally efficient\n    software package for robust statistics in regression, multivariate\n    and categorical data analysis. The current R version implements tools\n    for regression: (forward search, S- and MM-estimation, least trimmed\n    squares (LTS) and least median of squares (LMS)), for multivariate analysis\n    (forward search, S- and MM-estimation), for cluster analysis and cluster-wise regression.\n    The distinctive feature of our package is the possibility of\n    monitoring the statistics of interest as a function of breakdown point,\n    efficiency or subset size, depending on the estimator. This is\n    accompanied by a rich set of graphical features, such as dynamic\n    brushing, linking, particularly useful for exploratory data analysis.",
    "version": "0.9-0",
    "maintainer": "Valentin Todorov <valentin.todorov@chello.at>",
    "author": "Valentin Todorov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4215-0245>),\n  Emmanuele Sordini [aut],\n  Aldo Corbellini [ctb],\n  Francesca Torti [ctb],\n  Marco Riani [ctb],\n  Domenico Perrotta [ctb],\n  Andrea Cerioli [ctb]",
    "url": "https://github.com/UniprJRC/fsdaR",
    "bug_reports": "https://github.com/UniprJRC/fsdaR/issues",
    "repository": "https://cran.r-project.org/package=fsdaR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fsdaR Robust Data Analysis Through Monitoring and Dynamic\nVisualization Provides interface to the 'MATLAB' toolbox 'Flexible Statistical Data Analysis\n    (FSDA)' which is comprehensive and computationally efficient\n    software package for robust statistics in regression, multivariate\n    and categorical data analysis. The current R version implements tools\n    for regression: (forward search, S- and MM-estimation, least trimmed\n    squares (LTS) and least median of squares (LMS)), for multivariate analysis\n    (forward search, S- and MM-estimation), for cluster analysis and cluster-wise regression.\n    The distinctive feature of our package is the possibility of\n    monitoring the statistics of interest as a function of breakdown point,\n    efficiency or subset size, depending on the estimator. This is\n    accompanied by a rich set of graphical features, such as dynamic\n    brushing, linking, particularly useful for exploratory data analysis.  "
  },
  {
    "id": 12742,
    "package_name": "fuel",
    "title": "Framework for Unified Estimation in Lognormal Models",
    "description": "Lognormal models have broad applications in various research areas such as economics, actuarial science, biology, environmental science and psychology. The estimation problem in lognormal models has been extensively studied. This R package 'fuel' implements thirty-nine existing and newly proposed estimators. See Zhang, F., and Gou, J. (2020), A unified framework for estimation in lognormal models, Technical report. ",
    "version": "1.2.0",
    "maintainer": "Jiangtao Gou <gouRpackage@gmail.com>",
    "author": "Jiangtao Gou and Fengqing (Zoe) Zhang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fuel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fuel Framework for Unified Estimation in Lognormal Models Lognormal models have broad applications in various research areas such as economics, actuarial science, biology, environmental science and psychology. The estimation problem in lognormal models has been extensively studied. This R package 'fuel' implements thirty-nine existing and newly proposed estimators. See Zhang, F., and Gou, J. (2020), A unified framework for estimation in lognormal models, Technical report.   "
  },
  {
    "id": 12745,
    "package_name": "fuj",
    "title": "Functions and Utilities for Jordan",
    "description": "Provides core functions and utilities for packages and other code\n    developed by Jordan Mark Barbone.",
    "version": "0.2.2",
    "maintainer": "Jordan Mark Barbone <jmbarbone@gmail.com>",
    "author": "Jordan Mark Barbone [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-9788-3628>)",
    "url": "https://jmbarbone.github.io/fuj/, https://github.com/jmbarbone/fuj",
    "bug_reports": "https://github.com/jmbarbone/fuj/issues",
    "repository": "https://cran.r-project.org/package=fuj",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fuj Functions and Utilities for Jordan Provides core functions and utilities for packages and other code\n    developed by Jordan Mark Barbone.  "
  },
  {
    "id": 12746,
    "package_name": "fullROC",
    "title": "Plot Full ROC Curves using Eyewitness Lineup Data",
    "description": "Enable researchers to adjust identification rates using the 1/(lineup size) method, generate the full receiver operating characteristic (ROC) curves, and statistically compare the area under the curves (AUC). \n  References: Yueran Yang & Andrew Smith. (2020). \"fullROC: An R package for generating and analyzing eyewitness-lineup ROC curves\". <doi:10.13140/RG.2.2.20415.94885/1>  ,\n              Andrew Smith, Yueran Yang, & Gary Wells. (2020). \"Distinguishing between investigator discriminability and eyewitness discriminability: A method for creating full receiver operating characteristic curves of lineup identification performance\". Perspectives on Psychological Science, 15(3), 589-607. <doi:10.1177/1745691620902426>.",
    "version": "0.1.0",
    "maintainer": "Yueran Yang <yuerany@unr.edu>",
    "author": "Yueran Yang [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/yuerany/fullROC/issues",
    "repository": "https://cran.r-project.org/package=fullROC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fullROC Plot Full ROC Curves using Eyewitness Lineup Data Enable researchers to adjust identification rates using the 1/(lineup size) method, generate the full receiver operating characteristic (ROC) curves, and statistically compare the area under the curves (AUC). \n  References: Yueran Yang & Andrew Smith. (2020). \"fullROC: An R package for generating and analyzing eyewitness-lineup ROC curves\". <doi:10.13140/RG.2.2.20415.94885/1>  ,\n              Andrew Smith, Yueran Yang, & Gary Wells. (2020). \"Distinguishing between investigator discriminability and eyewitness discriminability: A method for creating full receiver operating characteristic curves of lineup identification performance\". Perspectives on Psychological Science, 15(3), 589-607. <doi:10.1177/1745691620902426>.  "
  },
  {
    "id": 12784,
    "package_name": "fusen",
    "title": "Build a Package from Rmarkdown Files",
    "description": "Use Rmarkdown First method to build your package. Start your\n    package with documentation, functions, examples and tests in the same\n    unique file. Everything can be set from the Rmarkdown template file\n    provided in your project, then inflated as a package. Inflating the\n    template copies the relevant chunks and sections in the appropriate\n    files required for package development.",
    "version": "0.7.2",
    "maintainer": "Vincent Guyader <vincent@thinkr.fr>",
    "author": "Sebastien Rochette [aut] (ORCID:\n    <https://orcid.org/0000-0002-1565-9313>, creator),\n  Vincent Guyader [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0671-9270>),\n  Yohann Mansiaux [aut],\n  ThinkR [cph]",
    "url": "https://thinkr-open.github.io/fusen/,\nhttps://github.com/Thinkr-open/fusen",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fusen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fusen Build a Package from Rmarkdown Files Use Rmarkdown First method to build your package. Start your\n    package with documentation, functions, examples and tests in the same\n    unique file. Everything can be set from the Rmarkdown template file\n    provided in your project, then inflated as a package. Inflating the\n    template copies the relevant chunks and sections in the appropriate\n    files required for package development.  "
  },
  {
    "id": 12789,
    "package_name": "futile.options",
    "title": "Futile Options Management",
    "description": "A scoped options management framework. Used in other packages.",
    "version": "1.0.1",
    "maintainer": "Brian Lee Yung Rowe <r@zatonovo.com>",
    "author": "Brian Lee Yung Rowe",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=futile.options",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "futile.options Futile Options Management A scoped options management framework. Used in other packages.  "
  },
  {
    "id": 12822,
    "package_name": "gMCPLite",
    "title": "Lightweight Graph Based Multiple Comparison Procedures",
    "description": "A lightweight fork of 'gMCP' with functions for graphical\n    described multiple test procedures introduced in\n    Bretz et al. (2009) <doi:10.1002/sim.3495> and\n    Bretz et al. (2011) <doi:10.1002/bimj.201000239>.\n    Implements a flexible function using 'ggplot2' to create\n    multiplicity graph visualizations.\n    Contains instructions of multiplicity graph and graphical testing for\n    group sequential design, described in\n    Maurer and Bretz (2013) <doi:10.1080/19466315.2013.807748>,\n    with necessary unit testing using 'testthat'.",
    "version": "0.1.6",
    "maintainer": "Nan Xiao <nan.xiao1@merck.com>",
    "author": "Yalin Zhu [aut] (ORCID: <https://orcid.org/0000-0003-3830-8660>),\n  Yilong Zhang [aut],\n  Xuan Deng [aut],\n  Keaven Anderson [aut],\n  Nan Xiao [aut, cre] (ORCID: <https://orcid.org/0000-0002-0250-5673>),\n  Kornelius Rohmeyer [ctb] (gMCP author),\n  Florian Klinglmueller [ctb] (gMCP author),\n  gMCP project contributors [cph] (gMCP package),\n  Merck & Co., Inc., Rahway, NJ, USA and its affiliates [cph]",
    "url": "https://merck.github.io/gMCPLite/,\nhttps://github.com/Merck/gMCPLite",
    "bug_reports": "https://github.com/Merck/gMCPLite/issues",
    "repository": "https://cran.r-project.org/package=gMCPLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gMCPLite Lightweight Graph Based Multiple Comparison Procedures A lightweight fork of 'gMCP' with functions for graphical\n    described multiple test procedures introduced in\n    Bretz et al. (2009) <doi:10.1002/sim.3495> and\n    Bretz et al. (2011) <doi:10.1002/bimj.201000239>.\n    Implements a flexible function using 'ggplot2' to create\n    multiplicity graph visualizations.\n    Contains instructions of multiplicity graph and graphical testing for\n    group sequential design, described in\n    Maurer and Bretz (2013) <doi:10.1080/19466315.2013.807748>,\n    with necessary unit testing using 'testthat'.  "
  },
  {
    "id": 12849,
    "package_name": "galaxias",
    "title": "Describe, Package, and Share Biodiversity Data",
    "description": "The Darwin Core data standard is widely used to share \n  biodiversity information, most notably by the Global Biodiversity Information \n  Facility and its partner nodes; but converting data to this standard can be \n  tricky. 'galaxias' is functionally similar to 'devtools', but with a focus on \n  building Darwin Core Archives rather than R packages, enabling data to be \n  shared and re-used with relative ease. For details see \n  Wieczorek and colleagues (2012) <doi:10.1371/journal.pone.0029715>.",
    "version": "0.1.1",
    "maintainer": "Martin Westgate <martin.westgate@csiro.au>",
    "author": "Martin Westgate [aut, cre],\n  Shandiya Balasubramaniam [aut],\n  Dax Kellie [aut]",
    "url": "https://galaxias.ala.org.au/R/",
    "bug_reports": "https://github.com/AtlasOfLivingAustralia/galaxias/issues",
    "repository": "https://cran.r-project.org/package=galaxias",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "galaxias Describe, Package, and Share Biodiversity Data The Darwin Core data standard is widely used to share \n  biodiversity information, most notably by the Global Biodiversity Information \n  Facility and its partner nodes; but converting data to this standard can be \n  tricky. 'galaxias' is functionally similar to 'devtools', but with a focus on \n  building Darwin Core Archives rather than R packages, enabling data to be \n  shared and re-used with relative ease. For details see \n  Wieczorek and colleagues (2012) <doi:10.1371/journal.pone.0029715>.  "
  },
  {
    "id": 12900,
    "package_name": "gasanalyzer",
    "title": "Import, Recompute and Analyze Data from Portable Gas Analyzers",
    "description": "\n    The gasanalyzer R package offers methods for importing, preprocessing,\n    and analyzing data related to photosynthetic characteristics (gas exchange,\n    chlorophyll fluorescence and isotope ratios). It translates variable names\n    into a standard format, and can recalculate derived, physiological \n    quantities using imported or predefined equations. The package also allows\n    users to assess the sensitivity of their results to different assumptions\n    used in the calculations. \n    See also Tholen (2024) <doi:10.1093/aobpla/plae035>.",
    "version": "0.4.3",
    "maintainer": "Danny Tholen <thalecress+p@gmail.com>",
    "author": "Danny Tholen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9517-0939>, affiliation: University of\n    Natural Resources and Life Sciences, Vienna)",
    "url": "https://gitlab.com/plantphys/gasanalyzer",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gasanalyzer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gasanalyzer Import, Recompute and Analyze Data from Portable Gas Analyzers \n    The gasanalyzer R package offers methods for importing, preprocessing,\n    and analyzing data related to photosynthetic characteristics (gas exchange,\n    chlorophyll fluorescence and isotope ratios). It translates variable names\n    into a standard format, and can recalculate derived, physiological \n    quantities using imported or predefined equations. The package also allows\n    users to assess the sensitivity of their results to different assumptions\n    used in the calculations. \n    See also Tholen (2024) <doi:10.1093/aobpla/plae035>.  "
  },
  {
    "id": 12931,
    "package_name": "gcbd",
    "title": "'GPU'/CPU Benchmarking in Debian-Based Systems",
    "description": "'GPU'/CPU Benchmarking on Debian-package based systems\n This package benchmarks performance of a few standard linear algebra\n operations (such as a matrix product and QR, SVD and LU decompositions)\n across a number of different 'BLAS' libraries as well as a 'GPU' implementation.\n To do so, it takes advantage of the ability to 'plug and play' different\n 'BLAS' implementations easily on a Debian and/or Ubuntu system.  The current\n version supports\n  - 'Reference BLAS' ('refblas') which are un-accelerated as a baseline\n  - Atlas which are tuned but typically configure single-threaded\n  - Atlas39 which are tuned and configured for multi-threaded mode\n  - 'Goto Blas' which are accelerated and multi-threaded\n  - 'Intel MKL' which is a commercial accelerated and multithreaded version.\n As for 'GPU' computing, we use the CRAN package\n  - 'gputools'\n For 'Goto Blas', the 'gotoblas2-helper' script from the ISM in Tokyo can be\n used. For 'Intel MKL' we use the Revolution R packages from Ubuntu 9.10.",
    "version": "0.2.7",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>)",
    "url": "https://github.com/eddelbuettel/gcbd",
    "bug_reports": "https://github.com/eddelbuettel/gcbd/issues",
    "repository": "https://cran.r-project.org/package=gcbd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gcbd 'GPU'/CPU Benchmarking in Debian-Based Systems 'GPU'/CPU Benchmarking on Debian-package based systems\n This package benchmarks performance of a few standard linear algebra\n operations (such as a matrix product and QR, SVD and LU decompositions)\n across a number of different 'BLAS' libraries as well as a 'GPU' implementation.\n To do so, it takes advantage of the ability to 'plug and play' different\n 'BLAS' implementations easily on a Debian and/or Ubuntu system.  The current\n version supports\n  - 'Reference BLAS' ('refblas') which are un-accelerated as a baseline\n  - Atlas which are tuned but typically configure single-threaded\n  - Atlas39 which are tuned and configured for multi-threaded mode\n  - 'Goto Blas' which are accelerated and multi-threaded\n  - 'Intel MKL' which is a commercial accelerated and multithreaded version.\n As for 'GPU' computing, we use the CRAN package\n  - 'gputools'\n For 'Goto Blas', the 'gotoblas2-helper' script from the ISM in Tokyo can be\n used. For 'Intel MKL' we use the Revolution R packages from Ubuntu 9.10.  "
  },
  {
    "id": 12942,
    "package_name": "gcplyr",
    "title": "Wrangle and Analyze Growth Curve Data",
    "description": "Easy wrangling and model-free analysis of\n    microbial growth curve data, as commonly output by plate readers.\n    Tools for reshaping common plate reader outputs into 'tidy' formats and\n    merging them with design information, making data easy to work with using \n    'gcplyr' and other packages. Also streamlines common growth curve\n    processing steps, like smoothing and calculating derivatives, and\n    facilitates model-free characterization and analysis of growth data.\n    See methods at <https://mikeblazanin.github.io/gcplyr/>.",
    "version": "1.12.0",
    "maintainer": "Mike Blazanin <mikeblazanin@gmail.com>",
    "author": "Mike Blazanin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4630-6235>)",
    "url": "https://mikeblazanin.github.io/gcplyr/,\nhttps://github.com/mikeblazanin/gcplyr/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gcplyr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gcplyr Wrangle and Analyze Growth Curve Data Easy wrangling and model-free analysis of\n    microbial growth curve data, as commonly output by plate readers.\n    Tools for reshaping common plate reader outputs into 'tidy' formats and\n    merging them with design information, making data easy to work with using \n    'gcplyr' and other packages. Also streamlines common growth curve\n    processing steps, like smoothing and calculating derivatives, and\n    facilitates model-free characterization and analysis of growth data.\n    See methods at <https://mikeblazanin.github.io/gcplyr/>.  "
  },
  {
    "id": 12959,
    "package_name": "gdxdt",
    "title": "IO for GAMS GDX Files using 'data.table'",
    "description": "Interfaces GAMS data (*.gdx) files with 'data.table's using the GAMS R package 'gdxrrw'. The 'gdxrrw' package is available on the GAMS wiki: <https://support.gams.com/doku.php?id=gdxrrw:interfacing_gams_and_r>.",
    "version": "0.1.0",
    "maintainer": "Alois Dirnaichner <alodi@directbox.com>",
    "author": "Alois Dirnaichner [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gdxdt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gdxdt IO for GAMS GDX Files using 'data.table' Interfaces GAMS data (*.gdx) files with 'data.table's using the GAMS R package 'gdxrrw'. The 'gdxrrw' package is available on the GAMS wiki: <https://support.gams.com/doku.php?id=gdxrrw:interfacing_gams_and_r>.  "
  },
  {
    "id": 13002,
    "package_name": "geneExpressionFromGEO",
    "title": "Easily Downloads a Gene Expression Dataset from a GEO Code and\nRetrieves the Gene Symbols of Its Probesets",
    "description": "A function that reads in the GEO code of a gene expression dataset, retrieves its data from GEO, (optionally) retrieves the gene symbols of the dataset, and returns a simple dataframe table containing all the data. Platforms available: GPL11532, GPL23126, GPL6244, GPL8300, GPL80, GPL96, GPL570, GPL571, GPL20115, GPL1293,  GPL6102, GPL6104, GPL6883, GPL6884, GPL13497, GPL14550, GPL17077, GPL6480. GEO: Gene Expression Omnibus. ID: identifier code. The GEO datasets are downloaded from the URL <https://ftp.ncbi.nlm.nih.gov/geo/series/>. More information can be found in the following manuscript: Davide Chicco, \"geneExpressionFromGEO: an R package to facilitate data reading from Gene Expression Omnibus (GEO)\". Microarray Data Analysis, Methods in Molecular Biology, volume 2401, chapter 12, pages 187-194, Springer Protocols, 2021, <doi:10.1007/978-1-0716-1839-4_12>.",
    "version": "1.3",
    "maintainer": "Davide Chicco <davidechicco@davidechicco.it>",
    "author": "Davide Chicco [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9655-7142>)",
    "url": "https://github.com/davidechicco/geneExpressionFromGEO",
    "bug_reports": "https://github.com/davidechicco/geneExpressionFromGEO/issues",
    "repository": "https://cran.r-project.org/package=geneExpressionFromGEO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geneExpressionFromGEO Easily Downloads a Gene Expression Dataset from a GEO Code and\nRetrieves the Gene Symbols of Its Probesets A function that reads in the GEO code of a gene expression dataset, retrieves its data from GEO, (optionally) retrieves the gene symbols of the dataset, and returns a simple dataframe table containing all the data. Platforms available: GPL11532, GPL23126, GPL6244, GPL8300, GPL80, GPL96, GPL570, GPL571, GPL20115, GPL1293,  GPL6102, GPL6104, GPL6883, GPL6884, GPL13497, GPL14550, GPL17077, GPL6480. GEO: Gene Expression Omnibus. ID: identifier code. The GEO datasets are downloaded from the URL <https://ftp.ncbi.nlm.nih.gov/geo/series/>. More information can be found in the following manuscript: Davide Chicco, \"geneExpressionFromGEO: an R package to facilitate data reading from Gene Expression Omnibus (GEO)\". Microarray Data Analysis, Methods in Molecular Biology, volume 2401, chapter 12, pages 187-194, Springer Protocols, 2021, <doi:10.1007/978-1-0716-1839-4_12>.  "
  },
  {
    "id": 13096,
    "package_name": "geospark",
    "title": "Bring Local Sf to Spark",
    "description": "R binds 'GeoSpark' <http://geospark.datasyslab.org/> extending 'sparklyr' \n    <https://spark.rstudio.com/> R package to make distributed 'geocomputing' easier. Sf is a\n    package that provides [simple features] <https://en.wikipedia.org/wiki/Simple_Features> access\n    for R and which is a leading 'geospatial' data processing tool. 'Geospark' R package bring \n    the same simple features access like sf but running on Spark distributed system.",
    "version": "0.3.1",
    "maintainer": "Harry Zhu <7harryprince@gmail.com>",
    "author": "Harry Zhu [aut, cre],\n  Javier Luraschi [ctb]",
    "url": "",
    "bug_reports": "https://github.com/harryprince/geospark/issues",
    "repository": "https://cran.r-project.org/package=geospark",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geospark Bring Local Sf to Spark R binds 'GeoSpark' <http://geospark.datasyslab.org/> extending 'sparklyr' \n    <https://spark.rstudio.com/> R package to make distributed 'geocomputing' easier. Sf is a\n    package that provides [simple features] <https://en.wikipedia.org/wiki/Simple_Features> access\n    for R and which is a leading 'geospatial' data processing tool. 'Geospark' R package bring \n    the same simple features access like sf but running on Spark distributed system.  "
  },
  {
    "id": 13101,
    "package_name": "geostats",
    "title": "An Introduction to Statistics for Geoscientists",
    "description": "A collection of datasets and simplified functions for an introductory (geo)statistics module at University College London. Provides functionality for compositional, directional and spatial data, including ternary diagrams, Wulff and Schmidt stereonets, and ordinary kriging interpolation. Implements logistic and (additive and centred) logratio transformations. Computes vector averages and concentration parameters for the von-Mises distribution. Includes a collection of natural and synthetic fractals, and a simulator for deterministic chaos using a magnetic pendulum example. The main purpose of these functions is pedagogical. Researchers can find more complete alternatives for these tools in other packages such as 'compositions', 'robCompositions', 'sp', 'gstat' and 'RFOC'. All the functions are written in plain R, with no compiled code and a minimal number of dependencies. Theoretical background and worked examples are available at <https://tinyurl.com/UCLgeostats/>.",
    "version": "1.6",
    "maintainer": "Pieter Vermeesch <p.vermeesch@ucl.ac.uk>",
    "author": "Pieter Vermeesch [aut, cre]",
    "url": "https://github.com/pvermees/geostats/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=geostats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geostats An Introduction to Statistics for Geoscientists A collection of datasets and simplified functions for an introductory (geo)statistics module at University College London. Provides functionality for compositional, directional and spatial data, including ternary diagrams, Wulff and Schmidt stereonets, and ordinary kriging interpolation. Implements logistic and (additive and centred) logratio transformations. Computes vector averages and concentration parameters for the von-Mises distribution. Includes a collection of natural and synthetic fractals, and a simulator for deterministic chaos using a magnetic pendulum example. The main purpose of these functions is pedagogical. Researchers can find more complete alternatives for these tools in other packages such as 'compositions', 'robCompositions', 'sp', 'gstat' and 'RFOC'. All the functions are written in plain R, with no compiled code and a minimal number of dependencies. Theoretical background and worked examples are available at <https://tinyurl.com/UCLgeostats/>.  "
  },
  {
    "id": 13107,
    "package_name": "geozoo",
    "title": "Zoo of Geometric Objects",
    "description": "Geometric objects defined in 'geozoo' can be simulated or displayed in the R package 'tourr'.",
    "version": "0.5.1",
    "maintainer": "Barret Schloerke <schloerke@gmail.com>",
    "author": "Barret Schloerke [aut, cre],\n  Di Cook [ths],\n  Hadley Wickham [ths]",
    "url": "http://schloerke.github.io/geozoo/, http://www.ggobi.org,\nhttps://github.com/schloerke/geozoo",
    "bug_reports": "https://github.com/schloerke/geozoo/issues",
    "repository": "https://cran.r-project.org/package=geozoo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geozoo Zoo of Geometric Objects Geometric objects defined in 'geozoo' can be simulated or displayed in the R package 'tourr'.  "
  },
  {
    "id": 13127,
    "package_name": "getopt",
    "title": "C-Like 'getopt' Behavior",
    "description": "Package designed to be used with Rscript to write\n    '#!' shebang scripts that accept short and long flags/options.\n    Many users will prefer using instead the packages optparse or argparse\n    which add extra features like automatically generated help option and usage,\n    support for default values, positional argument support, etc.",
    "version": "1.20.4",
    "maintainer": "Trevor L Davis <trevor.l.davis@gmail.com>",
    "author": "Trevor L Davis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6341-4639>),\n  Allen Day [aut] (Original package author),\n  Roman Zenka [ctb]",
    "url": "https://github.com/trevorld/r-getopt",
    "bug_reports": "https://github.com/trevorld/r-getopt/issues",
    "repository": "https://cran.r-project.org/package=getopt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "getopt C-Like 'getopt' Behavior Package designed to be used with Rscript to write\n    '#!' shebang scripts that accept short and long flags/options.\n    Many users will prefer using instead the packages optparse or argparse\n    which add extra features like automatically generated help option and usage,\n    support for default values, positional argument support, etc.  "
  },
  {
    "id": 13150,
    "package_name": "ggHoriPlot",
    "title": "Horizon Plots for 'ggplot2'",
    "description": "A user-friendly, highly customizable R package for building\n    horizon plots in the 'ggplot2' environment.",
    "version": "1.0.1",
    "maintainer": "Iker Rivas-Gonz\u00e1lez <ikerrivas96@gmail.com>",
    "author": "Iker Rivas-Gonz\u00e1lez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0515-0628>)",
    "url": "https://rivasiker.github.io/ggHoriPlot/,\nhttps://github.com/rivasiker/ggHoriPlot,\nhttps://CRAN.R-project.org/package=ggHoriPlot",
    "bug_reports": "https://github.com/rivasiker/ggHoriPlot/issues",
    "repository": "https://cran.r-project.org/package=ggHoriPlot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggHoriPlot Horizon Plots for 'ggplot2' A user-friendly, highly customizable R package for building\n    horizon plots in the 'ggplot2' environment.  "
  },
  {
    "id": 13154,
    "package_name": "ggResidpanel",
    "title": "Panels and Interactive Versions of Diagnostic Plots using\n'ggplot2'",
    "description": "An R package for creating panels of diagnostic plots for residuals from a model \n    using ggplot2 and plotly to analyze residuals and model assumptions from a variety of \n    viewpoints. It also allows for the creation of interactive diagnostic plots.",
    "version": "0.3.0",
    "maintainer": "Katherine Goode <kgoode@iastate.edu>",
    "author": "Katherine Goode [aut, cre],\n  Kathleen Rey [aut]",
    "url": "https://goodekat.github.io/ggResidpanel/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ggResidpanel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggResidpanel Panels and Interactive Versions of Diagnostic Plots using\n'ggplot2' An R package for creating panels of diagnostic plots for residuals from a model \n    using ggplot2 and plotly to analyze residuals and model assumptions from a variety of \n    viewpoints. It also allows for the creation of interactive diagnostic plots.  "
  },
  {
    "id": 13159,
    "package_name": "ggVennDiagram",
    "title": "A 'ggplot2' Implement of Venn Diagram",
    "description": "Easy-to-use functions to generate 2-7 sets Venn or upset plot in publication quality. \n  'ggVennDiagram' plot Venn or upset using well-defined geometry dataset and 'ggplot2'. The shapes of 2-4 sets \n  Venn use circles and ellipses, while the shapes of 4-7 sets Venn use irregular polygons (4 has both forms), which \n  are developed and imported from another package 'venn', authored by Adrian Dusa. We provided internal functions to \n  integrate shape data with user provided sets data, and calculated the geometry of every regions/intersections \n  of them, then separately plot Venn in four components, set edges/labels, and region edges/labels.\n  From version 1.0, it is possible to customize these components as you demand in ordinary 'ggplot2' grammar.\n  From version 1.4.4, it supports unlimited number of sets, as it can draw a plain upset plot automatically when\n  number of sets is more than 7.",
    "version": "1.5.4",
    "maintainer": "Chun-Hui Gao <gaospecial@gmail.com>",
    "author": "Chun-Hui Gao [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1445-7939>),\n  Guangchuang Yu [ctb] (ORCID: <https://orcid.org/0000-0002-6485-8781>),\n  Adrian Dusa [aut, cph] (ORCID: <https://orcid.org/0000-0002-3525-9253>,\n    note: Adrian Dusa is the author and copyright holder of venn, where\n    ggVennDiagram imports the polygon coordinates enabling 5 - 7 sets\n    Venn diagram.),\n  Turgut Yigit Akyol [ctb] (ORCID:\n    <https://orcid.org/0000-0003-0897-7716>)",
    "url": "https://github.com/gaospecial/ggVennDiagram,\nhttps://gaospecial.github.io/ggVennDiagram/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ggVennDiagram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggVennDiagram A 'ggplot2' Implement of Venn Diagram Easy-to-use functions to generate 2-7 sets Venn or upset plot in publication quality. \n  'ggVennDiagram' plot Venn or upset using well-defined geometry dataset and 'ggplot2'. The shapes of 2-4 sets \n  Venn use circles and ellipses, while the shapes of 4-7 sets Venn use irregular polygons (4 has both forms), which \n  are developed and imported from another package 'venn', authored by Adrian Dusa. We provided internal functions to \n  integrate shape data with user provided sets data, and calculated the geometry of every regions/intersections \n  of them, then separately plot Venn in four components, set edges/labels, and region edges/labels.\n  From version 1.0, it is possible to customize these components as you demand in ordinary 'ggplot2' grammar.\n  From version 1.4.4, it supports unlimited number of sets, as it can draw a plain upset plot automatically when\n  number of sets is more than 7.  "
  },
  {
    "id": 13169,
    "package_name": "ggautomap",
    "title": "Create Maps from a Column of Place Names",
    "description": "Mapping tools that convert place names to coordinates on the fly.\n    These 'ggplot2' extensions make maps from a data frame where one of the\n    columns contains place names, without having to directly work with the\n    underlying geospatial data and tools. The corresponding map data must be\n    registered with 'cartographer' either by the user or by another package.",
    "version": "0.3.3",
    "maintainer": "Carl Suster <carl.suster@sydney.edu.au>",
    "author": "Carl Suster [aut, cre] (ORCID: <https://orcid.org/0000-0001-7021-9380>),\n  Western Sydney Local Health District, NSW Health [cph] (2023-2025)",
    "url": "https://github.com/cidm-ph/ggautomap,\nhttps://cidm-ph.github.io/ggautomap/",
    "bug_reports": "https://github.com/cidm-ph/ggautomap/issues",
    "repository": "https://cran.r-project.org/package=ggautomap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggautomap Create Maps from a Column of Place Names Mapping tools that convert place names to coordinates on the fly.\n    These 'ggplot2' extensions make maps from a data frame where one of the\n    columns contains place names, without having to directly work with the\n    underlying geospatial data and tools. The corresponding map data must be\n    registered with 'cartographer' either by the user or by another package.  "
  },
  {
    "id": 13187,
    "package_name": "ggdag",
    "title": "Analyze and Create Elegant Directed Acyclic Graphs",
    "description": "Tidy, analyze, and plot directed acyclic graphs (DAGs).\n    'ggdag' is built on top of 'dagitty', an R package that uses the\n    'DAGitty' web tool (<https://dagitty.net/>) for creating and analyzing\n    DAGs. 'ggdag' makes it easy to tidy and plot 'dagitty' objects using\n    'ggplot2' and 'ggraph', as well as common analytic and graphical\n    functions, such as determining adjustment sets and node relationships.",
    "version": "0.2.13",
    "maintainer": "Malcolm Barrett <malcolmbarrett@gmail.com>",
    "author": "Malcolm Barrett [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0299-5825>)",
    "url": "https://github.com/r-causal/ggdag,\nhttps://r-causal.github.io/ggdag/",
    "bug_reports": "https://github.com/r-causal/ggdag/issues",
    "repository": "https://cran.r-project.org/package=ggdag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggdag Analyze and Create Elegant Directed Acyclic Graphs Tidy, analyze, and plot directed acyclic graphs (DAGs).\n    'ggdag' is built on top of 'dagitty', an R package that uses the\n    'DAGitty' web tool (<https://dagitty.net/>) for creating and analyzing\n    DAGs. 'ggdag' makes it easy to tidy and plot 'dagitty' objects using\n    'ggplot2' and 'ggraph', as well as common analytic and graphical\n    functions, such as determining adjustment sets and node relationships.  "
  },
  {
    "id": 13370,
    "package_name": "gif",
    "title": "Graphical Independence Filtering",
    "description": "Provides a method of recovering the precision matrix for Gaussian graphical models efficiently. Our approach could be divided into three categories. First of all, we use Hard Graphical Thresholding for best subset selection problem of Gaussian graphical model, and the core concept of this method was proposed by Luo et al. (2014) <arXiv:1407.7819>. Secondly, a closed form solution for graphical lasso under acyclic graph structure is implemented in our package (Fattahi and Sojoudi (2019) <https://jmlr.org/papers/v20/17-501.html>). Furthermore, we implement block coordinate descent algorithm to efficiently solve the covariance selection problem (Dempster (1972) <doi:10.2307/2528966>). Our package is computationally efficient and can solve ultra-high-dimensional problems, e.g. p > 10,000, in a few minutes.",
    "version": "0.1.1",
    "maintainer": "Shiyun Lin <linshy27@mail2.sysu.edu.cn>",
    "author": "Shiyun Lin [aut, cre],\n  Jin Zhu [aut],\n  Junxian Zhu [aut],\n  Xueqin Wang [aut],\n  SC2S2 [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gif",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gif Graphical Independence Filtering Provides a method of recovering the precision matrix for Gaussian graphical models efficiently. Our approach could be divided into three categories. First of all, we use Hard Graphical Thresholding for best subset selection problem of Gaussian graphical model, and the core concept of this method was proposed by Luo et al. (2014) <arXiv:1407.7819>. Secondly, a closed form solution for graphical lasso under acyclic graph structure is implemented in our package (Fattahi and Sojoudi (2019) <https://jmlr.org/papers/v20/17-501.html>). Furthermore, we implement block coordinate descent algorithm to efficiently solve the covariance selection problem (Dempster (1972) <doi:10.2307/2528966>). Our package is computationally efficient and can solve ultra-high-dimensional problems, e.g. p > 10,000, in a few minutes.  "
  },
  {
    "id": 13397,
    "package_name": "gkmSVM",
    "title": "Gapped-Kmer Support Vector Machine",
    "description": "Imports the 'gkmSVM' v2.0 functionalities into R <https://www.beerlab.org/gkmsvm/>\n    It also uses the 'kernlab' library (separate R package by different authors) for various SVM algorithms.\n    Users should note that the suggested packages 'rtracklayer', 'GenomicRanges', 'BSgenome', 'BiocGenerics', \n    'Biostrings', 'GenomeInfoDb', 'IRanges', and 'S4Vectors' are all BioConductor packages <https://bioconductor.org>.",
    "version": "0.83.0",
    "maintainer": "Mike Beer <mbeer@jhu.edu>",
    "author": "Mahmoud Ghandi",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gkmSVM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gkmSVM Gapped-Kmer Support Vector Machine Imports the 'gkmSVM' v2.0 functionalities into R <https://www.beerlab.org/gkmsvm/>\n    It also uses the 'kernlab' library (separate R package by different authors) for various SVM algorithms.\n    Users should note that the suggested packages 'rtracklayer', 'GenomicRanges', 'BSgenome', 'BiocGenerics', \n    'Biostrings', 'GenomeInfoDb', 'IRanges', and 'S4Vectors' are all BioConductor packages <https://bioconductor.org>.  "
  },
  {
    "id": 13406,
    "package_name": "glca",
    "title": "An R Package for Multiple-Group Latent Class Analysis",
    "description": "Fits multiple-group latent class analysis (LCA) for exploring \n    differences between populations in the data with a multilevel structure. \n    There are two approaches to reflect group differences in glca: \n    fixed-effect LCA (Bandeen-Roche et al (1997) <doi:10.1080/01621459.1997.10473658>;\n    Clogg and Goodman (1985) <doi:10.2307/270847>) and nonparametric random-effect LCA \n    (Vermunt (2003) <doi:10.1111/j.0081-1750.2003.t01-1-00131.x>).",
    "version": "1.4.2",
    "maintainer": "Youngsun Kim <yskstat@gmail.com>",
    "author": "Youngsun Kim [aut, cre],\n  Hwan Chung [aut]",
    "url": "https://kim0sun.github.io/glca/",
    "bug_reports": "https://github.com/kim0sun/glca/issues/",
    "repository": "https://cran.r-project.org/package=glca",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glca An R Package for Multiple-Group Latent Class Analysis Fits multiple-group latent class analysis (LCA) for exploring \n    differences between populations in the data with a multilevel structure. \n    There are two approaches to reflect group differences in glca: \n    fixed-effect LCA (Bandeen-Roche et al (1997) <doi:10.1080/01621459.1997.10473658>;\n    Clogg and Goodman (1985) <doi:10.2307/270847>) and nonparametric random-effect LCA \n    (Vermunt (2003) <doi:10.1111/j.0081-1750.2003.t01-1-00131.x>).  "
  },
  {
    "id": 13426,
    "package_name": "glmm.hp",
    "title": "Hierarchical Partitioning of Marginal R2 for Generalized\nMixed-Effect Models",
    "description": "Conducts hierarchical partitioning to calculate individual contributions of each predictor (fixed effects) towards marginal R2 for generalized linear mixed-effect model (including lm, glm and glmm) based on output of r.squaredGLMM() in 'MuMIn', applying the algorithm of Lai J.,Zou Y., Zhang S.,Zhang X.,Mao L.(2022)glmm.hp: an R package for computing individual effect of predictors in generalized linear mixed models.Journal of Plant Ecology,15(6)1302-1307<doi:10.1093/jpe/rtac096>.",
    "version": "1.0-0",
    "maintainer": "Jiangshan Lai <lai@njfu.edu.cn>",
    "author": "Jiangshan Lai [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0279-8816>),\n  Kim Nimon [aut],\n  Yao Liu [aut]",
    "url": "https://github.com/laijiangshan/glmm.hp",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glmm.hp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glmm.hp Hierarchical Partitioning of Marginal R2 for Generalized\nMixed-Effect Models Conducts hierarchical partitioning to calculate individual contributions of each predictor (fixed effects) towards marginal R2 for generalized linear mixed-effect model (including lm, glm and glmm) based on output of r.squaredGLMM() in 'MuMIn', applying the algorithm of Lai J.,Zou Y., Zhang S.,Zhang X.,Mao L.(2022)glmm.hp: an R package for computing individual effect of predictors in generalized linear mixed models.Journal of Plant Ecology,15(6)1302-1307<doi:10.1093/jpe/rtac096>.  "
  },
  {
    "id": 13451,
    "package_name": "glmxdiag",
    "title": "A Collection of Graphic Tools for GLM Diagnostics and some\nExtensions",
    "description": "Provides diagnostic graphic tools for GLMs, beta-binomial regression model (estimated by 'VGAM' package), beta regression model (estimated by 'betareg' package) and negative binomial regression model (estimated by 'MASS' package). Since most of functions implemented in 'glmxdiag' already exist in other packages, the aim is to provide the user unique functions that work on almost all regression models previously specified. Details about some of the implemented functions can be found in Brown (1992) <doi:10.2307/2347617>, Dunn and Smyth (1996) <doi:10.2307/1390802>, O'Hara Hines and Carter (1993) <doi:10.2307/2347405>, Wang (1985) <doi:10.2307/1269708>.",
    "version": "1.0.0",
    "maintainer": "Giuseppe Reale <giuseppe.reale97@gmail.com>",
    "author": "Giuseppe Reale [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glmxdiag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glmxdiag A Collection of Graphic Tools for GLM Diagnostics and some\nExtensions Provides diagnostic graphic tools for GLMs, beta-binomial regression model (estimated by 'VGAM' package), beta regression model (estimated by 'betareg' package) and negative binomial regression model (estimated by 'MASS' package). Since most of functions implemented in 'glmxdiag' already exist in other packages, the aim is to provide the user unique functions that work on almost all regression models previously specified. Details about some of the implemented functions can be found in Brown (1992) <doi:10.2307/2347617>, Dunn and Smyth (1996) <doi:10.2307/1390802>, O'Hara Hines and Carter (1993) <doi:10.2307/2347405>, Wang (1985) <doi:10.2307/1269708>.  "
  },
  {
    "id": 13479,
    "package_name": "gmfamm",
    "title": "Generalized Multivariate Functional Additive Models",
    "description": "Supply implementation to model generalized multivariate functional\n data using Bayesian additive mixed models of R package 'bamlss' via a latent\n Gaussian process (see Umlauf, Klein, Zeileis (2018) \n <doi:10.1080/10618600.2017.1407325>).",
    "version": "0.1.0",
    "maintainer": "Alexander Volkmann <alexandervolkmann8@gmail.com>",
    "author": "Nikolaus Umlauf [aut] (ORCID: <https://orcid.org/0000-0003-2160-9803>),\n  Alexander Volkmann [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gmfamm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gmfamm Generalized Multivariate Functional Additive Models Supply implementation to model generalized multivariate functional\n data using Bayesian additive mixed models of R package 'bamlss' via a latent\n Gaussian process (see Umlauf, Klein, Zeileis (2018) \n <doi:10.1080/10618600.2017.1407325>).  "
  },
  {
    "id": 13509,
    "package_name": "godley",
    "title": "Stock-Flow-Consistent Model Simulator",
    "description": "Define, simulate, and validate stock-flow consistent (SFC) macroeconomic models. The godley R package offers tools to dynamically define model structures by adding variables and specifying governing systems of equations. With it, users can analyze how different macroeconomic structures affect key variables, perform parameter sensitivity analyses, introduce policy shocks, and visualize resulting economic scenarios. The accounting structure of SFC models follows the approach outlined in the seminal study by Godley and Lavoie (2007, ISBN:978-1-137-08599-3), ensuring a comprehensive integration of all economic flows and stocks. The algorithms implemented to solve the models are based on methodologies from Kinsella and O'Shea (2010) <doi:10.2139/ssrn.1729205>, Peressini and Sullivan (1988, ISBN:0-387-96614-5), and contributions by Joao Macalos.",
    "version": "0.2.2",
    "maintainer": "El\u017cbieta Jowik <jowik.elzbieta@gmail.com>",
    "author": "Micha\u0142 Gamrot [aut, cph],\n  Iwo Augusty\u0144ski [ctb],\n  Julian Kacprzak [ctb],\n  El\u017cbieta Jowik [cre, ctb]",
    "url": "https://gamrot.github.io/godley/",
    "bug_reports": "https://github.com/gamrot/godley/issues",
    "repository": "https://cran.r-project.org/package=godley",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "godley Stock-Flow-Consistent Model Simulator Define, simulate, and validate stock-flow consistent (SFC) macroeconomic models. The godley R package offers tools to dynamically define model structures by adding variables and specifying governing systems of equations. With it, users can analyze how different macroeconomic structures affect key variables, perform parameter sensitivity analyses, introduce policy shocks, and visualize resulting economic scenarios. The accounting structure of SFC models follows the approach outlined in the seminal study by Godley and Lavoie (2007, ISBN:978-1-137-08599-3), ensuring a comprehensive integration of all economic flows and stocks. The algorithms implemented to solve the models are based on methodologies from Kinsella and O'Shea (2010) <doi:10.2139/ssrn.1729205>, Peressini and Sullivan (1988, ISBN:0-387-96614-5), and contributions by Joao Macalos.  "
  },
  {
    "id": 13542,
    "package_name": "googlenlp",
    "title": "An Interface to Google's Cloud Natural Language API",
    "description": "Interact with Google's Cloud Natural Language API\n    <https://cloud.google.com/natural-language/> (v1) via R. The API has\n    four main features, all of which are available through this\n    R package: syntax analysis and part-of-speech tagging, entity\n    analysis, sentiment analysis, and language identification.",
    "version": "0.2.0",
    "maintainer": "Brian Weinstien <bweinstein02@gmail.com>",
    "author": "Brian Weinstien [aut, cre]",
    "url": "https://github.com/BrianWeinstein/googlenlp",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=googlenlp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "googlenlp An Interface to Google's Cloud Natural Language API Interact with Google's Cloud Natural Language API\n    <https://cloud.google.com/natural-language/> (v1) via R. The API has\n    four main features, all of which are available through this\n    R package: syntax analysis and part-of-speech tagging, entity\n    analysis, sentiment analysis, and language identification.  "
  },
  {
    "id": 13560,
    "package_name": "gpboost",
    "title": "Combining Tree-Boosting with Gaussian Process and Mixed Effects\nModels",
    "description": "An R package that allows for combining tree-boosting with Gaussian process and mixed effects models. It also allows for independently doing tree-boosting as well as inference and prediction for Gaussian process and mixed effects models. See <https://github.com/fabsig/GPBoost> for more information on the software and Sigrist (2022, JMLR) <https://www.jmlr.org/papers/v23/20-322.html> and Sigrist (2023, TPAMI) <doi:10.1109/TPAMI.2022.3168152> for more information on the methodology.",
    "version": "1.6.4",
    "maintainer": "Fabio Sigrist <fabiosigrist@gmail.com>",
    "author": "Fabio Sigrist [aut, cre],\n  Tim Gyger [aut],\n  Pascal Kuendig [aut],\n  Benoit Jacob [cph],\n  Gael Guennebaud [cph],\n  Nicolas Carre [cph],\n  Pierre Zoppitelli [cph],\n  Gauthier Brun [cph],\n  Jean Ceccato [cph],\n  Jitse Niesen [cph],\n  Other authors of Eigen for the included version of Eigen [ctb, cph],\n  Timothy A. Davis [cph],\n  Guolin Ke [ctb],\n  Damien Soukhavong [ctb],\n  James Lamb [ctb],\n  Other authors of LightGBM for the included version of LightGBM [ctb],\n  Microsoft Corporation [cph],\n  Dropbox, Inc. [cph],\n  Jay Loden [cph],\n  Dave Daeschler [cph],\n  Giampaolo Rodola [cph],\n  Alberto Ferreira [ctb],\n  Daniel Lemire [ctb],\n  Victor Zverovich [cph],\n  IBM Corporation [ctb],\n  Keith O'Hara [cph],\n  Stephen L. Moshier [cph],\n  Jorge Nocedal [cph],\n  Naoaki Okazaki [cph],\n  Yixuan Qiu [cph],\n  Dirk Toewe [cph]",
    "url": "https://github.com/fabsig/GPBoost",
    "bug_reports": "https://github.com/fabsig/GPBoost/issues",
    "repository": "https://cran.r-project.org/package=gpboost",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gpboost Combining Tree-Boosting with Gaussian Process and Mixed Effects\nModels An R package that allows for combining tree-boosting with Gaussian process and mixed effects models. It also allows for independently doing tree-boosting as well as inference and prediction for Gaussian process and mixed effects models. See <https://github.com/fabsig/GPBoost> for more information on the software and Sigrist (2022, JMLR) <https://www.jmlr.org/papers/v23/20-322.html> and Sigrist (2023, TPAMI) <doi:10.1109/TPAMI.2022.3168152> for more information on the methodology.  "
  },
  {
    "id": 13571,
    "package_name": "gps",
    "title": "General P-Splines",
    "description": "General P-splines are non-uniform B-splines penalized by a general difference penalty, proposed by Li and Cao (2022) <arXiv:2201.06808>. Constructible on arbitrary knots, they extend the standard P-splines of Eilers and Marx (1996) <doi:10.1214/ss/1038425655>. They are also related to the O-splines of O'Sullivan (1986) <doi:10.1214/ss/1177013525> via a sandwich formula that links a general difference penalty to a derivative penalty. The package includes routines for setting up and handling difference and derivative penalties. It also fits P-splines and O-splines to (x, y) data (optionally weighted) for a grid of smoothing parameter values in the automatic search intervals of Li and Cao (2023) <doi:10.1007/s11222-022-10178-z>. It aims to facilitate other packages to implement P-splines or O-splines as a smoothing tool in their model estimation framework.",
    "version": "1.2",
    "maintainer": "Zheyuan Li <zheyuan.li@bath.edu>",
    "author": "Zheyuan Li [aut, cre] (ORCID: <https://orcid.org/0000-0002-7434-5947>)",
    "url": "https://github.com/ZheyuanLi/gps",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gps General P-Splines General P-splines are non-uniform B-splines penalized by a general difference penalty, proposed by Li and Cao (2022) <arXiv:2201.06808>. Constructible on arbitrary knots, they extend the standard P-splines of Eilers and Marx (1996) <doi:10.1214/ss/1038425655>. They are also related to the O-splines of O'Sullivan (1986) <doi:10.1214/ss/1177013525> via a sandwich formula that links a general difference penalty to a derivative penalty. The package includes routines for setting up and handling difference and derivative penalties. It also fits P-splines and O-splines to (x, y) data (optionally weighted) for a grid of smoothing parameter values in the automatic search intervals of Li and Cao (2023) <doi:10.1007/s11222-022-10178-z>. It aims to facilitate other packages to implement P-splines or O-splines as a smoothing tool in their model estimation framework.  "
  },
  {
    "id": 13574,
    "package_name": "gptr",
    "title": "A Convenient R Interface with the OpenAI 'ChatGPT' API",
    "description": "A convenient interface with the OpenAI 'ChatGPT' API <https://openai.com/api>. 'gptr' allows you to interact with 'ChatGPT', a powerful language model, for various natural language processing tasks. The 'gptr' R package makes talking to 'ChatGPT' in R super easy. It helps researchers and data folks by simplifying the complicated stuff, like asking questions and getting answers. With 'gptr', you can use 'ChatGPT' in R without any hassle, making it simpler for everyone to do cool things with language!",
    "version": "0.7.0",
    "maintainer": "Wanjun Gu <wanjun.gu@ucsf.edu>",
    "author": "Wanjun Gu [aut, cre] (ORCID: <https://orcid.org/0000-0002-7342-7000>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gptr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gptr A Convenient R Interface with the OpenAI 'ChatGPT' API A convenient interface with the OpenAI 'ChatGPT' API <https://openai.com/api>. 'gptr' allows you to interact with 'ChatGPT', a powerful language model, for various natural language processing tasks. The 'gptr' R package makes talking to 'ChatGPT' in R super easy. It helps researchers and data folks by simplifying the complicated stuff, like asking questions and getting answers. With 'gptr', you can use 'ChatGPT' in R without any hassle, making it simpler for everyone to do cool things with language!  "
  },
  {
    "id": 13597,
    "package_name": "graph3d",
    "title": "A Wrapper of the JavaScript Library 'vis-graph3d'",
    "description": "Create interactive visualization charts to draw data in three dimensional graphs. The graphs can be included in Shiny apps and R markdown documents, or viewed from the R console and 'RStudio' Viewer. Based on the 'vis.js' Graph3d module and the 'htmlwidgets' R package.",
    "version": "0.2.0",
    "maintainer": "St\u00e9phane Laurent <laurent_step@outlook.fr>",
    "author": "St\u00e9phane Laurent [aut, cre] (R interface),\n  B. V. Almende [aut, cph] (vis.js library),\n  vis.js contributors [aut, cph]",
    "url": "https://github.com/stla/graph3d",
    "bug_reports": "https://github.com/stla/graph3d/issues",
    "repository": "https://cran.r-project.org/package=graph3d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "graph3d A Wrapper of the JavaScript Library 'vis-graph3d' Create interactive visualization charts to draw data in three dimensional graphs. The graphs can be included in Shiny apps and R markdown documents, or viewed from the R console and 'RStudio' Viewer. Based on the 'vis.js' Graph3d module and the 'htmlwidgets' R package.  "
  },
  {
    "id": 13598,
    "package_name": "graph4lg",
    "title": "Build Graphs for Landscape Genetics Analysis",
    "description": "Build graphs for landscape genetics analysis. This set of \n\tfunctions can be used to import and convert spatial and genetic data \n\tinitially in different formats, import landscape graphs created with \n\t'GRAPHAB' software (Foltete et al., 2012) <doi:10.1016/j.envsoft.2012.07.002>, \n\tmake diagnosis plots of isolation by distance relationships in order to \n\tchoose how to build genetic graphs, create graphs with a large range of \n\tpruning methods, weight their links with several genetic distances, plot \n\tand analyse graphs,\tcompare them with other graphs. It uses functions from \n\tother packages such as 'adegenet' \n\t(Jombart, 2008) <doi:10.1093/bioinformatics/btn129> and 'igraph' (Csardi\n\tet Nepusz, 2006) <https://igraph.org/>. It also implements methods \n\tcommonly used in landscape genetics to create graphs, described by Dyer et \n\tNason (2004) <doi:10.1111/j.1365-294X.2004.02177.x> and Greenbaum et \n\tFefferman (2017) <doi:10.1111/mec.14059>, and to analyse distance data \n\t(van Strien et al., 2015) <doi:10.1038/hdy.2014.62>.",
    "version": "1.8.0",
    "maintainer": "Paul Savary <psavary@protonmail.com>",
    "author": "Paul Savary [aut, cre] (ORCID: <https://orcid.org/0000-0002-2104-9941>),\n  Gilles Vuidel [ctb] (ORCID: <https://orcid.org/0000-0001-6330-6136>),\n  Tyler Rudolph [ctb],\n  Alexandrine Daniel [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=graph4lg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "graph4lg Build Graphs for Landscape Genetics Analysis Build graphs for landscape genetics analysis. This set of \n\tfunctions can be used to import and convert spatial and genetic data \n\tinitially in different formats, import landscape graphs created with \n\t'GRAPHAB' software (Foltete et al., 2012) <doi:10.1016/j.envsoft.2012.07.002>, \n\tmake diagnosis plots of isolation by distance relationships in order to \n\tchoose how to build genetic graphs, create graphs with a large range of \n\tpruning methods, weight their links with several genetic distances, plot \n\tand analyse graphs,\tcompare them with other graphs. It uses functions from \n\tother packages such as 'adegenet' \n\t(Jombart, 2008) <doi:10.1093/bioinformatics/btn129> and 'igraph' (Csardi\n\tet Nepusz, 2006) <https://igraph.org/>. It also implements methods \n\tcommonly used in landscape genetics to create graphs, described by Dyer et \n\tNason (2004) <doi:10.1111/j.1365-294X.2004.02177.x> and Greenbaum et \n\tFefferman (2017) <doi:10.1111/mec.14059>, and to analyse distance data \n\t(van Strien et al., 2015) <doi:10.1038/hdy.2014.62>.  "
  },
  {
    "id": 13614,
    "package_name": "grateful",
    "title": "Facilitate Citation of R Packages",
    "description": "Facilitates the citation of R packages used in analysis\n    projects. Scans project for packages used, gets their citations, and\n    produces a document with citations in the preferred bibliography\n    format, ready to be pasted into reports or manuscripts. Alternatively,\n    'grateful' can be used directly within an 'R Markdown' or 'Quarto' document.",
    "version": "0.3.0",
    "maintainer": "Francisco Rodriguez-Sanchez <f.rodriguez.sanc@gmail.com>",
    "author": "Francisco Rodriguez-Sanchez [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7981-1599>),\n  Connor P. Jackson [aut] (ORCID:\n    <https://orcid.org/0000-0002-4220-5210>),\n  Shaurita D. Hutchins [ctb],\n  James M. Clawson [ctb]",
    "url": "https://pakillo.github.io/grateful/",
    "bug_reports": "https://github.com/Pakillo/grateful/issues",
    "repository": "https://cran.r-project.org/package=grateful",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "grateful Facilitate Citation of R Packages Facilitates the citation of R packages used in analysis\n    projects. Scans project for packages used, gets their citations, and\n    produces a document with citations in the preferred bibliography\n    format, ready to be pasted into reports or manuscripts. Alternatively,\n    'grateful' can be used directly within an 'R Markdown' or 'Quarto' document.  "
  },
  {
    "id": 13678,
    "package_name": "growthPheno",
    "title": "Functional Analysis of Phenotypic Growth Data to Smooth and\nExtract Traits",
    "description": "Assists in the plotting and functional smoothing of traits \n    measured over time and the extraction of features from these traits, \n    implementing the SET (Smoothing and Extraction of Traits) method \n    described in Brien et al. (2020) Plant Methods, 16. Smoothing of \n    growth trends for individual plants using natural cubic smoothing \n    splines or P-splines is available for removing transient effects and \n    segmented smoothing is available to deal with discontinuities in \n    growth trends. There are graphical tools for assessing the adequacy \n    of trait smoothing, both when using this and other packages, such as \n    those that fit nonlinear growth models. A range of per-unit (plant, \n    pot, plot) growth traits or features can be extracted from the \n    data, including single time points, interval growth rates and other \n    growth statistics, such as maximum growth or days to maximum growth. \n    The package also has tools adapted to inputting data from \n    high-throughput phenotyping facilities, such from a Lemna-Tec \n    Scananalyzer 3D (see <https://www.youtube.com/watch?v=MRAF_mAEa7E/> \n    for more information). The package 'growthPheno' can also be \n    installed from <http://chris.brien.name/rpackages/>.",
    "version": "3.1.18",
    "maintainer": "Chris Brien <chris.brien@adelaide.edu.au>",
    "author": "Chris Brien [aut, cre] (ORCID: <https://orcid.org/0000-0003-0581-1817>)",
    "url": "http://chris.brien.name/",
    "bug_reports": "https://github.com/briencj/growthPheno/issues",
    "repository": "https://cran.r-project.org/package=growthPheno",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "growthPheno Functional Analysis of Phenotypic Growth Data to Smooth and\nExtract Traits Assists in the plotting and functional smoothing of traits \n    measured over time and the extraction of features from these traits, \n    implementing the SET (Smoothing and Extraction of Traits) method \n    described in Brien et al. (2020) Plant Methods, 16. Smoothing of \n    growth trends for individual plants using natural cubic smoothing \n    splines or P-splines is available for removing transient effects and \n    segmented smoothing is available to deal with discontinuities in \n    growth trends. There are graphical tools for assessing the adequacy \n    of trait smoothing, both when using this and other packages, such as \n    those that fit nonlinear growth models. A range of per-unit (plant, \n    pot, plot) growth traits or features can be extracted from the \n    data, including single time points, interval growth rates and other \n    growth statistics, such as maximum growth or days to maximum growth. \n    The package also has tools adapted to inputting data from \n    high-throughput phenotyping facilities, such from a Lemna-Tec \n    Scananalyzer 3D (see <https://www.youtube.com/watch?v=MRAF_mAEa7E/> \n    for more information). The package 'growthPheno' can also be \n    installed from <http://chris.brien.name/rpackages/>.  "
  },
  {
    "id": 13713,
    "package_name": "gspcr",
    "title": "Generalized Supervised Principal Component Regression",
    "description": "Generalization of supervised principal component regression (SPCR; \n    Bair et al., 2006, <doi:10.1198/016214505000000628>) to support continuous, \n    binary, and discrete variables as outcomes and predictors \n    (inspired by the 'superpc' R package <https://cran.r-project.org/package=superpc>).",
    "version": "0.9.5",
    "maintainer": "Edoardo Costantini <costantini.edoardo@yahoo.com>",
    "author": "Edoardo Costantini [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9581-9913>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gspcr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gspcr Generalized Supervised Principal Component Regression Generalization of supervised principal component regression (SPCR; \n    Bair et al., 2006, <doi:10.1198/016214505000000628>) to support continuous, \n    binary, and discrete variables as outcomes and predictors \n    (inspired by the 'superpc' R package <https://cran.r-project.org/package=superpc>).  "
  },
  {
    "id": 13732,
    "package_name": "gto",
    "title": "Insert 'gt' Tables into Word Documents",
    "description": "Insert tables created by the 'gt' R package into 'Microsoft Word' \n    documents. This gives users the ability to add to their existing word documents\n    the tables made in 'gt' using the familiar 'officer' package and syntax from\n    the 'officeverse'.",
    "version": "0.1.2",
    "maintainer": "Ellis Hughes <ellis.h.hughes@gsk.com>",
    "author": "Ellis Hughes [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0637-4436>),\n  GlaxoSmithKline Research & Development Limited [cph, fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gto",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gto Insert 'gt' Tables into Word Documents Insert tables created by the 'gt' R package into 'Microsoft Word' \n    documents. This gives users the ability to add to their existing word documents\n    the tables made in 'gt' using the familiar 'officer' package and syntax from\n    the 'officeverse'.  "
  },
  {
    "id": 13733,
    "package_name": "gtools",
    "title": "Various R Programming Tools",
    "description": "Functions to assist in R programming, including:\n  - assist in developing, updating, and maintaining R and R packages ('ask', 'checkRVersion',\n    'getDependencies', 'keywords', 'scat'),\n  - calculate the logit and inverse logit transformations ('logit', 'inv.logit'),\n  - test if a value is missing, empty or contains only NA and NULL values ('invalid'),\n  - manipulate R's .Last function ('addLast'),\n  - define macros ('defmacro'),\n  - detect odd and even integers ('odd', 'even'),\n  - convert strings containing non-ASCII characters (like single quotes) to plain ASCII ('ASCIIfy'),\n  - perform a binary search ('binsearch'),\n  - sort strings containing both numeric and character components ('mixedsort'),\n  - create a factor variable from the quantiles of a continuous variable ('quantcut'),\n  - enumerate permutations and combinations ('combinations', 'permutation'),\n  - calculate and convert between fold-change and log-ratio ('foldchange',\n    'logratio2foldchange', 'foldchange2logratio'),\n  - calculate probabilities and generate random numbers from Dirichlet distributions\n    ('rdirichlet', 'ddirichlet'),\n  - apply a function over adjacent subsets of a vector ('running'),\n  - modify the TCP_NODELAY ('de-Nagle') flag for socket objects,\n  - efficient 'rbind' of data frames, even if the column names don't match ('smartbind'),\n  - generate significance stars from p-values ('stars.pval'),\n  - convert characters to/from ASCII codes ('asc', 'chr'),\n  - convert character vector to ASCII representation ('ASCIIfy'),\n  - apply title capitalization rules to a character vector ('capwords').",
    "version": "3.9.5",
    "maintainer": "Ben Bolker <bolker@mcmaster.ca>",
    "author": "Gregory R. Warnes [aut],\n  Ben Bolker [aut, cre] (ORCID: <https://orcid.org/0000-0002-2127-0443>),\n  Thomas Lumley [aut],\n  Arni Magnusson [aut],\n  Bill Venables [aut],\n  Genei Ryodan [aut],\n  Steffen Moeller [aut],\n  Ian Wilson [ctb],\n  Mark Davis [ctb],\n  Nitin Jain [ctb],\n  Scott Chamberlain [ctb]",
    "url": "https://github.com/r-gregmisc/gtools",
    "bug_reports": "https://github.com/r-gregmisc/gtools/issues",
    "repository": "https://cran.r-project.org/package=gtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gtools Various R Programming Tools Functions to assist in R programming, including:\n  - assist in developing, updating, and maintaining R and R packages ('ask', 'checkRVersion',\n    'getDependencies', 'keywords', 'scat'),\n  - calculate the logit and inverse logit transformations ('logit', 'inv.logit'),\n  - test if a value is missing, empty or contains only NA and NULL values ('invalid'),\n  - manipulate R's .Last function ('addLast'),\n  - define macros ('defmacro'),\n  - detect odd and even integers ('odd', 'even'),\n  - convert strings containing non-ASCII characters (like single quotes) to plain ASCII ('ASCIIfy'),\n  - perform a binary search ('binsearch'),\n  - sort strings containing both numeric and character components ('mixedsort'),\n  - create a factor variable from the quantiles of a continuous variable ('quantcut'),\n  - enumerate permutations and combinations ('combinations', 'permutation'),\n  - calculate and convert between fold-change and log-ratio ('foldchange',\n    'logratio2foldchange', 'foldchange2logratio'),\n  - calculate probabilities and generate random numbers from Dirichlet distributions\n    ('rdirichlet', 'ddirichlet'),\n  - apply a function over adjacent subsets of a vector ('running'),\n  - modify the TCP_NODELAY ('de-Nagle') flag for socket objects,\n  - efficient 'rbind' of data frames, even if the column names don't match ('smartbind'),\n  - generate significance stars from p-values ('stars.pval'),\n  - convert characters to/from ASCII codes ('asc', 'chr'),\n  - convert character vector to ASCII representation ('ASCIIfy'),\n  - apply title capitalization rules to a character vector ('capwords').  "
  },
  {
    "id": 13747,
    "package_name": "guix.install",
    "title": "Install R Packages with GNU Guix",
    "description": "This 'R' package provides a single procedure guix.install(),\n  which allows users to install 'R' packages via 'Guix' right from within\n  their running 'R' session.  If the requested 'R' package does not exist\n  in 'Guix' at this time, the package and all its missing dependencies\n  will be imported recursively and the generated package definitions\n  will be written to ~/.Rguix/packages.scm.  This record of imported\n  packages can be used later to reproduce the environment, and to add\n  the packages in question to a proper 'Guix' channel (or 'Guix' itself).\n  guix.install() not only supports installing packages from CRAN, but\n  also from Bioconductor or even arbitrary 'git' or 'mercurial'\n  repositories, replacing the need for installation via 'devtools'.",
    "version": "1.0.0",
    "maintainer": "Ricardo Wurmus <ricardo.wurmus@mdc-berlin.de>",
    "author": "Ricardo Wurmus",
    "url": "https://github.com/BIMSBbioinfo/guix.install",
    "bug_reports": "https://github.com/BIMSBbioinfo/guix.install/issues",
    "repository": "https://cran.r-project.org/package=guix.install",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "guix.install Install R Packages with GNU Guix This 'R' package provides a single procedure guix.install(),\n  which allows users to install 'R' packages via 'Guix' right from within\n  their running 'R' session.  If the requested 'R' package does not exist\n  in 'Guix' at this time, the package and all its missing dependencies\n  will be imported recursively and the generated package definitions\n  will be written to ~/.Rguix/packages.scm.  This record of imported\n  packages can be used later to reproduce the environment, and to add\n  the packages in question to a proper 'Guix' channel (or 'Guix' itself).\n  guix.install() not only supports installing packages from CRAN, but\n  also from Bioconductor or even arbitrary 'git' or 'mercurial'\n  repositories, replacing the need for installation via 'devtools'.  "
  },
  {
    "id": 13773,
    "package_name": "h3lib",
    "title": "Exposes the 'Uber' 'H3' Library to R Packages",
    "description": "'H3' is a hexagonal hierarchical spatial index developed by 'Uber' <https://h3geo.org/>.\n  This package exposes the source code of 'H3' (written in 'C') to routines that are callable through 'R'.",
    "version": "0.1.4",
    "maintainer": "David Cooley <dcooley@symbolix.com.au>",
    "author": "David Cooley [aut, cre],\n  Ray Shao [ctb]",
    "url": "https://github.com/symbolixau/h3lib",
    "bug_reports": "https://github.com/symbolixau/h3lib/issues",
    "repository": "https://cran.r-project.org/package=h3lib",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "h3lib Exposes the 'Uber' 'H3' Library to R Packages 'H3' is a hexagonal hierarchical spatial index developed by 'Uber' <https://h3geo.org/>.\n  This package exposes the source code of 'H3' (written in 'C') to routines that are callable through 'R'.  "
  },
  {
    "id": 13877,
    "package_name": "healthiar",
    "title": "Quantify and Monetize the Burden of Disease Attributable to\nExposure",
    "description": "This R package has been developed with a focus on air pollution and noise but can applied to other exposures. The initial development has been funded by the European Union project BEST-COST. Disclaimer: It is work in progress and the developers are not liable for any calculation errors or inaccuracies resulting from the use of this package.\n References (in chronological order): \n WHO (2003a) \"Assessing the environmental burden of disease at national and local levels\" <https://www.who.int/publications/i/item/9241546204> (accessed October 2025);\n WHO (2003b) \"Comparative quantification of health risks: Conceptual framework and methodological issues\" <doi:10.1186/1478-7954-1-1> (accessed October 2025);\n Miller & Hurley (2003) \"Life table methods for quantitative impact assessments in chronic mortality\" <doi:10.1136/jech.57.3.200> (accessed October 2025);\n Steenland & Armstrong (2006) \"An Overview of Methods for Calculating the Burden of Disease Due to Specific Risk Factors\" <doi:10.1097/01.ede.0000229155.05644.43> (accessed October 2025);\n Miller (2010) \"Report on estimation of mortality impacts of particulate air pollution in London\" <https://cleanair.london/app/uploads/CAL-098-Mayors-health-study-report-June-2010-1.pdf> (accessed October 2025);\n WHO (2011) \"Burden of disease from environmental noise\" <https://iris.who.int/items/723ab97c-5c33-4e3b-8df1-744aa5bc1c27> (accessed October 2025);\n Jerrett et al. (2013) \"Spatial Analysis of Air Pollution and Mortality in California\" <doi:10.1164/rccm.201303-0609OC> (accessed October 2025);\n GBD 2019 Risk Factors Collaborators (2020) \"Global burden of 87 risk factors in 204 countries and territories, 1990\u20132019\" <doi:10.1016/S0140-6736(20)30752-2> (accessed October 2025);\n VanderWeele (2019) \"Optimal Approximate Conversions of Odds Ratios and Hazard Ratios to Risk Ratios\" <doi: 10.1111/biom.13197> (accessed October 2025);\n WHO (2020) \"Health impact assessment of air pollution: AirQ+ life table manual\" <https://iris.who.int/bitstream/handle/10665/337683/WHO-EURO-2020-1559-41310-56212-eng.pdf?sequence=1> (accessed October 2025);\n ETC HE (2022) \"Health risk assessment of air pollution and the impact of the new WHO guidelines\" <https://www.eionet.europa.eu/etcs/all-etc-reports> (accessed October 2025);\n Kim et al. (2022) \"DALY Estimation Approaches: Understanding and Using the Incidence-based Approach and the Prevalence-based Approach\" <doi:10.3961/jpmph.21.597> (accessed October 2025);\n Pozzer et al. (2022) \"Mortality Attributable to Ambient Air Pollution: A Review of Global Estimates\" <doi:10.1029/2022GH000711> (accessed October 2025);\n Teaching group in EBM (2022) \"Evidence-based medicine research helper\" <https://ebm-helper.cn/en/Conv/HR_RR.html> (accessed October 2025).",
    "version": "0.2.1",
    "maintainer": "Alberto Castro <alberto.castrofernandez@swisstph.ch>",
    "author": "Alberto Castro [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-4665-3299>),\n  Axel Luyten [aut] (ORCID: <https://orcid.org/0000-0002-7005-5889>),\n  Arno Pauwels [ctb] (ORCID: <https://orcid.org/0000-0001-7519-8080>),\n  Liliana Vazquez Fernandez [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3778-9415>),\n  Vanessa Gorasso [ctb] (ORCID: <https://orcid.org/0000-0001-6884-9316>),\n  Carl Michael Baravelli [ctb] (ORCID:\n    <https://orcid.org/0000-0001-7772-5315>),\n  Susanne Breitner [ctb] (ORCID: <https://orcid.org/0000-0002-0956-6911>),\n  Maria Lepnurm [ctb] (ORCID: <https://orcid.org/0009-0009-4372-6227>),\n  Maria Jose Rueda Lopez [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2443-1038>),\n  Iracy Pimenta [ctb] (ORCID: <https://orcid.org/0000-0003-0032-1536>),\n  Andreia Novais [ctb] (ORCID: <https://orcid.org/0009-0007-7775-108X>),\n  Ana Barbosa [ctb] (ORCID: <https://orcid.org/0000-0002-9623-9002>),\n  Joao Vasco Santos [ctb] (ORCID:\n    <https://orcid.org/0000-0003-4696-1002>),\n  Anette Kocbach Bolling [ctb] (ORCID:\n    <https://orcid.org/0000-0003-4209-7448>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=healthiar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "healthiar Quantify and Monetize the Burden of Disease Attributable to\nExposure This R package has been developed with a focus on air pollution and noise but can applied to other exposures. The initial development has been funded by the European Union project BEST-COST. Disclaimer: It is work in progress and the developers are not liable for any calculation errors or inaccuracies resulting from the use of this package.\n References (in chronological order): \n WHO (2003a) \"Assessing the environmental burden of disease at national and local levels\" <https://www.who.int/publications/i/item/9241546204> (accessed October 2025);\n WHO (2003b) \"Comparative quantification of health risks: Conceptual framework and methodological issues\" <doi:10.1186/1478-7954-1-1> (accessed October 2025);\n Miller & Hurley (2003) \"Life table methods for quantitative impact assessments in chronic mortality\" <doi:10.1136/jech.57.3.200> (accessed October 2025);\n Steenland & Armstrong (2006) \"An Overview of Methods for Calculating the Burden of Disease Due to Specific Risk Factors\" <doi:10.1097/01.ede.0000229155.05644.43> (accessed October 2025);\n Miller (2010) \"Report on estimation of mortality impacts of particulate air pollution in London\" <https://cleanair.london/app/uploads/CAL-098-Mayors-health-study-report-June-2010-1.pdf> (accessed October 2025);\n WHO (2011) \"Burden of disease from environmental noise\" <https://iris.who.int/items/723ab97c-5c33-4e3b-8df1-744aa5bc1c27> (accessed October 2025);\n Jerrett et al. (2013) \"Spatial Analysis of Air Pollution and Mortality in California\" <doi:10.1164/rccm.201303-0609OC> (accessed October 2025);\n GBD 2019 Risk Factors Collaborators (2020) \"Global burden of 87 risk factors in 204 countries and territories, 1990\u20132019\" <doi:10.1016/S0140-6736(20)30752-2> (accessed October 2025);\n VanderWeele (2019) \"Optimal Approximate Conversions of Odds Ratios and Hazard Ratios to Risk Ratios\" <doi: 10.1111/biom.13197> (accessed October 2025);\n WHO (2020) \"Health impact assessment of air pollution: AirQ+ life table manual\" <https://iris.who.int/bitstream/handle/10665/337683/WHO-EURO-2020-1559-41310-56212-eng.pdf?sequence=1> (accessed October 2025);\n ETC HE (2022) \"Health risk assessment of air pollution and the impact of the new WHO guidelines\" <https://www.eionet.europa.eu/etcs/all-etc-reports> (accessed October 2025);\n Kim et al. (2022) \"DALY Estimation Approaches: Understanding and Using the Incidence-based Approach and the Prevalence-based Approach\" <doi:10.3961/jpmph.21.597> (accessed October 2025);\n Pozzer et al. (2022) \"Mortality Attributable to Ambient Air Pollution: A Review of Global Estimates\" <doi:10.1029/2022GH000711> (accessed October 2025);\n Teaching group in EBM (2022) \"Evidence-based medicine research helper\" <https://ebm-helper.cn/en/Conv/HR_RR.html> (accessed October 2025).  "
  },
  {
    "id": 13904,
    "package_name": "helloJavaWorld",
    "title": "Hello Java World",
    "description": "A dummy package to demonstrate how to interface to a jar\n        file that resides inside an R package.",
    "version": "0.0-9",
    "maintainer": "Tobias Verbeke <tobias.verbeke@openanalytics.eu>",
    "author": "Tobias Verbeke",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=helloJavaWorld",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "helloJavaWorld Hello Java World A dummy package to demonstrate how to interface to a jar\n        file that resides inside an R package.  "
  },
  {
    "id": 13905,
    "package_name": "hellorust",
    "title": "Minimal Examples of Using Rust Code in R",
    "description": "Template R package with minimal setup to use Rust code in R without\n    hacks or frameworks. Includes basic examples of importing cargo dependencies,\n    spawning threads and passing numbers or strings from Rust to R. Cargo crates\n    are automatically 'vendored' in the R source package to support offline\n    installation. The GitHub repository for this package has more details and also \n    explains how to set up CI. This project was first presented at 'Erum2018' to \n    showcase R-Rust integration <https://jeroen.github.io/erum2018/>; for a real\n    world use-case, see the 'gifski' package on 'CRAN'.",
    "version": "1.2.3",
    "maintainer": "Jeroen Ooms <jeroenooms@gmail.com>",
    "author": "Jeroen Ooms [aut, cre] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Authors of the dependency Rust crates [aut] (see AUTHORS file)",
    "url": "https://github.com/r-rust/hellorust",
    "bug_reports": "https://github.com/r-rust/hellorust/issues",
    "repository": "https://cran.r-project.org/package=hellorust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hellorust Minimal Examples of Using Rust Code in R Template R package with minimal setup to use Rust code in R without\n    hacks or frameworks. Includes basic examples of importing cargo dependencies,\n    spawning threads and passing numbers or strings from Rust to R. Cargo crates\n    are automatically 'vendored' in the R source package to support offline\n    installation. The GitHub repository for this package has more details and also \n    explains how to set up CI. This project was first presented at 'Erum2018' to \n    showcase R-Rust integration <https://jeroen.github.io/erum2018/>; for a real\n    world use-case, see the 'gifski' package on 'CRAN'.  "
  },
  {
    "id": 13916,
    "package_name": "hesim",
    "title": "Health Economic Simulation Modeling and Decision Analysis",
    "description": "A modular and computationally efficient R package for  \n  parameterizing, simulating, and analyzing health economic simulation \n  models. The package supports cohort discrete time state transition models \n  (Briggs et al. 1998) <doi:10.2165/00019053-199813040-00003>,\n  N-state partitioned survival models (Glasziou et al. 1990)\n  <doi:10.1002/sim.4780091106>, and individual-level continuous \n  time state transition models (Siebert et al. 2012) <doi:10.1016/j.jval.2012.06.014>,\n  encompassing both Markov (time-homogeneous and time-inhomogeneous) and \n  semi-Markov processes. Decision uncertainty from a cost-effectiveness analysis is \n  quantified with standard graphical and tabular summaries of a probabilistic \n  sensitivity analysis (Claxton et al. 2005, Barton et al. 2008) <doi:10.1002/hec.985>, \n  <doi:10.1111/j.1524-4733.2008.00358.x>. Use of C++ and data.table\n  make individual-patient simulation, probabilistic sensitivity analysis, \n  and incorporation of patient heterogeneity fast.",
    "version": "0.5.7",
    "maintainer": "Devin Incerti <devin.incerti@gmail.com>",
    "author": "Devin Incerti [aut, cre],\n  Jeroen P. Jansen [aut],\n  Mark Clements [aut],\n  R Core Team [ctb] (hesim uses some slightly modified C functions from\n    base R)",
    "url": "https://hesim-dev.github.io/hesim/,\nhttps://github.com/hesim-dev/hesim",
    "bug_reports": "https://github.com/hesim-dev/hesim/issues",
    "repository": "https://cran.r-project.org/package=hesim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hesim Health Economic Simulation Modeling and Decision Analysis A modular and computationally efficient R package for  \n  parameterizing, simulating, and analyzing health economic simulation \n  models. The package supports cohort discrete time state transition models \n  (Briggs et al. 1998) <doi:10.2165/00019053-199813040-00003>,\n  N-state partitioned survival models (Glasziou et al. 1990)\n  <doi:10.1002/sim.4780091106>, and individual-level continuous \n  time state transition models (Siebert et al. 2012) <doi:10.1016/j.jval.2012.06.014>,\n  encompassing both Markov (time-homogeneous and time-inhomogeneous) and \n  semi-Markov processes. Decision uncertainty from a cost-effectiveness analysis is \n  quantified with standard graphical and tabular summaries of a probabilistic \n  sensitivity analysis (Claxton et al. 2005, Barton et al. 2008) <doi:10.1002/hec.985>, \n  <doi:10.1111/j.1524-4733.2008.00358.x>. Use of C++ and data.table\n  make individual-patient simulation, probabilistic sensitivity analysis, \n  and incorporation of patient heterogeneity fast.  "
  },
  {
    "id": 13922,
    "package_name": "heteromixgm",
    "title": "Copula Graphical Models for Heterogeneous Mixed Data",
    "description": "A multi-core R package that allows for the statistical modeling of multi-group multivariate mixed data using Gaussian graphical models. Combining the Gaussian copula framework with the fused graphical lasso penalty, the 'heteromixgm' package can handle a wide variety of datasets found in various sciences. The package also includes an option to perform model selection using the AIC, BIC and EBIC information criteria, a function that plots partial correlation graphs based on the selected precision matrices, as well as simulate mixed heterogeneous data for exploratory or simulation purposes and one multi-group multivariate mixed agricultural dataset pertaining to maize yields. The package implements the methodological developments found in Hermes et al. (2024) <doi:10.1080/10618600.2023.2289545>.",
    "version": "2.0.2",
    "maintainer": "Sjoerd Hermes <sjoerd.hermes@wur.nl>",
    "author": "Sjoerd Hermes [aut, cre],\n  Joost van Heerwaarden [ctb],\n  Pariya Behrouzi [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=heteromixgm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "heteromixgm Copula Graphical Models for Heterogeneous Mixed Data A multi-core R package that allows for the statistical modeling of multi-group multivariate mixed data using Gaussian graphical models. Combining the Gaussian copula framework with the fused graphical lasso penalty, the 'heteromixgm' package can handle a wide variety of datasets found in various sciences. The package also includes an option to perform model selection using the AIC, BIC and EBIC information criteria, a function that plots partial correlation graphs based on the selected precision matrices, as well as simulate mixed heterogeneous data for exploratory or simulation purposes and one multi-group multivariate mixed agricultural dataset pertaining to maize yields. The package implements the methodological developments found in Hermes et al. (2024) <doi:10.1080/10618600.2023.2289545>.  "
  },
  {
    "id": 13946,
    "package_name": "hgutils",
    "title": "Collection of Utility Functions",
    "description": "\n    A handy collection of utility functions designed to aid in\n    package development, plotting and scientific research.  Package\n    development functionalities includes among others tools such as\n    cross-referencing package imports with the description file, analysis\n    of redundant package imports, editing of the description file and the\n    creation of package badges for GitHub.  Some of the other\n    functionalities include automatic package installation and loading,\n    plotting points without overlap, creating nice breaks for plots,\n    overview tables and many more handy utility functions.",
    "version": "0.2.19",
    "maintainer": "H.G. van den Boorn <hvdboorn@gmail.com>",
    "author": "H.G. van den Boorn [aut, cre]",
    "url": "https://github.com/hvdboorn/hgutils",
    "bug_reports": "https://github.com/hvdboorn/hgutils/issues",
    "repository": "https://cran.r-project.org/package=hgutils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hgutils Collection of Utility Functions \n    A handy collection of utility functions designed to aid in\n    package development, plotting and scientific research.  Package\n    development functionalities includes among others tools such as\n    cross-referencing package imports with the description file, analysis\n    of redundant package imports, editing of the description file and the\n    creation of package badges for GitHub.  Some of the other\n    functionalities include automatic package installation and loading,\n    plotting points without overlap, creating nice breaks for plots,\n    overview tables and many more handy utility functions.  "
  },
  {
    "id": 13950,
    "package_name": "hhmR",
    "title": "Hierarchical Heatmaps",
    "description": "Allows users to create high-quality heatmaps from labelled, hierarchical data. Specifically, for data with a two-level hierarchical structure, it will produce a heatmap where each row and column represents a category at the lower level. These rows and columns are then grouped by the higher-level group each category belongs to, with the names for each category and groups shown in the margins. While other packages (e.g. 'dendextend') allow heatmap rows and columns to be arranged by groups only, 'hhmR' also allows the labelling of the data at both the category and group level.",
    "version": "0.0.1.1",
    "maintainer": "Michael Mahony <michael.mahony@cantab.net>",
    "author": "Michael Mahony [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0003-2784-2745>),\n  Francisco Rowe [aut] (ORCID: <https://orcid.org/0000-0003-4137-0246>),\n  Carmen Cabrera-Arnau [aut] (ORCID:\n    <https://orcid.org/0000-0002-2732-6436>)",
    "url": "https://github.com/sgmmahon/hhmR, https://sgmmahon.github.io/hhmR/",
    "bug_reports": "https://github.com/sgmmahon/hhmR/issues",
    "repository": "https://cran.r-project.org/package=hhmR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hhmR Hierarchical Heatmaps Allows users to create high-quality heatmaps from labelled, hierarchical data. Specifically, for data with a two-level hierarchical structure, it will produce a heatmap where each row and column represents a category at the lower level. These rows and columns are then grouped by the higher-level group each category belongs to, with the names for each category and groups shown in the margins. While other packages (e.g. 'dendextend') allow heatmap rows and columns to be arranged by groups only, 'hhmR' also allows the labelling of the data at both the category and group level.  "
  },
  {
    "id": 13977,
    "package_name": "highriskzone",
    "title": "Determining and Evaluating High-Risk Zones",
    "description": "Functions for determining and evaluating high-risk zones and\n    simulating and thinning point process data, as described in 'Determining\n    high risk zones using point process methodology - Realization by building\n    an R package' Seibold (2012) <http://highriskzone.r-forge.r-project.org/Bachelorarbeit.pdf> \n    and 'Determining high-risk zones for unexploded World War II bombs by using point \n    process methodology', Mahling et al. (2013) <doi:10.1111/j.1467-9876.2012.01055.x>.",
    "version": "1.4.9",
    "maintainer": "Rickmer Schulte <R.Schulte@campus.lmu.de>",
    "author": "Heidi Seibold <Heidi.Seibold@uzh.ch>, Monia Mahling\n    <monia.mahling@stat.uni-muenchen.de>, Sebastian Linne\n    <Sebastian.Linne@campus.lmu.de>, Felix Guenther\n    <felix.guenther@stat.uni-muenchen.de>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=highriskzone",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "highriskzone Determining and Evaluating High-Risk Zones Functions for determining and evaluating high-risk zones and\n    simulating and thinning point process data, as described in 'Determining\n    high risk zones using point process methodology - Realization by building\n    an R package' Seibold (2012) <http://highriskzone.r-forge.r-project.org/Bachelorarbeit.pdf> \n    and 'Determining high-risk zones for unexploded World War II bombs by using point \n    process methodology', Mahling et al. (2013) <doi:10.1111/j.1467-9876.2012.01055.x>.  "
  },
  {
    "id": 14028,
    "package_name": "holobiont",
    "title": "Microbiome Analysis Tools",
    "description": "We provide functions for identifying the core community phylogeny in any microbiome, drawing phylogenetic Venn diagrams, calculating the core Faith\u2019s PD for a set of communities, and calculating the core UniFrac distance between two sets of communities. All functions rely on construction of a core community phylogeny, which is a phylogeny where branches are defined based on their presence in multiple samples from a single type of habitat. Our package provides two options for constructing the core community phylogeny, a tip-based approach, where the core community phylogeny is identified based on incidence of leaf nodes and a branch-based approach, where the core community phylogeny is identified based on incidence of individual branches. We suggest use of the microViz package.",
    "version": "0.1.3",
    "maintainer": "Sharon Bewick <sbewick@clemson.edu>",
    "author": "Sharon Bewick [aut, cre],\n  Benjamin Camper [aut],\n  National Science Foundation Division of Integrative Organismal Systems\n    (award #2104605) [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=holobiont",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "holobiont Microbiome Analysis Tools We provide functions for identifying the core community phylogeny in any microbiome, drawing phylogenetic Venn diagrams, calculating the core Faith\u2019s PD for a set of communities, and calculating the core UniFrac distance between two sets of communities. All functions rely on construction of a core community phylogeny, which is a phylogeny where branches are defined based on their presence in multiple samples from a single type of habitat. Our package provides two options for constructing the core community phylogeny, a tip-based approach, where the core community phylogeny is identified based on incidence of leaf nodes and a branch-based approach, where the core community phylogeny is identified based on incidence of individual branches. We suggest use of the microViz package.  "
  },
  {
    "id": 14067,
    "package_name": "hsem",
    "title": "Hierarchical Structural Equation Model",
    "description": "We present this package for fitting structural equation models using the hierarchical likelihood method. This package allows extended structural equation model, including dynamic structural equation model. We illustrate the use of our packages with well-known data sets. Therefore, this package are able to handle two serious problems inadmissible solution and factor indeterminacy <doi:10.3390/sym13040657>.",
    "version": "1.0",
    "maintainer": "Rezzy Eko Caraka <rezzyekocaraka@gmail.com>",
    "author": "Rezzy Eko Caraka [aut, cre],\n  Maengseok Noh [aut],\n  Youngjo Lee [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hsem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hsem Hierarchical Structural Equation Model We present this package for fitting structural equation models using the hierarchical likelihood method. This package allows extended structural equation model, including dynamic structural equation model. We illustrate the use of our packages with well-known data sets. Therefore, this package are able to handle two serious problems inadmissible solution and factor indeterminacy <doi:10.3390/sym13040657>.  "
  },
  {
    "id": 14093,
    "package_name": "httptest",
    "title": "A Test Environment for HTTP Requests",
    "description": "Testing and documenting code that communicates with remote servers\n    can be painful. Dealing with authentication, server state,\n    and other complications can make testing seem too costly to\n    bother with. But it doesn't need to be that hard. This package enables one\n    to test all of the logic on the R sides of the API in your package without\n    requiring access to the remote service. Importantly, it provides three\n    contexts that mock the network connection in different ways, as well as\n    testing functions to assert that HTTP requests were---or were\n    not---made. It also allows one to safely record real API responses to use as\n    test fixtures. The ability to save responses and load them offline also\n    enables one to write vignettes and other dynamic documents that can be\n    distributed without access to a live server.",
    "version": "4.2.3",
    "maintainer": "Neal Richardson <neal.p.richardson@gmail.com>",
    "author": "Neal Richardson [aut, cre] (ORCID:\n    <https://orcid.org/0009-0002-7992-3520>),\n  Jonathan Keane [ctb],\n  Ma\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>)",
    "url": "https://enpiar.com/r/httptest/,\nhttps://github.com/nealrichardson/httptest",
    "bug_reports": "https://github.com/nealrichardson/httptest/issues",
    "repository": "https://cran.r-project.org/package=httptest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "httptest A Test Environment for HTTP Requests Testing and documenting code that communicates with remote servers\n    can be painful. Dealing with authentication, server state,\n    and other complications can make testing seem too costly to\n    bother with. But it doesn't need to be that hard. This package enables one\n    to test all of the logic on the R sides of the API in your package without\n    requiring access to the remote service. Importantly, it provides three\n    contexts that mock the network connection in different ways, as well as\n    testing functions to assert that HTTP requests were---or were\n    not---made. It also allows one to safely record real API responses to use as\n    test fixtures. The ability to save responses and load them offline also\n    enables one to write vignettes and other dynamic documents that can be\n    distributed without access to a live server.  "
  },
  {
    "id": 14094,
    "package_name": "httptest2",
    "title": "Test Helpers for 'httr2'",
    "description": "Testing and documenting code that communicates with remote servers\n    can be painful. This package helps with writing tests for packages that\n    use 'httr2'. It enables testing all of the logic\n    on the R sides of the API without requiring access to the\n    remote service, and it also allows recording real API responses to use as\n    test fixtures. The ability to save responses and load them offline also\n    enables writing vignettes and other dynamic documents that can be\n    distributed without access to a live server.",
    "version": "1.2.2",
    "maintainer": "Neal Richardson <neal.p.richardson@gmail.com>",
    "author": "Neal Richardson [aut, cre] (ORCID:\n    <https://orcid.org/0009-0002-7992-3520>),\n  Jonathan Keane [ctb],\n  Ma\u00eblle Salmon [ctb] (ORCID: <https://orcid.org/0000-0002-2815-0399>)",
    "url": "https://enpiar.com/httptest2/,\nhttps://github.com/nealrichardson/httptest2",
    "bug_reports": "https://github.com/nealrichardson/httptest2/issues",
    "repository": "https://cran.r-project.org/package=httptest2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "httptest2 Test Helpers for 'httr2' Testing and documenting code that communicates with remote servers\n    can be painful. This package helps with writing tests for packages that\n    use 'httr2'. It enables testing all of the logic\n    on the R sides of the API without requiring access to the\n    remote service, and it also allows recording real API responses to use as\n    test fixtures. The ability to save responses and load them offline also\n    enables writing vignettes and other dynamic documents that can be\n    distributed without access to a live server.  "
  },
  {
    "id": 14100,
    "package_name": "huito",
    "title": "Reproducible and Flexible Label Design",
    "description": "An open-source R package to deploys reproducible and flexible labels using layers. \n  The 'huito' package is part of the 'inkaverse' project for developing different procedures and\n  tools used in plant science and experimental designs. \n  Learn more about the 'inkaverse' project at <https://inkaverse.com/>.",
    "version": "0.2.6",
    "maintainer": "Flavio Lozano-Isla <flozanoisla@gmail.com>",
    "author": "Flavio Lozano-Isla [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0714-669X>),\n  Inkaverse [cph]",
    "url": "https://huito.inkaverse.com/, https://github.com/flavjack/huito",
    "bug_reports": "https://github.com/flavjack/huito/issues/",
    "repository": "https://cran.r-project.org/package=huito",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "huito Reproducible and Flexible Label Design An open-source R package to deploys reproducible and flexible labels using layers. \n  The 'huito' package is part of the 'inkaverse' project for developing different procedures and\n  tools used in plant science and experimental designs. \n  Learn more about the 'inkaverse' project at <https://inkaverse.com/>.  "
  },
  {
    "id": 14105,
    "package_name": "humidity",
    "title": "Calculate Water Vapor Measures from Temperature and Dew Point",
    "description": "Vapor pressure, relative humidity, absolute humidity, specific humidity, and mixing ratio are commonly used water vapor measures in meteorology. This R package provides functions for calculating saturation vapor pressure (hPa), partial water vapor pressure (Pa), relative humidity (%), absolute humidity (kg/m^3), specific humidity (kg/kg), and mixing ratio (kg/kg) from temperature (K) and dew point (K). Conversion functions between humidity measures are also provided.",
    "version": "0.1.5",
    "maintainer": "Jun Cai <cai-j12@mails.tsinghua.edu.cn>",
    "author": "Jun Cai [aut, cre] (ORCID: <https://orcid.org/0000-0001-9495-1226>)",
    "url": "https://github.com/caijun/humidity",
    "bug_reports": "https://github.com/caijun/humidity/issues",
    "repository": "https://cran.r-project.org/package=humidity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "humidity Calculate Water Vapor Measures from Temperature and Dew Point Vapor pressure, relative humidity, absolute humidity, specific humidity, and mixing ratio are commonly used water vapor measures in meteorology. This R package provides functions for calculating saturation vapor pressure (hPa), partial water vapor pressure (Pa), relative humidity (%), absolute humidity (kg/m^3), specific humidity (kg/kg), and mixing ratio (kg/kg) from temperature (K) and dew point (K). Conversion functions between humidity measures are also provided.  "
  },
  {
    "id": 14119,
    "package_name": "hySpc.testthat",
    "title": "'testthat' Unit Test Enhancements",
    "description": "Enhance package 'testthat' by allowing tests to be attached to the function/object they test. \n    This allows to keep functional and unit test code together.",
    "version": "0.2.1",
    "maintainer": "Claudia Beleites <Claudia.Beleites@chemometrix.gmbh>",
    "author": "Claudia Beleites [aut, cre],\n  Erick Oduniyi [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hySpc.testthat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hySpc.testthat 'testthat' Unit Test Enhancements Enhance package 'testthat' by allowing tests to be attached to the function/object they test. \n    This allows to keep functional and unit test code together.  "
  },
  {
    "id": 14120,
    "package_name": "hybridModels",
    "title": "An R Package for the Stochastic Simulation of Disease Spreading\nin Dynamic Networks",
    "description": "Simulates stochastic hybrid models for transmission of infectious\n    diseases in dynamic networks. It is a metapopulation model in which each\n    node in the network is a sub-population and disease spreads within nodes\n    and among them, combining two approaches: stochastic simulation algorithm\n    (<doi:10.1146/annurev.physchem.58.032806.104637>) and individual-based\n    approach, respectively. Equations that models spread within nodes are\n    customizable and there are two link types among nodes: migration and\n    influence (commuting). More information in Fernando S. Marques,\n    Jose H. H. Grisi-Filho, Marcos Amaku et al. (2020) <doi:10.18637/jss.v094.i06>.",
    "version": "0.3.8",
    "maintainer": "Fernando S. Marques <fernandosix@gmail.com>",
    "author": "Fernando S. Marques [aut, cre],\n  Jose H. H. Grisi-Filho [aut],\n  Marcos Amaku [aut]",
    "url": "https://github.com/fernandosm/hybridModels",
    "bug_reports": "https://github.com/fernandosm/hybridModels/issues",
    "repository": "https://cran.r-project.org/package=hybridModels",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hybridModels An R Package for the Stochastic Simulation of Disease Spreading\nin Dynamic Networks Simulates stochastic hybrid models for transmission of infectious\n    diseases in dynamic networks. It is a metapopulation model in which each\n    node in the network is a sub-population and disease spreads within nodes\n    and among them, combining two approaches: stochastic simulation algorithm\n    (<doi:10.1146/annurev.physchem.58.032806.104637>) and individual-based\n    approach, respectively. Equations that models spread within nodes are\n    customizable and there are two link types among nodes: migration and\n    influence (commuting). More information in Fernando S. Marques,\n    Jose H. H. Grisi-Filho, Marcos Amaku et al. (2020) <doi:10.18637/jss.v094.i06>.  "
  },
  {
    "id": 14125,
    "package_name": "hydflood",
    "title": "Flood Extents and Duration along the Rivers Elbe and Rhine",
    "description": "Raster based flood modelling internally using 'hyd1d', an R package\n    to interpolate 1d water level and gauging data. The package computes flood\n    extent and duration through strategies originally developed for 'INFORM',\n    an 'ArcGIS'-based hydro-ecological modelling framework. It does not provide\n    a full, physical hydraulic modelling algorithm, but a simplified, near real\n    time 'GIS' approach for flood extent and duration modelling. Computationally\n    demanding annual flood durations have been computed already and data\n    products were published by Weber (2022) <doi:10.1594/PANGAEA.948042>.",
    "version": "0.5.10",
    "maintainer": "Arnd Weber <arnd.weber@bafg.de>",
    "author": "Arnd Weber [aut, cre] (ORCID: <https://orcid.org/0000-0002-5973-2770>),\n  Stephan Rosenzweig [ctb],\n  Benjamin Eberhardt [ctb]",
    "url": "https://hydflood.bafg.de, https://github.com/bafg-bund/hydflood",
    "bug_reports": "https://github.com/bafg-bund/hydflood/issues/",
    "repository": "https://cran.r-project.org/package=hydflood",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydflood Flood Extents and Duration along the Rivers Elbe and Rhine Raster based flood modelling internally using 'hyd1d', an R package\n    to interpolate 1d water level and gauging data. The package computes flood\n    extent and duration through strategies originally developed for 'INFORM',\n    an 'ArcGIS'-based hydro-ecological modelling framework. It does not provide\n    a full, physical hydraulic modelling algorithm, but a simplified, near real\n    time 'GIS' approach for flood extent and duration modelling. Computationally\n    demanding annual flood durations have been computed already and data\n    products were published by Weber (2022) <doi:10.1594/PANGAEA.948042>.  "
  },
  {
    "id": 14130,
    "package_name": "hydroMOPSO",
    "title": "Multi-Objective Optimisation with Focus on Environmental Models",
    "description": "State-of-the-art Multi-Objective Particle Swarm Optimiser (MOPSO), based on the algorithm developed by Lin et al. (2018) <doi:10.1109/TEVC.2016.2631279> with improvements described by Marinao-Rivas & Zambrano-Bigiarini (2020) <doi:10.1109/LA-CCI48322.2021.9769844>. This package is inspired by and closely follows the philosophy of the single objective 'hydroPSO' R package ((Zambrano-Bigiarini & Rojas, 2013) <doi:10.1016/j.envsoft.2013.01.004>), and can be used for global optimisation of non-smooth and non-linear R functions and R-base models (e.g., 'TUWmodel', 'GR4J', 'GR6J'). However, the main focus of 'hydroMOPSO' is optimising environmental and other real-world models that need to be run from the system console (e.g., 'SWAT+'). 'hydroMOPSO' communicates with the model to be optimised through its input and output files, without requiring modifying its source code. Thanks to its flexible design and the availability of several fine-tuning options, 'hydroMOPSO' can tackle a wide range of multi-objective optimisation problems (e.g., multi-objective functions, multiple model variables, multiple periods). Finally, 'hydroMOPSO' is designed to run on multi-core machines or network clusters, to alleviate the computational burden of complex models with long execution time.",
    "version": "0.1-14",
    "maintainer": "Rodrigo Marinao-Rivas <ra.marinao.rivas@gmail.com>",
    "author": "Rodrigo Marinao-Rivas [aut, cre, cph],\n  Mauricio Zambrano-Bigiarini [aut, ctb, cph] (ORCID:\n    <https://orcid.org/0000-0002-9536-643X>)",
    "url": "https://gitlab.com/rmarinao/hydroMOPSO",
    "bug_reports": "https://gitlab.com/rmarinao/hydroMOPSO/-/issues",
    "repository": "https://cran.r-project.org/package=hydroMOPSO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hydroMOPSO Multi-Objective Optimisation with Focus on Environmental Models State-of-the-art Multi-Objective Particle Swarm Optimiser (MOPSO), based on the algorithm developed by Lin et al. (2018) <doi:10.1109/TEVC.2016.2631279> with improvements described by Marinao-Rivas & Zambrano-Bigiarini (2020) <doi:10.1109/LA-CCI48322.2021.9769844>. This package is inspired by and closely follows the philosophy of the single objective 'hydroPSO' R package ((Zambrano-Bigiarini & Rojas, 2013) <doi:10.1016/j.envsoft.2013.01.004>), and can be used for global optimisation of non-smooth and non-linear R functions and R-base models (e.g., 'TUWmodel', 'GR4J', 'GR6J'). However, the main focus of 'hydroMOPSO' is optimising environmental and other real-world models that need to be run from the system console (e.g., 'SWAT+'). 'hydroMOPSO' communicates with the model to be optimised through its input and output files, without requiring modifying its source code. Thanks to its flexible design and the availability of several fine-tuning options, 'hydroMOPSO' can tackle a wide range of multi-objective optimisation problems (e.g., multi-objective functions, multiple model variables, multiple periods). Finally, 'hydroMOPSO' is designed to run on multi-core machines or network clusters, to alleviate the computational burden of complex models with long execution time.  "
  },
  {
    "id": 14172,
    "package_name": "iCellR",
    "title": "Analyzing High-Throughput Single Cell Sequencing Data",
    "description": "A toolkit that allows scientists to work with data from single cell sequencing technologies such as scRNA-seq, scVDJ-seq, scATAC-seq, CITE-Seq and Spatial Transcriptomics (ST). Single (i) Cell R package ('iCellR') provides unprecedented flexibility at every step of the analysis pipeline, including normalization, clustering, dimensionality reduction, imputation, visualization, and so on. Users can design both unsupervised and supervised models to best suit their research. In addition, the toolkit provides 2D and 3D interactive visualizations, differential expression analysis, filters based on cells, genes and clusters, data merging, normalizing for dropouts, data imputation methods, correcting for batch differences, pathway analysis, tools to find marker genes for clusters and conditions, predict cell types and pseudotime analysis. See Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.05.05.078550>  and Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.03.31.019109> for more details.",
    "version": "1.7.0",
    "maintainer": "Alireza Khodadadi-Jamayran <alireza.khodadadi.j@gmail.com>",
    "author": "Alireza Khodadadi-Jamayran [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2495-7504>),\n  Joseph Pucella [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-0875-8046>),\n  Hua Zhou [aut, ctb] (ORCID: <https://orcid.org/0000-0003-1822-1306>),\n  Nicole Doudican [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-3827-9644>),\n  John Carucci [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-6817-9439>),\n  Adriana Heguy [aut, ctb],\n  Boris Reizis [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-1140-7853>),\n  Aristotelis Tsirigos [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-7512-8477>)",
    "url": "https://github.com/rezakj/iCellR",
    "bug_reports": "https://github.com/rezakj/iCellR/issues",
    "repository": "https://cran.r-project.org/package=iCellR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iCellR Analyzing High-Throughput Single Cell Sequencing Data A toolkit that allows scientists to work with data from single cell sequencing technologies such as scRNA-seq, scVDJ-seq, scATAC-seq, CITE-Seq and Spatial Transcriptomics (ST). Single (i) Cell R package ('iCellR') provides unprecedented flexibility at every step of the analysis pipeline, including normalization, clustering, dimensionality reduction, imputation, visualization, and so on. Users can design both unsupervised and supervised models to best suit their research. In addition, the toolkit provides 2D and 3D interactive visualizations, differential expression analysis, filters based on cells, genes and clusters, data merging, normalizing for dropouts, data imputation methods, correcting for batch differences, pathway analysis, tools to find marker genes for clusters and conditions, predict cell types and pseudotime analysis. See Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.05.05.078550>  and Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.03.31.019109> for more details.  "
  },
  {
    "id": 14185,
    "package_name": "iNEXT",
    "title": "Interpolation and Extrapolation for Species Diversity",
    "description": "Provides simple functions to compute and plot two types \n    (sample-size- and coverage-based) rarefaction and extrapolation curves for species\n    diversity (Hill numbers) based on individual-based abundance data or sampling-unit-\n    based incidence data; see Chao and others (2014, Ecological Monographs) for pertinent\n    theory and methodologies, and Hsieh, Ma and Chao (2016, Methods in Ecology and Evolution)\n    for an introduction of the R package.",
    "version": "3.0.2",
    "maintainer": "Anne Chao <chao@stat.nthu.edu.tw>",
    "author": "T. C. Hsieh [aut],\n  K. H. Ma [aut],\n  Anne Chao [aut, cre]",
    "url": "https://sites.google.com/view/chao-lab-website/software/inext",
    "bug_reports": "https://github.com/AnneChao/iNEXT/issues",
    "repository": "https://cran.r-project.org/package=iNEXT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iNEXT Interpolation and Extrapolation for Species Diversity Provides simple functions to compute and plot two types \n    (sample-size- and coverage-based) rarefaction and extrapolation curves for species\n    diversity (Hill numbers) based on individual-based abundance data or sampling-unit-\n    based incidence data; see Chao and others (2014, Ecological Monographs) for pertinent\n    theory and methodologies, and Hsieh, Ma and Chao (2016, Methods in Ecology and Evolution)\n    for an introduction of the R package.  "
  },
  {
    "id": 14205,
    "package_name": "iTOS",
    "title": "Methods and Examples from Introduction to the Theory of\nObservational Studies",
    "description": "Supplements for a book, \"iTOS\" = \"Introduction to the Theory of Observational Studies.\"  Data sets are 'aHDL' from Rosenbaum (2023a) <doi:10.1111/biom.13558> and 'bingeM' from Rosenbaum (2023b) <doi:10.1111/biom.13921>.  The function makematch() uses two-criteria matching from Zhang et al. (2023) <doi:10.1080/01621459.2021.1981337> to create the matched data 'bingeM' from 'binge'.  The makematch() function also implements optimal matching (Rosenbaum (1989) <doi:10.2307/2290079>) and matching with fine or near-fine balance (Rosenbaum et al. (2007) <doi:10.1198/016214506000001059> and Yang et al (2012) <doi:10.1111/j.1541-0420.2011.01691.x>).  The book makes use of two other R packages, 'weightedRank' and 'tightenBlock'.",
    "version": "1.0.3",
    "maintainer": "Paul R. Rosenbaum <rosenbaum@wharton.upenn.edu>",
    "author": "Paul R. Rosenbaum [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iTOS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iTOS Methods and Examples from Introduction to the Theory of\nObservational Studies Supplements for a book, \"iTOS\" = \"Introduction to the Theory of Observational Studies.\"  Data sets are 'aHDL' from Rosenbaum (2023a) <doi:10.1111/biom.13558> and 'bingeM' from Rosenbaum (2023b) <doi:10.1111/biom.13921>.  The function makematch() uses two-criteria matching from Zhang et al. (2023) <doi:10.1080/01621459.2021.1981337> to create the matched data 'bingeM' from 'binge'.  The makematch() function also implements optimal matching (Rosenbaum (1989) <doi:10.2307/2290079>) and matching with fine or near-fine balance (Rosenbaum et al. (2007) <doi:10.1198/016214506000001059> and Yang et al (2012) <doi:10.1111/j.1541-0420.2011.01691.x>).  The book makes use of two other R packages, 'weightedRank' and 'tightenBlock'.  "
  },
  {
    "id": 14232,
    "package_name": "ical",
    "title": "'iCalendar' Parsing",
    "description": "A simple wrapper around the 'ical.js' library executing \n    'Javascript' code via 'V8' (the 'Javascript' engine driving the 'Chrome' \n    browser and 'Node.js' and accessible via the 'V8' R package). \n    This package enables users to parse 'iCalendar' files ('.ics', '.ifb', \n    '.iCal', '.iFBf') into lists and 'data.frames' to ultimately do statistics\n    on events, meetings, schedules, birthdays, and the like.",
    "version": "0.1.6",
    "maintainer": "Peter Meissner <retep.meissner@gmail.com>",
    "author": "Peter Meissner [aut, cre],\n  Philipp Kewisch [cph] (Ical.js file is is licences under MPL.  Source:\n    https://github.com/mozilla-comm/ical.js)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ical",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ical 'iCalendar' Parsing A simple wrapper around the 'ical.js' library executing \n    'Javascript' code via 'V8' (the 'Javascript' engine driving the 'Chrome' \n    browser and 'Node.js' and accessible via the 'V8' R package). \n    This package enables users to parse 'iCalendar' files ('.ics', '.ifb', \n    '.iCal', '.iFBf') into lists and 'data.frames' to ultimately do statistics\n    on events, meetings, schedules, birthdays, and the like.  "
  },
  {
    "id": 14353,
    "package_name": "immunarch",
    "title": "Multi-Modal Immune Repertoire Analytics for Immunotherapy and\nVaccine Design in R",
    "description": "A comprehensive analytics framework for building reproducible pipelines on T-cell and B-cell immune receptor repertoire data.\n    Delivers multi-modal immune profiling (bulk, single-cell, CITE-seq/AbSeq, spatial, immunogenicity data), \n    feature engineering (ML-ready feature tables and matrices), and biomarker discovery workflows\n    (cohort comparisons, longitudinal tracking, repertoire similarity, enrichment). \n    Provides a user-friendly interface to widely used AIRR methods \u2014 \n    clonality/diversity, V(D)J usage, similarity, annotation, tracking, and many more.\n    Think Scanpy or Seurat, but for AIRR data, a.k.a. Adaptive Immune Receptor Repertoire, VDJ-seq, RepSeq, or \n    VDJ sequencing data. A successor to our previously published \"tcR\" R package (Nazarov 2015).",
    "version": "0.10.3",
    "maintainer": "Vadim I. Nazarov <support@immunomind.com>",
    "author": "Vadim I. Nazarov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3659-2709>),\n  Vasily O. Tsvetkov [aut],\n  Aleksandr A. Popov [aut],\n  Ivan Balashov [aut]",
    "url": "https://immunomind.github.io/docs/,\nhttps://github.com/immunomind/immunarch/,\nhttps://immunarch.com/",
    "bug_reports": "https://github.com/immunomind/immunarch/issues",
    "repository": "https://cran.r-project.org/package=immunarch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "immunarch Multi-Modal Immune Repertoire Analytics for Immunotherapy and\nVaccine Design in R A comprehensive analytics framework for building reproducible pipelines on T-cell and B-cell immune receptor repertoire data.\n    Delivers multi-modal immune profiling (bulk, single-cell, CITE-seq/AbSeq, spatial, immunogenicity data), \n    feature engineering (ML-ready feature tables and matrices), and biomarker discovery workflows\n    (cohort comparisons, longitudinal tracking, repertoire similarity, enrichment). \n    Provides a user-friendly interface to widely used AIRR methods \u2014 \n    clonality/diversity, V(D)J usage, similarity, annotation, tracking, and many more.\n    Think Scanpy or Seurat, but for AIRR data, a.k.a. Adaptive Immune Receptor Repertoire, VDJ-seq, RepSeq, or \n    VDJ sequencing data. A successor to our previously published \"tcR\" R package (Nazarov 2015).  "
  },
  {
    "id": 14416,
    "package_name": "inferCSN",
    "title": "Inferring Cell-Specific Gene Regulatory Network",
    "description": "An R package for inferring cell-type specific gene regulatory network from single-cell RNA-seq data.",
    "version": "1.2.0",
    "maintainer": "Meng Xu <mengxu98@qq.com>",
    "author": "Meng Xu [aut, cre] (ORCID: <https://orcid.org/0000-0002-8300-1054>)",
    "url": "https://mengxu98.github.io/inferCSN/",
    "bug_reports": "https://github.com/mengxu98/inferCSN/issues",
    "repository": "https://cran.r-project.org/package=inferCSN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inferCSN Inferring Cell-Specific Gene Regulatory Network An R package for inferring cell-type specific gene regulatory network from single-cell RNA-seq data.  "
  },
  {
    "id": 14433,
    "package_name": "informedSen",
    "title": "Sensitivity Analysis Informed by a Test for Bias",
    "description": "After testing for biased treatment assignment in an observational study using an unaffected outcome, the sensitivity analysis is constrained to be compatible with that test.  The package uses the optimization software gurobi obtainable from <https://www.gurobi.com/>, together with its associated R package, also called gurobi; see: <https://www.gurobi.com/documentation/7.0/refman/installing_the_r_package.html>.  The method is a substantial computational and practical enhancement of a concept introduced in Rosenbaum (1992) Detecting bias with confidence in observational studies Biometrika, 79(2), 367-374  <doi:10.1093/biomet/79.2.367>.",
    "version": "1.0.7",
    "maintainer": "Paul R Rosenbaum <rosenbaum@wharton.upenn.edu>",
    "author": "Paul R Rosenbaum",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=informedSen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "informedSen Sensitivity Analysis Informed by a Test for Bias After testing for biased treatment assignment in an observational study using an unaffected outcome, the sensitivity analysis is constrained to be compatible with that test.  The package uses the optimization software gurobi obtainable from <https://www.gurobi.com/>, together with its associated R package, also called gurobi; see: <https://www.gurobi.com/documentation/7.0/refman/installing_the_r_package.html>.  The method is a substantial computational and practical enhancement of a concept introduced in Rosenbaum (1992) Detecting bias with confidence in observational studies Biometrika, 79(2), 367-374  <doi:10.1093/biomet/79.2.367>.  "
  },
  {
    "id": 14461,
    "package_name": "install.load",
    "title": "Check, Install and Load CRAN Packages",
    "description": "The function 'install_load' checks the local R library(ies) to see\n    if the required package(s) is/are installed or not. If the package(s)\n    is/are not installed, then the package(s) will be installed along with\n    the required dependency(ies). This function pulls source or\n    binary packages from the Posit/RStudio-sponsored CRAN mirror. Lastly, the\n    chosen package(s) is/are loaded. The function 'load_package' simply loads\n    the provided package(s). If this package does not fit your needs, then you\n    may want to consider these other R packages: 'needs', 'easypackages',\n    'pacman', 'pak', 'anyLib', and/or 'librarian'.",
    "version": "1.2.5",
    "maintainer": "Irucka Embry <iembry@ecoccs.com>",
    "author": "maloneypatr [aut, cre], Irucka Embry [aut, ctb]",
    "url": "https://gitlab.com/iembry/install.load",
    "bug_reports": "https://gitlab.com/iembry/install.load/-/issues",
    "repository": "https://cran.r-project.org/package=install.load",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "install.load Check, Install and Load CRAN Packages The function 'install_load' checks the local R library(ies) to see\n    if the required package(s) is/are installed or not. If the package(s)\n    is/are not installed, then the package(s) will be installed along with\n    the required dependency(ies). This function pulls source or\n    binary packages from the Posit/RStudio-sponsored CRAN mirror. Lastly, the\n    chosen package(s) is/are loaded. The function 'load_package' simply loads\n    the provided package(s). If this package does not fit your needs, then you\n    may want to consider these other R packages: 'needs', 'easypackages',\n    'pacman', 'pak', 'anyLib', and/or 'librarian'.  "
  },
  {
    "id": 14463,
    "package_name": "instantiate",
    "title": "Pre-Compiled 'CmdStan' Models in R Packages",
    "description": "Similar to 'rstantools' for 'rstan',\n  the 'instantiate' package builds pre-compiled\n  'CmdStan' models into CRAN-ready statistical modeling R packages.\n  The models compile once during installation,\n  the executables live inside the file systems of their respective packages,\n  and users have the full power and convenience of\n  'cmdstanr' without any additional compilation after package installation.\n  This approach saves time and helps R package developers\n  migrate from 'rstan' to the more modern 'cmdstanr'.\n  Packages 'rstantools', 'cmdstanr', 'stannis', and\n  'stanapi' are similar Stan clients with different objectives.",
    "version": "0.2.3",
    "maintainer": "William Michael Landau <will.landau.oss@gmail.com>",
    "author": "William Michael Landau [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1878-3253>),\n  Eli Lilly and Company [cph, fnd]",
    "url": "https://wlandau.github.io/instantiate/,\nhttps://github.com/wlandau/instantiate",
    "bug_reports": "https://github.com/wlandau/instantiate/issues",
    "repository": "https://cran.r-project.org/package=instantiate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "instantiate Pre-Compiled 'CmdStan' Models in R Packages Similar to 'rstantools' for 'rstan',\n  the 'instantiate' package builds pre-compiled\n  'CmdStan' models into CRAN-ready statistical modeling R packages.\n  The models compile once during installation,\n  the executables live inside the file systems of their respective packages,\n  and users have the full power and convenience of\n  'cmdstanr' without any additional compilation after package installation.\n  This approach saves time and helps R package developers\n  migrate from 'rstan' to the more modern 'cmdstanr'.\n  Packages 'rstantools', 'cmdstanr', 'stannis', and\n  'stanapi' are similar Stan clients with different objectives.  "
  },
  {
    "id": 14469,
    "package_name": "intSDM",
    "title": "Reproducible Integrated Species Distribution Models Across\nNorway using 'INLA'",
    "description": "Integration of disparate datasets is needed in order to make efficient use of all available data and thereby address the issues currently threatening biodiversity.\n   Data integration is a powerful modeling framework which allows us to combine these datasets together into a single model, yet retain the strengths of each individual dataset.\n   We therefore introduce the package, 'intSDM': an R package designed to help ecologists develop a reproducible workflow of integrated species distribution models, using data both provided from the user as well as data obtained freely online.\n   An introduction to data integration methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O\u2019Hara (2020) <doi:10.1016/j.tree.2019.08.006>.",
    "version": "2.1.2",
    "maintainer": "Philip Mostert <philip.s.mostert@ntnu.no>",
    "author": "Philip Mostert [aut, cre],\n  Angeline Bruls [aut],\n  Ragnhild {Bj\u00f8rk\u00e5s} [aut],\n  Wouter Koch [aut],\n  Ellen Martin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=intSDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "intSDM Reproducible Integrated Species Distribution Models Across\nNorway using 'INLA' Integration of disparate datasets is needed in order to make efficient use of all available data and thereby address the issues currently threatening biodiversity.\n   Data integration is a powerful modeling framework which allows us to combine these datasets together into a single model, yet retain the strengths of each individual dataset.\n   We therefore introduce the package, 'intSDM': an R package designed to help ecologists develop a reproducible workflow of integrated species distribution models, using data both provided from the user as well as data obtained freely online.\n   An introduction to data integration methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O\u2019Hara (2020) <doi:10.1016/j.tree.2019.08.006>.  "
  },
  {
    "id": 14488,
    "package_name": "intergraph",
    "title": "Coercion Routines for Network Data Objects",
    "description": "Functions implemented in this package allow to coerce (i.e.\n\tconvert) network data between classes provided by other R packages.\n\tCurrently supported classes are those defined in packages: network and\n\tigraph.",
    "version": "2.0-4",
    "maintainer": "Micha\u0142 Bojanowski <michal2992@gmail.com>",
    "author": "Micha\u0142 Bojanowski [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7503-852X>)",
    "url": "https://mbojan.github.io/intergraph/",
    "bug_reports": "https://github.com/mbojan/intergraph/issues",
    "repository": "https://cran.r-project.org/package=intergraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "intergraph Coercion Routines for Network Data Objects Functions implemented in this package allow to coerce (i.e.\n\tconvert) network data between classes provided by other R packages.\n\tCurrently supported classes are those defined in packages: network and\n\tigraph.  "
  },
  {
    "id": 14494,
    "package_name": "interplex",
    "title": "Coercion Methods for Simplicial Complex Data Structures",
    "description": "Computational topology, which enables topological data analysis\n    (TDA), makes pervasive use of abstract mathematical objects called\n    simplicial complexes; see Edelsbrunner and Harer (2010)\n    <doi:10.1090/mbk/069>.\n    Several R packages and other software libraries used through an R interface\n    construct and use data structures that represent simplicial complexes,\n    including mathematical graphs viewed as 1-dimensional complexes.\n    This package provides coercers (converters) between these data structures.\n    Currently supported structures are complete lists of simplices as used by\n    'TDA'; the simplex trees of Boissonnat and Maria (2014)\n    <doi:10.1007/s00453-014-9887-3> as implemented in 'simplextree' and in\n    Python GUDHI (by way of 'reticulate'); and the graph classes of 'igraph' and\n    'network', by way of the 'intergraph' package.",
    "version": "0.1.2",
    "maintainer": "Jason Cory Brunson <cornelioid@gmail.com>",
    "author": "Jason Cory Brunson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3126-9494>),\n  Yara Skaf [ctb]",
    "url": "https://github.com/tdaverse/interplex",
    "bug_reports": "https://github.com/tdaverse/interplex/issues",
    "repository": "https://cran.r-project.org/package=interplex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "interplex Coercion Methods for Simplicial Complex Data Structures Computational topology, which enables topological data analysis\n    (TDA), makes pervasive use of abstract mathematical objects called\n    simplicial complexes; see Edelsbrunner and Harer (2010)\n    <doi:10.1090/mbk/069>.\n    Several R packages and other software libraries used through an R interface\n    construct and use data structures that represent simplicial complexes,\n    including mathematical graphs viewed as 1-dimensional complexes.\n    This package provides coercers (converters) between these data structures.\n    Currently supported structures are complete lists of simplices as used by\n    'TDA'; the simplex trees of Boissonnat and Maria (2014)\n    <doi:10.1007/s00453-014-9887-3> as implemented in 'simplextree' and in\n    Python GUDHI (by way of 'reticulate'); and the graph classes of 'igraph' and\n    'network', by way of the 'intergraph' package.  "
  },
  {
    "id": 14513,
    "package_name": "intrinsicFRP",
    "title": "An R Package for Factor Model Asset Pricing",
    "description": "Functions for evaluating and testing asset pricing models, including\n    estimation and testing of factor risk premia, selection of \"strong\" risk \n    factors (factors having nonzero population correlation with test asset\n    returns), heteroskedasticity and autocorrelation robust covariance matrix\n    estimation and testing for model misspecification and identification. \n    The functions for estimating and testing factor risk \n    premia implement the Fama-MachBeth (1973) <doi:10.1086/260061> two-pass \n    approach, the misspecification-robust approaches of Kan-Robotti-Shanken (2013) \n    <doi:10.1111/jofi.12035>, and the approaches based on tradable factor risk\n    premia of Quaini-Trojani-Yuan (2023) <doi:10.2139/ssrn.4574683>. The \n    functions for selecting the \"strong\" risk factors are based on the Oracle\n    estimator of Quaini-Trojani-Yuan (2023) <doi:10.2139/ssrn.4574683> and the \n    factor screening procedure of Gospodinov-Kan-Robotti (2014) <doi:10.2139/ssrn.2579821>. \n    The functions for evaluating model misspecification implement the HJ\n    model misspecification distance of Kan-Robotti (2008) <doi:10.1016/j.jempfin.2008.03.003>,\n    which is a modification of the prominent Hansen-Jagannathan (1997)\n    <doi:10.1111/j.1540-6261.1997.tb04813.x> distance.\n    The functions for testing model identification \n    specialize the Kleibergen-Paap (2006) <doi:10.1016/j.jeconom.2005.02.011> \n    and the Chen-Fang (2019) <doi:10.1111/j.1540-6261.1997.tb04813.x> rank test \n    to the regression coefficient matrix of test asset returns on risk factors.\n    Finally, the function for heteroskedasticity and autocorrelation robust \n    covariance estimation implements the Newey-West (1994) <doi:10.2307/2297912>\n    covariance estimator.",
    "version": "2.1.0",
    "maintainer": "Alberto Quaini <alberto91quaini@gmail.com>",
    "author": "Alberto Quaini [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1251-0599>)",
    "url": "https://github.com/a91quaini/intrinsicFRP",
    "bug_reports": "https://github.com/a91quaini/intrinsicFRP/issues",
    "repository": "https://cran.r-project.org/package=intrinsicFRP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "intrinsicFRP An R Package for Factor Model Asset Pricing Functions for evaluating and testing asset pricing models, including\n    estimation and testing of factor risk premia, selection of \"strong\" risk \n    factors (factors having nonzero population correlation with test asset\n    returns), heteroskedasticity and autocorrelation robust covariance matrix\n    estimation and testing for model misspecification and identification. \n    The functions for estimating and testing factor risk \n    premia implement the Fama-MachBeth (1973) <doi:10.1086/260061> two-pass \n    approach, the misspecification-robust approaches of Kan-Robotti-Shanken (2013) \n    <doi:10.1111/jofi.12035>, and the approaches based on tradable factor risk\n    premia of Quaini-Trojani-Yuan (2023) <doi:10.2139/ssrn.4574683>. The \n    functions for selecting the \"strong\" risk factors are based on the Oracle\n    estimator of Quaini-Trojani-Yuan (2023) <doi:10.2139/ssrn.4574683> and the \n    factor screening procedure of Gospodinov-Kan-Robotti (2014) <doi:10.2139/ssrn.2579821>. \n    The functions for evaluating model misspecification implement the HJ\n    model misspecification distance of Kan-Robotti (2008) <doi:10.1016/j.jempfin.2008.03.003>,\n    which is a modification of the prominent Hansen-Jagannathan (1997)\n    <doi:10.1111/j.1540-6261.1997.tb04813.x> distance.\n    The functions for testing model identification \n    specialize the Kleibergen-Paap (2006) <doi:10.1016/j.jeconom.2005.02.011> \n    and the Chen-Fang (2019) <doi:10.1111/j.1540-6261.1997.tb04813.x> rank test \n    to the regression coefficient matrix of test asset returns on risk factors.\n    Finally, the function for heteroskedasticity and autocorrelation robust \n    covariance estimation implements the Newey-West (1994) <doi:10.2307/2297912>\n    covariance estimator.  "
  },
  {
    "id": 14553,
    "package_name": "ipeadatar",
    "title": "API Wrapper for 'Ipeadata'",
    "description": "Allows direct access to the macroeconomic, \n             financial and regional database maintained by \n             Brazilian Institute for Applied Economic Research ('Ipea').\n             This R package uses the 'Ipeadata' API. For more information, \n             see <http://www.ipeadata.gov.br/>.",
    "version": "0.1.6",
    "maintainer": "Luiz Eduardo S. Gomes <gomes.leduardo@gmail.com>",
    "author": "Luiz Eduardo S. Gomes [aut, cre],\n  Jessyka A. P. Goltara [ctb]",
    "url": "https://github.com/gomesleduardo/ipeadatar",
    "bug_reports": "https://github.com/gomesleduardo/ipeadatar/issues",
    "repository": "https://cran.r-project.org/package=ipeadatar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipeadatar API Wrapper for 'Ipeadata' Allows direct access to the macroeconomic, \n             financial and regional database maintained by \n             Brazilian Institute for Applied Economic Research ('Ipea').\n             This R package uses the 'Ipeadata' API. For more information, \n             see <http://www.ipeadata.gov.br/>.  "
  },
  {
    "id": 14560,
    "package_name": "ipkg",
    "title": "Install R Packages or Download File from GitHub via the Proxy\nSite",
    "description": "When you want to install R package or download file from GitHub, \n    but you can't access GitHub, this package helps you install R packages or \n    download file from GitHub via the proxy website <https://gh-proxy.com/> \n    or <https://ghfast.top/>, which is in real-time sync with GitHub.",
    "version": "1.1.3",
    "maintainer": "Xinyuan Chu <chuxinyuan@outlook.com>",
    "author": "Xinyuan Chu [aut, cre]",
    "url": "https://github.com/chuxinyuan/ipkg",
    "bug_reports": "https://github.com/chuxinyuan/ipkg/issues",
    "repository": "https://cran.r-project.org/package=ipkg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipkg Install R Packages or Download File from GitHub via the Proxy\nSite When you want to install R package or download file from GitHub, \n    but you can't access GitHub, this package helps you install R packages or \n    download file from GitHub via the proxy website <https://gh-proxy.com/> \n    or <https://ghfast.top/>, which is in real-time sync with GitHub.  "
  },
  {
    "id": 14591,
    "package_name": "irtQ",
    "title": "Unidimensional Item Response Theory Modeling",
    "description": "Fit unidimensional item response theory (IRT) models to test\n    data, which includes both dichotomous and polytomous items, calibrate \n    pretest item parameters, estimate examinees' abilities, and examine \n    the IRT model-data fit on item-level in different ways as well as provide \n    useful functions related to IRT analyses such as IRT model-data fit \n    evaluation and differential item functioning analysis. \n    The bring.flexmirt() and write.flexmirt() functions were written by modifying \n    the read.flexmirt() function (Pritikin & Falk (2022) <doi:10.1177/0146621620929431>).\n    The bring.bilog() and bring.parscale() functions were written by modifying the read.bilog() \n    and read.parscale() functions, respectively (Weeks (2010) <doi:10.18637/jss.v035.i12>).\n    The bisection() function was written by modifying the bisection() function \n    (Howard (2017, ISBN:9780367657918)). The code of the inverse test characteristic curve \n    scoring in the est_score() function was written by modifying the irt.eq.tse() function \n    (Gonz\u00e1lez (2014) <doi:10.18637/jss.v059.i07>). In est_score() function, the code of weighted \n    likelihood estimation method was written by referring to the Pi(), Ji(), and Ii() functions\n    of the catR package (Magis & Barrada (2017) <doi:10.18637/jss.v076.c01>).",
    "version": "1.0.0",
    "maintainer": "Hwanggyu Lim <hglim83@gmail.com>",
    "author": "Hwanggyu Lim [aut, cre],\n  Craig S. Wells [ctb],\n  James Howard [ctb],\n  Joshua Pritikin [ctb],\n  Jonathan P Weeks [ctb],\n  Jorge Gonz\u00e1lez [ctb],\n  David Magis [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=irtQ",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "irtQ Unidimensional Item Response Theory Modeling Fit unidimensional item response theory (IRT) models to test\n    data, which includes both dichotomous and polytomous items, calibrate \n    pretest item parameters, estimate examinees' abilities, and examine \n    the IRT model-data fit on item-level in different ways as well as provide \n    useful functions related to IRT analyses such as IRT model-data fit \n    evaluation and differential item functioning analysis. \n    The bring.flexmirt() and write.flexmirt() functions were written by modifying \n    the read.flexmirt() function (Pritikin & Falk (2022) <doi:10.1177/0146621620929431>).\n    The bring.bilog() and bring.parscale() functions were written by modifying the read.bilog() \n    and read.parscale() functions, respectively (Weeks (2010) <doi:10.18637/jss.v035.i12>).\n    The bisection() function was written by modifying the bisection() function \n    (Howard (2017, ISBN:9780367657918)). The code of the inverse test characteristic curve \n    scoring in the est_score() function was written by modifying the irt.eq.tse() function \n    (Gonz\u00e1lez (2014) <doi:10.18637/jss.v059.i07>). In est_score() function, the code of weighted \n    likelihood estimation method was written by referring to the Pi(), Ji(), and Ii() functions\n    of the catR package (Magis & Barrada (2017) <doi:10.18637/jss.v076.c01>).  "
  },
  {
    "id": 14649,
    "package_name": "its.analysis",
    "title": "Running Interrupted Time Series Analysis",
    "description": "Two functions for running and then post-estimating an Interrupted Time Series Analysis model. This is a solution for running time series analyses on temporally short data. See English (2019) 'The its.analysis R package - Modelling short time series data' <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3398189> for an overview of the method.",
    "version": "1.6.0",
    "maintainer": "Patrick English <p.english@exeter.ac.uk>",
    "author": "Patrick English",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=its.analysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "its.analysis Running Interrupted Time Series Analysis Two functions for running and then post-estimating an Interrupted Time Series Analysis model. This is a solution for running time series analyses on temporally short data. See English (2019) 'The its.analysis R package - Modelling short time series data' <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3398189> for an overview of the method.  "
  },
  {
    "id": 14720,
    "package_name": "jmatrix",
    "title": "Read from/Write to Disk Matrices with any Data Type in a Binary\nFormat",
    "description": "A mainly instrumental package meant to allow other packages whose core is written in 'C++' to read, write\n        and manipulate matrices in a binary format so that the memory used for them is no more than strictly needed. Its functionality\n        is already inside 'parallelpam' and 'scellpam', so if you have installed any of these, you do not need to install 'jmatrix'.\n        Using just the needed memory is not always true with 'R' matrices or vectors, since by default they are of double type. Trials\n        like the 'float' package have been done, but to use them you have to coerce a matrix already loaded in 'R' memory to a float matrix,\n        and then you can delete it. The problem comes when your computer has not memory enough to hold the matrix in the first place, so\n        you are forced to load it by chunks. This is the problem this package tries to address (with partial success, but this is a\n        difficult problem since 'R' is not a strictly typed language, which is anyway quite hard to get in an interpreted language).\n\tThis package allows the creation and manipulation of full, sparse and symmetric matrices of any standard data type.",
    "version": "1.5.2",
    "maintainer": "Juan Domingo <Juan.Domingo@uv.es>",
    "author": "Juan Domingo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4728-6256>),\n  Guillermo Ayala [ctb] (ORCID: <https://orcid.org/0000-0002-6231-2865>),\n  Spanish Ministry of Science and Innovation, MCIN/AEI\n    <doi:10.13039/501100011033> [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=jmatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jmatrix Read from/Write to Disk Matrices with any Data Type in a Binary\nFormat A mainly instrumental package meant to allow other packages whose core is written in 'C++' to read, write\n        and manipulate matrices in a binary format so that the memory used for them is no more than strictly needed. Its functionality\n        is already inside 'parallelpam' and 'scellpam', so if you have installed any of these, you do not need to install 'jmatrix'.\n        Using just the needed memory is not always true with 'R' matrices or vectors, since by default they are of double type. Trials\n        like the 'float' package have been done, but to use them you have to coerce a matrix already loaded in 'R' memory to a float matrix,\n        and then you can delete it. The problem comes when your computer has not memory enough to hold the matrix in the first place, so\n        you are forced to load it by chunks. This is the problem this package tries to address (with partial success, but this is a\n        difficult problem since 'R' is not a strictly typed language, which is anyway quite hard to get in an interpreted language).\n\tThis package allows the creation and manipulation of full, sparse and symmetric matrices of any standard data type.  "
  },
  {
    "id": 14761,
    "package_name": "jquerylib",
    "title": "Obtain 'jQuery' as an HTML Dependency Object",
    "description": "Obtain any major version of 'jQuery' (<https://code.jquery.com/>) and use it in any webpage generated by 'htmltools' (e.g. 'shiny', 'htmlwidgets', and 'rmarkdown').\n    Most R users don't need to use this package directly, but other R packages (e.g. 'shiny', 'rmarkdown', etc.) depend on this package to avoid bundling redundant copies of 'jQuery'.",
    "version": "0.1.4",
    "maintainer": "Carson Sievert <carson@rstudio.com>",
    "author": "Carson Sievert [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4958-2844>),\n  Joe Cheng [aut],\n  RStudio [cph],\n  jQuery Foundation [cph] (jQuery library and jQuery UI library),\n  jQuery contributors [ctb, cph] (jQuery library; authors listed in\n    inst/lib/jquery-AUTHORS.txt)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=jquerylib",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jquerylib Obtain 'jQuery' as an HTML Dependency Object Obtain any major version of 'jQuery' (<https://code.jquery.com/>) and use it in any webpage generated by 'htmltools' (e.g. 'shiny', 'htmlwidgets', and 'rmarkdown').\n    Most R users don't need to use this package directly, but other R packages (e.g. 'shiny', 'rmarkdown', etc.) depend on this package to avoid bundling redundant copies of 'jQuery'.  "
  },
  {
    "id": 14846,
    "package_name": "kernelshap",
    "title": "Kernel SHAP",
    "description": "Efficient implementation of Kernel SHAP (Lundberg and Lee,\n    2017, <doi:10.48550/arXiv.1705.07874>) permutation SHAP, and additive\n    SHAP for model interpretability.  For Kernel SHAP and permutation\n    SHAP, if the number of features is too large for exact calculations,\n    the algorithms iterate until the SHAP values are sufficiently precise\n    in terms of their standard errors.  The package integrates smoothly\n    with meta-learning packages such as 'tidymodels', 'caret' or 'mlr3'.\n    It supports multi-output models, case weights, and parallel\n    computations.  Visualizations can be done using the R package\n    'shapviz'.",
    "version": "0.9.1",
    "maintainer": "Michael Mayer <mayermichael79@gmail.com>",
    "author": "Michael Mayer [aut, cre] (ORCID:\n    <https://orcid.org/0009-0007-2540-9629>),\n  David Watson [aut] (ORCID: <https://orcid.org/0000-0001-9632-2159>),\n  Przemyslaw Biecek [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8423-1823>)",
    "url": "https://github.com/ModelOriented/kernelshap",
    "bug_reports": "https://github.com/ModelOriented/kernelshap/issues",
    "repository": "https://cran.r-project.org/package=kernelshap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kernelshap Kernel SHAP Efficient implementation of Kernel SHAP (Lundberg and Lee,\n    2017, <doi:10.48550/arXiv.1705.07874>) permutation SHAP, and additive\n    SHAP for model interpretability.  For Kernel SHAP and permutation\n    SHAP, if the number of features is too large for exact calculations,\n    the algorithms iterate until the SHAP values are sufficiently precise\n    in terms of their standard errors.  The package integrates smoothly\n    with meta-learning packages such as 'tidymodels', 'caret' or 'mlr3'.\n    It supports multi-output models, case weights, and parallel\n    computations.  Visualizations can be done using the R package\n    'shapviz'.  "
  },
  {
    "id": 14865,
    "package_name": "kfda",
    "title": "Kernel Fisher Discriminant Analysis",
    "description": "Kernel Fisher Discriminant Analysis (KFDA) is performed using Kernel Principal Component Analysis (KPCA) and Fisher Discriminant Analysis (FDA).\n    There are some similar packages. First, 'lfda' is a package that performs Local Fisher Discriminant Analysis (LFDA) and performs other functions.\n    In particular, 'lfda' seems to be impossible to test because it needs the label information of the data in the function argument. Also, the 'ks' package has a limited dimension, which makes it difficult to analyze properly.\n    This package is a simple and practical package for KFDA based on the paper of Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) <DOI:10.1016/j.patcog.2003.10.015>.",
    "version": "1.0.0",
    "maintainer": "Donghwan Kim <donhkim9714@korea.ac.kr>",
    "author": "Donghwan Kim",
    "url": "https://github.com/ainsuotain/kfda",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kfda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kfda Kernel Fisher Discriminant Analysis Kernel Fisher Discriminant Analysis (KFDA) is performed using Kernel Principal Component Analysis (KPCA) and Fisher Discriminant Analysis (FDA).\n    There are some similar packages. First, 'lfda' is a package that performs Local Fisher Discriminant Analysis (LFDA) and performs other functions.\n    In particular, 'lfda' seems to be impossible to test because it needs the label information of the data in the function argument. Also, the 'ks' package has a limited dimension, which makes it difficult to analyze properly.\n    This package is a simple and practical package for KFDA based on the paper of Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) <DOI:10.1016/j.patcog.2003.10.015>.  "
  },
  {
    "id": 14879,
    "package_name": "kim",
    "title": "A Toolkit for Behavioral Scientists",
    "description": "A collection of functions for analyzing data typically collected \n    or used by behavioral scientists. Examples of the functions include\n    a function that compares groups in a factorial experimental design,\n    a function that conducts two-way analysis of variance (ANOVA),\n    and a function that cleans a data set generated by Qualtrics surveys.\n    Some of the functions will require installing additional package(s).\n    Such packages and other references are cited within the section\n    describing the relevant functions. Many functions in this package\n    rely heavily on these two popular R packages:\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Wickham et al. (2021) <https://CRAN.R-project.org/package=ggplot2>.",
    "version": "0.6.1",
    "maintainer": "Jin Kim <jinkim@aya.yale.edu>",
    "author": "Jin Kim [aut, cre] (ORCID: <https://orcid.org/0000-0002-5013-3958>)",
    "url": "https://github.com/jinkim3/kim, https://jinkim.science",
    "bug_reports": "https://github.com/jinkim3/kim/issues",
    "repository": "https://cran.r-project.org/package=kim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kim A Toolkit for Behavioral Scientists A collection of functions for analyzing data typically collected \n    or used by behavioral scientists. Examples of the functions include\n    a function that compares groups in a factorial experimental design,\n    a function that conducts two-way analysis of variance (ANOVA),\n    and a function that cleans a data set generated by Qualtrics surveys.\n    Some of the functions will require installing additional package(s).\n    Such packages and other references are cited within the section\n    describing the relevant functions. Many functions in this package\n    rely heavily on these two popular R packages:\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Wickham et al. (2021) <https://CRAN.R-project.org/package=ggplot2>.  "
  },
  {
    "id": 14899,
    "package_name": "klausuR",
    "title": "Multiple Choice Test Evaluation",
    "description": "A set of functions designed to quickly generate results of a multiple choice\n          test. Generates detailed global results, lists for anonymous feedback and\n          personalised result feedback (in LaTeX and/or PDF format), as well as item\n          statistics like Cronbach's alpha or disciminatory power. 'klausuR' also\n          includes a plugin for the R GUI and IDE RKWard, providing graphical dialogs for\n          its basic features. The respective R package 'rkward' cannot be installed\n          directly from a repository, as it is a part of RKWard. To make full use of this\n          feature, please install RKWard from <https://rkward.kde.org> (plugins are\n          detected automatically). Due to some restrictions on CRAN, the full package\n          sources are only available from the project homepage.",
    "version": "0.12-14",
    "maintainer": "m.eik michalke <meik.michalke@hhu.de>",
    "author": "m.eik michalke [aut, cre]",
    "url": "https://reaktanz.de/?c=hacking&s=klausuR",
    "bug_reports": "https://github.com/unDocUMeantIt/klausuR/issues",
    "repository": "https://cran.r-project.org/package=klausuR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "klausuR Multiple Choice Test Evaluation A set of functions designed to quickly generate results of a multiple choice\n          test. Generates detailed global results, lists for anonymous feedback and\n          personalised result feedback (in LaTeX and/or PDF format), as well as item\n          statistics like Cronbach's alpha or disciminatory power. 'klausuR' also\n          includes a plugin for the R GUI and IDE RKWard, providing graphical dialogs for\n          its basic features. The respective R package 'rkward' cannot be installed\n          directly from a repository, as it is a part of RKWard. To make full use of this\n          feature, please install RKWard from <https://rkward.kde.org> (plugins are\n          detected automatically). Due to some restrictions on CRAN, the full package\n          sources are only available from the project homepage.  "
  },
  {
    "id": 14916,
    "package_name": "knfi",
    "title": "Analysis of Korean National Forest Inventory Database",
    "description": "Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.",
    "version": "1.0.1.9",
    "maintainer": "Sinyoung Park <youngsin0306@kookmin.ac.kr>",
    "author": "Sinyoung Park [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3658-0935>),\n  Wonhee Cho [aut, ctb] (ORCID: <https://orcid.org/0000-0002-9598-6188>),\n  Inyoo Kim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-7709-8224>),\n  Wontaek Lim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-5872-1121>),\n  Dongwook W. Ko [aut, ths] (ORCID:\n    <https://orcid.org/0000-0002-6944-0261>)",
    "url": "https://github.com/SYOUNG9836/knfi,\nhttps://syoung9836.github.io/knfi/",
    "bug_reports": "https://github.com/SYOUNG9836/knfi/issues",
    "repository": "https://cran.r-project.org/package=knfi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knfi Analysis of Korean National Forest Inventory Database Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.  "
  },
  {
    "id": 14931,
    "package_name": "koRpus",
    "title": "Text Analysis with Emphasis on POS Tagging, Readability, and\nLexical Diversity",
    "description": "A set of tools to analyze texts. Includes, amongst others, functions for\n          automatic language detection, hyphenation, several indices of lexical diversity\n          (e.g., type token ratio, HD-D/vocd-D, MTLD) and readability (e.g., Flesch,\n          SMOG, LIX, Dale-Chall). Basic import functions for language corpora are also\n          provided, to enable frequency analyses (supports Celex and Leipzig Corpora\n          Collection file formats) and measures like tf-idf. Note: For full functionality\n          a local installation of TreeTagger is recommended. It is also recommended to\n          not load this package directly, but by loading one of the available language\n          support packages from the 'l10n' repository\n          <https://undocumeantit.github.io/repos/l10n/>. 'koRpus' also includes a plugin\n          for the R GUI and IDE RKWard, providing graphical dialogs for its basic\n          features. The respective R package 'rkward' cannot be installed directly from a\n          repository, as it is a part of RKWard. To make full use of this feature, please\n          install RKWard from <https://rkward.kde.org> (plugins are detected\n          automatically). Due to some restrictions on CRAN, the full package sources are\n          only available from the project homepage. To ask for help, report bugs, request\n          features, or discuss the development of the package, please subscribe to the\n          koRpus-dev mailing list (<https://korpusml.reaktanz.de>).",
    "version": "0.13-8",
    "maintainer": "Meik Michalke <meik.michalke@hhu.de>",
    "author": "Meik Michalke [aut, cre],\n  Earl Brown [ctb],\n  Alberto Mirisola [ctb],\n  Alexandre Brulet [ctb],\n  Laura Hauser [ctb]",
    "url": "https://reaktanz.de/?c=hacking&s=koRpus",
    "bug_reports": "https://github.com/unDocUMeantIt/koRpus/issues",
    "repository": "https://cran.r-project.org/package=koRpus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "koRpus Text Analysis with Emphasis on POS Tagging, Readability, and\nLexical Diversity A set of tools to analyze texts. Includes, amongst others, functions for\n          automatic language detection, hyphenation, several indices of lexical diversity\n          (e.g., type token ratio, HD-D/vocd-D, MTLD) and readability (e.g., Flesch,\n          SMOG, LIX, Dale-Chall). Basic import functions for language corpora are also\n          provided, to enable frequency analyses (supports Celex and Leipzig Corpora\n          Collection file formats) and measures like tf-idf. Note: For full functionality\n          a local installation of TreeTagger is recommended. It is also recommended to\n          not load this package directly, but by loading one of the available language\n          support packages from the 'l10n' repository\n          <https://undocumeantit.github.io/repos/l10n/>. 'koRpus' also includes a plugin\n          for the R GUI and IDE RKWard, providing graphical dialogs for its basic\n          features. The respective R package 'rkward' cannot be installed directly from a\n          repository, as it is a part of RKWard. To make full use of this feature, please\n          install RKWard from <https://rkward.kde.org> (plugins are detected\n          automatically). Due to some restrictions on CRAN, the full package sources are\n          only available from the project homepage. To ask for help, report bugs, request\n          features, or discuss the development of the package, please subscribe to the\n          koRpus-dev mailing list (<https://korpusml.reaktanz.de>).  "
  },
  {
    "id": 14940,
    "package_name": "kosel",
    "title": "Variable Selection by Revisited Knockoffs Procedures",
    "description": "Performs variable selection for many types of L1-regularised regressions using the revisited knockoffs procedure. This procedure uses a matrix of knockoffs of the covariates independent from the response variable Y. The idea is to determine if a covariate belongs to the model depending on whether it enters the model before or after its knockoff. The procedure suits for a wide range of regressions with various types of response variables. Regression models available are exported from the R packages 'glmnet' and 'ordinalNet'. Based on the paper linked to via the URL below: Gegout A., Gueudin A., Karmann C. (2019) <arXiv:1907.03153>.",
    "version": "0.0.1",
    "maintainer": "Clemence Karmann <clemence.karmann@gmail.com>",
    "author": "Clemence Karmann [aut, cre],\n  Aurelie Gueudin [aut]",
    "url": "https://arxiv.org/pdf/1907.03153.pdf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kosel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kosel Variable Selection by Revisited Knockoffs Procedures Performs variable selection for many types of L1-regularised regressions using the revisited knockoffs procedure. This procedure uses a matrix of knockoffs of the covariates independent from the response variable Y. The idea is to determine if a covariate belongs to the model depending on whether it enters the model before or after its knockoff. The procedure suits for a wide range of regressions with various types of response variables. Regression models available are exported from the R packages 'glmnet' and 'ordinalNet'. Based on the paper linked to via the URL below: Gegout A., Gueudin A., Karmann C. (2019) <arXiv:1907.03153>.  "
  },
  {
    "id": 14975,
    "package_name": "l1kdeconv",
    "title": "Deconvolution for LINCS L1000 Data",
    "description": "LINCS L1000 is a high-throughput technology that allows the gene expression measurement in a large number of assays. However, to fit the measurements of ~1000 genes in the ~500 color channels of LINCS L1000, every two landmark genes are designed to share a single channel. Thus, a deconvolution step is required to infer the expression values of each gene. Any errors in this step can be propagated adversely to the downstream analyses. We present a LINCS L1000 data peak calling R package l1kdeconv based on a new outlier detection method and an aggregate Gaussian mixture model. Upon the remove of outliers and the borrowing information among similar samples, l1kdeconv shows more stable and better performance than methods commonly used in LINCS L1000 data deconvolution.",
    "version": "1.2.0",
    "maintainer": "Zhao Li <lizhao.informatics@gmail.com>",
    "author": "Zhao Li[aut], Peng Yu[aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=l1kdeconv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "l1kdeconv Deconvolution for LINCS L1000 Data LINCS L1000 is a high-throughput technology that allows the gene expression measurement in a large number of assays. However, to fit the measurements of ~1000 genes in the ~500 color channels of LINCS L1000, every two landmark genes are designed to share a single channel. Thus, a deconvolution step is required to infer the expression values of each gene. Any errors in this step can be propagated adversely to the downstream analyses. We present a LINCS L1000 data peak calling R package l1kdeconv based on a new outlier detection method and an aggregate Gaussian mixture model. Upon the remove of outliers and the borrowing information among similar samples, l1kdeconv shows more stable and better performance than methods commonly used in LINCS L1000 data deconvolution.  "
  },
  {
    "id": 14984,
    "package_name": "labelVector",
    "title": "Label Attributes for Atomic Vectors",
    "description": "Labels are a common construct in statistical software providing a \n  human readable description of a variable. While variable names are succinct,\n  quick to type, and follow a language's naming conventions, labels may \n  be more illustrative and may use plain text and spaces. R does not provide\n  native support for labels. Some packages, however, have made this feature\n  available.  Most notably, the 'Hmisc' package provides labelling methods\n  for a number of different object. Due to design decisions, these methods\n  are not all exported, and so are unavailable for use in package development.\n  The 'labelVector' package supports labels for atomic vectors in a light-weight\n  design that is suitable for use in other packages.",
    "version": "0.1.2",
    "maintainer": "Benjamin Nutter <benjamin.nutter@gmail.com>",
    "author": "Benjamin Nutter [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=labelVector",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "labelVector Label Attributes for Atomic Vectors Labels are a common construct in statistical software providing a \n  human readable description of a variable. While variable names are succinct,\n  quick to type, and follow a language's naming conventions, labels may \n  be more illustrative and may use plain text and spaces. R does not provide\n  native support for labels. Some packages, however, have made this feature\n  available.  Most notably, the 'Hmisc' package provides labelling methods\n  for a number of different object. Due to design decisions, these methods\n  are not all exported, and so are unavailable for use in package development.\n  The 'labelVector' package supports labels for atomic vectors in a light-weight\n  design that is suitable for use in other packages.  "
  },
  {
    "id": 15038,
    "package_name": "latentcor",
    "title": "Fast Computation of Latent Correlations for Mixed Data",
    "description": "The first stand-alone R package for computation of latent correlation that takes into account all variable types (continuous/binary/ordinal/zero-inflated),\n             comes with an optimized memory footprint, and is computationally efficient, essentially making latent correlation estimation almost as fast as rank-based correlation estimation.\n             The estimation is based on latent copula Gaussian models.\n             For continuous/binary types, see Fan, J., Liu, H., Ning, Y., and Zou, H. (2017).\n             For ternary type, see Quan X., Booth J.G. and Wells M.T. (2018) <doi:10.48550/arXiv.1809.06255>.\n             For truncated type or zero-inflated type, see Yoon G., Carroll R.J. and Gaynanova I. (2020) <doi:10.1093/biomet/asaa007>.\n             For approximation method of computation, see Yoon G., M\u00fcller C.L. and Gaynanova I. (2021) <doi:10.1080/10618600.2021.1882468>. The latter method uses multi-linear interpolation originally implemented in the R package <https://cran.r-project.org/package=chebpol>.",
    "version": "2.0.2",
    "maintainer": "Irina Gaynanova <irinagn@umich.edu>",
    "author": "Mingze Huang [aut] (ORCID: <https://orcid.org/0000-0003-3919-1564>),\n  Grace Yoon [aut] (ORCID: <https://orcid.org/0000-0003-3263-1352>),\n  Christian M&uuml;ller [aut] (ORCID:\n    <https://orcid.org/0000-0002-3821-7083>),\n  Irina Gaynanova [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4116-0268>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=latentcor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "latentcor Fast Computation of Latent Correlations for Mixed Data The first stand-alone R package for computation of latent correlation that takes into account all variable types (continuous/binary/ordinal/zero-inflated),\n             comes with an optimized memory footprint, and is computationally efficient, essentially making latent correlation estimation almost as fast as rank-based correlation estimation.\n             The estimation is based on latent copula Gaussian models.\n             For continuous/binary types, see Fan, J., Liu, H., Ning, Y., and Zou, H. (2017).\n             For ternary type, see Quan X., Booth J.G. and Wells M.T. (2018) <doi:10.48550/arXiv.1809.06255>.\n             For truncated type or zero-inflated type, see Yoon G., Carroll R.J. and Gaynanova I. (2020) <doi:10.1093/biomet/asaa007>.\n             For approximation method of computation, see Yoon G., M\u00fcller C.L. and Gaynanova I. (2021) <doi:10.1080/10618600.2021.1882468>. The latter method uses multi-linear interpolation originally implemented in the R package <https://cran.r-project.org/package=chebpol>.  "
  },
  {
    "id": 15045,
    "package_name": "latrend",
    "title": "A Framework for Clustering Longitudinal Data",
    "description": "A framework for clustering longitudinal datasets in a standardized way. \n    The package provides an interface to existing R packages for clustering longitudinal univariate trajectories, facilitating reproducible and transparent analyses. \n    Additionally, standard tools are provided to support cluster analyses, including repeated estimation, model validation, and model assessment. \n    The interface enables users to compare results between methods, and to implement and evaluate new methods with ease.\n    The 'akmedoids' package is available from <https://github.com/MAnalytics/akmedoids>.",
    "version": "1.6.2",
    "maintainer": "Niek Den Teuling <niek.den.teuling@philips.com>",
    "author": "Niek Den Teuling [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1026-5080>),\n  Steffen Pauws [ctb],\n  Edwin van den Heuvel [ctb],\n  Koninklijke Philips N.V. [cph]",
    "url": "https://github.com/niekdt/latrend,\nhttps://niekdt.github.io/latrend/",
    "bug_reports": "https://github.com/niekdt/latrend/issues",
    "repository": "https://cran.r-project.org/package=latrend",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "latrend A Framework for Clustering Longitudinal Data A framework for clustering longitudinal datasets in a standardized way. \n    The package provides an interface to existing R packages for clustering longitudinal univariate trajectories, facilitating reproducible and transparent analyses. \n    Additionally, standard tools are provided to support cluster analyses, including repeated estimation, model validation, and model assessment. \n    The interface enables users to compare results between methods, and to implement and evaluate new methods with ease.\n    The 'akmedoids' package is available from <https://github.com/MAnalytics/akmedoids>.  "
  },
  {
    "id": 15053,
    "package_name": "lavaan.mi",
    "title": "Fit Structural Equation Models to Multiply Imputed Data",
    "description": "The primary purpose of 'lavaan.mi' is to extend the functionality \n     of the R package 'lavaan', which implements structural equation modeling\n     (SEM).  When incomplete data have been multiply imputed, the imputed data\n     sets can be analyzed by 'lavaan' using complete-data estimation methods,\n     but results must be pooled across imputations (Rubin, 1987, <doi:10.1002/9780470316696>).\n     The 'lavaan.mi' package automates the pooling of point and standard-error\n     estimates, as well as a variety of test statistics, using a familiar interface\n     that allows users to fit an SEM to multiple imputations as they would to a\n     single data set using the 'lavaan' package.",
    "version": "0.1-0",
    "maintainer": "Terrence D. Jorgensen <TJorgensen314@gmail.com>",
    "author": "Terrence D. Jorgensen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5111-6773>),\n  Yves Rosseel [ctb] (ORCID: <https://orcid.org/0000-0002-4129-4477>)",
    "url": "https://github.com/TDJorgensen/lavaan.mi",
    "bug_reports": "https://github.com/TDJorgensen/lavaan.mi/issues",
    "repository": "https://cran.r-project.org/package=lavaan.mi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lavaan.mi Fit Structural Equation Models to Multiply Imputed Data The primary purpose of 'lavaan.mi' is to extend the functionality \n     of the R package 'lavaan', which implements structural equation modeling\n     (SEM).  When incomplete data have been multiply imputed, the imputed data\n     sets can be analyzed by 'lavaan' using complete-data estimation methods,\n     but results must be pooled across imputations (Rubin, 1987, <doi:10.1002/9780470316696>).\n     The 'lavaan.mi' package automates the pooling of point and standard-error\n     estimates, as well as a variety of test statistics, using a familiar interface\n     that allows users to fit an SEM to multiple imputations as they would to a\n     single data set using the 'lavaan' package.  "
  },
  {
    "id": 15054,
    "package_name": "lavaan.printer",
    "title": "Helper Functions for Printing 'lavaan' Outputs",
    "description": "Helpers for customizing selected outputs from\n  'lavaan' by Rosseel (2012) <doi:10.18637/jss.v048.i02>\n  and print them. The functions are intended to be used\n  by package developers in their packages and so are not\n  designed to be user-friendly. They are designed to be\n  let developers customize the tables by other\n  functions. Currently the parameter estimates tables of a\n  fitted object are supported.",
    "version": "0.1.0",
    "maintainer": "Shu Fai Cheung <shufai.cheung@gmail.com>",
    "author": "Shu Fai Cheung [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9871-9448>)",
    "url": "https://sfcheung.github.io/lavaan.printer/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lavaan.printer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lavaan.printer Helper Functions for Printing 'lavaan' Outputs Helpers for customizing selected outputs from\n  'lavaan' by Rosseel (2012) <doi:10.18637/jss.v048.i02>\n  and print them. The functions are intended to be used\n  by package developers in their packages and so are not\n  designed to be user-friendly. They are designed to be\n  let developers customize the tables by other\n  functions. Currently the parameter estimates tables of a\n  fitted object are supported.  "
  },
  {
    "id": 15056,
    "package_name": "lavaanExtra",
    "title": "Convenience Functions for Package 'lavaan'",
    "description": "Affords an alternative, vector-based syntax to 'lavaan', as well as other \n             convenience functions such as naming paths and defining indirect\n             links automatically, in addition to convenience formatting optimized\n             for a publication and script sharing workflow.",
    "version": "0.2.2",
    "maintainer": "R\u00e9mi Th\u00e9riault <remi.theriault@mail.mcgill.ca>",
    "author": "R\u00e9mi Th\u00e9riault [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4315-6788>)",
    "url": "https://lavaanExtra.remi-theriault.com",
    "bug_reports": "https://github.com/rempsyc/lavaanExtra/issues",
    "repository": "https://cran.r-project.org/package=lavaanExtra",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lavaanExtra Convenience Functions for Package 'lavaan' Affords an alternative, vector-based syntax to 'lavaan', as well as other \n             convenience functions such as naming paths and defining indirect\n             links automatically, in addition to convenience formatting optimized\n             for a publication and script sharing workflow.  "
  },
  {
    "id": 15065,
    "package_name": "lazyData",
    "title": "A LazyData Facility",
    "description": "Supplies a LazyData facility for packages which have data\n\t\tsets but do not provide LazyData: true.  A single function is\n\t\tis included, requireData, which is a drop-in replacement for\n\t\tbase::require, but carrying the additional\n\t\tfunctionality. By default, it suppresses package\n\t\tstartup messages as well.  See argument 'reallyQuitely'.",
    "version": "1.1.0",
    "maintainer": "Bill Venables <bill.venables@gmail.com>",
    "author": "Bill Venables",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lazyData",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lazyData A LazyData Facility Supplies a LazyData facility for packages which have data\n\t\tsets but do not provide LazyData: true.  A single function is\n\t\tis included, requireData, which is a drop-in replacement for\n\t\tbase::require, but carrying the additional\n\t\tfunctionality. By default, it suppresses package\n\t\tstartup messages as well.  See argument 'reallyQuitely'.  "
  },
  {
    "id": 15071,
    "package_name": "lazytrade",
    "title": "Learn Computer and Data Science using Algorithmic Trading",
    "description": "Provide sets of functions and methods to learn and practice data science using idea of algorithmic trading.\n    Main goal is to process information within \"Decision Support System\" to come up with analysis or predictions.\n    There are several utilities such as dynamic and adaptive risk management using reinforcement learning\n    and even functions to generate predictions of price changes using pattern recognition deep regression learning.\n    Summary of Methods used: Awesome H2O tutorials: <https://github.com/h2oai/awesome-h2o>, \n    Market Type research of Van Tharp Institute: <https://vantharp.com/>,\n    Reinforcement Learning R package: <https://CRAN.R-project.org/package=ReinforcementLearning>.",
    "version": "0.5.4",
    "maintainer": "Vladimir Zhbanko <vladimir.zhbanko@gmail.com>",
    "author": "Vladimir Zhbanko",
    "url": "https://vladdsm.github.io/myblog_attempt/topics/lazy%20trading/,\nhttps://github.com/vzhomeexperiments/lazytrade",
    "bug_reports": "https://github.com/vzhomeexperiments/lazytrade/issues",
    "repository": "https://cran.r-project.org/package=lazytrade",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lazytrade Learn Computer and Data Science using Algorithmic Trading Provide sets of functions and methods to learn and practice data science using idea of algorithmic trading.\n    Main goal is to process information within \"Decision Support System\" to come up with analysis or predictions.\n    There are several utilities such as dynamic and adaptive risk management using reinforcement learning\n    and even functions to generate predictions of price changes using pattern recognition deep regression learning.\n    Summary of Methods used: Awesome H2O tutorials: <https://github.com/h2oai/awesome-h2o>, \n    Market Type research of Van Tharp Institute: <https://vantharp.com/>,\n    Reinforcement Learning R package: <https://CRAN.R-project.org/package=ReinforcementLearning>.  "
  },
  {
    "id": 15088,
    "package_name": "lcsm",
    "title": "Univariate and Bivariate Latent Change Score Modelling",
    "description": "Helper functions to implement univariate and bivariate latent change score models in R using the 'lavaan' package.\n  For details about Latent Change Score Modeling (LCSM) see McArdle (2009) <doi:10.1146/annurev.psych.60.110707.163612> and Grimm, An, McArdle, Zonderman and Resnick (2012) <doi:10.1080/10705511.2012.659627>.\n  The package automatically generates 'lavaan' syntax for different model specifications and varying timepoints.\n  The 'lavaan' syntax generated by this package can be returned and further specifications can be added manually.\n  Longitudinal plots as well as simplified path diagrams can be created to visualise data and model specifications.\n  Estimated model parameters and fit statistics can be extracted as data frames.\n  Data for different univariate and bivariate LCSM can be simulated by specifying estimates for model parameters to explore their effects.\n  This package combines the strengths of other R packages like 'lavaan', 'broom', and 'semPlot' by generating 'lavaan' syntax that helps these packages work together.",
    "version": "0.3.2",
    "maintainer": "Milan Wiedemann <milan.wiedemann@gmail.com>",
    "author": "Milan Wiedemann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1991-282X>),\n  Graham M Thew [ctb] (ORCID: <https://orcid.org/0000-0003-2851-1315>),\n  Ur\u0161ka Ko\u0161ir [ctb] (ORCID: <https://orcid.org/0000-0003-2132-4090>),\n  Anke Ehlers [ths] (ORCID: <https://orcid.org/0000-0002-8742-0192>),\n  Mental Health Research UK [fnd]",
    "url": "https://milanwiedemann.github.io/lcsm/",
    "bug_reports": "https://github.com/milanwiedemann/lcsm/issues",
    "repository": "https://cran.r-project.org/package=lcsm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lcsm Univariate and Bivariate Latent Change Score Modelling Helper functions to implement univariate and bivariate latent change score models in R using the 'lavaan' package.\n  For details about Latent Change Score Modeling (LCSM) see McArdle (2009) <doi:10.1146/annurev.psych.60.110707.163612> and Grimm, An, McArdle, Zonderman and Resnick (2012) <doi:10.1080/10705511.2012.659627>.\n  The package automatically generates 'lavaan' syntax for different model specifications and varying timepoints.\n  The 'lavaan' syntax generated by this package can be returned and further specifications can be added manually.\n  Longitudinal plots as well as simplified path diagrams can be created to visualise data and model specifications.\n  Estimated model parameters and fit statistics can be extracted as data frames.\n  Data for different univariate and bivariate LCSM can be simulated by specifying estimates for model parameters to explore their effects.\n  This package combines the strengths of other R packages like 'lavaan', 'broom', and 'semPlot' by generating 'lavaan' syntax that helps these packages work together.  "
  },
  {
    "id": 15179,
    "package_name": "libopenexr",
    "title": "Static Library and Headers for 'OpenEXR' Image I/O",
    "description": "Provides the 'OpenEXR' static library and 'C++' headers \n    for high-dynamic-range image I/O  (see <https://openexr.com/>) \n    needed to link R packages against the 'OpenEXR' library, along \n    with a basic R interface to load 'EXR' images.",
    "version": "3.4.0-5",
    "maintainer": "Tyler Morgan-Wall <tylermw@gmail.com>",
    "author": "Tyler Morgan-Wall [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3131-3814>),\n  Aaron Demolder [ctb, cph],\n  Abe Fettig [ctb, cph],\n  Aloys Baillet [ctb, cph],\n  Andre Mazzone [ctb, cph],\n  Andrew Kunz [ctb, cph],\n  Anton Dukhovnikov [ctb, cph],\n  Antonio Rojas [ctb, cph],\n  Aras Pranckevi\u010dius [ctb, cph],\n  Arkady Shapkin [ctb, cph],\n  Arkell Rasiah [ctb, cph],\n  Axel Waggershauser [ctb, cph],\n  Bal\u00e1zs Oroszi [ctb, cph],\n  Barnaby Robson [ctb, cph],\n  Ben Grimes [ctb, cph],\n  Brendan Bolles [ctb, cph],\n  Cary Phillips [ctb, cph],\n  Chris Leu [ctb, cph],\n  Christina Tempelaar-Lietz [ctb, cph],\n  Christopher Horvath [ctb, cph],\n  Christopher Kulla [ctb, cph],\n  Christoph Gohlke [ctb, cph],\n  Cristian Mart\u00ednez [ctb, cph],\n  Dan Hor\u00e1k [ctb, cph],\n  Daniel Kaneider [ctb, cph],\n  Darby Johnston [ctb, cph],\n  Dave Sawyer [ctb, cph],\n  David Korczynski [ctb, cph],\n  Diogo Teles Sant'Anna [ctb, cph],\n  Dirk Lemstra [ctb, cph],\n  Drew Hess [ctb, cph],\n  Ed Hanway [ctb, cph],\n  Edward Kmett [ctb, cph],\n  Eric Sommerlade [ctb, cph],\n  E Sommerlade [ctb, cph],\n  Florian Kainz [ctb, cph],\n  Grant Kim [ctb, cph],\n  Gregorio Litenstein [ctb, cph],\n  Gyula Gubacsi [ctb, cph],\n  Halfdan Ingvarsson [ctb, cph],\n  Harry Mallon [ctb, cph],\n  Huibean Luo [ctb, cph],\n  Ibraheem Alhashim [ctb, cph],\n  Jack Kingsman [ctb, cph],\n  Jamie Kenyon [ctb, cph],\n  Jan Tojnar [ctb, cph],\n  Jean-Francois Panisset [ctb, cph],\n  Jens Lindgren [ctb, cph],\n  Ji Hun Yu [ctb, cph],\n  Johannes Vollmer [ctb, cph],\n  John Loy [ctb, cph],\n  John Mertic [ctb, cph],\n  Jonathan Stone [ctb, cph],\n  Jose Luis Cercos-Pita [ctb, cph],\n  Joseph Goldstone [ctb, cph],\n  Juha Reunanen [ctb, cph],\n  Julian Amann [ctb, cph],\n  Juri Abramov [ctb, cph],\n  Karl Hendrikse [ctb, cph],\n  Karl Rasche [ctb, cph],\n  Kevin Wheatley [ctb, cph],\n  Kimball Thurston [ctb, cph],\n  Larry Gritz [ctb, cph],\n  Laurens Voerman [ctb, cph],\n  L. E. Segovia [ctb, cph],\n  Liam Fernandez [ctb, cph],\n  Lucy Wilkes [ctb, cph],\n  Mark Reid [ctb, cph],\n  Mark Sisson [ctb, cph],\n  Martin Aum\u00fcller [ctb, cph],\n  Martin Husemann [ctb, cph],\n  Matth\u00e4us G. Chajdas [ctb, cph],\n  Matthias C. M. Troffaes [ctb, cph],\n  Matt Pharr [ctb, cph],\n  Md Sadman Chowdhury [ctb, cph],\n  Michael Thomas [ctb, cph],\n  Nicholas Yue [ctb, cph],\n  Nick Porcino [ctb, cph],\n  Nick Rasmussen [ctb, cph],\n  Nicolas Chauvet [ctb, cph],\n  Niklas Hamb\u00fcchen [ctb, cph],\n  Owen Thompson [ctb, cph],\n  Paul Schneider [ctb, cph],\n  Peter Hillman [ctb, cph],\n  Peter Steneteg [ctb, cph],\n  Peter Urbanec [ctb, cph],\n  Phil Barrett [ctb, cph],\n  Piotr Stanczyk [ctb, cph],\n  Ralph Potter [ctb, cph],\n  R\u00e9mi Achard [ctb, cph],\n  Reto Kromer [ctb, cph],\n  Richard Goedeken [ctb, cph],\n  Sergey Fedorov [ctb, cph],\n  Shawn Walker-Salas [ctb, cph],\n  Simon Boorer [ctb, cph],\n  Simon Otter [ctb, cph],\n  Srinath Ravichandran [ctb, cph],\n  Thanh Ha [ctb, cph],\n  Thomas Debesse [ctb, cph],\n  Thorsten Kaufmann [ctb, cph],\n  Timothy Lyanguzov [ctb, cph],\n  Wenzel Jakob [ctb, cph],\n  Wojciech Jarosz [ctb, cph],\n  Xo Wang [ctb, cph],\n  Yaakov Selkowitz [ctb, cph],\n  Yining Karl Li [ctb, cph],\n  Yujie Shu [ctb, cph],\n  Kevin Ushey [cph]",
    "url": "",
    "bug_reports": "https://github.com/tylermorganwall/libopenexr/issues",
    "repository": "https://cran.r-project.org/package=libopenexr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "libopenexr Static Library and Headers for 'OpenEXR' Image I/O Provides the 'OpenEXR' static library and 'C++' headers \n    for high-dynamic-range image I/O  (see <https://openexr.com/>) \n    needed to link R packages against the 'OpenEXR' library, along \n    with a basic R interface to load 'EXR' images.  "
  },
  {
    "id": 15181,
    "package_name": "librarian",
    "title": "Install, Update, Load Packages from CRAN, 'GitHub', and\n'Bioconductor' in One Step",
    "description": "Automatically install, update, and load 'CRAN', 'GitHub', and 'Bioconductor' \n    packages in a single function call. By accepting bare unquoted names for packages, \n    it's easy to add or remove packages from the list.",
    "version": "1.8.1",
    "maintainer": "Desi Quintans <science@desiquintans.com>",
    "author": "Desi Quintans [aut, cre]",
    "url": "https://github.com/DesiQuintans/librarian",
    "bug_reports": "https://github.com/DesiQuintans/librarian/issues",
    "repository": "https://cran.r-project.org/package=librarian",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "librarian Install, Update, Load Packages from CRAN, 'GitHub', and\n'Bioconductor' in One Step Automatically install, update, and load 'CRAN', 'GitHub', and 'Bioconductor' \n    packages in a single function call. By accepting bare unquoted names for packages, \n    it's easy to add or remove packages from the list.  "
  },
  {
    "id": 15182,
    "package_name": "librarysnapshot",
    "title": "Library Snapshot for Packages and Dependencies in Use by Current\nSession",
    "description": "Generate a local library copy with relevant packages. \n    All packages currently found within the search path - except base packages - \n    will be copied to the directory provided and can be used later on with the \n    .libPaths() function. ",
    "version": "0.1.2",
    "maintainer": "Peter Meissner <retep.meissner@gmail.com>",
    "author": "Peter Meissner [aut, cre]",
    "url": "https://github.com/petermeissner/librarysnapshot",
    "bug_reports": "https://github.com/petermeissner/librarysnapshot/issues",
    "repository": "https://cran.r-project.org/package=librarysnapshot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "librarysnapshot Library Snapshot for Packages and Dependencies in Use by Current\nSession Generate a local library copy with relevant packages. \n    All packages currently found within the search path - except base packages - \n    will be copied to the directory provided and can be used later on with the \n    .libPaths() function.   "
  },
  {
    "id": 15229,
    "package_name": "link",
    "title": "Hyperlink Automatic Detection",
    "description": "Automatic detection of hyperlinks for packages and calls in the text\n    of 'rmarkdown' or 'quarto' documents.",
    "version": "2024.4.0",
    "maintainer": "Romain Fran\u00e7ois <romain@tada.science>",
    "author": "Romain Fran\u00e7ois [aut, cre],\n  tada.science [cph, fnd]",
    "url": "https://link.tada.science/, https://github.com/tadascience/link",
    "bug_reports": "https://github.com/tadascience/link/issues",
    "repository": "https://cran.r-project.org/package=link",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "link Hyperlink Automatic Detection Automatic detection of hyperlinks for packages and calls in the text\n    of 'rmarkdown' or 'quarto' documents.  "
  },
  {
    "id": 15239,
    "package_name": "lipidmapsR",
    "title": "Lipid Maps Rest Service",
    "description": "Lipid Maps Rest service. Researchers can access the Lipid Maps Rest\n  service programmatically and conveniently integrate it into the current workflow\n  or packages.",
    "version": "1.0.4",
    "maintainer": "Mingzhuo Tian <tianmingzhuo@outlook.com>",
    "author": "Mingzhuo Tian [aut, cre],\n  Yaoxiang Li [ctb],\n  Amrita Cheema [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lipidmapsR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lipidmapsR Lipid Maps Rest Service Lipid Maps Rest service. Researchers can access the Lipid Maps Rest\n  service programmatically and conveniently integrate it into the current workflow\n  or packages.  "
  },
  {
    "id": 15258,
    "package_name": "literanger",
    "title": "Fast Serializable Random Forests Based on 'ranger'",
    "description": "An updated implementation of R package 'ranger' by Wright et al,\n    (2017) <doi:10.18637/jss.v077.i01> for training and predicting from random\n    forests, particularly suited to high-dimensional data, and for embedding in\n    'Multiple Imputation by Chained Equations' (MICE) by van Buuren (2007)\n    <doi:10.1177/0962280206074463>. Ensembles of classification and regression\n    trees are currently supported. Sparse data of class 'dgCMatrix' (R package\n    'Matrix') can be directly analyzed. Conventional bagged predictions are\n    available alongside an efficient prediction for MICE via the algorithm\n    proposed by Doove et al (2014) <doi:10.1016/j.csda.2013.10.025>. Trained\n    forests can be written to and read from storage. Survival and probability\n    forests are not supported in the update, nor is data of class 'gwaa.data'\n    (R package 'GenABEL'); use the original 'ranger' package for these analyses.",
    "version": "0.2.0",
    "maintainer": "Stephen Wade <stephematician@gmail.com>",
    "author": "Stephen Wade [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2573-9683>),\n  Marvin N Wright [ctb]",
    "url": "https://gitlab.com/stephematician/literanger",
    "bug_reports": "https://gitlab.com/stephematician/literanger/-/issues",
    "repository": "https://cran.r-project.org/package=literanger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "literanger Fast Serializable Random Forests Based on 'ranger' An updated implementation of R package 'ranger' by Wright et al,\n    (2017) <doi:10.18637/jss.v077.i01> for training and predicting from random\n    forests, particularly suited to high-dimensional data, and for embedding in\n    'Multiple Imputation by Chained Equations' (MICE) by van Buuren (2007)\n    <doi:10.1177/0962280206074463>. Ensembles of classification and regression\n    trees are currently supported. Sparse data of class 'dgCMatrix' (R package\n    'Matrix') can be directly analyzed. Conventional bagged predictions are\n    available alongside an efficient prediction for MICE via the algorithm\n    proposed by Doove et al (2014) <doi:10.1016/j.csda.2013.10.025>. Trained\n    forests can be written to and read from storage. Survival and probability\n    forests are not supported in the update, nor is data of class 'gwaa.data'\n    (R package 'GenABEL'); use the original 'ranger' package for these analyses.  "
  },
  {
    "id": 15296,
    "package_name": "lmomPi",
    "title": "(Precipitation) Frequency Analysis and Variability with\nL-Moments from 'lmom'",
    "description": "It is an extension of 'lmom' R package: 'pel...()','cdf...()',qua...()' function\n    families are lumped and called from one function per each family respectively in order to\n    create robust automatic tools to fit data  with different probability\n    distributions and then to estimate probability values and return periods.  The implemented functions are able to manage time series with constant and/or missing values without stopping\n    the execution with error messages. The package also contains tools to  calculate several  indices based on variability (e.g. 'SPI' , Standardized\n    Precipitation Index, see <https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi> and <http://spei.csic.es/>) for multiple time series or spatially gridded values. ",
    "version": "0.6.7",
    "maintainer": "Emanuele Cordano <emanuele.cordano@gmail.com>",
    "author": "Emanuele Cordano [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3508-5898>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lmomPi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lmomPi (Precipitation) Frequency Analysis and Variability with\nL-Moments from 'lmom' It is an extension of 'lmom' R package: 'pel...()','cdf...()',qua...()' function\n    families are lumped and called from one function per each family respectively in order to\n    create robust automatic tools to fit data  with different probability\n    distributions and then to estimate probability values and return periods.  The implemented functions are able to manage time series with constant and/or missing values without stopping\n    the execution with error messages. The package also contains tools to  calculate several  indices based on variability (e.g. 'SPI' , Standardized\n    Precipitation Index, see <https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi> and <http://spei.csic.es/>) for multiple time series or spatially gridded values.   "
  },
  {
    "id": 15321,
    "package_name": "localsolver",
    "title": "R API to LocalSolver",
    "description": "The package converts R data onto input and data for LocalSolver,\n    executes optimization and exposes optimization results as R data.\n    LocalSolver (http://www.localsolver.com/) is an optimization engine\n    developed by Innovation24 (http://www.innovation24.fr/). It is designed to\n    solve large-scale mixed-variable non-convex optimization problems.  The\n    localsolver package is developed and maintained by WLOG Solutions\n    (http://www.wlogsolutions.com/en/) in collaboration with Decision Support\n    and Analysis Division at Warsaw School of Economics\n    (http://www.sgh.waw.pl/en/).",
    "version": "2.3",
    "maintainer": "Walerian Sokolowski <walerian.sokolowski@wlogsolutions.com>",
    "author": "Walerian Sokolowski [aut, cre, cph],\n  Wit Jakuczun [aut, cph],\n  Natalia Okinczyc [aut],\n  Bogumil Kaminski [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=localsolver",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "localsolver R API to LocalSolver The package converts R data onto input and data for LocalSolver,\n    executes optimization and exposes optimization results as R data.\n    LocalSolver (http://www.localsolver.com/) is an optimization engine\n    developed by Innovation24 (http://www.innovation24.fr/). It is designed to\n    solve large-scale mixed-variable non-convex optimization problems.  The\n    localsolver package is developed and maintained by WLOG Solutions\n    (http://www.wlogsolutions.com/en/) in collaboration with Decision Support\n    and Analysis Division at Warsaw School of Economics\n    (http://www.sgh.waw.pl/en/).  "
  },
  {
    "id": 15345,
    "package_name": "logger",
    "title": "A Lightweight, Modern and Flexible Logging Utility",
    "description": "Inspired by the the 'futile.logger' R package and 'logging'\n    Python module, this utility provides a flexible and extensible way of\n    formatting and delivering log messages with low overhead.",
    "version": "0.4.1",
    "maintainer": "Gergely Dar\u00f3czi <daroczig@rapporter.net>",
    "author": "Gergely Dar\u00f3czi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3149-8537>),\n  Hadley Wickham [aut] (ORCID: <https://orcid.org/0000-0003-4757-117X>),\n  Spare Cores [fnd],\n  System1 [fnd]",
    "url": "https://daroczig.github.io/logger/",
    "bug_reports": "https://github.com/daroczig/logger/issues",
    "repository": "https://cran.r-project.org/package=logger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "logger A Lightweight, Modern and Flexible Logging Utility Inspired by the the 'futile.logger' R package and 'logging'\n    Python module, this utility provides a flexible and extensible way of\n    formatting and delivering log messages with low overhead.  "
  },
  {
    "id": 15379,
    "package_name": "longit",
    "title": "High Dimensional Longitudinal Data Analysis Using MCMC",
    "description": "High dimensional longitudinal data analysis with Markov Chain Monte Carlo(MCMC). \n             Currently support mixed effect regression with or without missing observations by considering \n             covariance structures. It provides estimates by missing at random and missing not at random assumptions.\n             In this R package, we present Bayesian approaches that statisticians and clinical \n             researchers can easily use. The functions' methodology is based on the book \"Bayesian Approaches in Oncology Using R and OpenBUGS\" by \n             Bhattacharjee A (2020) <doi:10.1201/9780429329449-14>.",
    "version": "0.1.0",
    "maintainer": "Atanu Bhattacharjee <atanustat@gmail.com>",
    "author": "Atanu Bhattacharjee [aut, cre, ctb],\n  Akash Pawar [aut, ctb],\n  Bhrigu Kumar Rajbongshi [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=longit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "longit High Dimensional Longitudinal Data Analysis Using MCMC High dimensional longitudinal data analysis with Markov Chain Monte Carlo(MCMC). \n             Currently support mixed effect regression with or without missing observations by considering \n             covariance structures. It provides estimates by missing at random and missing not at random assumptions.\n             In this R package, we present Bayesian approaches that statisticians and clinical \n             researchers can easily use. The functions' methodology is based on the book \"Bayesian Approaches in Oncology Using R and OpenBUGS\" by \n             Bhattacharjee A (2020) <doi:10.1201/9780429329449-14>.  "
  },
  {
    "id": 15439,
    "package_name": "lsoda",
    "title": "'C++' Header Library for Ordinary Differential Equations",
    "description": "A 'C++' header library for using the 'libsoda-cxx' library with R. The 'C++' header reimplements the 'lsoda' function from the 'ODEPACK' library for solving initial value problems for first order ordinary differential equations (Hindmarsh, 1982; <https://computing.llnl.gov/sites/default/files/ODEPACK_pub1_u88007.pdf>). The 'C++' header can be used by other R packages by linking against this package. The 'C++' functions can be called inline using 'Rcpp'. Finally, the package provides an 'ode' function to call from R.",
    "version": "1.2",
    "maintainer": "Mark Clements <mark.clements@ki.se>",
    "author": "Mark Clements [aut, cre],\n  Dilawar Singh [ctb],\n  Heng Li [ctb],\n  Peter N. Brown [ctb],\n  George D. Byrne [ctb],\n  Alan C. Hindmarsh [ctb],\n  Cleve Moler [ctb],\n  Linda R. Petzold [ctb]",
    "url": "https://github.com/mclements/lsoda",
    "bug_reports": "https://github.com/mclements/lsoda/issues",
    "repository": "https://cran.r-project.org/package=lsoda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lsoda 'C++' Header Library for Ordinary Differential Equations A 'C++' header library for using the 'libsoda-cxx' library with R. The 'C++' header reimplements the 'lsoda' function from the 'ODEPACK' library for solving initial value problems for first order ordinary differential equations (Hindmarsh, 1982; <https://computing.llnl.gov/sites/default/files/ODEPACK_pub1_u88007.pdf>). The 'C++' header can be used by other R packages by linking against this package. The 'C++' functions can be called inline using 'Rcpp'. Finally, the package provides an 'ode' function to call from R.  "
  },
  {
    "id": 15459,
    "package_name": "lucid",
    "title": "Printing Floating Point Numbers in a Human-Friendly Format",
    "description": "Print vectors (and data frames) of floating point numbers\n    using a non-scientific format optimized for human readers.  Vectors of\n    numbers are rounded using significant digits, aligned at the decimal\n    point, and all zeros trailing the decimal point are dropped.  See:\n    Wright (2016). Lucid: An R Package for Pretty-Printing Floating Point\n    Numbers. In JSM Proceedings, Statistical Computing Section.\n    Alexandria, VA: American Statistical Association. 2270-2279.",
    "version": "1.9",
    "maintainer": "Kevin Wright <kw.stat@gmail.com>",
    "author": "Kevin Wright [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0617-8673>)",
    "url": "https://kwstat.github.io/lucid/, http://kwstat.github.io/lucid/",
    "bug_reports": "https://github.com/kwstat/lucid/issues",
    "repository": "https://cran.r-project.org/package=lucid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lucid Printing Floating Point Numbers in a Human-Friendly Format Print vectors (and data frames) of floating point numbers\n    using a non-scientific format optimized for human readers.  Vectors of\n    numbers are rounded using significant digits, aligned at the decimal\n    point, and all zeros trailing the decimal point are dropped.  See:\n    Wright (2016). Lucid: An R Package for Pretty-Printing Floating Point\n    Numbers. In JSM Proceedings, Statistical Computing Section.\n    Alexandria, VA: American Statistical Association. 2270-2279.  "
  },
  {
    "id": 15487,
    "package_name": "mFilter",
    "title": "Miscellaneous Time Series Filters",
    "description": "The mFilter package implements several time series filters useful\n        for smoothing and extracting trend and cyclical components of a\n        time series. The routines are commonly used in economics and\n        finance, however they should also be interest to other areas.\n        Currently, Christiano-Fitzgerald, Baxter-King,\n        Hodrick-Prescott, Butterworth, and trigonometric regression\n        filters are included in the package.",
    "version": "0.1-5",
    "maintainer": "Mehmet Balcilar <mehmet@mbalcilar.net>",
    "author": "Mehmet Balcilar <mehmet@mbalcilar.net>",
    "url": "http://www.mbalcilar.net",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mFilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mFilter Miscellaneous Time Series Filters The mFilter package implements several time series filters useful\n        for smoothing and extracting trend and cyclical components of a\n        time series. The routines are commonly used in economics and\n        finance, however they should also be interest to other areas.\n        Currently, Christiano-Fitzgerald, Baxter-King,\n        Hodrick-Prescott, Butterworth, and trigonometric regression\n        filters are included in the package.  "
  },
  {
    "id": 15492,
    "package_name": "mMARCH.AC",
    "title": "Processing of Accelerometry Data with 'GGIR' in mMARCH",
    "description": "Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.",
    "version": "3.2.0.1",
    "maintainer": "Wei Guo <wei.guo3@nih.gov>",
    "author": "Wei Guo [aut, cre],\n  Andrew Leroux [aut],\n  Vadim Zipunnikov [aut],\n  Kathleen Merikangas [aut]",
    "url": "https://github.com/WeiGuoNIMH/mMARCH.AC",
    "bug_reports": "https://github.com/WeiGuoNIMH/mMARCH.AC/issues",
    "repository": "https://cran.r-project.org/package=mMARCH.AC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mMARCH.AC Processing of Accelerometry Data with 'GGIR' in mMARCH Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.  "
  },
  {
    "id": 15545,
    "package_name": "maketools",
    "title": "Exploring and Testing the Toolchain and System Libraries",
    "description": "Helper functions that interface with the system utilities to learn \n    about the local build environment. Lets you explore 'make' rules to test the\n    local configuration, or query 'pkg-config' to find compiler flags and libs \n    needed for building packages with external dependencies. Also contains tools\n    to analyze which libraries that a installed R package linked to by inspecting\n    output from 'ldd' in combination with information from your distribution \n    package manager, e.g. 'rpm' or 'dpkg'.",
    "version": "1.3.2",
    "maintainer": "Jeroen Ooms <jeroenooms@gmail.com>",
    "author": "Jeroen Ooms [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4035-0289>)",
    "url": "https://jeroen.r-universe.dev/maketools",
    "bug_reports": "https://github.com/jeroen/maketools/issues",
    "repository": "https://cran.r-project.org/package=maketools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "maketools Exploring and Testing the Toolchain and System Libraries Helper functions that interface with the system utilities to learn \n    about the local build environment. Lets you explore 'make' rules to test the\n    local configuration, or query 'pkg-config' to find compiler flags and libs \n    needed for building packages with external dependencies. Also contains tools\n    to analyze which libraries that a installed R package linked to by inspecting\n    output from 'ldd' in combination with information from your distribution \n    package manager, e.g. 'rpm' or 'dpkg'.  "
  },
  {
    "id": 15554,
    "package_name": "mallet",
    "title": "An R Wrapper for the Java Mallet Topic Modeling Toolkit",
    "description": "\n  An R interface for the Java Machine Learning for Language Toolkit (mallet)\n  <http://mallet.cs.umass.edu/> to estimate probabilistic topic models, such\n  as Latent Dirichlet Allocation. We can use the R package to read textual \n  data into mallet from R objects, run the Java implementation of mallet \n  directly in R, and extract results as R objects. The Mallet toolkit \n  has many functions, this wrapper focuses on the topic modeling sub-package \n  written by David Mimno. The package uses the rJava package to connect to a \n  JVM.",
    "version": "1.3.0",
    "maintainer": "M\u00e5ns Magnusson <mons.magnusson@gmail.com>",
    "author": "M\u00e5ns Magnusson [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0296-2719>),\n  David Mimno [aut, cph] (ORCID: <https://orcid.org/0000-0001-7510-9404>)",
    "url": "https://github.com/mimno/RMallet",
    "bug_reports": "https://github.com/mimno/RMallet/issues",
    "repository": "https://cran.r-project.org/package=mallet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mallet An R Wrapper for the Java Mallet Topic Modeling Toolkit \n  An R interface for the Java Machine Learning for Language Toolkit (mallet)\n  <http://mallet.cs.umass.edu/> to estimate probabilistic topic models, such\n  as Latent Dirichlet Allocation. We can use the R package to read textual \n  data into mallet from R objects, run the Java implementation of mallet \n  directly in R, and extract results as R objects. The Mallet toolkit \n  has many functions, this wrapper focuses on the topic modeling sub-package \n  written by David Mimno. The package uses the rJava package to connect to a \n  JVM.  "
  },
  {
    "id": 15596,
    "package_name": "mappestRisk",
    "title": "Create Maps Forecasting Risk of Pest Occurrence",
    "description": "There are three different modules: (1) model fitting and selection \n    using a set of the most commonly used equations describing developmental \n    responses to temperature helped by already existing R packages ('rTPC') \n    and nonlinear regression model functions from 'nls.multstart' \n    (Padfield et al. 2021, <doi:10.1111/2041-210X.13585>), with visualization \n    of model predictions to guide ecological criteria for model selection; \n    (2) calculation of suitability thermal limits, which consist on a \n    temperature interval delimiting the optimal performance zone or suitability; \n    and (3) climatic data extraction and visualization inspired on previous \n    research (Taylor et al. 2019, <doi:10.1111/1365-2664.13455>), with either \n    exportable rasters, static map images or html, interactive maps.",
    "version": "0.1.2",
    "maintainer": "Dar\u00edo San-Segundo Molina <dario.ssm2@gmail.com>",
    "author": "Dar\u00edo San-Segundo Molina [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7831-9623>),\n  A. M\u00e1rcia Barbosa [aut, cph] (ORCID:\n    <https://orcid.org/0000-0001-8972-7713>),\n  Antonio Jes\u00fas P\u00e9rez-Luque [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-1747-0469>),\n  Francisco Rodr\u00edguez-S\u00e1nchez [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7981-1599>)",
    "url": "https://github.com/EcologyR/mappestRisk,\nhttps://ecologyr.github.io/mappestRisk/",
    "bug_reports": "https://github.com/EcologyR/mappestRisk/issues",
    "repository": "https://cran.r-project.org/package=mappestRisk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mappestRisk Create Maps Forecasting Risk of Pest Occurrence There are three different modules: (1) model fitting and selection \n    using a set of the most commonly used equations describing developmental \n    responses to temperature helped by already existing R packages ('rTPC') \n    and nonlinear regression model functions from 'nls.multstart' \n    (Padfield et al. 2021, <doi:10.1111/2041-210X.13585>), with visualization \n    of model predictions to guide ecological criteria for model selection; \n    (2) calculation of suitability thermal limits, which consist on a \n    temperature interval delimiting the optimal performance zone or suitability; \n    and (3) climatic data extraction and visualization inspired on previous \n    research (Taylor et al. 2019, <doi:10.1111/1365-2664.13455>), with either \n    exportable rasters, static map images or html, interactive maps.  "
  },
  {
    "id": 15628,
    "package_name": "markmyassignment",
    "title": "Automatic Marking of R Assignments",
    "description": "Automatic marking of R assignments for students and teachers based\n    on 'testthat' test suites.",
    "version": "0.8.9",
    "maintainer": "Mans Magnusson <mons.magnusson@gmail.com>",
    "author": "Mans Magnusson [aut, cre],\n  Oscar Pettersson [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=markmyassignment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "markmyassignment Automatic Marking of R Assignments Automatic marking of R assignments for students and teachers based\n    on 'testthat' test suites.  "
  },
  {
    "id": 15662,
    "package_name": "mathml",
    "title": "Translate R Expressions to 'MathML' and 'LaTeX'/'MathJax'",
    "description": "Translate R expressions to 'MathML' or 'MathJax'/'LaTeX' so that\n    they can be rendered in R markdown documents and shiny apps. This package\n    depends on R package 'rolog', which requires an installation of the\n    'SWI'-'Prolog' runtime either from 'swi-prolog.org' or from R\n    package 'rswipl'.",
    "version": "1.6",
    "maintainer": "Matthias Gondan <Matthias.Gondan-Rochon@uibk.ac.at>",
    "author": "Matthias Gondan [aut, cre, cph] (University of Innsbruck),\n  Irene Alfarone [aut] (University of Innsbruck),\n  European Commission [fnd] (Erasmus+ Programme,\n    2019-1-EE01-KA203-051708)",
    "url": "https://github.com/mgondan/mathml",
    "bug_reports": "https://github.com/mgondan/mathml/issues",
    "repository": "https://cran.r-project.org/package=mathml",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mathml Translate R Expressions to 'MathML' and 'LaTeX'/'MathJax' Translate R expressions to 'MathML' or 'MathJax'/'LaTeX' so that\n    they can be rendered in R markdown documents and shiny apps. This package\n    depends on R package 'rolog', which requires an installation of the\n    'SWI'-'Prolog' runtime either from 'swi-prolog.org' or from R\n    package 'rswipl'.  "
  },
  {
    "id": 15726,
    "package_name": "mc.heterogeneity",
    "title": "A Monte Carlo Based Heterogeneity Test for Meta-Analysis",
    "description": "Implements a Monte Carlo Based Heterogeneity Test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (OR) in Meta-Analysis Studies. Depending on the presence of moderators, this Monte Carlo Based Test can be implemented in the random or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihood, so installation of R package 'metafor' is required. This approach refers to the studies of Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009).",
    "version": "0.1.2",
    "maintainer": "Ge Jiang <gejiang2@illinois.edu>",
    "author": "Han Du [aut],\n  Ge Jiang [aut, cre],\n  Zijun Ke [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mc.heterogeneity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mc.heterogeneity A Monte Carlo Based Heterogeneity Test for Meta-Analysis Implements a Monte Carlo Based Heterogeneity Test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (OR) in Meta-Analysis Studies. Depending on the presence of moderators, this Monte Carlo Based Test can be implemented in the random or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihood, so installation of R package 'metafor' is required. This approach refers to the studies of Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009).  "
  },
  {
    "id": 15775,
    "package_name": "mcunit",
    "title": "Unit Tests for MC Methods",
    "description": "Unit testing for Monte Carlo methods, particularly Markov Chain Monte Carlo (MCMC) methods, are implemented as extensions of the 'testthat' package. The MCMC methods check whether the MCMC chain has the correct invariant distribution. They do not check other properties of successful samplers such as whether the chain can reach all points, i.e. whether is recurrent. The tests require the ability to sample from the prior and to run steps of the MCMC chain. The methodology is described in Gandy and Scott (2020) <arXiv:2001.06465>.",
    "version": "0.3.2",
    "maintainer": "Axel Gandy <a.gandy@imperial.ac.uk>",
    "author": "Axel Gandy [aut, cre],\n  James Scott [aut]",
    "url": "https://bitbucket.org/agandy/mcunit/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mcunit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcunit Unit Tests for MC Methods Unit testing for Monte Carlo methods, particularly Markov Chain Monte Carlo (MCMC) methods, are implemented as extensions of the 'testthat' package. The MCMC methods check whether the MCMC chain has the correct invariant distribution. They do not check other properties of successful samplers such as whether the chain can reach all points, i.e. whether is recurrent. The tests require the ability to sample from the prior and to run steps of the MCMC chain. The methodology is described in Gandy and Scott (2020) <arXiv:2001.06465>.  "
  },
  {
    "id": 15824,
    "package_name": "medicaldata",
    "title": "Data Package for Medical Datasets",
    "description": "Provides access to well-documented medical datasets for teaching.\n    Featuring several from the Teaching of Statistics in the Health Sciences \n    website <https://www.causeweb.org/tshs/category/dataset/>, a few reconstructed datasets of historical significance in medical\n    research, some reformatted and extended from existing R packages, \n    and some data donations. ",
    "version": "0.2.0",
    "maintainer": "Peter Higgins <higgi13425@yahoo.com>",
    "author": "Peter Higgins [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7111-0077>)",
    "url": "https://higgi13425.github.io/medicaldata/,\nhttps://github.com/higgi13425/medicaldata/",
    "bug_reports": "https://github.com/higgi13425/medicaldata/issues",
    "repository": "https://cran.r-project.org/package=medicaldata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "medicaldata Data Package for Medical Datasets Provides access to well-documented medical datasets for teaching.\n    Featuring several from the Teaching of Statistics in the Health Sciences \n    website <https://www.causeweb.org/tshs/category/dataset/>, a few reconstructed datasets of historical significance in medical\n    research, some reformatted and extended from existing R packages, \n    and some data donations.   "
  },
  {
    "id": 15835,
    "package_name": "memapp",
    "title": "The Moving Epidemic Method Web Application",
    "description": "The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.",
    "version": "2.16",
    "maintainer": "Jose E. Lozano <lozalojo@gmail.com>",
    "author": "Jose E. Lozano [aut, cre]",
    "url": "https://github.com/lozalojo/memapp",
    "bug_reports": "https://github.com/lozalojo/memapp/issues",
    "repository": "https://cran.r-project.org/package=memapp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "memapp The Moving Epidemic Method Web Application The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.  "
  },
  {
    "id": 15859,
    "package_name": "messy",
    "title": "Create Messy Data from Clean Data Frames",
    "description": "For the purposes of teaching, it is often desirable to show \n    examples of working with messy data and how to clean it. This R package \n    creates messy data from clean, tidy data frames so that students have a \n    clean example to work towards.",
    "version": "0.1.0",
    "maintainer": "Nicola Rennie <nrennie35@gmail.com>",
    "author": "Nicola Rennie [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4797-557X>)",
    "url": "https://nrennie.rbind.io/messy/, https://github.com/nrennie/messy",
    "bug_reports": "https://github.com/nrennie/messy/issues",
    "repository": "https://cran.r-project.org/package=messy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "messy Create Messy Data from Clean Data Frames For the purposes of teaching, it is often desirable to show \n    examples of working with messy data and how to clean it. This R package \n    creates messy data from clean, tidy data frames so that students have a \n    clean example to work towards.  "
  },
  {
    "id": 15866,
    "package_name": "meta4diag",
    "title": "Meta-Analysis for Diagnostic Test Studies",
    "description": "Bayesian inference analysis for bivariate meta-analysis of diagnostic test studies using integrated nested Laplace approximation with INLA. A purpose built graphic user interface is available. The installation of R package INLA is compulsory for successful usage. The INLA package can be obtained from <https://www.r-inla.org>. We recommend the testing version, which can be downloaded by running: install.packages(\"INLA\", repos=c(getOption(\"repos\"), INLA=\"https://inla.r-inla-download.org/R/testing\"), dep=TRUE).",
    "version": "2.1.1",
    "maintainer": "Jingyi Guo <jingyi.guo@ntnu.no>",
    "author": "Jingyi Guo <jingyi.guo@ntnu.no> and Andrea Riebler <andrea.riebler@ntnu.no>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=meta4diag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "meta4diag Meta-Analysis for Diagnostic Test Studies Bayesian inference analysis for bivariate meta-analysis of diagnostic test studies using integrated nested Laplace approximation with INLA. A purpose built graphic user interface is available. The installation of R package INLA is compulsory for successful usage. The INLA package can be obtained from <https://www.r-inla.org>. We recommend the testing version, which can be downloaded by running: install.packages(\"INLA\", repos=c(getOption(\"repos\"), INLA=\"https://inla.r-inla-download.org/R/testing\"), dep=TRUE).  "
  },
  {
    "id": 15892,
    "package_name": "metacore",
    "title": "A Centralized Metadata Object Focus on Clinical Trial Data\nProgramming Workflows",
    "description": "Create an immutable container holding metadata for the\n    purpose of better enabling programming activities and functionality of\n    other packages within the clinical programming workflow.",
    "version": "0.2.1",
    "maintainer": "Liam Hobby <liam.f.hobby@gsk.com>",
    "author": "Liam Hobby [aut, cre],\n  Christina Fillmore [aut] (ORCID:\n    <https://orcid.org/0000-0003-0595-2302>),\n  Bill Denney [aut],\n  Maya Gans [aut] (ORCID: <https://orcid.org/0000-0002-5452-6089>),\n  Ashley Tarasiewicz [aut],\n  Mike Stackhouse [aut] (ORCID: <https://orcid.org/0000-0001-6030-723X>),\n  Tamara Senior [aut],\n  GSK/Atorus JPT [cph, fnd]",
    "url": "https://atorus-research.github.io/metacore/,\nhttps://github.com/atorus-research/metacore",
    "bug_reports": "https://github.com/atorus-research/metacore/issues",
    "repository": "https://cran.r-project.org/package=metacore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metacore A Centralized Metadata Object Focus on Clinical Trial Data\nProgramming Workflows Create an immutable container holding metadata for the\n    purpose of better enabling programming activities and functionality of\n    other packages within the clinical programming workflow.  "
  },
  {
    "id": 15902,
    "package_name": "metagear",
    "title": "Comprehensive Research Synthesis Tools for Systematic Reviews\nand Meta-Analysis",
    "description": "Functionalities for facilitating systematic reviews, data\n    extractions, and meta-analyses. It includes a GUI (graphical user interface)\n    to help screen the abstracts and titles of bibliographic data; tools to assign\n    screening effort across multiple collaborators/reviewers and to assess inter-\n    reviewer reliability; tools to help automate the download and retrieval of\n    journal PDF articles from online databases; figure and image extractions \n    from PDFs; web scraping of citations; automated and manual data extraction \n    from scatter-plot and bar-plot images; PRISMA (Preferred Reporting Items for\n    Systematic Reviews and Meta-Analyses) flow diagrams; simple imputation tools\n    to fill gaps in incomplete or missing study parameters; generation of random\n    effects sizes for Hedges' d, log response ratio, odds ratio, and correlation\n    coefficients for Monte Carlo experiments; covariance equations for modelling\n    dependencies among multiple effect sizes (e.g., effect sizes with a common\n    control); and finally summaries that replicate analyses and outputs from \n    widely used but no longer updated meta-analysis software (i.e., metawin).\n\tFunding for this package was supported by National Science Foundation (NSF) \n\tgrants DBI-1262545 and DEB-1451031. CITE: Lajeunesse, M.J. (2016) \n\tFacilitating systematic reviews, data extraction and meta-analysis with the \n\tmetagear package for R. Methods in Ecology and Evolution 7, 323-330 \n\t<doi:10.1111/2041-210X.12472>.",
    "version": "0.7",
    "maintainer": "Marc J. Lajeunesse <lajeunesse@usf.edu>",
    "author": "Marc J. Lajeunesse [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9678-2080>)",
    "url": "http://lajeunesse.myweb.usf.edu/ https://github.com/mjlajeunesse/\nhttps://www.youtube.com/c/LajeunesseLab/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=metagear",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metagear Comprehensive Research Synthesis Tools for Systematic Reviews\nand Meta-Analysis Functionalities for facilitating systematic reviews, data\n    extractions, and meta-analyses. It includes a GUI (graphical user interface)\n    to help screen the abstracts and titles of bibliographic data; tools to assign\n    screening effort across multiple collaborators/reviewers and to assess inter-\n    reviewer reliability; tools to help automate the download and retrieval of\n    journal PDF articles from online databases; figure and image extractions \n    from PDFs; web scraping of citations; automated and manual data extraction \n    from scatter-plot and bar-plot images; PRISMA (Preferred Reporting Items for\n    Systematic Reviews and Meta-Analyses) flow diagrams; simple imputation tools\n    to fill gaps in incomplete or missing study parameters; generation of random\n    effects sizes for Hedges' d, log response ratio, odds ratio, and correlation\n    coefficients for Monte Carlo experiments; covariance equations for modelling\n    dependencies among multiple effect sizes (e.g., effect sizes with a common\n    control); and finally summaries that replicate analyses and outputs from \n    widely used but no longer updated meta-analysis software (i.e., metawin).\n\tFunding for this package was supported by National Science Foundation (NSF) \n\tgrants DBI-1262545 and DEB-1451031. CITE: Lajeunesse, M.J. (2016) \n\tFacilitating systematic reviews, data extraction and meta-analysis with the \n\tmetagear package for R. Methods in Ecology and Evolution 7, 323-330 \n\t<doi:10.1111/2041-210X.12472>.  "
  },
  {
    "id": 15926,
    "package_name": "metapro",
    "title": "Robust P-Value Combination Methods",
    "description": "The meta-analysis is performed to increase the statistical power by integrating the results from several experiments. The p-values are often combined in meta-analysis when the effect sizes are not available. The 'metapro' R package provides not only traditional methods (Becker BJ (1994, ISBN:0-87154-226-9), Mosteller, F. & Bush, R.R. (1954, ISBN:0201048523) and Lancaster HO (1949, ISSN:00063444)), but also new method named weighted Fisher\u2019s method we developed. While the (weighted) Z-method is suitable for finding features effective in most experiments, (weighted) Fisher\u2019s method is useful for detecting partially associated features. Thus, the users can choose the function based on their purpose. Yoon et al. (2021) \"Powerful p-value combination methods to detect incomplete association\" <doi:10.1038/s41598-021-86465-y>.",
    "version": "1.5.11",
    "maintainer": "Sora Yoon <ysora90@gmail.com>",
    "author": "Sora Yoon <ysora90@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=metapro",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metapro Robust P-Value Combination Methods The meta-analysis is performed to increase the statistical power by integrating the results from several experiments. The p-values are often combined in meta-analysis when the effect sizes are not available. The 'metapro' R package provides not only traditional methods (Becker BJ (1994, ISBN:0-87154-226-9), Mosteller, F. & Bush, R.R. (1954, ISBN:0201048523) and Lancaster HO (1949, ISSN:00063444)), but also new method named weighted Fisher\u2019s method we developed. While the (weighted) Z-method is suitable for finding features effective in most experiments, (weighted) Fisher\u2019s method is useful for detecting partially associated features. Thus, the users can choose the function based on their purpose. Yoon et al. (2021) \"Powerful p-value combination methods to detect incomplete association\" <doi:10.1038/s41598-021-86465-y>.  "
  },
  {
    "id": 15989,
    "package_name": "miLAG",
    "title": "Calculates Microbial Lag Duration (on the Population Level) from\nProvided Growth Curve Data",
    "description": "Microbial growth is often measured by growth curves i.e. a table of population sizes and times of measurements. \n  This package allows to use such growth curve data to determine the duration of \"microbial lag phase\" i.e. the time needed for microbes to restart divisions.\n  It implements the most commonly used methods to calculate the lag duration, these methods are discussed and described in Opalek et.al. 2022.\n  Citation: Smug, B. J., Opalek, M., Necki, M., & Wloch-Salamon, D. (2024). Microbial lag calculator: A shiny-based application and an R package for calculating the duration of microbial lag phase. Methods in Ecology and Evolution, 15, 301\u2013307 <doi:10.1111/2041-210X.14269>. ",
    "version": "1.0.5",
    "maintainer": "Bogna Smug <bogna.smug@uj.edu.pl>",
    "author": "Bogna Smug [aut, cre] (ORCID: <https://orcid.org/0000-0001-9364-163X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=miLAG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "miLAG Calculates Microbial Lag Duration (on the Population Level) from\nProvided Growth Curve Data Microbial growth is often measured by growth curves i.e. a table of population sizes and times of measurements. \n  This package allows to use such growth curve data to determine the duration of \"microbial lag phase\" i.e. the time needed for microbes to restart divisions.\n  It implements the most commonly used methods to calculate the lag duration, these methods are discussed and described in Opalek et.al. 2022.\n  Citation: Smug, B. J., Opalek, M., Necki, M., & Wloch-Salamon, D. (2024). Microbial lag calculator: A shiny-based application and an R package for calculating the duration of microbial lag phase. Methods in Ecology and Evolution, 15, 301\u2013307 <doi:10.1111/2041-210X.14269>.   "
  },
  {
    "id": 16003,
    "package_name": "miceFast",
    "title": "Fast Imputations Using 'Rcpp' and 'Armadillo'",
    "description": "\n  Fast imputations under the object-oriented programming paradigm. \t\n  Moreover there are offered a few functions built to work with popular R packages such as 'data.table' or 'dplyr'.\n  The biggest improvement in time performance could be achieve for a calculation where a grouping variable have to be used.\n  A single evaluation of a quantitative model for the multiple imputations is another major enhancement.\n  A new major improvement is one of the fastest predictive mean matching in the R world because of presorting and binary search.",
    "version": "0.8.5",
    "maintainer": "Maciej Nasinski <nasinski.maciej@gmail.com>",
    "author": "Maciej Nasinski [aut, cre]",
    "url": "https://github.com/Polkas/miceFast",
    "bug_reports": "https://github.com/Polkas/miceFast/issues",
    "repository": "https://cran.r-project.org/package=miceFast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "miceFast Fast Imputations Using 'Rcpp' and 'Armadillo' \n  Fast imputations under the object-oriented programming paradigm. \t\n  Moreover there are offered a few functions built to work with popular R packages such as 'data.table' or 'dplyr'.\n  The biggest improvement in time performance could be achieve for a calculation where a grouping variable have to be used.\n  A single evaluation of a quantitative model for the multiple imputations is another major enhancement.\n  A new major improvement is one of the fastest predictive mean matching in the R world because of presorting and binary search.  "
  },
  {
    "id": 16014,
    "package_name": "microbats",
    "title": "An Implementation of Bat Algorithm in R",
    "description": "A nature-inspired metaheuristic algorithm based on the echolocation behavior of microbats that uses frequency tuning to optimize problems in both continuous and discrete dimensions. This R package makes it easy to implement the standard bat algorithm on any user-supplied function. The algorithm was first developed by Xin-She Yang in 2010 (<DOI:10.1007/978-3-642-12538-6_6>, <DOI:10.1109/CINTI.2014.7028669>).",
    "version": "0.1-1",
    "maintainer": "Seong Hyun Hwang <krshh1412@gmail.com>",
    "author": "Seong Hyun Hwang with contributions from Rachel Myoung Moon",
    "url": "https://github.com/stathwang/microbats",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=microbats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "microbats An Implementation of Bat Algorithm in R A nature-inspired metaheuristic algorithm based on the echolocation behavior of microbats that uses frequency tuning to optimize problems in both continuous and discrete dimensions. This R package makes it easy to implement the standard bat algorithm on any user-supplied function. The algorithm was first developed by Xin-She Yang in 2010 (<DOI:10.1007/978-3-642-12538-6_6>, <DOI:10.1109/CINTI.2014.7028669>).  "
  },
  {
    "id": 16023,
    "package_name": "micromapST",
    "title": "Linked Micromap Plots for U. S. and Other Geographic Areas",
    "description": "Provides the users with the ability to quickly create linked \n     micromap plots for a collection of geographic areas. Linked micromap \n     plots are visualizations of geo-referenced data that link statistical \n     graphics to an organized series of small maps or graphic images. \n     The Help description contains examples of how to use the 'micromapST' \n     function. Contained in this package are border group datasets to \n     support creating linked micromap plots for the 50 U.S. states and \n     District of Columbia (51 areas), the U. S. 20 Seer Registries, the \n     105 counties in the state of Kansas, the 62 counties of New York, \n     the 24 counties of Maryland, the 29 counties of Utah, the 32 \n     administrative areas in China, the 218 administrative areas in \n     the UK and Ireland (for testing only), the 25 districts in the \n     city of Seoul South Korea, and the 52 counties on the Africa continent.\n     A border group dataset contains the boundaries related to the data \n     level areas, a second layer boundaries, a top or third layer boundary, \n     a parameter list of run options, and a cross indexing table between \n     area names, abbreviations, numeric identification and alias matching \n     strings for the specific geographic area.  By specifying a border group, \n     the package create linked micromap plots for any geographic region.  \n     The user can create and provide their own border group dataset for \n     any area beyond the areas contained within the package with the \n     'BuildBorderGroup' function. In April of 2022, it was announced that \n     'maptools', 'rgdal', and 'rgeos' R packages would be retired in \n     middle to end of 2023 and removed from the CRAN libraries.  \n     The 'BuildBorderGroup' function was dependent on these packages.  \n     'micromapST' functions were not impacted by the retired R packages.  \n     Upgrading of 'BuildBorderGroup' function was completed and released with \n     version 3.0.0 on August 10, 2023 using the 'sf' R package.\n     References: Carr and Pickle, Chapman and Hall/CRC, Visualizing\n     Data Patterns with Micromaps, CRC Press, 2010. Pickle, Pearson,\n     and Carr (2015), micromapST: Exploring and Communicating\n     Geospatial Patterns in US State Data., Journal of Statistical\n     Software, 63(3), 1-25., <https://www.jstatsoft.org/v63/i03/>.\n     Copyrighted 2013, 2014, 2015, 2016, 2022, 2023, 2024, and \n     2025 by Carr, Pearson and Pickle.",
    "version": "3.1.1",
    "maintainer": "Jim Pearson <jbpearson353@gmail.com>",
    "author": "Jim Pearson [aut, cre, cph],\n  Dan Carr [aut, cph],\n  Linda Pickle [ctb, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=micromapST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "micromapST Linked Micromap Plots for U. S. and Other Geographic Areas Provides the users with the ability to quickly create linked \n     micromap plots for a collection of geographic areas. Linked micromap \n     plots are visualizations of geo-referenced data that link statistical \n     graphics to an organized series of small maps or graphic images. \n     The Help description contains examples of how to use the 'micromapST' \n     function. Contained in this package are border group datasets to \n     support creating linked micromap plots for the 50 U.S. states and \n     District of Columbia (51 areas), the U. S. 20 Seer Registries, the \n     105 counties in the state of Kansas, the 62 counties of New York, \n     the 24 counties of Maryland, the 29 counties of Utah, the 32 \n     administrative areas in China, the 218 administrative areas in \n     the UK and Ireland (for testing only), the 25 districts in the \n     city of Seoul South Korea, and the 52 counties on the Africa continent.\n     A border group dataset contains the boundaries related to the data \n     level areas, a second layer boundaries, a top or third layer boundary, \n     a parameter list of run options, and a cross indexing table between \n     area names, abbreviations, numeric identification and alias matching \n     strings for the specific geographic area.  By specifying a border group, \n     the package create linked micromap plots for any geographic region.  \n     The user can create and provide their own border group dataset for \n     any area beyond the areas contained within the package with the \n     'BuildBorderGroup' function. In April of 2022, it was announced that \n     'maptools', 'rgdal', and 'rgeos' R packages would be retired in \n     middle to end of 2023 and removed from the CRAN libraries.  \n     The 'BuildBorderGroup' function was dependent on these packages.  \n     'micromapST' functions were not impacted by the retired R packages.  \n     Upgrading of 'BuildBorderGroup' function was completed and released with \n     version 3.0.0 on August 10, 2023 using the 'sf' R package.\n     References: Carr and Pickle, Chapman and Hall/CRC, Visualizing\n     Data Patterns with Micromaps, CRC Press, 2010. Pickle, Pearson,\n     and Carr (2015), micromapST: Exploring and Communicating\n     Geospatial Patterns in US State Data., Journal of Statistical\n     Software, 63(3), 1-25., <https://www.jstatsoft.org/v63/i03/>.\n     Copyrighted 2013, 2014, 2015, 2016, 2022, 2023, 2024, and \n     2025 by Carr, Pearson and Pickle.  "
  },
  {
    "id": 16029,
    "package_name": "microsimulation",
    "title": "Discrete Event Simulation in R and C++, with Tools for\nCost-Effectiveness Analysis",
    "description": "Discrete event simulation using both R and C++ (Karlsson et al 2016; <doi:10.1109/eScience.2016.7870915>). The C++ code is adapted from the SSIM library <https://www.inf.usi.ch/carzaniga/ssim/>, allowing for event-oriented simulation. The code includes a SummaryReport class for reporting events and costs by age and other covariates. The C++ code is available as a static library for linking to other packages. A priority queue implementation is given in C++ together with an S3 closure and a reference class implementation. Finally, some tools are provided for cost-effectiveness analysis.",
    "version": "1.4.5",
    "maintainer": "Mark Clements <mark.clements@ki.se>",
    "author": "Mark Clements [aut, cre, cph],\n  Alexandra Jauhiainen [aut],\n  Andreas Karlsson [aut],\n  Antonio Carzaniga [cph],\n  University of Colorado [cph],\n  Pierre L'Ecuyer [cph]",
    "url": "https://github.com/mclements/microsimulation",
    "bug_reports": "https://github.com/mclements/microsimulation/issues",
    "repository": "https://cran.r-project.org/package=microsimulation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "microsimulation Discrete Event Simulation in R and C++, with Tools for\nCost-Effectiveness Analysis Discrete event simulation using both R and C++ (Karlsson et al 2016; <doi:10.1109/eScience.2016.7870915>). The C++ code is adapted from the SSIM library <https://www.inf.usi.ch/carzaniga/ssim/>, allowing for event-oriented simulation. The code includes a SummaryReport class for reporting events and costs by age and other covariates. The C++ code is available as a static library for linking to other packages. A priority queue implementation is given in C++ together with an S3 closure and a reference class implementation. Finally, some tools are provided for cost-effectiveness analysis.  "
  },
  {
    "id": 16054,
    "package_name": "mikropml",
    "title": "User-Friendly R Package for Supervised Machine Learning\nPipelines",
    "description": "An interface to build machine learning models for\n    classification and regression problems. 'mikropml' implements the ML\n    pipeline described by Top\u00e7uo\u011flu et al. (2020)\n    <doi:10.1128/mBio.00434-20> with reasonable default options for data\n    preprocessing, hyperparameter tuning, cross-validation, testing, model\n    evaluation, and interpretation steps.  See the website\n    <https://www.schlosslab.org/mikropml/> for more information,\n    documentation, and examples.",
    "version": "1.7.0",
    "maintainer": "Kelly Sovacool <sovacool@umich.edu>",
    "author": "Beg\u00fcm Top\u00e7uo\u011flu [aut] (ORCID: <https://orcid.org/0000-0003-3140-537X>),\n  Zena Lapp [aut] (ORCID: <https://orcid.org/0000-0003-4674-2176>),\n  Kelly Sovacool [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3283-829X>),\n  Evan Snitkin [aut] (ORCID: <https://orcid.org/0000-0001-8409-278X>),\n  Jenna Wiens [aut] (ORCID: <https://orcid.org/0000-0002-1057-7722>),\n  Patrick Schloss [aut] (ORCID: <https://orcid.org/0000-0002-6935-4275>),\n  Nick Lesniak [ctb] (ORCID: <https://orcid.org/0000-0001-9359-5194>),\n  Courtney Armour [ctb] (ORCID: <https://orcid.org/0000-0002-5250-1224>),\n  Sarah Lucas [ctb] (ORCID: <https://orcid.org/0000-0003-1676-5801>),\n  Tuomas Borman [ctb] (ORCID: <https://orcid.org/0000-0002-8563-8884>)",
    "url": "https://www.schlosslab.org/mikropml/,\nhttps://github.com/SchlossLab/mikropml",
    "bug_reports": "https://github.com/SchlossLab/mikropml/issues",
    "repository": "https://cran.r-project.org/package=mikropml",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mikropml User-Friendly R Package for Supervised Machine Learning\nPipelines An interface to build machine learning models for\n    classification and regression problems. 'mikropml' implements the ML\n    pipeline described by Top\u00e7uo\u011flu et al. (2020)\n    <doi:10.1128/mBio.00434-20> with reasonable default options for data\n    preprocessing, hyperparameter tuning, cross-validation, testing, model\n    evaluation, and interpretation steps.  See the website\n    <https://www.schlosslab.org/mikropml/> for more information,\n    documentation, and examples.  "
  },
  {
    "id": 16055,
    "package_name": "mildsvm",
    "title": "Multiple-Instance Learning with Support Vector Machines",
    "description": "Weakly supervised (WS), multiple instance (MI) data lives in\n    numerous interesting applications such as drug discovery, object\n    detection, and tumor prediction on whole slide images. The 'mildsvm'\n    package provides an easy way to learn from this data by training\n    Support Vector Machine (SVM)-based classifiers. It also contains\n    helpful functions for building and printing multiple instance data\n    frames. The core methods from 'mildsvm' come from the following\n    references: Kent and Yu (2024) <doi:10.1214/24-AOAS1876>; Xiao, Liu, and Hao\n    (2018) <doi:10.1109/TNNLS.2017.2766164>; Muandet et al. (2012)\n    <https://proceedings.neurips.cc/paper/2012/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf>;\n    Chu and Keerthi (2007) <doi:10.1162/neco.2007.19.3.792>; and Andrews\n    et al. (2003)\n    <https://papers.nips.cc/paper/2232-support-vector-machines-for-multiple-instance-learning.pdf>.\n    Many functions use the 'Gurobi' optimization back-end to improve the\n    optimization problem speed; the 'gurobi' R package and associated\n    software can be downloaded from <https://www.gurobi.com> after\n    obtaining a license.",
    "version": "0.4.1",
    "maintainer": "Sean Kent <skent259@gmail.com>",
    "author": "Sean Kent [aut, cre] (ORCID: <https://orcid.org/0000-0001-8697-9069>),\n  Yifei Liou [aut]",
    "url": "https://github.com/skent259/mildsvm",
    "bug_reports": "https://github.com/skent259/mildsvm/issues",
    "repository": "https://cran.r-project.org/package=mildsvm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mildsvm Multiple-Instance Learning with Support Vector Machines Weakly supervised (WS), multiple instance (MI) data lives in\n    numerous interesting applications such as drug discovery, object\n    detection, and tumor prediction on whole slide images. The 'mildsvm'\n    package provides an easy way to learn from this data by training\n    Support Vector Machine (SVM)-based classifiers. It also contains\n    helpful functions for building and printing multiple instance data\n    frames. The core methods from 'mildsvm' come from the following\n    references: Kent and Yu (2024) <doi:10.1214/24-AOAS1876>; Xiao, Liu, and Hao\n    (2018) <doi:10.1109/TNNLS.2017.2766164>; Muandet et al. (2012)\n    <https://proceedings.neurips.cc/paper/2012/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf>;\n    Chu and Keerthi (2007) <doi:10.1162/neco.2007.19.3.792>; and Andrews\n    et al. (2003)\n    <https://papers.nips.cc/paper/2232-support-vector-machines-for-multiple-instance-learning.pdf>.\n    Many functions use the 'Gurobi' optimization back-end to improve the\n    optimization problem speed; the 'gurobi' R package and associated\n    software can be downloaded from <https://www.gurobi.com> after\n    obtaining a license.  "
  },
  {
    "id": 16093,
    "package_name": "minque",
    "title": "Various Linear Mixed Model Analyses",
    "description": "This package offers three important components: (1) to construct a use-defined linear mixed model, (2) to employ one of linear mixed model approaches: minimum norm quadratic unbiased estimation (MINQUE) (Rao, 1971) for variance component estimation and random effect prediction; and (3) to employ a jackknife resampling technique to conduct various statistical tests. In addition, this package provides the function for model or data evaluations.This R package offers fast computations for large data sets analyses for various irregular data structures.",
    "version": "2.0.0",
    "maintainer": "Jixiang Wu <jixiang.wu@sdstate.edu>",
    "author": "Jixiang Wu",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=minque",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "minque Various Linear Mixed Model Analyses This package offers three important components: (1) to construct a use-defined linear mixed model, (2) to employ one of linear mixed model approaches: minimum norm quadratic unbiased estimation (MINQUE) (Rao, 1971) for variance component estimation and random effect prediction; and (3) to employ a jackknife resampling technique to conduct various statistical tests. In addition, this package provides the function for model or data evaluations.This R package offers fast computations for large data sets analyses for various irregular data structures.  "
  },
  {
    "id": 16118,
    "package_name": "missCompare",
    "title": "Intuitive Missing Data Imputation Framework",
    "description": "Offers a convenient pipeline to test and compare various missing data\n  imputation algorithms on simulated and real data. These include simpler methods, such as mean and median\n  imputation and random replacement, but also include more sophisticated algorithms already implemented in popular \n  R packages, such as 'mi', described by Su et al. (2011) <doi:10.18637/jss.v045.i02>; 'mice', described by van Buuren \n  and Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>; 'missForest', described by Stekhoven and Buhlmann (2012) \n  <doi:10.1093/bioinformatics/btr597>; 'missMDA', described by Josse and Husson (2016) <doi:10.18637/jss.v070.i01>; and \n  'pcaMethods', described by Stacklies et al. (2007) <doi:10.1093/bioinformatics/btm069>. The central assumption behind \n  'missCompare' is that structurally different datasets (e.g. larger datasets with a large number of correlated variables \n  vs. smaller datasets with non correlated variables) will benefit differently from different missing data imputation \n  algorithms. 'missCompare' takes measurements of your dataset and sets up a sandbox to try a curated list of standard and \n  sophisticated missing data imputation algorithms and compares them assuming custom missingness patterns.\n  'missCompare' will also impute your real-life dataset for you after the selection of the best performing algorithm\n  in the simulations. The package also provides various post-imputation diagnostics and visualizations to help you \n  assess imputation performance.   ",
    "version": "1.0.3",
    "maintainer": "Tibor V. Varga <tirgit@hotmail.com>",
    "author": "Tibor V. Varga [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2383-699X>),\n  David Westergaard [aut] (ORCID:\n    <https://orcid.org/0000-0003-0128-8432>)",
    "url": "",
    "bug_reports": "https://github.com/Tirgit/missCompare/issues",
    "repository": "https://cran.r-project.org/package=missCompare",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "missCompare Intuitive Missing Data Imputation Framework Offers a convenient pipeline to test and compare various missing data\n  imputation algorithms on simulated and real data. These include simpler methods, such as mean and median\n  imputation and random replacement, but also include more sophisticated algorithms already implemented in popular \n  R packages, such as 'mi', described by Su et al. (2011) <doi:10.18637/jss.v045.i02>; 'mice', described by van Buuren \n  and Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>; 'missForest', described by Stekhoven and Buhlmann (2012) \n  <doi:10.1093/bioinformatics/btr597>; 'missMDA', described by Josse and Husson (2016) <doi:10.18637/jss.v070.i01>; and \n  'pcaMethods', described by Stacklies et al. (2007) <doi:10.1093/bioinformatics/btm069>. The central assumption behind \n  'missCompare' is that structurally different datasets (e.g. larger datasets with a large number of correlated variables \n  vs. smaller datasets with non correlated variables) will benefit differently from different missing data imputation \n  algorithms. 'missCompare' takes measurements of your dataset and sets up a sandbox to try a curated list of standard and \n  sophisticated missing data imputation algorithms and compares them assuming custom missingness patterns.\n  'missCompare' will also impute your real-life dataset for you after the selection of the best performing algorithm\n  in the simulations. The package also provides various post-imputation diagnostics and visualizations to help you \n  assess imputation performance.     "
  },
  {
    "id": 16146,
    "package_name": "mixR",
    "title": "Finite Mixture Modeling for Raw and Binned Data",
    "description": "Performs maximum likelihood estimation for finite mixture models for families including Normal, Weibull, Gamma and Lognormal by using EM algorithm, together with Newton-Raphson algorithm or bisection method when necessary. It also conducts mixture model selection by using information criteria or bootstrap likelihood ratio test. The data used for mixture model fitting can be raw data or binned data. The model fitting process is accelerated by using R package 'Rcpp'.",
    "version": "0.2.1",
    "maintainer": "Youjiao Yu <jiaoisjiao@gmail.com>",
    "author": "Youjiao Yu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mixR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mixR Finite Mixture Modeling for Raw and Binned Data Performs maximum likelihood estimation for finite mixture models for families including Normal, Weibull, Gamma and Lognormal by using EM algorithm, together with Newton-Raphson algorithm or bisection method when necessary. It also conducts mixture model selection by using information criteria or bootstrap likelihood ratio test. The data used for mixture model fitting can be raw data or binned data. The model fitting process is accelerated by using R package 'Rcpp'.  "
  },
  {
    "id": 16153,
    "package_name": "mixcure",
    "title": "Mixture Cure Models",
    "description": "Implementation of parametric and semiparametric mixture cure models based on existing R packages. See details of the models in Peng and Yu (2020) <ISBN: 9780367145576>.",
    "version": "2.0",
    "maintainer": "Yingwei Peng <yingwei.peng@queensu.ca>",
    "author": "Yingwei Peng [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mixcure",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mixcure Mixture Cure Models Implementation of parametric and semiparametric mixture cure models based on existing R packages. See details of the models in Peng and Yu (2020) <ISBN: 9780367145576>.  "
  },
  {
    "id": 16183,
    "package_name": "mknapsack",
    "title": "Multiple Knapsack Problem Solver",
    "description": "Package solves multiple knapsack optimisation problem. \n    Given a set of items, each with volume and value, \n    it will allocate them to knapsacks of a given size in a way that\n    value of top N knapsacks is as large as possible.",
    "version": "0.1.0",
    "maintainer": "Bulat Yapparov <bulat.yapparov@made.com>",
    "author": "Bulat Yapparov [aut, cre],\n  MADE.com [cph]",
    "url": "https://github.com/madedotcom/mknapsack",
    "bug_reports": "https://github.com/madedotcom/mknapsack/issues",
    "repository": "https://cran.r-project.org/package=mknapsack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mknapsack Multiple Knapsack Problem Solver Package solves multiple knapsack optimisation problem. \n    Given a set of items, each with volume and value, \n    it will allocate them to knapsacks of a given size in a way that\n    value of top N knapsacks is as large as possible.  "
  },
  {
    "id": 16202,
    "package_name": "mlim",
    "title": "Single and Multiple Imputation with Automated Machine Learning",
    "description": "Machine learning algorithms have been used for performing \n    single missing data imputation and most recently, multiple imputations. \n    However, this is the first attempt for using automated machine learning algorithms \n    for performing both \n    single and multiple imputation. Automated machine learning is a procedure for \n    fine-tuning the model automatic, performing a random search for a model that \n    results in less error, without overfitting the data. The main idea is \n    to allow the model to set its own parameters for imputing each variable separately \n    instead of setting fixed predefined parameters to impute all variables \n    of the dataset.\n    Using automated machine learning, the package fine-tunes an Elastic \n    Net (default) or Gradient Boosting, Random Forest, Deep Learning, Extreme Gradient Boosting,\n    or Stacked Ensemble machine learning model (from one or a combination of other \n    supported algorithms) for imputing the missing \n    observations. This procedure has been implemented for the \n    first time by this package and is expected to outperform other packages for \n    imputing missing data that do not fine-tune their models. The multiple imputation \n    is implemented via bootstrapping without letting the duplicated observations to \n    harm the cross-validation procedure, which is the way imputed variables are evaluated.\n    Most notably, the package implements automated procedure for handling imputing imbalanced \n    data (class rarity problem), which happens when a factor variable has a level that is far more \n    prevalent than the other(s). This is known to result in biased predictions, hence, biased \n    imputation of missing data. However, the autobalancing procedure ensures that instead of \n    focusing on maximizing accuracy (classification error) in imputing factor variables, \n    a fairer procedure and imputation method is practiced. ",
    "version": "0.3.0",
    "maintainer": "E. F. Haghish <haghish@uio.no>",
    "author": "E. F. Haghish [aut, cre, cph]",
    "url": "https://github.com/haghish/mlim,\nhttps://www.sv.uio.no/psi/english/people/aca/haghish/",
    "bug_reports": "https://github.com/haghish/mlim/issues",
    "repository": "https://cran.r-project.org/package=mlim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlim Single and Multiple Imputation with Automated Machine Learning Machine learning algorithms have been used for performing \n    single missing data imputation and most recently, multiple imputations. \n    However, this is the first attempt for using automated machine learning algorithms \n    for performing both \n    single and multiple imputation. Automated machine learning is a procedure for \n    fine-tuning the model automatic, performing a random search for a model that \n    results in less error, without overfitting the data. The main idea is \n    to allow the model to set its own parameters for imputing each variable separately \n    instead of setting fixed predefined parameters to impute all variables \n    of the dataset.\n    Using automated machine learning, the package fine-tunes an Elastic \n    Net (default) or Gradient Boosting, Random Forest, Deep Learning, Extreme Gradient Boosting,\n    or Stacked Ensemble machine learning model (from one or a combination of other \n    supported algorithms) for imputing the missing \n    observations. This procedure has been implemented for the \n    first time by this package and is expected to outperform other packages for \n    imputing missing data that do not fine-tune their models. The multiple imputation \n    is implemented via bootstrapping without letting the duplicated observations to \n    harm the cross-validation procedure, which is the way imputed variables are evaluated.\n    Most notably, the package implements automated procedure for handling imputing imbalanced \n    data (class rarity problem), which happens when a factor variable has a level that is far more \n    prevalent than the other(s). This is known to result in biased predictions, hence, biased \n    imputation of missing data. However, the autobalancing procedure ensures that instead of \n    focusing on maximizing accuracy (classification error) in imputing factor variables, \n    a fairer procedure and imputation method is practiced.   "
  },
  {
    "id": 16203,
    "package_name": "mllrnrs",
    "title": "R6-Based ML Learners for 'mlexperiments'",
    "description": "Enhances 'mlexperiments'\n    <https://CRAN.R-project.org/package=mlexperiments> with additional\n    machine learning ('ML') learners. The package provides R6-based\n    learners for the following algorithms: 'glmnet'\n    <https://CRAN.R-project.org/package=glmnet>, 'ranger'\n    <https://CRAN.R-project.org/package=ranger>, 'xgboost'\n    <https://CRAN.R-project.org/package=xgboost>, and 'lightgbm'\n    <https://CRAN.R-project.org/package=lightgbm>. These can be used\n    directly with the 'mlexperiments' R package.",
    "version": "0.0.7",
    "maintainer": "Lorenz A. Kapsner <lorenz.kapsner@gmail.com>",
    "author": "Lorenz A. Kapsner [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0003-1866-860X>)",
    "url": "https://github.com/kapsner/mllrnrs",
    "bug_reports": "https://github.com/kapsner/mllrnrs/issues",
    "repository": "https://cran.r-project.org/package=mllrnrs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mllrnrs R6-Based ML Learners for 'mlexperiments' Enhances 'mlexperiments'\n    <https://CRAN.R-project.org/package=mlexperiments> with additional\n    machine learning ('ML') learners. The package provides R6-based\n    learners for the following algorithms: 'glmnet'\n    <https://CRAN.R-project.org/package=glmnet>, 'ranger'\n    <https://CRAN.R-project.org/package=ranger>, 'xgboost'\n    <https://CRAN.R-project.org/package=xgboost>, and 'lightgbm'\n    <https://CRAN.R-project.org/package=lightgbm>. These can be used\n    directly with the 'mlexperiments' R package.  "
  },
  {
    "id": 16238,
    "package_name": "mlr3spatial",
    "title": "Support for Spatial Objects Within the 'mlr3' Ecosystem",
    "description": "Extends the 'mlr3' ML framework with methods for spatial\n    objects. Data storage and prediction are supported for packages\n    'terra', 'raster' and 'stars'.",
    "version": "0.6.1",
    "maintainer": "Marc Becker <marcbecker@posteo.de>",
    "author": "Marc Becker [aut, cre] (ORCID: <https://orcid.org/0000-0002-8115-0400>),\n  Patrick Schratz [aut] (ORCID: <https://orcid.org/0000-0003-0748-6624>)",
    "url": "https://mlr3spatial.mlr-org.com,\nhttps://github.com/mlr-org/mlr3spatial",
    "bug_reports": "https://github.com/mlr-org/mlr3spatial/issues",
    "repository": "https://cran.r-project.org/package=mlr3spatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlr3spatial Support for Spatial Objects Within the 'mlr3' Ecosystem Extends the 'mlr3' ML framework with methods for spatial\n    objects. Data storage and prediction are supported for packages\n    'terra', 'raster' and 'stars'.  "
  },
  {
    "id": 16254,
    "package_name": "mlstrOpalr",
    "title": "Support Compatibility Between 'Maelstrom' R Packages and 'Opal'\nEnvironment",
    "description": "Functions to support compatibility between 'Maelstrom' R packages \n     and 'Opal' environment. 'Opal' is the 'OBiBa' core database application for \n     biobanks. It is used to build data repositories that integrates data \n     collected from multiple sources. 'Opal Maelstrom' is a specific \n     implementation of this software. This 'Opal' client is specifically \n     designed to interact with 'Opal Maelstrom' distributions to perform \n     operations on the R server side. The user must have adequate credentials.\n     Please see <https://opaldoc.obiba.org/> for complete documentation.",
    "version": "1.0.3",
    "maintainer": "Guillaume Fabre <guijoseph.fabre@gmail.com>",
    "author": "Guillaume Fabre [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0124-9970>),\n  Maelstrom-research group [fnd, cph],\n  OBiBa group [ctb]",
    "url": "https://github.com/maelstrom-research/mlstrOpalr",
    "bug_reports": "https://github.com/maelstrom-research/mlstrOpalr/issues",
    "repository": "https://cran.r-project.org/package=mlstrOpalr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlstrOpalr Support Compatibility Between 'Maelstrom' R Packages and 'Opal'\nEnvironment Functions to support compatibility between 'Maelstrom' R packages \n     and 'Opal' environment. 'Opal' is the 'OBiBa' core database application for \n     biobanks. It is used to build data repositories that integrates data \n     collected from multiple sources. 'Opal Maelstrom' is a specific \n     implementation of this software. This 'Opal' client is specifically \n     designed to interact with 'Opal Maelstrom' distributions to perform \n     operations on the R server side. The user must have adequate credentials.\n     Please see <https://opaldoc.obiba.org/> for complete documentation.  "
  },
  {
    "id": 16255,
    "package_name": "mlsurvlrnrs",
    "title": "R6-Based ML Survival Learners for 'mlexperiments'",
    "description": "Enhances 'mlexperiments'\n    <https://CRAN.R-project.org/package=mlexperiments> with additional\n    machine learning ('ML') learners for survival analysis. The package\n    provides R6-based survival learners for the following algorithms:\n    'glmnet' <https://CRAN.R-project.org/package=glmnet>, 'ranger'\n    <https://CRAN.R-project.org/package=ranger>, 'xgboost'\n    <https://CRAN.R-project.org/package=xgboost>, and 'rpart'\n    <https://CRAN.R-project.org/package=rpart>. These can be used directly\n    with the 'mlexperiments' R package.",
    "version": "0.0.7",
    "maintainer": "Lorenz A. Kapsner <lorenz.kapsner@gmail.com>",
    "author": "Lorenz A. Kapsner [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0003-1866-860X>)",
    "url": "https://github.com/kapsner/mlsurvlrnrs",
    "bug_reports": "https://github.com/kapsner/mlsurvlrnrs/issues",
    "repository": "https://cran.r-project.org/package=mlsurvlrnrs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlsurvlrnrs R6-Based ML Survival Learners for 'mlexperiments' Enhances 'mlexperiments'\n    <https://CRAN.R-project.org/package=mlexperiments> with additional\n    machine learning ('ML') learners for survival analysis. The package\n    provides R6-based survival learners for the following algorithms:\n    'glmnet' <https://CRAN.R-project.org/package=glmnet>, 'ranger'\n    <https://CRAN.R-project.org/package=ranger>, 'xgboost'\n    <https://CRAN.R-project.org/package=xgboost>, and 'rpart'\n    <https://CRAN.R-project.org/package=rpart>. These can be used directly\n    with the 'mlexperiments' R package.  "
  },
  {
    "id": 16277,
    "package_name": "mmibain",
    "title": "Bayesian Informative Hypotheses Evaluation Web Applications",
    "description": "Researchers often have expectations about the relations between means\n    of different groups or standardized regression coefficients; using informative\n    hypothesis testing to incorporate these expectations into the analysis through\n    order constraints increases statistical power\n    Vanbrabant and Rosseel (2020) <doi:10.4324/9780429273872-14>. Another valuable\n    tool, the Bayes factor, can evaluate evidence for multiple hypotheses without\n    concerns about multiple testing, and can be used in Bayesian updating\n    Hoijtink, Mulder, van Lissa & Gu (2019) <doi:10.1037/met0000201>. The 'bain'\n    R package enables informative hypothesis testing using the Bayes factor. The\n    'mmibain' package provides 'shiny' web applications based on 'bain'. The\n    RepliCrisis() function launches a 'shiny' card game to simulate the evaluation\n    of replication studies while the mmibain() function launches a 'shiny'\n    application to fit Bayesian informative hypotheses evaluation models from\n    'bain'.",
    "version": "0.2.0",
    "maintainer": "Mackson Ncube <macksonncube.stats@gmail.com>",
    "author": "Mackson Ncube [aut, cre],\n  mightymetrika, LLC [cph, fnd]",
    "url": "https://github.com/mightymetrika/mmibain",
    "bug_reports": "https://github.com/mightymetrika/mmibain/issues",
    "repository": "https://cran.r-project.org/package=mmibain",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mmibain Bayesian Informative Hypotheses Evaluation Web Applications Researchers often have expectations about the relations between means\n    of different groups or standardized regression coefficients; using informative\n    hypothesis testing to incorporate these expectations into the analysis through\n    order constraints increases statistical power\n    Vanbrabant and Rosseel (2020) <doi:10.4324/9780429273872-14>. Another valuable\n    tool, the Bayes factor, can evaluate evidence for multiple hypotheses without\n    concerns about multiple testing, and can be used in Bayesian updating\n    Hoijtink, Mulder, van Lissa & Gu (2019) <doi:10.1037/met0000201>. The 'bain'\n    R package enables informative hypothesis testing using the Bayes factor. The\n    'mmibain' package provides 'shiny' web applications based on 'bain'. The\n    RepliCrisis() function launches a 'shiny' card game to simulate the evaluation\n    of replication studies while the mmibain() function launches a 'shiny'\n    application to fit Bayesian informative hypotheses evaluation models from\n    'bain'.  "
  },
  {
    "id": 16304,
    "package_name": "mockthat",
    "title": "Function Mocking for Unit Testing",
    "description": "With the deprecation of mocking capabilities shipped with\n    'testthat' as of 'edition 3' it is left to third-party packages to replace\n    this functionality, which in some test-scenarios is essential in order to\n    run unit tests in limited environments (such as no Internet connection).\n    Mocking in this setting means temporarily substituting a function with a\n    stub that acts in some sense like the original function (for example by\n    serving a HTTP response that has been cached as a file). The only exported\n    function 'with_mock()' is modeled after the eponymous 'testthat' function\n    with the intention of providing a drop-in replacement.",
    "version": "0.2.8",
    "maintainer": "Nicolas Bennett <nicolas.bennett@stat.math.ethz.ch>",
    "author": "Nicolas Bennett [aut, cre]",
    "url": "https://nbenn.github.io/mockthat/",
    "bug_reports": "https://github.com/nbenn/mockthat/issues",
    "repository": "https://cran.r-project.org/package=mockthat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mockthat Function Mocking for Unit Testing With the deprecation of mocking capabilities shipped with\n    'testthat' as of 'edition 3' it is left to third-party packages to replace\n    this functionality, which in some test-scenarios is essential in order to\n    run unit tests in limited environments (such as no Internet connection).\n    Mocking in this setting means temporarily substituting a function with a\n    stub that acts in some sense like the original function (for example by\n    serving a HTTP response that has been cached as a file). The only exported\n    function 'with_mock()' is modeled after the eponymous 'testthat' function\n    with the intention of providing a drop-in replacement.  "
  },
  {
    "id": 16324,
    "package_name": "modeltests",
    "title": "Testing Infrastructure for Broom Model Generics",
    "description": "Provides a number of testthat tests that can be\n    used to verify that tidy(), glance() and augment() methods meet\n    consistent specifications. This allows methods for the same generic to\n    be spread across multiple packages, since all of those packages can\n    make the same guarantees to users about returned objects.",
    "version": "0.1.7",
    "maintainer": "Alex Hayes <alexpghayes@gmail.com>",
    "author": "Alex Hayes [aut, cre] (ORCID: <https://orcid.org/0000-0002-4985-5160>),\n  Simon Couch [aut]",
    "url": "https://github.com/alexpghayes/modeltests",
    "bug_reports": "https://github.com/alexpghayes/modeltests/issues",
    "repository": "https://cran.r-project.org/package=modeltests",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modeltests Testing Infrastructure for Broom Model Generics Provides a number of testthat tests that can be\n    used to verify that tidy(), glance() and augment() methods meet\n    consistent specifications. This allows methods for the same generic to\n    be spread across multiple packages, since all of those packages can\n    make the same guarantees to users about returned objects.  "
  },
  {
    "id": 16342,
    "package_name": "modsem",
    "title": "Latent Interaction (and Moderation) Analysis in Structural\nEquation Models (SEM)",
    "description": "\n    Estimation of interaction (i.e., moderation) effects between latent variables\n    in structural equation models (SEM). \n    The supported methods are:\n      The constrained approach (Algina & Moulder, 2001).\n      The unconstrained approach (Marsh et al., 2004).\n      The residual centering approach (Little et al., 2006).\n      The double centering approach (Lin et al., 2010).\n      The latent moderated structural equations (LMS) approach (Klein & Moosbrugger, 2000).\n      The quasi-maximum likelihood (QML) approach (Klein & Muth\u00e9n, 2007)\n    The constrained- unconstrained, residual- and double centering- approaches\n    are estimated via 'lavaan' (Rosseel, 2012), whilst the LMS- and QML- approaches\n    are estimated via 'modsem' it self. Alternatively model can be\n    estimated via 'Mplus' (Muth\u00e9n & Muth\u00e9n, 1998-2017).\n    References:\n    Algina, J., & Moulder, B. C. (2001). \n      <doi:10.1207/S15328007SEM0801_3>.\n      \"A note on estimating the J\u00f6reskog-Yang model for latent variable interaction using 'LISREL' 8.3.\"\n    Klein, A., & Moosbrugger, H. (2000). \n      <doi:10.1007/BF02296338>.\n      \"Maximum likelihood estimation of latent interaction effects with the LMS method.\"\n    Klein, A. G., & Muth\u00e9n, B. O. (2007). \n      <doi:10.1080/00273170701710205>.\n      \"Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects.\"\n    Lin, G. C., Wen, Z., Marsh, H. W., & Lin, H. S. (2010). \n      <doi:10.1080/10705511.2010.488999>.\n      \"Structural equation models of latent interactions: Clarification of orthogonalizing and double-mean-centering strategies.\"\n    Little, T. D., Bovaird, J. A., & Widaman, K. F. (2006). \n      <doi:10.1207/s15328007sem1304_1>.\n      \"On the merits of orthogonalizing powered and product terms: Implications for modeling interactions among latent variables.\"\n    Marsh, H. W., Wen, Z., & Hau, K. T. (2004). \n      <doi:10.1037/1082-989X.9.3.275>.\n      \"Structural equation models of latent interactions: evaluation of alternative estimation strategies and indicator construction.\"\n    Muth\u00e9n, L.K. and Muth\u00e9n, B.O. (1998-2017).  \n      \"'Mplus' User\u2019s Guide. Eighth Edition.\"\n      <https://www.statmodel.com/>.\n    Rosseel Y (2012). \n      <doi:10.18637/jss.v048.i02>.\n      \"'lavaan': An R Package for Structural Equation Modeling.\" ",
    "version": "1.0.14",
    "maintainer": "Kjell Solem Slupphaug <slupphaugkjell@gmail.com>",
    "author": "Kjell Solem Slupphaug [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-8324-2834>),\n  Mehmet Mehmetoglu [ctb] (ORCID:\n    <https://orcid.org/0000-0002-6092-8551>),\n  Matthias Mittner [ctb] (ORCID: <https://orcid.org/0000-0003-0205-7353>)",
    "url": "https://modsem.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=modsem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modsem Latent Interaction (and Moderation) Analysis in Structural\nEquation Models (SEM) \n    Estimation of interaction (i.e., moderation) effects between latent variables\n    in structural equation models (SEM). \n    The supported methods are:\n      The constrained approach (Algina & Moulder, 2001).\n      The unconstrained approach (Marsh et al., 2004).\n      The residual centering approach (Little et al., 2006).\n      The double centering approach (Lin et al., 2010).\n      The latent moderated structural equations (LMS) approach (Klein & Moosbrugger, 2000).\n      The quasi-maximum likelihood (QML) approach (Klein & Muth\u00e9n, 2007)\n    The constrained- unconstrained, residual- and double centering- approaches\n    are estimated via 'lavaan' (Rosseel, 2012), whilst the LMS- and QML- approaches\n    are estimated via 'modsem' it self. Alternatively model can be\n    estimated via 'Mplus' (Muth\u00e9n & Muth\u00e9n, 1998-2017).\n    References:\n    Algina, J., & Moulder, B. C. (2001). \n      <doi:10.1207/S15328007SEM0801_3>.\n      \"A note on estimating the J\u00f6reskog-Yang model for latent variable interaction using 'LISREL' 8.3.\"\n    Klein, A., & Moosbrugger, H. (2000). \n      <doi:10.1007/BF02296338>.\n      \"Maximum likelihood estimation of latent interaction effects with the LMS method.\"\n    Klein, A. G., & Muth\u00e9n, B. O. (2007). \n      <doi:10.1080/00273170701710205>.\n      \"Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects.\"\n    Lin, G. C., Wen, Z., Marsh, H. W., & Lin, H. S. (2010). \n      <doi:10.1080/10705511.2010.488999>.\n      \"Structural equation models of latent interactions: Clarification of orthogonalizing and double-mean-centering strategies.\"\n    Little, T. D., Bovaird, J. A., & Widaman, K. F. (2006). \n      <doi:10.1207/s15328007sem1304_1>.\n      \"On the merits of orthogonalizing powered and product terms: Implications for modeling interactions among latent variables.\"\n    Marsh, H. W., Wen, Z., & Hau, K. T. (2004). \n      <doi:10.1037/1082-989X.9.3.275>.\n      \"Structural equation models of latent interactions: evaluation of alternative estimation strategies and indicator construction.\"\n    Muth\u00e9n, L.K. and Muth\u00e9n, B.O. (1998-2017).  \n      \"'Mplus' User\u2019s Guide. Eighth Edition.\"\n      <https://www.statmodel.com/>.\n    Rosseel Y (2012). \n      <doi:10.18637/jss.v048.i02>.\n      \"'lavaan': An R Package for Structural Equation Modeling.\"   "
  },
  {
    "id": 16387,
    "package_name": "morestopwords",
    "title": "All Stop Words in One Place",
    "description": "A standalone package combining several stop-word lists for 65 languages with a median of 329 stop words for language and over 1,000 entries for English, Breton, Latin, Slovenian, and Ancient Greek! The user automatically gets access to all the unique stop words contained in: the 'StopwordISO' repository; the 'Natural Language Toolkit' for 'python'; the 'Snowball' stop-word list; the R package 'quanteda'; the 'marimo' repository; the 'Perseus' project; and A. Berra's list of stop words for Ancient Greek and Latin.",
    "version": "0.2.0",
    "maintainer": "Fabio Ashtar Telarico <Fabio-Ashtar.Telarico@fdv.uni-lj.si>",
    "author": "Fabio Ashtar Telarico [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8740-7078>),\n  Kohei Watanabe [aut]",
    "url": "https://fatelarico.github.io/morestopwords.html",
    "bug_reports": "https://github.com/FATelarico/morestopwords/issues",
    "repository": "https://cran.r-project.org/package=morestopwords",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "morestopwords All Stop Words in One Place A standalone package combining several stop-word lists for 65 languages with a median of 329 stop words for language and over 1,000 entries for English, Breton, Latin, Slovenian, and Ancient Greek! The user automatically gets access to all the unique stop words contained in: the 'StopwordISO' repository; the 'Natural Language Toolkit' for 'python'; the 'Snowball' stop-word list; the R package 'quanteda'; the 'marimo' repository; the 'Perseus' project; and A. Berra's list of stop words for Ancient Greek and Latin.  "
  },
  {
    "id": 16405,
    "package_name": "mosum",
    "title": "Moving Sum Based Procedures for Changes in the Mean",
    "description": "Implementations of MOSUM-based statistical procedures and algorithms for detecting multiple changes in the mean. This comprises the MOSUM procedure for estimating multiple mean changes from Eichinger and Kirch (2018) <doi:10.3150/16-BEJ887> and the multiscale algorithmic extension from Cho and Kirch (2022) <doi:10.1007/s10463-021-00811-5>, as well as the bootstrap procedure for generating confidence intervals about the locations of change points as proposed in Cho and Kirch (2022) <doi:10.1016/j.csda.2022.107552>. See also Meier, Kirch and Cho (2021) <doi:10.18637/jss.v097.i08> which accompanies the R package.",
    "version": "1.2.7",
    "maintainer": "Haeran Cho <haeran.cho@bristol.ac.uk>",
    "author": "Alexander Meier [aut],\n  Haeran Cho [aut, cre],\n  Claudia Kirch [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mosum",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mosum Moving Sum Based Procedures for Changes in the Mean Implementations of MOSUM-based statistical procedures and algorithms for detecting multiple changes in the mean. This comprises the MOSUM procedure for estimating multiple mean changes from Eichinger and Kirch (2018) <doi:10.3150/16-BEJ887> and the multiscale algorithmic extension from Cho and Kirch (2022) <doi:10.1007/s10463-021-00811-5>, as well as the bootstrap procedure for generating confidence intervals about the locations of change points as proposed in Cho and Kirch (2022) <doi:10.1016/j.csda.2022.107552>. See also Meier, Kirch and Cho (2021) <doi:10.18637/jss.v097.i08> which accompanies the R package.  "
  },
  {
    "id": 16487,
    "package_name": "msig",
    "title": "An R Package for Exploring Molecular Signatures Database",
    "description": "The Molecular Signatures Database ('MSigDB') is one of the most widely \n    used and comprehensive databases of gene sets for performing gene set \n    enrichment analysis <doi:10.1016/j.cels.2015.12.004>. The 'msig' package provides \n    you with powerful, easy-to-use and flexible query functions for the 'MsigDB' \n    database.\n        There are 2 query modes in the 'msig' package: online query and local query. \n    Both queries contain 2 steps: gene set name and gene.\n        The online search is divided into 2 modes: registered search and \n    non-registered browse. For registered search, email that you registered should \n    be provided.\n        Local queries can be made from local database, which can be updated by msig_update() function.",
    "version": "1.0",
    "maintainer": "Jing Zhang <zj391120@163.com>",
    "author": "Jing Zhang [aut, cre],\n  Zhi Jin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=msig",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "msig An R Package for Exploring Molecular Signatures Database The Molecular Signatures Database ('MSigDB') is one of the most widely \n    used and comprehensive databases of gene sets for performing gene set \n    enrichment analysis <doi:10.1016/j.cels.2015.12.004>. The 'msig' package provides \n    you with powerful, easy-to-use and flexible query functions for the 'MsigDB' \n    database.\n        There are 2 query modes in the 'msig' package: online query and local query. \n    Both queries contain 2 steps: gene set name and gene.\n        The online search is divided into 2 modes: registered search and \n    non-registered browse. For registered search, email that you registered should \n    be provided.\n        Local queries can be made from local database, which can be updated by msig_update() function.  "
  },
  {
    "id": 16489,
    "package_name": "msir",
    "title": "Model-Based Sliced Inverse Regression",
    "description": "An R package for dimension reduction based on finite Gaussian mixture modeling of inverse regression.",
    "version": "1.3.3",
    "maintainer": "Luca Scrucca <luca.scrucca@unipg.it>",
    "author": "Luca Scrucca [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3826-0484>)",
    "url": "https://mclust-org.github.io/msir/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=msir",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "msir Model-Based Sliced Inverse Regression An R package for dimension reduction based on finite Gaussian mixture modeling of inverse regression.  "
  },
  {
    "id": 16524,
    "package_name": "mulea",
    "title": "Enrichment Analysis Using Multiple Ontologies and False\nDiscovery Rate",
    "description": "Background - Traditional gene set enrichment analyses are \n    typically limited to a few ontologies and do not account for the \n    interdependence of gene sets or terms, resulting in overcorrected p-values. \n    To address these challenges, we introduce mulea, an R package offering \n    comprehensive overrepresentation and functional enrichment analysis. \n    Results - mulea employs a progressive empirical false discovery rate \n    (eFDR) method, specifically designed for interconnected biological data, \n    to accurately identify significant terms within diverse ontologies. mulea \n    expands beyond traditional tools by incorporating a wide range of \n    ontologies, encompassing Gene Ontology, pathways, regulatory elements, \n    genomic locations, and protein domains. This flexibility enables \n    researchers to tailor enrichment analysis to their specific questions, \n    such as identifying enriched transcriptional regulators in gene expression \n    data or overrepresented protein domains in protein sets. To facilitate \n    seamless analysis, mulea provides gene sets (in standardised GMT format) \n    for 27 model organisms, covering 22 ontology types from 16 databases and \n    various identifiers resulting in almost 900 files. Additionally, the \n    muleaData ExperimentData Bioconductor package simplifies access to these \n    pre-defined ontologies. Finally, mulea's architecture allows for easy \n    integration of user-defined ontologies, or GMT files from external \n    sources (e.g., MSigDB or Enrichr), expanding its applicability across \n    diverse research areas. Conclusions - mulea is distributed as a CRAN R \n    package. It offers researchers a powerful and flexible toolkit for \n    functional enrichment analysis, addressing limitations of traditional \n    tools with its progressive eFDR and by supporting a variety of ontologies. \n    Overall, mulea fosters the exploration of diverse biological questions \n    across various model organisms.",
    "version": "1.1.1",
    "maintainer": "Tamas Stirling <stirling.tamas@gmail.com>",
    "author": "Cezary Turek [aut] (ORCID: <https://orcid.org/0000-0002-1445-5378>),\n  Marton Olbei [aut] (ORCID: <https://orcid.org/0000-0002-4903-6237>),\n  Tamas Stirling [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8964-6443>),\n  Gergely Fekete [aut] (ORCID: <https://orcid.org/0000-0001-9939-4860>),\n  Ervin Tasnadi [aut] (ORCID: <https://orcid.org/0000-0002-4713-5397>),\n  Leila Gul [aut],\n  Balazs Bohar [aut] (ORCID: <https://orcid.org/0000-0002-3033-5448>),\n  Balazs Papp [aut] (ORCID: <https://orcid.org/0000-0003-3093-8852>),\n  Wiktor Jurkowski [aut] (ORCID: <https://orcid.org/0000-0002-7820-1991>),\n  Eszter Ari [aut, cph] (ORCID: <https://orcid.org/0000-0001-7774-1067>)",
    "url": "https://github.com/ELTEbioinformatics/mulea",
    "bug_reports": "https://github.com/ELTEbioinformatics/mulea/issues",
    "repository": "https://cran.r-project.org/package=mulea",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mulea Enrichment Analysis Using Multiple Ontologies and False\nDiscovery Rate Background - Traditional gene set enrichment analyses are \n    typically limited to a few ontologies and do not account for the \n    interdependence of gene sets or terms, resulting in overcorrected p-values. \n    To address these challenges, we introduce mulea, an R package offering \n    comprehensive overrepresentation and functional enrichment analysis. \n    Results - mulea employs a progressive empirical false discovery rate \n    (eFDR) method, specifically designed for interconnected biological data, \n    to accurately identify significant terms within diverse ontologies. mulea \n    expands beyond traditional tools by incorporating a wide range of \n    ontologies, encompassing Gene Ontology, pathways, regulatory elements, \n    genomic locations, and protein domains. This flexibility enables \n    researchers to tailor enrichment analysis to their specific questions, \n    such as identifying enriched transcriptional regulators in gene expression \n    data or overrepresented protein domains in protein sets. To facilitate \n    seamless analysis, mulea provides gene sets (in standardised GMT format) \n    for 27 model organisms, covering 22 ontology types from 16 databases and \n    various identifiers resulting in almost 900 files. Additionally, the \n    muleaData ExperimentData Bioconductor package simplifies access to these \n    pre-defined ontologies. Finally, mulea's architecture allows for easy \n    integration of user-defined ontologies, or GMT files from external \n    sources (e.g., MSigDB or Enrichr), expanding its applicability across \n    diverse research areas. Conclusions - mulea is distributed as a CRAN R \n    package. It offers researchers a powerful and flexible toolkit for \n    functional enrichment analysis, addressing limitations of traditional \n    tools with its progressive eFDR and by supporting a variety of ontologies. \n    Overall, mulea fosters the exploration of diverse biological questions \n    across various model organisms.  "
  },
  {
    "id": 16561,
    "package_name": "multid",
    "title": "Multivariate Difference Between Two Groups",
    "description": "Estimation of multivariate differences between two groups (e.g., multivariate sex differences) with regularized regression methods and predictive approach. See Ilmarinen et al. (2023) <doi:10.1177/08902070221088155>. Deconstructing difference score correlations (e.g., gender-equality paradox), see Ilmarinen & L\u00f6nnqvist (2024) <doi:10.1037/pspp0000508>.\n    Includes also tools that help in understanding difference score reliability, conditional intra-class correlations, tail-dependency, and heterogeneity of variance estimates. Package development was supported by the Academy of Finland research grant 338891.",
    "version": "1.0.2",
    "maintainer": "Ville-Juhani Ilmarinen <vj.ilmarinen@gmail.com>",
    "author": "Ville-Juhani Ilmarinen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9493-379X>)",
    "url": "",
    "bug_reports": "https://github.com/vjilmari/multid/issues",
    "repository": "https://cran.r-project.org/package=multid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multid Multivariate Difference Between Two Groups Estimation of multivariate differences between two groups (e.g., multivariate sex differences) with regularized regression methods and predictive approach. See Ilmarinen et al. (2023) <doi:10.1177/08902070221088155>. Deconstructing difference score correlations (e.g., gender-equality paradox), see Ilmarinen & L\u00f6nnqvist (2024) <doi:10.1037/pspp0000508>.\n    Includes also tools that help in understanding difference score reliability, conditional intra-class correlations, tail-dependency, and heterogeneity of variance estimates. Package development was supported by the Academy of Finland research grant 338891.  "
  },
  {
    "id": 16585,
    "package_name": "multimorbidity",
    "title": "Harmonizing Various Comorbidity, Multimorbidity, and Frailty\nMeasures",
    "description": "Identifying comorbidities, frailty, and multimorbidity in claims \n    and administrative data is often a duplicative process.\n    The functions contained in this package are meant to first prepare the data to a format\n    acceptable by all other packages, then provide a uniform and simple approach to\n    generate comorbidity and multimorbidity metrics based on these claims data. The package\n    is ever evolving to include new metrics, and is always looking for new measures to include.\n    The citations used in this package include the following publications: \n    Anne Elixhauser, Claudia Steiner, D. Robert Harris, Rosanna M. Coffey (1998) <doi:10.1097/00005650-199801000-00004>,\n    Brian J Moore, Susan White, Raynard Washington, et al. (2017) <doi:10.1097/MLR.0000000000000735>,\n    Mary E. Charlson, Peter Pompei, Kathy L. Ales, C. Ronald MacKenzie (1987) <doi:10.1016/0021-9681(87)90171-8>,\n    Richard A. Deyo, Daniel C. Cherkin, Marcia A. Ciol (1992) <doi:10.1016/0895-4356(92)90133-8>,\n    Hude Quan, Vijaya Sundararajan, Patricia Halfon, et al. (2005) <doi:10.1097/01.mlr.0000182534.19832.83>,\n    Dae Hyun Kim, Sebastian Schneeweiss, Robert J Glynn, et al. (2018) <doi:10.1093/gerona/glx229>,\n    Melissa Y Wei, David Ratz, Kenneth J Mukamal (2020) <doi:10.1111/jgs.16310>,\n    Kathryn Nicholson, Amanda L. Terry, Martin Fortin, et al. (2015) <doi:10.15256/joc.2015.5.61>,\n    Martin Fortin, Jos\u00e9 Almirall, and Kathryn Nicholson (2017)<doi:10.15256/joc.2017.7.122>.",
    "version": "0.5.1",
    "maintainer": "Wyatt Bensken <wpb27@case.edu>",
    "author": "Wyatt Bensken [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2597-9732>)",
    "url": "https://github.com/WYATTBENSKEN/multimorbidity",
    "bug_reports": "https://github.com/WYATTBENSKEN/multimorbidity/issues",
    "repository": "https://cran.r-project.org/package=multimorbidity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multimorbidity Harmonizing Various Comorbidity, Multimorbidity, and Frailty\nMeasures Identifying comorbidities, frailty, and multimorbidity in claims \n    and administrative data is often a duplicative process.\n    The functions contained in this package are meant to first prepare the data to a format\n    acceptable by all other packages, then provide a uniform and simple approach to\n    generate comorbidity and multimorbidity metrics based on these claims data. The package\n    is ever evolving to include new metrics, and is always looking for new measures to include.\n    The citations used in this package include the following publications: \n    Anne Elixhauser, Claudia Steiner, D. Robert Harris, Rosanna M. Coffey (1998) <doi:10.1097/00005650-199801000-00004>,\n    Brian J Moore, Susan White, Raynard Washington, et al. (2017) <doi:10.1097/MLR.0000000000000735>,\n    Mary E. Charlson, Peter Pompei, Kathy L. Ales, C. Ronald MacKenzie (1987) <doi:10.1016/0021-9681(87)90171-8>,\n    Richard A. Deyo, Daniel C. Cherkin, Marcia A. Ciol (1992) <doi:10.1016/0895-4356(92)90133-8>,\n    Hude Quan, Vijaya Sundararajan, Patricia Halfon, et al. (2005) <doi:10.1097/01.mlr.0000182534.19832.83>,\n    Dae Hyun Kim, Sebastian Schneeweiss, Robert J Glynn, et al. (2018) <doi:10.1093/gerona/glx229>,\n    Melissa Y Wei, David Ratz, Kenneth J Mukamal (2020) <doi:10.1111/jgs.16310>,\n    Kathryn Nicholson, Amanda L. Terry, Martin Fortin, et al. (2015) <doi:10.15256/joc.2015.5.61>,\n    Martin Fortin, Jos\u00e9 Almirall, and Kathryn Nicholson (2017)<doi:10.15256/joc.2017.7.122>.  "
  },
  {
    "id": 16604,
    "package_name": "multisite.accuracy",
    "title": "Estimation of Accuracy in Multisite Machine-Learning Models",
    "description": "The effects of the site may severely bias the accuracy of a multisite machine-learning model, even if the analysts removed them when fitting the model in the 'training set' and applying the model in the 'test set' (Solanes et al., Neuroimage 2023, 265:119800). This simple R package estimates the accuracy of a multisite machine-learning model unbiasedly, as described in (Solanes et al., Psychiatry Research: Neuroimaging 2021, 314:111313). It currently supports the estimation of sensitivity, specificity, balanced accuracy (for binary or multinomial variables), the area under the curve, correlation, mean squarer error, and hazard ratio for binomial, multinomial, gaussian, and survival (time-to-event) outcomes.",
    "version": "1.3",
    "maintainer": "Joaquim Radua <quimradua@gmail.com>",
    "author": "Joaquim Radua [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1240-5438>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multisite.accuracy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multisite.accuracy Estimation of Accuracy in Multisite Machine-Learning Models The effects of the site may severely bias the accuracy of a multisite machine-learning model, even if the analysts removed them when fitting the model in the 'training set' and applying the model in the 'test set' (Solanes et al., Neuroimage 2023, 265:119800). This simple R package estimates the accuracy of a multisite machine-learning model unbiasedly, as described in (Solanes et al., Psychiatry Research: Neuroimaging 2021, 314:111313). It currently supports the estimation of sensitivity, specificity, balanced accuracy (for binary or multinomial variables), the area under the curve, correlation, mean squarer error, and hazard ratio for binomial, multinomial, gaussian, and survival (time-to-event) outcomes.  "
  },
  {
    "id": 16612,
    "package_name": "multivator",
    "title": "A Multivariate Emulator",
    "description": "A multivariate generalization of the emulator package.",
    "version": "1.1-11",
    "maintainer": "Robin K. S. Hankin <hankin.robin@gmail.com>",
    "author": "Robin K. S. Hankin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5982-0415>)",
    "url": "https://github.com/RobinHankin/multivator",
    "bug_reports": "https://github.com/RobinHankin/multivator",
    "repository": "https://cran.r-project.org/package=multivator",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multivator A Multivariate Emulator A multivariate generalization of the emulator package.  "
  },
  {
    "id": 16636,
    "package_name": "mvDFA",
    "title": "Multivariate Detrended Fluctuation Analysis",
    "description": "This R package provides an implementation of multivariate extensions of a well-known fractal analysis technique, Detrended Fluctuations Analysis (DFA; Peng et al., 1995<doi:10.1063/1.166141>), for multivariate time series: multivariate DFA (mvDFA). Several coefficients are implemented that take into account the correlation structure of the multivariate time series to varying degrees. These coefficients may be used to analyze long memory and changes in the dynamic structure that would by univariate DFA. Therefore, this R package aims to extend and complement the original univariate DFA (Peng et al., 1995) for estimating the scaling properties of nonstationary time series.",
    "version": "0.0.4",
    "maintainer": "Julien Patrick Irmer <jirmer@psych.uni-frankfurt.de>",
    "author": "Julien Patrick Irmer [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7544-6483>),\n  Sebastian Wallot [aut, ctb]",
    "url": "https://github.com/jpirmer/mvDFA",
    "bug_reports": "https://github.com/jpirmer/mvDFA/issues",
    "repository": "https://cran.r-project.org/package=mvDFA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mvDFA Multivariate Detrended Fluctuation Analysis This R package provides an implementation of multivariate extensions of a well-known fractal analysis technique, Detrended Fluctuations Analysis (DFA; Peng et al., 1995<doi:10.1063/1.166141>), for multivariate time series: multivariate DFA (mvDFA). Several coefficients are implemented that take into account the correlation structure of the multivariate time series to varying degrees. These coefficients may be used to analyze long memory and changes in the dynamic structure that would by univariate DFA. Therefore, this R package aims to extend and complement the original univariate DFA (Peng et al., 1995) for estimating the scaling properties of nonstationary time series.  "
  },
  {
    "id": 16688,
    "package_name": "mwlaxeref",
    "title": "Cross-References Lake Identifiers Between Different Data Sets",
    "description": "Handy helper package for cross-referencing lake identifiers \n    among different data sets in the Midwestern United States. There are \n    multiple different state, regional, and federal agencies that have \n    different identifiers on lakes. This package helps you to go between them.",
    "version": "0.0.1",
    "maintainer": "Paul Frater <paul.frater@wisconsin.gov>",
    "author": "Paul Frater [aut, cre] (ORCID: <https://orcid.org/0000-0002-7237-6563>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mwlaxeref",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mwlaxeref Cross-References Lake Identifiers Between Different Data Sets Handy helper package for cross-referencing lake identifiers \n    among different data sets in the Midwestern United States. There are \n    multiple different state, regional, and federal agencies that have \n    different identifiers on lakes. This package helps you to go between them.  "
  },
  {
    "id": 16694,
    "package_name": "mxnorm",
    "title": "Apply Normalization Methods to Multiplexed Images",
    "description": "Implements methods to normalize multiplexed imaging data, including\n    statistical metrics and visualizations to quantify technical variation in \n    this data type. Reference for methods listed here: Harris, C., Wrobel, J., \n    & Vandekar, S. (2022). mxnorm: An R Package to Normalize Multiplexed Imaging \n    Data. Journal of Open Source Software, 7(71), 4180, \n    <doi:10.21105/joss.04180>.",
    "version": "1.1.0",
    "maintainer": "Coleman Harris <coleman.r.harris@vanderbilt.edu>",
    "author": "Coleman Harris [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6325-0694>)",
    "url": "https://github.com/ColemanRHarris/mxnorm",
    "bug_reports": "https://github.com/ColemanRHarris/mxnorm/issues",
    "repository": "https://cran.r-project.org/package=mxnorm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mxnorm Apply Normalization Methods to Multiplexed Images Implements methods to normalize multiplexed imaging data, including\n    statistical metrics and visualizations to quantify technical variation in \n    this data type. Reference for methods listed here: Harris, C., Wrobel, J., \n    & Vandekar, S. (2022). mxnorm: An R Package to Normalize Multiplexed Imaging \n    Data. Journal of Open Source Software, 7(71), 4180, \n    <doi:10.21105/joss.04180>.  "
  },
  {
    "id": 16696,
    "package_name": "myCRAN",
    "title": "Graph of Daily and Cumulative Downloads of your Packages",
    "description": "Plot the daily and cumulative number of downloads of your packages.\n    It is designed to be slightly more convenient than the several similar programs. If you want to run this each morning,\n    you do not need to keep typing in the names of your packages. Also, this combines the daily and cumulative counts in one\n    run, you do not need to run separate programs to get both types of information.",
    "version": "1.3",
    "maintainer": "Barry Zeeberg <barryz2013@gmail.com>",
    "author": "Barry Zeeberg [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=myCRAN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "myCRAN Graph of Daily and Cumulative Downloads of your Packages Plot the daily and cumulative number of downloads of your packages.\n    It is designed to be slightly more convenient than the several similar programs. If you want to run this each morning,\n    you do not need to keep typing in the names of your packages. Also, this combines the daily and cumulative counts in one\n    run, you do not need to run separate programs to get both types of information.  "
  },
  {
    "id": 16700,
    "package_name": "mycobacrvR",
    "title": "Integrative Immunoinformatics for Mycobacterial Diseases in R\nPlatform",
    "description": "The mycobacrvR package contains utilities to provide detailed information for B cell and T cell epitopes for predicted adhesins from various servers such as ABCpred, Bcepred, Bimas, Propred, NetMHC and IEDB. Please refer the URL below to download data files (data_mycobacrvR.zip) used in functions of this package.",
    "version": "1.1",
    "maintainer": "S. Ramachandran<ramu@igib.in>",
    "author": "Deepika Kulshreshtha, Rupanjali Chaudhuri, Surabhi Seth, S. Ramachandran",
    "url": "https://mycobacteriarv.igib.res.in/download.html",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mycobacrvR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mycobacrvR Integrative Immunoinformatics for Mycobacterial Diseases in R\nPlatform The mycobacrvR package contains utilities to provide detailed information for B cell and T cell epitopes for predicted adhesins from various servers such as ABCpred, Bcepred, Bimas, Propred, NetMHC and IEDB. Please refer the URL below to download data files (data_mycobacrvR.zip) used in functions of this package.  "
  },
  {
    "id": 16713,
    "package_name": "nadiv",
    "title": "(Non)Additive Genetic Relatedness Matrices",
    "description": "Constructs (non)additive genetic relationship matrices, and their\n    inverses, from a pedigree to be used in linear mixed effect models (A.K.A.\n    the 'animal model'). Also includes other functions to facilitate the use of\n    animal models. Some functions have been created to be used in conjunction\n    with the R package 'asreml' for the 'ASReml' software, which can be\n    obtained upon purchase from 'VSN' international \n    (<https://vsni.co.uk/software/asreml>).",
    "version": "2.18.0",
    "maintainer": "Matthew Wolak <matthewwolak@gmail.com>",
    "author": "Matthew Wolak [cre, aut]",
    "url": "https://github.com/matthewwolak/nadiv",
    "bug_reports": "https://github.com/matthewwolak/nadiv/issues",
    "repository": "https://cran.r-project.org/package=nadiv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nadiv (Non)Additive Genetic Relatedness Matrices Constructs (non)additive genetic relationship matrices, and their\n    inverses, from a pedigree to be used in linear mixed effect models (A.K.A.\n    the 'animal model'). Also includes other functions to facilitate the use of\n    animal models. Some functions have been created to be used in conjunction\n    with the R package 'asreml' for the 'ASReml' software, which can be\n    obtained upon purchase from 'VSN' international \n    (<https://vsni.co.uk/software/asreml>).  "
  },
  {
    "id": 16720,
    "package_name": "namedropR",
    "title": "Create Visual Citations for Presentations and Posters",
    "description": "Provides 'visual citations' containing the metadata of a\n    scientific paper and a 'QR' code.  A 'visual citation' is a banner\n    containing title, authors, journal and year of a publication.  This\n    package can create such banners based on 'BibTeX' and 'BibLaTeX'\n    references or call the reference metadata from 'Crossref'-API. The\n    banners include a QR code pointing to the 'DOI'.  The resulting HTML\n    object or PNG image can be included in a presentation to point the\n    audience to good resources for further reading.  Styling is possible\n    via predefined designs or via custom 'CSS'.  This package is not\n    intended as replacement for proper reference manager packages, but a\n    tool to enrich scientific presentation slides and conference posters.",
    "version": "2.4.1",
    "maintainer": "Christian A. Gebhard <christian.gebhard@posteo.de>",
    "author": "Christian A. Gebhard [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8792-565X>),\n  Lukas Wallrich [ctb] (ORCID: <https://orcid.org/0000-0003-2121-5177>),\n  Matthew T. Warkentin [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8730-3511>)",
    "url": "https://github.com/nucleic-acid/namedropR",
    "bug_reports": "https://github.com/nucleic-acid/namedropR/issues",
    "repository": "https://cran.r-project.org/package=namedropR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "namedropR Create Visual Citations for Presentations and Posters Provides 'visual citations' containing the metadata of a\n    scientific paper and a 'QR' code.  A 'visual citation' is a banner\n    containing title, authors, journal and year of a publication.  This\n    package can create such banners based on 'BibTeX' and 'BibLaTeX'\n    references or call the reference metadata from 'Crossref'-API. The\n    banners include a QR code pointing to the 'DOI'.  The resulting HTML\n    object or PNG image can be included in a presentation to point the\n    audience to good resources for further reading.  Styling is possible\n    via predefined designs or via custom 'CSS'.  This package is not\n    intended as replacement for proper reference manager packages, but a\n    tool to enrich scientific presentation slides and conference posters.  "
  },
  {
    "id": 16744,
    "package_name": "natmanager",
    "title": "Install the 'Natverse' Packages from Scratch",
    "description": "Provides streamlined installation for packages from the 'natverse',\n    a suite of R packages for computational neuroanatomy built on top of the\n    'nat' 'NeuroAnatomy Toolbox' package. Installation of the complete\n    'natverse' suite requires a 'GitHub' user account and personal access token\n    'GITHUB_PAT'. 'natmanager' will help the end user set this up if necessary.",
    "version": "0.5.2",
    "maintainer": "Gregory Jefferis <jefferis@gmail.com>",
    "author": "Sridhar Jagannathan [aut] (ORCID:\n    <https://orcid.org/0000-0002-2078-1145>),\n  Gregory Jefferis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0587-9355>)",
    "url": "https://github.com/natverse/natmanager,\nhttp://natverse.org/natmanager/",
    "bug_reports": "https://github.com/natverse/natmanager/issues",
    "repository": "https://cran.r-project.org/package=natmanager",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "natmanager Install the 'Natverse' Packages from Scratch Provides streamlined installation for packages from the 'natverse',\n    a suite of R packages for computational neuroanatomy built on top of the\n    'nat' 'NeuroAnatomy Toolbox' package. Installation of the complete\n    'natverse' suite requires a 'GitHub' user account and personal access token\n    'GITHUB_PAT'. 'natmanager' will help the end user set this up if necessary.  "
  },
  {
    "id": 16784,
    "package_name": "neatStats",
    "title": "Neat and Painless Statistical Reporting",
    "description": "User-friendly, clear and simple statistics, primarily for\n  publication in psychological science. The main functions are wrappers for\n  other packages, but there are various additions as well. Every relevant step\n  from data aggregation to reportable printed statistics is covered for basic\n  experimental designs.",
    "version": "1.13.5",
    "maintainer": "G\u00e1sp\u00e1r Luk\u00e1cs <lkcsgaspar@gmail.com>",
    "author": "G\u00e1sp\u00e1r Luk\u00e1cs [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9401-4830>),\n  Bennett Kleinberg [ctb] (ORCID:\n    <https://orcid.org/0000-0003-1658-9086>),\n  Johnny van Doorn [ctb] (ORCID: <https://orcid.org/0000-0003-0270-096X>)",
    "url": "https://github.com/gasparl/neatstats",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=neatStats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "neatStats Neat and Painless Statistical Reporting User-friendly, clear and simple statistics, primarily for\n  publication in psychological science. The main functions are wrappers for\n  other packages, but there are various additions as well. Every relevant step\n  from data aggregation to reportable printed statistics is covered for basic\n  experimental designs.  "
  },
  {
    "id": 16788,
    "package_name": "needs",
    "title": "Attaches and Installs Packages",
    "description": "A simple function for easier package loading and auto-installation.",
    "version": "0.0.3",
    "maintainer": "Josh Katz <josh.katz@nytimes.com>",
    "author": "Josh Katz [aut, cre]",
    "url": "https://github.com/joshkatz/needs",
    "bug_reports": "https://github.com/joshkatz/needs/issues",
    "repository": "https://cran.r-project.org/package=needs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "needs Attaches and Installs Packages A simple function for easier package loading and auto-installation.  "
  },
  {
    "id": 16825,
    "package_name": "netgwas",
    "title": "Network-Based Genome Wide Association Studies",
    "description": "A multi-core R package that contains a set of tools based on copula graphical\n             models for accomplishing the three interrelated goals in genetics and genomics in an\n\t\t\t unified way: (1) linkage map construction, (2) constructing linkage disequilibrium\n\t\t\t networks, and (3) exploring high-dimensional genotype-phenotype network and genotype-\n\t\t\t phenotype-environment interactions networks. \n\t\t\t The 'netgwas' package can deal with biparental inbreeding and outbreeding species with\n\t\t\t any ploidy level, namely diploid (2 sets of chromosomes), triploid (3 sets of chromosomes),\n\t\t\t tetraploid (4 sets of chromosomes) and so on. We target on high-dimensional data where \n\t\t\t number of variables p is considerably larger than number of sample sizes (p >> n). \n\t\t\t The computations is memory-optimized using the sparse matrix output. The 'netgwas' \n\t\t\t implements the methodological developments in Behrouzi and Wit (2017)\n             <doi:10.1111/rssc.12287> and Behrouzi and Wit (2017) <doi:10.1093/bioinformatics/bty777>. ",
    "version": "1.14.4",
    "maintainer": "Pariya Behrouzi <pariya.behrouzi@gmail.com>",
    "author": "Pariya Behrouzi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6762-5433>),\n  Ernst C. Wit [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=netgwas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netgwas Network-Based Genome Wide Association Studies A multi-core R package that contains a set of tools based on copula graphical\n             models for accomplishing the three interrelated goals in genetics and genomics in an\n\t\t\t unified way: (1) linkage map construction, (2) constructing linkage disequilibrium\n\t\t\t networks, and (3) exploring high-dimensional genotype-phenotype network and genotype-\n\t\t\t phenotype-environment interactions networks. \n\t\t\t The 'netgwas' package can deal with biparental inbreeding and outbreeding species with\n\t\t\t any ploidy level, namely diploid (2 sets of chromosomes), triploid (3 sets of chromosomes),\n\t\t\t tetraploid (4 sets of chromosomes) and so on. We target on high-dimensional data where \n\t\t\t number of variables p is considerably larger than number of sample sizes (p >> n). \n\t\t\t The computations is memory-optimized using the sparse matrix output. The 'netgwas' \n\t\t\t implements the methodological developments in Behrouzi and Wit (2017)\n             <doi:10.1111/rssc.12287> and Behrouzi and Wit (2017) <doi:10.1093/bioinformatics/bty777>.   "
  },
  {
    "id": 16871,
    "package_name": "neverhpfilter",
    "title": "An Alternative to the Hodrick-Prescott Filter",
    "description": "In the working paper titled \"Why You Should Never Use the Hodrick-Prescott Filter\", James D. Hamilton proposes a new alternative to economic time series filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.",
    "version": "0.5-0",
    "maintainer": "Justin M. Shea <jshea01@uic.edu>",
    "author": "Justin M. Shea [aut, cre]",
    "url": "https://justinmshea.github.io/neverhpfilter/",
    "bug_reports": "https://github.com/JustinMShea/neverhpfilter/issues",
    "repository": "https://cran.r-project.org/package=neverhpfilter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "neverhpfilter An Alternative to the Hodrick-Prescott Filter In the working paper titled \"Why You Should Never Use the Hodrick-Prescott Filter\", James D. Hamilton proposes a new alternative to economic time series filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.  "
  },
  {
    "id": 16872,
    "package_name": "new.dist",
    "title": "Alternative Continuous and Discrete Distributions",
    "description": "The aim is to develop an R package, which is the 'new.dist'\n    package, for the probability (density) function, the\n    distribution function, the quantile function and the\n    associated random number generation function for discrete and\n    continuous distributions, which have recently been proposed\n    in the literature. This package implements the following\n    distributions: The Power Muth Distribution, a Bimodal Weibull\n    Distribution, the Discrete Lindley Distribution, The\n    Gamma-Lomax Distribution, Weighted Geometric Distribution, a\n    Power Log-Dagum Distribution, Kumaraswamy Distribution,\n    Lindley Distribution, the Unit-Inverse Gaussian Distribution,\n    EP Distribution, Akash Distribution, Ishita Distribution,\n    Maxwell Distribution, the Standard Omega Distribution,\n    Slashed Generalized Rayleigh Distribution, Two-Parameter\n    Rayleigh Distribution, Muth Distribution, Uniform-Geometric\n    Distribution, Discrete Weibull Distribution.",
    "version": "0.1.1",
    "maintainer": "Ramazan Akman <ramazanakman12345@gmail.com>",
    "author": "Ramazan Akman [cre, ctb]\n    (https://www.researchgate.net/profile/Ramazan-Akman),\n  Co\u015fkun Ku\u015f [aut, ctb] (https://www.selcuk.edu.tr/Person/Detail/coskun),\n  Ihab Abusaif [aut, ctb]\n    (https://www.researchgate.net/profile/Ihab-Abusaif)",
    "url": "https://github.com/akmn35/new.dist,\nhttps://akmn35.github.io/new.dist/",
    "bug_reports": "https://github.com/akmn35/new.dist/issues",
    "repository": "https://cran.r-project.org/package=new.dist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "new.dist Alternative Continuous and Discrete Distributions The aim is to develop an R package, which is the 'new.dist'\n    package, for the probability (density) function, the\n    distribution function, the quantile function and the\n    associated random number generation function for discrete and\n    continuous distributions, which have recently been proposed\n    in the literature. This package implements the following\n    distributions: The Power Muth Distribution, a Bimodal Weibull\n    Distribution, the Discrete Lindley Distribution, The\n    Gamma-Lomax Distribution, Weighted Geometric Distribution, a\n    Power Log-Dagum Distribution, Kumaraswamy Distribution,\n    Lindley Distribution, the Unit-Inverse Gaussian Distribution,\n    EP Distribution, Akash Distribution, Ishita Distribution,\n    Maxwell Distribution, the Standard Omega Distribution,\n    Slashed Generalized Rayleigh Distribution, Two-Parameter\n    Rayleigh Distribution, Muth Distribution, Uniform-Geometric\n    Distribution, Discrete Weibull Distribution.  "
  },
  {
    "id": 16968,
    "package_name": "nlstac",
    "title": "An R Package for Fitting Separable Nonlinear Models",
    "description": "Set of functions implementing the algorithm described in Fernandez \n    Torvisco et al. (2018) for fitting separable nonlinear regression curves. \n    See Fernandez Torvisco, Rodriguez-Arias Fernandez and Cabello Sanchez (2018)\n    <doi:10.2298/FIL1812233T>. ",
    "version": "0.2.0",
    "maintainer": "Rafael Benitez <rabesua@uv.es>",
    "author": "Mariano Rodriguez-Arias <arias@unex.es>, Juan Antonio Fernandez <jfernandck@alumnos.unex.es>, Javier Cabello <coco@unex.es>, Rafael Benitez <rabesua@uv.es>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nlstac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nlstac An R Package for Fitting Separable Nonlinear Models Set of functions implementing the algorithm described in Fernandez \n    Torvisco et al. (2018) for fitting separable nonlinear regression curves. \n    See Fernandez Torvisco, Rodriguez-Arias Fernandez and Cabello Sanchez (2018)\n    <doi:10.2298/FIL1812233T>.   "
  },
  {
    "id": 17048,
    "package_name": "normalr",
    "title": "Normalisation of Multiple Variables in Large-Scale Datasets",
    "description": "The robustness of many of the statistical techniques, such as factor analysis, applied in \n          the social sciences rests upon the assumption of item-level normality. However, when dealing \n          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)\n          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for \n          large datasets of continuous variables, its application in current software programs is cumbersome\n          with analysts having to take several steps to normalise each variable. We present an R package \n          'normalr' that enables researchers to make convenient optimal transformations of multiple variables\n          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their \n          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, \n          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their \n          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, \n          kurtosis, and other inferential assessments of normality.",
    "version": "1.0.0",
    "maintainer": "Kevin Chang <k.chang@auckland.ac.nz>",
    "author": "Kevin Chang [aut, cre],\n  Matthew Courtney [aut]",
    "url": "https://github.com/kcha193/normalr",
    "bug_reports": "https://github.com/kcha193/normalr/issues",
    "repository": "https://cran.r-project.org/package=normalr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "normalr Normalisation of Multiple Variables in Large-Scale Datasets The robustness of many of the statistical techniques, such as factor analysis, applied in \n          the social sciences rests upon the assumption of item-level normality. However, when dealing \n          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)\n          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for \n          large datasets of continuous variables, its application in current software programs is cumbersome\n          with analysts having to take several steps to normalise each variable. We present an R package \n          'normalr' that enables researchers to make convenient optimal transformations of multiple variables\n          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their \n          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, \n          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their \n          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, \n          kurtosis, and other inferential assessments of normality.  "
  },
  {
    "id": 17109,
    "package_name": "npsurvSS",
    "title": "Sample Size and Power Calculation for Common Non-Parametric\nTests in Survival Analysis",
    "description": "A number of statistical tests have been proposed to compare two \n  survival curves, including the difference in (or ratio of) t-year \n  survival, difference in (or ratio of) p-th percentile survival, difference in\n  (or ratio of) restricted mean survival time, and the weighted log-rank test. \n  Despite the multitude of options, the convention in survival studies is to assume\n  proportional hazards and to use the unweighted log-rank test for design and \n  analysis. This package provides sample size and power \n  calculation for all of the above statistical tests with allowance for \n  flexible accrual, censoring, and survival (eg. Weibull, piecewise-exponential, \n  mixture cure). It is the companion R package to the paper by Yung and Liu (2020)\n  <doi:10.1111/biom.13196>. Specific to the weighted log-rank test, users may \n  specify which approximations they wish to use to estimate the large-sample mean \n  and variance. The default option has been shown to provide substantial\n  improvement over the conventional sample size and power equations based on Schoenfeld \n  (1981) <doi:10.1093/biomet/68.1.316>.",
    "version": "1.1.0",
    "maintainer": "Godwin Yung <godwin.y.yung@gmail.com>",
    "author": "Godwin Yung [aut, cre],\n  Yi Liu [aut]",
    "url": "https://github.com/godwinyyung/npsurvSS",
    "bug_reports": "https://github.com/godwinyyung/npsurvSS/issues",
    "repository": "https://cran.r-project.org/package=npsurvSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "npsurvSS Sample Size and Power Calculation for Common Non-Parametric\nTests in Survival Analysis A number of statistical tests have been proposed to compare two \n  survival curves, including the difference in (or ratio of) t-year \n  survival, difference in (or ratio of) p-th percentile survival, difference in\n  (or ratio of) restricted mean survival time, and the weighted log-rank test. \n  Despite the multitude of options, the convention in survival studies is to assume\n  proportional hazards and to use the unweighted log-rank test for design and \n  analysis. This package provides sample size and power \n  calculation for all of the above statistical tests with allowance for \n  flexible accrual, censoring, and survival (eg. Weibull, piecewise-exponential, \n  mixture cure). It is the companion R package to the paper by Yung and Liu (2020)\n  <doi:10.1111/biom.13196>. Specific to the weighted log-rank test, users may \n  specify which approximations they wish to use to estimate the large-sample mean \n  and variance. The default option has been shown to provide substantial\n  improvement over the conventional sample size and power equations based on Schoenfeld \n  (1981) <doi:10.1093/biomet/68.1.316>.  "
  },
  {
    "id": 17163,
    "package_name": "obcost",
    "title": "Obesity Cost Database",
    "description": "This database contains necessary data relevant to medical costs on obesity throughout the United States. This database, in form of an R package, could output necessary data frames relevant to obesity costs, where the clients could easily manipulate the output using difference parameters, e.g. relative risks for each illnesses. This package contributes to parts of our published journal named \"Modeling the Economic Cost of Obesity Risk and Its Relation to the Health Insurance Premium in the United States: A State Level Analysis\". Please use the following citation for the journal: Woods Thomas, Tatjana Miljkovic (2022) \"Modeling the Economic Cost of Obesity Risk and Its Relation to the Health Insurance Premium in the United States: A State Level Analysis\" <doi:10.3390/risks10100197>. The database is composed of the following main tables: 1. Relative_Risks: (constant) Relative risks for a given disease group with a risk factor of obesity; 2. Disease_Cost: (obesity_cost_disease) Supplementary output with all variables related to individual disease groups in a given state and year; 3. Full_Cost: (obesity_cost_full) Complete output with all variables used to make cost calculations, as well as cost calculations in a given state and year; 4. National_Summary: (obesity_cost_national_summary) National summary cost calculations in a given year. Three functions are included to assist users in calling and adjusting the mentioned tables and they are data_load(), data_produce(), and rel_risk_fun(). ",
    "version": "0.1.0",
    "maintainer": "Tianyue Zang <zangt2@miamioh.edu>",
    "author": "Tianyue Zang [aut, cre, cph],\n  Thomas Woods [aut],\n  Tatjana Miljkovic [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=obcost",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "obcost Obesity Cost Database This database contains necessary data relevant to medical costs on obesity throughout the United States. This database, in form of an R package, could output necessary data frames relevant to obesity costs, where the clients could easily manipulate the output using difference parameters, e.g. relative risks for each illnesses. This package contributes to parts of our published journal named \"Modeling the Economic Cost of Obesity Risk and Its Relation to the Health Insurance Premium in the United States: A State Level Analysis\". Please use the following citation for the journal: Woods Thomas, Tatjana Miljkovic (2022) \"Modeling the Economic Cost of Obesity Risk and Its Relation to the Health Insurance Premium in the United States: A State Level Analysis\" <doi:10.3390/risks10100197>. The database is composed of the following main tables: 1. Relative_Risks: (constant) Relative risks for a given disease group with a risk factor of obesity; 2. Disease_Cost: (obesity_cost_disease) Supplementary output with all variables related to individual disease groups in a given state and year; 3. Full_Cost: (obesity_cost_full) Complete output with all variables used to make cost calculations, as well as cost calculations in a given state and year; 4. National_Summary: (obesity_cost_national_summary) National summary cost calculations in a given year. Three functions are included to assist users in calling and adjusting the mentioned tables and they are data_load(), data_produce(), and rel_risk_fun().   "
  },
  {
    "id": 17239,
    "package_name": "omock",
    "title": "Creation of Mock Observational Medical Outcomes Partnership\nCommon Data Model",
    "description": "Creates mock data for testing and package development for the\n    Observational Medical Outcomes Partnership common data model. The\n    package offers functions crafted with pipeline-friendly\n    implementation, enabling users to effortlessly include only the\n    necessary tables for their testing needs.",
    "version": "0.6.0",
    "maintainer": "Mike Du <mike.du@ndorms.ox.ac.uk>",
    "author": "Mike Du [aut, cre] (ORCID: <https://orcid.org/0000-0002-9517-8834>),\n  Mart\u00ed Catal\u00e0 [aut] (ORCID: <https://orcid.org/0000-0003-3308-9905>),\n  Edward Burn [aut] (ORCID: <https://orcid.org/0000-0002-9286-1128>),\n  Nuria Mercade-Besora [aut] (ORCID:\n    <https://orcid.org/0009-0006-7948-3747>),\n  Xihang Chen [aut] (ORCID: <https://orcid.org/0009-0001-8112-8959>)",
    "url": "https://ohdsi.github.io/omock/, https://github.com/ohdsi/omock",
    "bug_reports": "https://github.com/ohdsi/omock/issues",
    "repository": "https://cran.r-project.org/package=omock",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "omock Creation of Mock Observational Medical Outcomes Partnership\nCommon Data Model Creates mock data for testing and package development for the\n    Observational Medical Outcomes Partnership common data model. The\n    package offers functions crafted with pipeline-friendly\n    implementation, enabling users to effortlessly include only the\n    necessary tables for their testing needs.  "
  },
  {
    "id": 17250,
    "package_name": "oncmap",
    "title": "Analyze Data from Electronic Adherence Monitoring Devices",
    "description": "Medication adherence, defined as medication-taking behavior that aligns with the agreed-upon \n    treatment protocol, is critical for realizing the benefits of prescription medications. \n    Medication adherence can be assessed using electronic adherence monitoring devices (EAMDs), \n    pill bottles or boxes that contain a computer chip that records the date and time of each \n    opening (or \u201cactuation\u201d). Before researchers can use EAMD data, they must apply a series of \n    decision rules to transform actuation data into adherence data. \n    The purpose of this R package ('oncmap') is to transform EAMD actuations in the form of a raw .csv file, \n    information about the patient, regimen, and non-monitored periods into two daily adherence values -- \n    Dose Taken and Correct Dose Taken.",
    "version": "0.1.7",
    "maintainer": "Michal Kouril <Michal.Kouril@cchmc.org>",
    "author": "Michal Kouril [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4786-7934>),\n  Meghan McGrady [aut] (ORCID: <https://orcid.org/0000-0002-3150-3239>),\n  Mara Constance [aut] (ORCID: <https://orcid.org/0000-0002-6776-8060>),\n  Kevin Hommel [aut] (ORCID: <https://orcid.org/0000-0002-9913-509X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=oncmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oncmap Analyze Data from Electronic Adherence Monitoring Devices Medication adherence, defined as medication-taking behavior that aligns with the agreed-upon \n    treatment protocol, is critical for realizing the benefits of prescription medications. \n    Medication adherence can be assessed using electronic adherence monitoring devices (EAMDs), \n    pill bottles or boxes that contain a computer chip that records the date and time of each \n    opening (or \u201cactuation\u201d). Before researchers can use EAMD data, they must apply a series of \n    decision rules to transform actuation data into adherence data. \n    The purpose of this R package ('oncmap') is to transform EAMD actuations in the form of a raw .csv file, \n    information about the patient, regimen, and non-monitored periods into two daily adherence values -- \n    Dose Taken and Correct Dose Taken.  "
  },
  {
    "id": 17264,
    "package_name": "onlineforecast",
    "title": "Forecast Modelling for Online Applications",
    "description": "A framework for fitting adaptive forecasting models. Provides a way to use forecasts as input to models, e.g. weather forecasts for energy related forecasting. The models can be fitted recursively and can easily be setup for updating parameters when new data arrives. See the included vignettes, the website <https://onlineforecasting.org> and the paper \"onlineforecast: An R package for adaptive and recursive forecasting\" <https://journal.r-project.org/articles/RJ-2023-031/>.",
    "version": "1.0.2",
    "maintainer": "Peder Bacher <pbac@dtu.dk>",
    "author": "Peder Bacher [cre],\n  Hjorleifur G Bergsteinsson [aut]",
    "url": "https://onlineforecasting.org",
    "bug_reports": "https://lab.compute.dtu.dk/packages/onlineforecast/-/issues",
    "repository": "https://cran.r-project.org/package=onlineforecast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "onlineforecast Forecast Modelling for Online Applications A framework for fitting adaptive forecasting models. Provides a way to use forecasts as input to models, e.g. weather forecasts for energy related forecasting. The models can be fitted recursively and can easily be setup for updating parameters when new data arrives. See the included vignettes, the website <https://onlineforecasting.org> and the paper \"onlineforecast: An R package for adaptive and recursive forecasting\" <https://journal.r-project.org/articles/RJ-2023-031/>.  "
  },
  {
    "id": 17275,
    "package_name": "ontologyIndex",
    "title": "Reading Ontologies into R",
    "description": "Functions for reading ontologies into R as lists and manipulating sets of ontological terms - 'ontologyX: A suite of R packages for working with ontological data', Greene et al 2017 <doi:10.1093/bioinformatics/btw763>.",
    "version": "2.12",
    "maintainer": "Daniel Greene <dg333@cam.ac.uk>",
    "author": "Daniel Greene <dg333@cam.ac.uk>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ontologyIndex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ontologyIndex Reading Ontologies into R Functions for reading ontologies into R as lists and manipulating sets of ontological terms - 'ontologyX: A suite of R packages for working with ontological data', Greene et al 2017 <doi:10.1093/bioinformatics/btw763>.  "
  },
  {
    "id": 17329,
    "package_name": "optbdmaeAT",
    "title": "Optimal Block Designs for Two-Colour cDNA Microarray Experiments",
    "description": "Computes A-, MV-, D- and E-optimal or near-optimal block designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The algorithms used in this package are based on the treatment exchange and array exchange algorithms of Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617>. The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.",
    "version": "1.0.2",
    "maintainer": "Dibaba Bayisa Gemechu <diboobayu@gmail.com>",
    "author": "Dibaba Bayisa Gemechu [aut, cre],\n  Legesse Kassa Debusho [aut],\n  Linda Haines [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=optbdmaeAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optbdmaeAT Optimal Block Designs for Two-Colour cDNA Microarray Experiments Computes A-, MV-, D- and E-optimal or near-optimal block designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The algorithms used in this package are based on the treatment exchange and array exchange algorithms of Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617>. The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.  "
  },
  {
    "id": 17335,
    "package_name": "optiSolve",
    "title": "Linear, Quadratic, and Rational Optimization",
    "description": "Solver for linear, quadratic, and rational programs with linear, quadratic, and rational constraints. A unified interface to different R packages is provided. Optimization problems are transformed into equivalent formulations and solved by the respective package. For example, quadratic programming problems with linear, quadratic and rational constraints can be solved by augmented Lagrangian minimization using package 'alabama', or by sequential quadratic programming using solver 'slsqp'.  Alternatively, they can be reformulated as optimization problems with second order cone constraints and solved with package 'cccp'.",
    "version": "1.0",
    "maintainer": "Robin Wellmann <r.wellmann@uni-hohenheim.de>",
    "author": "Robin Wellmann",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=optiSolve",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optiSolve Linear, Quadratic, and Rational Optimization Solver for linear, quadratic, and rational programs with linear, quadratic, and rational constraints. A unified interface to different R packages is provided. Optimization problems are transformed into equivalent formulations and solved by the respective package. For example, quadratic programming problems with linear, quadratic and rational constraints can be solved by augmented Lagrangian minimization using package 'alabama', or by sequential quadratic programming using solver 'slsqp'.  Alternatively, they can be reformulated as optimization problems with second order cone constraints and solved with package 'cccp'.  "
  },
  {
    "id": 17340,
    "package_name": "optifunset",
    "title": "Set Options if Unset",
    "description": "A single function 'options.ifunset(...)' is contained herewith, which allows the user to set a global option ONLY if it is not already set. By this token, for package maintainers this function can be used in preference to the standard 'options(...)' function, making provision for THEIR end user to place 'options(...)' directives within their '.Rprofile' file, which will not be overridden at the point when a package is loaded.",
    "version": "1.0",
    "maintainer": "Nicholas Hamilton <n.hamilton@unsw.edu.au>",
    "author": "Nicholas Hamilton",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=optifunset",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optifunset Set Options if Unset A single function 'options.ifunset(...)' is contained herewith, which allows the user to set a global option ONLY if it is not already set. By this token, for package maintainers this function can be used in preference to the standard 'options(...)' function, making provision for THEIR end user to place 'options(...)' directives within their '.Rprofile' file, which will not be overridden at the point when a package is loaded.  "
  },
  {
    "id": 17364,
    "package_name": "optrcdmaeAT",
    "title": "Optimal Row-Column Designs for Two-Colour cDNA Microarray\nExperiments",
    "description": "Computes A-, MV-, D- and E-optimal or near-optimal row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all pairwise treatment contrasts. The algorithms used in this package are based on the array exchange and treatment exchange algorithms adopted from Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617> algorithms after adjusting for the row-column designs setup. The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.",
    "version": "1.0.1",
    "maintainer": "Dibaba Bayisa Gemechu <diboobayu@gmail.com>",
    "author": "Dibaba Bayisa Gemechu [aut, cre],\n  Legesse Kassa Debusho [aut],\n  Linda Haines [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=optrcdmaeAT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optrcdmaeAT Optimal Row-Column Designs for Two-Colour cDNA Microarray\nExperiments Computes A-, MV-, D- and E-optimal or near-optimal row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all pairwise treatment contrasts. The algorithms used in this package are based on the array exchange and treatment exchange algorithms adopted from Debusho, Gemechu and Haines (2018) <doi:10.1080/03610918.2018.1429617> algorithms after adjusting for the row-column designs setup. The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.  "
  },
  {
    "id": 17365,
    "package_name": "optrefine",
    "title": "Optimally Refine Strata",
    "description": "Splits initial strata into refined strata that optimize covariate balance. For more information, please email the author for a copy of the accompanying manuscript. To solve the linear program, the 'Gurobi' commercial optimization software is recommended, but not required. The 'gurobi' R package can be installed following the instructions at <https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html>.",
    "version": "1.1.0",
    "maintainer": "Katherine Brumberg <kbrum@wharton.upenn.edu>",
    "author": "Katherine Brumberg [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5193-6250>)",
    "url": "https://github.com/kkbrum/optrefine,\nhttps://kkbrum.github.io/optrefine/,\nhttps://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html",
    "bug_reports": "https://github.com/kkbrum/optrefine/issues",
    "repository": "https://cran.r-project.org/package=optrefine",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optrefine Optimally Refine Strata Splits initial strata into refined strata that optimize covariate balance. For more information, please email the author for a copy of the accompanying manuscript. To solve the linear program, the 'Gurobi' commercial optimization software is recommended, but not required. The 'gurobi' R package can be installed following the instructions at <https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html>.  "
  },
  {
    "id": 17374,
    "package_name": "ordbetareg",
    "title": "Ordered Beta Regression Models with 'brms'",
    "description": "Implements ordered beta regression models, which are for modeling continuous variables with upper and lower bounds, such as\n   survey sliders, dose-response relationships and indexes. For more information, see\n   Kubinec (2023) <doi:10.31235/osf.io/2sx6y>. The package is a front-end to the R package 'brms', which \n   facilitates a range of regression specifications, including hierarchical, dynamic and\n   multivariate modeling.",
    "version": "0.8",
    "maintainer": "Robert Kubinec <bobkubinec@gmail.com>",
    "author": "Robert Kubinec [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6655-4119>)",
    "url": "",
    "bug_reports": "https://github.com/saudiwin/ordbetareg_pack/issues",
    "repository": "https://cran.r-project.org/package=ordbetareg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ordbetareg Ordered Beta Regression Models with 'brms' Implements ordered beta regression models, which are for modeling continuous variables with upper and lower bounds, such as\n   survey sliders, dose-response relationships and indexes. For more information, see\n   Kubinec (2023) <doi:10.31235/osf.io/2sx6y>. The package is a front-end to the R package 'brms', which \n   facilitates a range of regression specifications, including hierarchical, dynamic and\n   multivariate modeling.  "
  },
  {
    "id": 17376,
    "package_name": "orderanalyzer",
    "title": "Extracting Order Position Tables from PDF-Based Order Documents",
    "description": "Functions for extracting text and tables from \n  PDF-based order documents. It provides an n-gram-based approach for identifying \n  the language of an order document. It furthermore uses R-package 'pdftools' to \n  extract the text from an order document. In the case that the PDF document is \n  only including an image (because it is scanned document), R package 'tesseract' \n  is used for OCR. Furthermore, the package provides functionality for identifying \n  and extracting order position tables in order documents based on a clustering approach.",
    "version": "1.0.0",
    "maintainer": "Michael Scholz <michael.scholz@th-deg.de>",
    "author": "Michael Scholz [cre, aut],\n  Joerg Bauer [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=orderanalyzer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "orderanalyzer Extracting Order Position Tables from PDF-Based Order Documents Functions for extracting text and tables from \n  PDF-based order documents. It provides an n-gram-based approach for identifying \n  the language of an order document. It furthermore uses R-package 'pdftools' to \n  extract the text from an order document. In the case that the PDF document is \n  only including an image (because it is scanned document), R package 'tesseract' \n  is used for OCR. Furthermore, the package provides functionality for identifying \n  and extracting order position tables in order documents based on a clustering approach.  "
  },
  {
    "id": 17403,
    "package_name": "origin",
    "title": "Explicitly Qualifying Namespaces by Automatically Adding 'pkg::'\nto Functions",
    "description": "Automatically adding 'pkg::' to a function, i.e. mutate()\n    becomes dplyr::mutate(). It is up to the user to determine which\n    packages should be used explicitly, whether to include base R packages\n    or use the functionality on selected text, a file, or a complete\n    directory. User friendly logging is provided in the 'RStudio' Markers\n    pane. Lives in the spirit of 'lintr' and 'styler'. Can also be used\n    for checking which packages are actually used in a project.",
    "version": "1.2.0",
    "maintainer": "Matthias Nistler <m_nistler@web.de>",
    "author": "Matthias Nistler [aut, cre]",
    "url": "https://github.com/mnist91/origin",
    "bug_reports": "https://github.com/mnist91/origin/issues",
    "repository": "https://cran.r-project.org/package=origin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "origin Explicitly Qualifying Namespaces by Automatically Adding 'pkg::'\nto Functions Automatically adding 'pkg::' to a function, i.e. mutate()\n    becomes dplyr::mutate(). It is up to the user to determine which\n    packages should be used explicitly, whether to include base R packages\n    or use the functionality on selected text, a file, or a complete\n    directory. User friendly logging is provided in the 'RStudio' Markers\n    pane. Lives in the spirit of 'lintr' and 'styler'. Can also be used\n    for checking which packages are actually used in a project.  "
  },
  {
    "id": 17426,
    "package_name": "osrm.backend",
    "title": "Bindings for 'Open Source Routing Machine'",
    "description": "Install and control 'Open Source Routing Machine' ('OSRM')\n    backend executables to prepare routing data and run/stop a local\n    'OSRM' server. For computations with the running server use the 'osrm'\n    R package (<https://cran.r-project.org/package=osrm>).",
    "version": "0.1.1",
    "maintainer": "Egor Kotov <kotov.egor@gmail.com>",
    "author": "Egor Kotov [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-6690-5345>)",
    "url": "https://github.com/e-kotov/osrm.backend,\nhttps://www.ekotov.pro/osrm.backend/",
    "bug_reports": "https://github.com/e-kotov/osrm.backend/issues",
    "repository": "https://cran.r-project.org/package=osrm.backend",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "osrm.backend Bindings for 'Open Source Routing Machine' Install and control 'Open Source Routing Machine' ('OSRM')\n    backend executables to prepare routing data and run/stop a local\n    'OSRM' server. For computations with the running server use the 'osrm'\n    R package (<https://cran.r-project.org/package=osrm>).  "
  },
  {
    "id": 17449,
    "package_name": "overdisp",
    "title": "Overdispersion in Count Data Multiple Regression Analysis",
    "description": "Detection of overdispersion in count data for multiple regression analysis.\n    Log-linear count data regression is one of the most popular techniques for predictive \n    modeling where there is a non-negative discrete quantitative dependent variable. In \n    order to ensure the inferences from the use of count data models are appropriate, \n    researchers may choose between the estimation of a Poisson model and a negative binomial\n    model, and the correct decision for prediction from a count data estimation is directly\n    linked to the existence of overdispersion of the dependent variable, conditional to the \n    explanatory variables. Based on the studies of Cameron and Trivedi (1990)\n    <doi:10.1016/0304-4076(90)90014-K> and Cameron and Trivedi (2013, ISBN:978-1107667273), \n    the overdisp() command is a contribution to researchers, providing a fast and secure \n    solution for the detection of overdispersion in count data. Another advantage is that \n    the installation of other packages is unnecessary, since the command runs in the basic \n    R language.",
    "version": "0.1.2",
    "maintainer": "Rafael Freitas Souza <fsrafael@usp.br>",
    "author": "Rafael Freitas Souza [cre],\n  Hamilton Luiz Correa [ctb],\n  A. Colin Cameron [aut],\n  Pravin Trivedi [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=overdisp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "overdisp Overdispersion in Count Data Multiple Regression Analysis Detection of overdispersion in count data for multiple regression analysis.\n    Log-linear count data regression is one of the most popular techniques for predictive \n    modeling where there is a non-negative discrete quantitative dependent variable. In \n    order to ensure the inferences from the use of count data models are appropriate, \n    researchers may choose between the estimation of a Poisson model and a negative binomial\n    model, and the correct decision for prediction from a count data estimation is directly\n    linked to the existence of overdispersion of the dependent variable, conditional to the \n    explanatory variables. Based on the studies of Cameron and Trivedi (1990)\n    <doi:10.1016/0304-4076(90)90014-K> and Cameron and Trivedi (2013, ISBN:978-1107667273), \n    the overdisp() command is a contribution to researchers, providing a fast and secure \n    solution for the detection of overdispersion in count data. Another advantage is that \n    the installation of other packages is unnecessary, since the command runs in the basic \n    R language.  "
  },
  {
    "id": 17463,
    "package_name": "oysteR",
    "title": "Scans R Projects for Vulnerable Third Party Dependencies",
    "description": "Collects a list of your third party R packages, and scans\n    them with the 'OSS' Index provided by 'Sonatype', reporting back on\n    any vulnerabilities that are found in the third party packages you\n    use.",
    "version": "0.1.4",
    "maintainer": "Colin Gillespie <csgillespie@gmail.com>",
    "author": "Jeffry Hesse [aut],\n  Brittany Belle [aut],\n  Colin Gillespie [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1787-0275>),\n  Dan Rollo [aut],\n  Josiah Parry [aut] (ORCID: <https://orcid.org/0000-0001-9910-865X>),\n  Sonatype [cph]",
    "url": "https://github.com/sonatype-nexus-community/oysteR",
    "bug_reports": "https://github.com/sonatype-nexus-community/oysteR/issues",
    "repository": "https://cran.r-project.org/package=oysteR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oysteR Scans R Projects for Vulnerable Third Party Dependencies Collects a list of your third party R packages, and scans\n    them with the 'OSS' Index provided by 'Sonatype', reporting back on\n    any vulnerabilities that are found in the third party packages you\n    use.  "
  },
  {
    "id": 17492,
    "package_name": "packageDiff",
    "title": "Compare R Package Differences",
    "description": "It provides utility functions for investigating changes within R\n    packages. The pkgInfo() function extracts package information such as\n    exported and non-exported functions as well as their arguments. The\n    pkgDiff() function compares this information for two versions of a package\n    and creates a diff file viewable in a browser.",
    "version": "0.1",
    "maintainer": "Cole Beck <cole.beck@vumc.org>",
    "author": "Cole Beck [aut, cre] (ORCID: <https://orcid.org/0000-0002-6849-6255>)",
    "url": "https://github.com/couthcommander/packageDiff",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=packageDiff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "packageDiff Compare R Package Differences It provides utility functions for investigating changes within R\n    packages. The pkgInfo() function extracts package information such as\n    exported and non-exported functions as well as their arguments. The\n    pkgDiff() function compares this information for two versions of a package\n    and creates a diff file viewable in a browser.  "
  },
  {
    "id": 17494,
    "package_name": "packagefinder",
    "title": "Comfortable Search for R Packages on CRAN, Either Directly from\nthe R Console or with an R Studio Add-in",
    "description": "Search for R packages on CRAN directly from the R console, based on the packages' titles, short and long descriptions, or other fields. Combine multiple keywords with logical operators ('and', 'or'), view detailed information on any package and keep track of the latest package contributions to CRAN. If you don't want to search from the R console, use the comfortable R Studio add-in.",
    "version": "0.3.5",
    "maintainer": "Joachim Zuckarelli <joachim@zuckarelli.de>",
    "author": "Joachim Zuckarelli [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9280-3016>)",
    "url": "https://github.com/jsugarelli/packagefinder/,\nhttp://www.zuckarelli.de/packagefinder/tutorial.html,\nhttps://youtu.be/B96NMSo3nJI",
    "bug_reports": "https://github.com/jsugarelli/packagefinder/issues",
    "repository": "https://cran.r-project.org/package=packagefinder",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "packagefinder Comfortable Search for R Packages on CRAN, Either Directly from\nthe R Console or with an R Studio Add-in Search for R packages on CRAN directly from the R console, based on the packages' titles, short and long descriptions, or other fields. Combine multiple keywords with logical operators ('and', 'or'), view detailed information on any package and keep track of the latest package contributions to CRAN. If you don't want to search from the R console, use the comfortable R Studio add-in.  "
  },
  {
    "id": 17495,
    "package_name": "packagepal",
    "title": "Guidelines and Checklists for Building CRAN-Worthy Packages",
    "description": "Provides essential checklists for R package developers, whether\n    you're creating your first package or beginning a new project. This tool\n    guides you through each step of the development process, including specific\n    considerations for submitting your package to the Comprehensive R Archive\n    Network (CRAN). Simplify your workflow and ensure adherence to best\n    practices with 'packagepal'.",
    "version": "0.1.0",
    "maintainer": "Lee Durbin <l.d.durbin@gmail.com>",
    "author": "Lee Durbin [aut, cre, cph]",
    "url": "https://github.com/lddurbin/packagepal",
    "bug_reports": "https://github.com/lddurbin/packagepal/issues",
    "repository": "https://cran.r-project.org/package=packagepal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "packagepal Guidelines and Checklists for Building CRAN-Worthy Packages Provides essential checklists for R package developers, whether\n    you're creating your first package or beginning a new project. This tool\n    guides you through each step of the development process, including specific\n    considerations for submitting your package to the Comprehensive R Archive\n    Network (CRAN). Simplify your workflow and ensure adherence to best\n    practices with 'packagepal'.  "
  },
  {
    "id": 17496,
    "package_name": "packager",
    "title": "Create, Build and Maintain Packages",
    "description": "Helper functions for package creation, building and\n    maintenance. Designed to work with a build system such as 'GNU make' or\n    package 'fakemake' to help you to conditionally work through the stages of\n    package development (such as spell checking, linting, testing, before\n    building and checking a package).",
    "version": "1.15.3",
    "maintainer": "Andreas Dominik Cullmann <fvafrcu@mailbox.org>",
    "author": "Andreas Dominik Cullmann [aut, cre]",
    "url": "https://gitlab.com/fvafrcu/packager",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=packager",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "packager Create, Build and Maintain Packages Helper functions for package creation, building and\n    maintenance. Designed to work with a build system such as 'GNU make' or\n    package 'fakemake' to help you to conditionally work through the stages of\n    package development (such as spell checking, linting, testing, before\n    building and checking a package).  "
  },
  {
    "id": 17502,
    "package_name": "pacs",
    "title": "Supplementary Tools for R Packages Developers",
    "description": "\n  Supplementary utils for CRAN maintainers and R packages developers.\n  Validating the library, packages and lock files.\n  Exploring a complexity of a specific package like evaluating its size in bytes with all dependencies.\n  The shiny app complexity could be explored too.\n  Assessing the life duration of a specific package version.\n  Checking a CRAN package check page status for any errors and warnings.\n  Retrieving a DESCRIPTION or NAMESPACE file for any package version. \n  Comparing DESCRIPTION or NAMESPACE files between different package versions.\n  Getting a list of all releases for a specific package.\n  The Bioconductor is partly supported.",
    "version": "0.6.0",
    "maintainer": "Maciej Nasinski <nasinski.maciej@gmail.com>",
    "author": "Maciej Nasinski [aut, cre]",
    "url": "https://github.com/Polkas/pacs, https://polkas.github.io/pacs/",
    "bug_reports": "https://github.com/Polkas/pacs/issues",
    "repository": "https://cran.r-project.org/package=pacs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pacs Supplementary Tools for R Packages Developers \n  Supplementary utils for CRAN maintainers and R packages developers.\n  Validating the library, packages and lock files.\n  Exploring a complexity of a specific package like evaluating its size in bytes with all dependencies.\n  The shiny app complexity could be explored too.\n  Assessing the life duration of a specific package version.\n  Checking a CRAN package check page status for any errors and warnings.\n  Retrieving a DESCRIPTION or NAMESPACE file for any package version. \n  Comparing DESCRIPTION or NAMESPACE files between different package versions.\n  Getting a list of all releases for a specific package.\n  The Bioconductor is partly supported.  "
  },
  {
    "id": 17538,
    "package_name": "palinsol",
    "title": "Insolation for Palaeoclimate Studies",
    "description": "R package to compute Incoming Solar Radiation (insolation) for palaeoclimate studies. Features three solutions: Berger (1978), Berger and Loutre (1991) and Laskar et al. (2004). Computes daily-mean, season-averaged and annual means and for all latitudes, and polar night dates.",
    "version": "1.0",
    "maintainer": "Michel Crucifix <michel.crucifix@uclouvain.be>",
    "author": "Michel Crucifix [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3437-4911>)",
    "url": "https://github.com/mcrucifix/palinsol",
    "bug_reports": "https://github.com/mcrucifix/palinsol/issues",
    "repository": "https://cran.r-project.org/package=palinsol",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "palinsol Insolation for Palaeoclimate Studies R package to compute Incoming Solar Radiation (insolation) for palaeoclimate studies. Features three solutions: Berger (1978), Berger and Loutre (1991) and Laskar et al. (2004). Computes daily-mean, season-averaged and annual means and for all latitudes, and polar night dates.  "
  },
  {
    "id": 17573,
    "package_name": "parallelDist",
    "title": "Parallel Distance Matrix Computation using Multiple Threads",
    "description": "A fast parallelized alternative to R's native 'dist' function to\n    calculate distance matrices for continuous, binary, and multi-dimensional\n    input matrices, which supports a broad variety of 41 predefined distance\n    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-\n    defined functions written in C++. For ease of use, the 'parDist' function\n    extends the signature of the 'dist' function and uses the same parameter\n    naming conventions as distance methods of existing R packages. The package\n    is mainly implemented in C++ and leverages the 'RcppParallel' package to\n    parallelize the distance computations with the help of the 'TinyThread'\n    library. Furthermore, the 'Armadillo' linear algebra library is used for\n    optimized matrix operations during distance calculations. The curiously\n    recurring template pattern (CRTP) technique is applied to avoid virtual\n    functions, which improves the Dynamic Time Warping calculations while\n    the implementation stays flexible enough to support different DTW step\n    patterns and normalization methods.",
    "version": "0.2.7",
    "maintainer": "Alexander Eckert <info@alexandereckert.com>",
    "author": "Alexander Eckert [aut, cre],\n  Lucas Godoy [ctb],\n  Srikanth KS [ctb]",
    "url": "https://github.com/alexeckert/parallelDist,\nhttps://www.alexandereckert.com/projects/#r-packages",
    "bug_reports": "https://github.com/alexeckert/parallelDist/issues",
    "repository": "https://cran.r-project.org/package=parallelDist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "parallelDist Parallel Distance Matrix Computation using Multiple Threads A fast parallelized alternative to R's native 'dist' function to\n    calculate distance matrices for continuous, binary, and multi-dimensional\n    input matrices, which supports a broad variety of 41 predefined distance\n    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-\n    defined functions written in C++. For ease of use, the 'parDist' function\n    extends the signature of the 'dist' function and uses the same parameter\n    naming conventions as distance methods of existing R packages. The package\n    is mainly implemented in C++ and leverages the 'RcppParallel' package to\n    parallelize the distance computations with the help of the 'TinyThread'\n    library. Furthermore, the 'Armadillo' linear algebra library is used for\n    optimized matrix operations during distance calculations. The curiously\n    recurring template pattern (CRTP) technique is applied to avoid virtual\n    functions, which improves the Dynamic Time Warping calculations while\n    the implementation stays flexible enough to support different DTW step\n    patterns and normalization methods.  "
  },
  {
    "id": 17577,
    "package_name": "parallelpam",
    "title": "Parallel Partitioning-Around-Medoids (PAM) for Big Sets of Data",
    "description": "Application of the Partitioning-Around-Medoids (PAM) clustering algorithm described in Schubert, E. and Rousseeuw, P.J.:\n        \"Fast and eager k-medoids clustering: O(k) runtime improvement of the PAM, CLARA, and CLARANS algorithms.\" Information Systems,\n        vol. 101, p. 101804, (2021). <doi:10.1016/j.is.2021.101804>.\n\tIt uses a binary format for storing and retrieval of matrices developed for the 'jmatrix' package but the functionality of 'jmatrix'\n\tis included here, so you do not need to install it. Also, it is used by package 'scellpam', so if you have installed it, you do not need\n\tto install this package.\n\tPAM can be applied to sets of data whose dissimilarity matrix can be very big. It has been tested with up to 100.000 points.\n\tIt does this with the help of the code developed for other package, 'jmatrix', which allows the matrix not to be loaded in 'R' memory (which\n\twould force it to be of double type) but it gets from disk, which allows using float (or even smaller data types). Moreover, the\n\tdissimilarity matrix is calculated in parallel if the computer has several cores so it can open many threads. The initial part\n\tof the PAM algorithm can be done with the BUILD or LAB algorithms; the BUILD algorithm has been implemented in parallel. The optimization\n\tphase implements the FastPAM1 algorithm, also in parallel. Finally, calculation of silhouette is available and also implemented in parallel.",
    "version": "1.4.3",
    "maintainer": "Juan Domingo <Juan.Domingo@uv.es>",
    "author": "Juan Domingo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4728-6256>),\n  Guillermo Ayala [ctb] (ORCID: <https://orcid.org/0000-0002-6231-2865>),\n  Spanish Ministry of Science and Innovation, MCIN/AEI\n    <doi:10.13039/501100011033> [fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=parallelpam",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "parallelpam Parallel Partitioning-Around-Medoids (PAM) for Big Sets of Data Application of the Partitioning-Around-Medoids (PAM) clustering algorithm described in Schubert, E. and Rousseeuw, P.J.:\n        \"Fast and eager k-medoids clustering: O(k) runtime improvement of the PAM, CLARA, and CLARANS algorithms.\" Information Systems,\n        vol. 101, p. 101804, (2021). <doi:10.1016/j.is.2021.101804>.\n\tIt uses a binary format for storing and retrieval of matrices developed for the 'jmatrix' package but the functionality of 'jmatrix'\n\tis included here, so you do not need to install it. Also, it is used by package 'scellpam', so if you have installed it, you do not need\n\tto install this package.\n\tPAM can be applied to sets of data whose dissimilarity matrix can be very big. It has been tested with up to 100.000 points.\n\tIt does this with the help of the code developed for other package, 'jmatrix', which allows the matrix not to be loaded in 'R' memory (which\n\twould force it to be of double type) but it gets from disk, which allows using float (or even smaller data types). Moreover, the\n\tdissimilarity matrix is calculated in parallel if the computer has several cores so it can open many threads. The initial part\n\tof the PAM algorithm can be done with the BUILD or LAB algorithms; the BUILD algorithm has been implemented in parallel. The optimization\n\tphase implements the FastPAM1 algorithm, also in parallel. Finally, calculation of silhouette is available and also implemented in parallel.  "
  },
  {
    "id": 17626,
    "package_name": "pasteAsComment",
    "title": "'RStudio' Addin to Paste the Clipboard as a Comment Block or a\n'roxygen' Block",
    "description": "Provides a 'RStudio' addin allowing to paste the content of the clipboard as a comment block or as 'roxygen' lines. This is very useful to insert an example in the 'roxygen' block.",
    "version": "0.2.1",
    "maintainer": "St\u00e9phane Laurent <laurent_step@outlook.fr>",
    "author": "St\u00e9phane Laurent",
    "url": "https://github.com/stla/pasteAsComment",
    "bug_reports": "https://github.com/stla/pasteAsComment/issues",
    "repository": "https://cran.r-project.org/package=pasteAsComment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pasteAsComment 'RStudio' Addin to Paste the Clipboard as a Comment Block or a\n'roxygen' Block Provides a 'RStudio' addin allowing to paste the content of the clipboard as a comment block or as 'roxygen' lines. This is very useful to insert an example in the 'roxygen' block.  "
  },
  {
    "id": 17627,
    "package_name": "pastecs",
    "title": "Package for Analysis of Space-Time Ecological Series",
    "description": "Regularisation, decomposition and analysis of space-time series.\n  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff\n  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.",
    "version": "1.4.2",
    "maintainer": "Philippe Grosjean <phgrosjean@sciviews.org>",
    "author": "Philippe Grosjean [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2694-9471>),\n  Frederic Ibanez [aut],\n  Michele Etienne [ctb]",
    "url": "https://github.com/SciViews/pastecs",
    "bug_reports": "https://github.com/SciViews/pastecs/issues",
    "repository": "https://cran.r-project.org/package=pastecs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pastecs Package for Analysis of Space-Time Ecological Series Regularisation, decomposition and analysis of space-time series.\n  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff\n  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.  "
  },
  {
    "id": 17630,
    "package_name": "patchwork",
    "title": "The Composer of Plots",
    "description": "The 'ggplot2' package provides a strong API for sequentially \n    building up a plot, but does not concern itself with composition of multiple\n    plots. 'patchwork' is a package that expands the API to allow for \n    arbitrarily complex composition of plots by, among others, providing \n    mathematical operators for combining multiple plots. Other packages that try \n    to address this need (but with a different approach) are 'gridExtra' and \n    'cowplot'.",
    "version": "1.3.2",
    "maintainer": "Thomas Lin Pedersen <thomasp85@gmail.com>",
    "author": "Thomas Lin Pedersen [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-5147-4711>)",
    "url": "https://patchwork.data-imaginist.com,\nhttps://github.com/thomasp85/patchwork",
    "bug_reports": "https://github.com/thomasp85/patchwork/issues",
    "repository": "https://cran.r-project.org/package=patchwork",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "patchwork The Composer of Plots The 'ggplot2' package provides a strong API for sequentially \n    building up a plot, but does not concern itself with composition of multiple\n    plots. 'patchwork' is a package that expands the API to allow for \n    arbitrarily complex composition of plots by, among others, providing \n    mathematical operators for combining multiple plots. Other packages that try \n    to address this need (but with a different approach) are 'gridExtra' and \n    'cowplot'.  "
  },
  {
    "id": 17634,
    "package_name": "pathfindR",
    "title": "Enrichment Analysis Utilizing Active Subnetworks",
    "description": "Enrichment analysis enables researchers to uncover mechanisms \n    underlying a phenotype. However, conventional methods for enrichment \n    analysis do not take into account protein-protein interaction information, \n    resulting in incomplete conclusions. 'pathfindR' is a tool for enrichment \n    analysis utilizing active subnetworks. The main function identifies active \n    subnetworks in a protein-protein interaction network using a user-provided \n    list of genes and associated p values. It then performs enrichment analyses \n    on the identified subnetworks, identifying enriched terms (i.e. pathways or, \n    more broadly, gene sets) that possibly underlie the phenotype of interest.\n    'pathfindR' also offers functionalities to cluster the enriched terms and \n    identify representative terms in each cluster, to score the enriched terms \n    per sample and to visualize analysis results. The enrichment, clustering and \n    other methods implemented in 'pathfindR' are described in detail in \n    Ulgen E, Ozisik O, Sezerman OU. 2019. 'pathfindR': An R Package for \n    Comprehensive Identification of Enriched Pathways in Omics Data Through \n    Active Subnetworks. Front. Genet. <doi:10.3389/fgene.2019.00858>.",
    "version": "2.6.0",
    "maintainer": "Ege Ulgen <egeulgen@gmail.com>",
    "author": "Ege Ulgen [cre, cph] (ORCID: <https://orcid.org/0000-0003-2090-3621>),\n  Ozan Ozisik [aut] (ORCID: <https://orcid.org/0000-0001-5980-8002>)",
    "url": "https://egeulgen.github.io/pathfindR/,\nhttps://github.com/egeulgen/pathfindR",
    "bug_reports": "https://github.com/egeulgen/pathfindR/issues",
    "repository": "https://cran.r-project.org/package=pathfindR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pathfindR Enrichment Analysis Utilizing Active Subnetworks Enrichment analysis enables researchers to uncover mechanisms \n    underlying a phenotype. However, conventional methods for enrichment \n    analysis do not take into account protein-protein interaction information, \n    resulting in incomplete conclusions. 'pathfindR' is a tool for enrichment \n    analysis utilizing active subnetworks. The main function identifies active \n    subnetworks in a protein-protein interaction network using a user-provided \n    list of genes and associated p values. It then performs enrichment analyses \n    on the identified subnetworks, identifying enriched terms (i.e. pathways or, \n    more broadly, gene sets) that possibly underlie the phenotype of interest.\n    'pathfindR' also offers functionalities to cluster the enriched terms and \n    identify representative terms in each cluster, to score the enriched terms \n    per sample and to visualize analysis results. The enrichment, clustering and \n    other methods implemented in 'pathfindR' are described in detail in \n    Ulgen E, Ozisik O, Sezerman OU. 2019. 'pathfindR': An R Package for \n    Comprehensive Identification of Enriched Pathways in Omics Data Through \n    Active Subnetworks. Front. Genet. <doi:10.3389/fgene.2019.00858>.  "
  },
  {
    "id": 17641,
    "package_name": "patrick",
    "title": "Parameterized Unit Testing",
    "description": "This is an extension of the 'testthat' package that\n    lets you add parameters to your unit tests. Parameterized unit tests\n    are often easier to read and more reliable, since they follow the DNRY\n    (do not repeat yourself) rule.",
    "version": "0.3.1",
    "maintainer": "Michael Chirico <chiricom@google.com>",
    "author": "Michael Quinn [aut],\n  Michael Chirico [aut, cre]",
    "url": "https://github.com/google/patrick",
    "bug_reports": "https://github.com/google/patrick/issues",
    "repository": "https://cran.r-project.org/package=patrick",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "patrick Parameterized Unit Testing This is an extension of the 'testthat' package that\n    lets you add parameters to your unit tests. Parameterized unit tests\n    are often easier to read and more reliable, since they follow the DNRY\n    (do not repeat yourself) rule.  "
  },
  {
    "id": 17667,
    "package_name": "pbatR",
    "title": "Pedigree/Family-Based Genetic Association Tests Analysis and\nPower",
    "description": "This R package provides power calculations via internal simulation methods. The package also provides a frontend to the now abandoned PBAT program (developed by Christoph Lange), and reads in the corresponding output and displays results and figures when appropriate. The license of this R package itself is GPL. However, to have the program interact with the PBAT program for some functionality of the R package, users must additionally obtain the PBAT program from Christoph Lange, and accept his license. Both the data analysis and power calculations have command line and graphical interfaces using tcltk.",
    "version": "2.2-17",
    "maintainer": "Thomas Hoffmann <tjhoffm@gmail.com>",
    "author": "Thomas Hoffmann <tjhoffm@gmail.com>, with contributions from Christoph Lange <clange@hsph.harvard.edu>",
    "url": "https://academic.oup.com/bioinformatics/article-abstract/22/24/3103/208723",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pbatR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pbatR Pedigree/Family-Based Genetic Association Tests Analysis and\nPower This R package provides power calculations via internal simulation methods. The package also provides a frontend to the now abandoned PBAT program (developed by Christoph Lange), and reads in the corresponding output and displays results and figures when appropriate. The license of this R package itself is GPL. However, to have the program interact with the PBAT program for some functionality of the R package, users must additionally obtain the PBAT program from Christoph Lange, and accept his license. Both the data analysis and power calculations have command line and graphical interfaces using tcltk.  "
  },
  {
    "id": 17703,
    "package_name": "pcmabc",
    "title": "Approximate Bayesian Computations for Phylogenetic Comparative\nMethods",
    "description": "Fits by ABC, the parameters of a stochastic process modelling the phylogeny and evolution of a suite of traits following the tree. The user may define an arbitrary Markov process for the trait and phylogeny. Importantly, trait-dependent speciation models are handled and fitted to data. See K. Bartoszek, P. Lio' (2019) <doi:10.5506/APhysPolBSupp.12.25>. The suggested geiger package can be obtained from CRAN's archive <https://cran.r-project.org/src/contrib/Archive/geiger/>, suggested to take latest version. Otherwise its required code is present in the pcmabc package. The suggested distory package can be obtained from CRAN's archive <https://cran.r-project.org/src/contrib/Archive/distory/>, suggested to take latest version. ",
    "version": "1.1.3",
    "maintainer": "Krzysztof Bartoszek <krzbar@protonmail.ch>",
    "author": "Krzysztof Bartoszek <krzbar@protonmail.ch>, Pietro Lio'",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pcmabc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pcmabc Approximate Bayesian Computations for Phylogenetic Comparative\nMethods Fits by ABC, the parameters of a stochastic process modelling the phylogeny and evolution of a suite of traits following the tree. The user may define an arbitrary Markov process for the trait and phylogeny. Importantly, trait-dependent speciation models are handled and fitted to data. See K. Bartoszek, P. Lio' (2019) <doi:10.5506/APhysPolBSupp.12.25>. The suggested geiger package can be obtained from CRAN's archive <https://cran.r-project.org/src/contrib/Archive/geiger/>, suggested to take latest version. Otherwise its required code is present in the pcmabc package. The suggested distory package can be obtained from CRAN's archive <https://cran.r-project.org/src/contrib/Archive/distory/>, suggested to take latest version.   "
  },
  {
    "id": 17740,
    "package_name": "pedFamilias",
    "title": "Import and Export 'Familias' Files",
    "description": "Tools for exchanging pedigree data between the 'pedsuite'\n    packages and the 'Familias' software for forensic kinship computations\n    (Egeland et al. (2000) <doi:10.1016/s0379-0738(00)00147-x>). These\n    functions were split out from the 'forrel' package to streamline\n    maintenance and provide a lightweight alternative for packages otherwise\n    independent of 'forrel'.",
    "version": "0.2.4",
    "maintainer": "Magnus Dehli Vigeland <m.d.vigeland@medisin.uio.no>",
    "author": "Magnus Dehli Vigeland [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9134-4962>)",
    "url": "https://github.com/magnusdv/pedFamilias",
    "bug_reports": "https://github.com/magnusdv/pedFamilias/issues",
    "repository": "https://cran.r-project.org/package=pedFamilias",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pedFamilias Import and Export 'Familias' Files Tools for exchanging pedigree data between the 'pedsuite'\n    packages and the 'Familias' software for forensic kinship computations\n    (Egeland et al. (2000) <doi:10.1016/s0379-0738(00)00147-x>). These\n    functions were split out from the 'forrel' package to streamline\n    maintenance and provide a lightweight alternative for packages otherwise\n    independent of 'forrel'.  "
  },
  {
    "id": 17751,
    "package_name": "pedometrics",
    "title": "Miscellaneous Pedometric Tools",
    "description": "An R implementation of methods employed in the field of pedometrics, soil science\n    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil\n    using statistical and computational methods. The methods found here include the calibration of\n    linear regression models using covariate selection strategies, computation of summary validation\n    statistics for predictions, generation of summary plots, evaluation of the local quality of a\n    geostatistical model of uncertainty, and so on. Other functions simply extend the\n    functionalities of or facilitate the usage of functions from other packages that are commonly\n    used for the analysis of soil data. Formerly available versions of suggested packages no longer\n    available from CRAN can be obtained from the CRAN archive\n    <https://cran.r-project.org/src/contrib/Archive/>.",
    "version": "0.12.1",
    "maintainer": "Alessandro Samuel-Rosa <alessandrosamuelrosa@gmail.com>",
    "author": "Alessandro Samuel-Rosa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0877-1320>),\n  Lucia Helena Cunha dos Anjos [ths] (ORCID:\n    <https://orcid.org/0000-0003-0063-3521>),\n  Gustavo Vasques [ths] (ORCID: <https://orcid.org/0000-0001-9463-1898>),\n  Gerard B M Heuvelink [ths] (ORCID:\n    <https://orcid.org/0000-0003-0959-9358>),\n  Juan Carlos Ruiz Cuetos [ctb],\n  Maria Eugenia Polo Garcia [ctb],\n  Pablo Garcia Rodriguez [ctb],\n  Joshua French [ctb],\n  Ken Kleinman [ctb],\n  Dick Brus [ctb] (ORCID: <https://orcid.org/0000-0003-2194-4783>),\n  Frank Harrell Jr [ctb],\n  Ruo Xu [ctb]",
    "url": "https://github.com/Laboratorio-de-Pedometria/pedometrics-package",
    "bug_reports": "https://github.com/Laboratorio-de-Pedometria/pedometrics-package/issues",
    "repository": "https://cran.r-project.org/package=pedometrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pedometrics Miscellaneous Pedometric Tools An R implementation of methods employed in the field of pedometrics, soil science\n    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil\n    using statistical and computational methods. The methods found here include the calibration of\n    linear regression models using covariate selection strategies, computation of summary validation\n    statistics for predictions, generation of summary plots, evaluation of the local quality of a\n    geostatistical model of uncertainty, and so on. Other functions simply extend the\n    functionalities of or facilitate the usage of functions from other packages that are commonly\n    used for the analysis of soil data. Formerly available versions of suggested packages no longer\n    available from CRAN can be obtained from the CRAN archive\n    <https://cran.r-project.org/src/contrib/Archive/>.  "
  },
  {
    "id": 17798,
    "package_name": "permubiome",
    "title": "A Permutation Based Test for Biomarker Discovery in Microbiome\nData",
    "description": "The permubiome R package was created to perform a permutation-based non-parametric analysis on microbiome data for biomarker discovery aims. This test executes thousands of comparisons in a pairwise manner, after a random shuffling of data into the different groups of study with a prior selection of the microbiome features with the largest variation among groups. Previous to the permutation test itself, data can be normalized according to different methods proposed to handle microbiome data ('proportions' or 'Anders'). The median-based differences between groups resulting from the multiple simulations are fitted to a normal distribution with the aim to calculate their significance. A multiple testing correction based on Benjamini-Hochberg method (fdr) is finally applied to extract the differentially presented features between groups of your dataset. LATEST UPDATES: v1.1 and olders incorporates function to parse COLUMN format; v1.2 and olders incorporates -optimize- function to maximize evaluation of features with largest inter-class variation; v1.3 and olders includes the -size.effect- function to perform estimation statistics using the bootstrap-coupled approach implemented in the 'dabestr' (>=0.3.0) R package. Current v1.3.2 fixed bug with \"Class\" recognition and updated 'dabestr' functions.",
    "version": "1.3.2",
    "maintainer": "Alfonso Benitez-Paez <alfbenpa@gmail.com>",
    "author": "Alfonso Benitez-Paez",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=permubiome",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "permubiome A Permutation Based Test for Biomarker Discovery in Microbiome\nData The permubiome R package was created to perform a permutation-based non-parametric analysis on microbiome data for biomarker discovery aims. This test executes thousands of comparisons in a pairwise manner, after a random shuffling of data into the different groups of study with a prior selection of the microbiome features with the largest variation among groups. Previous to the permutation test itself, data can be normalized according to different methods proposed to handle microbiome data ('proportions' or 'Anders'). The median-based differences between groups resulting from the multiple simulations are fitted to a normal distribution with the aim to calculate their significance. A multiple testing correction based on Benjamini-Hochberg method (fdr) is finally applied to extract the differentially presented features between groups of your dataset. LATEST UPDATES: v1.1 and olders incorporates function to parse COLUMN format; v1.2 and olders incorporates -optimize- function to maximize evaluation of features with largest inter-class variation; v1.3 and olders includes the -size.effect- function to perform estimation statistics using the bootstrap-coupled approach implemented in the 'dabestr' (>=0.3.0) R package. Current v1.3.2 fixed bug with \"Class\" recognition and updated 'dabestr' functions.  "
  },
  {
    "id": 17800,
    "package_name": "permutations",
    "title": "The Symmetric Group: Permutations of a Finite Set",
    "description": "Manipulates invertible functions from a finite set to\n             itself.  Can transform from word form to cycle form and\n             back.  To cite the package in publications please use\n             Hankin (2020) \"Introducing the permutations R package\",\n             SoftwareX, volume 11 <doi:10.1016/j.softx.2020.100453>.",
    "version": "1.1-6",
    "maintainer": "Robin K. S. Hankin <hankin.robin@gmail.com>",
    "author": "Robin K. S. Hankin [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5982-0415>),\n  Paul Egeler [ctb] (ORCID: <https://orcid.org/0000-0001-6948-9498>)",
    "url": "https://github.com/RobinHankin/permutations,\nhttps://robinhankin.github.io/permutations/",
    "bug_reports": "https://github.com/RobinHankin/permutations/issues",
    "repository": "https://cran.r-project.org/package=permutations",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "permutations The Symmetric Group: Permutations of a Finite Set Manipulates invertible functions from a finite set to\n             itself.  Can transform from word form to cycle form and\n             back.  To cite the package in publications please use\n             Hankin (2020) \"Introducing the permutations R package\",\n             SoftwareX, volume 11 <doi:10.1016/j.softx.2020.100453>.  "
  },
  {
    "id": 17811,
    "package_name": "personalr",
    "title": "Automated Personal Package Setup",
    "description": "Functions to setup a personal R package that attaches given\n    libraries and exports personal helper functions.",
    "version": "1.0.3",
    "maintainer": "Sebastian Carl <mrcaseb@gmail.com>",
    "author": "Sebastian Carl [aut, cre]",
    "url": "https://mrcaseb.github.io/personalr/index.html,\nhttps://github.com/mrcaseb/personalr",
    "bug_reports": "https://github.com/mrcaseb/personalr/issues",
    "repository": "https://cran.r-project.org/package=personalr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "personalr Automated Personal Package Setup Functions to setup a personal R package that attaches given\n    libraries and exports personal helper functions.  "
  },
  {
    "id": 17869,
    "package_name": "pheno",
    "title": "Auxiliary Functions for Phenological Data Analysis",
    "description": "Provides some easy-to-use functions for time series\n        analyses of (plant-) phenological data sets. These functions\n        mainly deal with the estimation of combined phenological time\n        series and are usually wrappers for functions that are already\n        implemented in other R packages adapted to the special\n        structure of phenological data and the needs of phenologists.\n        Some date conversion functions to handle Julian dates are also\n        provided.",
    "version": "1.7-0",
    "maintainer": "Maximilian Lange <maximilian.lange@ufz.de>",
    "author": "Joerg Schaber",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pheno",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pheno Auxiliary Functions for Phenological Data Analysis Provides some easy-to-use functions for time series\n        analyses of (plant-) phenological data sets. These functions\n        mainly deal with the estimation of combined phenological time\n        series and are usually wrappers for functions that are already\n        implemented in other R packages adapted to the special\n        structure of phenological data and the needs of phenologists.\n        Some date conversion functions to handle Julian dates are also\n        provided.  "
  },
  {
    "id": 17882,
    "package_name": "phoenix",
    "title": "The Phoenix Pediatric Sepsis and Septic Shock Criteria",
    "description": "Implementation of the Phoenix and Phoenix-8 Sepsis Criteria as\n    described in \"Development and Validation of the Phoenix Criteria for\n    Pediatric Sepsis and Septic Shock\" by Sanchez-Pinto, Bennett, DeWitt,\n    Russell et al. (2024) <doi:10.1001/jama.2024.0196> (Drs. Sanchez-Pinto\n    and Bennett contributed equally to this manuscript; Dr. DeWitt and Mr.\n    Russell contributed equally to the manuscript), \"International Consensus\n    Criteria for Pediatric Sepsis and Septic Shock\" by Schlapbach, Watson,\n    Sorce, Argent, et al. (2024) <doi:10.1001/jama.2024.0179> (Drs Schlapbach,\n    Watson, Sorce, and Argent contributed equally) and the application note\n    \"phoenix: an R package and Python module for calculating the Phoenix\n    pediatric sepsis score and criteria\" by DeWitt, Russell, Rebull,\n    Sanchez-Pinto, and Bennett (2024) <doi:10.1093/jamiaopen/ooae066>.",
    "version": "1.1.3",
    "maintainer": "Peter DeWitt <peter.dewitt@cuanschutz.edu>",
    "author": "Peter DeWitt [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6391-0795>),\n  Seth Russell [ctb] (ORCID: <https://orcid.org/0000-0002-2436-1367>),\n  Meg Rebull [ctb] (ORCID: <https://orcid.org/0000-0003-0334-4223>),\n  Tell Bennett [ctb] (ORCID: <https://orcid.org/0000-0003-1483-4236>),\n  L. Nelson Sanchez-Pinto [ctb] (ORCID:\n    <https://orcid.org/0000-0002-7434-6747>)",
    "url": "https://cu-dbmi-peds.github.io/phoenix/,\nhttps://github.com/CU-DBMI-Peds/phoenix/",
    "bug_reports": "https://github.com/CU-DBMI-Peds/phoenix/issues",
    "repository": "https://cran.r-project.org/package=phoenix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phoenix The Phoenix Pediatric Sepsis and Septic Shock Criteria Implementation of the Phoenix and Phoenix-8 Sepsis Criteria as\n    described in \"Development and Validation of the Phoenix Criteria for\n    Pediatric Sepsis and Septic Shock\" by Sanchez-Pinto, Bennett, DeWitt,\n    Russell et al. (2024) <doi:10.1001/jama.2024.0196> (Drs. Sanchez-Pinto\n    and Bennett contributed equally to this manuscript; Dr. DeWitt and Mr.\n    Russell contributed equally to the manuscript), \"International Consensus\n    Criteria for Pediatric Sepsis and Septic Shock\" by Schlapbach, Watson,\n    Sorce, Argent, et al. (2024) <doi:10.1001/jama.2024.0179> (Drs Schlapbach,\n    Watson, Sorce, and Argent contributed equally) and the application note\n    \"phoenix: an R package and Python module for calculating the Phoenix\n    pediatric sepsis score and criteria\" by DeWitt, Russell, Rebull,\n    Sanchez-Pinto, and Bennett (2024) <doi:10.1093/jamiaopen/ooae066>.  "
  },
  {
    "id": 17890,
    "package_name": "photobiologyInOut",
    "title": "Read Spectral and Logged Data from Foreign Files",
    "description": "Functions for reading, and in some cases writing, foreign files \n    containing spectral data from spectrometers and their associated software, \n    output from daylight simulation models in common use, and some spectral \n    data repositories. As well as functions for exchange of spectral data with \n    other R packages. Part of the 'r4photobiology' suite, \n    Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",
    "version": "0.4.32",
    "maintainer": "Pedro J. Aphalo <pedro.aphalo@helsinki.fi>",
    "author": "Pedro J. Aphalo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3385-972X>),\n  Titta K. Kotilainen [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2822-9734>),\n  Glenn Davis [ctb]",
    "url": "https://docs.r4photobiology.info/photobiologyInOut/",
    "bug_reports": "https://github.com/aphalo/photobiologyinout/issues/",
    "repository": "https://cran.r-project.org/package=photobiologyInOut",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "photobiologyInOut Read Spectral and Logged Data from Foreign Files Functions for reading, and in some cases writing, foreign files \n    containing spectral data from spectrometers and their associated software, \n    output from daylight simulation models in common use, and some spectral \n    data repositories. As well as functions for exchange of spectral data with \n    other R packages. Part of the 'r4photobiology' suite, \n    Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.  "
  },
  {
    "id": 17905,
    "package_name": "phutil",
    "title": "Persistence Homology Utilities",
    "description": "A low-level package for hosting persistence data. It is part of the\n    'TDAverse' suite of packages, which is designed to provide a collection of\n    packages for enabling machine learning and data science tasks using\n    persistent homology. Implements a class for hosting persistence data, a\n    number of coercers from and to already existing and used data structures\n    from other packages and functions to compute distances between persistence\n    diagrams. A formal definition and study of bottleneck and Wasserstein\n    distances can be found in Bubenik, Scott and Stanley (2023)\n    <doi:10.1007/s41468-022-00103-8>. Their implementation in 'phutil' relies on\n    the 'C++' Hera library developed by Kerber, Morozov and Nigmetov (2017)\n    <doi:10.1145/3064175>.",
    "version": "0.0.1",
    "maintainer": "Aymeric Stamm <aymeric.stamm@cnrs.fr>",
    "author": "Aymeric Stamm [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8725-3654>),\n  Jason Cory Brunson [aut] (ORCID:\n    <https://orcid.org/0000-0003-3126-9494>),\n  Michael Kerber [ctb] (HERA C++ code),\n  Dmitriy Morozov [ctb] (HERA C++ code),\n  Arnur Nigmetov [ctb] (HERA C++ code)",
    "url": "https://github.com/tdaverse/phutil,\nhttps://tdaverse.github.io/phutil/",
    "bug_reports": "https://github.com/tdaverse/phutil/issues",
    "repository": "https://cran.r-project.org/package=phutil",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phutil Persistence Homology Utilities A low-level package for hosting persistence data. It is part of the\n    'TDAverse' suite of packages, which is designed to provide a collection of\n    packages for enabling machine learning and data science tasks using\n    persistent homology. Implements a class for hosting persistence data, a\n    number of coercers from and to already existing and used data structures\n    from other packages and functions to compute distances between persistence\n    diagrams. A formal definition and study of bottleneck and Wasserstein\n    distances can be found in Bubenik, Scott and Stanley (2023)\n    <doi:10.1007/s41468-022-00103-8>. Their implementation in 'phutil' relies on\n    the 'C++' Hera library developed by Kerber, Morozov and Nigmetov (2017)\n    <doi:10.1145/3064175>.  "
  },
  {
    "id": 17907,
    "package_name": "phyext2",
    "title": "An Extension (for Package 'SigTree') of Some of the Classes in\nPackage 'phylobase'",
    "description": "Based on (but not identical to) the no-longer-maintained package 'phyext', provides enhancements to 'phylobase' classes, specifically for use by package 'SigTree'; provides classes and methods which help users manipulate branch-annotated trees (as in 'SigTree'); also provides support for a few other extra features.",
    "version": "0.0.4",
    "maintainer": "John R. Stevens <john.r.stevens@usu.edu>",
    "author": "J. Conrad Stack",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=phyext2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phyext2 An Extension (for Package 'SigTree') of Some of the Classes in\nPackage 'phylobase' Based on (but not identical to) the no-longer-maintained package 'phyext', provides enhancements to 'phylobase' classes, specifically for use by package 'SigTree'; provides classes and methods which help users manipulate branch-annotated trees (as in 'SigTree'); also provides support for a few other extra features.  "
  },
  {
    "id": 17920,
    "package_name": "phylosem",
    "title": "Phylogenetic Structural Equation Model",
    "description": "Applies phylogenetic comparative methods (PCM) and phylogenetic trait imputation using \n    structural equation models (SEM), extending methods from Thorson et al. (2023) <doi:10.1111/2041-210X.14076>.  \n    This implementation includes a minimal set of features, to \n    allow users to easily read all of the documentation and source code.  PCM using SEM \n    includes phylogenetic linear models and structural equation models as nested submodels, \n    but also allows imputation of missing values.  Features and comparison with other packages\n    are described in Thorson and van der Bijl (2023) <doi:10.1111/jeb.14234>. ",
    "version": "1.1.4",
    "maintainer": "James Thorson <James.Thorson@noaa.gov>",
    "author": "James Thorson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7415-1010>),\n  Wouter van der Bijl [ctb] (ORCID:\n    <https://orcid.org/0000-0002-7366-1868>)",
    "url": "https://james-thorson-noaa.github.io/phylosem/",
    "bug_reports": "https://github.com/James-Thorson-NOAA/phylosem/issues",
    "repository": "https://cran.r-project.org/package=phylosem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "phylosem Phylogenetic Structural Equation Model Applies phylogenetic comparative methods (PCM) and phylogenetic trait imputation using \n    structural equation models (SEM), extending methods from Thorson et al. (2023) <doi:10.1111/2041-210X.14076>.  \n    This implementation includes a minimal set of features, to \n    allow users to easily read all of the documentation and source code.  PCM using SEM \n    includes phylogenetic linear models and structural equation models as nested submodels, \n    but also allows imputation of missing values.  Features and comparison with other packages\n    are described in Thorson and van der Bijl (2023) <doi:10.1111/jeb.14234>.   "
  },
  {
    "id": 17949,
    "package_name": "pinfsc50",
    "title": "Sequence ('FASTA'), Annotation ('GFF') and Variants ('VCF') for\n17 Samples of 'P. Infestans\" and 1 'P. Mirabilis'",
    "description": "Genomic data for the plant pathogen \"Phytophthora infestans.\" It\n    includes a variant file ('VCF'), a sequence file ('FASTA') and an annotation file\n    ('GFF'). This package is intended to be used as example data for packages that\n    work with genomic data.",
    "version": "1.3.0",
    "maintainer": "Brian J. Knaus <briank.lists@gmail.com>",
    "author": "Brian J. Knaus [cre, aut],\n  Niklaus J. Grunwald [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pinfsc50",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pinfsc50 Sequence ('FASTA'), Annotation ('GFF') and Variants ('VCF') for\n17 Samples of 'P. Infestans\" and 1 'P. Mirabilis' Genomic data for the plant pathogen \"Phytophthora infestans.\" It\n    includes a variant file ('VCF'), a sequence file ('FASTA') and an annotation file\n    ('GFF'). This package is intended to be used as example data for packages that\n    work with genomic data.  "
  },
  {
    "id": 17968,
    "package_name": "piton",
    "title": "Parsing Expression Grammars in Rcpp",
    "description": "A wrapper around the 'Parsing Expression Grammar Template Library', a C++11 library for generating\n    Parsing Expression Grammars, that makes it accessible within Rcpp. With this, developers can implement\n    their own grammars and easily expose them in R packages.",
    "version": "1.0.1",
    "maintainer": "Os Keyes <ironholds@gmail.com>",
    "author": "Os Keyes [aut, cre],\n  Duncan Garmonsway [ctb],\n  Colin Hirsch [cph],\n  Daniel Frey [cph]",
    "url": "https://github.com/Ironholds/piton",
    "bug_reports": "https://github.com/Ironholds/piton/issues",
    "repository": "https://cran.r-project.org/package=piton",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "piton Parsing Expression Grammars in Rcpp A wrapper around the 'Parsing Expression Grammar Template Library', a C++11 library for generating\n    Parsing Expression Grammars, that makes it accessible within Rcpp. With this, developers can implement\n    their own grammars and easily expose them in R packages.  "
  },
  {
    "id": 17982,
    "package_name": "pkgGraphR",
    "title": "Graph the Relationship Between Functions in an R Package",
    "description": "It is often useful when developing an R package to track the relationship between functions in order to appropriately test and track changes. This package generates a graph of the relationship between all R functions in a package. It can also be used on any directory containing .R files which can be very useful for 'shiny' apps or other non-package workflows. ",
    "version": "0.3.1",
    "maintainer": "David Oliver <doliv071@gmail.com>",
    "author": "David Oliver [aut, cre, cph]",
    "url": "https://gitlab.com/doliv071/pkggraphr",
    "bug_reports": "https://gitlab.com/doliv071/pkggraphr/-/issues",
    "repository": "https://cran.r-project.org/package=pkgGraphR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgGraphR Graph the Relationship Between Functions in an R Package It is often useful when developing an R package to track the relationship between functions in order to appropriately test and track changes. This package generates a graph of the relationship between all R functions in a package. It can also be used on any directory containing .R files which can be very useful for 'shiny' apps or other non-package workflows.   "
  },
  {
    "id": 17983,
    "package_name": "pkgKitten",
    "title": "Create Simple Packages Which Do not Upset R Package Checks",
    "description": "Provides a function kitten() which creates cute little \n packages which pass R package checks. This sets it apart from \n package.skeleton() which it calls, and which leaves imperfect files \n behind. As this is not exactly helpful for beginners, kitten() offers \n an alternative. Unit test support can be added via the 'tinytest'\n package (if present), and documentation-creation support can be\n added via 'roxygen2' (if present).",
    "version": "0.2.4",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>)",
    "url": "https://github.com/eddelbuettel/pkgkitten,\nhttps://eddelbuettel.github.io/pkgkitten/",
    "bug_reports": "https://github.com/eddelbuettel/pkgkitten/issues",
    "repository": "https://cran.r-project.org/package=pkgKitten",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgKitten Create Simple Packages Which Do not Upset R Package Checks Provides a function kitten() which creates cute little \n packages which pass R package checks. This sets it apart from \n package.skeleton() which it calls, and which leaves imperfect files \n behind. As this is not exactly helpful for beginners, kitten() offers \n an alternative. Unit test support can be added via the 'tinytest'\n package (if present), and documentation-creation support can be\n added via 'roxygen2' (if present).  "
  },
  {
    "id": 17985,
    "package_name": "pkgdepR",
    "title": "Statically Determine Function Dependencies Between Packages",
    "description": "Statically determine and visualize the function dependencies\n    within and across packages. This may be useful for managing function \n    dependencies across a code base of multiple R packages.",
    "version": "1.1.1",
    "maintainer": "Ed Peyton <edppeyton@gmail.com>",
    "author": "Ed Peyton [aut, cre] (ORCID: <https://orcid.org/0000-0002-1427-0306>)",
    "url": "https://pkgdepR.org/",
    "bug_reports": "https://github.com/edpeyton/pkgdepR/issues",
    "repository": "https://cran.r-project.org/package=pkgdepR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgdepR Statically Determine Function Dependencies Between Packages Statically determine and visualize the function dependencies\n    within and across packages. This may be useful for managing function \n    dependencies across a code base of multiple R packages.  "
  },
  {
    "id": 17986,
    "package_name": "pkgdown.offline",
    "title": "Build 'pkgdown' Websites Offline",
    "description": "Provides support for building 'pkgdown' websites without an\n    internet connection. Works by bundling cached dependencies and\n    implementing drop-in replacements for key 'pkgdown' functions.\n    Enables package documentation websites to be built in environments\n    where internet access is unavailable or restricted.\n    For more details on generating 'pkgdown' websites, see\n    Wickham et al. (2025) <doi:10.32614/CRAN.package.pkgdown>.",
    "version": "0.1.2",
    "maintainer": "Nan Xiao <me@nanx.me>",
    "author": "Nan Xiao [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0250-5673>),\n  John Blischak [aut] (ORCID: <https://orcid.org/0000-0003-2634-9879>),\n  Algolia, Inc. and other contributors [ctb, cph] (autocomplete.js\n    library),\n  Aidan Feldman [ctb, cph] (bootstrap-toc library),\n  Zeno Rocha [ctb, cph] (clipboard.js library),\n  Nick Williams [ctb, cph] (headroom.js library),\n  Julian K\u00fchnel [ctb, cph] (mark.js library),\n  Kiro Risk [ctb, cph] (Fuse.js library),\n  Khan Academy and other contributors [ctb, cph] (KaTeX library),\n  The MathJax Consortium [ctb, cph] (MathJax library)",
    "url": "https://nanx.me/pkgdown.offline/,\nhttps://github.com/nanxstats/pkgdown.offline",
    "bug_reports": "https://github.com/nanxstats/pkgdown.offline/issues",
    "repository": "https://cran.r-project.org/package=pkgdown.offline",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgdown.offline Build 'pkgdown' Websites Offline Provides support for building 'pkgdown' websites without an\n    internet connection. Works by bundling cached dependencies and\n    implementing drop-in replacements for key 'pkgdown' functions.\n    Enables package documentation websites to be built in environments\n    where internet access is unavailable or restricted.\n    For more details on generating 'pkgdown' websites, see\n    Wickham et al. (2025) <doi:10.32614/CRAN.package.pkgdown>.  "
  },
  {
    "id": 17987,
    "package_name": "pkgfilecache",
    "title": "Download and Manage Optional Package Data",
    "description": "Manage optional data for your package. The data can be hosted anywhere, and you have to give a Uniform Resource Locator (URL) for each file. File integrity checks are supported. This is useful for package authors who need to ship more than the 5 Megabyte of data currently allowed by the the Comprehensive R Archive Network (CRAN).",
    "version": "0.1.5",
    "maintainer": "Tim Sch\u00e4fer <ts+code@rcmd.org>",
    "author": "Tim Sch\u00e4fer [aut, cre] (ORCID: <https://orcid.org/0000-0002-3683-8070>)",
    "url": "https://github.com/dfsp-spirit/pkgfilecache",
    "bug_reports": "https://github.com/dfsp-spirit/pkgfilecache/issues",
    "repository": "https://cran.r-project.org/package=pkgfilecache",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgfilecache Download and Manage Optional Package Data Manage optional data for your package. The data can be hosted anywhere, and you have to give a Uniform Resource Locator (URL) for each file. File integrity checks are supported. This is useful for package authors who need to ship more than the 5 Megabyte of data currently allowed by the the Comprehensive R Archive Network (CRAN).  "
  },
  {
    "id": 17989,
    "package_name": "pkglite",
    "title": "Compact Package Representations",
    "description": "A tool, grammar, and standard to represent and exchange\n    R package source code as text files. Converts one or more source\n    packages to a text file and restores the package structures from the file.",
    "version": "0.2.4",
    "maintainer": "Nan Xiao <nan.xiao1@merck.com>",
    "author": "Nan Xiao [aut, cre] (ORCID: <https://orcid.org/0000-0002-0250-5673>),\n  Yilong Zhang [aut],\n  Keaven Anderson [aut],\n  Amin Shirazi [ctb],\n  Jeff Cheng [ctb],\n  Danfeng Fu [ctb],\n  Merck & Co., Inc., Rahway, NJ, USA and its affiliates [cph]",
    "url": "https://merck.github.io/pkglite/, https://github.com/Merck/pkglite",
    "bug_reports": "https://github.com/Merck/pkglite/issues",
    "repository": "https://cran.r-project.org/package=pkglite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkglite Compact Package Representations A tool, grammar, and standard to represent and exchange\n    R package source code as text files. Converts one or more source\n    packages to a text file and restores the package structures from the file.  "
  },
  {
    "id": 17990,
    "package_name": "pkgndep",
    "title": "Analyze Dependency Heaviness of R Packages",
    "description": "A new metric named 'dependency heaviness' is proposed that measures the number \n    of additional dependency packages that a parent package brings to its child package \n    and are unique to the dependency packages imported by all other parents.  \n    The dependency heaviness analysis is visualized by a customized heatmap. \n    The package is described in <doi:10.1093/bioinformatics/btac449>. \n    We have also performed the dependency heaviness analysis on the CRAN/Bioconductor \n    package ecosystem and the results are implemented as a web-based database \n    which provides comprehensive tools for querying dependencies of individual R packages. \n    The systematic analysis on the CRAN/Bioconductor ecosystem is described in \n    <doi:10.1016/j.jss.2023.111610>. From 'pkgndep' version 2.0.0, the heaviness \n    database includes snapshots of the CRAN/Bioconductor ecosystems for many old R versions.",
    "version": "1.99.3",
    "maintainer": "Zuguang Gu <z.gu@dkfz.de>",
    "author": "Zuguang Gu [aut, cre] (ORCID: <https://orcid.org/0000-0002-7395-8709>)",
    "url": "https://github.com/jokergoo/pkgndep",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pkgndep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgndep Analyze Dependency Heaviness of R Packages A new metric named 'dependency heaviness' is proposed that measures the number \n    of additional dependency packages that a parent package brings to its child package \n    and are unique to the dependency packages imported by all other parents.  \n    The dependency heaviness analysis is visualized by a customized heatmap. \n    The package is described in <doi:10.1093/bioinformatics/btac449>. \n    We have also performed the dependency heaviness analysis on the CRAN/Bioconductor \n    package ecosystem and the results are implemented as a web-based database \n    which provides comprehensive tools for querying dependencies of individual R packages. \n    The systematic analysis on the CRAN/Bioconductor ecosystem is described in \n    <doi:10.1016/j.jss.2023.111610>. From 'pkgndep' version 2.0.0, the heaviness \n    database includes snapshots of the CRAN/Bioconductor ecosystems for many old R versions.  "
  },
  {
    "id": 17991,
    "package_name": "pkgnet",
    "title": "Get Network Representation of an R Package",
    "description": "Tools from the domain of graph theory can be used to quantify the complexity\n             and vulnerability to failure of a software package. That is the guiding philosophy\n             of this package. 'pkgnet' provides tools to analyze the dependencies between functions\n             in an R package and between its imported packages.  See the pkgnet website for vignettes \n             and other supplementary information.",
    "version": "0.5.0",
    "maintainer": "Brian Burns <brian.burns.opensource@gmail.com>",
    "author": "Brian Burns [aut, cre],\n  James Lamb [aut],\n  Jay Qi [aut]",
    "url": "https://github.com/uptake/pkgnet, https://uptake.github.io/pkgnet/",
    "bug_reports": "https://github.com/uptake/pkgnet/issues",
    "repository": "https://cran.r-project.org/package=pkgnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgnet Get Network Representation of an R Package Tools from the domain of graph theory can be used to quantify the complexity\n             and vulnerability to failure of a software package. That is the guiding philosophy\n             of this package. 'pkgnet' provides tools to analyze the dependencies between functions\n             in an R package and between its imported packages.  See the pkgnet website for vignettes \n             and other supplementary information.  "
  },
  {
    "id": 17992,
    "package_name": "pkgnews",
    "title": "Retrieve R Package News Files",
    "description": "Read R package news files, regardless of whether or not the package\n  is installed.",
    "version": "0.0.2",
    "maintainer": "Owen Jones <owenjonesuob@gmail.com>",
    "author": "Owen Jones [aut, cre]",
    "url": "https://github.com/owenjonesuob/pkgnews",
    "bug_reports": "https://github.com/owenjonesuob/pkgnews/issues",
    "repository": "https://cran.r-project.org/package=pkgnews",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgnews Retrieve R Package News Files Read R package news files, regardless of whether or not the package\n  is installed.  "
  },
  {
    "id": 17993,
    "package_name": "pkgverse",
    "title": "Build a Meta-Package Universe",
    "description": "Build your own universe of packages similar to the 'tidyverse'\n    package <https://tidyverse.org/> with this meta-package creator. Create a\n    package-verse, or meta package, by supplying a custom name for the\n    collection of packages and the vector of desired package names to include\u2013\n    and optionally supply a destination directory, an indicator of whether to\n    keep the created package directory, and/or a vector of verbs implement via\n    the 'usethis' <http://usethis.r-lib.org/> package.",
    "version": "0.0.1",
    "maintainer": "Michael Wayne Kearney <kearneymw@missouri.edu>",
    "author": "Michael Wayne Kearney [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0730-4694>)",
    "url": "https://pkgverse.mikewk.com",
    "bug_reports": "https://github.com/mkearney/pkgverse/issues",
    "repository": "https://cran.r-project.org/package=pkgverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkgverse Build a Meta-Package Universe Build your own universe of packages similar to the 'tidyverse'\n    package <https://tidyverse.org/> with this meta-package creator. Create a\n    package-verse, or meta package, by supplying a custom name for the\n    collection of packages and the vector of desired package names to include\u2013\n    and optionally supply a destination directory, an indicator of whether to\n    keep the created package directory, and/or a vector of verbs implement via\n    the 'usethis' <http://usethis.r-lib.org/> package.  "
  },
  {
    "id": 18094,
    "package_name": "pmml",
    "title": "Generate PMML for Various Models",
    "description": "The Predictive Model Markup Language (PMML) is an XML-based language which provides a way for applications to define machine learning, statistical and data mining models and to share models between PMML compliant applications. More information about the PMML industry standard and the Data Mining Group can be found at <http://dmg.org/>. The generated PMML can be imported into any PMML consuming application, such as Zementis Predictive Analytics products. The package isofor (used for anomaly detection) can be installed with devtools::install_github(\"gravesee/isofor\").",
    "version": "2.5.2",
    "maintainer": "Dmitriy Bolotov <dmitriy.bolotov@softwareag.com>",
    "author": "Dmitriy Bolotov [aut, cre],\n  Tridivesh Jena [aut],\n  Graham Williams [aut],\n  Wen-Ching Lin [aut],\n  Michael Hahsler [aut],\n  Hemant Ishwaran [aut],\n  Udaya B. Kogalur [aut],\n  Rajarshi Guha [aut],\n  Software AG [cph]",
    "url": "https://open-source.softwareag.com/r-pmml/,\nhttps://github.com/SoftwareAG/r-pmml,\nhttps://www.softwareag.com/corporate/products/az/zementis/default.html",
    "bug_reports": "https://github.com/SoftwareAG/r-pmml/issues",
    "repository": "https://cran.r-project.org/package=pmml",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pmml Generate PMML for Various Models The Predictive Model Markup Language (PMML) is an XML-based language which provides a way for applications to define machine learning, statistical and data mining models and to share models between PMML compliant applications. More information about the PMML industry standard and the Data Mining Group can be found at <http://dmg.org/>. The generated PMML can be imported into any PMML consuming application, such as Zementis Predictive Analytics products. The package isofor (used for anomaly detection) can be installed with devtools::install_github(\"gravesee/isofor\").  "
  },
  {
    "id": 18130,
    "package_name": "polaroid",
    "title": "Create Hex Stickers with 'shiny'",
    "description": "Create hexagonal shape sticker image.\n  'polaroid' can be used in user's web browser.\n  'polaroid' can be used in 'shinyapps.io'.\n  In both way, user can download created 'hexSticker' as 'PNG' image.\n  'polaroid' is built based on 'argonDash', 'colourpicker' and 'hexSticker' R package.",
    "version": "0.2.1",
    "maintainer": "Jinhwan Kim <hwanistic@gmail.com>",
    "author": "Jinhwan Kim [aut, cre, cph]",
    "url": "https://github.com/jhk0530/polaroid",
    "bug_reports": "https://github.com/jhk0530/polaroid/issues",
    "repository": "https://cran.r-project.org/package=polaroid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "polaroid Create Hex Stickers with 'shiny' Create hexagonal shape sticker image.\n  'polaroid' can be used in user's web browser.\n  'polaroid' can be used in 'shinyapps.io'.\n  In both way, user can download created 'hexSticker' as 'PNG' image.\n  'polaroid' is built based on 'argonDash', 'colourpicker' and 'hexSticker' R package.  "
  },
  {
    "id": 18183,
    "package_name": "popPCR",
    "title": "Classify Digital PCR Droplets by Fitting Fluorescence\nPopulations",
    "description": "Estimates DNA target concentration by classifying digital PCR (polymerase chain reaction) droplets as positive, negative, or rain, using Expectation-Maximization Clustering. The fitting is accomplished using the 'EMMIXskew' R package (v. 1.0.3) by Kui Wang, Angus Ng, and Geoff McLachlan (2018) as based on their paper \"Multivariate Skew t Mixture Models: Applications to Fluorescence-Activated Cell Sorting Data\" <doi:10.1109/DICTA.2009.88>.",
    "version": "0.1.1.1",
    "maintainer": "Joyce Emlyn Guiao <joyce_emlyn_guiao@dlsu.edu.ph>",
    "author": "Joyce Emlyn Guiao [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=popPCR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "popPCR Classify Digital PCR Droplets by Fitting Fluorescence\nPopulations Estimates DNA target concentration by classifying digital PCR (polymerase chain reaction) droplets as positive, negative, or rain, using Expectation-Maximization Clustering. The fitting is accomplished using the 'EMMIXskew' R package (v. 1.0.3) by Kui Wang, Angus Ng, and Geoff McLachlan (2018) as based on their paper \"Multivariate Skew t Mixture Models: Applications to Fluorescence-Activated Cell Sorting Data\" <doi:10.1109/DICTA.2009.88>.  "
  },
  {
    "id": 18220,
    "package_name": "postpack",
    "title": "Utilities for Processing Posterior Samples Stored in\n'mcmc.lists'",
    "description": "The aim of 'postpack' is to provide the infrastructure for a standardized workflow for 'mcmc.list' objects.\n    These objects can be used to store output from models fitted with Bayesian inference using\n    'JAGS', 'WinBUGS', 'OpenBUGS', 'NIMBLE', 'Stan', or even custom MCMC algorithms. Although the 'coda' R package provides\n    some methods for these objects, it is somewhat limited in easily performing post-processing tasks for\n    specific nodes. Models are ever increasing in their complexity and the number of tracked nodes, and oftentimes\n    a user may wish to summarize/diagnose sampling behavior for only a small subset of nodes at a time\n    for a particular question or figure. Thus, many 'postpack' functions support performing tasks on a\n    subset of nodes, where the subset is specified with regular expressions. The functions in 'postpack'\n    streamline the extraction, summarization, and diagnostics of specific monitored nodes after model fitting.\n    Further, because there is rarely only ever one model under consideration, 'postpack' scales efficiently \n    to perform the same tasks on output from multiple models simultaneously, facilitating rapid assessment \n    of model sensitivity to changes in assumptions.",
    "version": "0.5.4",
    "maintainer": "Ben Staton <statonbe@gmail.com>",
    "author": "Ben Staton [aut, cre] (ORCID: <https://orcid.org/0000-0002-2342-3482>)",
    "url": "https://bstaton1.github.io/postpack/",
    "bug_reports": "https://github.com/bstaton1/postpack/issues",
    "repository": "https://cran.r-project.org/package=postpack",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "postpack Utilities for Processing Posterior Samples Stored in\n'mcmc.lists' The aim of 'postpack' is to provide the infrastructure for a standardized workflow for 'mcmc.list' objects.\n    These objects can be used to store output from models fitted with Bayesian inference using\n    'JAGS', 'WinBUGS', 'OpenBUGS', 'NIMBLE', 'Stan', or even custom MCMC algorithms. Although the 'coda' R package provides\n    some methods for these objects, it is somewhat limited in easily performing post-processing tasks for\n    specific nodes. Models are ever increasing in their complexity and the number of tracked nodes, and oftentimes\n    a user may wish to summarize/diagnose sampling behavior for only a small subset of nodes at a time\n    for a particular question or figure. Thus, many 'postpack' functions support performing tasks on a\n    subset of nodes, where the subset is specified with regular expressions. The functions in 'postpack'\n    streamline the extraction, summarization, and diagnostics of specific monitored nodes after model fitting.\n    Further, because there is rarely only ever one model under consideration, 'postpack' scales efficiently \n    to perform the same tasks on output from multiple models simultaneously, facilitating rapid assessment \n    of model sensitivity to changes in assumptions.  "
  },
  {
    "id": 18223,
    "package_name": "potions",
    "title": "Easy Options Management",
    "description": "Store and retrieve data from options() using syntax derived from\n    the 'here' package. 'potions' makes it straightforward to update and \n    retrieve options, either in the workspace or during package development, \n    without overwriting global options.",
    "version": "0.2.0",
    "maintainer": "Martin Westgate <martin.westgate@csiro.au>",
    "author": "Martin Westgate [aut, cre]",
    "url": "https://potions.ala.org.au",
    "bug_reports": "https://github.com/AtlasOfLivingAustralia/potions/issues",
    "repository": "https://cran.r-project.org/package=potions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "potions Easy Options Management Store and retrieve data from options() using syntax derived from\n    the 'here' package. 'potions' makes it straightforward to update and \n    retrieve options, either in the workspace or during package development, \n    without overwriting global options.  "
  },
  {
    "id": 18224,
    "package_name": "potools",
    "title": "Tools for Internationalization and Portability in R Packages",
    "description": "Translating messages in R packages is managed using the po\n    top-level directory and the 'gettext' program. This package provides\n    some helper functions for building this support in R packages, e.g.\n    common validation & I/O tasks.",
    "version": "0.2.4",
    "maintainer": "Michael Chirico <MichaelChirico4@gmail.com>",
    "author": "Michael Chirico [cre, aut],\n  Hadley Wickham [aut]",
    "url": "https://github.com/MichaelChirico/potools,\nhttps://michaelchirico.github.io/potools/",
    "bug_reports": "https://github.com/MichaelChirico/potools/issues",
    "repository": "https://cran.r-project.org/package=potools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "potools Tools for Internationalization and Portability in R Packages Translating messages in R packages is managed using the po\n    top-level directory and the 'gettext' program. This package provides\n    some helper functions for building this support in R packages, e.g.\n    common validation & I/O tasks.  "
  },
  {
    "id": 18230,
    "package_name": "poweRbal",
    "title": "Phylogenetic Tree Models and the Power of Tree Shape Statistics",
    "description": "The first goal of this package is to provide a multitude of tree models,\n    i.e., functions that generate rooted binary trees with a given number of leaves.\n    Second, the package allows for an easy evaluation and comparison of tree shape\n    statistics by estimating their power to differentiate between different tree models.\n    Please note that this R package was developed alongside the manuscript\n    \"Tree balance in phylogenetic models\" by\n    S. J. Kersting, K. Wicke, and M. Fischer (2024) <doi:10.48550/arXiv.2406.05185>,\n    which provides further background and the respective mathematical definitions.\n    This project was supported by the project ArtIGROW, which is a part of the\n    WIR!-Alliance ArtIFARM \u2013  Artificial Intelligence in Farming funded by the\n    German Federal Ministry of Education and Research (No. 03WIR4805).",
    "version": "0.0.1.1",
    "maintainer": "Sophie Kersting <sophie_kersting@gmx.de>",
    "author": "Sophie Kersting [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1038-9246>),\n  Kristina Wicke [aut] (ORCID: <https://orcid.org/0000-0002-4275-5546>),\n  Mareike Fischer [aut] (ORCID: <https://orcid.org/0000-0002-9429-0859>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=poweRbal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "poweRbal Phylogenetic Tree Models and the Power of Tree Shape Statistics The first goal of this package is to provide a multitude of tree models,\n    i.e., functions that generate rooted binary trees with a given number of leaves.\n    Second, the package allows for an easy evaluation and comparison of tree shape\n    statistics by estimating their power to differentiate between different tree models.\n    Please note that this R package was developed alongside the manuscript\n    \"Tree balance in phylogenetic models\" by\n    S. J. Kersting, K. Wicke, and M. Fischer (2024) <doi:10.48550/arXiv.2406.05185>,\n    which provides further background and the respective mathematical definitions.\n    This project was supported by the project ArtIGROW, which is a part of the\n    WIR!-Alliance ArtIFARM \u2013  Artificial Intelligence in Farming funded by the\n    German Federal Ministry of Education and Research (No. 03WIR4805).  "
  },
  {
    "id": 18244,
    "package_name": "powerbrmsINLA",
    "title": "Bayesian Power Analysis Using 'brms' and 'INLA'",
    "description": "Provides tools for Bayesian power analysis and assurance calculations using the statistical frameworks of 'brms' and 'INLA'. Includes simulation-based approaches, support for multiple decision rules (direction, threshold, ROPE), sequential designs, and visualisation helpers. Methods are based on Kruschke (2014, ISBN:9780124058880) \"Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan\", O'Hagan & Stevens (2001) <doi:10.1177/0272989X0102100307> \"Bayesian Assessment of Sample Size for Clinical Trials of Cost-Effectiveness\", Kruschke (2018) <doi:10.1177/2515245918771304> \"Rejecting or Accepting Parameter Values in Bayesian Estimation\", Rue et al. (2009) <doi:10.1111/j.1467-9868.2008.00700.x> \"Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations\", and B\u00fcrkner (2017) <doi:10.18637/jss.v080.i01> \"brms: An R Package for Bayesian Multilevel Models using Stan\".",
    "version": "1.1.1",
    "maintainer": "Tony Myers <admyers@aol.com>",
    "author": "Tony Myers [aut, cre] (ORCID: <https://orcid.org/0000-0003-4516-4829>)",
    "url": "https://github.com/Tony-Myers/powerbrmsINLA",
    "bug_reports": "https://github.com/Tony-Myers/powerbrmsINLA/issues",
    "repository": "https://cran.r-project.org/package=powerbrmsINLA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "powerbrmsINLA Bayesian Power Analysis Using 'brms' and 'INLA' Provides tools for Bayesian power analysis and assurance calculations using the statistical frameworks of 'brms' and 'INLA'. Includes simulation-based approaches, support for multiple decision rules (direction, threshold, ROPE), sequential designs, and visualisation helpers. Methods are based on Kruschke (2014, ISBN:9780124058880) \"Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan\", O'Hagan & Stevens (2001) <doi:10.1177/0272989X0102100307> \"Bayesian Assessment of Sample Size for Clinical Trials of Cost-Effectiveness\", Kruschke (2018) <doi:10.1177/2515245918771304> \"Rejecting or Accepting Parameter Values in Bayesian Estimation\", Rue et al. (2009) <doi:10.1111/j.1467-9868.2008.00700.x> \"Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations\", and B\u00fcrkner (2017) <doi:10.18637/jss.v080.i01> \"brms: An R Package for Bayesian Multilevel Models using Stan\".  "
  },
  {
    "id": 18247,
    "package_name": "powerindexR",
    "title": "Measuring the Power in Voting Systems",
    "description": "This R package allows the determination of some distributions of the voters' power when passing laws in weighted voting situations.",
    "version": "1.6",
    "maintainer": "Livino M. Armijos-Toro <livinoa@gmail.com>",
    "author": "Livino M. Armijos-Toro [aut, cre],\n  Jose M. Alonso-Meijide [aut],\n  Manuel A. Mosquera [aut],\n  Alejandro Saavedra-Nieves [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=powerindexR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "powerindexR Measuring the Power in Voting Systems This R package allows the determination of some distributions of the voters' power when passing laws in weighted voting situations.  "
  },
  {
    "id": 18255,
    "package_name": "ppcSpatial",
    "title": "Spatial Analysis of Pakistan Population Census",
    "description": "Spatial Analysis for exploration of Pakistan Population Census 2017 (<https://www.pbs.gov.pk/content/population-census>). It uses data from R package 'PakPC2017'.",
    "version": "0.3.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Arfan Dilber [aut, ctb]",
    "url": "https://github.com/MYaseen208/ppcSpatial",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ppcSpatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ppcSpatial Spatial Analysis of Pakistan Population Census Spatial Analysis for exploration of Pakistan Population Census 2017 (<https://www.pbs.gov.pk/content/population-census>). It uses data from R package 'PakPC2017'.  "
  },
  {
    "id": 18285,
    "package_name": "pracpac",
    "title": "Practical 'R' Packaging in 'Docker'",
    "description": "Streamline the creation of 'Docker' images with 'R' packages and dependencies embedded. The 'pracpac' package provides a 'usethis'-like interface to creating Dockerfiles with dependencies managed by 'renv'. The 'pracpac' functionality is described in Nagraj and Turner (2023) <doi:10.48550/arXiv.2303.07876>.",
    "version": "0.2.0",
    "maintainer": "VP Nagraj <nagraj@nagraj.net>",
    "author": "Stephen Turner [aut] (ORCID: <https://orcid.org/0000-0001-9140-9028>),\n  VP Nagraj [cre, aut] (ORCID: <https://orcid.org/0000-0003-0060-566X>),\n  Signature Science, LLC. [cph]",
    "url": "https://signaturescience.github.io/pracpac/,\nhttps://github.com/signaturescience/pracpac/",
    "bug_reports": "https://github.com/signaturescience/pracpac/issues",
    "repository": "https://cran.r-project.org/package=pracpac",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pracpac Practical 'R' Packaging in 'Docker' Streamline the creation of 'Docker' images with 'R' packages and dependencies embedded. The 'pracpac' package provides a 'usethis'-like interface to creating Dockerfiles with dependencies managed by 'renv'. The 'pracpac' functionality is described in Nagraj and Turner (2023) <doi:10.48550/arXiv.2303.07876>.  "
  },
  {
    "id": 18288,
    "package_name": "praise",
    "title": "Praise Users",
    "description": "Build friendly R packages that\n    praise their users if they have done something\n    good, or they just need it to feel better.",
    "version": "1.0.0",
    "maintainer": "Gabor Csardi <csardi.gabor@gmail.com>",
    "author": "Gabor Csardi, Sindre Sorhus",
    "url": "https://github.com/gaborcsardi/praise",
    "bug_reports": "https://github.com/gaborcsardi/praise/issues",
    "repository": "https://cran.r-project.org/package=praise",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "praise Praise Users Build friendly R packages that\n    praise their users if they have done something\n    good, or they just need it to feel better.  "
  },
  {
    "id": 18318,
    "package_name": "prefeR",
    "title": "R Package for Pairwise Preference Elicitation",
    "description": "Allows users to derive multi-objective weights from pairwise comparisons, which\n    research shows is more repeatable, transparent, and intuitive other techniques. These weights\n    can be rank existing alternatives or to define a multi-objective utility function for optimization.",
    "version": "0.1.3",
    "maintainer": "John Lepird <jlepird@alum.mit.edu>",
    "author": "John Lepird",
    "url": "https://github.com/jlepird/prefeR,\nhttps://jlepird.github.io/prefeR/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=prefeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prefeR R Package for Pairwise Preference Elicitation Allows users to derive multi-objective weights from pairwise comparisons, which\n    research shows is more repeatable, transparent, and intuitive other techniques. These weights\n    can be rank existing alternatives or to define a multi-objective utility function for optimization.  "
  },
  {
    "id": 18370,
    "package_name": "prioriactions",
    "title": "Multi-Action Conservation Planning",
    "description": "This uses a mixed integer mathematical programming (MIP)\n        approach for building and solving multi-action planning problems, \n        where the goal is to find an optimal combination of management actions that\n        abate threats, in an efficient way while accounting for spatial aspects. \n        Thus, optimizing the connectivity and conservation effectiveness of \n        the prioritized units and of the deployed actions. The package is capable of \n        handling different commercial (gurobi, CPLEX) and non-commercial (symphony, CBC) MIP solvers. \n        Gurobi optimization solver can be installed using comprehensive instructions in \n        the 'gurobi' installation vignette of the prioritizr package (available in \n        <https://prioritizr.net/articles/gurobi_installation_guide.html>). Instead, 'CPLEX'\n        optimization solver can be obtain from IBM CPLEX web page (available here \n        <https://www.ibm.com/es-es/products/ilog-cplex-optimization-studio>). Additionally, \n        the 'rcbc' R package (available at\n    <https://github.com/dirkschumacher/rcbc>) can be used to obtain solutions\n    using the CBC optimization software (<https://github.com/coin-or/Cbc>). Methods used in the \n        package refers to Salgado-Rojas et al. (2020) <doi:10.1016/j.ecolmodel.2019.108901>,\n        Beyer et al. (2016) <doi:10.1016/j.ecolmodel.2016.02.005>, Cattarino et al. (2015)\n        <doi:10.1371/journal.pone.0128027> and Watts et al. (2009) <doi:10.1016/j.envsoft.2009.06.005>. \n        See the prioriactions website for more information, documentations and examples.",
    "version": "0.5.0",
    "maintainer": "Jose Salgado-Rojas <jose.salgroj@gmail.com>",
    "author": "Jose Salgado-Rojas [aut, cre],\n  Irlanda Ceballos-Fuentealba [aut],\n  Virgilio Hermoso [aut],\n  Eduardo Alvarez-Miranda [aut],\n  Jordi Garcia-Gonzalo [aut]",
    "url": "https://prioriactions.github.io/prioriactions/,\nhttps://github.com/prioriactions/prioriactions",
    "bug_reports": "https://github.com/prioriactions/prioriactions/issues",
    "repository": "https://cran.r-project.org/package=prioriactions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prioriactions Multi-Action Conservation Planning This uses a mixed integer mathematical programming (MIP)\n        approach for building and solving multi-action planning problems, \n        where the goal is to find an optimal combination of management actions that\n        abate threats, in an efficient way while accounting for spatial aspects. \n        Thus, optimizing the connectivity and conservation effectiveness of \n        the prioritized units and of the deployed actions. The package is capable of \n        handling different commercial (gurobi, CPLEX) and non-commercial (symphony, CBC) MIP solvers. \n        Gurobi optimization solver can be installed using comprehensive instructions in \n        the 'gurobi' installation vignette of the prioritizr package (available in \n        <https://prioritizr.net/articles/gurobi_installation_guide.html>). Instead, 'CPLEX'\n        optimization solver can be obtain from IBM CPLEX web page (available here \n        <https://www.ibm.com/es-es/products/ilog-cplex-optimization-studio>). Additionally, \n        the 'rcbc' R package (available at\n    <https://github.com/dirkschumacher/rcbc>) can be used to obtain solutions\n    using the CBC optimization software (<https://github.com/coin-or/Cbc>). Methods used in the \n        package refers to Salgado-Rojas et al. (2020) <doi:10.1016/j.ecolmodel.2019.108901>,\n        Beyer et al. (2016) <doi:10.1016/j.ecolmodel.2016.02.005>, Cattarino et al. (2015)\n        <doi:10.1371/journal.pone.0128027> and Watts et al. (2009) <doi:10.1016/j.envsoft.2009.06.005>. \n        See the prioriactions website for more information, documentations and examples.  "
  },
  {
    "id": 18371,
    "package_name": "prioritizr",
    "title": "Systematic Conservation Prioritization in R",
    "description": "\n    Systematic conservation prioritization using mixed integer linear\n    programming (MILP). It provides a flexible interface for building and\n    solving conservation planning problems. Once built, conservation planning\n    problems can be solved using a variety of commercial and open-source exact\n    algorithm solvers. By using exact algorithm solvers, solutions can be\n    generated that are guaranteed to be optimal (or within a pre-specified\n    optimality gap). Furthermore, conservation problems can be constructed to\n    optimize the spatial allocation of different management actions or zones,\n    meaning that conservation practitioners can identify solutions that benefit\n    multiple stakeholders. To solve large-scale or complex conservation\n    planning problems, users should install the Gurobi optimization software\n    (available from <https://www.gurobi.com/>) and the 'gurobi' R package (see\n    Gurobi Installation Guide vignette for details). Users can also install the\n    IBM CPLEX software (<https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer>) and\n    the 'cplexAPI' R package (available at <https://github.com/cran/cplexAPI>).\n    Additionally, the 'rcbc' R package (available at\n    <https://github.com/dirkschumacher/rcbc>) can be used to generate solutions\n    using the CBC optimization software (<https://github.com/coin-or/Cbc>). For\n    further details, see Hanson et al. (2025) <doi:10.1111/cobi.14376>.",
    "version": "8.1.0",
    "maintainer": "Richard Schuster <richard.schuster@glel.carleton.ca>",
    "author": "Jeffrey O Hanson [aut] (ORCID: <https://orcid.org/0000-0002-4716-6134>),\n  Richard Schuster [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3191-7869>),\n  Nina Morrell [aut],\n  Matthew Strimas-Mackey [aut] (ORCID:\n    <https://orcid.org/0000-0001-8929-7776>),\n  Brandon P M Edwards [aut] (ORCID:\n    <https://orcid.org/0000-0003-0865-3076>),\n  Matthew E Watts [aut],\n  Peter Arcese [aut] (ORCID: <https://orcid.org/0000-0002-8097-482X>),\n  Joseph R Bennett [aut] (ORCID: <https://orcid.org/0000-0002-3901-9513>),\n  Hugh P Possingham [aut] (ORCID:\n    <https://orcid.org/0000-0001-7755-996X>)",
    "url": "https://prioritizr.net, https://github.com/prioritizr/prioritizr",
    "bug_reports": "https://github.com/prioritizr/prioritizr/issues",
    "repository": "https://cran.r-project.org/package=prioritizr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prioritizr Systematic Conservation Prioritization in R \n    Systematic conservation prioritization using mixed integer linear\n    programming (MILP). It provides a flexible interface for building and\n    solving conservation planning problems. Once built, conservation planning\n    problems can be solved using a variety of commercial and open-source exact\n    algorithm solvers. By using exact algorithm solvers, solutions can be\n    generated that are guaranteed to be optimal (or within a pre-specified\n    optimality gap). Furthermore, conservation problems can be constructed to\n    optimize the spatial allocation of different management actions or zones,\n    meaning that conservation practitioners can identify solutions that benefit\n    multiple stakeholders. To solve large-scale or complex conservation\n    planning problems, users should install the Gurobi optimization software\n    (available from <https://www.gurobi.com/>) and the 'gurobi' R package (see\n    Gurobi Installation Guide vignette for details). Users can also install the\n    IBM CPLEX software (<https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer>) and\n    the 'cplexAPI' R package (available at <https://github.com/cran/cplexAPI>).\n    Additionally, the 'rcbc' R package (available at\n    <https://github.com/dirkschumacher/rcbc>) can be used to generate solutions\n    using the CBC optimization software (<https://github.com/coin-or/Cbc>). For\n    further details, see Hanson et al. (2025) <doi:10.1111/cobi.14376>.  "
  },
  {
    "id": 18381,
    "package_name": "prmisc",
    "title": "Miscellaneous Printing of Numeric and Statistical Output in R\nMarkdown and Quarto Documents",
    "description": "Miscellaneous printing of numeric or statistical results in R Markdown or Quarto documents according to guidelines of the \"Publication Manual\" of the American Psychological Association (2020, ISBN: 978-1-4338-3215-4). These guidelines are usually referred to as APA style (<https://apastyle.apa.org/>) and include specific rules on the formatting of numbers and statistical test results. APA style has to be implemented when submitting scientific reports in a wide range of research fields, especially in the social sciences. The default output of numbers in the R console or R Markdown and Quarto documents does not meet the APA style requirements, and reformatting results manually can be cumbersome and error-prone. This package covers the automatic conversion of R objects to textual representations that meet the APA style requirements, which can be included in R Markdown or Quarto documents. It covers some basic statistical tests (t-test, ANOVA, correlation, chi-squared test, Wilcoxon test) as well as some basic number printing manipulations (formatting p-values, removing leading zeros for numbers that cannot be greater than one, and others). Other packages exist for formatting numbers and tests according to the APA style guidelines, such as 'papaja' (<https://cran.r-project.org/package=papaja>) and 'apa' (<https://cran.r-project.org/package=apa>), but they do not offer all convenience functionality included in 'prmisc'. The vignette has an overview of most of the functions included in the package.",
    "version": "0.0.3",
    "maintainer": "Martin Papenberg <martin.papenberg@hhu.de>",
    "author": "Martin Papenberg [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9900-4268>),\n  Juliane V. Nagel [aut] (ORCID: <https://orcid.org/0000-0002-5310-8088>)",
    "url": "https://github.com/m-Py/prmisc",
    "bug_reports": "https://github.com/m-Py/prmisc/issues",
    "repository": "https://cran.r-project.org/package=prmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prmisc Miscellaneous Printing of Numeric and Statistical Output in R\nMarkdown and Quarto Documents Miscellaneous printing of numeric or statistical results in R Markdown or Quarto documents according to guidelines of the \"Publication Manual\" of the American Psychological Association (2020, ISBN: 978-1-4338-3215-4). These guidelines are usually referred to as APA style (<https://apastyle.apa.org/>) and include specific rules on the formatting of numbers and statistical test results. APA style has to be implemented when submitting scientific reports in a wide range of research fields, especially in the social sciences. The default output of numbers in the R console or R Markdown and Quarto documents does not meet the APA style requirements, and reformatting results manually can be cumbersome and error-prone. This package covers the automatic conversion of R objects to textual representations that meet the APA style requirements, which can be included in R Markdown or Quarto documents. It covers some basic statistical tests (t-test, ANOVA, correlation, chi-squared test, Wilcoxon test) as well as some basic number printing manipulations (formatting p-values, removing leading zeros for numbers that cannot be greater than one, and others). Other packages exist for formatting numbers and tests according to the APA style guidelines, such as 'papaja' (<https://cran.r-project.org/package=papaja>) and 'apa' (<https://cran.r-project.org/package=apa>), but they do not offer all convenience functionality included in 'prmisc'. The vignette has an overview of most of the functions included in the package.  "
  },
  {
    "id": 18396,
    "package_name": "procmaps",
    "title": "Portable Address Space Mapping",
    "description": "Portable '/proc/self/maps' as a data frame.\n    Determine which library or other region is mapped to a specific\n    address of a process. --\n    R packages can contain native code, compiled to shared libraries at build or\n    installation time.\n    When loaded, each shared library occupies a portion of the address space of\n    the main process.\n    When only a machine instruction pointer is available (e.g. from a backtrace\n    during error inspection or profiling), the address space map determines\n    which library this instruction pointer corresponds to.",
    "version": "0.0.5",
    "maintainer": "Kirill M\u00fcller <kirill@cynkra.com>",
    "author": "Kirill M\u00fcller [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1416-3412>),\n  R Consortium [fnd],\n  Kostya Serebryany [ctb] (Bundled gperftools library),\n  Sanjay Ghemawat [ctb] (Bundled gperftools library),\n  Craig Silverstein [ctb] (Bundled gperftools library),\n  Google Inc. [cph] (Bundled gperftools library)",
    "url": "https://r-prof.github.io/procmaps/,\nhttps://github.com/r-prof/procmaps",
    "bug_reports": "https://github.com/r-prof/procmaps/issues",
    "repository": "https://cran.r-project.org/package=procmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "procmaps Portable Address Space Mapping Portable '/proc/self/maps' as a data frame.\n    Determine which library or other region is mapped to a specific\n    address of a process. --\n    R packages can contain native code, compiled to shared libraries at build or\n    installation time.\n    When loaded, each shared library occupies a portion of the address space of\n    the main process.\n    When only a machine instruction pointer is available (e.g. from a backtrace\n    during error inspection or profiling), the address space map determines\n    which library this instruction pointer corresponds to.  "
  },
  {
    "id": 18428,
    "package_name": "prompt",
    "title": "Dynamic 'R' Prompt",
    "description": "Set the 'R' prompt dynamically, from a function. The package\n    contains some examples to include various useful dynamic information\n    in the prompt: the status of the last command (success or failure);\n    the amount of memory allocated by the current 'R' process; the name of\n    the R package(s) loaded by 'pkgload' and/or 'devtools'; various 'git'\n    information: the name of the active branch, whether it is dirty,\n    if it needs pushes pulls. You can also create your own prompt if you\n    don't like the predefined examples.",
    "version": "1.0.2",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi",
    "url": "https://github.com/gaborcsardi/prompt",
    "bug_reports": "https://github.com/gaborcsardi/prompt/issues",
    "repository": "https://cran.r-project.org/package=prompt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prompt Dynamic 'R' Prompt Set the 'R' prompt dynamically, from a function. The package\n    contains some examples to include various useful dynamic information\n    in the prompt: the status of the last command (success or failure);\n    the amount of memory allocated by the current 'R' process; the name of\n    the R package(s) loaded by 'pkgload' and/or 'devtools'; various 'git'\n    information: the name of the active branch, whether it is dirty,\n    if it needs pushes pulls. You can also create your own prompt if you\n    don't like the predefined examples.  "
  },
  {
    "id": 18472,
    "package_name": "psHarmonize",
    "title": "Creates a Harmonized Dataset Based on a Set of Instructions",
    "description": "Functions which facilitate harmonization of data from multiple\n    different datasets. Data harmonization involves taking data sources with\n    differing values, creating coding instructions to create a harmonized\n    set of values, then making those data modifications. 'psHarmonize' will\n    assist with data modification once the harmonization instructions are\n    written. Coding instructions are written by the user to create a\n    \"harmonization sheet\". This sheet catalogs variable names, domains\n    (e.g. clinical, behavioral, outcomes), provides R code instructions for\n    mapping or conversion of data, specifies the variable name in the\n    harmonized data set, and tracks notes. The package will then harmonize\n    the source datasets according to the harmonization sheet to create a\n    harmonized dataset. Once harmonization is finished, the package also has\n    functions that will create descriptive statistics using 'RMarkdown'. Data\n    Harmonization guidelines have been described by Fortier I, Raina P,\n    Van den Heuvel ER, et al. (2017) <doi:10.1093/ije/dyw075>. Additional\n    details of our R package have been described by Stephen JJ, Carolan P,\n    Krefman AE, et al. (2024) <doi:10.1016/j.patter.2024.101003>.",
    "version": "0.3.6",
    "maintainer": "John Stephen <John.Stephen@northwestern.edu>",
    "author": "John Stephen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7309-9193>),\n  Maxwell Mansolf [ctb] (ORCID: <https://orcid.org/0000-0001-6861-8657>)",
    "url": "https://github.com/NUDACC/psHarmonize",
    "bug_reports": "https://github.com/NUDACC/psHarmonize/issues",
    "repository": "https://cran.r-project.org/package=psHarmonize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "psHarmonize Creates a Harmonized Dataset Based on a Set of Instructions Functions which facilitate harmonization of data from multiple\n    different datasets. Data harmonization involves taking data sources with\n    differing values, creating coding instructions to create a harmonized\n    set of values, then making those data modifications. 'psHarmonize' will\n    assist with data modification once the harmonization instructions are\n    written. Coding instructions are written by the user to create a\n    \"harmonization sheet\". This sheet catalogs variable names, domains\n    (e.g. clinical, behavioral, outcomes), provides R code instructions for\n    mapping or conversion of data, specifies the variable name in the\n    harmonized data set, and tracks notes. The package will then harmonize\n    the source datasets according to the harmonization sheet to create a\n    harmonized dataset. Once harmonization is finished, the package also has\n    functions that will create descriptive statistics using 'RMarkdown'. Data\n    Harmonization guidelines have been described by Fortier I, Raina P,\n    Van den Heuvel ER, et al. (2017) <doi:10.1093/ije/dyw075>. Additional\n    details of our R package have been described by Stephen JJ, Carolan P,\n    Krefman AE, et al. (2024) <doi:10.1016/j.patter.2024.101003>.  "
  },
  {
    "id": 18552,
    "package_name": "pumilioR",
    "title": "Pumilio in R",
    "description": "R package to query and get data out of a Pumilio sound archive system (http://ljvillanueva.github.io/pumilio/).",
    "version": "1.3.1",
    "maintainer": "Luis J. Villanueva-Rivera <ljvillanueva@coquipr.com>",
    "author": "Luis J. Villanueva-Rivera",
    "url": "http://ljvillanueva.github.io/pumilioR/",
    "bug_reports": "https://github.com/ljvillanueva/pumilioR/issues",
    "repository": "https://cran.r-project.org/package=pumilioR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pumilioR Pumilio in R R package to query and get data out of a Pumilio sound archive system (http://ljvillanueva.github.io/pumilio/).  "
  },
  {
    "id": 18558,
    "package_name": "purging",
    "title": "Simple Method for Purging Mediation Effects among Independent\nVariables",
    "description": "Simple method of purging independent variables of mediating effects. First, regress the direct variable on the indirect variable. Then, used the stored residuals as the new purged (direct) variable in the updated specification. This purging process allows for use of a new direct variable uncorrelated with the indirect variable. Please cite the method and/or package using Waggoner, Philip D. (2018) <doi:10.1177/1532673X18759644>.",
    "version": "1.0.0",
    "maintainer": "Philip D. Waggoner <philip.waggoner@gmail.com>",
    "author": "Philip D. Waggoner <philip.waggoner@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=purging",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "purging Simple Method for Purging Mediation Effects among Independent\nVariables Simple method of purging independent variables of mediating effects. First, regress the direct variable on the indirect variable. Then, used the stored residuals as the new purged (direct) variable in the updated specification. This purging process allows for use of a new direct variable uncorrelated with the indirect variable. Please cite the method and/or package using Waggoner, Philip D. (2018) <doi:10.1177/1532673X18759644>.  "
  },
  {
    "id": 18584,
    "package_name": "pwrss",
    "title": "Statistical Power and Sample Size Calculation Tools",
    "description": "\n  The 'pwrss' R package provides flexible and comprehensive functions for\n  statistical power and minimum required sample size calculations across a wide\n  range of commonly used hypothesis tests in psychological, biomedical, and\n  social sciences.",
    "version": "1.0.0",
    "maintainer": "Metin Bulus <bulusmetin@gmail.com>",
    "author": "Metin Bulus [aut, cre],\n  Sebastian Jentschke [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pwrss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pwrss Statistical Power and Sample Size Calculation Tools \n  The 'pwrss' R package provides flexible and comprehensive functions for\n  statistical power and minimum required sample size calculations across a wide\n  range of commonly used hypothesis tests in psychological, biomedical, and\n  social sciences.  "
  },
  {
    "id": 18590,
    "package_name": "pxweb",
    "title": "R Interface to PXWEB APIs",
    "description": "Generic interface for the PX-Web/PC-Axis API. The\n    PX-Web/PC-Axis API is used by organizations such as Statistics Sweden\n    and Statistics Finland to disseminate data. The R package can interact\n    with all PX-Web/PC-Axis APIs to fetch information about the data\n    hierarchy, extract metadata and extract and parse statistics to R\n    data.frame format. PX-Web is a solution to disseminate PC-Axis data\n    files in dynamic tables on the web.  Since 2013 PX-Web contains an API\n    to disseminate PC-Axis files.",
    "version": "0.17.0",
    "maintainer": "Mans Magnusson <mons.magnusson@gmail.com>",
    "author": "Mans Magnusson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0296-2719>),\n  Markus Kainu [aut],\n  Janne Huovari [aut],\n  Leo Lahti [aut] (ORCID: <https://orcid.org/0000-0001-5537-637X>),\n  Love Hansson [ctb],\n  Eydun Nielsen [ctb],\n  Bo Werth [ctb],\n  Thomas Runarsson [ctb],\n  Torbj\u00f6rn Lindquist [ctb],\n  Palmar Thorsteinsson [ctb],\n  Pyry Kantanen [ctb],\n  Sebastian Ankargren [ctb]",
    "url": "https://github.com/rOpenGov/pxweb/,\nhttps://ropengov.github.io/pxweb/,\nhttps://github.com/rOpenGov/pxweb",
    "bug_reports": "https://github.com/rOpenGov/pxweb/issues",
    "repository": "https://cran.r-project.org/package=pxweb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pxweb R Interface to PXWEB APIs Generic interface for the PX-Web/PC-Axis API. The\n    PX-Web/PC-Axis API is used by organizations such as Statistics Sweden\n    and Statistics Finland to disseminate data. The R package can interact\n    with all PX-Web/PC-Axis APIs to fetch information about the data\n    hierarchy, extract metadata and extract and parse statistics to R\n    data.frame format. PX-Web is a solution to disseminate PC-Axis data\n    files in dynamic tables on the web.  Since 2013 PX-Web contains an API\n    to disseminate PC-Axis files.  "
  },
  {
    "id": 18596,
    "package_name": "pysd2r",
    "title": "API to 'Python' Library 'pysd'",
    "description": "Using the R package 'reticulate', this package creates an interface to the 'pysd' toolset.\n    The package provides an R interface to a number of 'pysd' functions, and can read files in\n    'Vensim' 'mdl' format, and 'xmile' format. The resulting simulations are returned as a 'tibble', and from \n    that the results can be processed using 'dplyr' and 'ggplot2'. The package has been tested  using 'python3'.",
    "version": "0.1.0",
    "maintainer": "Jim Duggan <jim.duggan@nuigalway.ie>",
    "author": "Jim Duggan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pysd2r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pysd2r API to 'Python' Library 'pysd' Using the R package 'reticulate', this package creates an interface to the 'pysd' toolset.\n    The package provides an R interface to a number of 'pysd' functions, and can read files in\n    'Vensim' 'mdl' format, and 'xmile' format. The resulting simulations are returned as a 'tibble', and from \n    that the results can be processed using 'dplyr' and 'ggplot2'. The package has been tested  using 'python3'.  "
  },
  {
    "id": 18623,
    "package_name": "qcr",
    "title": "Quality Control Review",
    "description": "Univariate and multivariate SQC tools that completes and increases\n    the SQC techniques available in R. Apart from integrating different R packages \n    devoted to SQC ('qcc','MSQC'), provides nonparametric tools that are highly \n    useful when Gaussian assumption is not met. \n    This package computes standard univariate control charts for individual measurements, \n    'X-bar', 'S', 'R', 'p', 'np', 'c', 'u', 'EWMA' and 'CUSUM'. In addition, it \n    includes functions to perform multivariate control charts such as 'Hotelling T2', \n    'MEWMA' and 'MCUSUM'. As representative feature, multivariate nonparametric \n    alternatives based on data depth are implemented in this package: 'r', 'Q' and \n    'S' control charts. In addition, Phase I and II control charts for functional \n    data are included. This package also allows the estimation of the most complete \n    set of capability indices from first to fourth generation, covering the nonparametric \n    alternatives, and performing the corresponding capability analysis graphical outputs,\n    including the process capability plots. See Flores et al. (2021) <doi:10.32614/RJ-2021-034>.",
    "version": "1.4",
    "maintainer": "Miguel Flores <ma.flores@outlook.com>",
    "author": "Miguel Flores [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7742-1247>),\n  Ruben Fernandez-Casal [aut] (ORCID:\n    <https://orcid.org/0000-0002-5785-3739>),\n  Salvador Naya [aut],\n  Javier Tarrio-Saavedra [aut]",
    "url": "https://github.com/mflores72000/qcr",
    "bug_reports": "https://github.com/mflores72000/qcr/issues",
    "repository": "https://cran.r-project.org/package=qcr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "qcr Quality Control Review Univariate and multivariate SQC tools that completes and increases\n    the SQC techniques available in R. Apart from integrating different R packages \n    devoted to SQC ('qcc','MSQC'), provides nonparametric tools that are highly \n    useful when Gaussian assumption is not met. \n    This package computes standard univariate control charts for individual measurements, \n    'X-bar', 'S', 'R', 'p', 'np', 'c', 'u', 'EWMA' and 'CUSUM'. In addition, it \n    includes functions to perform multivariate control charts such as 'Hotelling T2', \n    'MEWMA' and 'MCUSUM'. As representative feature, multivariate nonparametric \n    alternatives based on data depth are implemented in this package: 'r', 'Q' and \n    'S' control charts. In addition, Phase I and II control charts for functional \n    data are included. This package also allows the estimation of the most complete \n    set of capability indices from first to fourth generation, covering the nonparametric \n    alternatives, and performing the corresponding capability analysis graphical outputs,\n    including the process capability plots. See Flores et al. (2021) <doi:10.32614/RJ-2021-034>.  "
  },
  {
    "id": 18688,
    "package_name": "qspray",
    "title": "Multivariate Polynomials with Rational Coefficients",
    "description": "Symbolic calculation and evaluation of multivariate\n    polynomials with rational coefficients. This package is strongly\n    inspired by the 'spray' package. It provides a function to \n    compute Gr\u00f6bner bases (reference <doi:10.1007/978-3-319-16721-3>). It \n    also includes some features for symmetric polynomials, such as the Hall\n    inner product.\n    The header file of the C++ code can be used by other packages. It \n    provides the templated class 'Qspray' that can be used to represent and \n    to deal with multivariate polynomials with another type of coefficients.",
    "version": "3.1.0",
    "maintainer": "St\u00e9phane Laurent <laurent_step@outlook.fr>",
    "author": "St\u00e9phane Laurent [aut, cre],\n  Robin Hankin [ctb, cph] (author of the 'spray' package, which strongly\n    inspired this package)",
    "url": "https://github.com/stla/qspray",
    "bug_reports": "https://github.com/stla/qspray/issues",
    "repository": "https://cran.r-project.org/package=qspray",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "qspray Multivariate Polynomials with Rational Coefficients Symbolic calculation and evaluation of multivariate\n    polynomials with rational coefficients. This package is strongly\n    inspired by the 'spray' package. It provides a function to \n    compute Gr\u00f6bner bases (reference <doi:10.1007/978-3-319-16721-3>). It \n    also includes some features for symmetric polynomials, such as the Hall\n    inner product.\n    The header file of the C++ code can be used by other packages. It \n    provides the templated class 'Qspray' that can be used to represent and \n    to deal with multivariate polynomials with another type of coefficients.  "
  },
  {
    "id": 18689,
    "package_name": "qst",
    "title": "Store Tables in SQL Database",
    "description": "Provides functions for quickly writing (and \n  reading back) a data.frame to file in 'SQLite' format. The name \n  stands for *Store Tables using 'SQLite'*, or alternatively for *Quick \n  Store Tables* (either way, it could be pronounced as *Quest*). \n  For data.frames containing the supported data \n  types it is intended to work as a drop-in replacement for the \n  'write_*()' and 'read_*()' functions provided by similar packages. ",
    "version": "0.1.2",
    "maintainer": "Magnus Thor Torfason <m@zulutime.net>",
    "author": "Magnus Thor Torfason",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=qst",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "qst Store Tables in SQL Database Provides functions for quickly writing (and \n  reading back) a data.frame to file in 'SQLite' format. The name \n  stands for *Store Tables using 'SQLite'*, or alternatively for *Quick \n  Store Tables* (either way, it could be pronounced as *Quest*). \n  For data.frames containing the supported data \n  types it is intended to work as a drop-in replacement for the \n  'write_*()' and 'read_*()' functions provided by similar packages.   "
  },
  {
    "id": 18762,
    "package_name": "quickcheck",
    "title": "Property Based Testing",
    "description": "Property based testing, inspired by \n    the original 'QuickCheck'. This package builds on \n    the property based testing framework provided by \n    'hedgehog' and is designed to seamlessly integrate with \n    'testthat'.",
    "version": "0.1.3",
    "maintainer": "Andrew McNeil <andrew.richard.mcneil@gmail.com>",
    "author": "Andrew McNeil [aut, cre]",
    "url": "https://github.com/armcn/quickcheck,\nhttps://armcn.github.io/quickcheck/",
    "bug_reports": "https://github.com/armcn/quickcheck/issues",
    "repository": "https://cran.r-project.org/package=quickcheck",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "quickcheck Property Based Testing Property based testing, inspired by \n    the original 'QuickCheck'. This package builds on \n    the property based testing framework provided by \n    'hedgehog' and is designed to seamlessly integrate with \n    'testthat'.  "
  },
  {
    "id": 18770,
    "package_name": "quietR",
    "title": "Simplify Output Verbosity",
    "description": "Simplifies output suppression logic in R packages, as it's common\n    to develop some form of it in R. 'quietR' intends to simplify that problem \n    and allow a set of simple toggle functions to be used to suppress console \n    output.",
    "version": "0.1.0",
    "maintainer": "Thomas Johnson <thomascjohnson@gmail.com>",
    "author": "Thomas Johnson [aut, cre]",
    "url": "https://github.com/thomascjohnson/quietR",
    "bug_reports": "https://github.com/thomascjohnson/quietR/issues",
    "repository": "https://cran.r-project.org/package=quietR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "quietR Simplify Output Verbosity Simplifies output suppression logic in R packages, as it's common\n    to develop some form of it in R. 'quietR' intends to simplify that problem \n    and allow a set of simple toggle functions to be used to suppress console \n    output.  "
  },
  {
    "id": 18776,
    "package_name": "qvirus",
    "title": "Quantum Computing for Analyzing CD4 Lymphocytes and\nAntiretroviral Therapy",
    "description": "Resources, tutorials, and code snippets dedicated to exploring the intersection of quantum computing and artificial intelligence (AI) in the context of analyzing Cluster of Differentiation 4 (CD4) lymphocytes and optimizing antiretroviral therapy (ART) for human immunodeficiency virus (HIV). With the emergence of quantum artificial intelligence and the development of small-scale quantum computers, there's an unprecedented opportunity to revolutionize the understanding of HIV dynamics and treatment strategies. This project leverages the R package 'qsimulatR' (Ostmeyer and Urbach, 2023, <https://CRAN.R-project.org/package=qsimulatR>), a quantum computer simulator, to explore these applications in quantum computing techniques, addressing the challenges in studying CD4 lymphocytes and enhancing ART efficacy.",
    "version": "0.0.5",
    "maintainer": "Juan Pablo Acu\u00f1a Gonz\u00e1lez <22253567@uagro.mx>",
    "author": "Juan Pablo Acu\u00f1a Gonz\u00e1lez [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0003-6029-6560>)",
    "url": "https://github.com/juan-acu/qvirus",
    "bug_reports": "https://github.com/juan-acu/qvirus/issues",
    "repository": "https://cran.r-project.org/package=qvirus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "qvirus Quantum Computing for Analyzing CD4 Lymphocytes and\nAntiretroviral Therapy Resources, tutorials, and code snippets dedicated to exploring the intersection of quantum computing and artificial intelligence (AI) in the context of analyzing Cluster of Differentiation 4 (CD4) lymphocytes and optimizing antiretroviral therapy (ART) for human immunodeficiency virus (HIV). With the emergence of quantum artificial intelligence and the development of small-scale quantum computers, there's an unprecedented opportunity to revolutionize the understanding of HIV dynamics and treatment strategies. This project leverages the R package 'qsimulatR' (Ostmeyer and Urbach, 2023, <https://CRAN.R-project.org/package=qsimulatR>), a quantum computer simulator, to explore these applications in quantum computing techniques, addressing the challenges in studying CD4 lymphocytes and enhancing ART efficacy.  "
  },
  {
    "id": 18799,
    "package_name": "r2shortcode",
    "title": "Shorten Function Names of Functions in Another Package and\nCreate an Index to Make Them Accessible",
    "description": "When creating a package, authors may sometimes struggle with coming up with easy and straightforward function names, and at the same time hoping that other packages do not already have the same function names. In trying to meet this goal, sometimes, function names are not descriptive enough and may confuse the potential users. The purpose of this package is to serve as a package function short form generator and also provide shorthand names for other functions. Having this package will entice authors to create long function names without the fear of users not wanting to use their packages because of the long names. In a way, everyone wins - the authors can use long descriptive function names, and the users can use this package to make short functions names while still using the package in question.",
    "version": "0.2",
    "maintainer": "Obinna Obianom <idonshayo@gmail.com>",
    "author": "Obinna Obianom",
    "url": "https://github.com/oobianom/r2shortcode",
    "bug_reports": "https://github.com/oobianom/r2shortcode",
    "repository": "https://cran.r-project.org/package=r2shortcode",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "r2shortcode Shorten Function Names of Functions in Another Package and\nCreate an Index to Make Them Accessible When creating a package, authors may sometimes struggle with coming up with easy and straightforward function names, and at the same time hoping that other packages do not already have the same function names. In trying to meet this goal, sometimes, function names are not descriptive enough and may confuse the potential users. The purpose of this package is to serve as a package function short form generator and also provide shorthand names for other functions. Having this package will entice authors to create long function names without the fear of users not wanting to use their packages because of the long names. In a way, everyone wins - the authors can use long descriptive function names, and the users can use this package to make short functions names while still using the package in question.  "
  },
  {
    "id": 18807,
    "package_name": "r3dmol",
    "title": "Create Interactive 3D Visualizations of Molecular Data",
    "description": "Create rich and fully interactive 3D visualizations of molecular data.\n    Visualizations can be included in Shiny apps and R markdown documents, or viewed\n    from the R console and 'RStudio' Viewer. 'r3dmol' includes an extensive API\n    to manipulate the visualization after creation, and supports getting data out of\n    the visualization into R. Based on the '3dmol.js' and the 'htmlwidgets' R package.",
    "version": "0.1.2",
    "maintainer": "Wei Su <swsoyee@gmail.com>",
    "author": "Wei Su [aut, cre] (ORCID: <https://orcid.org/0000-0002-9302-5332>),\n  Brady Johnston [aut] (ORCID: <https://orcid.org/0000-0001-6301-2269>)",
    "url": "https://github.com/swsoyee/r3dmol",
    "bug_reports": "https://github.com/swsoyee/r3dmol/issues",
    "repository": "https://cran.r-project.org/package=r3dmol",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "r3dmol Create Interactive 3D Visualizations of Molecular Data Create rich and fully interactive 3D visualizations of molecular data.\n    Visualizations can be included in Shiny apps and R markdown documents, or viewed\n    from the R console and 'RStudio' Viewer. 'r3dmol' includes an extensive API\n    to manipulate the visualization after creation, and supports getting data out of\n    the visualization into R. Based on the '3dmol.js' and the 'htmlwidgets' R package.  "
  },
  {
    "id": 18819,
    "package_name": "rARPACK",
    "title": "Solvers for Large Scale Eigenvalue and SVD Problems",
    "description": "Previously an R wrapper of the 'ARPACK' library\n    <http://www.caam.rice.edu/software/ARPACK/>, and now a shell of the\n    R package 'RSpectra', an R interface to the 'Spectra' library\n    <http://yixuan.cos.name/spectra/> for solving large scale\n    eigenvalue/vector problems. The current version of 'rARPACK'\n    simply imports and exports the functions provided by 'RSpectra'.\n    New users of 'rARPACK' are advised to switch to the 'RSpectra' package.",
    "version": "0.11-0",
    "maintainer": "Yixuan Qiu <yixuan.qiu@cos.name>",
    "author": "Yixuan Qiu, Jiali Mei and authors of the ARPACK library. See file\n    AUTHORS for details.",
    "url": "https://github.com/yixuan/rARPACK",
    "bug_reports": "https://github.com/yixuan/rARPACK/issues",
    "repository": "https://cran.r-project.org/package=rARPACK",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rARPACK Solvers for Large Scale Eigenvalue and SVD Problems Previously an R wrapper of the 'ARPACK' library\n    <http://www.caam.rice.edu/software/ARPACK/>, and now a shell of the\n    R package 'RSpectra', an R interface to the 'Spectra' library\n    <http://yixuan.cos.name/spectra/> for solving large scale\n    eigenvalue/vector problems. The current version of 'rARPACK'\n    simply imports and exports the functions provided by 'RSpectra'.\n    New users of 'rARPACK' are advised to switch to the 'RSpectra' package.  "
  },
  {
    "id": 18823,
    "package_name": "rAmCharts4",
    "title": "Interface to the JavaScript Library 'amCharts 4'",
    "description": "Creates JavaScript charts. The charts can be included in 'Shiny' apps and R markdown documents, or viewed from the R console and 'RStudio' viewer. Based on the JavaScript library 'amCharts 4' and the R packages 'htmlwidgets' and 'reactR'. Currently available types of chart are: vertical and horizontal bar chart, radial bar chart, stacked bar chart, vertical and horizontal Dumbbell chart, line chart, scatter chart, range area chart, gauge chart, boxplot chart, pie chart, and 100% stacked bar chart.",
    "version": "1.6.0",
    "maintainer": "St\u00e9phane Laurent <laurent_step@outlook.fr>",
    "author": "St\u00e9phane Laurent [aut, cre],\n  Antanas Marcelionis [ctb, cph] ('amCharts' library\n    (https://www.amcharts.com/)),\n  Terence Eden [ctb, cph] ('SuperTinyIcons' library\n    (https://github.com/edent/SuperTinyIcons/)),\n  Tom Alexander [ctb, cph] ('regression-js' library\n    (https://github.com/Tom-Alexander/regression-js))",
    "url": "https://github.com/stla/rAmCharts4",
    "bug_reports": "https://github.com/stla/rAmCharts4/issues",
    "repository": "https://cran.r-project.org/package=rAmCharts4",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rAmCharts4 Interface to the JavaScript Library 'amCharts 4' Creates JavaScript charts. The charts can be included in 'Shiny' apps and R markdown documents, or viewed from the R console and 'RStudio' viewer. Based on the JavaScript library 'amCharts 4' and the R packages 'htmlwidgets' and 'reactR'. Currently available types of chart are: vertical and horizontal bar chart, radial bar chart, stacked bar chart, vertical and horizontal Dumbbell chart, line chart, scatter chart, range area chart, gauge chart, boxplot chart, pie chart, and 100% stacked bar chart.  "
  },
  {
    "id": 18845,
    "package_name": "rFIA",
    "title": "Estimation of Forest Variables using the FIA Database",
    "description": "The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted and model-based estimators to improve population, change, and ratio estimates.",
    "version": "1.1.2",
    "maintainer": "Jeffrey Doser <jwdoser@ncsu.edu>",
    "author": "Jeffrey Doser [aut, cre],\n  Hunter Stanke [aut],\n  Andrew Finley [aut]",
    "url": "https://github.com/doserjef/rFIA,\nhttps://www.doserlab.com/files/rFIA",
    "bug_reports": "https://github.com/doserjef/rFIA/issues",
    "repository": "https://cran.r-project.org/package=rFIA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rFIA Estimation of Forest Variables using the FIA Database The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted and model-based estimators to improve population, change, and ratio estimates.  "
  },
  {
    "id": 18857,
    "package_name": "rJavaEnv",
    "title": "'Java' Environments for R Projects",
    "description": "Quickly install 'Java Development Kit (JDK)' without\n    administrative privileges and set environment variables in current R\n    session or project to solve common issues with 'Java' environment\n    management in 'R'. Recommended to users of 'Java'/'rJava'-dependent\n    'R' packages such as 'r5r', 'opentripplanner', 'xlsx', 'openNLP',\n    'rWeka', 'RJDBC', 'tabulapdf', and many more. 'rJavaEnv' prevents\n    common problems like 'Java' not found, 'Java' version conflicts,\n    missing 'Java' installations, and the inability to install 'Java' due\n    to lack of administrative privileges.  'rJavaEnv' automates the\n    download, installation, and setup of the 'Java' on a per-project basis\n    by setting the relevant 'JAVA_HOME' in the current 'R' session or the\n    current working directory (via '.Rprofile', with the user's consent).\n    Similar to what 'renv' does for 'R' packages, 'rJavaEnv' allows\n    different 'Java' versions to be used across different projects, but\n    can also be configured to allow multiple versions within the same\n    project (e.g.  with the help of 'targets' package). Note: there are a\n    few extra steps for 'Linux' users, who don't have any 'Java'\n    previously installed in their system, and who prefer package\n    installation from source, rather then installing binaries from 'Posit\n    Package Manager'. See documentation for details.",
    "version": "0.3.0",
    "maintainer": "Egor Kotov <kotov.egor@gmail.com>",
    "author": "Egor Kotov [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-6690-5345>),\n  Chung-hong Chan [aut] (ORCID: <https://orcid.org/0000-0002-6232-7530>),\n  Mauricio Vargas [ctb] (ORCID: <https://orcid.org/0000-0003-1017-7574>),\n  Hadley Wickham [ctb] (use_java feature suggestion and PR review),\n  Enrique Mondragon-Estrada [ctb] (ORCID:\n    <https://orcid.org/0009-0004-5592-1728>),\n  Jonas Lieth [ctb] (ORCID: <https://orcid.org/0000-0002-3451-3176>)",
    "url": "https://github.com/e-kotov/rJavaEnv,\nhttps://www.ekotov.pro/rJavaEnv/",
    "bug_reports": "https://github.com/e-kotov/rJavaEnv/issues",
    "repository": "https://cran.r-project.org/package=rJavaEnv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rJavaEnv 'Java' Environments for R Projects Quickly install 'Java Development Kit (JDK)' without\n    administrative privileges and set environment variables in current R\n    session or project to solve common issues with 'Java' environment\n    management in 'R'. Recommended to users of 'Java'/'rJava'-dependent\n    'R' packages such as 'r5r', 'opentripplanner', 'xlsx', 'openNLP',\n    'rWeka', 'RJDBC', 'tabulapdf', and many more. 'rJavaEnv' prevents\n    common problems like 'Java' not found, 'Java' version conflicts,\n    missing 'Java' installations, and the inability to install 'Java' due\n    to lack of administrative privileges.  'rJavaEnv' automates the\n    download, installation, and setup of the 'Java' on a per-project basis\n    by setting the relevant 'JAVA_HOME' in the current 'R' session or the\n    current working directory (via '.Rprofile', with the user's consent).\n    Similar to what 'renv' does for 'R' packages, 'rJavaEnv' allows\n    different 'Java' versions to be used across different projects, but\n    can also be configured to allow multiple versions within the same\n    project (e.g.  with the help of 'targets' package). Note: there are a\n    few extra steps for 'Linux' users, who don't have any 'Java'\n    previously installed in their system, and who prefer package\n    installation from source, rather then installing binaries from 'Posit\n    Package Manager'. See documentation for details.  "
  },
  {
    "id": 18859,
    "package_name": "rKOMICS",
    "title": "Minicircle Sequence Classes (MSC) Analyses",
    "description": "This is a analysis toolkit to streamline the analyses of minicircle sequence diversity in population-scale genome projects. rKOMICS is a user-friendly R package that has simple installation requirements and that is applicable to all 27 trypanosomatid genera. Once minicircle sequence alignments are generated, rKOMICS allows to examine, summarize and visualize minicircle sequence diversity within and between samples through the analyses of minicircle sequence clusters. We showcase the functionalities of the (r)KOMICS tool suite using a whole-genome sequencing dataset from a recently published study on the history of diversification of the Leishmania braziliensis species complex in Peru. Analyses of population diversity and structure highlighted differences in minicircle sequence richness and composition between Leishmania subspecies, and between subpopulations within subspecies. The rKOMICS package establishes a critical framework to manipulate, explore and extract biologically relevant information from mitochondrial minicircle assemblies in tens to hundreds of samples simultaneously and efficiently. This should facilitate research that aims to develop new molecular markers for identifying species-specific minicircles, or to study the ancestry of parasites for complementary insights into their evolutionary history. ***** !! WARNING: this package relies on dependencies from Bioconductor. For Mac users, this can generate errors when installing rKOMICS. Install Bioconductor and ComplexHeatmap at advance: install.packages(\"BiocManager\"); BiocManager::install(\"ComplexHeatmap\") *****.",
    "version": "1.3",
    "maintainer": "Manon Geerts <geertsmanon@gmail.com>",
    "author": "Frederik Van den Broeck [aut],\n  Manon Geerts [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rKOMICS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rKOMICS Minicircle Sequence Classes (MSC) Analyses This is a analysis toolkit to streamline the analyses of minicircle sequence diversity in population-scale genome projects. rKOMICS is a user-friendly R package that has simple installation requirements and that is applicable to all 27 trypanosomatid genera. Once minicircle sequence alignments are generated, rKOMICS allows to examine, summarize and visualize minicircle sequence diversity within and between samples through the analyses of minicircle sequence clusters. We showcase the functionalities of the (r)KOMICS tool suite using a whole-genome sequencing dataset from a recently published study on the history of diversification of the Leishmania braziliensis species complex in Peru. Analyses of population diversity and structure highlighted differences in minicircle sequence richness and composition between Leishmania subspecies, and between subpopulations within subspecies. The rKOMICS package establishes a critical framework to manipulate, explore and extract biologically relevant information from mitochondrial minicircle assemblies in tens to hundreds of samples simultaneously and efficiently. This should facilitate research that aims to develop new molecular markers for identifying species-specific minicircles, or to study the ancestry of parasites for complementary insights into their evolutionary history. ***** !! WARNING: this package relies on dependencies from Bioconductor. For Mac users, this can generate errors when installing rKOMICS. Install Bioconductor and ComplexHeatmap at advance: install.packages(\"BiocManager\"); BiocManager::install(\"ComplexHeatmap\") *****.  "
  },
  {
    "id": 18867,
    "package_name": "rMEA",
    "title": "Synchrony in Motion Energy Analysis (MEA) Time-Series",
    "description": "A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Kleinbub, J. R., & Ramseyer, F. T. (2020). rMEA: An R package to assess nonverbal synchronization in motion energy analysis time-series. Psychotherapy research, 1-14. <doi:10.1080/10503307.2020.1844334>.",
    "version": "1.2.2",
    "maintainer": "Johann R. Kleinbub <johann.kleinbub@gmail.com>",
    "author": "Johann R. Kleinbub, Fabian Ramseyer",
    "url": "https://github.com/kleinbub/rMEA https://psync.ch",
    "bug_reports": "https://github.com/kleinbub/rMEA/issues",
    "repository": "https://cran.r-project.org/package=rMEA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rMEA Synchrony in Motion Energy Analysis (MEA) Time-Series A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Kleinbub, J. R., & Ramseyer, F. T. (2020). rMEA: An R package to assess nonverbal synchronization in motion energy analysis time-series. Psychotherapy research, 1-14. <doi:10.1080/10503307.2020.1844334>.  "
  },
  {
    "id": 18886,
    "package_name": "rQCC",
    "title": "Robust Quality Control Chart",
    "description": "Constructs various robust quality control charts based on the median or Hodges-Lehmann estimator (location) and the median absolute deviation (MAD) or Shamos estimator (scale). The estimators used for the robust control charts are all unbiased with a sample of finite size. For more details, see Park, Kim and Wang (2022) <doi:10.1080/03610918.2019.1699114>. In addition, using this R package, the conventional quality control charts such as X-bar, S, R, p, np, u, c, g, h, and t charts are also easily constructed. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A2C1091319).",
    "version": "2.22.12",
    "maintainer": "Chanseok Park <statpnu@gmail.com>",
    "author": "Chanseok Park [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2208-3498>),\n  Min Wang [ctb] (ORCID: <https://orcid.org/0000-0002-9233-7844>)",
    "url": "https://AppliedStat.GitHub.io/R/",
    "bug_reports": "https://GitHub.com/AppliedStat/R/issues",
    "repository": "https://cran.r-project.org/package=rQCC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rQCC Robust Quality Control Chart Constructs various robust quality control charts based on the median or Hodges-Lehmann estimator (location) and the median absolute deviation (MAD) or Shamos estimator (scale). The estimators used for the robust control charts are all unbiased with a sample of finite size. For more details, see Park, Kim and Wang (2022) <doi:10.1080/03610918.2019.1699114>. In addition, using this R package, the conventional quality control charts such as X-bar, S, R, p, np, u, c, g, h, and t charts are also easily constructed. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A2C1091319).  "
  },
  {
    "id": 18889,
    "package_name": "rSCA",
    "title": "An R Package for Stepwise Cluster Analysis",
    "description": "A statistical tool for multivariate modeling and clustering using stepwise cluster analysis. The modeling output of rSCA is constructed as a cluster tree to represent the complicated relationships between multiple dependent and independent variables. A free tool (named rSCA Tree Generator) for visualizing the cluster tree from rSCA is also released and it can be downloaded at <https://rscatree.weebly.com/>.",
    "version": "3.1",
    "maintainer": "Xiuquan (Xander) Wang <xiuquan.wang@gmail.com>",
    "author": "Xiuquan (Xander) Wang",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rSCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rSCA An R Package for Stepwise Cluster Analysis A statistical tool for multivariate modeling and clustering using stepwise cluster analysis. The modeling output of rSCA is constructed as a cluster tree to represent the complicated relationships between multiple dependent and independent variables. A free tool (named rSCA Tree Generator) for visualizing the cluster tree from rSCA is also released and it can be downloaded at <https://rscatree.weebly.com/>.  "
  },
  {
    "id": 18944,
    "package_name": "ramcmc",
    "title": "Robust Adaptive Metropolis Algorithm",
    "description": "Function for adapting the shape of the random walk Metropolis proposal\n    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <doi:10.1007/s11222-011-9269-5>. \n    The package also includes fast functions for rank-one Cholesky update and downdate.\n    These functions can be used directly from R or the corresponding C++ header files \n    can be easily linked to other R packages.",
    "version": "0.1.2",
    "maintainer": "Jouni Helske <jouni.helske@iki.fi>",
    "author": "Jouni Helske [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7130-793X>)",
    "url": "",
    "bug_reports": "https://github.com/helske/ramcmc/issues",
    "repository": "https://cran.r-project.org/package=ramcmc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ramcmc Robust Adaptive Metropolis Algorithm Function for adapting the shape of the random walk Metropolis proposal\n    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <doi:10.1007/s11222-011-9269-5>. \n    The package also includes fast functions for rank-one Cholesky update and downdate.\n    These functions can be used directly from R or the corresponding C++ header files \n    can be easily linked to other R packages.  "
  },
  {
    "id": 18976,
    "package_name": "rang",
    "title": "Reconstructing Reproducible R Computational Environments",
    "description": "Resolve the dependency graph of R packages at a specific time point based on the information from various 'R-hub' web services <https://blog.r-hub.io/>. The dependency graph can then be used to reconstruct the R computational environment with 'Rocker' <https://rocker-project.org>.",
    "version": "0.3.0",
    "maintainer": "Chung-hong Chan <chainsawtiney@gmail.com>",
    "author": "Chung-hong Chan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6232-7530>),\n  David Schoch [aut] (ORCID: <https://orcid.org/0000-0003-2952-4812>),\n  Egor Kotov [ctb] (ORCID: <https://orcid.org/0000-0001-6690-5345>)",
    "url": "https://github.com/gesistsa/rang",
    "bug_reports": "https://github.com/gesistsa/rang/issues",
    "repository": "https://cran.r-project.org/package=rang",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rang Reconstructing Reproducible R Computational Environments Resolve the dependency graph of R packages at a specific time point based on the information from various 'R-hub' web services <https://blog.r-hub.io/>. The dependency graph can then be used to reconstruct the R computational environment with 'Rocker' <https://rocker-project.org>.  "
  },
  {
    "id": 18979,
    "package_name": "rangeModelMetadata",
    "title": "Provides Templates for Metadata Files Associated with Species\nRange Models",
    "description": "Range Modeling Metadata Standards (RMMS) address three challenges: \n  they (i) are designed for convenience to encourage use, (ii) accommodate a wide \n  variety of applications, and (iii) are extensible to allow the community of range \n  modelers to steer it as needed. RMMS are based on a data dictionary that specifies \n  a hierarchical structure to catalog different aspects of the range modeling process. \n  The dictionary balances a constrained, minimalist vocabulary to improve \n  standardization with flexibility for users to provide their own values. \n  Merow et al. (2019) <DOI:10.1111/geb.12993> describe the standards in \n  more detail. Note that users who prefer to use the R package 'ecospat' can obtain it from\n  <https://github.com/ecospat/ecospat>.",
    "version": "0.1.5",
    "maintainer": "Cory Merow <cory.merow@gmail.com>",
    "author": "Cory Merow [aut, cre],\n  Brian Maitner [aut],\n  Hannah Owens [aut],\n  Jamie Kass [aut],\n  Brian Enquist [aut],\n  Rob Guralnik [aut],\n  Damaris Zurrell [aut],\n  Christian Koenig [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rangeModelMetadata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rangeModelMetadata Provides Templates for Metadata Files Associated with Species\nRange Models Range Modeling Metadata Standards (RMMS) address three challenges: \n  they (i) are designed for convenience to encourage use, (ii) accommodate a wide \n  variety of applications, and (iii) are extensible to allow the community of range \n  modelers to steer it as needed. RMMS are based on a data dictionary that specifies \n  a hierarchical structure to catalog different aspects of the range modeling process. \n  The dictionary balances a constrained, minimalist vocabulary to improve \n  standardization with flexibility for users to provide their own values. \n  Merow et al. (2019) <DOI:10.1111/geb.12993> describe the standards in \n  more detail. Note that users who prefer to use the R package 'ecospat' can obtain it from\n  <https://github.com/ecospat/ecospat>.  "
  },
  {
    "id": 18981,
    "package_name": "ranger",
    "title": "A Fast Implementation of Random Forests",
    "description": "A fast implementation of Random Forests, particularly suited for high\n          dimensional data. Ensembles of classification, regression, survival and\n          probability prediction trees are supported. Data from genome-wide association\n          studies can be analyzed efficiently. In addition to data frames, datasets of\n          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') \n          can be directly analyzed.",
    "version": "0.17.0",
    "maintainer": "Marvin N. Wright <cran@wrig.de>",
    "author": "Marvin N. Wright [aut, cre],\n  Stefan Wager [ctb],\n  Philipp Probst [ctb]",
    "url": "https://imbs-hl.github.io/ranger/,\nhttps://github.com/imbs-hl/ranger",
    "bug_reports": "https://github.com/imbs-hl/ranger/issues",
    "repository": "https://cran.r-project.org/package=ranger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ranger A Fast Implementation of Random Forests A fast implementation of Random Forests, particularly suited for high\n          dimensional data. Ensembles of classification, regression, survival and\n          probability prediction trees are supported. Data from genome-wide association\n          studies can be analyzed efficiently. In addition to data frames, datasets of\n          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') \n          can be directly analyzed.  "
  },
  {
    "id": 19019,
    "package_name": "rasterKernelEstimates",
    "title": "Kernel Based Estimates on in-Memory Raster Images",
    "description": "Performs kernel based estimates on in-memory raster images \n  from the raster package.  These kernel estimates include local means\n  variances, modes, and quantiles.  All results are in the form of \n  raster images, preserving original resolution and projection attributes.",
    "version": "1.0.2",
    "maintainer": "Jonathan Lisic <jlisic@gmail.com>",
    "author": "Jonathan Lisic [aut, cre]",
    "url": "http://meanmean.me/blog/rasterKernel/rasterKernel.html",
    "bug_reports": "https://github.com/jlisic/rasterKernelEstimates/issues",
    "repository": "https://cran.r-project.org/package=rasterKernelEstimates",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rasterKernelEstimates Kernel Based Estimates on in-Memory Raster Images Performs kernel based estimates on in-memory raster images \n  from the raster package.  These kernel estimates include local means\n  variances, modes, and quantiles.  All results are in the form of \n  raster images, preserving original resolution and projection attributes.  "
  },
  {
    "id": 19108,
    "package_name": "rcollectadhd",
    "title": "Collection of Data Sets Containing ADHD Related Data",
    "description": "A collection of data sets relating to ADHD (Attention Deficit \n    Hyperactivity Disorder) which have been sourced from other packages on CRAN\n    or from publications on other websites such as Kaggle\n    <http://www.kaggle.com/>.The package also includes some simple functions for\n    analysing data sets. The data sets and descriptions of the data sets may\n    differ from what is on CRAN or other source websites. The aim of this\n    package is to bring together data sets from a variety of ADHD research\n    publications. This package would be useful for those interested in finding\n    out what research has been done on the topic of ADHD, or those interested in\n    comparing the results from different existing works. I started this project\n    because I wanted to put together a collection of the data sets relevant to\n    ADHD research, which I have a personal interest in. This work was conducted\n    with the support of my mentor within the Global Talent Mentoring platform.\n    <https://globaltalentmentoring.org/>.",
    "version": "0.8",
    "maintainer": "John Nolan <john.mccabe.nolan@outlook.com>",
    "author": "John Nolan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rcollectadhd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcollectadhd Collection of Data Sets Containing ADHD Related Data A collection of data sets relating to ADHD (Attention Deficit \n    Hyperactivity Disorder) which have been sourced from other packages on CRAN\n    or from publications on other websites such as Kaggle\n    <http://www.kaggle.com/>.The package also includes some simple functions for\n    analysing data sets. The data sets and descriptions of the data sets may\n    differ from what is on CRAN or other source websites. The aim of this\n    package is to bring together data sets from a variety of ADHD research\n    publications. This package would be useful for those interested in finding\n    out what research has been done on the topic of ADHD, or those interested in\n    comparing the results from different existing works. I started this project\n    because I wanted to put together a collection of the data sets relevant to\n    ADHD research, which I have a personal interest in. This work was conducted\n    with the support of my mentor within the Global Talent Mentoring platform.\n    <https://globaltalentmentoring.org/>.  "
  },
  {
    "id": 19111,
    "package_name": "rcompendium",
    "title": "Create a Package or Research Compendium Structure",
    "description": "Makes easier the creation of R package or research compendium \n    (i.e. a predefined files/folders structure) so that users can focus on the \n    code/analysis instead of wasting time organizing files. A full \n    ready-to-work structure is set up with some additional features: version \n    control, remote repository creation, CI/CD configuration (check package \n    integrity under several OS, test code with 'testthat', and build and deploy \n    website using 'pkgdown'). This package heavily relies on the R packages \n    'devtools' and 'usethis' and follows recommendations made by Wickham H. \n    (2015) <ISBN:9781491910597> and Marwick B. et al. (2018) \n    <doi:10.7287/peerj.preprints.3192v2>.",
    "version": "1.4",
    "maintainer": "Nicolas Casajus <nicolas.casajus@fondationbiodiversite.fr>",
    "author": "Nicolas Casajus [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5537-5294>)",
    "url": "https://github.com/FRBCesab/rcompendium,\nhttps://frbcesab.github.io/rcompendium/",
    "bug_reports": "https://github.com/FRBCesab/rcompendium/issues",
    "repository": "https://cran.r-project.org/package=rcompendium",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcompendium Create a Package or Research Compendium Structure Makes easier the creation of R package or research compendium \n    (i.e. a predefined files/folders structure) so that users can focus on the \n    code/analysis instead of wasting time organizing files. A full \n    ready-to-work structure is set up with some additional features: version \n    control, remote repository creation, CI/CD configuration (check package \n    integrity under several OS, test code with 'testthat', and build and deploy \n    website using 'pkgdown'). This package heavily relies on the R packages \n    'devtools' and 'usethis' and follows recommendations made by Wickham H. \n    (2015) <ISBN:9781491910597> and Marwick B. et al. (2018) \n    <doi:10.7287/peerj.preprints.3192v2>.  "
  },
  {
    "id": 19114,
    "package_name": "rcontroll",
    "title": "Individual-Based Forest Growth Simulator 'TROLL'",
    "description": "'TROLL' is coded in C++ and it typically simulates hundreds of\n    thousands of individuals over hundreds of years. The 'rcontroll' R package \n    is a wrapper of 'TROLL'. 'rcontroll' includes functions that generate inputs \n    for simulations and run simulations. Finally, it is possible to analyse \n    the 'TROLL' outputs through tables, figures, and maps taking advantage of \n    other R visualisation packages. 'rcontroll' also offers the possibility to \n    generate a virtual LiDAR point cloud that corresponds to a snapshot of \n    the simulated forest.",
    "version": "0.1.2",
    "maintainer": "Sylvain Schmitt <sylvain.m.schmitt@gmail.com>",
    "author": "Sylvain Schmitt [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7759-7106>),\n  Guillaume Salzet [aut] (ORCID: <https://orcid.org/0000-0003-4548-5673>),\n  Fabian Fischer [aut] (ORCID: <https://orcid.org/0000-0003-2325-9886>),\n  Isabelle Mar\u00e9chaux [aut] (ORCID:\n    <https://orcid.org/0000-0002-5401-0197>),\n  J\u00e9r\u00f4me Chave [aut] (ORCID: <https://orcid.org/0000-0002-7766-1347>)",
    "url": "https://github.com/sylvainschmitt/rcontroll,\nhttps://sylvainschmitt.github.io/rcontroll/",
    "bug_reports": "https://github.com/sylvainschmitt/rcontroll/issues",
    "repository": "https://cran.r-project.org/package=rcontroll",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcontroll Individual-Based Forest Growth Simulator 'TROLL' 'TROLL' is coded in C++ and it typically simulates hundreds of\n    thousands of individuals over hundreds of years. The 'rcontroll' R package \n    is a wrapper of 'TROLL'. 'rcontroll' includes functions that generate inputs \n    for simulations and run simulations. Finally, it is possible to analyse \n    the 'TROLL' outputs through tables, figures, and maps taking advantage of \n    other R visualisation packages. 'rcontroll' also offers the possibility to \n    generate a virtual LiDAR point cloud that corresponds to a snapshot of \n    the simulated forest.  "
  },
  {
    "id": 19127,
    "package_name": "rdacca.hp",
    "title": "Hierarchical and Variation Partitioning for Canonical Analysis",
    "description": "This function conducts variation partitioning and hierarchical partitioning to calculate the unique, shared (referred as to \"common\") and individual contributions of each predictor (or matrix) towards explained variation (R-square and adjusted R-square) on canonical analysis (RDA,CCA and db-RDA), applying the algorithm of Lai J.,Zou Y., Zhang J.,Peres-Neto P.(2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution,13: 782-788 <DOI:10.1111/2041-210X.13800>. ",
    "version": "1.1-1",
    "maintainer": "Jiangshan Lai <lai@njfu.edu.cn>",
    "author": "Jiangshan Lai [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0279-8816>),\n  Kim Nimon [aut],\n  Yao Liu [aut],\n  Pedro Peres-Neto [aut]",
    "url": "https://github.com/laijiangshan/rdacca.hp",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rdacca.hp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdacca.hp Hierarchical and Variation Partitioning for Canonical Analysis This function conducts variation partitioning and hierarchical partitioning to calculate the unique, shared (referred as to \"common\") and individual contributions of each predictor (or matrix) towards explained variation (R-square and adjusted R-square) on canonical analysis (RDA,CCA and db-RDA), applying the algorithm of Lai J.,Zou Y., Zhang J.,Peres-Neto P.(2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution,13: 782-788 <DOI:10.1111/2041-210X.13800>.   "
  },
  {
    "id": 19131,
    "package_name": "rdcmchecks",
    "title": "Common Argument Checks for 'r-dcm' Packages",
    "description": "Many packages in the 'r-dcm' family take similar arguments,\n    which are checked for expected structures and values. Rather than\n    duplicating code across several packages, commonly used check\n    functions are included here.  This package can then be imported to\n    access the check functions in other packages.",
    "version": "0.1.0",
    "maintainer": "W. Jake Thompson <wjakethompson@gmail.com>",
    "author": "W. Jake Thompson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7339-0300>),\n  University of Kansas [cph],\n  Institute of Education Sciences [fnd],\n  Accessible Teaching, Learning, and Assessment Systems [fnd]",
    "url": "https://rdcmchecks.r-dcm.org, https://github.com/r-dcm/rdcmchecks",
    "bug_reports": "https://github.com/r-dcm/rdcmchecks/issues",
    "repository": "https://cran.r-project.org/package=rdcmchecks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdcmchecks Common Argument Checks for 'r-dcm' Packages Many packages in the 'r-dcm' family take similar arguments,\n    which are checked for expected structures and values. Rather than\n    duplicating code across several packages, commonly used check\n    functions are included here.  This package can then be imported to\n    access the check functions in other packages.  "
  },
  {
    "id": 19150,
    "package_name": "rdoxygen",
    "title": "Create Doxygen Documentation for Source Code",
    "description": "Create doxygen documentation for source code in R packages. \n  Includes a RStudio Addin, that allows to trigger the doxygenize process.",
    "version": "1.0.0",
    "maintainer": "Clemens Schmid <clemens@nevrome.de>",
    "author": "Clemens Schmid [cre, cph, aut]",
    "url": "https://github.com/nevrome/rdoxygen",
    "bug_reports": "https://github.com/nevrome/rdoxygen/issues",
    "repository": "https://cran.r-project.org/package=rdoxygen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdoxygen Create Doxygen Documentation for Source Code Create doxygen documentation for source code in R packages. \n  Includes a RStudio Addin, that allows to trigger the doxygenize process.  "
  },
  {
    "id": 19207,
    "package_name": "rebus",
    "title": "Build Regular Expressions in a Human Readable Way",
    "description": "Build regular expressions piece by piece using human readable code.\n    This package is designed for interactive use.  For package development, use\n    the rebus.* dependencies.",
    "version": "0.1-3",
    "maintainer": "Richard Cotton <richierocks@gmail.com>",
    "author": "Richard Cotton [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rebus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rebus Build Regular Expressions in a Human Readable Way Build regular expressions piece by piece using human readable code.\n    This package is designed for interactive use.  For package development, use\n    the rebus.* dependencies.  "
  },
  {
    "id": 19221,
    "package_name": "recluster",
    "title": "Ordination Methods for the Analysis of Beta-Diversity Indices",
    "description": "The analysis of different aspects of biodiversity requires specific algorithms. \n\tFor example, in regionalisation analyses, the high frequency of ties and zero values in \n\tdissimilarity matrices produced by Beta-diversity turnover produces hierarchical \n\tcluster dendrograms whose topology and bootstrap supports are affected by the order of \n\trows in the original matrix. Moreover, visualisation of biogeographical regionalisation \n\tcan be facilitated by a combination of hierarchical clustering and multi-dimensional \n\tscaling. The recluster package provides robust techniques to visualise and analyse \n\tpattern of biodiversity and to improve occurrence data for cryptic taxa. \n\tOther functions \trelated to recluster (e.g. the biodecrypt family) are currently \n\tavailable in GitHub at <https://github.com/leondap/recluster>.",
    "version": "2.9",
    "maintainer": "Leonardo Dapporto <leondap@gmail.com>",
    "author": "Leonardo Dapporto, Matteo Ramazzotti, Simone Fattorini, Roger\n        Vila, Gerard Talavera, Roger H.L. Dennis",
    "url": "https://github.com/leondap/recluster",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=recluster",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "recluster Ordination Methods for the Analysis of Beta-Diversity Indices The analysis of different aspects of biodiversity requires specific algorithms. \n\tFor example, in regionalisation analyses, the high frequency of ties and zero values in \n\tdissimilarity matrices produced by Beta-diversity turnover produces hierarchical \n\tcluster dendrograms whose topology and bootstrap supports are affected by the order of \n\trows in the original matrix. Moreover, visualisation of biogeographical regionalisation \n\tcan be facilitated by a combination of hierarchical clustering and multi-dimensional \n\tscaling. The recluster package provides robust techniques to visualise and analyse \n\tpattern of biodiversity and to improve occurrence data for cryptic taxa. \n\tOther functions \trelated to recluster (e.g. the biodecrypt family) are currently \n\tavailable in GitHub at <https://github.com/leondap/recluster>.  "
  },
  {
    "id": 19232,
    "package_name": "recommenderlabJester",
    "title": "Jester Dataset for 'recommenderlab'",
    "description": "Provides the Jester Dataset for package recommenderlab.",
    "version": "0.2-0",
    "maintainer": "Michael Hahsler <mhahsler@smu.edu>",
    "author": "Michael Hahsler",
    "url": "https://github.com/mhahsler/recommenderlabJester",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=recommenderlabJester",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "recommenderlabJester Jester Dataset for 'recommenderlab' Provides the Jester Dataset for package recommenderlab.  "
  },
  {
    "id": 19264,
    "package_name": "refreg",
    "title": "Conditional Multivariate Reference Regions",
    "description": "An R package for estimating conditional multivariate reference regions. \n    The reference region is non parametrically estimated using a kernel density estimator.\n    Covariates effects on the multivariate response means vector and variance-covariance\n    matrix, thus on the region shape, are estimated by flexible additive predictors. \n    Continuous covariates non linear effects might be estimated using penalized splines smoothers.\n    Confidence intervals for the covariates estimated effects might be derived from\n    bootstrap resampling. Kernel density bandwidth can be estimated with different methods, including\n    a method that optimize the region coverage. Numerical, and graphical, summaries\n    can be obtained by the user in order to evaluate reference region performance with real data.\n    Full mathematical details can be found in <doi:10.1002/sim.9163> and <doi:10.1007/s00477-020-01901-1>.",
    "version": "0.1.1",
    "maintainer": "Oscar Lado-Baleato <oscarlado.baleato@usc.es>",
    "author": "Oscar Lado-Baleato [cre, aut],\n  Javier Roca-Pardinas [aut, ctb],\n  Carmen Cadarso-Suarez [aut, ths],\n  Gude Francisco [aut, ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=refreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "refreg Conditional Multivariate Reference Regions An R package for estimating conditional multivariate reference regions. \n    The reference region is non parametrically estimated using a kernel density estimator.\n    Covariates effects on the multivariate response means vector and variance-covariance\n    matrix, thus on the region shape, are estimated by flexible additive predictors. \n    Continuous covariates non linear effects might be estimated using penalized splines smoothers.\n    Confidence intervals for the covariates estimated effects might be derived from\n    bootstrap resampling. Kernel density bandwidth can be estimated with different methods, including\n    a method that optimize the region coverage. Numerical, and graphical, summaries\n    can be obtained by the user in order to evaluate reference region performance with real data.\n    Full mathematical details can be found in <doi:10.1002/sim.9163> and <doi:10.1007/s00477-020-01901-1>.  "
  },
  {
    "id": 19283,
    "package_name": "registry",
    "title": "Infrastructure for R Package Registries",
    "description": "Provides a generic infrastructure for creating and using registries.",
    "version": "0.5-1",
    "maintainer": "David Meyer <David.Meyer@R-project.org>",
    "author": "David Meyer",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=registry",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "registry Infrastructure for R Package Registries Provides a generic infrastructure for creating and using registries.  "
  },
  {
    "id": 19315,
    "package_name": "releaser",
    "title": "Help with Preparing a New Version of an R Package",
    "description": "Helps to prepare a release. Before releasing an R package it is important to update the DESCRIPTION file and the changelog. This package prepares these files and also updates the versions according to the branches. It relies heavily on the 'desc' packages.",
    "version": "1.0.0",
    "maintainer": "Tanguy Barthelemy <tanguy.barthelemy@insee.fr>",
    "author": "Tanguy Barthelemy [aut, cre, art]",
    "url": "https://github.com/TanguyBarthelemy/releaser,\nhttps://tanguybarthelemy.github.io/releaser/",
    "bug_reports": "https://github.com/TanguyBarthelemy/releaser/issues",
    "repository": "https://cran.r-project.org/package=releaser",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "releaser Help with Preparing a New Version of an R Package Helps to prepare a release. Before releasing an R package it is important to update the DESCRIPTION file and the changelog. This package prepares these files and also updates the versions according to the branches. It relies heavily on the 'desc' packages.  "
  },
  {
    "id": 19329,
    "package_name": "remify",
    "title": "Processing and Transforming Relational Event History Data",
    "description": "Efficiently processes relational event history data and transforms them into formats suitable for other packages. The primary objective of this package is to convert event history data into a format that integrates with the packages in 'remverse' and is compatible with various analytical tools (e.g., computing network statistics, estimating tie-oriented or actor-oriented social network models). Second, it can also transform the data into formats compatible with other packages out of 'remverse'. The package processes the data for two types of temporal social network models: tie-oriented modeling framework (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented modeling framework (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>). ",
    "version": "3.2.9",
    "maintainer": "Giuseppe Arena <g.arena@uva.nl>",
    "author": "Giuseppe Arena [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5204-3326>),\n  Rumana Lakdawala [ctb],\n  Marlyne Meijerink-Bosman [ctb],\n  Diana Karimova [ctb],\n  Fabio Generoso Vieira [ctb],\n  Mahdi Shafiee Kamalabad [ctb],\n  Roger Leenders [ctb],\n  Joris Mulder [ctb]",
    "url": "https://tilburgnetworkgroup.github.io/remify/",
    "bug_reports": "https://github.com/TilburgNetworkGroup/remify/issues",
    "repository": "https://cran.r-project.org/package=remify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "remify Processing and Transforming Relational Event History Data Efficiently processes relational event history data and transforms them into formats suitable for other packages. The primary objective of this package is to convert event history data into a format that integrates with the packages in 'remverse' and is compatible with various analytical tools (e.g., computing network statistics, estimating tie-oriented or actor-oriented social network models). Second, it can also transform the data into formats compatible with other packages out of 'remverse'. The package processes the data for two types of temporal social network models: tie-oriented modeling framework (Butts, C., 2008, <doi:10.1111/j.1467-9531.2008.00203.x>) and actor-oriented modeling framework (Stadtfeld, C., & Block, P., 2017, <doi:10.15195/v4.a14>).   "
  },
  {
    "id": 19368,
    "package_name": "reproducible",
    "title": "Enhance Reproducibility of R Code",
    "description": "A collection of high-level, machine- and OS-independent tools\n    for making reproducible and reusable content in R.\n    The two workhorse functions are Cache() and prepInputs(). Cache()\n    allows for nested caching, is robust to environments and objects with\n    environments (like functions), and deals with some classes of \n    file-backed R objects e.g., from terra and raster packages. \n    Both functions have been developed to \n    be foundational components of data retrieval\n    and processing in continuous workflow situations. In both functions,\n    efforts are made to make the first and subsequent calls of functions have \n    the same result, but faster at subsequent times by way of checksums\n    and digesting. Several features are still under development, including\n    cloud storage of cached objects allowing for sharing between users. Several\n    advanced options are available, see ?reproducibleOptions().",
    "version": "2.1.2",
    "maintainer": "Eliot J B McIntire <eliot.mcintire@canada.ca>",
    "author": "Eliot J B McIntire [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6914-8316>),\n  Alex M Chubaty [aut] (ORCID: <https://orcid.org/0000-0001-7146-8135>),\n  Tati Micheletti [ctb] (ORCID: <https://orcid.org/0000-0003-4838-8342>),\n  Ceres Barros [ctb] (ORCID: <https://orcid.org/0000-0003-4036-977X>),\n  Ian Eddy [ctb] (ORCID: <https://orcid.org/0000-0001-7397-2116>),\n  His Majesty the King in Right of Canada, as represented by the Minister\n    of Natural Resources Canada [cph]",
    "url": "https://reproducible.predictiveecology.org,\nhttps://github.com/PredictiveEcology/reproducible",
    "bug_reports": "https://github.com/PredictiveEcology/reproducible/issues",
    "repository": "https://cran.r-project.org/package=reproducible",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "reproducible Enhance Reproducibility of R Code A collection of high-level, machine- and OS-independent tools\n    for making reproducible and reusable content in R.\n    The two workhorse functions are Cache() and prepInputs(). Cache()\n    allows for nested caching, is robust to environments and objects with\n    environments (like functions), and deals with some classes of \n    file-backed R objects e.g., from terra and raster packages. \n    Both functions have been developed to \n    be foundational components of data retrieval\n    and processing in continuous workflow situations. In both functions,\n    efforts are made to make the first and subsequent calls of functions have \n    the same result, but faster at subsequent times by way of checksums\n    and digesting. Several features are still under development, including\n    cloud storage of cached objects allowing for sharing between users. Several\n    advanced options are available, see ?reproducibleOptions().  "
  },
  {
    "id": 19378,
    "package_name": "requiRements",
    "title": "Helper Package to Install Packages for R",
    "description": "Helper function to install packages for R using an external\n    'requirements.txt' or a string containing diverse packages from\n    several resources like Github or CRAN.",
    "version": "0.0.3",
    "maintainer": "Jonathan M. Mang <jonathan.mang@uk-erlangen.de>",
    "author": "Jonathan M. Mang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0518-4710>),\n  MIRACUM - Medical Informatics in Research and Care in University\n    Medicine [fnd],\n  Universit\u00e4tsklinikum Erlangen [cph]",
    "url": "https://github.com/joundso/requirements",
    "bug_reports": "https://github.com/joundso/requirements/issues",
    "repository": "https://cran.r-project.org/package=requiRements",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "requiRements Helper Package to Install Packages for R Helper function to install packages for R using an external\n    'requirements.txt' or a string containing diverse packages from\n    several resources like Github or CRAN.  "
  },
  {
    "id": 19383,
    "package_name": "resampledata",
    "title": "Data Sets for Mathematical Statistics with Resampling in R",
    "description": "Package of data sets from \"Mathematical Statistics\n    with Resampling in R\" (1st Ed. 2011, 2nd Ed. 2018) by Laura Chihara and Tim Hesterberg.",
    "version": "0.3.2",
    "maintainer": "Albert Y. Kim <albert.ys.kim@gmail.com>",
    "author": "Laura Chihara [aut],\n  Tim Hesterberg [aut],\n  Albert Y. Kim [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7824-306X>)",
    "url": "https://github.com/rudeboybert/resampledata",
    "bug_reports": "https://github.com/rudeboybert/resampledata/issues",
    "repository": "https://cran.r-project.org/package=resampledata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "resampledata Data Sets for Mathematical Statistics with Resampling in R Package of data sets from \"Mathematical Statistics\n    with Resampling in R\" (1st Ed. 2011, 2nd Ed. 2018) by Laura Chihara and Tim Hesterberg.  "
  },
  {
    "id": 19415,
    "package_name": "rethnicity",
    "title": "Predicting Ethnic Group from Names",
    "description": "Implementation of the race/ethnicity prediction method, described \n    in \"rethnicity: An R package for predicting ethnicity from names\" \n    by Fangzhou Xie (2022) <doi:10.1016/j.softx.2021.100965> and \n    \"Rethnicity: Predicting Ethnicity from Names\" \n    by Fangzhou Xie (2021) <doi:10.48550/arXiv.2109.09228>.",
    "version": "0.2.7",
    "maintainer": "Fangzhou Xie <fangzhou.xie@rutgers.edu>",
    "author": "Fangzhou Xie [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7702-093X>)",
    "url": "https://github.com/fangzhou-xie/rethnicity",
    "bug_reports": "https://github.com/fangzhou-xie/rethnicity/issues",
    "repository": "https://cran.r-project.org/package=rethnicity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rethnicity Predicting Ethnic Group from Names Implementation of the race/ethnicity prediction method, described \n    in \"rethnicity: An R package for predicting ethnicity from names\" \n    by Fangzhou Xie (2022) <doi:10.1016/j.softx.2021.100965> and \n    \"Rethnicity: Predicting Ethnicity from Names\" \n    by Fangzhou Xie (2021) <doi:10.48550/arXiv.2109.09228>.  "
  },
  {
    "id": 19428,
    "package_name": "revengc",
    "title": "Reverse Engineering Summarized Data",
    "description": "Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec function reverse engineers summarized data into an uncensored bivariate table of probabilities.",
    "version": "1.0.4",
    "maintainer": "Samantha Duchscherer <sam.duchscherer@gmail.com>",
    "author": "Samantha Duchscherer [aut, cre],\n  UT-Battelle, LLC [cph]",
    "url": "https://github.com/GIST-ORNL/revengc",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=revengc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "revengc Reverse Engineering Summarized Data Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec function reverse engineers summarized data into an uncensored bivariate table of probabilities.  "
  },
  {
    "id": 19438,
    "package_name": "rextendr",
    "title": "Call Rust Code from R using the 'extendr' Crate",
    "description": "Provides functions to compile and load Rust code from R, similar\n    to how 'Rcpp' or 'cpp11' allow easy interfacing with C++ code. Also provides\n    helper functions to create R packages that use Rust code. Under the hood,\n    the Rust crate 'extendr' is used to do all the heavy lifting.",
    "version": "0.4.2",
    "maintainer": "Ilia Kosenkov <ilia.kosenkov@outlook.com>",
    "author": "Claus O. Wilke [aut] (ORCID: <https://orcid.org/0000-0002-7470-9261>),\n  Andy Thomason [aut],\n  Mossa M. Reimert [aut],\n  Ilia Kosenkov [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5563-7840>),\n  Malcolm Barrett [aut] (ORCID: <https://orcid.org/0000-0003-0299-5825>),\n  Josiah Parry [ctb] (ORCID: <https://orcid.org/0000-0001-9910-865X>),\n  Kenneth Vernon [ctb] (ORCID: <https://orcid.org/0000-0003-0098-5092>),\n  Alberson Miranda [ctb] (ORCID: <https://orcid.org/0000-0001-9252-4175>)",
    "url": "https://extendr.rs/rextendr/, https://github.com/extendr/rextendr",
    "bug_reports": "https://github.com/extendr/rextendr/issues",
    "repository": "https://cran.r-project.org/package=rextendr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rextendr Call Rust Code from R using the 'extendr' Crate Provides functions to compile and load Rust code from R, similar\n    to how 'Rcpp' or 'cpp11' allow easy interfacing with C++ code. Also provides\n    helper functions to create R packages that use Rust code. Under the hood,\n    the Rust crate 'extendr' is used to do all the heavy lifting.  "
  },
  {
    "id": 19452,
    "package_name": "rfold",
    "title": "Working with many R Folders Within an R Package",
    "description": "\n    Allows developers to work with many R folders inside a package. It offers functionalities to transfer R scripts (saved outside the R folder) into \n    the R folder while making additional checks.",
    "version": "0.2.0",
    "maintainer": "Mohamed El Fodil Ihaddaden <ihaddaden.fodeil@gmail.com>",
    "author": "Mohamed El Fodil Ihaddaden [aut, cre]",
    "url": "https://github.com/feddelegrand7/rfold",
    "bug_reports": "https://github.com/feddelegrand7/rfold/issues",
    "repository": "https://cran.r-project.org/package=rfold",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rfold Working with many R Folders Within an R Package \n    Allows developers to work with many R folders inside a package. It offers functionalities to transfer R scripts (saved outside the R folder) into \n    the R folder while making additional checks.  "
  },
  {
    "id": 19529,
    "package_name": "risk.assessr",
    "title": "Assessing Package Risk Metrics",
    "description": "A reliable and validated tool that captures detailed risk metrics \n    such as R 'CMD' check, test coverage, traceability matrix, documentation, dependencies, \n    reverse dependencies, suggested dependency analysis, repository data, \n    and enhanced reporting for R packages that are local or stored \n    on remote repositories such as GitHub, CRAN, and Bioconductor.",
    "version": "3.0.1",
    "maintainer": "Edward Gillian <edward.gillian-ext@sanofi.com>",
    "author": "Edward Gillian [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-2732-5107>),\n  Hugo Bottois [aut] (ORCID: <https://orcid.org/0000-0003-4674-0875>),\n  Paulin Charliquart [aut],\n  Andre Couturier [aut],\n  Sanofi [cph, fnd]",
    "url": "https://sanofi-public.github.io/risk.assessr/",
    "bug_reports": "https://github.com/Sanofi-Public/risk.assessr/issues",
    "repository": "https://cran.r-project.org/package=risk.assessr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "risk.assessr Assessing Package Risk Metrics A reliable and validated tool that captures detailed risk metrics \n    such as R 'CMD' check, test coverage, traceability matrix, documentation, dependencies, \n    reverse dependencies, suggested dependency analysis, repository data, \n    and enhanced reporting for R packages that are local or stored \n    on remote repositories such as GitHub, CRAN, and Bioconductor.  "
  },
  {
    "id": 19536,
    "package_name": "riskdiff",
    "title": "Risk Difference Estimation with Multiple Link Functions and\nInverse Probability of Treatment Weighting",
    "description": "Calculates risk differences (or prevalence differences for \n    cross-sectional data) using generalized linear models with automatic \n    link function selection. Provides robust model fitting with fallback \n    methods, support for stratification and adjustment variables, inverse\n    probability of treatment weighting (IPTW) for causal inference, and \n    publication-ready output formatting. Handles model convergence issues\n    gracefully and provides confidence intervals using multiple approaches.\n    Methods are based on approaches described in Mark W. Donoghoe and \n    Ian C. Marschner (2018) \"logbin: An R Package for Relative Risk \n    Regression Using the Log-Binomial Model\" <doi:10.18637/jss.v086.i09> \n    for robust GLM fitting, Peter C. Austin (2011) \"An Introduction to \n    Propensity Score Methods for Reducing the Effects of Confounding in \n    Observational Studies\" <doi:10.1080/00273171.2011.568786> for IPTW methods,\n    and standard epidemiological methods for risk difference estimation as \n    described in Kenneth J. Rothman, Sander Greenland and Timothy L. Lash \n    (2008, ISBN:9780781755641) \"Modern Epidemiology\".",
    "version": "0.2.1",
    "maintainer": "John D. Murphy <jackmurphy2351@gmail.com>",
    "author": "John D. Murphy [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7714-9976>, MPH, PhD)",
    "url": "https://github.com/jackmurphy2351/riskdiff",
    "bug_reports": "https://github.com/jackmurphy2351/riskdiff/issues",
    "repository": "https://cran.r-project.org/package=riskdiff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "riskdiff Risk Difference Estimation with Multiple Link Functions and\nInverse Probability of Treatment Weighting Calculates risk differences (or prevalence differences for \n    cross-sectional data) using generalized linear models with automatic \n    link function selection. Provides robust model fitting with fallback \n    methods, support for stratification and adjustment variables, inverse\n    probability of treatment weighting (IPTW) for causal inference, and \n    publication-ready output formatting. Handles model convergence issues\n    gracefully and provides confidence intervals using multiple approaches.\n    Methods are based on approaches described in Mark W. Donoghoe and \n    Ian C. Marschner (2018) \"logbin: An R Package for Relative Risk \n    Regression Using the Log-Binomial Model\" <doi:10.18637/jss.v086.i09> \n    for robust GLM fitting, Peter C. Austin (2011) \"An Introduction to \n    Propensity Score Methods for Reducing the Effects of Confounding in \n    Observational Studies\" <doi:10.1080/00273171.2011.568786> for IPTW methods,\n    and standard epidemiological methods for risk difference estimation as \n    described in Kenneth J. Rothman, Sander Greenland and Timothy L. Lash \n    (2008, ISBN:9780781755641) \"Modern Epidemiology\".  "
  },
  {
    "id": 19537,
    "package_name": "riskmetric",
    "title": "Risk Metrics to Evaluating R Packages",
    "description": "Facilities for assessing R packages against a number of metrics to \n    help quantify their robustness.",
    "version": "0.2.5",
    "maintainer": "Eli Miller <eli.miller@atorusresearch.com>",
    "author": "R Validation Hub [aut],\n  Doug Kelkhoff [aut],\n  Marly Gotti [aut],\n  Eli Miller [cre, aut],\n  Kevin K [aut],\n  Yilong Zhang [aut],\n  Eric Milliman [aut],\n  Juliane Manitz [aut],\n  Mark Padgham [ctb],\n  PSI special interest group Application and Implementation of\n    Methodologies in Statistics [cph]",
    "url": "https://pharmar.github.io/riskmetric/,\nhttps://github.com/pharmaR/riskmetric",
    "bug_reports": "https://github.com/pharmaR/riskmetric/issues",
    "repository": "https://cran.r-project.org/package=riskmetric",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "riskmetric Risk Metrics to Evaluating R Packages Facilities for assessing R packages against a number of metrics to \n    help quantify their robustness.  "
  },
  {
    "id": 19558,
    "package_name": "rjsoncons",
    "title": "Query, Pivot, Patch, and Validate 'JSON' and 'NDJSON'",
    "description": "Functions to query (filter or transform), pivot (convert\n    from array-of-objects to object-of-arrays, for easy import as 'R'\n    data frame), search, patch (edit), and validate (against 'JSON Schema')\n    'JSON' and 'NDJSON' strings, files, or URLs. Query and\n    pivot support 'JSONpointer', 'JSONpath' or 'JMESpath'\n    expressions. The implementation uses the 'jsoncons'\n    <https://danielaparker.github.io/jsoncons/> header-only library;\n    the library is easily linked to other packages for direct access\n    to 'C++' functionality not implemented here.",
    "version": "1.3.2",
    "maintainer": "Martin Morgan <mtmorgan.xyz@gmail.com>",
    "author": "Martin Morgan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5874-8148>),\n  Marcel Ramos [aut] (ORCID: <https://orcid.org/0000-0002-3242-0582>),\n  Daniel Parker [aut, cph] (jsoncons C++ library maintainer)",
    "url": "https://mtmorgan.github.io/rjsoncons/",
    "bug_reports": "https://github.com/mtmorgan/rjsoncons/issues",
    "repository": "https://cran.r-project.org/package=rjsoncons",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rjsoncons Query, Pivot, Patch, and Validate 'JSON' and 'NDJSON' Functions to query (filter or transform), pivot (convert\n    from array-of-objects to object-of-arrays, for easy import as 'R'\n    data frame), search, patch (edit), and validate (against 'JSON Schema')\n    'JSON' and 'NDJSON' strings, files, or URLs. Query and\n    pivot support 'JSONpointer', 'JSONpath' or 'JMESpath'\n    expressions. The implementation uses the 'jsoncons'\n    <https://danielaparker.github.io/jsoncons/> header-only library;\n    the library is easily linked to other packages for direct access\n    to 'C++' functionality not implemented here.  "
  },
  {
    "id": 19563,
    "package_name": "rkafkajars",
    "title": "External Jars Required for Package 'rkafka'",
    "description": "The 'rkafkajars' package collects all the external jars required for the 'rkafka' package.",
    "version": "1.2",
    "maintainer": "Shruti Gupta <shrutigupta34@gmail.com>",
    "author": "Shruti Gupta [aut,cre], Coda Hale and Yammer Inc.[ctb,cph],Sun Microsystems Inc.[ctb,cph],Marc Prud'hommeaux[ctb,cph],Paul Holser[ctb],Junit[ctb,cph],The Apache Software Foundation [ctb,cph],Stefan Groschupf[ctb,cph],Taro L.Saito[ctb],EPFL Typesafe Inc.[ctb,cph],QOS.ch[ctb,cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rkafkajars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rkafkajars External Jars Required for Package 'rkafka' The 'rkafkajars' package collects all the external jars required for the 'rkafka' package.  "
  },
  {
    "id": 19592,
    "package_name": "rmarchingcubes",
    "title": "Calculate 3D Contour Meshes Using the Marching Cubes Algorithm",
    "description": "A port of the C++ routine for applying the marching cubes algorithm written by \n    Thomas Lewiner et al. (2012) <doi:10.1080/10867651.2003.10487582> into an R package. \n    The package supplies the contour3d() function, which takes a 3-dimensional array of voxel \n    data and calculates the vertices, vertex normals, and faces for a 3d mesh representing \n    the contour(s) at a given level.",
    "version": "0.1.4",
    "maintainer": "S. H. Wilks <sam.wilks@unimelb.edu.au>",
    "author": "S. H. Wilks [aut, cre],\n  Thomas Lewiner [aut]",
    "url": "https://github.com/shwilks/rmarchingcubes",
    "bug_reports": "https://github.com/shwilks/rmarchingcubes/issues",
    "repository": "https://cran.r-project.org/package=rmarchingcubes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rmarchingcubes Calculate 3D Contour Meshes Using the Marching Cubes Algorithm A port of the C++ routine for applying the marching cubes algorithm written by \n    Thomas Lewiner et al. (2012) <doi:10.1080/10867651.2003.10487582> into an R package. \n    The package supplies the contour3d() function, which takes a 3-dimensional array of voxel \n    data and calculates the vertices, vertex normals, and faces for a 3d mesh representing \n    the contour(s) at a given level.  "
  },
  {
    "id": 19647,
    "package_name": "rnrfa",
    "title": "UK National River Flow Archive Data from R",
    "description": "Utility functions to retrieve data from the UK National River\n    Flow Archive (<https://nrfa.ceh.ac.uk/>, terms and conditions:\n    <https://nrfa.ceh.ac.uk/help/costs-terms-and-conditions>). The package\n    contains R wrappers to the UK NRFA data temporary-API. There are\n    functions to retrieve stations falling in a bounding box, to generate\n    a map and extracting time series and general information. The package\n    is fully described in Vitolo et al (2016) \"rnrfa: An R package to\n    Retrieve, Filter and Visualize Data from the UK National River Flow\n    Archive\"\n    <https://journal.r-project.org/archive/2016/RJ-2016-036/RJ-2016-036.pdf>.",
    "version": "2.1.0.7",
    "maintainer": "Ilaria Prosdocimi <prosdocimi.ilaria@gmail.com>",
    "author": "Ilaria Prosdocimi [ctb, cre] (ORCID:\n    <https://orcid.org/0000-0001-8565-094X>),\n  Claudia Vitolo [aut] (ORCID: <https://orcid.org/0000-0002-4252-1176>,\n    Claudia is the original creator of the package),\n  Matthew Fry [ctb] (Matthew supervised the unofficial API integration.),\n  Wouter Buytaert [ctb] (This package is part of Claudia Vitolo's PhD\n    work and Wouter is the supervisor.),\n  Michael Spencer [ctb] (Michael updated the function osg_parse to work\n    with grid references of different lengths.),\n  Tobias Gauster [ctb] (Tobias improved the function osg_parse\n    introducing vectorisation)",
    "url": "https://ilapros.github.io/rnrfa/",
    "bug_reports": "https://github.com/ilapros/rnrfa/issues",
    "repository": "https://cran.r-project.org/package=rnrfa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rnrfa UK National River Flow Archive Data from R Utility functions to retrieve data from the UK National River\n    Flow Archive (<https://nrfa.ceh.ac.uk/>, terms and conditions:\n    <https://nrfa.ceh.ac.uk/help/costs-terms-and-conditions>). The package\n    contains R wrappers to the UK NRFA data temporary-API. There are\n    functions to retrieve stations falling in a bounding box, to generate\n    a map and extracting time series and general information. The package\n    is fully described in Vitolo et al (2016) \"rnrfa: An R package to\n    Retrieve, Filter and Visualize Data from the UK National River Flow\n    Archive\"\n    <https://journal.r-project.org/archive/2016/RJ-2016-036/RJ-2016-036.pdf>.  "
  },
  {
    "id": 19712,
    "package_name": "roclang",
    "title": "Functions for Diffusing Function Documentations into 'Roxygen'\nComments",
    "description": "Efficient diffusing of content across function documentations. Sections, parameters or dot parameters are extracted from function documentations and turned into valid Rd character strings, which are ready to diffuse into the 'roxygen' comments of another function by inserting inline code. ",
    "version": "0.2.3",
    "maintainer": "Xiurui Zhu <zxr6@163.com>",
    "author": "Xiurui Zhu [aut, cre]",
    "url": "https://github.com/zhuxr11/roclang",
    "bug_reports": "https://github.com/zhuxr11/roclang/issues",
    "repository": "https://cran.r-project.org/package=roclang",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roclang Functions for Diffusing Function Documentations into 'Roxygen'\nComments Efficient diffusing of content across function documentations. Sections, parameters or dot parameters are extracted from function documentations and turned into valid Rd character strings, which are ready to diffuse into the 'roxygen' comments of another function by inserting inline code.   "
  },
  {
    "id": 19715,
    "package_name": "rocrateR",
    "title": "RO-Crate R Package Wrapper",
    "description": "R package for creating, manipulating and reading RO-Crates. Latest\n    supported version of the specification: <https://w3id.org/ro/crate/1.2/>.",
    "version": "0.0.1",
    "maintainer": "Roberto Villegas-Diaz <r.villegas-diaz@outlook.com>",
    "author": "Roberto Villegas-Diaz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5036-8661>),\n  Research Object community [cph]",
    "url": "https://github.com/ResearchObject/ro-crate-r/",
    "bug_reports": "https://github.com/ResearchObject/ro-crate-r/issues/",
    "repository": "https://cran.r-project.org/package=rocrateR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rocrateR RO-Crate R Package Wrapper R package for creating, manipulating and reading RO-Crates. Latest\n    supported version of the specification: <https://w3id.org/ro/crate/1.2/>.  "
  },
  {
    "id": 19720,
    "package_name": "roger",
    "title": "Automated Grading of R Scripts",
    "description": "Tools for grading the coding style and documentation of R\n  scripts. This is the R component of Roger the Omni Grader, an\n  automated grading system for computer programming projects based on\n  Unix shell scripts; see <https://gitlab.com/roger-project>. The\n  package also provides an R interface to the shell scripts. Inspired by\n  the lintr package.",
    "version": "1.5-1",
    "maintainer": "Vincent Goulet <vincent.goulet@act.ulaval.ca>",
    "author": "Vincent Goulet [aut, cre],\n  Samuel Fr\u00e9chette [aut],\n  Jean-Christophe Langlois [aut],\n  Jim Hester [ctb]",
    "url": "https://roger-project.gitlab.io",
    "bug_reports": "https://gitlab.com/roger-project/roger-rpkg/-/issues",
    "repository": "https://cran.r-project.org/package=roger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roger Automated Grading of R Scripts Tools for grading the coding style and documentation of R\n  scripts. This is the R component of Roger the Omni Grader, an\n  automated grading system for computer programming projects based on\n  Unix shell scripts; see <https://gitlab.com/roger-project>. The\n  package also provides an R interface to the shell scripts. Inspired by\n  the lintr package.  "
  },
  {
    "id": 19732,
    "package_name": "rolog",
    "title": "Query 'SWI'-'Prolog' from R",
    "description": "This R package connects to SWI-Prolog, <https://www.swi-prolog.org/>, so that R can send deterministic and non-deterministic queries to prolog (consult, query/submit, once, findall).",
    "version": "0.9.23",
    "maintainer": "Matthias Gondan <Matthias.Gondan-Rochon@uibk.ac.at>",
    "author": "Matthias Gondan [aut, com, cre] (University of Innsbruck),\n  European Commission [fnd] (Erasmus+ Programme,\n    2019-1-EE01-KA203-051708)",
    "url": "https://github.com/mgondan/rolog",
    "bug_reports": "https://github.com/mgondan/rolog/issues",
    "repository": "https://cran.r-project.org/package=rolog",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rolog Query 'SWI'-'Prolog' from R This R package connects to SWI-Prolog, <https://www.swi-prolog.org/>, so that R can send deterministic and non-deterministic queries to prolog (consult, query/submit, once, findall).  "
  },
  {
    "id": 19740,
    "package_name": "ropensecretsapi",
    "title": "R Package for the OpenSecrets.org API",
    "description": "An R package for the OpenSecrets.org web services API.",
    "version": "1.0.1",
    "maintainer": "Thomas P. Fuller <thomas.fuller@coherentlogic.com>",
    "author": "Thomas P. Fuller <thomas.fuller@coherentlogic.com>",
    "url": "http://www.r-project.org,\nhttp://coherentlogic.com/r-package-for-the-opensecrets-org-api?source=cran",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ropensecretsapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ropensecretsapi R Package for the OpenSecrets.org API An R package for the OpenSecrets.org web services API.  "
  },
  {
    "id": 19765,
    "package_name": "roxut",
    "title": "Document Unit Tests Roxygen-Style",
    "description": "Much as 'roxygen2' allows one to document functions in the same file as the function itself, 'roxut'  allows one to write the unit tests in the same file as the function.  Once processed, the unit tests are moved to the appropriate directory.  Currently supports 'testthat' and 'tinytest' frameworks. The 'roxygen2' package provides much of the infrastructure.",
    "version": "0.4.0",
    "maintainer": "Bryan A. Hanson <hanson@depauw.edu>",
    "author": "Bryan A. Hanson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3536-8246>),\n  Claudia Beleites [ctb],\n  Hadley Wickham [aut, cph] (roxygen2 code),\n  Peter Danenberg [aut, cph] (roxygen2 code),\n  G\u00e1bor Cs\u00e1rdi [aut] (roxygen2 code),\n  Manuel Eugster [aut, cph] (roxygen2 code),\n  RStudio [cph] (roxygen2 code)",
    "url": "https://github.com/bryanhanson/roxut",
    "bug_reports": "https://github.com/bryanhanson/roxut/issues",
    "repository": "https://cran.r-project.org/package=roxut",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxut Document Unit Tests Roxygen-Style Much as 'roxygen2' allows one to document functions in the same file as the function itself, 'roxut'  allows one to write the unit tests in the same file as the function.  Once processed, the unit tests are moved to the appropriate directory.  Currently supports 'testthat' and 'tinytest' frameworks. The 'roxygen2' package provides much of the infrastructure.  "
  },
  {
    "id": 19766,
    "package_name": "roxy.shinylive",
    "title": "A 'roxygen2' Extension for 'Shinylive'",
    "description": "An extension for 'roxygen2' to embed 'Shinylive' applications\n    in the package documentation.",
    "version": "1.0.0",
    "maintainer": "Pawel Rucki <pawel.rucki@roche.com>",
    "author": "Pawel Rucki [aut, cre],\n  F. Hoffmann-La Roche AG [cph, fnd]",
    "url": "https://github.com/insightsengineering/roxy.shinylive/",
    "bug_reports": "https://github.com/insightsengineering/roxy.shinylive/issues",
    "repository": "https://cran.r-project.org/package=roxy.shinylive",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxy.shinylive A 'roxygen2' Extension for 'Shinylive' An extension for 'roxygen2' to embed 'Shinylive' applications\n    in the package documentation.  "
  },
  {
    "id": 19767,
    "package_name": "roxyglobals",
    "title": "'Roxygen2' Global Variable Declarations",
    "description": "Generate utils::globalVariables() from 'roxygen2' @global and @autoglobal tags.",
    "version": "1.0.0",
    "maintainer": "Anthony North <anthony.jl.north@gmail.com>",
    "author": "Anthony North [aut, cre, cph],\n  Miles McBain [ctb] (ORCID: <https://orcid.org/0000-0003-2865-2548>)",
    "url": "https://github.com/anthonynorth/roxyglobals",
    "bug_reports": "https://github.com/anthonynorth/roxyglobals/issues",
    "repository": "https://cran.r-project.org/package=roxyglobals",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxyglobals 'Roxygen2' Global Variable Declarations Generate utils::globalVariables() from 'roxygen2' @global and @autoglobal tags.  "
  },
  {
    "id": 19768,
    "package_name": "roxylint",
    "title": "Lint 'roxygen2'-Generated Documentation",
    "description": "Provides formatting linting to 'roxygen2' tags. Linters report\n    'roxygen2' tags that do not conform to a standard style. These linters\n    can be a helpful check for building more consistent documentation and \n    to provide reminders about best practices or checks for typos. Default \n    linting suites are provided for common style guides such as the one \n    followed by the 'tidyverse', though custom linters can be registered by \n    other packages or be custom-tailored to a specific package.",
    "version": "0.1.0",
    "maintainer": "Doug Kelkhoff <doug.kelkhoff@gmail.com>",
    "author": "Doug Kelkhoff [aut, cre]",
    "url": "https://github.com/openpharma/roxylint,\nhttps://openpharma.github.io/roxylint/",
    "bug_reports": "https://github.com/openpharma/roxylint/issues",
    "repository": "https://cran.r-project.org/package=roxylint",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxylint Lint 'roxygen2'-Generated Documentation Provides formatting linting to 'roxygen2' tags. Linters report\n    'roxygen2' tags that do not conform to a standard style. These linters\n    can be a helpful check for building more consistent documentation and \n    to provide reminders about best practices or checks for typos. Default \n    linting suites are provided for common style guides such as the one \n    followed by the 'tidyverse', though custom linters can be registered by \n    other packages or be custom-tailored to a specific package.  "
  },
  {
    "id": 19769,
    "package_name": "roxytest",
    "title": "Various Tests with 'roxygen2'",
    "description": "Various tests as 'roxygen2' roclets: e.g. 'testthat' and 'tinytest' tests. \n  Also other static analysis tools as checking parameter documentation consistency and others.",
    "version": "0.0.2",
    "maintainer": "Mikkel Meyer Andersen <mikl@math.aau.dk>",
    "author": "Mikkel Meyer Andersen [aut, cre],\n  Ege Rubak [ctb]",
    "url": "",
    "bug_reports": "https://github.com/mikldk/roxytest/issues",
    "repository": "https://cran.r-project.org/package=roxytest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxytest Various Tests with 'roxygen2' Various tests as 'roxygen2' roclets: e.g. 'testthat' and 'tinytest' tests. \n  Also other static analysis tools as checking parameter documentation consistency and others.  "
  },
  {
    "id": 19770,
    "package_name": "roxytypes",
    "title": "Typed Parameter Tags for Integration with 'roxygen2'",
    "description": "Provides typed parameter documentation tags for integration\n    with 'roxygen2'. Typed parameter tags provide a consistent interface for\n    annotating expected types for parameters and returned values. Tools for\n    converting from existing styles are also provided to easily adapt projects\n    which implement typed documentation by convention rather than tag. Use the\n    default format or provide your own.",
    "version": "0.1.2",
    "maintainer": "Doug Kelkhoff <doug.kelkhoff@gmail.com>",
    "author": "Doug Kelkhoff [aut, cre]",
    "url": "https://github.com/openpharma/roxytypes,\nhttps://openpharma.github.io/roxytypes/",
    "bug_reports": "https://github.com/openpharma/roxytypes/issues",
    "repository": "https://cran.r-project.org/package=roxytypes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roxytypes Typed Parameter Tags for Integration with 'roxygen2' Provides typed parameter documentation tags for integration\n    with 'roxygen2'. Typed parameter tags provide a consistent interface for\n    annotating expected types for parameters and returned values. Tools for\n    converting from existing styles are also provided to easily adapt projects\n    which implement typed documentation by convention rather than tag. Use the\n    default format or provide your own.  "
  },
  {
    "id": 19814,
    "package_name": "rrapply",
    "title": "Revisiting Base Rapply",
    "description": "The minimal 'rrapply'-package contains a single function rrapply(), providing an extended implementation of 'R'-base rapply() by allowing to recursively apply a function to elements of a nested list based on a general condition function and including the possibility to prune or aggregate nested list elements from the result. In addition, special arguments can be supplied to access the name, location, parents and siblings in the nested list of the element under evaluation. The rrapply() function builds upon rapply()'s native 'C' implementation and requires no other package dependencies.",
    "version": "1.2.8",
    "maintainer": "Joris Chau <joris.chau@openanalytics.eu>",
    "author": "Joris Chau [aut, cre]",
    "url": "https://jorischau.github.io/rrapply/,\nhttps://github.com/JorisChau/rrapply",
    "bug_reports": "https://github.com/JorisChau/rrapply/issues",
    "repository": "https://cran.r-project.org/package=rrapply",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rrapply Revisiting Base Rapply The minimal 'rrapply'-package contains a single function rrapply(), providing an extended implementation of 'R'-base rapply() by allowing to recursively apply a function to elements of a nested list based on a general condition function and including the possibility to prune or aggregate nested list elements from the result. In addition, special arguments can be supplied to access the name, location, parents and siblings in the nested list of the element under evaluation. The rrapply() function builds upon rapply()'s native 'C' implementation and requires no other package dependencies.  "
  },
  {
    "id": 19855,
    "package_name": "rsmatch",
    "title": "Matching Methods for Time-Varying Observational Studies",
    "description": "Implements popular methods for matching in time-varying\n    observational studies. Matching is difficult in this scenario because\n    participants can be treated at different times which may have an\n    influence on the outcomes. The core methods include: \"Balanced Risk\n    Set Matching\" from Li, Propert, and Rosenbaum (2011)\n    <doi:10.1198/016214501753208573> and \"Propensity Score Matching with\n    Time-Dependent Covariates\" from Lu (2005)\n    <doi:10.1111/j.1541-0420.2005.00356.x>. Some functions use the\n    'Gurobi' optimization back-end to improve the optimization problem\n    speed; the 'gurobi' R package and associated software can be\n    downloaded from <https://www.gurobi.com> after obtaining a license.",
    "version": "0.2.1",
    "maintainer": "Sean Kent <skent259@gmail.com>",
    "author": "Sean Kent [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-8697-9069>),\n  Mitchell Paukner [aut, cph] (ORCID:\n    <https://orcid.org/0000-0003-3839-5311>)",
    "url": "https://skent259.github.io/rsmatch/,\nhttps://github.com/skent259/rsmatch",
    "bug_reports": "https://github.com/skent259/rsmatch/issues",
    "repository": "https://cran.r-project.org/package=rsmatch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rsmatch Matching Methods for Time-Varying Observational Studies Implements popular methods for matching in time-varying\n    observational studies. Matching is difficult in this scenario because\n    participants can be treated at different times which may have an\n    influence on the outcomes. The core methods include: \"Balanced Risk\n    Set Matching\" from Li, Propert, and Rosenbaum (2011)\n    <doi:10.1198/016214501753208573> and \"Propensity Score Matching with\n    Time-Dependent Covariates\" from Lu (2005)\n    <doi:10.1111/j.1541-0420.2005.00356.x>. Some functions use the\n    'Gurobi' optimization back-end to improve the optimization problem\n    speed; the 'gurobi' R package and associated software can be\n    downloaded from <https://www.gurobi.com> after obtaining a license.  "
  },
  {
    "id": 19863,
    "package_name": "rspacer",
    "title": "'RSpace' API Wrapper",
    "description": "Wrapper for the 'RSpace' Electronic Lab Notebook (<https://www.researchspace.com/>)\n    API. This packages provides convenience functions to browse, search, create,\n    and edit your 'RSpace' documents. In addition, it enables filling 'RSpace' templates\n    from R Markdown/Quarto templates or tabular data (e.g., 'Excel' files).\n    This R package is not developed or endorsed by 'Research Space'.",
    "version": "0.3.1",
    "maintainer": "Gerhard Burger <burger.ga@gmail.com>",
    "author": "Gerhard Burger [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1062-5576>),\n  Hanneke Leegwater [aut] (ORCID:\n    <https://orcid.org/0000-0001-6003-1544>),\n  Leiden University [cph, fnd] (ROR: <https://ror.org/027bh9e22>)",
    "url": "https://github.com/lacdr/rspacer, https://lacdr.github.io/rspacer/",
    "bug_reports": "https://github.com/lacdr/rspacer/issues",
    "repository": "https://cran.r-project.org/package=rspacer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rspacer 'RSpace' API Wrapper Wrapper for the 'RSpace' Electronic Lab Notebook (<https://www.researchspace.com/>)\n    API. This packages provides convenience functions to browse, search, create,\n    and edit your 'RSpace' documents. In addition, it enables filling 'RSpace' templates\n    from R Markdown/Quarto templates or tabular data (e.g., 'Excel' files).\n    This R package is not developed or endorsed by 'Research Space'.  "
  },
  {
    "id": 19884,
    "package_name": "rsurv",
    "title": "Random Generation of Survival Data",
    "description": "Random generation of survival data from a wide range of regression models, including accelerated failure time (AFT), proportional hazards (PH), proportional odds (PO), accelerated hazard (AH), Yang and Prentice (YP), and extended hazard (EH) models. The package 'rsurv' also stands out by its ability to generate survival data from an unlimited number of baseline distributions provided that an implementation of the quantile function of the chosen baseline distribution is available in R. Another nice feature of the package 'rsurv' lies in the fact that linear predictors are specified via a formula-based approach, facilitating the inclusion of categorical variables and interaction terms. The functions implemented in the package 'rsurv' can also be employed to simulate survival data with more complex structures, such as survival data with different types of censoring mechanisms, survival data with cure fraction, survival data with random effects (frailties), multivariate survival data, and competing risks survival data. Details about the R package 'rsurv' can be found in Demarqui (2024) <doi:10.48550/arXiv.2406.01750>.",
    "version": "0.0.2",
    "maintainer": "Fabio Demarqui <fndemarqui@est.ufmg.br>",
    "author": "Fabio Demarqui [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9236-1986>)",
    "url": "https://github.com/fndemarqui/rsurv,\nhttps://fndemarqui.github.io/rsurv/",
    "bug_reports": "https://github.com/fndemarqui/rsurv/issues",
    "repository": "https://cran.r-project.org/package=rsurv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rsurv Random Generation of Survival Data Random generation of survival data from a wide range of regression models, including accelerated failure time (AFT), proportional hazards (PH), proportional odds (PO), accelerated hazard (AH), Yang and Prentice (YP), and extended hazard (EH) models. The package 'rsurv' also stands out by its ability to generate survival data from an unlimited number of baseline distributions provided that an implementation of the quantile function of the chosen baseline distribution is available in R. Another nice feature of the package 'rsurv' lies in the fact that linear predictors are specified via a formula-based approach, facilitating the inclusion of categorical variables and interaction terms. The functions implemented in the package 'rsurv' can also be employed to simulate survival data with more complex structures, such as survival data with different types of censoring mechanisms, survival data with cure fraction, survival data with random effects (frailties), multivariate survival data, and competing risks survival data. Details about the R package 'rsurv' can be found in Demarqui (2024) <doi:10.48550/arXiv.2406.01750>.  "
  },
  {
    "id": 19885,
    "package_name": "rsurveycto",
    "title": "Interact with Data on 'SurveyCTO'",
    "description": "'SurveyCTO' is a platform for mobile data collection in offline settings.\n  The 'rsurveycto' R package uses the 'SurveyCTO' REST API\n  <https://docs.surveycto.com/05-exporting-and-publishing-data/05-api-access/01.api-access.html>\n  to read datasets and forms from a 'SurveyCTO' server into R as 'data.table's\n  and to download file attachments. The package also has limited support to\n  write datasets to a server.",
    "version": "0.2.2",
    "maintainer": "Jake Hughey <jake@agency.fund>",
    "author": "Jake Hughey [aut, cre],\n  Robert On [aut]",
    "url": "https://agency-fund.github.io/rsurveycto/,\nhttps://github.com/agency-fund/rsurveycto",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rsurveycto",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rsurveycto Interact with Data on 'SurveyCTO' 'SurveyCTO' is a platform for mobile data collection in offline settings.\n  The 'rsurveycto' R package uses the 'SurveyCTO' REST API\n  <https://docs.surveycto.com/05-exporting-and-publishing-data/05-api-access/01.api-access.html>\n  to read datasets and forms from a 'SurveyCTO' server into R as 'data.table's\n  and to download file attachments. The package also has limited support to\n  write datasets to a server.  "
  },
  {
    "id": 19896,
    "package_name": "rtables.officer",
    "title": "Exporting Tools for 'rtables'",
    "description": "Designed to create and display complex tables with R, the\n    'rtables' R package allows cells in an 'rtables' object to contain any\n    high-dimensional data structure, which can then be displayed with\n    cell-specific formatting instructions. Additionally, the\n    'rtables.officer' package supports export formats related to the\n    Microsoft Office software suite, including Microsoft Word ('docx') and\n    Microsoft PowerPoint ('pptx').",
    "version": "0.1.1",
    "maintainer": "Joe Zhu <joe.zhu@roche.com>",
    "author": "Gabriel Becker [ctb],\n  Davide Garolini [aut] (ORCID: <https://orcid.org/0000-0002-1445-1369>),\n  Emily de la Rua [aut] (ORCID: <https://orcid.org/0009-0000-8738-5561>),\n  Abinaya Yogasekaram [aut] (ORCID:\n    <https://orcid.org/0009-0005-2083-1105>),\n  Joe Zhu [aut, cre] (ORCID: <https://orcid.org/0000-0001-7566-2787>),\n  F. Hoffmann-La Roche AG [cph, fnd]",
    "url": "https://github.com/insightsengineering/rtables.officer,\nhttps://insightsengineering.github.io/rtables.officer/",
    "bug_reports": "https://github.com/insightsengineering/rtables.officer/issues",
    "repository": "https://cran.r-project.org/package=rtables.officer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rtables.officer Exporting Tools for 'rtables' Designed to create and display complex tables with R, the\n    'rtables' R package allows cells in an 'rtables' object to contain any\n    high-dimensional data structure, which can then be displayed with\n    cell-specific formatting instructions. Additionally, the\n    'rtables.officer' package supports export formats related to the\n    Microsoft Office software suite, including Microsoft Word ('docx') and\n    Microsoft PowerPoint ('pptx').  "
  },
  {
    "id": 19941,
    "package_name": "runExamplesWrapper",
    "title": "Wrapper for 'run_examples()'",
    "description": "Captures errors encountered when running 'run_examples()', and processes and archives them. The function 'run_examples()' within the 'devtools' package allows batch execution of all of the examples within a given package. This is much more convenient than testing each example manually. However, a major inconvenience is that if an error is encountered, the program stops and does not complete testing the remaining examples. Also, there is not a systematic record of the results, namely which package functions had no examples, which had examples that failed, and which had examples that succeeded. The current package provides the missing functionality.",
    "version": "1.0",
    "maintainer": "Barry Zeeberg <barryz2013@gmail.com>",
    "author": "Barry Zeeberg [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=runExamplesWrapper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "runExamplesWrapper Wrapper for 'run_examples()' Captures errors encountered when running 'run_examples()', and processes and archives them. The function 'run_examples()' within the 'devtools' package allows batch execution of all of the examples within a given package. This is much more convenient than testing each example manually. However, a major inconvenience is that if an error is encountered, the program stops and does not complete testing the remaining examples. Also, there is not a systematic record of the results, namely which package functions had no examples, which had examples that failed, and which had examples that succeeded. The current package provides the missing functionality.  "
  },
  {
    "id": 19959,
    "package_name": "rvcheck",
    "title": "R/Package Version Check",
    "description": "Check latest release version of R and R package (both in 'CRAN', 'Bioconductor' or 'Github').",
    "version": "0.2.1",
    "maintainer": "Guangchuang Yu <guangchuangyu@gmail.com>",
    "author": "Guangchuang Yu [aut, cre],\n  Chun-hui Gao [ctb]",
    "url": "https://github.com/GuangchuangYu/rvcheck",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rvcheck",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rvcheck R/Package Version Check Check latest release version of R and R package (both in 'CRAN', 'Bioconductor' or 'Github').  "
  },
  {
    "id": 19979,
    "package_name": "rworkflows",
    "title": "Test, Document, Containerise, and Deploy R Packages",
    "description": "Reproducibility is essential to the progress of research, \n  yet achieving it remains elusive even in computational fields. \n  Continuous Integration (CI) platforms offer a powerful way to launch automated workflows \n  to check and document code, but often require considerable time, effort, \n  and technical expertise to setup. We therefore developed the rworkflows suite \n  to make robust CI workflows easy and freely accessible to all R package developers. \n  rworkflows consists of 1) a CRAN/Bioconductor-compatible R package template, \n  2) an R package to quickly implement a standardised workflow, and \n  3) a centrally maintained GitHub Action. ",
    "version": "1.0.6",
    "maintainer": "Brian Schilder <brian_schilder@alumni.brown.edu>",
    "author": "Brian Schilder [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5949-2191>),\n  Alan Murphy [aut, ctb] (ORCID: <https://orcid.org/0000-0002-2487-8753>),\n  Nathan Skene [aut] (ORCID: <https://orcid.org/0000-0002-6807-3180>)",
    "url": "https://github.com/neurogenomics/rworkflows,\nhttps://CRAN.R-project.org/package=rworkflows",
    "bug_reports": "https://github.com/neurogenomics/rworkflows/issues",
    "repository": "https://cran.r-project.org/package=rworkflows",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rworkflows Test, Document, Containerise, and Deploy R Packages Reproducibility is essential to the progress of research, \n  yet achieving it remains elusive even in computational fields. \n  Continuous Integration (CI) platforms offer a powerful way to launch automated workflows \n  to check and document code, but often require considerable time, effort, \n  and technical expertise to setup. We therefore developed the rworkflows suite \n  to make robust CI workflows easy and freely accessible to all R package developers. \n  rworkflows consists of 1) a CRAN/Bioconductor-compatible R package template, \n  2) an R package to quickly implement a standardised workflow, and \n  3) a centrally maintained GitHub Action.   "
  },
  {
    "id": 19997,
    "package_name": "s3fs",
    "title": "'Amazon Web Service S3' File System",
    "description": "Access 'Amazon Web Service Simple Storage Service' ('S3') <https://aws.amazon.com/s3/>\n    as if it were a file system. Interface based on the R package 'fs'.",
    "version": "0.1.7",
    "maintainer": "Dyfan Jones <dyfan.r.jones@gmail.com>",
    "author": "Dyfan Jones [aut, cre]",
    "url": "https://github.com/DyfanJones/s3fs",
    "bug_reports": "https://github.com/DyfanJones/s3fs/issues",
    "repository": "https://cran.r-project.org/package=s3fs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "s3fs 'Amazon Web Service S3' File System Access 'Amazon Web Service Simple Storage Service' ('S3') <https://aws.amazon.com/s3/>\n    as if it were a file system. Interface based on the R package 'fs'.  "
  },
  {
    "id": 20009,
    "package_name": "sRNAGenetic",
    "title": "Analysis of Small RNA Expression Changes in Hybrid Plants",
    "description": "The most important function of the R package is the genetic effects analysis of small RNA in hybrid plants via two methods, and at the same time, it provides various forms of graph related to data characteristics and expression analysis. In terms of two classification methods, one is the calculation of the additive (a) and dominant (d), the other is the evaluation of expression level dominance by comparing the total expression of the small RNA in progeny with the expression level in the parent species.",
    "version": "0.1.0",
    "maintainer": "Yu qing Wu <wuyuqing0104@163.com>",
    "author": "Yu qing Wu [aut, cre] (ORCID: <https://orcid.org/0000-0002-6333-0926>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sRNAGenetic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sRNAGenetic Analysis of Small RNA Expression Changes in Hybrid Plants The most important function of the R package is the genetic effects analysis of small RNA in hybrid plants via two methods, and at the same time, it provides various forms of graph related to data characteristics and expression analysis. In terms of two classification methods, one is the calculation of the additive (a) and dominant (d), the other is the evaluation of expression level dominance by comparing the total expression of the small RNA in progeny with the expression level in the parent species.  "
  },
  {
    "id": 20120,
    "package_name": "sas7bdat",
    "title": "sas7bdat Reverse Engineering Documentation",
    "description": "Documentation and prototypes for the earliest (circa 2010) open-source effort to reverse engineer the sas7bdat file format. The package includes a prototype reader for sas7bdat files. However, newer packages may contain more robust readers for sas7bdat files.",
    "version": "0.8",
    "maintainer": "Matt Shotwell <matt.shotwell@vanderbilt.edu>",
    "author": "Matt Shotwell [aut, cre],\n  Clint Cummins [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sas7bdat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sas7bdat sas7bdat Reverse Engineering Documentation Documentation and prototypes for the earliest (circa 2010) open-source effort to reverse engineer the sas7bdat file format. The package includes a prototype reader for sas7bdat files. However, newer packages may contain more robust readers for sas7bdat files.  "
  },
  {
    "id": 20121,
    "package_name": "sasLM",
    "title": "'SAS' Linear Model",
    "description": "This is a core implementation of 'SAS' procedures for linear models - GLM, REG, ANOVA, TTEST, FREQ, and UNIVARIATE. Some R packages provide type II and type III SS. However, the results of nested and complex designs are often different from those of 'SAS.' Different results does not necessarily mean incorrectness. However, many wants the same results to SAS. This package aims to achieve that. \n             Reference: Littell RC, Stroup WW, Freund RJ (2002, ISBN:0-471-22174-0).",
    "version": "0.10.7",
    "maintainer": "Kyun-Seop Bae <k@acr.kr>",
    "author": "Kyun-Seop Bae [aut, cre]",
    "url": "https://cran.r-project.org/package=sasLM",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sasLM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sasLM 'SAS' Linear Model This is a core implementation of 'SAS' procedures for linear models - GLM, REG, ANOVA, TTEST, FREQ, and UNIVARIATE. Some R packages provide type II and type III SS. However, the results of nested and complex designs are often different from those of 'SAS.' Different results does not necessarily mean incorrectness. However, many wants the same results to SAS. This package aims to achieve that. \n             Reference: Littell RC, Stroup WW, Freund RJ (2002, ISBN:0-471-22174-0).  "
  },
  {
    "id": 20161,
    "package_name": "scMappR",
    "title": "Single Cell Mapper",
    "description": "The single cell mapper (scMappR) R package contains a suite of bioinformatic tools that provide experimentally relevant cell-type specific information to a list of differentially expressed genes (DEG). The function \"scMappR_and_pathway_analysis\" reranks DEGs to generate cell-type specificity scores called cell-weighted fold-changes. Users input a list of DEGs, normalized counts, and a signature matrix into this function. scMappR then re-weights bulk DEGs by cell-type specific expression from the signature matrix, cell-type proportions from RNA-seq deconvolution and the ratio of cell-type proportions between the two conditions to account for changes in cell-type proportion. With cwFold-changes calculated, scMappR uses two approaches to utilize cwFold-changes to complete cell-type specific pathway analysis. The \"process_dgTMatrix_lists\" function in the scMappR package contains an automated scRNA-seq processing pipeline where users input scRNA-seq count data, which is made compatible for scMappR and other R packages that analyze scRNA-seq data. We further used this to store hundreds up regularly updating signature matrices. The functions \"tissue_by_celltype_enrichment\", \"tissue_scMappR_internal\", and \"tissue_scMappR_custom\" combine these consistently processed scRNAseq count data with gene-set enrichment tools to allow for cell-type marker enrichment of a generic gene list (e.g. GWAS hits). Reference: Sokolowski,D.J., Faykoo-Martinez,M., Erdman,L., Hou,H., Chan,C., Zhu,H., Holmes,M.M., Goldenberg,A. and Wilson,M.D. (2021) Single-cell mapper (scMappR): using scRNA-seq to infer cell-type specificities of differentially expressed genes. NAR Genomics and Bioinformatics. 3(1). Iqab011. <doi:10.1093/nargab/lqab011>.",
    "version": "1.0.12",
    "maintainer": "Dustin Sokolowski <djsokolowski95@gmail.com>",
    "author": "Dustin Sokolowski [aut, cre],\n  Mariela Faykoo-Martinez [aut],\n  Lauren Erdman [aut],\n  Houyun Hou [aut],\n  Cadia Chan [aut],\n  Helen Zhu [aut],\n  Melissa Holmes [aut],\n  Anna Goldenberg [aut],\n  Michael Wilson [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scMappR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scMappR Single Cell Mapper The single cell mapper (scMappR) R package contains a suite of bioinformatic tools that provide experimentally relevant cell-type specific information to a list of differentially expressed genes (DEG). The function \"scMappR_and_pathway_analysis\" reranks DEGs to generate cell-type specificity scores called cell-weighted fold-changes. Users input a list of DEGs, normalized counts, and a signature matrix into this function. scMappR then re-weights bulk DEGs by cell-type specific expression from the signature matrix, cell-type proportions from RNA-seq deconvolution and the ratio of cell-type proportions between the two conditions to account for changes in cell-type proportion. With cwFold-changes calculated, scMappR uses two approaches to utilize cwFold-changes to complete cell-type specific pathway analysis. The \"process_dgTMatrix_lists\" function in the scMappR package contains an automated scRNA-seq processing pipeline where users input scRNA-seq count data, which is made compatible for scMappR and other R packages that analyze scRNA-seq data. We further used this to store hundreds up regularly updating signature matrices. The functions \"tissue_by_celltype_enrichment\", \"tissue_scMappR_internal\", and \"tissue_scMappR_custom\" combine these consistently processed scRNAseq count data with gene-set enrichment tools to allow for cell-type marker enrichment of a generic gene list (e.g. GWAS hits). Reference: Sokolowski,D.J., Faykoo-Martinez,M., Erdman,L., Hou,H., Chan,C., Zhu,H., Holmes,M.M., Goldenberg,A. and Wilson,M.D. (2021) Single-cell mapper (scMappR): using scRNA-seq to infer cell-type specificities of differentially expressed genes. NAR Genomics and Bioinformatics. 3(1). Iqab011. <doi:10.1093/nargab/lqab011>.  "
  },
  {
    "id": 20165,
    "package_name": "scPipeline",
    "title": "A Wrapper for 'Seurat' and Related R Packages for End-to-End\nSingle Cell Analysis",
    "description": "Reports markers list, differentially expressed genes, associated pathways, cell-type annotations, does batch correction and other related single cell analyses all wrapped within 'Seurat'.",
    "version": "0.2.0.0",
    "maintainer": "Viswanadham Sridhara <Sridhara.Omics@gmail.com>",
    "author": "Viswanadham Sridhara [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0688-6140>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scPipeline",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scPipeline A Wrapper for 'Seurat' and Related R Packages for End-to-End\nSingle Cell Analysis Reports markers list, differentially expressed genes, associated pathways, cell-type annotations, does batch correction and other related single cell analyses all wrapped within 'Seurat'.  "
  },
  {
    "id": 20172,
    "package_name": "scSpatialSIM",
    "title": "A Point Pattern Simulator for Spatial Cellular Data",
    "description": "Single cell resolution data has been valuable in learning about tissue microenvironments and interactions between cells or spots. This package allows for the simulation of this level of data, be it single cell or \u2018spots\u2019, in both a univariate (single metric or cell type) and bivariate (2 or more metrics or cell types) ways. As more technologies come to marker, more methods will be developed to derive spatial metrics from the data which will require a way to benchmark methods against each other. Additionally, as the field currently stands, there is not a gold standard method to be compared against. We set out to develop an R package that will allow users to simulate point patterns that can be biologically informed from different tissue domains, holes, and varying degrees of clustering/colocalization. The data can be exported as spatial files and a summary file (like 'HALO'). <https://github.com/FridleyLab/scSpatialSIM/>.",
    "version": "0.1.3.4",
    "maintainer": "Fridley Lab <fridley.lab@moffitt.org>",
    "author": "Alex Soupir [aut],\n  Christopher Wilson [aut],\n  Jordan Creed [aut],\n  Julia Wrobel [aut],\n  Oscar Ospina [aut],\n  Brooke Fridley [aut, cph],\n  Fridley Lab [cre]",
    "url": "https://github.com/FridleyLab/scSpatialSIM",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=scSpatialSIM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scSpatialSIM A Point Pattern Simulator for Spatial Cellular Data Single cell resolution data has been valuable in learning about tissue microenvironments and interactions between cells or spots. This package allows for the simulation of this level of data, be it single cell or \u2018spots\u2019, in both a univariate (single metric or cell type) and bivariate (2 or more metrics or cell types) ways. As more technologies come to marker, more methods will be developed to derive spatial metrics from the data which will require a way to benchmark methods against each other. Additionally, as the field currently stands, there is not a gold standard method to be compared against. We set out to develop an R package that will allow users to simulate point patterns that can be biologically informed from different tissue domains, holes, and varying degrees of clustering/colocalization. The data can be exported as spatial files and a summary file (like 'HALO'). <https://github.com/FridleyLab/scSpatialSIM/>.  "
  },
  {
    "id": 20295,
    "package_name": "sdsfun",
    "title": "Spatial Data Science Complementary Features",
    "description": "Wrapping and supplementing commonly used functions in the R ecosystem related to spatial data science, \n             while serving as a basis for other packages maintained by Wenbo Lv.",
    "version": "0.8.1",
    "maintainer": "Wenbo Lv <lyu.geosocial@gmail.com>",
    "author": "Wenbo Lv [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0002-6003-3800>)",
    "url": "https://stscl.github.io/sdsfun/, https://github.com/stscl/sdsfun",
    "bug_reports": "https://github.com/stscl/sdsfun/issues",
    "repository": "https://cran.r-project.org/package=sdsfun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sdsfun Spatial Data Science Complementary Features Wrapping and supplementing commonly used functions in the R ecosystem related to spatial data science, \n             while serving as a basis for other packages maintained by Wenbo Lv.  "
  },
  {
    "id": 20313,
    "package_name": "secrdesign",
    "title": "Sampling Design for Spatially Explicit Capture-Recapture",
    "description": "Tools for designing spatially explicit capture-recapture studies of animal populations. This is primarily a simulation manager for package 'secr'. Extensions in version 2.5.0 include costing and evaluation of detector spacing.",
    "version": "2.10.0",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "author": "Murray Efford [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5231-5184>),\n  Ian Durbach [ctb] (ORCID: <https://orcid.org/0000-0003-0769-2153>)",
    "url": "https://www.otago.ac.nz/density/,\nhttps://github.com/MurrayEfford/secrdesign/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=secrdesign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "secrdesign Sampling Design for Spatially Explicit Capture-Recapture Tools for designing spatially explicit capture-recapture studies of animal populations. This is primarily a simulation manager for package 'secr'. Extensions in version 2.5.0 include costing and evaluation of detector spacing.  "
  },
  {
    "id": 20314,
    "package_name": "secret",
    "title": "Share Sensitive Information in R Packages",
    "description": "Allow sharing sensitive information, for example passwords,\n    'API' keys, etc., in R packages, using public key cryptography.",
    "version": "1.1.0",
    "maintainer": "G\u00e1bor Cs\u00e1rdi <csardi.gabor@gmail.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut, cre],\n  Andrie de Vries [aut]",
    "url": "https://github.com/gaborcsardi/secret#readme",
    "bug_reports": "https://github.com/gaborcsardi/secret/issues",
    "repository": "https://cran.r-project.org/package=secret",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "secret Share Sensitive Information in R Packages Allow sharing sensitive information, for example passwords,\n    'API' keys, etc., in R packages, using public key cryptography.  "
  },
  {
    "id": 20317,
    "package_name": "secrfunc",
    "title": "Helper Functions for Package 'secr'",
    "description": "Functions are provided for internal use by the spatial \n  capture-recapture package 'secr' (from version 5.4.0). The idea is to speed up \n  the installation of 'secr', and possibly reduce its size. Initially the functions \n  are those for area and transect search that use numerical integration code from \n  'RcppNumerical' and 'RcppEigen'. The functions are not intended to be user-friendly \n  and require considerable preprocessing of data.",
    "version": "1.0.0",
    "maintainer": "Murray Efford <murray.efford@otago.ac.nz>",
    "author": "Murray Efford [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5231-5184>),\n  Philipp Jund [ctb] ((faster transect search and spacing))",
    "url": "https://www.otago.ac.nz/density/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=secrfunc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "secrfunc Helper Functions for Package 'secr' Functions are provided for internal use by the spatial \n  capture-recapture package 'secr' (from version 5.4.0). The idea is to speed up \n  the installation of 'secr', and possibly reduce its size. Initially the functions \n  are those for area and transect search that use numerical integration code from \n  'RcppNumerical' and 'RcppEigen'. The functions are not intended to be user-friendly \n  and require considerable preprocessing of data.  "
  },
  {
    "id": 20333,
    "package_name": "segclust2d",
    "title": "Bivariate Segmentation/Clustering Methods and Tools",
    "description": "Provides two methods for segmentation and joint segmentation/clustering of\n    bivariate time-series. Originally intended for ecological segmentation\n    (home-range and behavioural modes) but easily applied on other series,\n    the package also provides tools for analysing outputs from R packages 'moveHMM' and 'marcher'.\n    The segmentation method is a bivariate extension of  Lavielle's method available in 'adehabitatLT' \n    (Lavielle, 1999 <doi:10.1016/S0304-4149(99)00023-X> and 2005 <doi:10.1016/j.sigpro.2005.01.012>).\n    This method rely on dynamic programming for efficient segmentation.\n    The segmentation/clustering method alternates steps of dynamic programming with an Expectation-Maximization algorithm.\n    This is an extension of Picard et al (2007) <doi:10.1111/j.1541-0420.2006.00729.x> method \n    (formerly available in 'cghseg' package) to the bivariate case.\n    The method is fully described in Patin et al (2018) <doi:10.1101/444794>.",
    "version": "0.3.3",
    "maintainer": "Remi Patin <remi.patin@normale.fr>",
    "author": "Remi Patin [aut, cre],\n  Marie-Pierre Etienne [aut],\n  Emilie Lebarbier [aut],\n  Simon Benhamou [aut]",
    "url": "https://github.com/rpatin/segclust2d",
    "bug_reports": "https://github.com/rpatin/segclust2d/issues",
    "repository": "https://cran.r-project.org/package=segclust2d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "segclust2d Bivariate Segmentation/Clustering Methods and Tools Provides two methods for segmentation and joint segmentation/clustering of\n    bivariate time-series. Originally intended for ecological segmentation\n    (home-range and behavioural modes) but easily applied on other series,\n    the package also provides tools for analysing outputs from R packages 'moveHMM' and 'marcher'.\n    The segmentation method is a bivariate extension of  Lavielle's method available in 'adehabitatLT' \n    (Lavielle, 1999 <doi:10.1016/S0304-4149(99)00023-X> and 2005 <doi:10.1016/j.sigpro.2005.01.012>).\n    This method rely on dynamic programming for efficient segmentation.\n    The segmentation/clustering method alternates steps of dynamic programming with an Expectation-Maximization algorithm.\n    This is an extension of Picard et al (2007) <doi:10.1111/j.1541-0420.2006.00729.x> method \n    (formerly available in 'cghseg' package) to the bivariate case.\n    The method is fully described in Patin et al (2018) <doi:10.1101/444794>.  "
  },
  {
    "id": 20395,
    "package_name": "sendmailR",
    "title": "Send Email Using R",
    "description": "Package contains a simple SMTP client with minimal dependencies which \n        provides a portable solution for sending email, including file attachments and inline html reports, \n        from within R. SMTP Authentication and SSL/STARTTLS is implemented using curl.",
    "version": "1.4-0",
    "maintainer": "Olaf Mersmann <olafm@p-value.net>",
    "author": "Olaf Mersmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7720-4939>),\n  Quinn Weber [ctb],\n  Marius Barth [ctb] (ORCID: <https://orcid.org/0000-0002-3421-6665>),\n  Are Edvardsen [ctb] (ORCID: <https://orcid.org/0000-0002-5210-3656>),\n  Alexander Bartel [ctb] (ORCID: <https://orcid.org/0000-0002-1280-6138>)",
    "url": "https://github.com/olafmersmann/sendmailR",
    "bug_reports": "https://github.com/olafmersmann/sendmailR/issues",
    "repository": "https://cran.r-project.org/package=sendmailR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sendmailR Send Email Using R Package contains a simple SMTP client with minimal dependencies which \n        provides a portable solution for sending email, including file attachments and inline html reports, \n        from within R. SMTP Authentication and SSL/STARTTLS is implemented using curl.  "
  },
  {
    "id": 20480,
    "package_name": "sft",
    "title": "Functions for Systems Factorial Technology Analysis of Data",
    "description": "A series of tools for analyzing Systems Factorial Technology data.  This includes functions for plotting and statistically testing capacity coefficient functions and survivor interaction contrast functions.  Houpt, Blaha, McIntire, Havig, and Townsend (2013) <doi:10.3758/s13428-013-0377-3> provide a basic introduction to Systems Factorial Technology along with examples using the sft R package.",
    "version": "2.4",
    "maintainer": "Joe Houpt <joseph.houpt@utsa.edu>",
    "author": "Joe Houpt [aut, cre] (ORCID: <https://orcid.org/0000-0002-2784-5535>),\n  Leslie Blaha [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sft",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sft Functions for Systems Factorial Technology Analysis of Data A series of tools for analyzing Systems Factorial Technology data.  This includes functions for plotting and statistically testing capacity coefficient functions and survivor interaction contrast functions.  Houpt, Blaha, McIntire, Havig, and Townsend (2013) <doi:10.3758/s13428-013-0377-3> provide a basic introduction to Systems Factorial Technology along with examples using the sft R package.  "
  },
  {
    "id": 20515,
    "package_name": "shapley",
    "title": "Weighted Mean SHAP and CI for Robust Feature Assessment in ML\nGrid",
    "description": "This R package introduces Weighted Mean SHapley Additive exPlanations (WMSHAP), an innovative method for calculating SHAP values for a grid of fine-tuned base-learner machine learning models as well as stacked ensembles, a method not previously available due to the common reliance on single best-performing models. By integrating the weighted mean SHAP values from individual base-learners comprising the ensemble or individual base-learners in a tuning grid search, the package weights SHAP contributions according to each model's performance, assessed by multiple either R squared (for both regression and classification models). alternatively, this software also offers weighting SHAP values based on the area under the precision-recall curve (AUCPR), the area under the curve (AUC), and F2 measures for binary classifiers. It further extends this framework to implement weighted confidence intervals for weighted mean SHAP values, offering a more comprehensive and robust feature importance evaluation over a grid of machine learning models, instead of solely computing SHAP values for the best model. This methodology is particularly beneficial for addressing the severe class imbalance (class rarity) problem by providing a transparent, generalized measure of feature importance that mitigates the risk of reporting SHAP values for an overfitted or biased model and maintains robustness under severe class imbalance, where there is no universal criteria of identifying the absolute best model. Furthermore, the package implements hypothesis testing to ascertain the statistical significance of SHAP values for individual features, as well as comparative significance testing of SHAP contributions between features. Additionally, it tackles a critical gap in feature selection literature by presenting criteria for the automatic feature selection of the most important features across a grid of models or stacked ensembles, eliminating the need for arbitrary determination of the number of top features to be extracted. This utility is invaluable for researchers analyzing feature significance, particularly within severely imbalanced outcomes where conventional methods fall short. Moreover, it is also expected to report democratic feature importance across a grid of models, resulting in a more comprehensive and generalizable feature selection. The package further implements a novel method for visualizing SHAP values both at subject level and feature level as well as a plot for feature selection based on the weighted mean SHAP ratios.",
    "version": "0.5.1",
    "maintainer": "E. F. Haghish <haghish@hotmail.com>",
    "author": "E. F. Haghish [aut, cre, cph]",
    "url": "https://github.com/haghish/shapley",
    "bug_reports": "https://github.com/haghish/shapley/issues",
    "repository": "https://cran.r-project.org/package=shapley",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shapley Weighted Mean SHAP and CI for Robust Feature Assessment in ML\nGrid This R package introduces Weighted Mean SHapley Additive exPlanations (WMSHAP), an innovative method for calculating SHAP values for a grid of fine-tuned base-learner machine learning models as well as stacked ensembles, a method not previously available due to the common reliance on single best-performing models. By integrating the weighted mean SHAP values from individual base-learners comprising the ensemble or individual base-learners in a tuning grid search, the package weights SHAP contributions according to each model's performance, assessed by multiple either R squared (for both regression and classification models). alternatively, this software also offers weighting SHAP values based on the area under the precision-recall curve (AUCPR), the area under the curve (AUC), and F2 measures for binary classifiers. It further extends this framework to implement weighted confidence intervals for weighted mean SHAP values, offering a more comprehensive and robust feature importance evaluation over a grid of machine learning models, instead of solely computing SHAP values for the best model. This methodology is particularly beneficial for addressing the severe class imbalance (class rarity) problem by providing a transparent, generalized measure of feature importance that mitigates the risk of reporting SHAP values for an overfitted or biased model and maintains robustness under severe class imbalance, where there is no universal criteria of identifying the absolute best model. Furthermore, the package implements hypothesis testing to ascertain the statistical significance of SHAP values for individual features, as well as comparative significance testing of SHAP contributions between features. Additionally, it tackles a critical gap in feature selection literature by presenting criteria for the automatic feature selection of the most important features across a grid of models or stacked ensembles, eliminating the need for arbitrary determination of the number of top features to be extracted. This utility is invaluable for researchers analyzing feature significance, particularly within severely imbalanced outcomes where conventional methods fall short. Moreover, it is also expected to report democratic feature importance across a grid of models, resulting in a more comprehensive and generalizable feature selection. The package further implements a novel method for visualizing SHAP values both at subject level and feature level as well as a plot for feature selection based on the weighted mean SHAP ratios.  "
  },
  {
    "id": 20516,
    "package_name": "shapper",
    "title": "Wrapper of Python Library 'shap'",
    "description": "Provides SHAP explanations of machine learning models. In applied machine learning, there is a strong belief that we need to strike a balance between interpretability and accuracy. However, in field of the Interpretable Machine Learning, there are more and more new ideas for explaining black-box models. One of the best known method for local explanations is SHapley Additive exPlanations (SHAP) introduced by Lundberg, S., et al., (2016) <arXiv:1705.07874> The SHAP method is used to calculate influences of variables on the particular observation. This method is based on Shapley values, a technique used in game theory. The R package 'shapper' is a port of the Python library 'shap'. ",
    "version": "0.1.3",
    "maintainer": "Szymon Maksymiuk <sz.maksymiuk@gmail.com>",
    "author": "Szymon Maksymiuk [aut, cre],\n  Alicja Gosiewska [aut],\n  Przemyslaw Biecek [aut],\n  Mateusz Staniak [ctb],\n  Michal Burdukiewicz [ctb]",
    "url": "https://github.com/ModelOriented/shapper",
    "bug_reports": "https://github.com/ModelOriented/shapper/issues",
    "repository": "https://cran.r-project.org/package=shapper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shapper Wrapper of Python Library 'shap' Provides SHAP explanations of machine learning models. In applied machine learning, there is a strong belief that we need to strike a balance between interpretability and accuracy. However, in field of the Interpretable Machine Learning, there are more and more new ideas for explaining black-box models. One of the best known method for local explanations is SHapley Additive exPlanations (SHAP) introduced by Lundberg, S., et al., (2016) <arXiv:1705.07874> The SHAP method is used to calculate influences of variables on the particular observation. This method is based on Shapley values, a technique used in game theory. The R package 'shapper' is a port of the Python library 'shap'.   "
  },
  {
    "id": 20517,
    "package_name": "shapviz",
    "title": "SHAP Visualizations",
    "description": "Visualizations for SHAP (SHapley Additive exPlanations), such\n    as waterfall plots, force plots, various types of importance plots,\n    dependence plots, and interaction plots.  These plots act on a\n    'shapviz' object created from a matrix of SHAP values and a\n    corresponding feature dataset. Wrappers for the R packages 'xgboost',\n    'lightgbm', 'fastshap', 'shapr', 'h2o', 'treeshap', 'DALEX', and\n    'kernelshap' are added for convenience.  By separating visualization\n    and computation, it is possible to display factor variables in graphs,\n    even if the SHAP values are calculated by a model that requires\n    numerical features. The plots are inspired by those provided by the\n    'shap' package in Python, but there is no dependency on it.",
    "version": "0.10.3",
    "maintainer": "Michael Mayer <mayermichael79@gmail.com>",
    "author": "Michael Mayer [aut, cre],\n  Adrian Stando [ctb]",
    "url": "https://github.com/ModelOriented/shapviz,\nhttps://modeloriented.github.io/shapviz/",
    "bug_reports": "https://github.com/ModelOriented/shapviz/issues",
    "repository": "https://cran.r-project.org/package=shapviz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shapviz SHAP Visualizations Visualizations for SHAP (SHapley Additive exPlanations), such\n    as waterfall plots, force plots, various types of importance plots,\n    dependence plots, and interaction plots.  These plots act on a\n    'shapviz' object created from a matrix of SHAP values and a\n    corresponding feature dataset. Wrappers for the R packages 'xgboost',\n    'lightgbm', 'fastshap', 'shapr', 'h2o', 'treeshap', 'DALEX', and\n    'kernelshap' are added for convenience.  By separating visualization\n    and computation, it is possible to display factor variables in graphs,\n    even if the SHAP values are calculated by a model that requires\n    numerical features. The plots are inspired by those provided by the\n    'shap' package in Python, but there is no dependency on it.  "
  },
  {
    "id": 20558,
    "package_name": "shinyCyJS",
    "title": "Create Interactive Network Visualizations in R and 'shiny'",
    "description": "Create Interactive Graph (Network) Visualizations. \n  'shinyCyJS' can be used in 'Shiny' apps or viewed from 'Rstudio' Viewer.\n  'shinyCyJS' includes API to build Graph model like node or edge with customized attributes for R. \n  'shinyCyJS' is built with 'cytoscape.js' and 'htmlwidgets' R package.",
    "version": "1.0.0",
    "maintainer": "Jinhwan Kim <hwanistic@gmail.com>",
    "author": "Jinhwan Kim [aut, cre, cph]",
    "url": "https://github.com/jhk0530/shinyCyJS",
    "bug_reports": "https://github.com/jhk0530/shinyCyJS/issues",
    "repository": "https://cran.r-project.org/package=shinyCyJS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shinyCyJS Create Interactive Network Visualizations in R and 'shiny' Create Interactive Graph (Network) Visualizations. \n  'shinyCyJS' can be used in 'Shiny' apps or viewed from 'Rstudio' Viewer.\n  'shinyCyJS' includes API to build Graph model like node or edge with customized attributes for R. \n  'shinyCyJS' is built with 'cytoscape.js' and 'htmlwidgets' R package.  "
  },
  {
    "id": 20592,
    "package_name": "shinySbm",
    "title": "'shiny' Application to Use the Stochastic Block Model",
    "description": "A 'shiny' interface for a simpler use of the 'sbm' R package. \n    It also contains useful functions to easily explore the 'sbm' package results. \n    With this package you should be able to use the stochastic block model \n    without any knowledge in R, get automatic reports and nice visuals, as \n    well as learning the basic functions of 'sbm'.",
    "version": "0.1.5",
    "maintainer": "Theodore Vanrenterghem <shiny.sbm.dev@gmail.com>",
    "author": "Theodore Vanrenterghem [cre, aut],\n  Julie Aubert [aut] (ORCID: <https://orcid.org/0000-0001-5203-5748>),\n  Saint-Clair Chabert-Liddell [aut] (ORCID:\n    <https://orcid.org/0000-0001-5604-7308>),\n  gro\u00dfBM team [ctb],\n  Golem User [cph]",
    "url": "",
    "bug_reports": "https://github.com/Jo-Theo/shinySbm/issues",
    "repository": "https://cran.r-project.org/package=shinySbm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shinySbm 'shiny' Application to Use the Stochastic Block Model A 'shiny' interface for a simpler use of the 'sbm' R package. \n    It also contains useful functions to easily explore the 'sbm' package results. \n    With this package you should be able to use the stochastic block model \n    without any knowledge in R, get automatic reports and nice visuals, as \n    well as learning the basic functions of 'sbm'.  "
  },
  {
    "id": 20609,
    "package_name": "shinychat",
    "title": "Chat UI Component for 'shiny'",
    "description": "Provides a scrolling chat interface with multiline input,\n    suitable for creating chatbot apps based on Large Language Models\n    (LLMs). Designed to work particularly well with the 'ellmer' R package\n    for calling LLMs.",
    "version": "0.3.0",
    "maintainer": "Garrick Aden-Buie <garrick@adenbuie.com>",
    "author": "Joe Cheng [aut],\n  Carson Sievert [aut],\n  Garrick Aden-Buie [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7111-0077>),\n  Barret Schloerke [aut] (ORCID: <https://orcid.org/0000-0001-9986-114X>),\n  Posit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://posit-dev.github.io/shinychat/r/,\nhttps://github.com/posit-dev/shinychat",
    "bug_reports": "https://github.com/posit-dev/shinychat/issues",
    "repository": "https://cran.r-project.org/package=shinychat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shinychat Chat UI Component for 'shiny' Provides a scrolling chat interface with multiline input,\n    suitable for creating chatbot apps based on Large Language Models\n    (LLMs). Designed to work particularly well with the 'ellmer' R package\n    for calling LLMs.  "
  },
  {
    "id": 20790,
    "package_name": "sinew",
    "title": "Package Development Documentation and Namespace Management",
    "description": "Manage package documentation and namespaces from the command line. \n             Programmatically attach namespaces in R and Rmd script, populates \n             'Roxygen2' skeletons with information scraped from within functions and \n             populate the Imports field of the DESCRIPTION file.",
    "version": "0.4.0",
    "maintainer": "Jonathan Sidi <yonicd@gmail.com>",
    "author": "Jonathan Sidi [aut, cre],\n  Anton Grishin [ctb],\n  Lorenzo Busetto [ctb],\n  Alexey Shiklomanov [ctb],\n  Stephen Holsenbeck [ctb]",
    "url": "https://github.com/yonicd/sinew",
    "bug_reports": "https://github.com/yonicd/sinew/issues",
    "repository": "https://cran.r-project.org/package=sinew",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sinew Package Development Documentation and Namespace Management Manage package documentation and namespaces from the command line. \n             Programmatically attach namespaces in R and Rmd script, populates \n             'Roxygen2' skeletons with information scraped from within functions and \n             populate the Imports field of the DESCRIPTION file.  "
  },
  {
    "id": 20797,
    "package_name": "siqr",
    "title": "An R Package for Single-Index Quantile Regression",
    "description": "Single-Index Quantile Regression is effective in some scenarios. We provides functions that allow users to fit Single-Index Quantile Regression model. It also provides functions to do prediction, estimate standard errors of the single-index coefficients via bootstrap, and visualize the estimated univariate function. Please see W., Y., Y. (2010) <doi:10.1016/j.jmva.2010.02.003> for details.",
    "version": "0.8.1",
    "maintainer": "Tianhai Zu <zuti@mail.uc.edu>",
    "author": "Tianhai Zu [cre],\n  Yan Yu [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=siqr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "siqr An R Package for Single-Index Quantile Regression Single-Index Quantile Regression is effective in some scenarios. We provides functions that allow users to fit Single-Index Quantile Regression model. It also provides functions to do prediction, estimate standard errors of the single-index coefficients via bootstrap, and visualize the estimated univariate function. Please see W., Y., Y. (2010) <doi:10.1016/j.jmva.2010.02.003> for details.  "
  },
  {
    "id": 20799,
    "package_name": "sirt",
    "title": "Supplementary Item Response Theory Models",
    "description": "\n    Supplementary functions for item response models aiming\n    to complement existing R packages. The functionality includes among others\n    multidimensional compensatory and noncompensatory IRT models\n    (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>), \n    MCMC for hierarchical IRT models and testlet models\n    (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>), \n    NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>), \n    Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;\n    Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),\n    faceted and hierarchical rater models (DeCarlo, Kim & Johnson, 2011,\n    <doi:10.1111/j.1745-3984.2011.00143.x>),\n    ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>), \n    DETECT statistic (Stout, Habing, Douglas & Kim, 1996, \n    <doi:10.1177/014662169602000403>), local structural equation modeling \n    (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,\n    <doi:10.1080/00273171.2016.1142856>).",
    "version": "4.2-133",
    "maintainer": "Alexander Robitzsch <robitzsch@ipn.uni-kiel.de>",
    "author": "Alexander Robitzsch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8226-3132>)",
    "url": "https://github.com/alexanderrobitzsch/sirt,\nhttps://sites.google.com/view/alexander-robitzsch/software",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sirt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sirt Supplementary Item Response Theory Models \n    Supplementary functions for item response models aiming\n    to complement existing R packages. The functionality includes among others\n    multidimensional compensatory and noncompensatory IRT models\n    (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>), \n    MCMC for hierarchical IRT models and testlet models\n    (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>), \n    NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>), \n    Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;\n    Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),\n    faceted and hierarchical rater models (DeCarlo, Kim & Johnson, 2011,\n    <doi:10.1111/j.1745-3984.2011.00143.x>),\n    ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>), \n    DETECT statistic (Stout, Habing, Douglas & Kim, 1996, \n    <doi:10.1177/014662169602000403>), local structural equation modeling \n    (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,\n    <doi:10.1080/00273171.2016.1142856>).  "
  },
  {
    "id": 20800,
    "package_name": "sirus",
    "title": "Stable and Interpretable RUle Set",
    "description": "A regression and classification algorithm based on random forests, which takes the form of a short list of rules. SIRUS combines the simplicity of decision trees with a predictivity close to random forests. The core aggregation principle of random forests is kept, but instead of aggregating predictions, SIRUS aggregates the forest structure: the most frequent nodes of the forest are selected to form a stable rule ensemble model. The algorithm is fully described in the following articles: Benard C., Biau G., da Veiga S., Scornet E. (2021), Electron. J. Statist., 15:427-505 <DOI:10.1214/20-EJS1792> for classification, and Benard C., Biau G., da Veiga S., Scornet E. (2021), AISTATS, PMLR 130:937-945 <http://proceedings.mlr.press/v130/benard21a>, for regression. This R package is a fork from the project ranger (<https://github.com/imbs-hl/ranger>). ",
    "version": "0.3.3",
    "maintainer": "Clement Benard <clement.benard5@gmail.com>",
    "author": "Clement Benard [aut, cre], Marvin N. Wright [ctb, cph]",
    "url": "https://gitlab.com/drti/sirus",
    "bug_reports": "https://gitlab.com/drti/sirus/-/issues",
    "repository": "https://cran.r-project.org/package=sirus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sirus Stable and Interpretable RUle Set A regression and classification algorithm based on random forests, which takes the form of a short list of rules. SIRUS combines the simplicity of decision trees with a predictivity close to random forests. The core aggregation principle of random forests is kept, but instead of aggregating predictions, SIRUS aggregates the forest structure: the most frequent nodes of the forest are selected to form a stable rule ensemble model. The algorithm is fully described in the following articles: Benard C., Biau G., da Veiga S., Scornet E. (2021), Electron. J. Statist., 15:427-505 <DOI:10.1214/20-EJS1792> for classification, and Benard C., Biau G., da Veiga S., Scornet E. (2021), AISTATS, PMLR 130:937-945 <http://proceedings.mlr.press/v130/benard21a>, for regression. This R package is a fork from the project ranger (<https://github.com/imbs-hl/ranger>).   "
  },
  {
    "id": 20808,
    "package_name": "sitepickR",
    "title": "Two-Level Sample Selection with Optimal Site Replacement",
    "description": "Carries out a two-level sample selection where the possibility of an initially selected site not wanting to participate is anticipated, and the site is optimally replaced. The procedure aims to reduce bias (and/or loss of external validity) with respect to the target population. In selecting units and sub-units, 'sitepickR' uses the cube method developed by 'Deville & Till\u00e9', (2004) <http://www.math.helsinki.fi/msm/banocoss/Deville_Tille_2004.pdf> and described in Till\u00e9 (2011) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2011002/article/11609-eng.pdf?st=5-sx8Q8n>. The cube method is a probability sampling method that is designed to satisfy criteria for balance between the sample and the population. Recent research has shown that this method performs well in simulations for studies of educational programs (see Fay & Olsen (2021, under review). To implement the cube method, 'sitepickR' uses the sampling R package <https://cran.r-project.org/package=sampling>. To implement statistical matching, 'sitepickR' uses the 'MatchIt' R package <https://cran.r-project.org/package=MatchIt>.",
    "version": "0.0.1",
    "maintainer": "Elena Badillo-Goicoechea <egoicoe1@jhu.edu>",
    "author": "Elena Badillo-Goicoechea [aut, cre],\n  Robert Olsen [aut],\n  Elizabeth Stuart [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sitepickR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sitepickR Two-Level Sample Selection with Optimal Site Replacement Carries out a two-level sample selection where the possibility of an initially selected site not wanting to participate is anticipated, and the site is optimally replaced. The procedure aims to reduce bias (and/or loss of external validity) with respect to the target population. In selecting units and sub-units, 'sitepickR' uses the cube method developed by 'Deville & Till\u00e9', (2004) <http://www.math.helsinki.fi/msm/banocoss/Deville_Tille_2004.pdf> and described in Till\u00e9 (2011) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2011002/article/11609-eng.pdf?st=5-sx8Q8n>. The cube method is a probability sampling method that is designed to satisfy criteria for balance between the sample and the population. Recent research has shown that this method performs well in simulations for studies of educational programs (see Fay & Olsen (2021, under review). To implement the cube method, 'sitepickR' uses the sampling R package <https://cran.r-project.org/package=sampling>. To implement statistical matching, 'sitepickR' uses the 'MatchIt' R package <https://cran.r-project.org/package=MatchIt>.  "
  },
  {
    "id": 20813,
    "package_name": "sitreeE",
    "title": "Sitree Extensions",
    "description": "Provides extensions for package 'sitree' for allometric variables, growth, mortality, recruitment, management, tree removal and external modifiers functions.",
    "version": "0.0-9",
    "maintainer": "Ignacio Sevillano <ignacio.sevillano@nibio.no>",
    "author": "Clara Anton Fernandez [aut] (ORCID:\n    <https://orcid.org/0000-0001-5545-3320>),\n  Ignacio Sevillano [cre] (ORCID:\n    <https://orcid.org/0000-0002-7784-643X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sitreeE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sitreeE Sitree Extensions Provides extensions for package 'sitree' for allometric variables, growth, mortality, recruitment, management, tree removal and external modifiers functions.  "
  },
  {
    "id": 20824,
    "package_name": "skater",
    "title": "Utilities for SNP-Based Kinship Analysis",
    "description": "Utilities for single nucleotide polymorphism (SNP) based kinship analysis\n    testing and evaluation. The 'skater' package contains functions for importing, parsing, \n    and analyzing pedigree data, performing relationship degree inference, benchmarking \n    relationship degree classification, and summarizing identity by descent (IBD) segment data.\n    Package functions and methods are described in Turner et al. (2021) \"skater: An R package \n    for SNP-based Kinship Analysis, Testing, and Evaluation\" <doi:10.1101/2021.07.21.453083>.",
    "version": "0.1.2",
    "maintainer": "Stephen Turner <vustephen@gmail.com>",
    "author": "Stephen Turner [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9140-9028>),\n  Matthew Scholz [aut] (ORCID: <https://orcid.org/0000-0003-3686-1227>),\n  VP Nagraj [aut] (ORCID: <https://orcid.org/0000-0003-0060-566X>),\n  Signature Science, LLC. [cph]",
    "url": "https://github.com/signaturescience/skater",
    "bug_reports": "https://github.com/signaturescience/skater/issues",
    "repository": "https://cran.r-project.org/package=skater",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "skater Utilities for SNP-Based Kinship Analysis Utilities for single nucleotide polymorphism (SNP) based kinship analysis\n    testing and evaluation. The 'skater' package contains functions for importing, parsing, \n    and analyzing pedigree data, performing relationship degree inference, benchmarking \n    relationship degree classification, and summarizing identity by descent (IBD) segment data.\n    Package functions and methods are described in Turner et al. (2021) \"skater: An R package \n    for SNP-based Kinship Analysis, Testing, and Evaluation\" <doi:10.1101/2021.07.21.453083>.  "
  },
  {
    "id": 20826,
    "package_name": "skeletor",
    "title": "An R Package Skeleton Generator",
    "description": "A tool for bootstrapping new packages with useful defaults,\n    including a test suite outline that passes checks and helpers for running\n    tests, checking test coverage, building vignettes, and more. Package\n    skeletons it creates are set up for pushing your package to\n    'GitHub' and using other hosted services for building and test automation.",
    "version": "1.0.4",
    "maintainer": "Neal Richardson <neal.p.richardson@gmail.com>",
    "author": "Neal Richardson [aut, cre]",
    "url": "https://github.com/nealrichardson/skeletor",
    "bug_reports": "https://github.com/nealrichardson/skeletor/issues",
    "repository": "https://cran.r-project.org/package=skeletor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "skeletor An R Package Skeleton Generator A tool for bootstrapping new packages with useful defaults,\n    including a test suite outline that passes checks and helpers for running\n    tests, checking test coverage, building vignettes, and more. Package\n    skeletons it creates are set up for pushing your package to\n    'GitHub' and using other hosted services for building and test automation.  "
  },
  {
    "id": 20829,
    "package_name": "sketcher",
    "title": "Pencil Sketch Effect",
    "description": "An implementation of image processing effects that convert a photo into a line drawing image. \n    For details, please refer to Tsuda, H. (2020). sketcher: An R package for converting a photo into a sketch style image. \n    <doi:10.31234/osf.io/svmw5>.",
    "version": "0.1.3",
    "maintainer": "Hiroyuki Tsuda <tsuda16k@gmail.com>",
    "author": "Hiroyuki Tsuda [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9396-5327>)",
    "url": "https://htsuda.net/sketcher/",
    "bug_reports": "https://github.com/tsuda16k/sketcher/issues/",
    "repository": "https://cran.r-project.org/package=sketcher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sketcher Pencil Sketch Effect An implementation of image processing effects that convert a photo into a line drawing image. \n    For details, please refer to Tsuda, H. (2020). sketcher: An R package for converting a photo into a sketch style image. \n    <doi:10.31234/osf.io/svmw5>.  "
  },
  {
    "id": 20841,
    "package_name": "skpr",
    "title": "Design of Experiments Suite: Generate and Evaluate Optimal\nDesigns",
    "description": "Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of blocked and split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible. For details, see Morgan-Wall et al. (2021) <doi:10.18637/jss.v099.i01>.",
    "version": "1.9.2",
    "maintainer": "Tyler Morgan-Wall <tylermw@gmail.com>",
    "author": "Tyler Morgan-Wall [aut, cre],\n  George Khoury [aut]",
    "url": "https://github.com/tylermorganwall/skpr,\nhttps://tylermorganwall.github.io/skpr/",
    "bug_reports": "https://github.com/tylermorganwall/skpr/issues",
    "repository": "https://cran.r-project.org/package=skpr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "skpr Design of Experiments Suite: Generate and Evaluate Optimal\nDesigns Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of blocked and split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible. For details, see Morgan-Wall et al. (2021) <doi:10.18637/jss.v099.i01>.  "
  },
  {
    "id": 20857,
    "package_name": "slendr",
    "title": "A Simulation Framework for Spatiotemporal Population Genetics",
    "description": "A framework for simulating spatially explicit genomic data which\n    leverages real cartographic information for programmatic and visual encoding\n    of spatiotemporal population dynamics on real geographic landscapes. Population\n    genetic models are then automatically executed by the 'SLiM' software by Haller\n    et al. (2019) <doi:10.1093/molbev/msy228> behind the scenes, using a custom\n    built-in simulation 'SLiM' script. Additionally, fully abstract spatial models\n    not tied to a specific geographic location are supported, and users can also\n    simulate data from standard, non-spatial, random-mating models. These can be\n    simulated either with the 'SLiM' built-in back-end script, or using an efficient\n    coalescent population genetics simulator 'msprime' by Baumdicker et al. (2022)\n    <doi:10.1093/genetics/iyab229> with a custom-built 'Python' script bundled with the\n    R package. Simulated genomic data is saved in a tree-sequence format and can be\n    loaded, manipulated, and summarised using tree-sequence functionality via an R\n    interface to the 'Python' module 'tskit' by Kelleher et al. (2019)\n    <doi:10.1038/s41588-019-0483-y>. Complete model configuration, simulation and\n    analysis pipelines can be therefore constructed without a need to leave the R\n    environment, eliminating friction between disparate tools for population genetic\n    simulations and data analysis.",
    "version": "1.3.0",
    "maintainer": "Martin Petr <contact@bodkan.net>",
    "author": "Martin Petr [aut, cre] (ORCID: <https://orcid.org/0000-0003-4879-8421>)",
    "url": "https://github.com/bodkan/slendr",
    "bug_reports": "https://github.com/bodkan/slendr/issues",
    "repository": "https://cran.r-project.org/package=slendr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "slendr A Simulation Framework for Spatiotemporal Population Genetics A framework for simulating spatially explicit genomic data which\n    leverages real cartographic information for programmatic and visual encoding\n    of spatiotemporal population dynamics on real geographic landscapes. Population\n    genetic models are then automatically executed by the 'SLiM' software by Haller\n    et al. (2019) <doi:10.1093/molbev/msy228> behind the scenes, using a custom\n    built-in simulation 'SLiM' script. Additionally, fully abstract spatial models\n    not tied to a specific geographic location are supported, and users can also\n    simulate data from standard, non-spatial, random-mating models. These can be\n    simulated either with the 'SLiM' built-in back-end script, or using an efficient\n    coalescent population genetics simulator 'msprime' by Baumdicker et al. (2022)\n    <doi:10.1093/genetics/iyab229> with a custom-built 'Python' script bundled with the\n    R package. Simulated genomic data is saved in a tree-sequence format and can be\n    loaded, manipulated, and summarised using tree-sequence functionality via an R\n    interface to the 'Python' module 'tskit' by Kelleher et al. (2019)\n    <doi:10.1038/s41588-019-0483-y>. Complete model configuration, simulation and\n    analysis pipelines can be therefore constructed without a need to leave the R\n    environment, eliminating friction between disparate tools for population genetic\n    simulations and data analysis.  "
  },
  {
    "id": 20863,
    "package_name": "slm",
    "title": "Stationary Linear Models",
    "description": "Provides statistical procedures for linear regression in the general context where the errors are assumed to be correlated. Different ways to estimate the asymptotic covariance matrix of the least squares estimators are available. Starting from this estimation of the covariance matrix, the confidence intervals and the usual tests on the parameters are modified. The functions of this package are very similar to those of 'lm': it contains methods such as summary(), plot(), confint() and predict(). The 'slm' package is described in the paper by E. Caron, J. Dedecker and B. Michel (2019), \"Linear regression with stationary errors: the R package slm\", arXiv preprint <arXiv:1906.06583>.",
    "version": "1.2.0",
    "maintainer": "Emmanuel Caron <emmanuelcaron3@gmail.com>",
    "author": "Emmanuel Caron, J\u00e9r\u00f4me Dedecker, Bertrand Michel",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=slm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "slm Stationary Linear Models Provides statistical procedures for linear regression in the general context where the errors are assumed to be correlated. Different ways to estimate the asymptotic covariance matrix of the least squares estimators are available. Starting from this estimation of the covariance matrix, the confidence intervals and the usual tests on the parameters are modified. The functions of this package are very similar to those of 'lm': it contains methods such as summary(), plot(), confint() and predict(). The 'slm' package is described in the paper by E. Caron, J. Dedecker and B. Michel (2019), \"Linear regression with stationary errors: the R package slm\", arXiv preprint <arXiv:1906.06583>.  "
  },
  {
    "id": 20869,
    "package_name": "slurmR",
    "title": "A Lightweight Wrapper for 'Slurm'",
    "description": "'Slurm', Simple Linux Utility for Resource Management\n          <https://slurm.schedmd.com/>, is a popular 'Linux' based software used to \n          schedule jobs in 'HPC' (High Performance Computing) clusters. This R package\n          provides a specialized lightweight wrapper of 'Slurm' with a syntax similar to\n          that found in the 'parallel' R package. The package also includes a method for\n          creating socket cluster objects spanning multiple nodes that can be used with\n          the 'parallel' package.",
    "version": "0.5-4",
    "maintainer": "George Vega Yon <g.vegayon@gmail.com>",
    "author": "George Vega Yon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3171-0844>),\n  Paul Marjoram [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0003-0824-7449>),\n  National Cancer Institute (NCI) [fnd] (Grant Number 5P01CA196569-02),\n  Michael Schubert [rev] (what: JOSS reviewer, ORCID:\n    <https://orcid.org/0000-0002-6862-5221>),\n  Michel Lang [rev] (what: JOSS reviewer, ORCID:\n    <https://orcid.org/0000-0001-9754-0393>)",
    "url": "https://github.com/USCbiostats/slurmR, https://slurm.schedmd.com/",
    "bug_reports": "https://github.com/USCbiostats/slurmR/issues",
    "repository": "https://cran.r-project.org/package=slurmR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "slurmR A Lightweight Wrapper for 'Slurm' 'Slurm', Simple Linux Utility for Resource Management\n          <https://slurm.schedmd.com/>, is a popular 'Linux' based software used to \n          schedule jobs in 'HPC' (High Performance Computing) clusters. This R package\n          provides a specialized lightweight wrapper of 'Slurm' with a syntax similar to\n          that found in the 'parallel' R package. The package also includes a method for\n          creating socket cluster objects spanning multiple nodes that can be used with\n          the 'parallel' package.  "
  },
  {
    "id": 20880,
    "package_name": "smartmap",
    "title": "Smartly Create Maps from R Objects",
    "description": "Preview spatial data as 'leaflet' maps with minimal\n  effort. smartmap is optimized for interactive use and distinguishes itself \n  from similar packages because it does not need real spatial ('sp' or 'sf')\n  objects an input; instead, it tries to automatically coerce everything that \n  looks like spatial data to sf objects or leaflet maps. It - for example -  \n  supports direct mapping of: a vector containing a single coordinate pair,\n  a two column matrix, a data.frame with longitude and latitude columns, or\n  the path or URL to a (possibly compressed) 'shapefile'.",
    "version": "0.1.1",
    "maintainer": "Stefan Fleck <stefan.b.fleck@gmail.com>",
    "author": "Stefan Fleck [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3344-9851>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=smartmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smartmap Smartly Create Maps from R Objects Preview spatial data as 'leaflet' maps with minimal\n  effort. smartmap is optimized for interactive use and distinguishes itself \n  from similar packages because it does not need real spatial ('sp' or 'sf')\n  objects an input; instead, it tries to automatically coerce everything that \n  looks like spatial data to sf objects or leaflet maps. It - for example -  \n  supports direct mapping of: a vector containing a single coordinate pair,\n  a two column matrix, a data.frame with longitude and latitude columns, or\n  the path or URL to a (possibly compressed) 'shapefile'.  "
  },
  {
    "id": 20890,
    "package_name": "smdi",
    "title": "Perform Structural Missing Data Investigations",
    "description": "An easy to use implementation of routine structural missing data diagnostics with functions to visualize the proportions of missing observations, investigate missing data patterns and conduct various empirical missing data diagnostic tests. Reference: Weberpals J, Raman SR, Shaw PA, Lee H, Hammill BG, Toh S, Connolly JG, Dandreo KJ, Tian F, Liu W, Li J, Hern\u00e1ndez-Mu\u00f1oz JJ, Glynn RJ, Desai RJ. smdi: an R package to perform structural missing data investigations on partially observed confounders in real-world evidence studies. JAMIA Open. 2024 Jan 31;7(1):ooae008. <doi:10.1093/jamiaopen/ooae008>.",
    "version": "0.3.1",
    "maintainer": "Janick Weberpals <janick.developer@gmail.com>",
    "author": "Janick Weberpals [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0404-7394>)",
    "url": "https://janickweberpals.gitlab-pages.partners.org/smdi/",
    "bug_reports": "https://gitlab-scm.partners.org/janickweberpals/smdi/-/issues",
    "repository": "https://cran.r-project.org/package=smdi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smdi Perform Structural Missing Data Investigations An easy to use implementation of routine structural missing data diagnostics with functions to visualize the proportions of missing observations, investigate missing data patterns and conduct various empirical missing data diagnostic tests. Reference: Weberpals J, Raman SR, Shaw PA, Lee H, Hammill BG, Toh S, Connolly JG, Dandreo KJ, Tian F, Liu W, Li J, Hern\u00e1ndez-Mu\u00f1oz JJ, Glynn RJ, Desai RJ. smdi: an R package to perform structural missing data investigations on partially observed confounders in real-world evidence studies. JAMIA Open. 2024 Jan 31;7(1):ooae008. <doi:10.1093/jamiaopen/ooae008>.  "
  },
  {
    "id": 20981,
    "package_name": "soiltestcorr",
    "title": "Soil Test Correlation and Calibration",
    "description": "A compilation of functions designed to assist users on the correlation analysis of crop yield and soil test values. Functions to estimate crop response patterns to soil nutrient availability and critical soil test values using various approaches such as: 1) the modified arcsine-log calibration curve (Correndo et al. (2017) <doi:10.1071/CP16444>); 2) the graphical Cate-Nelson quadrants analysis (Cate & Nelson (1965)), 3) the statistical Cate-Nelson quadrants analysis (Cate & Nelson (1971) <doi:10.2136/sssaj1971.03615995003500040048x>), 4) the linear-plateau regression (Anderson & Nelson (1975) <doi:10.2307/2529422>), 5) the quadratic-plateau regression (Bullock & Bullock (1994) <doi:10.2134/agronj1994.00021962008600010033x>), and 6) the Mitscherlich-type exponential regression (Melsted & Peck (1977) <doi:10.2134/asaspecpub29.c1>). The package development stemmed from ongoing work with the Fertilizer Recommendation Support Tool (FRST) and Feed the Future Innovation Lab for Collaborative Research on Sustainable Intensification (SIIL) projects. ",
    "version": "2.2.1",
    "maintainer": "Adrian A. Correndo <acorrend@uoguelph.ca>",
    "author": "Adrian A. Correndo [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4172-289X>),\n  Austin Pearce [aut] (ORCID: <https://orcid.org/0000-0002-2541-896X>),\n  Fernando Miguez [ctb] (ORCID: <https://orcid.org/0000-0002-4627-8329>),\n  Deanna Osmond [aut] (ORCID: <https://orcid.org/0000-0002-6336-8318>),\n  Ignacio A. Ciampitti [aut] (ORCID:\n    <https://orcid.org/0000-0001-9619-5129>)",
    "url": "https://adriancorrendo.github.io/soiltestcorr/,\nhttps://soiltestfrst.org/,\nhttps://www.siildigitalagconsortium.com/",
    "bug_reports": "https://github.com/adriancorrendo/soiltestcorr/issues",
    "repository": "https://cran.r-project.org/package=soiltestcorr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "soiltestcorr Soil Test Correlation and Calibration A compilation of functions designed to assist users on the correlation analysis of crop yield and soil test values. Functions to estimate crop response patterns to soil nutrient availability and critical soil test values using various approaches such as: 1) the modified arcsine-log calibration curve (Correndo et al. (2017) <doi:10.1071/CP16444>); 2) the graphical Cate-Nelson quadrants analysis (Cate & Nelson (1965)), 3) the statistical Cate-Nelson quadrants analysis (Cate & Nelson (1971) <doi:10.2136/sssaj1971.03615995003500040048x>), 4) the linear-plateau regression (Anderson & Nelson (1975) <doi:10.2307/2529422>), 5) the quadratic-plateau regression (Bullock & Bullock (1994) <doi:10.2134/agronj1994.00021962008600010033x>), and 6) the Mitscherlich-type exponential regression (Melsted & Peck (1977) <doi:10.2134/asaspecpub29.c1>). The package development stemmed from ongoing work with the Fertilizer Recommendation Support Tool (FRST) and Feed the Future Innovation Lab for Collaborative Research on Sustainable Intensification (SIIL) projects.   "
  },
  {
    "id": 21004,
    "package_name": "soptdmaeA",
    "title": "Sequential Optimal Designs for Two-Colour cDNA Microarray\nExperiments",
    "description": "Computes sequential A-, MV-, D- and E-optimal or near-optimal block and row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The package also provides an optional method of using the graphical user interface (GUI) R package 'tcltk' to ensure that it is user friendly.",
    "version": "1.0.1",
    "maintainer": "Dibaba Bayisa Gemechu <diboobayu@gmail.com>",
    "author": "Dibaba Bayisa Gemechu [aut, cre],\n  Legesse Kassa Debusho [aut],\n  Linda Haines [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=soptdmaeA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "soptdmaeA Sequential Optimal Designs for Two-Colour cDNA Microarray\nExperiments Computes sequential A-, MV-, D- and E-optimal or near-optimal block and row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The package also provides an optional method of using the graphical user interface (GUI) R package 'tcltk' to ensure that it is user friendly.  "
  },
  {
    "id": 21009,
    "package_name": "sos",
    "title": "Search Contributed R Packages, Sort by Package",
    "description": "Search contributed R packages, sort by package.",
    "version": "2.1-8",
    "maintainer": "Spencer Graves <spencer.graves@prodsyse.com>",
    "author": "Spencer Graves [cre, aut, cph], \n    Sundar Dorai-Raj [aut], and Romain Francois [ctb]",
    "url": "https://github.com/sbgraves237/sos",
    "bug_reports": "https://github.com/sbgraves237/sos/issues",
    "repository": "https://cran.r-project.org/package=sos",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sos Search Contributed R Packages, Sort by Package Search contributed R packages, sort by package.  "
  },
  {
    "id": 21057,
    "package_name": "spam64",
    "title": "64-Bit Extension of the SPArse Matrix R Package 'spam'",
    "description": "Provides the Fortran code of the R package 'spam'\n    with 64-bit integers. Loading this package together with the R package\n    spam enables the sparse matrix class spam to handle huge sparse matrices\n    with more than 2^31-1 non-zero elements.\n    Documentation is provided in Gerber, Moesinger and Furrer (2017) <doi:10.1016/j.cageo.2016.11.015>.",
    "version": "2.10-0",
    "maintainer": "Reinhard Furrer <reinhard.furrer@math.uzh.ch>",
    "author": "Reinhard Furrer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6319-2332>),\n  Florian Gerber [aut] (ORCID: <https://orcid.org/0000-0001-8545-5263>),\n  Roman Flury [aut] (ORCID: <https://orcid.org/0000-0002-0349-8698>),\n  Daniel Gerber [ctb],\n  Kaspar Moesinger [ctb],\n  Youcef Saad [ctb] (SPARSEKIT\n    http://www-users.cs.umn.edu/~saad/software/SPARSKIT/),\n  Esmond G. Ng [ctb] (Fortran Cholesky routines),\n  Barry W. Peyton [ctb] (Fortran Cholesky routines),\n  Joseph W.H. Liu [ctb] (Fortran Cholesky routines),\n  Alan D. George [ctb] (Fortran Cholesky routines),\n  Lehoucq B. Rich [ctb] (ARPACK),\n  Maschhoff Kristi [ctb] (ARPACK),\n  Sorensen C. Danny [ctb] (ARPACK),\n  Yang Chao [ctb] (ARPACK)",
    "url": "https://git.math.uzh.ch/reinhard.furrer/spam",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spam64",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spam64 64-Bit Extension of the SPArse Matrix R Package 'spam' Provides the Fortran code of the R package 'spam'\n    with 64-bit integers. Loading this package together with the R package\n    spam enables the sparse matrix class spam to handle huge sparse matrices\n    with more than 2^31-1 non-zero elements.\n    Documentation is provided in Gerber, Moesinger and Furrer (2017) <doi:10.1016/j.cageo.2016.11.015>.  "
  },
  {
    "id": 21063,
    "package_name": "spark.sas7bdat",
    "title": "Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark'",
    "description": "Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark' from R. 'Apache Spark' is an open source cluster computing framework available at <http://spark.apache.org>. This R package uses the 'spark-sas7bdat' 'Spark' package (<https://spark-packages.org/package/saurfang/spark-sas7bdat>) to import and process 'SAS' data in parallel using 'Spark'. Hereby allowing to execute 'dplyr' statements in parallel on top of 'SAS' data.",
    "version": "1.4",
    "maintainer": "Jan Wijffels <jwijffels@bnosac.be>",
    "author": "Jan Wijffels [aut, cre, cph],\n  BNOSAC [cph],\n  Geyer Bisschoff [ctb]",
    "url": "https://github.com/bnosac/spark.sas7bdat",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spark.sas7bdat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spark.sas7bdat Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark' Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark' from R. 'Apache Spark' is an open source cluster computing framework available at <http://spark.apache.org>. This R package uses the 'spark-sas7bdat' 'Spark' package (<https://spark-packages.org/package/saurfang/spark-sas7bdat>) to import and process 'SAS' data in parallel using 'Spark'. Hereby allowing to execute 'dplyr' statements in parallel on top of 'SAS' data.  "
  },
  {
    "id": 21117,
    "package_name": "spatialGE",
    "title": "Visualization and Analysis of Spatial Heterogeneity in\nSpatially-Resolved Gene Expression",
    "description": "Visualization and analysis of spatially resolved transcriptomics data. The 'spatialGE'\n\tR package provides methods for visualizing and analyzing spatially resolved transcriptomics data, \n\tsuch as 10X Visium, CosMx, or csv/tsv gene expression matrices. It includes tools for spatial \n\tinterpolation, autocorrelation analysis, tissue domain detection, gene set enrichment, and \n\tdifferential expression analysis using spatial mixed models.",
    "version": "1.2.2",
    "maintainer": "Oscar Ospina <oscar.ospina@jhmi.edu>",
    "author": "Oscar Ospina [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5986-4207>),\n  Alex Soupir [aut] (ORCID: <https://orcid.org/0000-0003-1251-9179>),\n  Brooke Fridley [aut] (ORCID: <https://orcid.org/0000-0001-7739-7956>),\n  Satija Lab [cph] (Copyright holder of code fragments from Seurat\n    function FindVariableFeatures)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spatialGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spatialGE Visualization and Analysis of Spatial Heterogeneity in\nSpatially-Resolved Gene Expression Visualization and analysis of spatially resolved transcriptomics data. The 'spatialGE'\n\tR package provides methods for visualizing and analyzing spatially resolved transcriptomics data, \n\tsuch as 10X Visium, CosMx, or csv/tsv gene expression matrices. It includes tools for spatial \n\tinterpolation, autocorrelation analysis, tissue domain detection, gene set enrichment, and \n\tdifferential expression analysis using spatial mixed models.  "
  },
  {
    "id": 21176,
    "package_name": "spectrolab",
    "title": "Class and Methods for Spectral Data",
    "description": "Input/Output, processing and visualization of spectra taken with different spectrometers, including SVC (Spectra Vista), ASD and PSR (Spectral Evolution). Implements an S3 class spectra that other packages can build on. Provides methods to access, plot, manipulate, splice sensor overlap, vector normalize and smooth spectra.",
    "version": "0.0.19",
    "maintainer": "Jose Eduardo Meireles <jemeireles@gmail.com>",
    "author": "Jose Eduardo Meireles [aut, cre],\n  Anna K. Schweiger [aut],\n  Jeannine Cavender-Bares [aut]",
    "url": "https://CRAN.R-project.org/package=spectrolab",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=spectrolab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spectrolab Class and Methods for Spectral Data Input/Output, processing and visualization of spectra taken with different spectrometers, including SVC (Spectra Vista), ASD and PSR (Spectral Evolution). Implements an S3 class spectra that other packages can build on. Provides methods to access, plot, manipulate, splice sensor overlap, vector normalize and smooth spectra.  "
  },
  {
    "id": 21234,
    "package_name": "splmm",
    "title": "Simultaneous Penalized Linear Mixed Effects Models",
    "description": "Contains functions that fit linear mixed-effects models\n        for high-dimensional data (p>>n) with penalty for both the fixed effects and random effects for variable selection. \n        The details of the algorithm can be found in Luoying Yang PhD thesis (Yang and Wu 2020). The algorithm implementation\n        is based on the R package 'lmmlasso'. \n        Reference: Yang L, Wu TT (2020). Model-Based Clustering of Longitudinal Data in High-Dimensionality. Unpublished thesis.",
    "version": "1.2.0",
    "maintainer": "Eli Sun <eli_sun@urmc.rochester.edu>",
    "author": "Luoying Yang [aut],\n  Eli Sun [aut, cre],\n  Tong Tong Wu [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=splmm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "splmm Simultaneous Penalized Linear Mixed Effects Models Contains functions that fit linear mixed-effects models\n        for high-dimensional data (p>>n) with penalty for both the fixed effects and random effects for variable selection. \n        The details of the algorithm can be found in Luoying Yang PhD thesis (Yang and Wu 2020). The algorithm implementation\n        is based on the R package 'lmmlasso'. \n        Reference: Yang L, Wu TT (2020). Model-Based Clustering of Longitudinal Data in High-Dimensionality. Unpublished thesis.  "
  },
  {
    "id": 21237,
    "package_name": "splus2R",
    "title": "Supplemental S-PLUS Functionality in R",
    "description": "Currently there are many functions in S-PLUS that are\n  missing in R. To facilitate the conversion of S-PLUS packages to R packages,\n  this package provides some missing S-PLUS functionality in R.",
    "version": "1.3-5",
    "maintainer": "Stephen Kaluzny <spkaluzny@gmail.com>",
    "author": "William Constantine [aut],\n  Tim Hesterberg [aut],\n  Knut Wittkowski [ctb],\n  Tingting Song [ctb],\n  Bill Dunlap [ctb],\n  Stephen Kaluzny [ctb, cre]",
    "url": "https://github.com/spkaluzny/splus2r",
    "bug_reports": "https://github.com/spkaluzny/splus2r/issues",
    "repository": "https://cran.r-project.org/package=splus2R",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "splus2R Supplemental S-PLUS Functionality in R Currently there are many functions in S-PLUS that are\n  missing in R. To facilitate the conversion of S-PLUS packages to R packages,\n  this package provides some missing S-PLUS functionality in R.  "
  },
  {
    "id": 21329,
    "package_name": "ssmodels",
    "title": "Sample Selection Models",
    "description": "In order to facilitate the adjustment of the sample selection models\n  existing in the literature, we created the 'ssmodels' package. Our package\n  allows the adjustment of the classic Heckman model (Heckman (1976),\n  Heckman (1979) <doi:10.2307/1912352>), and the estimation of the parameters of\n  this model via the maximum likelihood method and two-step method, in addition\n  to the adjustment of the Heckman-t models introduced in the literature by\n  Marchenko and Genton (2012) <doi:10.1080/01621459.2012.656011> and the\n  Heckman-Skew model introduced in the literature by Ogundimu and Hutton (2016)\n  <doi:10.1111/sjos.12171>. We also implemented functions to adjust the\n  generalized version of the Heckman model, introduced by Bastos, Barreto-Souza,\n  and Genton (2021) <doi:10.5705/ss.202021.0068>, that allows the inclusion of\n  covariables to the dispersion and correlation parameters, and a function to\n  adjust the Heckman-BS model introduced by Bastos and Barreto-Souza (2020)\n  <doi:10.1080/02664763.2020.1780570> that uses the Birnbaum-Saunders\n  distribution as a joint distribution of the selection and primary regression\n  variables. This package extends and complements existing R packages such as \n  'sampleSelection' (Toomet and Henningsen, 2008) and 'ssmrob' (Zhelonkin et al., 2016), providing additional robust and flexible sample selection models.",
    "version": "2.0.1",
    "maintainer": "Fernando de Souza Bastos <fernando.bastos@ufv.br>",
    "author": "Fernando de Souza Bastos [aut, cre],\n  Wagner Barreto de Souza [aut]",
    "url": "https://fsbmat-ufv.github.io/ssmodels/",
    "bug_reports": "https://github.com/fsbmat-ufv/ssmodels/issues",
    "repository": "https://cran.r-project.org/package=ssmodels",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ssmodels Sample Selection Models In order to facilitate the adjustment of the sample selection models\n  existing in the literature, we created the 'ssmodels' package. Our package\n  allows the adjustment of the classic Heckman model (Heckman (1976),\n  Heckman (1979) <doi:10.2307/1912352>), and the estimation of the parameters of\n  this model via the maximum likelihood method and two-step method, in addition\n  to the adjustment of the Heckman-t models introduced in the literature by\n  Marchenko and Genton (2012) <doi:10.1080/01621459.2012.656011> and the\n  Heckman-Skew model introduced in the literature by Ogundimu and Hutton (2016)\n  <doi:10.1111/sjos.12171>. We also implemented functions to adjust the\n  generalized version of the Heckman model, introduced by Bastos, Barreto-Souza,\n  and Genton (2021) <doi:10.5705/ss.202021.0068>, that allows the inclusion of\n  covariables to the dispersion and correlation parameters, and a function to\n  adjust the Heckman-BS model introduced by Bastos and Barreto-Souza (2020)\n  <doi:10.1080/02664763.2020.1780570> that uses the Birnbaum-Saunders\n  distribution as a joint distribution of the selection and primary regression\n  variables. This package extends and complements existing R packages such as \n  'sampleSelection' (Toomet and Henningsen, 2008) and 'ssmrob' (Zhelonkin et al., 2016), providing additional robust and flexible sample selection models.  "
  },
  {
    "id": 21360,
    "package_name": "stacomirtools",
    "title": "Connection Class for Package stacomiR",
    "description": "S4 class wrappers for the 'ODBC' and Pool DBI connection, also provides some \n    utilities to paste small datasets to clipboard, rename columns. It is used by the package 'stacomiR' for\n    connections to the database. Development versions of 'stacomiR' are available in R-forge.",
    "version": "0.6.0.1",
    "maintainer": "Cedric Briand <cedric.briand00@gmail.com>",
    "author": "Cedric Briand [aut, cre],\n  Marion Legrand [aut],\n  Beaulaton Laurent [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stacomirtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stacomirtools Connection Class for Package stacomiR S4 class wrappers for the 'ODBC' and Pool DBI connection, also provides some \n    utilities to paste small datasets to clipboard, rename columns. It is used by the package 'stacomiR' for\n    connections to the database. Development versions of 'stacomiR' are available in R-forge.  "
  },
  {
    "id": 21370,
    "package_name": "staninside",
    "title": "Facilitating the Use of 'Stan' Within Packages",
    "description": "Infrastructure and functions that can be used for \n    integrating 'Stan' (Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>) code into \n    stand alone R packages which in turn use the  'CmdStan' engine  which is often accessed through \n    'CmdStanR'. Details given in Stan Development Team (2025) <https://mc-stan.org/cmdstanr/>. \n    Using 'CmdStanR' and pre-written 'Stan' code can make package installation easy. Using 'staninside'\n    offers a way to cache user-compiled 'Stan' models in user-specified directories reducing the need\n    to recompile the same model multiple times.",
    "version": "0.0.4",
    "maintainer": "Michael DeWitt <me.dewitt.jr@gmail.com>",
    "author": "Michael DeWitt [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8940-1967>)",
    "url": "https://github.com/medewitt/staninside,\nhttps://medewitt.github.io/staninside/",
    "bug_reports": "https://github.com/medewitt/staninside/issues",
    "repository": "https://cran.r-project.org/package=staninside",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "staninside Facilitating the Use of 'Stan' Within Packages Infrastructure and functions that can be used for \n    integrating 'Stan' (Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>) code into \n    stand alone R packages which in turn use the  'CmdStan' engine  which is often accessed through \n    'CmdStanR'. Details given in Stan Development Team (2025) <https://mc-stan.org/cmdstanr/>. \n    Using 'CmdStanR' and pre-written 'Stan' code can make package installation easy. Using 'staninside'\n    offers a way to cache user-compiled 'Stan' models in user-specified directories reducing the need\n    to recompile the same model multiple times.  "
  },
  {
    "id": 21452,
    "package_name": "stepmetrics",
    "title": "Calculate Step and Cadence Metrics from Wearable Data",
    "description": "Provides functions to calculate step- and cadence-based metrics from \n    timestamped accelerometer and wearable device data. Supports CSV and AGD files from \n    'ActiGraph' devices, CSV files from 'Fitbit' devices, and step counts derived   \n    with R package 'GGIR' <https://github.com/wadpac/GGIR>, with automatic handling \n    of epoch lengths from 1 to 60 seconds. Metrics include total steps, cadence \n    peaks, minutes and steps in predefined cadence bands, and time and steps in \n    moderate-to-vigorous physical activity (MVPA). Methods and thresholds are \n    informed by the literature, e.g., \n    Tudor-Locke and Rowe (2012) <doi:10.2165/11599170-000000000-00000>, \n    Barreira et al. (2012) <doi:10.1249/MSS.0b013e318254f2a3>, \n    and Tudor-Locke et al. (2018) <doi:10.1136/bjsports-2017-097628>. \n    The package record is also available on Zenodo (2023) <doi:10.5281/zenodo.7858094>.",
    "version": "1.0.3",
    "maintainer": "Jairo H Migueles <jairo@jhmigueles.com>",
    "author": "Jairo H Migueles [aut, cre],\n  Elroy J Aguiar [fnd] (Funding and data support),\n  University of Alabama [fnd]",
    "url": "https://github.com/jhmigueles/stepmetrics",
    "bug_reports": "https://github.com/jhmigueles/stepmetrics/issues",
    "repository": "https://cran.r-project.org/package=stepmetrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stepmetrics Calculate Step and Cadence Metrics from Wearable Data Provides functions to calculate step- and cadence-based metrics from \n    timestamped accelerometer and wearable device data. Supports CSV and AGD files from \n    'ActiGraph' devices, CSV files from 'Fitbit' devices, and step counts derived   \n    with R package 'GGIR' <https://github.com/wadpac/GGIR>, with automatic handling \n    of epoch lengths from 1 to 60 seconds. Metrics include total steps, cadence \n    peaks, minutes and steps in predefined cadence bands, and time and steps in \n    moderate-to-vigorous physical activity (MVPA). Methods and thresholds are \n    informed by the literature, e.g., \n    Tudor-Locke and Rowe (2012) <doi:10.2165/11599170-000000000-00000>, \n    Barreira et al. (2012) <doi:10.1249/MSS.0b013e318254f2a3>, \n    and Tudor-Locke et al. (2018) <doi:10.1136/bjsports-2017-097628>. \n    The package record is also available on Zenodo (2023) <doi:10.5281/zenodo.7858094>.  "
  },
  {
    "id": 21493,
    "package_name": "stopp",
    "title": "Spatio-Temporal Point Pattern Methods, Model Fitting,\nDiagnostics, Simulation, Local Tests",
    "description": "Toolbox for different kinds of spatio-temporal analyses to be performed on observed point patterns, following the growing stream of literature on point process theory. This R package implements functions to perform different kinds of analyses on point processes, proposed in the papers (Siino, Adelfio, and Mateu 2018<doi:10.1007/s00477-018-1579-0>; Siino et al. 2018<doi:10.1002/env.2463>; Adelfio et al. 2020<doi:10.1007/s00477-019-01748-1>; D\u2019Angelo, Adelfio, and Mateu 2021<doi:10.1016/j.spasta.2021.100534>; D\u2019Angelo, Adelfio, and Mateu 2022<doi:10.1007/s00362-022-01338-4>; D\u2019Angelo, Adelfio, and Mateu 2023<doi:10.1016/j.csda.2022.107679>). The main topics include modeling, statistical inference, and simulation issues on spatio-temporal point processes on Euclidean space and linear networks. Version 1.0.0 has been updated for accompanying the journal publication D Angelo and Adelfio 2025 <doi:10.18637/jss.v113.i10>.",
    "version": "1.0.0",
    "maintainer": "Nicoletta D'Angelo <nicoletta.dangelo@unipa.it>",
    "author": "Nicoletta D'Angelo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8878-5986>),\n  Giada Adelfio [aut] (ORCID: <https://orcid.org/0000-0002-3194-4296>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stopp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stopp Spatio-Temporal Point Pattern Methods, Model Fitting,\nDiagnostics, Simulation, Local Tests Toolbox for different kinds of spatio-temporal analyses to be performed on observed point patterns, following the growing stream of literature on point process theory. This R package implements functions to perform different kinds of analyses on point processes, proposed in the papers (Siino, Adelfio, and Mateu 2018<doi:10.1007/s00477-018-1579-0>; Siino et al. 2018<doi:10.1002/env.2463>; Adelfio et al. 2020<doi:10.1007/s00477-019-01748-1>; D\u2019Angelo, Adelfio, and Mateu 2021<doi:10.1016/j.spasta.2021.100534>; D\u2019Angelo, Adelfio, and Mateu 2022<doi:10.1007/s00362-022-01338-4>; D\u2019Angelo, Adelfio, and Mateu 2023<doi:10.1016/j.csda.2022.107679>). The main topics include modeling, statistical inference, and simulation issues on spatio-temporal point processes on Euclidean space and linear networks. Version 1.0.0 has been updated for accompanying the journal publication D Angelo and Adelfio 2025 <doi:10.18637/jss.v113.i10>.  "
  },
  {
    "id": 21512,
    "package_name": "strata.MaxCombo",
    "title": "Stratified Max-Combo Test",
    "description": "Non-proportional hazard (NPH) is commonly observed in immuno-oncology studies, where the survival curves of the treatment and control groups show delayed separation. To properly account for NPH, several statistical methods have been developed. One such method is Max-Combo test, which is a straightforward and flexible hypothesis testing method that can simultaneously test for constant, early, middle, and late treatment effects. However, the majority of the Max-Combo test performed in clinical studies are unstratified, ignoring the important prognostic stratification factors. To fill this gap, we have developed an R package for stratified Max-Combo testing that accounts for stratified baseline factors. Our package explores various methods for calculating combined test statistics, estimating joint distributions, and determining the p-values.",
    "version": "0.0.1",
    "maintainer": "Yuwen Liu <yuwenliu9@gmail.com>",
    "author": "Yuwen Liu [aut, cre],\n  Yumeng Wang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=strata.MaxCombo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "strata.MaxCombo Stratified Max-Combo Test Non-proportional hazard (NPH) is commonly observed in immuno-oncology studies, where the survival curves of the treatment and control groups show delayed separation. To properly account for NPH, several statistical methods have been developed. One such method is Max-Combo test, which is a straightforward and flexible hypothesis testing method that can simultaneously test for constant, early, middle, and late treatment effects. However, the majority of the Max-Combo test performed in clinical studies are unstratified, ignoring the important prognostic stratification factors. To fill this gap, we have developed an R package for stratified Max-Combo testing that accounts for stratified baseline factors. Our package explores various methods for calculating combined test statistics, estimating joint distributions, and determining the p-values.  "
  },
  {
    "id": 21544,
    "package_name": "stringstatic",
    "title": "Dependency-Free String Operations",
    "description": "Provides drop-in replacements for functions from the\n    'stringr' package, with the same user interface. These functions have\n    no external dependencies and can be copied directly into your package\n    code using the 'staticimports' package.",
    "version": "0.1.2",
    "maintainer": "Alexander Rossell Hayes <alexander@rossellhayes.com>",
    "author": "Alexander Rossell Hayes [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9412-0457>),\n  Eli Pousson [ctb] (ORCID: <https://orcid.org/0000-0001-8280-1706>,\n    str_pad() and str_split() functions),\n  Hadley Wickham [ctb, cph] (stringr package),\n  RStudio [cph] (stringr package)",
    "url": "https://github.com/rossellhayes/stringstatic",
    "bug_reports": "https://github.com/rossellhayes/stringstatic/issues",
    "repository": "https://cran.r-project.org/package=stringstatic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stringstatic Dependency-Free String Operations Provides drop-in replacements for functions from the\n    'stringr' package, with the same user interface. These functions have\n    no external dependencies and can be copied directly into your package\n    code using the 'staticimports' package.  "
  },
  {
    "id": 21567,
    "package_name": "subgxe",
    "title": "Combine Multiple GWAS by Using Gene-Environment Interactions",
    "description": "Classical methods for combining summary data from genome-wide\n    association studies (GWAS) only use marginal genetic effects and power can\n    be compromised in the presence of heterogeneity. 'subgxe' is a R package\n    that implements p-value assisted subset testing for association (pASTA),\n    a method developed by Yu et al. (2019) <doi:10.1159/000496867>. pASTA\n    generalizes association analysis based on subsets by incorporating\n    gene-environment interactions into the testing procedure.",
    "version": "0.9.0",
    "maintainer": "Alexander Rix <alexrix@umich.edu>",
    "author": "Youfei Yu [aut],\n  Alexander Rix [cre]",
    "url": "https://github.com/umich-cphds/subgxe",
    "bug_reports": "https://github.com/umich-cphds/subgxe/issues",
    "repository": "https://cran.r-project.org/package=subgxe",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "subgxe Combine Multiple GWAS by Using Gene-Environment Interactions Classical methods for combining summary data from genome-wide\n    association studies (GWAS) only use marginal genetic effects and power can\n    be compromised in the presence of heterogeneity. 'subgxe' is a R package\n    that implements p-value assisted subset testing for association (pASTA),\n    a method developed by Yu et al. (2019) <doi:10.1159/000496867>. pASTA\n    generalizes association analysis based on subsets by incorporating\n    gene-environment interactions into the testing procedure.  "
  },
  {
    "id": 21582,
    "package_name": "sudokuAlt",
    "title": "Tools for Making and Spoiling Sudoku Games",
    "description": "Tools for making, retrieving, displaying and solving sudoku games.\n    This package is an alternative to the earlier sudoku-solver package,\n    'sudoku'.  The present package uses a slightly different algorithm, has a\n    simpler coding and presents a few more sugar tools, such as plot and print\n    methods.  Solved sudoku games are of some interest in Experimental Design\n    as examples of Latin Square designs with additional balance constraints.",
    "version": "0.2-1",
    "maintainer": "Bill Venables <Bill.Venables@gmail.com>",
    "author": "Bill Venables <Bill.Venables@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sudokuAlt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sudokuAlt Tools for Making and Spoiling Sudoku Games Tools for making, retrieving, displaying and solving sudoku games.\n    This package is an alternative to the earlier sudoku-solver package,\n    'sudoku'.  The present package uses a slightly different algorithm, has a\n    simpler coding and presents a few more sugar tools, such as plot and print\n    methods.  Solved sudoku games are of some interest in Experimental Design\n    as examples of Latin Square designs with additional balance constraints.  "
  },
  {
    "id": 21678,
    "package_name": "survivalVignettes",
    "title": "Survival Analysis Vignettes and Optional Datasets",
    "description": "Vignettes for the 'survival' package. Split from the 'survival' \n    package since the vignettes were getting large. Also, since 'survival' is a \n    recommended package it cannot make use of other packages outside of \n    base+recommended (e.g. 'rmarkdown').",
    "version": "0.1.6",
    "maintainer": "Elizabeth Atkinson <atkinson@mayo.edu>",
    "author": "Terry M Therneau [aut],\n  Elizabeth Atkinson [cre, ctb],\n  Cynthia Crowson [ctb]",
    "url": "https://github.com/bethatkinson/survivalVignettes",
    "bug_reports": "https://github.com/bethatkinson/survivalVignettes/issues",
    "repository": "https://cran.r-project.org/package=survivalVignettes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "survivalVignettes Survival Analysis Vignettes and Optional Datasets Vignettes for the 'survival' package. Split from the 'survival' \n    package since the vignettes were getting large. Also, since 'survival' is a \n    recommended package it cannot make use of other packages outside of \n    base+recommended (e.g. 'rmarkdown').  "
  },
  {
    "id": 21701,
    "package_name": "svTools",
    "title": "Wrappers for Tools in Other Packages for IDE Friendliness",
    "description": "Set of tools aimed at wrapping some of the functionalities of the\n  packages tools, utils and codetools into a nicer format so that an IDE can use\n  them.",
    "version": "0.9-5",
    "maintainer": "Philippe Grosjean <phgrosjean@sciviews.org>",
    "author": "Philippe Grosjean [aut, cre],\n  Romain Francois [aut]",
    "url": "http://www.sciviews.org/SciViews-R,\nhttp://romainfrancois.blog.free.fr/",
    "bug_reports": "https://r-forge.r-project.org/tracker/?group_id=194",
    "repository": "https://cran.r-project.org/package=svTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svTools Wrappers for Tools in Other Packages for IDE Friendliness Set of tools aimed at wrapping some of the functionalities of the\n  packages tools, utils and codetools into a nicer format so that an IDE can use\n  them.  "
  },
  {
    "id": 21750,
    "package_name": "switchr",
    "title": "Installing, Managing, and Switching Between Distinct Sets of\nInstalled Packages",
    "description": "Provides an abstraction for managing, installing,\n    and switching between sets of installed R packages. This allows users to\n    maintain multiple package libraries simultaneously, e.g. to maintain\n    strict, package-version-specific reproducibility of many analyses, or\n    work within a development/production release paradigm. Introduces a\n    generalized package installation process which supports multiple repository\n    and non-repository sources and tracks package provenance.",
    "version": "0.14.8",
    "maintainer": "Gabriel Becker <gabembecker@gmail.com>",
    "author": "Gabriel Becker[aut, cre]",
    "url": "https://github.com/gmbecker/switchr",
    "bug_reports": "https://github.com/gmbecker/switchr/issues",
    "repository": "https://cran.r-project.org/package=switchr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "switchr Installing, Managing, and Switching Between Distinct Sets of\nInstalled Packages Provides an abstraction for managing, installing,\n    and switching between sets of installed R packages. This allows users to\n    maintain multiple package libraries simultaneously, e.g. to maintain\n    strict, package-version-specific reproducibility of many analyses, or\n    work within a development/production release paradigm. Introduces a\n    generalized package installation process which supports multiple repository\n    and non-repository sources and tracks package provenance.  "
  },
  {
    "id": 21754,
    "package_name": "sylly",
    "title": "Hyphenation and Syllable Counting for Text Analysis",
    "description": "Provides the hyphenation algorithm used for 'TeX'/'LaTeX' and similar software, as proposed by Liang (1983, <https://tug.org/docs/liang/>). Mainly contains the\n                    function hyphen() to be used for hyphenation/syllable counting of text objects. It was originally developed for and part of the 'koRpus' package, but later\n                    released as a separate package so it's lighter to have this particular functionality available for other packages. Support for various languages needs be added\n                    on-the-fly or by plugin packages (<https://undocumeantit.github.io/repos/>); this package does not include any language specific data. Due to some restrictions\n                    on CRAN, the full package sources are only available from the project homepage. To ask for help, report bugs, request features, or discuss the development of\n                    the package, please subscribe to the koRpus-dev mailing list (<http://korpusml.reaktanz.de>).",
    "version": "0.1-6",
    "maintainer": "Meik Michalke <meik.michalke@hhu.de>",
    "author": "Meik Michalke [aut, cre]",
    "url": "https://reaktanz.de/?c=hacking&s=sylly",
    "bug_reports": "https://github.com/unDocUMeantIt/sylly/issues",
    "repository": "https://cran.r-project.org/package=sylly",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sylly Hyphenation and Syllable Counting for Text Analysis Provides the hyphenation algorithm used for 'TeX'/'LaTeX' and similar software, as proposed by Liang (1983, <https://tug.org/docs/liang/>). Mainly contains the\n                    function hyphen() to be used for hyphenation/syllable counting of text objects. It was originally developed for and part of the 'koRpus' package, but later\n                    released as a separate package so it's lighter to have this particular functionality available for other packages. Support for various languages needs be added\n                    on-the-fly or by plugin packages (<https://undocumeantit.github.io/repos/>); this package does not include any language specific data. Due to some restrictions\n                    on CRAN, the full package sources are only available from the project homepage. To ask for help, report bugs, request features, or discuss the development of\n                    the package, please subscribe to the koRpus-dev mailing list (<http://korpusml.reaktanz.de>).  "
  },
  {
    "id": 21781,
    "package_name": "sysfonts",
    "title": "Loading Fonts into R",
    "description": "Loading system fonts and Google Fonts\n    <https://fonts.google.com/> into R, in order to\n    support other packages such as 'R2SWF' and 'showtext'.",
    "version": "0.8.9",
    "maintainer": "Yixuan Qiu <yixuan.qiu@cos.name>",
    "author": "Yixuan Qiu and authors/contributors of the\n    included fonts. See file AUTHORS for details.",
    "url": "https://github.com/yixuan/sysfonts",
    "bug_reports": "https://github.com/yixuan/sysfonts/issues",
    "repository": "https://cran.r-project.org/package=sysfonts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sysfonts Loading Fonts into R Loading system fonts and Google Fonts\n    <https://fonts.google.com/> into R, in order to\n    support other packages such as 'R2SWF' and 'showtext'.  "
  },
  {
    "id": 21811,
    "package_name": "tablesgg",
    "title": "Presentation-Quality Tables, Displayed Using 'ggplot2'",
    "description": "Presentation-quality tables are displayed as plots on an R \n  graphics device.  Although there are other packages that format tables \n  for display, this package is unique in combining two features: (a) It is \n  aware of the logical structure of the table being presented, and makes \n  use of that for automatic layout and styling of the table.  This avoids \n  the need for most manual adjustments to achieve an attractive result. \n  (b) It displays tables using 'ggplot2' graphics.  Therefore a table can \n  be presented anywhere a graph could be, with no more effort.  External \n  software such as LaTeX or HTML or their viewers is not required.  The \n  package provides a full set of tools to control the style and appearance \n  of tables, including titles, footnotes and reference marks, horizontal \n  and vertical rules, and spacing of rows and columns.  Methods are included \n  to display matrices; data frames; tables created by R's ftable(), table(), \n  and xtabs() functions; and tables created by the 'tables' and 'xtable' \n  packages.  Methods can be added to display other table-like objects.  A \n  vignette is included that illustrates usage and options available in the \n  package.",
    "version": "0.9-1",
    "maintainer": "Richard Raubertas <rrprf@emvt.net>",
    "author": "Richard Raubertas [aut, cre]",
    "url": "https://github.com/rrprf/tablesgg",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tablesgg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tablesgg Presentation-Quality Tables, Displayed Using 'ggplot2' Presentation-quality tables are displayed as plots on an R \n  graphics device.  Although there are other packages that format tables \n  for display, this package is unique in combining two features: (a) It is \n  aware of the logical structure of the table being presented, and makes \n  use of that for automatic layout and styling of the table.  This avoids \n  the need for most manual adjustments to achieve an attractive result. \n  (b) It displays tables using 'ggplot2' graphics.  Therefore a table can \n  be presented anywhere a graph could be, with no more effort.  External \n  software such as LaTeX or HTML or their viewers is not required.  The \n  package provides a full set of tools to control the style and appearance \n  of tables, including titles, footnotes and reference marks, horizontal \n  and vertical rules, and spacing of rows and columns.  Methods are included \n  to display matrices; data frames; tables created by R's ftable(), table(), \n  and xtabs() functions; and tables created by the 'tables' and 'xtable' \n  packages.  Methods can be added to display other table-like objects.  A \n  vignette is included that illustrates usage and options available in the \n  package.  "
  },
  {
    "id": 21854,
    "package_name": "tastypie",
    "title": "Easy Pie Charts",
    "description": "You only need to type 'why pie charts are bad' on Google to find\n    thousands of articles full of (valid) reasons why other types of charts \n    should be preferred over this one.\n    Therefore, because of the little use due to the reasons already mentioned,\n    making pie charts (and related) in R is not straightforward, so other \n    functions are needed to simplify things.\n    In this R package there are useful functions to make 'tasty' pie charts \n    immediately by exploiting the many cool templates provided.",
    "version": "0.1.2",
    "maintainer": "Paolo Dalena <paolodalena97@gmail.com>",
    "author": "Paolo Dalena [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2920-9572>)",
    "url": "https://paolodalena.github.io/tastypie/,\nhttps://github.com/PaoloDalena/tastypie",
    "bug_reports": "https://github.com/PaoloDalena/tastypie/issues",
    "repository": "https://cran.r-project.org/package=tastypie",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tastypie Easy Pie Charts You only need to type 'why pie charts are bad' on Google to find\n    thousands of articles full of (valid) reasons why other types of charts \n    should be preferred over this one.\n    Therefore, because of the little use due to the reasons already mentioned,\n    making pie charts (and related) in R is not straightforward, so other \n    functions are needed to simplify things.\n    In this R package there are useful functions to make 'tasty' pie charts \n    immediately by exploiting the many cool templates provided.  "
  },
  {
    "id": 21868,
    "package_name": "tbl2xts",
    "title": "Convert Tibbles or Data Frames to Xts Easily",
    "description": "Facilitate the movement between data frames to 'xts'. Particularly\n    useful when moving from 'tidyverse' to the widely used 'xts' package, which is\n    the input format of choice to various other packages. It also allows the user \n    to use a 'spread_by' argument for a character column 'xts' conversion.",
    "version": "1.0.4",
    "maintainer": "Nico Katzke <nfkatzke@gmail.com>",
    "author": "Nico Katzke [aut, cre]",
    "url": "https://tbl2xts.nfkatzke.com",
    "bug_reports": "https://github.com/nicktz/tbl2xts/issues",
    "repository": "https://cran.r-project.org/package=tbl2xts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tbl2xts Convert Tibbles or Data Frames to Xts Easily Facilitate the movement between data frames to 'xts'. Particularly\n    useful when moving from 'tidyverse' to the widely used 'xts' package, which is\n    the input format of choice to various other packages. It also allows the user \n    to use a 'spread_by' argument for a character column 'xts' conversion.  "
  },
  {
    "id": 21877,
    "package_name": "tcpl",
    "title": "ToxCast Data Analysis Pipeline",
    "description": "The ToxCast Data Analysis Pipeline ('tcpl') is an R package that manages, curve-fits, plots, and stores ToxCast data to populate its linked MySQL database, 'invitrodb'. The package was developed for the chemical screening data curated by the US EPA's Toxicity Forecaster (ToxCast) program, but 'tcpl' can be used to support diverse chemical screening efforts.",
    "version": "3.3.1",
    "maintainer": "Madison Feshuk <feshuk.madison@epa.gov>",
    "author": "Dayne L Filer [aut],\n  Jason Brown [ctb] (ORCID: <https://orcid.org/0009-0000-2294-641X>),\n  Madison Feshuk [cre] (ORCID: <https://orcid.org/0000-0002-1390-6405>),\n  Carter Thunes [ctb],\n  Sarah E Davidson-Fritz [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2891-9380>),\n  Kelly Carstens [ctb] (ORCID: <https://orcid.org/0000-0002-1746-5379>),\n  Elizabeth Gilson [ctb],\n  Lindsay Knupp [ctb],\n  Lori Kolaczkowski [ctb],\n  Ashley Ko [ctb],\n  Zhihui Zhao [ctb],\n  Kurt Dunham [ctb],\n  Todd Zurlinden [ctb] (ORCID: <https://orcid.org/0000-0003-1372-3913>),\n  Parth Kothiya [ctb],\n  Woodrow R Setzer [ctb],\n  Matthew T Martin [ctb, ths],\n  Richard S Judson [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0002-2348-9633>),\n  Katie Paul Friedman [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2710-1691>)",
    "url": "https://github.com/USEPA/CompTox-ToxCast-tcpl,\nhttps://www.epa.gov/comptox-tools/toxicity-forecasting-toxcast",
    "bug_reports": "https://github.com/USEPA/CompTox-ToxCast-tcpl/issues",
    "repository": "https://cran.r-project.org/package=tcpl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tcpl ToxCast Data Analysis Pipeline The ToxCast Data Analysis Pipeline ('tcpl') is an R package that manages, curve-fits, plots, and stores ToxCast data to populate its linked MySQL database, 'invitrodb'. The package was developed for the chemical screening data curated by the US EPA's Toxicity Forecaster (ToxCast) program, but 'tcpl' can be used to support diverse chemical screening efforts.  "
  },
  {
    "id": 21878,
    "package_name": "tcplfit2",
    "title": "A Concentration-Response Modeling Utility",
    "description": "The tcplfit2 R package performs basic concentration-response curve fitting. The original tcplFit() function in the tcpl R package performed basic concentration-response curvefitting to 3 models. With tcplfit2, the core tcpl concentration-response functionality has been expanded to process diverse high-throughput screen (HTS) data generated at the US Environmental Protection Agency, including targeted ToxCast, high-throughput transcriptomics (HTTr) and high-throughput phenotypic profiling (HTPP). tcplfit2 can be used independently to support analysis for diverse chemical screening efforts.",
    "version": "0.1.9",
    "maintainer": "Madison Feshuk <feshuk.madison@epa.gov>",
    "author": "Thomas Sheffield [aut],\n  Jason Brown [ctb] (ORCID: <https://orcid.org/0009-0000-2294-641X>),\n  Sarah E. Davidson-Fritz [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2891-9380>),\n  Madison Feshuk [ctb, cre] (ORCID:\n    <https://orcid.org/0000-0002-1390-6405>),\n  Lindsay Knupp [ctb],\n  Zhihui Zhao [ctb],\n  Richard S Judson [ctb] (ORCID: <https://orcid.org/0000-0002-2348-9633>),\n  Katie Paul Friedman [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2710-1691>)",
    "url": "https://github.com/USEPA/CompTox-ToxCast-tcplFit2",
    "bug_reports": "https://github.com/USEPA/CompTox-ToxCast-tcplFit2/issues",
    "repository": "https://cran.r-project.org/package=tcplfit2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tcplfit2 A Concentration-Response Modeling Utility The tcplfit2 R package performs basic concentration-response curve fitting. The original tcplFit() function in the tcpl R package performed basic concentration-response curvefitting to 3 models. With tcplfit2, the core tcpl concentration-response functionality has been expanded to process diverse high-throughput screen (HTS) data generated at the US Environmental Protection Agency, including targeted ToxCast, high-throughput transcriptomics (HTTr) and high-throughput phenotypic profiling (HTPP). tcplfit2 can be used independently to support analysis for diverse chemical screening efforts.  "
  },
  {
    "id": 21951,
    "package_name": "testdat",
    "title": "Data Unit Testing for R",
    "description": "Test your data! An extension of the 'testthat' unit testing\n    framework with a family of functions and reporting tools for checking\n    and validating data frames.",
    "version": "0.4.4",
    "maintainer": "Danny Smith <danny@gorcha.org>",
    "author": "Danny Smith [aut, cre],\n  Kinto Behr [aut],\n  The Social Research Centre [cph]",
    "url": "https://socialresearchcentre.github.io/testdat/,\nhttps://github.com/socialresearchcentre/testdat",
    "bug_reports": "https://github.com/socialresearchcentre/testdat/issues",
    "repository": "https://cran.r-project.org/package=testdat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testdat Data Unit Testing for R Test your data! An extension of the 'testthat' unit testing\n    framework with a family of functions and reporting tools for checking\n    and validating data frames.  "
  },
  {
    "id": 21954,
    "package_name": "testex",
    "title": "Add Tests to Examples",
    "description": "\n    Add tests in-line in examples. Provides standalone functions for\n    facilitating easier test writing in Rd files. However, a more familiar\n    interface is provided using 'roxygen2' tags. Tools are also provided for\n    facilitating package configuration and use with 'testthat'.",
    "version": "0.2.1",
    "maintainer": "Doug Kelkhoff <doug.kelkhoff@gmail.com>",
    "author": "Doug Kelkhoff [aut, cre]",
    "url": "https://github.com/dgkf/testex, https://dgkf.github.io/testex/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=testex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testex Add Tests to Examples \n    Add tests in-line in examples. Provides standalone functions for\n    facilitating easier test writing in Rd files. However, a more familiar\n    interface is provided using 'roxygen2' tags. Tools are also provided for\n    facilitating package configuration and use with 'testthat'.  "
  },
  {
    "id": 21956,
    "package_name": "testit",
    "title": "A Simple Package for Testing R Packages",
    "description": "Provides two convenience functions assert() and test_pkg() to\n    facilitate testing R packages.",
    "version": "0.14",
    "maintainer": "Yihui Xie <xie@yihui.name>",
    "author": "Yihui Xie [aut, cre] (ORCID: <https://orcid.org/0000-0003-0645-5666>,\n    URL: https://yihui.org),\n  Tomas Kalibera [ctb],\n  Steven Mortimer [ctb]",
    "url": "https://github.com/yihui/testit",
    "bug_reports": "https://github.com/yihui/testit/issues",
    "repository": "https://cran.r-project.org/package=testit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testit A Simple Package for Testing R Packages Provides two convenience functions assert() and test_pkg() to\n    facilitate testing R packages.  "
  },
  {
    "id": 21957,
    "package_name": "testthatdocs",
    "title": "Automated and Idempotent Unit Tests Documentation for\nReproducible Quality Assurance",
    "description": "\n    Automates documentation of test_that() calls within R test files. \n    The package scans test sources, extracts human-readable test titles (even when \n    composed with functions like paste() or glue::glue(), ... etc.), and generates \n    reproducible roxygen2-style listings that can be inserted both globally and \n    per-section. It ensures idempotent updates and supports customizable numbering \n    templates with hierarchical indices. Designed for developers, QA teams, and package\n    maintainers seeking consistent, self-documenting test inventories. ",
    "version": "1.0.23",
    "maintainer": "Rafal Urniaz <rafal.urniaz@cantab.net>",
    "author": "Rafal Urniaz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0192-2165>)",
    "url": "https://github.com/urniaz/testthatdocs",
    "bug_reports": "https://github.com/urniaz/testthatdocs/issues",
    "repository": "https://cran.r-project.org/package=testthatdocs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testthatdocs Automated and Idempotent Unit Tests Documentation for\nReproducible Quality Assurance \n    Automates documentation of test_that() calls within R test files. \n    The package scans test sources, extracts human-readable test titles (even when \n    composed with functions like paste() or glue::glue(), ... etc.), and generates \n    reproducible roxygen2-style listings that can be inserted both globally and \n    per-section. It ensures idempotent updates and supports customizable numbering \n    templates with hierarchical indices. Designed for developers, QA teams, and package\n    maintainers seeking consistent, self-documenting test inventories.   "
  },
  {
    "id": 21958,
    "package_name": "testthatmulti",
    "title": "Testing for R Packages with Multiple Attempts for Noisy Tests",
    "description": "Runs tests using the 'testthat' package but allows for multiple\n    attempts for a single test. This is useful for noisy or flaky tests\n    that generally pass but can fail due to occasional random errors,\n    such as numeric instability or using random data.",
    "version": "0.2.0",
    "maintainer": "Collin Erickson <collinberickson@gmail.com>",
    "author": "Collin Erickson [aut, cre]",
    "url": "https://github.com/CollinErickson/testthatmulti",
    "bug_reports": "https://github.com/CollinErickson/testthatmulti/issues",
    "repository": "https://cran.r-project.org/package=testthatmulti",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testthatmulti Testing for R Packages with Multiple Attempts for Noisy Tests Runs tests using the 'testthat' package but allows for multiple\n    attempts for a single test. This is useful for noisy or flaky tests\n    that generally pass but can fail due to occasional random errors,\n    such as numeric instability or using random data.  "
  },
  {
    "id": 21959,
    "package_name": "testthis",
    "title": "Utils and 'RStudio' Addins to Make Testing Even More Fun",
    "description": "Utility functions and 'RStudio' addins for writing,\n    running and organizing automated tests. Integrates tightly with the\n    packages 'testthat', 'devtools' and 'usethis'.  Hotkeys can be\n    assigned to the 'RStudio' addins for running tests in a single file or\n    to switch between a source file and the associated test file. In\n    addition, testthis provides function to manage and run tests in\n    subdirectories of the test/testthat directory.",
    "version": "1.1.1",
    "maintainer": "Stefan Fleck <stefan.b.fleck@gmail.com>",
    "author": "Stefan Fleck [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3344-9851>)",
    "url": "https://s-fleck.github.io/testthis",
    "bug_reports": "https://github.com/s-fleck/testthis/issues",
    "repository": "https://cran.r-project.org/package=testthis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "testthis Utils and 'RStudio' Addins to Make Testing Even More Fun Utility functions and 'RStudio' addins for writing,\n    running and organizing automated tests. Integrates tightly with the\n    packages 'testthat', 'devtools' and 'usethis'.  Hotkeys can be\n    assigned to the 'RStudio' addins for running tests in a single file or\n    to switch between a source file and the associated test file. In\n    addition, testthis provides function to manage and run tests in\n    subdirectories of the test/testthat directory.  "
  },
  {
    "id": 21982,
    "package_name": "textanalyzer",
    "title": "'textanalyzer', an R Package to Analyze Text",
    "description": "It analyzes text to create a count of top n-grams, including tokens (one-word), bigrams(two-word), and trigrams (three-word), while removing all stopwords. It also plots the n-grams and corresponding counts as a bar chart.",
    "version": "0.2.0",
    "maintainer": "Pushker Ravindra <pushker@gmail.com>",
    "author": "Pushker Ravindra [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=textanalyzer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "textanalyzer 'textanalyzer', an R Package to Analyze Text It analyzes text to create a count of top n-grams, including tokens (one-word), bigrams(two-word), and trigrams (three-word), while removing all stopwords. It also plots the n-grams and corresponding counts as a bar chart.  "
  },
  {
    "id": 22019,
    "package_name": "thankr",
    "title": "Find Out Who Maintains the Packages you Use",
    "description": "Find out who maintains the packages you use in\n             your current session or in your package library and\n             maybe say 'thank you'.",
    "version": "1.0.0",
    "maintainer": "Dirk Schumacher <mail@dirk-schumacher.net>",
    "author": "Dirk Schumacher [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=thankr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "thankr Find Out Who Maintains the Packages you Use Find out who maintains the packages you use in\n             your current session or in your package library and\n             maybe say 'thank you'.  "
  },
  {
    "id": 22025,
    "package_name": "thestats",
    "title": "R Package for Exploring Turkish Higher Education Statistics",
    "description": "A user-friendly R data package that is intended to make Turkish higher education statistics more accessible. ",
    "version": "0.1.0",
    "maintainer": "Olgun Aydin <olgun.aydin@pg.edu.pl>",
    "author": "Olgun Aydin, Mustafa Cavus",
    "url": "https://github.com/analyticsresearchlab/thestats",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=thestats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "thestats R Package for Exploring Turkish Higher Education Statistics A user-friendly R data package that is intended to make Turkish higher education statistics more accessible.   "
  },
  {
    "id": 22029,
    "package_name": "this.path",
    "title": "Get Executing Script's Path",
    "description": "Determine the path of the executing script. Compatible\n        with several popular GUIs: 'Rgui', 'RStudio', 'Positron',\n        'VSCode', 'Jupyter', 'Emacs', and 'Rscript' (shell). Compatible\n        with several functions and packages: 'source()',\n        'sys.source()', 'debugSource()' in 'RStudio',\n        'compiler::loadcmp()', 'utils::Sweave()', 'box::use()',\n        'knitr::knit()', 'plumber::plumb()', 'shiny::runApp()',\n        'package:targets', and 'testthat::source_file()'.",
    "version": "2.7.1",
    "maintainer": "Iris Simmons <ikwsimmo@gmail.com>",
    "author": "Iris Simmons [aut, cre]",
    "url": "https://github.com/ArcadeAntics/this.path",
    "bug_reports": "https://github.com/ArcadeAntics/this.path/issues",
    "repository": "https://cran.r-project.org/package=this.path",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "this.path Get Executing Script's Path Determine the path of the executing script. Compatible\n        with several popular GUIs: 'Rgui', 'RStudio', 'Positron',\n        'VSCode', 'Jupyter', 'Emacs', and 'Rscript' (shell). Compatible\n        with several functions and packages: 'source()',\n        'sys.source()', 'debugSource()' in 'RStudio',\n        'compiler::loadcmp()', 'utils::Sweave()', 'box::use()',\n        'knitr::knit()', 'plumber::plumb()', 'shiny::runApp()',\n        'package:targets', and 'testthat::source_file()'.  "
  },
  {
    "id": 22070,
    "package_name": "tidycharts",
    "title": "Generate Tidy Charts Inspired by 'IBCS'",
    "description": "There is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The 'tidycharts' package enables the user to generate charts compliant with International Business Communication Standards ('IBCS').\n    It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What's more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments.\n    We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible.\n    All charts are generated in SVG format and can be shown in the 'RStudio' viewer pane or exported to HTML output of 'knitr'/'markdown'.",
    "version": "0.1.3",
    "maintainer": "Bartosz Sawicki <sawicki.bartosz@interia.pl>",
    "author": "Przemys\u0142aw Biecek [aut] (ORCID:\n    <https://orcid.org/0000-0001-8423-1823>),\n  Piotr Pi\u0105tyszek [aut],\n  Kinga U\u0142asik [aut],\n  Bartosz Sawicki [aut, cre]",
    "url": "https://mi2datalab.github.io/tidycharts/,\nhttps://github.com/MI2DataLab/tidycharts",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidycharts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidycharts Generate Tidy Charts Inspired by 'IBCS' There is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The 'tidycharts' package enables the user to generate charts compliant with International Business Communication Standards ('IBCS').\n    It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What's more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments.\n    We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible.\n    All charts are generated in SVG format and can be shown in the 'RStudio' viewer pane or exported to HTML output of 'knitr'/'markdown'.  "
  },
  {
    "id": 22088,
    "package_name": "tidyft",
    "title": "Fast and Memory Efficient Data Operations in Tidy Syntax",
    "description": "Tidy syntax for 'data.table', using modification by reference whenever possible.\n This toolkit is designed for big data analysis in high-performance desktop or laptop computers.\n The syntax of the package is similar or identical to 'tidyverse'.\n It is user friendly, memory efficient and time saving. For more information,\n check its ancestor package 'tidyfst'.",
    "version": "0.9.20",
    "maintainer": "Tian-Yuan Huang <huang.tian-yuan@qq.com>",
    "author": "Tian-Yuan Huang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4151-3764>)",
    "url": "https://github.com/hope-data-science/tidyft,\nhttps://hope-data-science.github.io/tidyft/",
    "bug_reports": "https://github.com/hope-data-science/tidyft/issues",
    "repository": "https://cran.r-project.org/package=tidyft",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidyft Fast and Memory Efficient Data Operations in Tidy Syntax Tidy syntax for 'data.table', using modification by reference whenever possible.\n This toolkit is designed for big data analysis in high-performance desktop or laptop computers.\n The syntax of the package is similar or identical to 'tidyverse'.\n It is user friendly, memory efficient and time saving. For more information,\n check its ancestor package 'tidyfst'.  "
  },
  {
    "id": 22131,
    "package_name": "tidytitanic",
    "title": "Dataframes Based on Titanic Passengers and Crew",
    "description": "A version of the Titanic survival data tailored for people analytics demonstrations and practice. While another package, 'titanic', reproduces the Kaggle competition files with minimal preprocessing, 'tidytitanic' combines the train and test datasets into the single dataset, 'passengers', for exploration and summary across all passengers. It also extracts personal identifiers\u2014such as first names, last names, and titles from the raw 'name' field, enabling demographic analysis. The 'passengers' data does not cover the crew, but this package also provides the more bare-bones, crew-containing datasets 'tidy_titanic' and 'flat_titanic' based on the 'Titanic' data set from 'datasets' for further exploration. This human-centered data package is designed to support exploratory data analysis, feature engineering, and pedagogical use cases.",
    "version": "0.0.1",
    "maintainer": "Evangeline Reynolds <evangeline.mae@gmail.com>",
    "author": "Evangeline Reynolds [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidytitanic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidytitanic Dataframes Based on Titanic Passengers and Crew A version of the Titanic survival data tailored for people analytics demonstrations and practice. While another package, 'titanic', reproduces the Kaggle competition files with minimal preprocessing, 'tidytitanic' combines the train and test datasets into the single dataset, 'passengers', for exploration and summary across all passengers. It also extracts personal identifiers\u2014such as first names, last names, and titles from the raw 'name' field, enabling demographic analysis. The 'passengers' data does not cover the crew, but this package also provides the more bare-bones, crew-containing datasets 'tidy_titanic' and 'flat_titanic' based on the 'Titanic' data set from 'datasets' for further exploration. This human-centered data package is designed to support exploratory data analysis, feature engineering, and pedagogical use cases.  "
  },
  {
    "id": 22169,
    "package_name": "timedeppar",
    "title": "Infer Constant and Stochastic, Time-Dependent Model Parameters",
    "description": "Infer constant and stochastic, time-dependent parameters to consider intrinsic stochasticity of a dynamic model and/or to analyze model structure modifications that could reduce model deficits.\n  The concept is based on inferring time-dependent parameters as stochastic processes in the form of Ornstein-Uhlenbeck processes jointly with inferring constant model parameters and parameters of the Ornstein-Uhlenbeck processes.\n  The package also contains functions to sample from and calculate densities of Ornstein-Uhlenbeck processes.\n  References:\n  Tomassini, L., Reichert, P., Kuensch, H.-R. Buser, C., Knutti, R. and Borsuk, M.E. (2009), A smoothing algorithm for estimating stochastic, continuous-time model parameters and its application to a simple climate model, Journal of the Royal Statistical Society: Series C (Applied Statistics) 58, 679-704, <doi:10.1111/j.1467-9876.2009.00678.x>\n  Reichert, P., and Mieleitner, J. (2009), Analyzing input and structural uncertainty of nonlinear dynamic models with stochastic, time-dependent parameters. Water Resources Research, 45, W10402, <doi:10.1029/2009WR007814>\n  Reichert, P., Ammann, L. and Fenicia, F. (2021), Potential and challenges of investigating intrinsic uncertainty of hydrological models with time-dependent, stochastic parameters. Water Resources Research 57(8), e2020WR028311, <doi:10.1029/2020WR028311>\n  Reichert, P. (2022), timedeppar: An R package for inferring stochastic, time-dependent model parameters, in preparation.",
    "version": "1.0.3",
    "maintainer": "Peter Reichert <peter.reichert@emeriti.eawag.ch>",
    "author": "Peter Reichert <peter.reichert@emeriti.eawag.ch> ",
    "url": "https://gitlab.com/p.reichert/timedeppar",
    "bug_reports": "https://gitlab.com/p.reichert/timedeppar/-/issues",
    "repository": "https://cran.r-project.org/package=timedeppar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timedeppar Infer Constant and Stochastic, Time-Dependent Model Parameters Infer constant and stochastic, time-dependent parameters to consider intrinsic stochasticity of a dynamic model and/or to analyze model structure modifications that could reduce model deficits.\n  The concept is based on inferring time-dependent parameters as stochastic processes in the form of Ornstein-Uhlenbeck processes jointly with inferring constant model parameters and parameters of the Ornstein-Uhlenbeck processes.\n  The package also contains functions to sample from and calculate densities of Ornstein-Uhlenbeck processes.\n  References:\n  Tomassini, L., Reichert, P., Kuensch, H.-R. Buser, C., Knutti, R. and Borsuk, M.E. (2009), A smoothing algorithm for estimating stochastic, continuous-time model parameters and its application to a simple climate model, Journal of the Royal Statistical Society: Series C (Applied Statistics) 58, 679-704, <doi:10.1111/j.1467-9876.2009.00678.x>\n  Reichert, P., and Mieleitner, J. (2009), Analyzing input and structural uncertainty of nonlinear dynamic models with stochastic, time-dependent parameters. Water Resources Research, 45, W10402, <doi:10.1029/2009WR007814>\n  Reichert, P., Ammann, L. and Fenicia, F. (2021), Potential and challenges of investigating intrinsic uncertainty of hydrological models with time-dependent, stochastic parameters. Water Resources Research 57(8), e2020WR028311, <doi:10.1029/2020WR028311>\n  Reichert, P. (2022), timedeppar: An R package for inferring stochastic, time-dependent model parameters, in preparation.  "
  },
  {
    "id": 22187,
    "package_name": "tinycodet",
    "title": "Functions to Help in your Coding Etiquette",
    "description": "Adds some functions to help in your coding etiquette.\n    'tinycodet' primarily focuses on 4 aspects.\n    1) Safer decimal (in)equality testing,\n    standard-evaluated alternatives to with() and aes(),\n    and other functions for safer coding.\n    2) A new package import system,\n    that attempts to combine the benefits of using a package without attaching it,\n    with the benefits of attaching a package.\n    3) Extending the string manipulation capabilities of the 'stringi' R package.\n    4) Reducing repetitive code.\n    Besides linking to 'Rcpp', 'tinycodet' has only one other dependency, namely 'stringi'.",
    "version": "0.5.8",
    "maintainer": "Tony Wilkes <tony_a_wilkes@outlook.com>",
    "author": "Tony Wilkes [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9498-8379>)",
    "url": "https://github.com/tony-aw/tinycodet/,\nhttps://tony-aw.github.io/tinycodet/",
    "bug_reports": "https://github.com/tony-aw/tinycodet/issues/",
    "repository": "https://cran.r-project.org/package=tinycodet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinycodet Functions to Help in your Coding Etiquette Adds some functions to help in your coding etiquette.\n    'tinycodet' primarily focuses on 4 aspects.\n    1) Safer decimal (in)equality testing,\n    standard-evaluated alternatives to with() and aes(),\n    and other functions for safer coding.\n    2) A new package import system,\n    that attempts to combine the benefits of using a package without attaching it,\n    with the benefits of attaching a package.\n    3) Extending the string manipulation capabilities of the 'stringi' R package.\n    4) Reducing repetitive code.\n    Besides linking to 'Rcpp', 'tinycodet' has only one other dependency, namely 'stringi'.  "
  },
  {
    "id": 22189,
    "package_name": "tinylens",
    "title": "Minimal Implementation of Functional Lenses",
    "description": "Provides utilities to create and use lenses to simplify data\n    manipulation. Lenses are composable getter/setter pairs that provide a\n    functional approach to manipulating deeply nested data structures, e.g.,\n    elements within list columns in data frames. The implementation is based on\n    the earlier 'lenses' R package <https://github.com/cfhammill/lenses>,\n    which was inspired by the Haskell 'lens' package by Kmett (2012)\n    <https://github.com/ekmett/lens>, one of the most widely referenced\n    implementations of lenses. For additional background and history on the\n    theory of lenses, see the 'lens' package wiki:\n    <https://github.com/ekmett/lens/wiki/History-of-Lenses>.",
    "version": "0.1.0",
    "maintainer": "Albert Wang <albert_z_wang@harvard.edu>",
    "author": "Albert Wang [aut, cre, cph]",
    "url": "https://github.com/arbelt/tinylens",
    "bug_reports": "https://github.com/arbelt/tinylens/issues",
    "repository": "https://cran.r-project.org/package=tinylens",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinylens Minimal Implementation of Functional Lenses Provides utilities to create and use lenses to simplify data\n    manipulation. Lenses are composable getter/setter pairs that provide a\n    functional approach to manipulating deeply nested data structures, e.g.,\n    elements within list columns in data frames. The implementation is based on\n    the earlier 'lenses' R package <https://github.com/cfhammill/lenses>,\n    which was inspired by the Haskell 'lens' package by Kmett (2012)\n    <https://github.com/ekmett/lens>, one of the most widely referenced\n    implementations of lenses. For additional background and history on the\n    theory of lenses, see the 'lens' package wiki:\n    <https://github.com/ekmett/lens/wiki/History-of-Lenses>.  "
  },
  {
    "id": 22193,
    "package_name": "tinytest",
    "title": "Lightweight and Feature Complete Unit Testing Framework",
    "description": "Provides a lightweight (zero-dependency) and easy to use \n    unit testing framework. Main features: install tests with \n    the package. Test results are treated as data that can be stored and \n    manipulated. Test files are R scripts interspersed with test commands, that\n    can be programmed over. Fully automated build-install-test sequence for \n    packages. Skip tests when not run locally (e.g. on CRAN). Flexible and \n    configurable output printing. Compare computed output with output stored \n    with the package. Run tests in parallel. Extensible by other packages.\n    Report side effects.",
    "version": "1.4.1",
    "maintainer": "Mark van der Loo <mark.vanderloo@gmail.com>",
    "author": "Mark van der Loo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9807-4686>)",
    "url": "https://github.com/markvanderloo/tinytest",
    "bug_reports": "https://github.com/markvanderloo/tinytest/issues",
    "repository": "https://cran.r-project.org/package=tinytest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinytest Lightweight and Feature Complete Unit Testing Framework Provides a lightweight (zero-dependency) and easy to use \n    unit testing framework. Main features: install tests with \n    the package. Test results are treated as data that can be stored and \n    manipulated. Test files are R scripts interspersed with test commands, that\n    can be programmed over. Fully automated build-install-test sequence for \n    packages. Skip tests when not run locally (e.g. on CRAN). Flexible and \n    configurable output printing. Compare computed output with output stored \n    with the package. Run tests in parallel. Extensible by other packages.\n    Report side effects.  "
  },
  {
    "id": 22194,
    "package_name": "tinytest2JUnit",
    "title": "Convert 'tinytest' Output to JUnit XML",
    "description": "Unit testing is a solid component of automated CI/CD pipelines. \n\t'tinytest' - a lightweight, zero-dependency  alternative to 'testthat' was developed.\n\tTo be able to integrate 'tinytests' results into common CI/CD systems the test results from \n\ttinytest need to be caputred and converted to JUnit XML format. \n\t'tinytest2JUnit' enables this conversion while staying also lightweight \n\tand only have 'tinytest' as its dependency.",
    "version": "1.1.2",
    "maintainer": "Lennart Tuijnder <lennart.tuijnder@openanalytics.eu>",
    "author": "Anne-Katrin Hess [aut],\n  Lennart Tuijnder [aut, cre]",
    "url": "https://github.com/openanalytics/tinytest2JUnit",
    "bug_reports": "https://github.com/openanalytics/tinytest2JUnit/issues",
    "repository": "https://cran.r-project.org/package=tinytest2JUnit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinytest2JUnit Convert 'tinytest' Output to JUnit XML Unit testing is a solid component of automated CI/CD pipelines. \n\t'tinytest' - a lightweight, zero-dependency  alternative to 'testthat' was developed.\n\tTo be able to integrate 'tinytests' results into common CI/CD systems the test results from \n\ttinytest need to be caputred and converted to JUnit XML format. \n\t'tinytest2JUnit' enables this conversion while staying also lightweight \n\tand only have 'tinytest' as its dependency.  "
  },
  {
    "id": 22211,
    "package_name": "tlars",
    "title": "The T-LARS Algorithm: Early-Terminated Forward Variable\nSelection",
    "description": "Computes the solution path of the Terminating-LARS (T-LARS) algorithm. The T-LARS algorithm \n    is a major building block of the T-Rex selector (see R package 'TRexSelector').\n    The package is based on the papers Machkour, Muma, and Palomar (2022) <arXiv:2110.06048>, Efron, Hastie, Johnstone, \n    and Tibshirani (2004) <doi:10.1214/009053604000000067>, and Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x>.",
    "version": "1.0.1",
    "maintainer": "Jasin Machkour <jasin.machkour@tu-darmstadt.de>",
    "author": "Jasin Machkour [aut, cre],\n  Simon Tien [aut],\n  Daniel P. Palomar [aut],\n  Michael Muma [aut]",
    "url": "https://github.com/jasinmachkour/tlars,\nhttps://arxiv.org/abs/2110.06048",
    "bug_reports": "https://github.com/jasinmachkour/tlars/issues",
    "repository": "https://cran.r-project.org/package=tlars",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tlars The T-LARS Algorithm: Early-Terminated Forward Variable\nSelection Computes the solution path of the Terminating-LARS (T-LARS) algorithm. The T-LARS algorithm \n    is a major building block of the T-Rex selector (see R package 'TRexSelector').\n    The package is based on the papers Machkour, Muma, and Palomar (2022) <arXiv:2110.06048>, Efron, Hastie, Johnstone, \n    and Tibshirani (2004) <doi:10.1214/009053604000000067>, and Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x>.  "
  },
  {
    "id": 22242,
    "package_name": "tmvmixnorm",
    "title": "Sampling from Truncated Multivariate Normal and t Distributions",
    "description": "Efficient sampling of truncated multivariate (scale) mixtures of normals under linear inequality constraints is nontrivial due to the analytically intractable normalizing constant. Meanwhile, traditional methods may subject to numerical issues, especially when the dimension is high and dependence is strong.    Algorithms proposed by Li and Ghosh (2015) <doi: 10.1080/15598608.2014.996690> are adopted for overcoming difficulties in simulating truncated distributions. Efficient rejection sampling for simulating truncated univariate normal distribution is included in the package, which shows superiority in terms of acceptance rate and numerical stability compared to existing methods and R packages. An efficient function for sampling from truncated multivariate normal distribution subject to convex polytope restriction regions based on Gibbs sampler for conditional truncated univariate distribution is provided. By extending the sampling method, a function for sampling truncated multivariate Student's t distribution is also developed.     Moreover, the proposed method and computation remain valid for high dimensional and strong dependence scenarios. Empirical results in Li and Ghosh (2015) <doi: 10.1080/15598608.2014.996690> illustrated the superior performance in terms of various criteria (e.g. mixing and integrated auto-correlation time).",
    "version": "1.1.1",
    "maintainer": "Ting Fung (Ralph) Ma <tingfung.ma@wisc.edu>",
    "author": "Ting Fung (Ralph) Ma [cre, aut],\n  Sujit K. Ghosh [aut],\n  Yifang Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tmvmixnorm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tmvmixnorm Sampling from Truncated Multivariate Normal and t Distributions Efficient sampling of truncated multivariate (scale) mixtures of normals under linear inequality constraints is nontrivial due to the analytically intractable normalizing constant. Meanwhile, traditional methods may subject to numerical issues, especially when the dimension is high and dependence is strong.    Algorithms proposed by Li and Ghosh (2015) <doi: 10.1080/15598608.2014.996690> are adopted for overcoming difficulties in simulating truncated distributions. Efficient rejection sampling for simulating truncated univariate normal distribution is included in the package, which shows superiority in terms of acceptance rate and numerical stability compared to existing methods and R packages. An efficient function for sampling from truncated multivariate normal distribution subject to convex polytope restriction regions based on Gibbs sampler for conditional truncated univariate distribution is provided. By extending the sampling method, a function for sampling truncated multivariate Student's t distribution is also developed.     Moreover, the proposed method and computation remain valid for high dimensional and strong dependence scenarios. Empirical results in Li and Ghosh (2015) <doi: 10.1080/15598608.2014.996690> illustrated the superior performance in terms of various criteria (e.g. mixing and integrated auto-correlation time).  "
  },
  {
    "id": 22259,
    "package_name": "toolStability",
    "title": "Tool for Stability Indices Calculation",
    "description": "Tools to calculate stability indices with parametric,\n non-parametric and probabilistic approaches. The basic data format requirement for 'toolStability' is a data frame with 3 columns including numeric trait values, genotype,and environmental labels. Output format of each function is the dataframe with chosen stability index for each genotype. \n Function \"table_stability\" offers the summary table of all stability indices in this package. \n This R package toolStability is part of the main publication: \n Wang, Casadebaig and Chen (2023) <doi:10.1007/s00122-023-04264-7>. \n Analysis pipeline for main publication can be found on github: <https://github.com/Illustratien/Wang_2023_TAAG>. \n Sample dataset in this package is derived from another publication:  \n Casadebaig P, Zheng B, Chapman S et al. (2016) <doi:10.1371/journal.pone.0146385>. \n For detailed documentation of dataset, please see on Zenodo <doi:10.5281/zenodo.4729636>. \n Indices used in this package are from: \n D\u00f6ring TF, Reckling M (2018) <doi:10.1016/j.eja.2018.06.007>. \n Eberhart SA, Russell WA (1966) <doi:10.2135/cropsci1966.0011183X000600010011x>. \n Eskridge KM (1990) <doi:10.2135/cropsci1990.0011183X003000020025x>. \n Finlay KW, Wilkinson GN (1963) <doi:10.1071/AR9630742>. \n Hanson WD (1970) Genotypic stability. <doi:10.1007/BF00285245>. \n Lin CS, Binns MR (1988). \n Nassar R, H\u00fchn M (1987). \n Pinthus MJ (1973) <doi:10.1007/BF00021563>. \n R\u00f6mer T (1917). \n Shukla GK (1972). \n Wricke G (1962). ",
    "version": "0.1.3",
    "maintainer": "Tien-Cheng Wang <wangtien@student.hu-berlin.de>",
    "author": "Tien-Cheng Wang [aut, cre],\n  Tsu-Wei Chen [com]",
    "url": "https://illustratien.github.io/toolStability/,\nhttps://link.springer.com/article/10.1007/s00122-023-04264-7,\nhttps://github.com/Illustratien/toolStability,\nhttps://github.com/Illustratien/Wang_2023_TAAG,\nhttps://doi.org/10.5281/zenodo.4729636",
    "bug_reports": "https://github.com/Illustratien/toolStability/issues",
    "repository": "https://cran.r-project.org/package=toolStability",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "toolStability Tool for Stability Indices Calculation Tools to calculate stability indices with parametric,\n non-parametric and probabilistic approaches. The basic data format requirement for 'toolStability' is a data frame with 3 columns including numeric trait values, genotype,and environmental labels. Output format of each function is the dataframe with chosen stability index for each genotype. \n Function \"table_stability\" offers the summary table of all stability indices in this package. \n This R package toolStability is part of the main publication: \n Wang, Casadebaig and Chen (2023) <doi:10.1007/s00122-023-04264-7>. \n Analysis pipeline for main publication can be found on github: <https://github.com/Illustratien/Wang_2023_TAAG>. \n Sample dataset in this package is derived from another publication:  \n Casadebaig P, Zheng B, Chapman S et al. (2016) <doi:10.1371/journal.pone.0146385>. \n For detailed documentation of dataset, please see on Zenodo <doi:10.5281/zenodo.4729636>. \n Indices used in this package are from: \n D\u00f6ring TF, Reckling M (2018) <doi:10.1016/j.eja.2018.06.007>. \n Eberhart SA, Russell WA (1966) <doi:10.2135/cropsci1966.0011183X000600010011x>. \n Eskridge KM (1990) <doi:10.2135/cropsci1990.0011183X003000020025x>. \n Finlay KW, Wilkinson GN (1963) <doi:10.1071/AR9630742>. \n Hanson WD (1970) Genotypic stability. <doi:10.1007/BF00285245>. \n Lin CS, Binns MR (1988). \n Nassar R, H\u00fchn M (1987). \n Pinthus MJ (1973) <doi:10.1007/BF00021563>. \n R\u00f6mer T (1917). \n Shukla GK (1972). \n Wricke G (1962).   "
  },
  {
    "id": 22298,
    "package_name": "tower",
    "title": "Easy Middle Ware Library for 'shiny'",
    "description": "The best way to implement middle ware for 'shiny' Applications. 'tower'\n    is designed to make implementing behavior on top of 'shiny' easy with a layering\n    model for incoming HTTP requests and server sessions. 'tower' is a very minimal\n    package with little overhead, it is mainly meant for other package developers\n    to implement new behavior.",
    "version": "0.2.0",
    "maintainer": "Andres Quintero <andres@ixpantia.com>",
    "author": "ixpantia, SRL [cph],\n  Andres Quintero [aut, cre]",
    "url": "https://github.com/ixpantia/tower",
    "bug_reports": "https://github.com/ixpantia/tower/issues",
    "repository": "https://cran.r-project.org/package=tower",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tower Easy Middle Ware Library for 'shiny' The best way to implement middle ware for 'shiny' Applications. 'tower'\n    is designed to make implementing behavior on top of 'shiny' easy with a layering\n    model for incoming HTTP requests and server sessions. 'tower' is a very minimal\n    package with little overhead, it is mainly meant for other package developers\n    to implement new behavior.  "
  },
  {
    "id": 22321,
    "package_name": "trackeRapp",
    "title": "Interface for the Analysis of Running, Cycling and Swimming Data\nfrom GPS-Enabled Tracking Devices",
    "description": "Provides an integrated user interface and workflow for\n             the analysis of running, cycling and swimming data from GPS-enabled\n             tracking devices through the 'trackeR' <https://CRAN.R-project.org/package=trackeR> R package.",
    "version": "1.2",
    "maintainer": "Ioannis Kosmidis <ioannis.kosmidis@warwick.ac.uk>",
    "author": "Ioannis Kosmidis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1556-0302>),\n  Robin Hornak [aut]",
    "url": "https://github.com/trackerproject/trackeRapp",
    "bug_reports": "https://github.com/trackerproject/trackeRapp/issues",
    "repository": "https://cran.r-project.org/package=trackeRapp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trackeRapp Interface for the Analysis of Running, Cycling and Swimming Data\nfrom GPS-Enabled Tracking Devices Provides an integrated user interface and workflow for\n             the analysis of running, cycling and swimming data from GPS-enabled\n             tracking devices through the 'trackeR' <https://CRAN.R-project.org/package=trackeR> R package.  "
  },
  {
    "id": 22352,
    "package_name": "transmdl",
    "title": "Semiparametric Transformation Models",
    "description": "To make the semiparametric transformation models easier to apply in real studies, \n    we introduce this R package, in which the MLE in transformation models via \n    an EM algorithm proposed by Zeng D, Lin DY(2007) <doi:10.1111/j.1369-7412.2007.00606.x> \n    and adaptive lasso method in transformation models proposed by Liu XX, Zeng \n    D(2013) <doi:10.1093/biomet/ast029> are implemented.  \n    C++ functions are used to compute complex loops. The coefficient vector and \n    cumulative baseline hazard function can be estimated, along with the \n    corresponding standard errors and P values.",
    "version": "0.1.0",
    "maintainer": "Fengyu Wen <Wenfy1207@qq.com>",
    "author": "Fengyu Wen [aut, cre],\n  Baosheng Liang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=transmdl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "transmdl Semiparametric Transformation Models To make the semiparametric transformation models easier to apply in real studies, \n    we introduce this R package, in which the MLE in transformation models via \n    an EM algorithm proposed by Zeng D, Lin DY(2007) <doi:10.1111/j.1369-7412.2007.00606.x> \n    and adaptive lasso method in transformation models proposed by Liu XX, Zeng \n    D(2013) <doi:10.1093/biomet/ast029> are implemented.  \n    C++ functions are used to compute complex loops. The coefficient vector and \n    cumulative baseline hazard function can be estimated, along with the \n    corresponding standard errors and P values.  "
  },
  {
    "id": 22365,
    "package_name": "trdist",
    "title": "Univariate Proability Distributions with Truncation",
    "description": "Truncation of univariate probability distributions. The probability distribution can come from other packages so long as the function names follow the standard d, p, q, r naming format. Also other univariate probability distributions are included. ",
    "version": "1.0.1",
    "maintainer": "Jared Studyvin <studyvinstat@gmail.com>",
    "author": "Jared Studyvin [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=trdist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trdist Univariate Proability Distributions with Truncation Truncation of univariate probability distributions. The probability distribution can come from other packages so long as the function names follow the standard d, p, q, r naming format. Also other univariate probability distributions are included.   "
  },
  {
    "id": 22367,
    "package_name": "treats",
    "title": "Trees and Traits Simulations",
    "description": "A modular package for simulating phylogenetic trees and species traits jointly. Trees can be simulated using modular birth-death parameters (e.g. changing starting parameters or algorithm rules). Traits can be simulated in any way designed by the user. The growth of the tree and the traits can influence each other through modifiers objects providing rules for affecting each other. Finally, events can be created to modify both the tree and the traits under specific conditions ( Guillerme, 2024 <DOI:10.1111/2041-210X.14306>).",
    "version": "1.1.6",
    "maintainer": "Thomas Guillerme <guillert@tcd.ie>",
    "author": "Thomas Guillerme [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4325-1275>)",
    "url": "https://github.com/TGuillerme/treats",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=treats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "treats Trees and Traits Simulations A modular package for simulating phylogenetic trees and species traits jointly. Trees can be simulated using modular birth-death parameters (e.g. changing starting parameters or algorithm rules). Traits can be simulated in any way designed by the user. The growth of the tree and the traits can influence each other through modifiers objects providing rules for affecting each other. Finally, events can be created to modify both the tree and the traits under specific conditions ( Guillerme, 2024 <DOI:10.1111/2041-210X.14306>).  "
  },
  {
    "id": 22373,
    "package_name": "treeDbalance",
    "title": "Computation of 3D Tree Imbalance",
    "description": "The main goal of the R package 'treeDbalance' is to provide\n    functions for the computation of several measurements of 3D node\n    imbalance and their respective 3D tree imbalance indices, as well as to\n    introduce the new 'phylo3D' format for rooted 3D tree objects.\n    Moreover, it encompasses an example dataset of 3D models of 63 beans \n    in 'phylo3D' format. Please note that this R package was developed \n    alongside the project described in the manuscript 'Measuring 3D tree \n    imbalance of plant models using graph-theoretical approaches' by \n    M. Fischer, S. Kersting, and L. K\u00fchn (2023) <arXiv:2307.14537>, which \n    provides precise mathematical definitions of the measurements.  \n    Furthermore, the package contains several helpful functions, for example, \n    some auxiliary functions for computing the ancestors, descendants, and \n    depths of the nodes, which ensures that the computations can be done in \n    linear time.  \n    Most functions of 'treeDbalance' require as input a rooted tree in the \n    'phylo3D' format, an extended 'phylo' format (as introduced in the R package\n    'ape' 1.9 in November 2006). Such a 'phylo3D' object must have at least \n    two new attributes next to those required by the 'phylo' format: \n    'node.coord', the coordinates of the nodes, as well as 'edge.weight', \n    the literal weight or volume of the edges.  \n    Optional attributes are 'edge.diam', the diameter of the edges, and\n    'edge.length', the length of the edges. For visualization purposes one\n    can also specify 'edge.type', which ranges from normal cylinder to bud\n    to leaf, as well as 'edge.color' to change the color of the edge depiction.  \n    This project was supported by the joint research project DIG-IT! \n    funded by the European Social Fund (ESF), reference:\n    ESF/14-BM-A55-0017/19, and the Ministry of Education, Science and\n    Culture of Mecklenburg-Western Pomerania, Germany, as well as by the\n    the project ArtIGROW, which is a part of the WIR!-Alliance 'ArtIFARM \u2013 \n    Artificial Intelligence in Farming' funded by the German Federal Ministry \n    of Education and Research (FKZ: 03WIR4805).",
    "version": "1.0.1",
    "maintainer": "Sophie Kersting <sophie_kersting@gmx.de>",
    "author": "Mareike Fischer [aut],\n  Sophie Kersting [aut, cre],\n  Luise K\u00fchn [aut],\n  Jule M\u00f6ller [ctr]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=treeDbalance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "treeDbalance Computation of 3D Tree Imbalance The main goal of the R package 'treeDbalance' is to provide\n    functions for the computation of several measurements of 3D node\n    imbalance and their respective 3D tree imbalance indices, as well as to\n    introduce the new 'phylo3D' format for rooted 3D tree objects.\n    Moreover, it encompasses an example dataset of 3D models of 63 beans \n    in 'phylo3D' format. Please note that this R package was developed \n    alongside the project described in the manuscript 'Measuring 3D tree \n    imbalance of plant models using graph-theoretical approaches' by \n    M. Fischer, S. Kersting, and L. K\u00fchn (2023) <arXiv:2307.14537>, which \n    provides precise mathematical definitions of the measurements.  \n    Furthermore, the package contains several helpful functions, for example, \n    some auxiliary functions for computing the ancestors, descendants, and \n    depths of the nodes, which ensures that the computations can be done in \n    linear time.  \n    Most functions of 'treeDbalance' require as input a rooted tree in the \n    'phylo3D' format, an extended 'phylo' format (as introduced in the R package\n    'ape' 1.9 in November 2006). Such a 'phylo3D' object must have at least \n    two new attributes next to those required by the 'phylo' format: \n    'node.coord', the coordinates of the nodes, as well as 'edge.weight', \n    the literal weight or volume of the edges.  \n    Optional attributes are 'edge.diam', the diameter of the edges, and\n    'edge.length', the length of the edges. For visualization purposes one\n    can also specify 'edge.type', which ranges from normal cylinder to bud\n    to leaf, as well as 'edge.color' to change the color of the edge depiction.  \n    This project was supported by the joint research project DIG-IT! \n    funded by the European Social Fund (ESF), reference:\n    ESF/14-BM-A55-0017/19, and the Ministry of Education, Science and\n    Culture of Mecklenburg-Western Pomerania, Germany, as well as by the\n    the project ArtIGROW, which is a part of the WIR!-Alliance 'ArtIFARM \u2013 \n    Artificial Intelligence in Farming' funded by the German Federal Ministry \n    of Education and Research (FKZ: 03WIR4805).  "
  },
  {
    "id": 22412,
    "package_name": "trip",
    "title": "Tracking Data",
    "description": "Access and manipulate spatial tracking data, with straightforward \n coercion from and to other formats. Filter for speed and create time spent \n maps from tracking data. There are coercion methods to convert between 'trip'\n and 'ltraj' from 'adehabitatLT', and between 'trip' and 'psp' and 'ppp' from \n 'spatstat'. Trip objects can be created from raw or grouped data frames, and \n from types in the 'sp', sf', 'amt', 'trackeR', 'mousetrap', and other packages, \n Sumner, MD (2011) <https://figshare.utas.edu.au/articles/thesis/The_tag_location_problem/23209538>.",
    "version": "1.10.0",
    "maintainer": "Michael D. Sumner <mdsumner@gmail.com>",
    "author": "Michael D. Sumner [aut, cre],\n  Sebastian Luque [ctb],\n  Anthony Fischbach [ctb],\n  Tomislav Hengl [ctb]",
    "url": "https://github.com/Trackage/trip",
    "bug_reports": "https://github.com/Trackage/trip/issues",
    "repository": "https://cran.r-project.org/package=trip",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trip Tracking Data Access and manipulate spatial tracking data, with straightforward \n coercion from and to other formats. Filter for speed and create time spent \n maps from tracking data. There are coercion methods to convert between 'trip'\n and 'ltraj' from 'adehabitatLT', and between 'trip' and 'psp' and 'ppp' from \n 'spatstat'. Trip objects can be created from raw or grouped data frames, and \n from types in the 'sp', sf', 'amt', 'trackeR', 'mousetrap', and other packages, \n Sumner, MD (2011) <https://figshare.utas.edu.au/articles/thesis/The_tag_location_problem/23209538>.  "
  },
  {
    "id": 22416,
    "package_name": "triplesmatch",
    "title": "Match Triples Consisting of Two Controls and a Treated Unit or\nVice Versa",
    "description": "Attain excellent covariate balance by matching two treated units\n    and one control unit or vice versa within strata. Using such triples, as\n    opposed to also allowing pairs of treated and control units, \n    allows easier interpretation of the two possible \n    weights of observations and better insensitivity to unmeasured bias in the test\n    statistic. Using triples instead of matching in a fixed 1:2 or 2:1 ratio\n    allows for the match to be feasible in more situations.\n    The 'rrelaxiv' package, which provides an alternative solver for the underlying \n    network flow problems, carries an academic license and is not available on CRAN, but\n    may be downloaded from 'GitHub' at <https://github.com/josherrickson/rrelaxiv/>.\n    The 'Gurobi' commercial optimization software is required to use the two functions\n    [infsentrip()] and [triplesIP()]. These functions are not essential\n    to the main purpose of this package. A free academic license can be obtained at \n    <https://www.gurobi.com/features/academic-named-user-license/>. \n    The 'gurobi' R package can then be installed following \n    the instructions at <https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html>.",
    "version": "1.1.0",
    "maintainer": "Katherine Brumberg <kbrum@umich.edu>",
    "author": "Katherine Brumberg [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=triplesmatch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "triplesmatch Match Triples Consisting of Two Controls and a Treated Unit or\nVice Versa Attain excellent covariate balance by matching two treated units\n    and one control unit or vice versa within strata. Using such triples, as\n    opposed to also allowing pairs of treated and control units, \n    allows easier interpretation of the two possible \n    weights of observations and better insensitivity to unmeasured bias in the test\n    statistic. Using triples instead of matching in a fixed 1:2 or 2:1 ratio\n    allows for the match to be feasible in more situations.\n    The 'rrelaxiv' package, which provides an alternative solver for the underlying \n    network flow problems, carries an academic license and is not available on CRAN, but\n    may be downloaded from 'GitHub' at <https://github.com/josherrickson/rrelaxiv/>.\n    The 'Gurobi' commercial optimization software is required to use the two functions\n    [infsentrip()] and [triplesIP()]. These functions are not essential\n    to the main purpose of this package. A free academic license can be obtained at \n    <https://www.gurobi.com/features/academic-named-user-license/>. \n    The 'gurobi' R package can then be installed following \n    the instructions at <https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html>.  "
  },
  {
    "id": 22457,
    "package_name": "tsensembler",
    "title": "Dynamic Ensembles for Time Series Forecasting",
    "description": "A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. \"Arbitrated Ensemble for Time Series Forecasting.\" to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: \"Arbitrated Ensemble for Solar Radiation Forecasting.\" International Work-Conference on Artificial Neural Networks. Springer, 2017 <doi:10.1007/978-3-319-59153-7_62>.",
    "version": "0.1.0",
    "maintainer": "Vitor Cerqueira <cerqueira.vitormanuel@gmail.com>",
    "author": "Vitor Cerqueira [aut, cre],\n  Luis Torgo [ctb],\n  Carlos Soares [ctb]",
    "url": "https://github.com/vcerqueira/tsensembler",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tsensembler",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsensembler Dynamic Ensembles for Time Series Forecasting A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. \"Arbitrated Ensemble for Time Series Forecasting.\" to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: \"Arbitrated Ensemble for Solar Radiation Forecasting.\" International Work-Conference on Artificial Neural Networks. Springer, 2017 <doi:10.1007/978-3-319-59153-7_62>.  "
  },
  {
    "id": 22519,
    "package_name": "turkeyelections",
    "title": "The Most Comprehensive R Package for Turkish Election Results",
    "description": "Includes the results of general, local, and presidential elections held in Turkey between 1995 and 2024, broken down by provinces and overall national results. It facilitates easy processing of this data and the creation of visual representations based on these election results.",
    "version": "0.1.4",
    "maintainer": "Ozancan Ozdemir <ozancanozdemir@gmail.com>",
    "author": "Ozancan Ozdemir [aut, cre]",
    "url": "https://github.com/ozancanozdemir/turkeyelections",
    "bug_reports": "https://github.com/ozancanozdemir/turkeyelections/issues",
    "repository": "https://cran.r-project.org/package=turkeyelections",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "turkeyelections The Most Comprehensive R Package for Turkish Election Results Includes the results of general, local, and presidential elections held in Turkey between 1995 and 2024, broken down by provinces and overall national results. It facilitates easy processing of this data and the creation of visual representations based on these election results.  "
  },
  {
    "id": 22668,
    "package_name": "upset.hp",
    "title": "Generate UpSet Plots of VP and HP Based on the ASV Concept",
    "description": "Using matrix layout to visualize the unique, common, or individual contribution of each predictor (or matrix of predictors) towards explained variation on different models. These contributions were derived from variation partitioning (VP) and hierarchical partitioning (HP), applying the algorithm of \"Lai et al. (2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution, 13: 782-788 <doi:10.1111/2041-210X.13800>\".",
    "version": "0.0.5",
    "maintainer": "Jiangshan Lai <lai@njfu.edu.cn>",
    "author": "Jiangshan Lai [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0279-8816>),\n  Yao Liu [aut],\n  Bangken Ying [aut]",
    "url": "https://github.com/laijiangshan/upset.hp",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=upset.hp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "upset.hp Generate UpSet Plots of VP and HP Based on the ASV Concept Using matrix layout to visualize the unique, common, or individual contribution of each predictor (or matrix of predictors) towards explained variation on different models. These contributions were derived from variation partitioning (VP) and hierarchical partitioning (HP), applying the algorithm of \"Lai et al. (2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution, 13: 782-788 <doi:10.1111/2041-210X.13800>\".  "
  },
  {
    "id": 22677,
    "package_name": "urlparse",
    "title": "Fast Simple URL Parser",
    "description": "A fast and simple 'URL' parser package for 'R'. This package provides\n    functions to parse 'URLs' into their components, such as scheme, user, password, host, port,\n    path, query, and fragment.",
    "version": "0.2.1",
    "maintainer": "Dyfan Jones <dyfan.r.jones@gmail.com>",
    "author": "Dyfan Jones [aut, cre]",
    "url": "https://github.com/dyfanjones/urlparse,\nhttps://dyfanjones.r-universe.dev/urlparse",
    "bug_reports": "https://github.com/dyfanjones/urlparse/issues",
    "repository": "https://cran.r-project.org/package=urlparse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "urlparse Fast Simple URL Parser A fast and simple 'URL' parser package for 'R'. This package provides\n    functions to parse 'URLs' into their components, such as scheme, user, password, host, port,\n    path, query, and fragment.  "
  },
  {
    "id": 22695,
    "package_name": "usefun",
    "title": "A Collection of Useful Functions by John",
    "description": "A set of general functions that I have used in various\n    projects and other R packages. Miscellaneous operations on data\n    frames, matrices and vectors, ROC and PR statistics.",
    "version": "0.5.2",
    "maintainer": "John Zobolas <bblodfon@gmail.com>",
    "author": "John Zobolas [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0002-3609-8674>)",
    "url": "https://github.com/bblodfon/usefun",
    "bug_reports": "https://github.com/bblodfon/usefun/issues",
    "repository": "https://cran.r-project.org/package=usefun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "usefun A Collection of Useful Functions by John A set of general functions that I have used in various\n    projects and other R packages. Miscellaneous operations on data\n    frames, matrices and vectors, ROC and PR statistics.  "
  },
  {
    "id": 22729,
    "package_name": "vaersNDvax",
    "title": "Non-Domestic Vaccine Adverse Event Reporting System (VAERS)\nVaccine Data for Present",
    "description": "Non-Domestic VAERS vaccine data for 01/01/2016 - 06/14/2016. If\n    you want to explore the full VAERS data for 1990 - Present (data, symptoms,\n    and vaccines), then check out the 'vaersND' package from the URL below. The\n    URL and BugReports below correspond to the 'vaersND' package, of which\n    'vaersNDvax' is a small subset (2016 only). 'vaersND' is not hosted on CRAN\n    due to the large size of the data set. To install the Suggested 'vaers' and\n    'vaersND' packages, use the following R code:\n    'devtools::install_git(\"https://gitlab.com/iembry/vaers.git\",\n    build_vignettes = TRUE)' and\n    'devtools::install_git(\"https://gitlab.com/iembry/vaersND.git\",\n    build_vignettes = TRUE)'. \"VAERS is a national vaccine safety\n    surveillance program co-sponsored by the US Centers for Disease Control and\n    Prevention (CDC) and the US Food and Drug Administration (FDA). VAERS is a\n    post-marketing safety surveillance program, collecting information about\n    adverse events (possible side effects) that occur after the administration\n    of vaccines licensed for use in the United States.\" For more information\n    about the data, visit <https://vaers.hhs.gov/index>. For information about\n    vaccination/immunization hazards, visit\n    <http://www.questionuniverse.com/rethink.html/#vaccine>.",
    "version": "1.0.4",
    "maintainer": "Irucka Embry <iembry@ecoccs.com>",
    "author": "Irucka Embry [aut, cre]",
    "url": "https://gitlab.com/iembry/vaersND",
    "bug_reports": "https://gitlab.com/iembry/vaersND/issues",
    "repository": "https://cran.r-project.org/package=vaersNDvax",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vaersNDvax Non-Domestic Vaccine Adverse Event Reporting System (VAERS)\nVaccine Data for Present Non-Domestic VAERS vaccine data for 01/01/2016 - 06/14/2016. If\n    you want to explore the full VAERS data for 1990 - Present (data, symptoms,\n    and vaccines), then check out the 'vaersND' package from the URL below. The\n    URL and BugReports below correspond to the 'vaersND' package, of which\n    'vaersNDvax' is a small subset (2016 only). 'vaersND' is not hosted on CRAN\n    due to the large size of the data set. To install the Suggested 'vaers' and\n    'vaersND' packages, use the following R code:\n    'devtools::install_git(\"https://gitlab.com/iembry/vaers.git\",\n    build_vignettes = TRUE)' and\n    'devtools::install_git(\"https://gitlab.com/iembry/vaersND.git\",\n    build_vignettes = TRUE)'. \"VAERS is a national vaccine safety\n    surveillance program co-sponsored by the US Centers for Disease Control and\n    Prevention (CDC) and the US Food and Drug Administration (FDA). VAERS is a\n    post-marketing safety surveillance program, collecting information about\n    adverse events (possible side effects) that occur after the administration\n    of vaccines licensed for use in the United States.\" For more information\n    about the data, visit <https://vaers.hhs.gov/index>. For information about\n    vaccination/immunization hazards, visit\n    <http://www.questionuniverse.com/rethink.html/#vaccine>.  "
  },
  {
    "id": 22730,
    "package_name": "vaersvax",
    "title": "US Vaccine Adverse Event Reporting System (VAERS) Vaccine Data\nfor Present",
    "description": "US VAERS vaccine data for 01/01/2018 - 06/14/2018. If you want to\n    explore the full VAERS data for 1990 - Present (data, symptoms, and\n    vaccines), then check out the 'vaers' package from the URL below. The URL\n    and BugReports below correspond to the 'vaers' package, of which 'vaersvax'\n    is a small subset (2018 only). 'vaers' is not hosted on CRAN due to the\n    large size of the data set. To install the Suggested 'vaers' and 'vaersND'\n    packages, use the following R code:\n    'devtools::install_git(\"<https://gitlab.com/iembry/vaers.git>\",\n    build_vignettes = TRUE)' and\n    'devtools::install_git(\"<https://gitlab.com/iembry/vaersND.git>\",\n    build_vignettes = TRUE)'. \"The Vaccine Adverse Event Reporting System (VAERS)\n    is a national early warning system to detect possible safety problems in\n    U.S.-licensed vaccines. VAERS is co-managed by the Centers for Disease Control\n    and Prevention (CDC) and the U.S. Food and Drug Administration (FDA).\" For\n    more information about the data, visit <https://vaers.hhs.gov/>. For\n    information about\n    vaccination/immunization hazards, visit\n    <http://www.questionuniverse.com/rethink.html#vaccine>.",
    "version": "1.0.5",
    "maintainer": "Irucka Embry <iembry@ecoccs.com>",
    "author": "Irucka Embry [aut, cre]",
    "url": "https://gitlab.com/iembry/vaers",
    "bug_reports": "https://gitlab.com/iembry/vaers/issues",
    "repository": "https://cran.r-project.org/package=vaersvax",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vaersvax US Vaccine Adverse Event Reporting System (VAERS) Vaccine Data\nfor Present US VAERS vaccine data for 01/01/2018 - 06/14/2018. If you want to\n    explore the full VAERS data for 1990 - Present (data, symptoms, and\n    vaccines), then check out the 'vaers' package from the URL below. The URL\n    and BugReports below correspond to the 'vaers' package, of which 'vaersvax'\n    is a small subset (2018 only). 'vaers' is not hosted on CRAN due to the\n    large size of the data set. To install the Suggested 'vaers' and 'vaersND'\n    packages, use the following R code:\n    'devtools::install_git(\"<https://gitlab.com/iembry/vaers.git>\",\n    build_vignettes = TRUE)' and\n    'devtools::install_git(\"<https://gitlab.com/iembry/vaersND.git>\",\n    build_vignettes = TRUE)'. \"The Vaccine Adverse Event Reporting System (VAERS)\n    is a national early warning system to detect possible safety problems in\n    U.S.-licensed vaccines. VAERS is co-managed by the Centers for Disease Control\n    and Prevention (CDC) and the U.S. Food and Drug Administration (FDA).\" For\n    more information about the data, visit <https://vaers.hhs.gov/>. For\n    information about\n    vaccination/immunization hazards, visit\n    <http://www.questionuniverse.com/rethink.html#vaccine>.  "
  },
  {
    "id": 22735,
    "package_name": "valentine",
    "title": "Spread the Love for R Packages with Poetry",
    "description": "Uses large language models to create poems about R packages.\n   Currently contains the roses() function to make \"roses are red, ...\" style \n   poems and the prompt() function to only assemble the prompt without submitting \n   it to the model.",
    "version": "2025.2.14",
    "maintainer": "Romain Fran\u00e7ois <romain@tada.science>",
    "author": "Romain Fran\u00e7ois [aut, cre]",
    "url": "https://github.com/tadascience/valentine,\nhttps://valentine.tada.science/",
    "bug_reports": "https://github.com/tadascience/valentine/issues",
    "repository": "https://cran.r-project.org/package=valentine",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "valentine Spread the Love for R Packages with Poetry Uses large language models to create poems about R packages.\n   Currently contains the roses() function to make \"roses are red, ...\" style \n   poems and the prompt() function to only assemble the prompt without submitting \n   it to the model.  "
  },
  {
    "id": 22809,
    "package_name": "vegIndexCalc",
    "title": "Vegetation Indices (VIs) Calculation for Remote Sensing Analysis",
    "description": "It provides a comprehensive toolkit for calculating a suite of common vegetation indices (VIs) derived from remote sensing imagery. VIs are essential tools used to quantify vegetation characteristics, such as biomass, leaf area index (LAI) and photosynthetic activity, which are essential parameters in various ecological, agricultural, and environmental studies. Applications of this package include biomass estimation, crop monitoring, forest management, land use and land cover change analysis and climate change studies. For method details see, Deb,D.,Deb,S.,Chakraborty,D.,Singh,J.P.,Singh,A.K.,Dutta,P.and Choudhury,A.(2020)<doi:10.1080/10106049.2020.1756461>. Utilizing this R package, users can effectively extract and analyze critical information from remote sensing imagery, enhancing their comprehension of vegetation dynamics and their importance in global ecosystems. The package includes the function vegetation_indices().",
    "version": "0.1.0",
    "maintainer": "Bijoy Chanda <bijoychanda08@gmail.com>",
    "author": "Dibyendu Deb [aut, ctb],\n  Arpan Bhowmik [aut, ctb],\n  Bijoy Chanda [aut, cre, ctb],\n  J.P. Singh [aut],\n  Sunil Mandi [aut],\n  Alemwati Pongener [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vegIndexCalc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vegIndexCalc Vegetation Indices (VIs) Calculation for Remote Sensing Analysis It provides a comprehensive toolkit for calculating a suite of common vegetation indices (VIs) derived from remote sensing imagery. VIs are essential tools used to quantify vegetation characteristics, such as biomass, leaf area index (LAI) and photosynthetic activity, which are essential parameters in various ecological, agricultural, and environmental studies. Applications of this package include biomass estimation, crop monitoring, forest management, land use and land cover change analysis and climate change studies. For method details see, Deb,D.,Deb,S.,Chakraborty,D.,Singh,J.P.,Singh,A.K.,Dutta,P.and Choudhury,A.(2020)<doi:10.1080/10106049.2020.1756461>. Utilizing this R package, users can effectively extract and analyze critical information from remote sensing imagery, enhancing their comprehension of vegetation dynamics and their importance in global ecosystems. The package includes the function vegetation_indices().  "
  },
  {
    "id": 22834,
    "package_name": "versions",
    "title": "Query and Install Specific Versions of Packages on CRAN",
    "description": "Installs specified versions of R packages hosted on CRAN and\n    provides functions to list available versions and the versions of currently\n    installed packages. These tools can be used to help make R projects and\n    packages more reproducible. 'versions' fits in the narrow gap between\n    the 'devtools' install_version() function and the 'checkpoint' package.\n    devtools::install_version() installs a stated package version from source files\n    stored on the CRAN archives. However CRAN does not store binary versions of\n    packages so Windows users need to have RTools installed and Windows and OSX\n    users get longer installation times. 'checkpoint' uses the Revolution Analytics\n    MRAN server to install packages (from source or binary) as they were available\n    on a given date. It also provides a helpful interface to detect the packages\n    in use in a directory and install all of those packages for a given date.\n    'checkpoint' doesn't provide install.packages-like functionality however, and\n    that's what 'versions' aims to do, by querying MRAN. As MRAN only goes back to\n    2014-09-17, 'versions' can't install packages archived before this date.",
    "version": "0.3",
    "maintainer": "Nick Golding <nick.golding.research@gmail.com>",
    "author": "Nick Golding",
    "url": "",
    "bug_reports": "https://github.com/goldingn/versions/issues",
    "repository": "https://cran.r-project.org/package=versions",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "versions Query and Install Specific Versions of Packages on CRAN Installs specified versions of R packages hosted on CRAN and\n    provides functions to list available versions and the versions of currently\n    installed packages. These tools can be used to help make R projects and\n    packages more reproducible. 'versions' fits in the narrow gap between\n    the 'devtools' install_version() function and the 'checkpoint' package.\n    devtools::install_version() installs a stated package version from source files\n    stored on the CRAN archives. However CRAN does not store binary versions of\n    packages so Windows users need to have RTools installed and Windows and OSX\n    users get longer installation times. 'checkpoint' uses the Revolution Analytics\n    MRAN server to install packages (from source or binary) as they were available\n    on a given date. It also provides a helpful interface to detect the packages\n    in use in a directory and install all of those packages for a given date.\n    'checkpoint' doesn't provide install.packages-like functionality however, and\n    that's what 'versions' aims to do, by querying MRAN. As MRAN only goes back to\n    2014-09-17, 'versions' can't install packages archived before this date.  "
  },
  {
    "id": 22847,
    "package_name": "vibass",
    "title": "Materials for Introductory Course on Bayesian Learning",
    "description": "Practicals, data sets, helper functions and interactive 'Shiny' apps\n    used in the introductory course on Bayesian inference at the\n    Valencia International Bayesian Summer School. Installing 'vibass' installs\n    all the other packages used during the course and downloads all necessary\n    materials for working off line.",
    "version": "1.0.3",
    "maintainer": "Facundo Mu\u00f1oz <facundo.munoz@cirad.fr>",
    "author": "VIBASS Team [aut, cph],\n  Facundo Mu\u00f1oz [ctb, cre] (Cirad, Package developer, ORCID:\n    <https://orcid.org/0000-0002-5061-4241>),\n  Carmen Armero [ctb] (Universitat de Val\u00e8ncia),\n  Anabel Forte [ctb] (Universitat de Val\u00e8ncia),\n  David Conesa [ctb] (Universitat de Val\u00e8ncia),\n  Mark Brewer [ctb] (Biomathematics and Statistics Scotland (BioSS),\n    ORCID: <https://orcid.org/0000-0001-7559-389X>),\n  Virgilio G\u00f3mez-Rubio [ctb] (Universidad Castilla-La Mancha, ORCID:\n    <https://orcid.org/0000-0002-4791-3072>)",
    "url": "http://vabar.es/vibass/, https://github.com/VABAR/vibass",
    "bug_reports": "https://github.com/VABAR/vibass/issues",
    "repository": "https://cran.r-project.org/package=vibass",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vibass Materials for Introductory Course on Bayesian Learning Practicals, data sets, helper functions and interactive 'Shiny' apps\n    used in the introductory course on Bayesian inference at the\n    Valencia International Bayesian Summer School. Installing 'vibass' installs\n    all the other packages used during the course and downloads all necessary\n    materials for working off line.  "
  },
  {
    "id": 22916,
    "package_name": "volcanoPlot",
    "title": "Volcano Plot for Clinical Trial Adverse Events",
    "description": "Interactive adverse event (AE) volcano plot for monitoring clinical trial safety. This tool allows users to view the overall distribution of AEs in a clinical trial using standard (e.g. MedDRA preferred term) or custom (e.g. Gender) categories using a volcano plot similar to proposal by Zink et al. (2013) <doi:10.1177/1740774513485311>. This tool provides a stand-along shiny application and flexible shiny modules allowing this tool to be used as a part of more robust safety monitoring framework like the Shiny app from the 'safetyGraphics' R package. ",
    "version": "1.0.0",
    "maintainer": "Jeremy Wildfire <jwildfire@gmail.com>",
    "author": "Jeremy Wildfire [cre, aut],\n  Becca Krouse [aut],\n  Natalia Andriychuk [aut],\n  Anh Tran [aut],\n  Isaac Zhao [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=volcanoPlot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "volcanoPlot Volcano Plot for Clinical Trial Adverse Events Interactive adverse event (AE) volcano plot for monitoring clinical trial safety. This tool allows users to view the overall distribution of AEs in a clinical trial using standard (e.g. MedDRA preferred term) or custom (e.g. Gender) categories using a volcano plot similar to proposal by Zink et al. (2013) <doi:10.1177/1740774513485311>. This tool provides a stand-along shiny application and flexible shiny modules allowing this tool to be used as a part of more robust safety monitoring framework like the Shiny app from the 'safetyGraphics' R package.   "
  },
  {
    "id": 22923,
    "package_name": "vortexRdata",
    "title": "Example Data for R Package 'vortexR'",
    "description": "Contains selected data from two publications,\n    Campbell 'et' 'al'. (2016) <DOI:10.1080/14486563.2015.1028486>\n    and 'Pacioni' 'et' 'al'. (2017) <DOI:10.1071/PC17002>.\n    The data is provided both as raw outputs from the population viability\n    analysis software 'Vortex' and packaged as R objects.\n    The R package 'vortexR' uses the raw data provided here to illustrate its\n    functionality of parsing raw 'Vortex' output into R objects.",
    "version": "1.0.5",
    "maintainer": "Carlo Pacioni <C.Pacioni@Murdoch.edu.au>",
    "author": "Carlo Pacioni [aut, cre],\n  Florian W. Mayer [aut]",
    "url": "https://github.com/carlopacioni/vortexRdata/",
    "bug_reports": "https://github.com/carlopacioni/vortexR/issues",
    "repository": "https://cran.r-project.org/package=vortexRdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vortexRdata Example Data for R Package 'vortexR' Contains selected data from two publications,\n    Campbell 'et' 'al'. (2016) <DOI:10.1080/14486563.2015.1028486>\n    and 'Pacioni' 'et' 'al'. (2017) <DOI:10.1071/PC17002>.\n    The data is provided both as raw outputs from the population viability\n    analysis software 'Vortex' and packaged as R objects.\n    The R package 'vortexR' uses the raw data provided here to illustrate its\n    functionality of parsing raw 'Vortex' output into R objects.  "
  },
  {
    "id": 22952,
    "package_name": "vvbitwarden",
    "title": "Interacts with 'Bitwarden Secrets Manager'",
    "description": "Provides functions to securely retrieve secrets from a 'Bitwarden Secrets Manager' vault using the \n              'Bitwarden CLI', enabling secret and configuration management within R packages and workflows. \n              For more information visit <https://bitwarden.com/products/secrets-manager/>.",
    "version": "0.1.0",
    "maintainer": "Hajo Bons <h.b.bons@vu.nl>",
    "author": "Hajo Bons [aut, cre],\n  Tomer Iwan [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vvbitwarden",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vvbitwarden Interacts with 'Bitwarden Secrets Manager' Provides functions to securely retrieve secrets from a 'Bitwarden Secrets Manager' vault using the \n              'Bitwarden CLI', enabling secret and configuration management within R packages and workflows. \n              For more information visit <https://bitwarden.com/products/secrets-manager/>.  "
  },
  {
    "id": 23020,
    "package_name": "wconf",
    "title": "Weighted Confusion Matrix",
    "description": "Allows users to create weighted confusion matrices and accuracy\n    metrics that help with the model selection process for classification\n    problems, where distance from the correct category is important. The\n    package includes several weighting schemes which can be parameterized, as\n    well as custom configuration options. Furthermore, users can decide\n    whether they wish to positively or negatively affect the accuracy score\n    as a result of applying weights to the confusion matrix. Functions are\n    included to calculate accuracy metrics for imbalanced data. Finally,\n    'wconf' integrates well with the 'caret' package, but it can also work\n    standalone when provided data in matrix form.\n    References:\n    Kuhn, M. (2008) \"Building Perspective Models in R Using the caret Package\"\n    <doi:10.18637/jss.v028.i05>\n    Monahov, A. (2021) \"Model Evaluation with Weighted Threshold Optimization\n    (and the mewto R package)\" <doi:10.2139/ssrn.3805911>\n    Monahov, A. (2024) \"Improved Accuracy Metrics for Classification with\n    Imbalanced Data and Where Distance from the Truth Matters, with the wconf R\n    Package\" <doi:10.2139/ssrn.4802336>\n    Starovoitov, V., Golub, Y. (2020). New Function for Estimating Imbalanced\n    Data Classification Results. Pattern Recognition and Image Analysis, 295\u2013302\n    Van de Velden, M., Iodice D'Enza, A., Markos, A., Cavicchia, C. (2023)\n    \"A general framework for implementing distances for categorical variables\"\n    <doi:10.48550/arXiv.2301.02190>.",
    "version": "1.2.0",
    "maintainer": "Alexandru Monahov <alexandru.monahov@proton.me>",
    "author": "Alexandru Monahov [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-6204-9131>)",
    "url": "https://www.alexandrumonahov.eu.org/projects",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wconf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wconf Weighted Confusion Matrix Allows users to create weighted confusion matrices and accuracy\n    metrics that help with the model selection process for classification\n    problems, where distance from the correct category is important. The\n    package includes several weighting schemes which can be parameterized, as\n    well as custom configuration options. Furthermore, users can decide\n    whether they wish to positively or negatively affect the accuracy score\n    as a result of applying weights to the confusion matrix. Functions are\n    included to calculate accuracy metrics for imbalanced data. Finally,\n    'wconf' integrates well with the 'caret' package, but it can also work\n    standalone when provided data in matrix form.\n    References:\n    Kuhn, M. (2008) \"Building Perspective Models in R Using the caret Package\"\n    <doi:10.18637/jss.v028.i05>\n    Monahov, A. (2021) \"Model Evaluation with Weighted Threshold Optimization\n    (and the mewto R package)\" <doi:10.2139/ssrn.3805911>\n    Monahov, A. (2024) \"Improved Accuracy Metrics for Classification with\n    Imbalanced Data and Where Distance from the Truth Matters, with the wconf R\n    Package\" <doi:10.2139/ssrn.4802336>\n    Starovoitov, V., Golub, Y. (2020). New Function for Estimating Imbalanced\n    Data Classification Results. Pattern Recognition and Image Analysis, 295\u2013302\n    Van de Velden, M., Iodice D'Enza, A., Markos, A., Cavicchia, C. (2023)\n    \"A general framework for implementing distances for categorical variables\"\n    <doi:10.48550/arXiv.2301.02190>.  "
  },
  {
    "id": 23026,
    "package_name": "wdpar",
    "title": "Interface to the World Database on Protected Areas",
    "description": "Fetch and clean data from the World Database on Protected\n    Areas (WDPA) and the World Database on Other Effective Area-Based\n    Conservation Measures (WDOECM). Data is obtained from Protected Planet\n    <https://www.protectedplanet.net/en>. To augment data cleaning procedures,\n    users can install the 'prepr' R package (available at\n    <https://github.com/prioritizr/prepr>). For more information on this\n    package, see Hanson (2022) <doi:10.21105/joss.04594>.",
    "version": "1.3.8",
    "maintainer": "Jeffrey O Hanson <jeffrey.hanson@uqconnect.edu.au>",
    "author": "Jeffrey O Hanson [aut, cre]",
    "url": "https://prioritizr.github.io/wdpar/,\nhttps://github.com/prioritizr/wdpar",
    "bug_reports": "https://github.com/prioritizr/wdpar/issues",
    "repository": "https://cran.r-project.org/package=wdpar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wdpar Interface to the World Database on Protected Areas Fetch and clean data from the World Database on Protected\n    Areas (WDPA) and the World Database on Other Effective Area-Based\n    Conservation Measures (WDOECM). Data is obtained from Protected Planet\n    <https://www.protectedplanet.net/en>. To augment data cleaning procedures,\n    users can install the 'prepr' R package (available at\n    <https://github.com/prioritizr/prepr>). For more information on this\n    package, see Hanson (2022) <doi:10.21105/joss.04594>.  "
  },
  {
    "id": 23089,
    "package_name": "whitewater",
    "title": "Parallel Processing Options for Package 'dataRetrieval'",
    "description": "Provides methods for retrieving United States Geological Survey (USGS) water data using sequential and parallel processing (Bengtsson, 2022 <doi:10.32614/RJ-2021-048>). In addition to parallel methods, data wrangling and additional statistical attributes are provided. ",
    "version": "0.1.3",
    "maintainer": "Josh Erickson <joshualerickson@gmail.com>",
    "author": "Josh Erickson [aut, cre, cph]",
    "url": "https://github.com/joshualerickson/whitewater/,\nhttps://joshualerickson.github.io/whitewater/",
    "bug_reports": "https://github.com/joshualerickson/whitewater/issues/",
    "repository": "https://cran.r-project.org/package=whitewater",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "whitewater Parallel Processing Options for Package 'dataRetrieval' Provides methods for retrieving United States Geological Survey (USGS) water data using sequential and parallel processing (Bengtsson, 2022 <doi:10.32614/RJ-2021-048>). In addition to parallel methods, data wrangling and additional statistical attributes are provided.   "
  },
  {
    "id": 23109,
    "package_name": "winch",
    "title": "Portable Native and Joint Stack Traces",
    "description": "Obtain the native stack trace and fuse it with R's\n    stack trace for easier debugging of R packages with native code.",
    "version": "0.1.2",
    "maintainer": "Kirill M\u00fcller <kirill@cynkra.com>",
    "author": "Kirill M\u00fcller [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1416-3412>),\n  R Consortium [fnd],\n  Ian Lance Taylor [aut] (Bundled libbacktrace library),\n  Free Software Foundation [cph] (Bundled libbacktrace library)",
    "url": "https://r-prof.github.io/winch/, https://github.com/r-prof/winch",
    "bug_reports": "https://github.com/r-prof/winch/issues",
    "repository": "https://cran.r-project.org/package=winch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "winch Portable Native and Joint Stack Traces Obtain the native stack trace and fuse it with R's\n    stack trace for easier debugging of R packages with native code.  "
  },
  {
    "id": 23146,
    "package_name": "wordpredictor",
    "title": "Develop Text Prediction Models Based on N-Grams",
    "description": "A framework for developing n-gram models for text prediction.\n    It provides data cleaning, data sampling, extracting tokens from text,\n    model generation, model evaluation and word prediction. For information on how n-gram models \n    work we referred to: \"Speech and Language Processing\"\n    <https://web.archive.org/web/20240919222934/https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fslp3%2F3.pdf>. For optimizing R code and\n    using R6 classes we referred to \"Advanced R\" \n    <https://adv-r.hadley.nz/r6.html>. For writing R extensions we referred to \n    \"R Packages\", <https://r-pkgs.org/index.html>.",
    "version": "0.0.5",
    "maintainer": "Nadir Latif <pakjiddat@gmail.com>",
    "author": "Nadir Latif [aut, cre] (ORCID: <https://orcid.org/0000-0002-7543-7405>)",
    "url": "https://github.com/pakjiddat/word-predictor,\nhttps://pakjiddat.github.io/word-predictor/",
    "bug_reports": "https://github.com/pakjiddat/word-predictor/issues",
    "repository": "https://cran.r-project.org/package=wordpredictor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wordpredictor Develop Text Prediction Models Based on N-Grams A framework for developing n-gram models for text prediction.\n    It provides data cleaning, data sampling, extracting tokens from text,\n    model generation, model evaluation and word prediction. For information on how n-gram models \n    work we referred to: \"Speech and Language Processing\"\n    <https://web.archive.org/web/20240919222934/https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fslp3%2F3.pdf>. For optimizing R code and\n    using R6 classes we referred to \"Advanced R\" \n    <https://adv-r.hadley.nz/r6.html>. For writing R extensions we referred to \n    \"R Packages\", <https://r-pkgs.org/index.html>.  "
  },
  {
    "id": 23196,
    "package_name": "wyz.code.rdoc",
    "title": "Wizardry Code Offensive Programming R Documentation",
    "description": "Allows to generate on-demand or by batch, any R documentation file,\n    whatever is kind, data, function, class or package. It populates\n    documentation sections, either automatically or by considering\n    your input. Input code could be standard R code or offensive programming code. \n    Documentation content completeness depends on the type of code you use. With\n    offensive programming code, expect generated documentation to be fully \n    completed, from a format and content point of view. With some standard R \n    code, you will have to activate post processing to fill-in any section that \n    requires complements. Produced manual page validity is automatically tested \n    against R documentation compliance rules. Documentation language \n    proficiency, wording style, and phrasal adjustments remains your job. ",
    "version": "1.1.19",
    "maintainer": "Fabien Gelineau <neonira@gmail.com>",
    "author": "Fabien Gelineau <neonira@gmail.com>",
    "url": "https://neonira.github.io/offensiveProgrammingBook_v1.2.2/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wyz.code.rdoc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wyz.code.rdoc Wizardry Code Offensive Programming R Documentation Allows to generate on-demand or by batch, any R documentation file,\n    whatever is kind, data, function, class or package. It populates\n    documentation sections, either automatically or by considering\n    your input. Input code could be standard R code or offensive programming code. \n    Documentation content completeness depends on the type of code you use. With\n    offensive programming code, expect generated documentation to be fully \n    completed, from a format and content point of view. With some standard R \n    code, you will have to activate post processing to fill-in any section that \n    requires complements. Produced manual page validity is automatically tested \n    against R documentation compliance rules. Documentation language \n    proficiency, wording style, and phrasal adjustments remains your job.   "
  },
  {
    "id": 23197,
    "package_name": "wyz.code.testthat",
    "title": "Wizardry Code Offensive Programming Test Generation",
    "description": "Allows to generate automatically 'testthat' code files from offensive \n    programming test cases. Generated test files are complete and ready to run.\n    Using 'wyz.code.testthat' you will earn a lot of time, reduce the number of\n    errors in test case production, be able to test immediately generated files \n    without any need to view or modify them, and enter a zero time latency between \n    code implementation and industrial testing. As with 'testthat', you may\n    complete provided test cases according to your needs to push testing further, \n    but this need is nearly void when using 'wyz.code.offensiveProgramming'. ",
    "version": "1.1.20",
    "maintainer": "Fabien Gelineau <neonira@gmail.com>",
    "author": "Fabien Gelineau <neonira@gmail.com>",
    "url": "https://neonira.github.io/offensiveProgrammingBook_v1.2.2/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=wyz.code.testthat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wyz.code.testthat Wizardry Code Offensive Programming Test Generation Allows to generate automatically 'testthat' code files from offensive \n    programming test cases. Generated test files are complete and ready to run.\n    Using 'wyz.code.testthat' you will earn a lot of time, reduce the number of\n    errors in test case production, be able to test immediately generated files \n    without any need to view or modify them, and enter a zero time latency between \n    code implementation and industrial testing. As with 'testthat', you may\n    complete provided test cases according to your needs to push testing further, \n    but this need is nearly void when using 'wyz.code.offensiveProgramming'.   "
  },
  {
    "id": 23199,
    "package_name": "x13binary",
    "title": "Provide the 'x13ashtml' Seasonal Adjustment Binary",
    "description": "The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.",
    "version": "1.1.61.1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Christoph Sax [aut] (ORCID: <https://orcid.org/0000-0002-7192-7044>),\n  Kirill M\u00fcller [ctb] (ORCID: <https://orcid.org/0000-0002-1416-3412>),\n  Jeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Michael Antonov [ctb]",
    "url": "https://github.com/x13org/x13binary",
    "bug_reports": "https://github.com/x13org/x13binary/issues/",
    "repository": "https://cran.r-project.org/package=x13binary",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "x13binary Provide the 'x13ashtml' Seasonal Adjustment Binary The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.  "
  },
  {
    "id": 23212,
    "package_name": "xefun",
    "title": "X-Engineering or Supporting Functions",
    "description": "Miscellaneous functions used for x-engineering (feature engineering) or \n  for supporting in other packages maintained by 'Shichen Xie'.",
    "version": "0.1.5",
    "maintainer": "Shichen Xie <xie@shichen.name>",
    "author": "Shichen Xie [aut, cre]",
    "url": "https://github.com/ShichenXie/xefun",
    "bug_reports": "https://github.com/ShichenXie/xefun/issues",
    "repository": "https://cran.r-project.org/package=xefun",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xefun X-Engineering or Supporting Functions Miscellaneous functions used for x-engineering (feature engineering) or \n  for supporting in other packages maintained by 'Shichen Xie'.  "
  },
  {
    "id": 23244,
    "package_name": "xmlwriter",
    "title": "Fast and Elegant XML Generation",
    "description": "Provides a fast and elegant interface for generating XML\n fragments and documents. It can be used in companion with R packages 'XML'\n or 'xml2' to generate XML documents. The fast XML generation is implemented using the\n 'Rcpp' package. ",
    "version": "0.1.1",
    "maintainer": "Edwin de Jonge <edwindjonge@gmail.com>",
    "author": "Edwin de Jonge [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6580-4718>)",
    "url": "https://edwindj.github.io/xmlwriter/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xmlwriter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xmlwriter Fast and Elegant XML Generation Provides a fast and elegant interface for generating XML\n fragments and documents. It can be used in companion with R packages 'XML'\n or 'xml2' to generate XML documents. The fast XML generation is implemented using the\n 'Rcpp' package.   "
  },
  {
    "id": 23250,
    "package_name": "xpectr",
    "title": "Generates Expectations for 'testthat' Unit Testing",
    "description": "Helps systematize and ease the process of \n    building unit tests with the 'testthat' package by providing \n    tools for generating expectations.",
    "version": "0.4.4",
    "maintainer": "Ludvig Renbo Olsen <r-pkgs@ludvigolsen.dk>",
    "author": "Ludvig Renbo Olsen [aut, cre] (ORCID:\n    <https://orcid.org/0009-0006-6798-7454>),\n  R. Mark Sharp [ctb]",
    "url": "https://github.com/ludvigolsen/xpectr",
    "bug_reports": "https://github.com/ludvigolsen/xpectr/issues",
    "repository": "https://cran.r-project.org/package=xpectr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xpectr Generates Expectations for 'testthat' Unit Testing Helps systematize and ease the process of \n    building unit tests with the 'testthat' package by providing \n    tools for generating expectations.  "
  },
  {
    "id": 23289,
    "package_name": "ympes",
    "title": "Collection of Helper Functions",
    "description": "Provides a collection of lightweight helper functions (imps) both\n  for interactive use and for inclusion within other packages. These include\n  functions for minimal input assertions, visualising colour palettes,\n  quoting user input, searching rows of a data frame and capturing string\n  tokens.",
    "version": "1.9.0",
    "maintainer": "Tim Taylor <tim.taylor@hiddenelephants.co.uk>",
    "author": "Tim Taylor [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-8587-7113>),\n  R Core Team [cph] (fstrcapture uses code from strcapture),\n  Toby Hocking [cph] (fstrcapture uses code from nc::capture_first_vec)",
    "url": "https://timtaylor.github.io/ympes/",
    "bug_reports": "https://github.com/TimTaylor/ympes/issues",
    "repository": "https://cran.r-project.org/package=ympes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ympes Collection of Helper Functions Provides a collection of lightweight helper functions (imps) both\n  for interactive use and for inclusion within other packages. These include\n  functions for minimal input assertions, visualising colour palettes,\n  quoting user input, searching rows of a data frame and capturing string\n  tokens.  "
  },
  {
    "id": 23311,
    "package_name": "zenplots",
    "title": "Zigzag Expanded Navigation Plots",
    "description": "Graphical tools for visualizing high-dimensional data along a\n    path of alternating one- and two-dimensional plots. Includes optional\n    interactive graphics via 'loon' (which uses 'tcltk' from base R).\n    Support is provided for constructing graph structures and, when\n    available, plotting them with Bioconductor packages (e.g., 'graph',\n    'Rgraphviz'); these are optional and examples/vignettes are skipped if\n    they are not installed. For algorithms and further details, see\n    <doi:10.18637/jss.v095.i04>.",
    "version": "1.0.7",
    "maintainer": "Wayne Oldford <rwoldford@uwaterloo.ca>",
    "author": "Marius Hofert [aut],\n  Wayne Oldford [aut, cre]",
    "url": "https://great-northern-diver.github.io/zenplots/,\nhttps://github.com/great-northern-diver/zenplots/",
    "bug_reports": "https://github.com/great-northern-diver/zenplots/issues",
    "repository": "https://cran.r-project.org/package=zenplots",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zenplots Zigzag Expanded Navigation Plots Graphical tools for visualizing high-dimensional data along a\n    path of alternating one- and two-dimensional plots. Includes optional\n    interactive graphics via 'loon' (which uses 'tcltk' from base R).\n    Support is provided for constructing graph structures and, when\n    available, plotting them with Bioconductor packages (e.g., 'graph',\n    'Rgraphviz'); these are optional and examples/vignettes are skipped if\n    they are not installed. For algorithms and further details, see\n    <doi:10.18637/jss.v095.i04>.  "
  },
  {
    "id": 23313,
    "package_name": "zephyr",
    "title": "Structured Messages and Options",
    "description": "Provides a structured framework for consistent user\n    communication and configuration management for package developers.",
    "version": "0.1.3",
    "maintainer": "Aksel Thomsen <oath@novonordisk.com>",
    "author": "Aksel Thomsen [aut, cre],\n  Mathias Lerbech Jeppesen [aut],\n  Cervan Girard [aut],\n  Kristian Troejelsgaard [aut],\n  Lovemore Gakava [aut],\n  Steffen Falgreen Larsen [aut],\n  Vladimir Obucina [aut],\n  Novo Nordisk A/S [cph]",
    "url": "https://novonordisk-opensource.github.io/zephyr/,\nhttps://github.com/novonordisk-opensource/zephyr",
    "bug_reports": "https://github.com/novonordisk-opensource/zephyr/issues",
    "repository": "https://cran.r-project.org/package=zephyr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zephyr Structured Messages and Options Provides a structured framework for consistent user\n    communication and configuration management for package developers.  "
  },
  {
    "id": 23319,
    "package_name": "zigg",
    "title": "Lightweight Interfaces to the 'Ziggurat' Pseudo Random Number\nGenerator",
    "description": "The 'Ziggurat' pseudo-random number generator (or PRNG),\n introduced by Marsaglia and Tsang (2000, <doi:10.18637/jss.v005.i08>) and\n further improved by Leong et al (2005, <doi:10.18637/jss.v012.i07>), offers\n a lightweight and very fast PRNG for the normal, exponential, and uniform\n distributions. It is provided here in a small zero-dependency package. It can\n be used from R as well as from 'C/C++' code in other packages as is demonstrated\n by four included sample packages using four distinct methods to use the PRNG\n presented here in client package. The implementation is influenced by our\n package 'RcppZiggurat' which offers a comparison among multiple alternative\n implementations but presented here in a lighter-weight implementation that is\n easier to use by other packages. The PRNGs provided are generally faster than\n the ones in base R: on our machine, the relative gains for normal, exponential\n and uniform are on the order of 7.4, 5.2 and 4.7 times faster than base R.\n However, these generators are of potentially lesser quality and shorter period\n so if in doubt use of the base R functions remains the general recommendation.",
    "version": "0.0.2",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>)",
    "url": "https://github.com/eddelbuettel/zigg",
    "bug_reports": "https://github.com/eddelbuettel/zigg/issues",
    "repository": "https://cran.r-project.org/package=zigg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zigg Lightweight Interfaces to the 'Ziggurat' Pseudo Random Number\nGenerator The 'Ziggurat' pseudo-random number generator (or PRNG),\n introduced by Marsaglia and Tsang (2000, <doi:10.18637/jss.v005.i08>) and\n further improved by Leong et al (2005, <doi:10.18637/jss.v012.i07>), offers\n a lightweight and very fast PRNG for the normal, exponential, and uniform\n distributions. It is provided here in a small zero-dependency package. It can\n be used from R as well as from 'C/C++' code in other packages as is demonstrated\n by four included sample packages using four distinct methods to use the PRNG\n presented here in client package. The implementation is influenced by our\n package 'RcppZiggurat' which offers a comparison among multiple alternative\n implementations but presented here in a lighter-weight implementation that is\n easier to use by other packages. The PRNGs provided are generally faster than\n the ones in base R: on our machine, the relative gains for normal, exponential\n and uniform are on the order of 7.4, 5.2 and 4.7 times faster than base R.\n However, these generators are of potentially lesser quality and shorter period\n so if in doubt use of the base R functions remains the general recommendation.  "
  }
]