[
  {
    "id": 1285,
    "package_name": "survey",
    "title": "Analysis of Complex Survey Samples",
    "description": "Summary statistics, two-sample tests, rank tests,\ngeneralised linear models, cumulative link models, Cox models,\nloglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled,\nunequally weighted survey samples. Variances by Taylor series\nlinearisation or replicate weights. Post-stratification,\ncalibration, and raking. Two-phase and multiphase subsampling\ndesigns. Graphics. PPS sampling without replacement. Small-area\nestimation. Dual-frame designs.",
    "version": "4.5",
    "maintainer": "\"Thomas Lumley\" <t.lumley@auckland.ac.nz>",
    "author": "Thomas Lumley, Peter Gao, Ben Schneider",
    "url": "http://r-survey.r-forge.r-project.org/survey/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "as.svrepdesign"
      ],
      [
        "as.svydesign2"
      ],
      [
        "bootweights"
      ],
      [
        "brrweights"
      ],
      [
        "cal_names"
      ],
      [
        "cal.linear"
      ],
      [
        "cal.logit"
      ],
      [
        "cal.raking"
      ],
      [
        "cal.sinh"
      ],
      [
        "calibrate"
      ],
      [
        "compressWeights"
      ],
      [
        "cv"
      ],
      [
        "deff"
      ],
      [
        "degf"
      ],
      [
        "dotchart"
      ],
      [
        "estWeights"
      ],
      [
        "grake"
      ],
      [
        "hadamard"
      ],
      [
        "HR"
      ],
      [
        "is.hadamard"
      ],
      [
        "jk1weights"
      ],
      [
        "jknweights"
      ],
      [
        "joinCells"
      ],
      [
        "make.calfun"
      ],
      [
        "make.formula"
      ],
      [
        "make.panel.svysmooth"
      ],
      [
        "marginpred"
      ],
      [
        "mrbweights"
      ],
      [
        "multiframe"
      ],
      [
        "multiphase"
      ],
      [
        "neighbours"
      ],
      [
        "nonresponse"
      ],
      [
        "oldsvyquantile"
      ],
      [
        "paley"
      ],
      [
        "pchisqsum"
      ],
      [
        "pFsum"
      ],
      [
        "poisson_sampling"
      ],
      [
        "postStratify"
      ],
      [
        "ppscov"
      ],
      [
        "ppsmat"
      ],
      [
        "psrsq"
      ],
      [
        "rake"
      ],
      [
        "regTermTest"
      ],
      [
        "reweight"
      ],
      [
        "SE"
      ],
      [
        "sparseCells"
      ],
      [
        "stratsample"
      ],
      [
        "subbootweights"
      ],
      [
        "svrepdesign"
      ],
      [
        "svrVar"
      ],
      [
        "svyboxplot"
      ],
      [
        "svyby"
      ],
      [
        "svybys"
      ],
      [
        "svycdf"
      ],
      [
        "svychisq"
      ],
      [
        "svyciprop"
      ],
      [
        "svycontrast"
      ],
      [
        "svycoplot"
      ],
      [
        "svycoxph"
      ],
      [
        "svyCprod"
      ],
      [
        "svycralpha"
      ],
      [
        "svydesign"
      ],
      [
        "svyfactanal"
      ],
      [
        "svyglm"
      ],
      [
        "svygofchisq"
      ],
      [
        "svyhist"
      ],
      [
        "svyivreg"
      ],
      [
        "svykappa"
      ],
      [
        "svykm"
      ],
      [
        "svyloglin"
      ],
      [
        "svylogrank"
      ],
      [
        "svymean"
      ],
      [
        "svymle"
      ],
      [
        "svynls"
      ],
      [
        "svyolr"
      ],
      [
        "svyplot"
      ],
      [
        "svyprcomp"
      ],
      [
        "svypredmeans"
      ],
      [
        "svyqqmath"
      ],
      [
        "svyqqplot"
      ],
      [
        "svyquantile"
      ],
      [
        "svyranktest"
      ],
      [
        "svyratio"
      ],
      [
        "svyrecvar"
      ],
      [
        "svyscoretest"
      ],
      [
        "svysmooth"
      ],
      [
        "svysmoothArea"
      ],
      [
        "svysmoothUnit"
      ],
      [
        "svystandardize"
      ],
      [
        "svysurvreg"
      ],
      [
        "svytable"
      ],
      [
        "svytotal"
      ],
      [
        "svyttest"
      ],
      [
        "svyvar"
      ],
      [
        "trimWeights"
      ],
      [
        "twophase"
      ],
      [
        "twophase2var"
      ],
      [
        "twophasevar"
      ],
      [
        "unwtd.count"
      ],
      [
        "withCrossval"
      ],
      [
        "withReplicates"
      ],
      [
        "xdesign"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 13.2127,
    "stars": 1,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "survey Analysis of Complex Survey Samples Summary statistics, two-sample tests, rank tests,\ngeneralised linear models, cumulative link models, Cox models,\nloglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled,\nunequally weighted survey samples. Variances by Taylor series\nlinearisation or replicate weights. Post-stratification,\ncalibration, and raking. Two-phase and multiphase subsampling\ndesigns. Graphics. PPS sampling without replacement. Small-area\nestimation. Dual-frame designs. as.svrepdesign as.svydesign2 bootweights brrweights cal_names cal.linear cal.logit cal.raking cal.sinh calibrate compressWeights cv deff degf dotchart estWeights grake hadamard HR is.hadamard jk1weights jknweights joinCells make.calfun make.formula make.panel.svysmooth marginpred mrbweights multiframe multiphase neighbours nonresponse oldsvyquantile paley pchisqsum pFsum poisson_sampling postStratify ppscov ppsmat psrsq rake regTermTest reweight SE sparseCells stratsample subbootweights svrepdesign svrVar svyboxplot svyby svybys svycdf svychisq svyciprop svycontrast svycoplot svycoxph svyCprod svycralpha svydesign svyfactanal svyglm svygofchisq svyhist svyivreg svykappa svykm svyloglin svylogrank svymean svymle svynls svyolr svyplot svyprcomp svypredmeans svyqqmath svyqqplot svyquantile svyranktest svyratio svyrecvar svyscoretest svysmooth svysmoothArea svysmoothUnit svystandardize svysurvreg svytable svytotal svyttest svyvar trimWeights twophase twophase2var twophasevar unwtd.count withCrossval withReplicates xdesign cpp"
  },
  {
    "id": 1067,
    "package_name": "rdhs",
    "title": "API Client and Dataset Management for the Demographic and Health\nSurvey (DHS) Data",
    "description": "Provides a client for (1) querying the DHS API for survey\nindicators and metadata\n(<https://api.dhsprogram.com/#/index.html>), (2) identifying\nsurveys and datasets for analysis, (3) downloading survey\ndatasets from the DHS website, (4) loading datasets and\nassociate metadata into R, and (5) extracting variables and\ncombining datasets for pooled analysis.",
    "version": "0.8.4",
    "maintainer": "OJ Watson <oj.watson@hotmail.co.uk>",
    "author": "OJ Watson [aut, cre] (ORCID: <https://orcid.org/0000-0003-2374-0741>),\nJeff Eaton [aut] (ORCID: <https://orcid.org/0000-0001-7728-728X>),\nLucy D'Agostino McGowan [rev] (ORCID:\n<https://orcid.org/0000-0001-7297-9359>),\nDuncan Gillespie [rev]",
    "url": "https://docs.ropensci.org/rdhs/",
    "bug_reports": "https://github.com/ropensci/rdhs/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "as_factor.labelled"
      ],
      [
        "client_dhs"
      ],
      [
        "data_and_labels"
      ],
      [
        "delabel_df"
      ],
      [
        "dhs_countries"
      ],
      [
        "dhs_data"
      ],
      [
        "dhs_data_updates"
      ],
      [
        "dhs_datasets"
      ],
      [
        "dhs_geometry"
      ],
      [
        "dhs_indicators"
      ],
      [
        "dhs_info"
      ],
      [
        "dhs_publications"
      ],
      [
        "dhs_survey_characteristics"
      ],
      [
        "dhs_surveys"
      ],
      [
        "dhs_tags"
      ],
      [
        "dhs_ui_updates"
      ],
      [
        "download_boundaries"
      ],
      [
        "extract_dhs"
      ],
      [
        "get_available_datasets"
      ],
      [
        "get_datasets"
      ],
      [
        "get_downloaded_datasets"
      ],
      [
        "get_rdhs_config"
      ],
      [
        "get_variable_labels"
      ],
      [
        "rbind_labelled"
      ],
      [
        "read_dhs_dta"
      ],
      [
        "read_zipdata"
      ],
      [
        "search_variable_labels"
      ],
      [
        "search_variables"
      ],
      [
        "set_rdhs_config"
      ],
      [
        "update_rdhs_config"
      ]
    ],
    "topics": [
      [
        "dataset"
      ],
      [
        "dhs"
      ],
      [
        "dhs-api"
      ],
      [
        "extract"
      ],
      [
        "peer-reviewed"
      ],
      [
        "survey-data"
      ]
    ],
    "score": 11.0378,
    "stars": 38,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "rdhs API Client and Dataset Management for the Demographic and Health\nSurvey (DHS) Data Provides a client for (1) querying the DHS API for survey\nindicators and metadata\n(<https://api.dhsprogram.com/#/index.html>), (2) identifying\nsurveys and datasets for analysis, (3) downloading survey\ndatasets from the DHS website, (4) loading datasets and\nassociate metadata into R, and (5) extracting variables and\ncombining datasets for pooled analysis. %>% as_factor.labelled client_dhs data_and_labels delabel_df dhs_countries dhs_data dhs_data_updates dhs_datasets dhs_geometry dhs_indicators dhs_info dhs_publications dhs_survey_characteristics dhs_surveys dhs_tags dhs_ui_updates download_boundaries extract_dhs get_available_datasets get_datasets get_downloaded_datasets get_rdhs_config get_variable_labels rbind_labelled read_dhs_dta read_zipdata search_variable_labels search_variables set_rdhs_config update_rdhs_config dataset dhs dhs-api extract peer-reviewed survey-data"
  },
  {
    "id": 1284,
    "package_name": "surveillance",
    "title": "Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic\nPhenomena",
    "description": "Statistical methods for the modeling and monitoring of\ntime series of counts, proportions and categorical data, as\nwell as for the modeling of continuous-time point processes of\nepidemic phenomena. The monitoring methods focus on aberration\ndetection in count data time series from public health\nsurveillance of communicable diseases, but applications could\njust as well originate from environmetrics, reliability\nengineering, econometrics, or social sciences. The package\nimplements many typical outbreak detection procedures such as\nthe (improved) Farrington algorithm, or the negative binomial\nGLR-CUSUM method of Hoehle and Paul (2008)\n<doi:10.1016/j.csda.2008.02.015>. A novel CUSUM approach\ncombining logistic and multinomial logistic modeling is also\nincluded. The package contains several real-world data sets,\nthe ability to simulate outbreak data, and to visualize the\nresults of the monitoring in a temporal, spatial or\nspatio-temporal fashion. A recent overview of the available\nmonitoring procedures is given by Salmon et al. (2016)\n<doi:10.18637/jss.v070.i10>. For the retrospective analysis of\nepidemic spread, the package provides three endemic-epidemic\nmodeling frameworks with tools for visualization, likelihood\ninference, and simulation. hhh4() estimates models for\n(multivariate) count time series following Paul and Held (2011)\n<doi:10.1002/sim.4177> and Meyer and Held (2014)\n<doi:10.1214/14-AOAS743>. twinSIR() models the\nsusceptible-infectious-recovered (SIR) event history of a fixed\npopulation, e.g, epidemics across farms or networks, as a\nmultivariate point process as proposed by Hoehle (2009)\n<doi:10.1002/bimj.200900050>. twinstim() estimates\nself-exciting point process models for a spatio-temporal point\npattern of infective events, e.g., time-stamped geo-referenced\nsurveillance data, as proposed by Meyer et al. (2012)\n<doi:10.1111/j.1541-0420.2011.01684.x>. A recent overview of\nthe implemented space-time modeling frameworks for epidemic\nphenomena is given by Meyer et al. (2017)\n<doi:10.18637/jss.v077.i11>.",
    "version": "1.25.0.9000",
    "maintainer": "Sebastian Meyer <seb.meyer@fau.de>",
    "author": "Michael Hoehle [aut, ths] (ORCID:\n<https://orcid.org/0000-0002-0423-6702>),\nSebastian Meyer [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-1791-9449>),\nMichaela Paul [aut],\nLeonhard Held [ctb, ths] (ORCID:\n<https://orcid.org/0000-0002-8686-5325>),\nHoward Burkom [ctb],\nThais Correa [ctb],\nMathias Hofmann [ctb],\nChristian Lang [ctb],\nJuliane Manitz [ctb],\nSophie Reichert [ctb],\nAndrea Riebler [ctb],\nDaniel Sabanes Bove [ctb],\nMaelle Salmon [ctb],\nDirk Schumacher [ctb],\nStefan Steiner [ctb],\nMikko Virtanen [ctb],\nWei Wei [ctb],\nValentin Wimmer [ctb],\nR Core Team [ctb] (ROR: <https://ror.org/02zz1nj61>, src/ks.c and a few\ncode fragments of standard S3 methods)",
    "url": "https://surveillance.R-Forge.R-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "addFormattedXAxis"
      ],
      [
        "addSeason2formula"
      ],
      [
        "aggregate"
      ],
      [
        "alarms"
      ],
      [
        "alarms<-"
      ],
      [
        "algo.bayes"
      ],
      [
        "algo.bayes1"
      ],
      [
        "algo.bayes2"
      ],
      [
        "algo.bayes3"
      ],
      [
        "algo.bayesLatestTimepoint"
      ],
      [
        "algo.call"
      ],
      [
        "algo.cdc"
      ],
      [
        "algo.cdcLatestTimepoint"
      ],
      [
        "algo.compare"
      ],
      [
        "algo.cusum"
      ],
      [
        "algo.farrington"
      ],
      [
        "algo.farrington.assign.weights"
      ],
      [
        "algo.farrington.fitGLM"
      ],
      [
        "algo.farrington.fitGLM.fast"
      ],
      [
        "algo.farrington.fitGLM.populationOffset"
      ],
      [
        "algo.farrington.threshold"
      ],
      [
        "algo.glrnb"
      ],
      [
        "algo.glrpois"
      ],
      [
        "algo.hmm"
      ],
      [
        "algo.outbreakP"
      ],
      [
        "algo.quality"
      ],
      [
        "algo.rki"
      ],
      [
        "algo.rki1"
      ],
      [
        "algo.rki2"
      ],
      [
        "algo.rki3"
      ],
      [
        "algo.rkiLatestTimepoint"
      ],
      [
        "algo.rogerson"
      ],
      [
        "algo.summary"
      ],
      [
        "animate"
      ],
      [
        "animate_nowcasts"
      ],
      [
        "animate.epidataCS"
      ],
      [
        "anscombe.residuals"
      ],
      [
        "arlCusum"
      ],
      [
        "as.data.frame"
      ],
      [
        "as.epidata"
      ],
      [
        "as.epidata.data.frame"
      ],
      [
        "as.epidata.default"
      ],
      [
        "as.epidata.epidataCS"
      ],
      [
        "as.epidataCS"
      ],
      [
        "as.hhh4simslist"
      ],
      [
        "as.xts.sts"
      ],
      [
        "at2ndChange"
      ],
      [
        "atChange"
      ],
      [
        "atMedian"
      ],
      [
        "autoplot.sts"
      ],
      [
        "backprojNP"
      ],
      [
        "bayes"
      ],
      [
        "bestCombination"
      ],
      [
        "boda"
      ],
      [
        "bodaDelay"
      ],
      [
        "calibrationTest"
      ],
      [
        "calibrationTest.default"
      ],
      [
        "categoricalCUSUM"
      ],
      [
        "checkResidualProcess"
      ],
      [
        "clapply"
      ],
      [
        "coeflist"
      ],
      [
        "coefW"
      ],
      [
        "control"
      ],
      [
        "control<-"
      ],
      [
        "cox"
      ],
      [
        "create.disProg"
      ],
      [
        "cusum"
      ],
      [
        "decompose.hhh4"
      ],
      [
        "delayCDF"
      ],
      [
        "discpoly"
      ],
      [
        "disProg2sts"
      ],
      [
        "dss"
      ],
      [
        "earsC"
      ],
      [
        "epidataCS2sts"
      ],
      [
        "epidataCSplot_space"
      ],
      [
        "epidataCSplot_time"
      ],
      [
        "epitest"
      ],
      [
        "epoch"
      ],
      [
        "epoch<-"
      ],
      [
        "epochInYear"
      ],
      [
        "estimateGLRNbHook"
      ],
      [
        "fanplot"
      ],
      [
        "farrington"
      ],
      [
        "farringtonFlexible"
      ],
      [
        "find.kh"
      ],
      [
        "findH"
      ],
      [
        "findK"
      ],
      [
        "fixef"
      ],
      [
        "formatDate"
      ],
      [
        "formatPval"
      ],
      [
        "frequency"
      ],
      [
        "getMaxEV"
      ],
      [
        "getMaxEV_season"
      ],
      [
        "getNEweights"
      ],
      [
        "getSourceDists"
      ],
      [
        "glm_epidataCS"
      ],
      [
        "glrnb"
      ],
      [
        "glrpois"
      ],
      [
        "hhh4"
      ],
      [
        "hValues"
      ],
      [
        "iafplot"
      ],
      [
        "intensity.twinstim"
      ],
      [
        "intensityplot"
      ],
      [
        "intensityplot.simEpidata"
      ],
      [
        "intensityplot.simEpidataCS"
      ],
      [
        "intensityplot.twinSIR"
      ],
      [
        "intensityplot.twinstim"
      ],
      [
        "intersectPolyCircle"
      ],
      [
        "intersperse"
      ],
      [
        "isoWeekYear"
      ],
      [
        "knox"
      ],
      [
        "ks.plot.unif"
      ],
      [
        "layout.labels"
      ],
      [
        "layout.scalebar"
      ],
      [
        "linelist2sts"
      ],
      [
        "logs"
      ],
      [
        "LRCUSUM.runlength"
      ],
      [
        "magic.dim"
      ],
      [
        "makeControl"
      ],
      [
        "marks"
      ],
      [
        "marks.epidataCS"
      ],
      [
        "meanHHH"
      ],
      [
        "multinomialTS"
      ],
      [
        "multinomialTS<-"
      ],
      [
        "multiplicity"
      ],
      [
        "nbOrder"
      ],
      [
        "neighbourhood"
      ],
      [
        "neighbourhood<-"
      ],
      [
        "nowcast"
      ],
      [
        "observed"
      ],
      [
        "observed<-"
      ],
      [
        "oneStepAhead"
      ],
      [
        "outbreakP"
      ],
      [
        "pairedbinCUSUM"
      ],
      [
        "pairedbinCUSUM.runlength"
      ],
      [
        "permutationTest"
      ],
      [
        "permute.epidataCS"
      ],
      [
        "pit"
      ],
      [
        "pit.default"
      ],
      [
        "plapply"
      ],
      [
        "plot"
      ],
      [
        "plotHHH4_fitted"
      ],
      [
        "plotHHH4_fitted1"
      ],
      [
        "plotHHH4_maps"
      ],
      [
        "plotHHH4_maxEV"
      ],
      [
        "plotHHH4_neweights"
      ],
      [
        "plotHHH4_ri"
      ],
      [
        "plotHHH4_season"
      ],
      [
        "plotHHH4sims_fan"
      ],
      [
        "plotHHH4sims_size"
      ],
      [
        "plotHHH4sims_time"
      ],
      [
        "poly2adjmat"
      ],
      [
        "polyAtBorder"
      ],
      [
        "population"
      ],
      [
        "population<-"
      ],
      [
        "predint"
      ],
      [
        "primeFactors"
      ],
      [
        "R0"
      ],
      [
        "ranef"
      ],
      [
        "refvalIdxByDate"
      ],
      [
        "reportingTriangle"
      ],
      [
        "reset.surveillance.options"
      ],
      [
        "rki"
      ],
      [
        "rps"
      ],
      [
        "score"
      ],
      [
        "scores"
      ],
      [
        "ses"
      ],
      [
        "siaf"
      ],
      [
        "siaf.constant"
      ],
      [
        "siaf.exponential"
      ],
      [
        "siaf.gaussian"
      ],
      [
        "siaf.powerlaw"
      ],
      [
        "siaf.powerlaw1"
      ],
      [
        "siaf.powerlawL"
      ],
      [
        "siaf.step"
      ],
      [
        "siaf.student"
      ],
      [
        "sim.pointSource"
      ],
      [
        "sim.seasonalNoise"
      ],
      [
        "simEndemicEvents"
      ],
      [
        "simEpidata"
      ],
      [
        "simEpidataCS"
      ],
      [
        "simpleR0"
      ],
      [
        "simulate.twinSIR"
      ],
      [
        "simulate.twinstim"
      ],
      [
        "sizeHHH"
      ],
      [
        "start"
      ],
      [
        "stateplot"
      ],
      [
        "stcd"
      ],
      [
        "stepComponent"
      ],
      [
        "stKtest"
      ],
      [
        "sts"
      ],
      [
        "sts_creation"
      ],
      [
        "sts_observation"
      ],
      [
        "sts2disProg"
      ],
      [
        "stsplot_alarm"
      ],
      [
        "stsplot_space"
      ],
      [
        "stsplot_time"
      ],
      [
        "stsplot_time1"
      ],
      [
        "summary.twinstim"
      ],
      [
        "surveillance.options"
      ],
      [
        "tiaf"
      ],
      [
        "tiaf.constant"
      ],
      [
        "tiaf.exponential"
      ],
      [
        "tiaf.step"
      ],
      [
        "tidy.sts"
      ],
      [
        "toLatex"
      ],
      [
        "twinSIR"
      ],
      [
        "twinstim"
      ],
      [
        "unionSpatialPolygons"
      ],
      [
        "untie"
      ],
      [
        "update.epidataCS"
      ],
      [
        "update.hhh4"
      ],
      [
        "update.twinstim"
      ],
      [
        "upperbound"
      ],
      [
        "upperbound<-"
      ],
      [
        "W_np"
      ],
      [
        "W_powerlaw"
      ],
      [
        "wrap.algo"
      ],
      [
        "xtable.summary.twinstim"
      ],
      [
        "year"
      ],
      [
        "zetaweights"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 10.7272,
    "stars": 2,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "surveillance Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic\nPhenomena Statistical methods for the modeling and monitoring of\ntime series of counts, proportions and categorical data, as\nwell as for the modeling of continuous-time point processes of\nepidemic phenomena. The monitoring methods focus on aberration\ndetection in count data time series from public health\nsurveillance of communicable diseases, but applications could\njust as well originate from environmetrics, reliability\nengineering, econometrics, or social sciences. The package\nimplements many typical outbreak detection procedures such as\nthe (improved) Farrington algorithm, or the negative binomial\nGLR-CUSUM method of Hoehle and Paul (2008)\n<doi:10.1016/j.csda.2008.02.015>. A novel CUSUM approach\ncombining logistic and multinomial logistic modeling is also\nincluded. The package contains several real-world data sets,\nthe ability to simulate outbreak data, and to visualize the\nresults of the monitoring in a temporal, spatial or\nspatio-temporal fashion. A recent overview of the available\nmonitoring procedures is given by Salmon et al. (2016)\n<doi:10.18637/jss.v070.i10>. For the retrospective analysis of\nepidemic spread, the package provides three endemic-epidemic\nmodeling frameworks with tools for visualization, likelihood\ninference, and simulation. hhh4() estimates models for\n(multivariate) count time series following Paul and Held (2011)\n<doi:10.1002/sim.4177> and Meyer and Held (2014)\n<doi:10.1214/14-AOAS743>. twinSIR() models the\nsusceptible-infectious-recovered (SIR) event history of a fixed\npopulation, e.g, epidemics across farms or networks, as a\nmultivariate point process as proposed by Hoehle (2009)\n<doi:10.1002/bimj.200900050>. twinstim() estimates\nself-exciting point process models for a spatio-temporal point\npattern of infective events, e.g., time-stamped geo-referenced\nsurveillance data, as proposed by Meyer et al. (2012)\n<doi:10.1111/j.1541-0420.2011.01684.x>. A recent overview of\nthe implemented space-time modeling frameworks for epidemic\nphenomena is given by Meyer et al. (2017)\n<doi:10.18637/jss.v077.i11>. addFormattedXAxis addSeason2formula aggregate alarms alarms<- algo.bayes algo.bayes1 algo.bayes2 algo.bayes3 algo.bayesLatestTimepoint algo.call algo.cdc algo.cdcLatestTimepoint algo.compare algo.cusum algo.farrington algo.farrington.assign.weights algo.farrington.fitGLM algo.farrington.fitGLM.fast algo.farrington.fitGLM.populationOffset algo.farrington.threshold algo.glrnb algo.glrpois algo.hmm algo.outbreakP algo.quality algo.rki algo.rki1 algo.rki2 algo.rki3 algo.rkiLatestTimepoint algo.rogerson algo.summary animate animate_nowcasts animate.epidataCS anscombe.residuals arlCusum as.data.frame as.epidata as.epidata.data.frame as.epidata.default as.epidata.epidataCS as.epidataCS as.hhh4simslist as.xts.sts at2ndChange atChange atMedian autoplot.sts backprojNP bayes bestCombination boda bodaDelay calibrationTest calibrationTest.default categoricalCUSUM checkResidualProcess clapply coeflist coefW control control<- cox create.disProg cusum decompose.hhh4 delayCDF discpoly disProg2sts dss earsC epidataCS2sts epidataCSplot_space epidataCSplot_time epitest epoch epoch<- epochInYear estimateGLRNbHook fanplot farrington farringtonFlexible find.kh findH findK fixef formatDate formatPval frequency getMaxEV getMaxEV_season getNEweights getSourceDists glm_epidataCS glrnb glrpois hhh4 hValues iafplot intensity.twinstim intensityplot intensityplot.simEpidata intensityplot.simEpidataCS intensityplot.twinSIR intensityplot.twinstim intersectPolyCircle intersperse isoWeekYear knox ks.plot.unif layout.labels layout.scalebar linelist2sts logs LRCUSUM.runlength magic.dim makeControl marks marks.epidataCS meanHHH multinomialTS multinomialTS<- multiplicity nbOrder neighbourhood neighbourhood<- nowcast observed observed<- oneStepAhead outbreakP pairedbinCUSUM pairedbinCUSUM.runlength permutationTest permute.epidataCS pit pit.default plapply plot plotHHH4_fitted plotHHH4_fitted1 plotHHH4_maps plotHHH4_maxEV plotHHH4_neweights plotHHH4_ri plotHHH4_season plotHHH4sims_fan plotHHH4sims_size plotHHH4sims_time poly2adjmat polyAtBorder population population<- predint primeFactors R0 ranef refvalIdxByDate reportingTriangle reset.surveillance.options rki rps score scores ses siaf siaf.constant siaf.exponential siaf.gaussian siaf.powerlaw siaf.powerlaw1 siaf.powerlawL siaf.step siaf.student sim.pointSource sim.seasonalNoise simEndemicEvents simEpidata simEpidataCS simpleR0 simulate.twinSIR simulate.twinstim sizeHHH start stateplot stcd stepComponent stKtest sts sts_creation sts_observation sts2disProg stsplot_alarm stsplot_space stsplot_time stsplot_time1 summary.twinstim surveillance.options tiaf tiaf.constant tiaf.exponential tiaf.step tidy.sts toLatex twinSIR twinstim unionSpatialPolygons untie update.epidataCS update.hhh4 update.twinstim upperbound upperbound<- W_np W_powerlaw wrap.algo xtable.summary.twinstim year zetaweights cpp"
  },
  {
    "id": 1041,
    "package_name": "qualtRics",
    "title": "Download 'Qualtrics' Survey Data",
    "description": "Provides functions to access survey results directly into\nR using the 'Qualtrics' API. 'Qualtrics'\n<https://www.qualtrics.com/about/> is an online survey and data\ncollection software platform. See <https://api.qualtrics.com/>\nfor more information about the 'Qualtrics' API.  This package\nis community-maintained and is not officially supported by\n'Qualtrics'.",
    "version": "3.2.2.9000",
    "maintainer": "Julia Silge <julia.silge@gmail.com>",
    "author": "Jasper Ginn [aut],\nJackson Curtis [ctb],\nShaun Jackson [ctb],\nSamuel Kaminsky [ctb],\nEric Knudsen [ctb],\nJoseph O'Brien [aut],\nDaniel Seneca [ctb],\nJulia Silge [aut, cre] (ORCID: <https://orcid.org/0000-0002-3671-836X>),\nPhoebe Wong [ctb]",
    "url": "https://docs.ropensci.org/qualtRics/,\nhttps://github.com/ropensci/qualtRics",
    "bug_reports": "https://github.com/ropensci/qualtRics/issues",
    "repository": "",
    "exports": [
      [
        "all_mailinglists"
      ],
      [
        "all_surveys"
      ],
      [
        "column_map"
      ],
      [
        "extract_colmap"
      ],
      [
        "fetch_description"
      ],
      [
        "fetch_distribution_history"
      ],
      [
        "fetch_distributions"
      ],
      [
        "fetch_id"
      ],
      [
        "fetch_mailinglist"
      ],
      [
        "fetch_survey"
      ],
      [
        "generate_url"
      ],
      [
        "list_distribution_links"
      ],
      [
        "metadata"
      ],
      [
        "qualtrics_api_credentials"
      ],
      [
        "read_survey"
      ],
      [
        "survey_questions"
      ]
    ],
    "topics": [
      [
        "api"
      ],
      [
        "qualtrics"
      ],
      [
        "qualtrics-api"
      ],
      [
        "survey"
      ],
      [
        "survey-data"
      ]
    ],
    "score": 10.6507,
    "stars": 226,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "qualtRics Download 'Qualtrics' Survey Data Provides functions to access survey results directly into\nR using the 'Qualtrics' API. 'Qualtrics'\n<https://www.qualtrics.com/about/> is an online survey and data\ncollection software platform. See <https://api.qualtrics.com/>\nfor more information about the 'Qualtrics' API.  This package\nis community-maintained and is not officially supported by\n'Qualtrics'. all_mailinglists all_surveys column_map extract_colmap fetch_description fetch_distribution_history fetch_distributions fetch_id fetch_mailinglist fetch_survey generate_url list_distribution_links metadata qualtrics_api_credentials read_survey survey_questions api qualtrics qualtrics-api survey survey-data"
  },
  {
    "id": 1341,
    "package_name": "tidyhydat",
    "title": "Extract and Tidy Canadian 'Hydrometric' Data",
    "description": "Provides functions to access historical and real-time\nnational 'hydrometric' data from Water Survey of Canada data\nsources and then applies tidy data principles.",
    "version": "0.7.2.9000",
    "maintainer": "Sam Albers <sam.albers@gmail.com>",
    "author": "Sam Albers [aut, cre] (ORCID: <https://orcid.org/0000-0002-9270-7884>),\nDavid Hutchinson [ctb],\nDewey Dunnington [ctb],\nRyan Whaley [ctb],\nProvince of British Columbia [cph],\nGovernment of Canada [dtc],\nLuke Winslow [rev] (Reviewed for rOpenSci),\nLaura DeCicco [rev] (Reviewed for rOpenSci)",
    "url": "https://docs.ropensci.org/tidyhydat/,\nhttps://github.com/ropensci/tidyhydat/",
    "bug_reports": "https://github.com/ropensci/tidyhydat/issues/",
    "repository": "",
    "exports": [
      [
        "download_hydat"
      ],
      [
        "enexpr"
      ],
      [
        "enquo"
      ],
      [
        "ensym"
      ],
      [
        "expr"
      ],
      [
        "exprs"
      ],
      [
        "hy_agency_list"
      ],
      [
        "hy_annual_instant_peaks"
      ],
      [
        "hy_annual_stats"
      ],
      [
        "hy_daily"
      ],
      [
        "hy_daily_flows"
      ],
      [
        "hy_daily_levels"
      ],
      [
        "hy_datum_list"
      ],
      [
        "hy_default_db"
      ],
      [
        "hy_dir"
      ],
      [
        "hy_downloaded_db"
      ],
      [
        "hy_monthly_flows"
      ],
      [
        "hy_monthly_levels"
      ],
      [
        "hy_plot"
      ],
      [
        "hy_reg_office_list"
      ],
      [
        "hy_remote"
      ],
      [
        "hy_sed_daily_loads"
      ],
      [
        "hy_sed_daily_suscon"
      ],
      [
        "hy_sed_monthly_loads"
      ],
      [
        "hy_sed_monthly_suscon"
      ],
      [
        "hy_sed_samples"
      ],
      [
        "hy_sed_samples_psd"
      ],
      [
        "hy_set_default_db"
      ],
      [
        "hy_src"
      ],
      [
        "hy_src_disconnect"
      ],
      [
        "hy_stations"
      ],
      [
        "hy_stn_data_coll"
      ],
      [
        "hy_stn_data_range"
      ],
      [
        "hy_stn_datum_conv"
      ],
      [
        "hy_stn_datum_unrelated"
      ],
      [
        "hy_stn_op_schedule"
      ],
      [
        "hy_stn_regulation"
      ],
      [
        "hy_stn_remarks"
      ],
      [
        "hy_test_db"
      ],
      [
        "hy_version"
      ],
      [
        "pull_station_number"
      ],
      [
        "quo"
      ],
      [
        "quo_name"
      ],
      [
        "quos"
      ],
      [
        "realtime_add_local_datetime"
      ],
      [
        "realtime_daily_mean"
      ],
      [
        "realtime_dd"
      ],
      [
        "realtime_plot"
      ],
      [
        "realtime_stations"
      ],
      [
        "realtime_ws"
      ],
      [
        "search_stn_name"
      ],
      [
        "search_stn_number"
      ],
      [
        "sym"
      ],
      [
        "syms"
      ],
      [
        "ws_daily_flows"
      ],
      [
        "ws_daily_levels"
      ]
    ],
    "topics": [
      [
        "citz"
      ],
      [
        "government-data"
      ],
      [
        "hydrology"
      ],
      [
        "hydrometrics"
      ],
      [
        "tidy-data"
      ],
      [
        "water-resources"
      ]
    ],
    "score": 10.1911,
    "stars": 71,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "tidyhydat Extract and Tidy Canadian 'Hydrometric' Data Provides functions to access historical and real-time\nnational 'hydrometric' data from Water Survey of Canada data\nsources and then applies tidy data principles. download_hydat enexpr enquo ensym expr exprs hy_agency_list hy_annual_instant_peaks hy_annual_stats hy_daily hy_daily_flows hy_daily_levels hy_datum_list hy_default_db hy_dir hy_downloaded_db hy_monthly_flows hy_monthly_levels hy_plot hy_reg_office_list hy_remote hy_sed_daily_loads hy_sed_daily_suscon hy_sed_monthly_loads hy_sed_monthly_suscon hy_sed_samples hy_sed_samples_psd hy_set_default_db hy_src hy_src_disconnect hy_stations hy_stn_data_coll hy_stn_data_range hy_stn_datum_conv hy_stn_datum_unrelated hy_stn_op_schedule hy_stn_regulation hy_stn_remarks hy_test_db hy_version pull_station_number quo quo_name quos realtime_add_local_datetime realtime_daily_mean realtime_dd realtime_plot realtime_stations realtime_ws search_stn_name search_stn_number sym syms ws_daily_flows ws_daily_levels citz government-data hydrology hydrometrics tidy-data water-resources"
  },
  {
    "id": 1051,
    "package_name": "ragnar",
    "title": "Retrieval-Augmented Generation (RAG) Workflows",
    "description": "Provides tools for implementing Retrieval-Augmented\nGeneration (RAG) workflows with Large Language Models (LLM).\nIncludes functions for document processing, text chunking,\nembedding generation, storage management, and content\nretrieval. Supports various document types and embedding\nproviders ('Ollama', 'OpenAI'), with 'DuckDB' as the default\nstorage backend. Integrates with the 'ellmer' package to equip\nchat objects with retrieval capabilities. Designed to offer\nboth sensible defaults and customization options with\ntransparent access to intermediate outputs.  For a review of\nretrieval-augmented generation methods, see Gao et al. (2023)\n\"Retrieval-Augmented Generation for Large Language Models: A\nSurvey\" <doi:10.48550/arXiv.2312.10997>.",
    "version": "0.2.1.9000",
    "maintainer": "Tomasz Kalinowski <tomasz@posit.co>",
    "author": "Tomasz Kalinowski [aut, cre],\nDaniel Falbel [aut],\nPosit Software, PBC [cph, fnd] (ROR: <https://ror.org/03wc8by49>)",
    "url": "https://ragnar.tidyverse.org/, https://github.com/tidyverse/ragnar",
    "bug_reports": "https://github.com/tidyverse/ragnar/issues",
    "repository": "",
    "exports": [
      [
        "chunks_deoverlap"
      ],
      [
        "embed_azure_openai"
      ],
      [
        "embed_bedrock"
      ],
      [
        "embed_databricks"
      ],
      [
        "embed_google_gemini"
      ],
      [
        "embed_google_vertex"
      ],
      [
        "embed_lm_studio"
      ],
      [
        "embed_ollama"
      ],
      [
        "embed_openai"
      ],
      [
        "embed_snowflake"
      ],
      [
        "markdown_chunk"
      ],
      [
        "markdown_frame"
      ],
      [
        "markdown_segment"
      ],
      [
        "MarkdownDocument"
      ],
      [
        "MarkdownDocumentChunks"
      ],
      [
        "mcp_serve_store"
      ],
      [
        "ragnar_chunk"
      ],
      [
        "ragnar_chunk_segments"
      ],
      [
        "ragnar_chunks_view"
      ],
      [
        "ragnar_find_links"
      ],
      [
        "ragnar_read"
      ],
      [
        "ragnar_read_document"
      ],
      [
        "ragnar_register_tool_retrieve"
      ],
      [
        "ragnar_retrieve"
      ],
      [
        "ragnar_retrieve_bm25"
      ],
      [
        "ragnar_retrieve_vss"
      ],
      [
        "ragnar_segment"
      ],
      [
        "ragnar_store_atlas"
      ],
      [
        "ragnar_store_build_index"
      ],
      [
        "ragnar_store_connect"
      ],
      [
        "ragnar_store_create"
      ],
      [
        "ragnar_store_ingest"
      ],
      [
        "ragnar_store_insert"
      ],
      [
        "ragnar_store_inspect"
      ],
      [
        "ragnar_store_update"
      ],
      [
        "read_as_markdown"
      ]
    ],
    "topics": [],
    "score": 9.7775,
    "stars": 151,
    "primary_category": "tidyverse",
    "source_universe": "tidyverse",
    "search_text": "ragnar Retrieval-Augmented Generation (RAG) Workflows Provides tools for implementing Retrieval-Augmented\nGeneration (RAG) workflows with Large Language Models (LLM).\nIncludes functions for document processing, text chunking,\nembedding generation, storage management, and content\nretrieval. Supports various document types and embedding\nproviders ('Ollama', 'OpenAI'), with 'DuckDB' as the default\nstorage backend. Integrates with the 'ellmer' package to equip\nchat objects with retrieval capabilities. Designed to offer\nboth sensible defaults and customization options with\ntransparent access to intermediate outputs.  For a review of\nretrieval-augmented generation methods, see Gao et al. (2023)\n\"Retrieval-Augmented Generation for Large Language Models: A\nSurvey\" <doi:10.48550/arXiv.2312.10997>. chunks_deoverlap embed_azure_openai embed_bedrock embed_databricks embed_google_gemini embed_google_vertex embed_lm_studio embed_ollama embed_openai embed_snowflake markdown_chunk markdown_frame markdown_segment MarkdownDocument MarkdownDocumentChunks mcp_serve_store ragnar_chunk ragnar_chunk_segments ragnar_chunks_view ragnar_find_links ragnar_read ragnar_read_document ragnar_register_tool_retrieve ragnar_retrieve ragnar_retrieve_bm25 ragnar_retrieve_vss ragnar_segment ragnar_store_atlas ragnar_store_build_index ragnar_store_connect ragnar_store_create ragnar_store_ingest ragnar_store_insert ragnar_store_inspect ragnar_store_update read_as_markdown "
  },
  {
    "id": 523,
    "package_name": "eph",
    "title": "Argentina's Permanent Household Survey Data and Manipulation\nUtilities",
    "description": "Tools to download and manipulate the Permanent Household\nSurvey from Argentina (EPH is the Spanish acronym for Permanent\nHousehold Survey). e.g: get_microdata() for downloading the\ndatasets, get_poverty_lines() for downloading the official\npoverty baskets, calculate_poverty() for the calculation of\nstating if a household is in poverty or not, following the\nofficial methodology. organize_panels() is used to concatenate\nobservations from different periods, and organize_labels() adds\nthe official labels to the data. The implemented methods are\nbased on INDEC (2016)\n<http://www.estadistica.ec.gba.gov.ar/dpe/images/SOCIEDAD/EPH_metodologia_22_pobreza.pdf>.\nAs this package works with the argentinian Permanent Household\nSurvey and its main audience is from this country, the\ndocumentation was written in Spanish.",
    "version": "1.0.2",
    "maintainer": "Carolina Pradier <carolinapradier@gmail.com>",
    "author": "Carolina Pradier [aut, cre] (ORCID:\n<https://orcid.org/0009-0007-5058-6352>),\nDiego Kozlowski [aut] (ORCID: <https://orcid.org/0000-0002-5396-3471>),\nPablo Tiscornia [aut],\nGuido Weksler [aut],\nNatsumi Shokida [aut],\nGerman Rosati [aut] (ORCID: <https://orcid.org/0000-0002-9775-0435>),\nJuan Gabriel Juara [ctb]",
    "url": "https://github.com/ropensci/eph",
    "bug_reports": "https://github.com/ropensci/eph/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "calculate_errors"
      ],
      [
        "calculate_poverty"
      ],
      [
        "calculate_tabulates"
      ],
      [
        "get_eahu"
      ],
      [
        "get_microdata"
      ],
      [
        "get_poverty_lines"
      ],
      [
        "get_total_urbano"
      ],
      [
        "map_agglomerates"
      ],
      [
        "organize_caes"
      ],
      [
        "organize_cno"
      ],
      [
        "organize_labels"
      ],
      [
        "organize_panels"
      ]
    ],
    "topics": [
      [
        "eph"
      ],
      [
        "indec"
      ],
      [
        "mercado-de-trabajo"
      ],
      [
        "rstatses"
      ]
    ],
    "score": 8.2494,
    "stars": 62,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "eph Argentina's Permanent Household Survey Data and Manipulation\nUtilities Tools to download and manipulate the Permanent Household\nSurvey from Argentina (EPH is the Spanish acronym for Permanent\nHousehold Survey). e.g: get_microdata() for downloading the\ndatasets, get_poverty_lines() for downloading the official\npoverty baskets, calculate_poverty() for the calculation of\nstating if a household is in poverty or not, following the\nofficial methodology. organize_panels() is used to concatenate\nobservations from different periods, and organize_labels() adds\nthe official labels to the data. The implemented methods are\nbased on INDEC (2016)\n<http://www.estadistica.ec.gba.gov.ar/dpe/images/SOCIEDAD/EPH_metodologia_22_pobreza.pdf>.\nAs this package works with the argentinian Permanent Household\nSurvey and its main audience is from this country, the\ndocumentation was written in Spanish. %>% calculate_errors calculate_poverty calculate_tabulates get_eahu get_microdata get_poverty_lines get_total_urbano map_agglomerates organize_caes organize_cno organize_labels organize_panels eph indec mercado-de-trabajo rstatses"
  },
  {
    "id": 211,
    "package_name": "USAboundaries",
    "title": "Historical and Contemporary Boundaries of the United States of\nAmerica",
    "description": "The boundaries for geographical units in the United States\nof America contained in this package include state, county,\ncongressional district, and zip code tabulation area.\nContemporary boundaries are provided by the U.S. Census Bureau\n(public domain). Historical boundaries for the years from 1629\nto 2000 are provided form the Newberry Library's 'Atlas of\nHistorical County Boundaries' (licensed CC BY-NC-SA).\nAdditional data is provided in the 'USAboundariesData' package;\nthis package provides an interface to access that data.",
    "version": "0.5.1",
    "maintainer": "Jacci Ziebert <jacciziebert@gmail.com>",
    "author": "Lincoln Mullen [aut] (ORCID: <https://orcid.org/0000-0001-5103-6917>),\nJordan Bratt [aut] (ORCID: <https://orcid.org/0000-0001-9051-7203>),\nUnited States Census Bureau [cph],\nJacci Ziebert [cre]",
    "url": "https://docs.ropensci.org/USAboundaries,\nhttps://github.com/ropensci/USAboundaries",
    "bug_reports": "https://github.com/ropensci/USAboundaries/issues",
    "repository": "",
    "exports": [
      [
        "check_data_package"
      ],
      [
        "install_USAboundariesData"
      ],
      [
        "state_plane"
      ],
      [
        "us_cities"
      ],
      [
        "us_congressional"
      ],
      [
        "us_counties"
      ],
      [
        "us_states"
      ],
      [
        "us_zipcodes"
      ]
    ],
    "topics": [
      [
        "digital-history"
      ],
      [
        "history"
      ],
      [
        "spatial-data"
      ]
    ],
    "score": 7.9625,
    "stars": 65,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "USAboundaries Historical and Contemporary Boundaries of the United States of\nAmerica The boundaries for geographical units in the United States\nof America contained in this package include state, county,\ncongressional district, and zip code tabulation area.\nContemporary boundaries are provided by the U.S. Census Bureau\n(public domain). Historical boundaries for the years from 1629\nto 2000 are provided form the Newberry Library's 'Atlas of\nHistorical County Boundaries' (licensed CC BY-NC-SA).\nAdditional data is provided in the 'USAboundariesData' package;\nthis package provides an interface to access that data. check_data_package install_USAboundariesData state_plane us_cities us_congressional us_counties us_states us_zipcodes digital-history history spatial-data"
  },
  {
    "id": 60,
    "package_name": "FedData",
    "title": "Download Geospatial Data Available from Several Federated Data\nSources",
    "description": "Download geospatial data available from several federated\ndata sources (mainly sources maintained by the US Federal\ngovernment). Currently, the package enables extraction from\nnine datasets: The National Elevation Dataset digital elevation\nmodels (<https://www.usgs.gov/3d-elevation-program> 1 and 1/3\narc-second; USGS); The National Hydrography Dataset\n(<https://www.usgs.gov/national-hydrography/national-hydrography-dataset>;\nUSGS); The Soil Survey Geographic (SSURGO) database from the\nNational Cooperative Soil Survey\n(<https://websoilsurvey.sc.egov.usda.gov/>; NCSS), which is led\nby the Natural Resources Conservation Service (NRCS) under the\nUSDA; the Global Historical Climatology Network\n(<https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily>;\nGHCN), coordinated by National Climatic Data Center at NOAA;\nthe Daymet gridded estimates of daily weather parameters for\nNorth America, version 4, available from the Oak Ridge National\nLaboratory's Distributed Active Archive Center\n(<https://daymet.ornl.gov/>; DAAC); the International Tree Ring\nData Bank; the National Land Cover Database\n(<https://www.mrlc.gov/>; NLCD); the Cropland Data Layer from\nthe National Agricultural Statistics Service\n(<https://www.nass.usda.gov/Research_and_Science/Cropland/SARS1a.php>;\nNASS); and the PAD-US dataset of protected area boundaries\n(<https://www.usgs.gov/programs/gap-analysis-project/science/pad-us-data-overview>;\nUSGS).",
    "version": "4.3.0",
    "maintainer": "R. Kyle Bocinsky <bocinsky@gmail.com>",
    "author": "R. Kyle Bocinsky [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0003-1862-3428>),\nDylan Beaudette [ctb],\nScott Chamberlain [ctb, rev],\nJeffrey Hollister [ctb],\nJulia Gustavsen [rev]",
    "url": "https://docs.ropensci.org/FedData/,\nhttps://github.com/ropensci/FedData",
    "bug_reports": "https://github.com/ropensci/FedData/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "agol_filter"
      ],
      [
        "agol_filter_httr"
      ],
      [
        "cdl_colors"
      ],
      [
        "check_service"
      ],
      [
        "download_data"
      ],
      [
        "download_ghcn_daily_station"
      ],
      [
        "download_itrdb"
      ],
      [
        "download_ssurgo_inventory"
      ],
      [
        "download_ssurgo_study_area"
      ],
      [
        "extract_ssurgo_data"
      ],
      [
        "get_cdl"
      ],
      [
        "get_daymet"
      ],
      [
        "get_ghcn_daily"
      ],
      [
        "get_ghcn_daily_station"
      ],
      [
        "get_ghcn_inventory"
      ],
      [
        "get_itrdb"
      ],
      [
        "get_nass"
      ],
      [
        "get_nass_cdl"
      ],
      [
        "get_ned"
      ],
      [
        "get_ned_tile"
      ],
      [
        "get_nhd"
      ],
      [
        "get_nlcd"
      ],
      [
        "get_nlcd_annual"
      ],
      [
        "get_padus"
      ],
      [
        "get_ssurgo"
      ],
      [
        "get_ssurgo_inventory"
      ],
      [
        "get_ssurgo_study_area"
      ],
      [
        "get_wbd"
      ],
      [
        "nlcd_colors"
      ],
      [
        "pal_nlcd"
      ],
      [
        "plot_nhd"
      ],
      [
        "polygon_from_extent"
      ],
      [
        "read_crn"
      ],
      [
        "read_crn_data"
      ],
      [
        "read_crn_metadata"
      ],
      [
        "replace_null"
      ],
      [
        "sequential_duplicated"
      ],
      [
        "split_bbox"
      ],
      [
        "station_to_data_frame"
      ],
      [
        "substr_right"
      ],
      [
        "unwrap_rows"
      ],
      [
        "url_base"
      ]
    ],
    "topics": [
      [
        "peer-reviewed"
      ]
    ],
    "score": 7.8617,
    "stars": 104,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "FedData Download Geospatial Data Available from Several Federated Data\nSources Download geospatial data available from several federated\ndata sources (mainly sources maintained by the US Federal\ngovernment). Currently, the package enables extraction from\nnine datasets: The National Elevation Dataset digital elevation\nmodels (<https://www.usgs.gov/3d-elevation-program> 1 and 1/3\narc-second; USGS); The National Hydrography Dataset\n(<https://www.usgs.gov/national-hydrography/national-hydrography-dataset>;\nUSGS); The Soil Survey Geographic (SSURGO) database from the\nNational Cooperative Soil Survey\n(<https://websoilsurvey.sc.egov.usda.gov/>; NCSS), which is led\nby the Natural Resources Conservation Service (NRCS) under the\nUSDA; the Global Historical Climatology Network\n(<https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily>;\nGHCN), coordinated by National Climatic Data Center at NOAA;\nthe Daymet gridded estimates of daily weather parameters for\nNorth America, version 4, available from the Oak Ridge National\nLaboratory's Distributed Active Archive Center\n(<https://daymet.ornl.gov/>; DAAC); the International Tree Ring\nData Bank; the National Land Cover Database\n(<https://www.mrlc.gov/>; NLCD); the Cropland Data Layer from\nthe National Agricultural Statistics Service\n(<https://www.nass.usda.gov/Research_and_Science/Cropland/SARS1a.php>;\nNASS); and the PAD-US dataset of protected area boundaries\n(<https://www.usgs.gov/programs/gap-analysis-project/science/pad-us-data-overview>;\nUSGS). %>% agol_filter agol_filter_httr cdl_colors check_service download_data download_ghcn_daily_station download_itrdb download_ssurgo_inventory download_ssurgo_study_area extract_ssurgo_data get_cdl get_daymet get_ghcn_daily get_ghcn_daily_station get_ghcn_inventory get_itrdb get_nass get_nass_cdl get_ned get_ned_tile get_nhd get_nlcd get_nlcd_annual get_padus get_ssurgo get_ssurgo_inventory get_ssurgo_study_area get_wbd nlcd_colors pal_nlcd plot_nhd polygon_from_extent read_crn read_crn_data read_crn_metadata replace_null sequential_duplicated split_bbox station_to_data_frame substr_right unwrap_rows url_base peer-reviewed"
  },
  {
    "id": 571,
    "package_name": "finalsize",
    "title": "Calculate the Final Size of an Epidemic",
    "description": "Calculate the final size of a\nsusceptible-infectious-recovered epidemic in a population with\ndemographic variation in contact patterns and susceptibility to\ndisease, as discussed in Miller (2012)\n<doi:10.1007/s11538-012-9749-6>.",
    "version": "0.2.1.9000",
    "maintainer": "Rosalind Eggo <r.eggo@lshtm.ac.uk>",
    "author": "Pratik Gupte [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-5294-7819>),\nEdwin Van Leeuwen [aut, cph] (ORCID:\n<https://orcid.org/0000-0002-2383-5305>),\nAdam Kucharski [aut, cph] (ORCID:\n<https://orcid.org/0000-0001-8814-9421>),\nRosalind Eggo [ctb, cre] (ORCID:\n<https://orcid.org/0000-0002-0362-6717>),\nHugo Gruson [ctb] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nThibaut Jombart [ctb] (ORCID: <https://orcid.org/0000-0003-3796-2097>),\nAndree Valle-Campos [ctb] (ORCID:\n<https://orcid.org/0000-0002-7779-481X>),\nJoshua W. Lambert [rev] (ORCID:\n<https://orcid.org/0000-0001-5218-3046>)",
    "url": "https://github.com/epiverse-trace/finalsize,\nhttps://epiverse-trace.github.io/finalsize/",
    "bug_reports": "https://github.com/epiverse-trace/finalsize/issues",
    "repository": "",
    "exports": [
      [
        "final_size"
      ],
      [
        "lambda_to_r0"
      ],
      [
        "r_eff"
      ],
      [
        "r0_to_lambda"
      ]
    ],
    "topics": [
      [
        "epidemic-modelling"
      ],
      [
        "epidemiology"
      ],
      [
        "epiverse"
      ],
      [
        "outbreak-analysis"
      ],
      [
        "rcpp"
      ],
      [
        "sdg-3"
      ],
      [
        "cpp"
      ]
    ],
    "score": 7.7147,
    "stars": 15,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "finalsize Calculate the Final Size of an Epidemic Calculate the final size of a\nsusceptible-infectious-recovered epidemic in a population with\ndemographic variation in contact patterns and susceptibility to\ndisease, as discussed in Miller (2012)\n<doi:10.1007/s11538-012-9749-6>. final_size lambda_to_r0 r_eff r0_to_lambda epidemic-modelling epidemiology epiverse outbreak-analysis rcpp sdg-3 cpp"
  },
  {
    "id": 540,
    "package_name": "essurvey",
    "title": "Download Data from the European Social Survey on the Fly",
    "description": "Download data from the European Social Survey directly\nfrom their website <http://www.europeansocialsurvey.org/>.\nThere are two families of functions that allow you to download\nand interactively check all countries and rounds available.",
    "version": "1.0.8",
    "maintainer": "Jorge Cimentada <cimentadaj@gmail.com>",
    "author": "Jorge Cimentada [aut, cre],\nThomas Leeper [rev] (Thomas reviewed the package for rOpensci,see\nhttps://github.com/ropensci/software-review/issues/201),\nNujcharee Haswell [rev] (Nujcharee reviewed the package for rOpensci,\nsee https://github.com/ropensci/software-review/issues/201),\nJorge Lopez [ctb],\nFran\u00e7ois Briatte [ctb]",
    "url": "https://docs.ropensci.org/essurvey/,\nhttps://github.com/ropensci/essurvey",
    "bug_reports": "https://github.com/ropensci/essurvey/issues",
    "repository": "",
    "exports": [
      [
        "download_country"
      ],
      [
        "download_rounds"
      ],
      [
        "download_sddf_country"
      ],
      [
        "import_all_cntrounds"
      ],
      [
        "import_all_rounds"
      ],
      [
        "import_all_sddf_cntrounds"
      ],
      [
        "import_country"
      ],
      [
        "import_rounds"
      ],
      [
        "import_sddf_country"
      ],
      [
        "recode_missings"
      ],
      [
        "recode_numeric_missing"
      ],
      [
        "recode_strings_missing"
      ],
      [
        "set_email"
      ],
      [
        "show_countries"
      ],
      [
        "show_country_rounds"
      ],
      [
        "show_rounds"
      ],
      [
        "show_rounds_country"
      ],
      [
        "show_sddf_cntrounds"
      ],
      [
        "show_theme_rounds"
      ],
      [
        "show_themes"
      ]
    ],
    "topics": [
      [
        "ess"
      ]
    ],
    "score": 6.9171,
    "stars": 51,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "essurvey Download Data from the European Social Survey on the Fly Download data from the European Social Survey directly\nfrom their website <http://www.europeansocialsurvey.org/>.\nThere are two families of functions that allow you to download\nand interactively check all countries and rounds available. download_country download_rounds download_sddf_country import_all_cntrounds import_all_rounds import_all_sddf_cntrounds import_country import_rounds import_sddf_country recode_missings recode_numeric_missing recode_strings_missing set_email show_countries show_country_rounds show_rounds show_rounds_country show_sddf_cntrounds show_theme_rounds show_themes ess"
  },
  {
    "id": 686,
    "package_name": "historydata",
    "title": "Datasets for Historians",
    "description": "These sample data sets are intended for historians\nlearning R. They include population, institutional, religious,\nmilitary, and prosopographical data suitable for mapping,\nquantitative analysis, and network analysis.",
    "version": "0.3.0",
    "maintainer": "Hien Le <minhhien2872002@gmail.com>",
    "author": "Lincoln Mullen [aut] (ORCID: <https://orcid.org/0000-0001-5103-6917>),\nMack Holt [ctb],\nErik Steiner [ctb],\nJason Heppler [ctb],\nJordan Bradford [ctb],\nHien Le [aut, cre]",
    "url": "https://docs.ropensci.org/historydata/,\nhttps://github.com/ropensci/historydata",
    "bug_reports": "https://github.com/ropensci/historydata/issues",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 6.9085,
    "stars": 91,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "historydata Datasets for Historians These sample data sets are intended for historians\nlearning R. They include population, institutional, religious,\nmilitary, and prosopographical data suitable for mapping,\nquantitative analysis, and network analysis.  "
  },
  {
    "id": 21,
    "package_name": "ColOpenData",
    "title": "Download Colombian Demographic, Climate and Geospatial Data",
    "description": "Downloads wrangled Colombian socioeconomic,\ngeospatial,population and climate data from DANE\n<https://www.dane.gov.co/> (National Administrative Department\nof Statistics) and IDEAM <https://ideam.gov.co> (Institute of\nHydrology, Meteorology and Environmental Studies). It solves\nthe problem of Colombian data being issued in different web\npages and sources by using functions that allow the user to\nselect the desired database and download it without having to\ndo the exhausting acquisition process.",
    "version": "0.3.1",
    "maintainer": "Maria Camila Tavera-Cifuentes <mc.tavera@uniandes.edu.co>",
    "author": "Maria Camila Tavera-Cifuentes [aut, cre, cph] (ORCID:\n<https://orcid.org/0009-0007-1610-4583>),\nJulian Otero [aut, cph] (ORCID:\n<https://orcid.org/0009-0006-0429-7747>),\nNatalia Nino-Machado [ctb] (ORCID:\n<https://orcid.org/0000-0001-7887-9439>),\nCatalina Gonzalez-Uribe [ctb] (ORCID:\n<https://orcid.org/0000-0002-3322-5017>),\nJuan Manuel Cordovez [ctb] (ORCID:\n<https://orcid.org/0000-0002-4005-3567>),\nHugo Gruson [rev] (ORCID: <https://orcid.org/0000-0002-4094-1476>),\nChris Hartgerink [rev] (ORCID: <https://orcid.org/0000-0003-1050-6809>),\nKarim Mane [rev] (ORCID: <https://orcid.org/0000-0002-9892-2999>),\nJoshua W. Lambert [rev] (ORCID:\n<https://orcid.org/0000-0001-5218-3046>)",
    "url": "https://github.com/epiverse-trace/ColOpenData,\nhttps://epiverse-trace.github.io/ColOpenData/",
    "bug_reports": "https://github.com/epiverse-trace/ColOpenData/issues",
    "repository": "",
    "exports": [
      [
        "aggregate_climate"
      ],
      [
        "code_to_name_dep"
      ],
      [
        "code_to_name_mun"
      ],
      [
        "divipola_table"
      ],
      [
        "download_climate"
      ],
      [
        "download_climate_geom"
      ],
      [
        "download_climate_stations"
      ],
      [
        "download_demographic"
      ],
      [
        "download_geospatial"
      ],
      [
        "download_pop_projections"
      ],
      [
        "geospatial_dictionary"
      ],
      [
        "get_climate_tags"
      ],
      [
        "list_datasets"
      ],
      [
        "look_up"
      ],
      [
        "merge_geo_demographic"
      ],
      [
        "name_to_code_dep"
      ],
      [
        "name_to_code_mun"
      ],
      [
        "name_to_standard_dep"
      ],
      [
        "name_to_standard_mun"
      ],
      [
        "stations_in_roi"
      ]
    ],
    "topics": [
      [
        "climate"
      ],
      [
        "colombia"
      ],
      [
        "data-package"
      ],
      [
        "demographics"
      ],
      [
        "maps"
      ]
    ],
    "score": 6.6189,
    "stars": 11,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "ColOpenData Download Colombian Demographic, Climate and Geospatial Data Downloads wrangled Colombian socioeconomic,\ngeospatial,population and climate data from DANE\n<https://www.dane.gov.co/> (National Administrative Department\nof Statistics) and IDEAM <https://ideam.gov.co> (Institute of\nHydrology, Meteorology and Environmental Studies). It solves\nthe problem of Colombian data being issued in different web\npages and sources by using functions that allow the user to\nselect the desired database and download it without having to\ndo the exhausting acquisition process. aggregate_climate code_to_name_dep code_to_name_mun divipola_table download_climate download_climate_geom download_climate_stations download_demographic download_geospatial download_pop_projections geospatial_dictionary get_climate_tags list_datasets look_up merge_geo_demographic name_to_code_dep name_to_code_mun name_to_standard_dep name_to_standard_mun stations_in_roi climate colombia data-package demographics maps"
  },
  {
    "id": 596,
    "package_name": "fuzzySim",
    "title": "Fuzzy Similarity in Species Distributions",
    "description": "Functions to compute fuzzy versions of species occurrence\npatterns based on presence-absence data (including inverse\ndistance interpolation, trend surface analysis, and\nprevalence-independent favourability obtained from probability\nof presence), as well as pair-wise fuzzy similarity (based on\nfuzzy logic versions of commonly used similarity indices) among\nthose occurrence patterns. Includes also functions for model\nconsensus and comparison (overlap and fuzzy similarity, fuzzy\nloss, fuzzy gain), and for data preparation, such as obtaining\nunique abbreviations of species names, defining the background\nregion, cleaning and gridding (thinning) point occurrence data\nonto raster maps, selecting among (pseudo)absences to address\nsurvey bias, converting species lists (long format) to\npresence-absence tables (wide format), transposing part of a\ndata frame, selecting relevant variables for models, assessing\nthe false discovery rate, or analysing and dealing with\nmulticollinearity. Initially described in Barbosa (2015)\n<doi:10.1111/2041-210X.12372>.",
    "version": "4.42",
    "maintainer": "A. Marcia Barbosa <ana.marcia.barbosa@gmail.com>",
    "author": "A. Marcia Barbosa [aut],\nAlba Estrada [ctb],\nPaul Melloy [ctb],\nJose Carlos Guerrero [fnd],\nA. Marcia Barbosa [cre]",
    "url": "http://fuzzysim.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "appendData"
      ],
      [
        "biasLayer"
      ],
      [
        "bioThreat"
      ],
      [
        "cleanCoords"
      ],
      [
        "corSelect"
      ],
      [
        "distMat"
      ],
      [
        "distPres"
      ],
      [
        "dms2dec"
      ],
      [
        "entropy"
      ],
      [
        "Fav"
      ],
      [
        "favClass"
      ],
      [
        "FDR"
      ],
      [
        "fuzSim"
      ],
      [
        "fuzzyConsensus"
      ],
      [
        "fuzzyOverlay"
      ],
      [
        "fuzzyRangeChange"
      ],
      [
        "getPreds"
      ],
      [
        "getRegion"
      ],
      [
        "gridRecords"
      ],
      [
        "integerCols"
      ],
      [
        "modelTrim"
      ],
      [
        "modOverlap"
      ],
      [
        "multConvert"
      ],
      [
        "multGLM"
      ],
      [
        "multicol"
      ],
      [
        "multTSA"
      ],
      [
        "pairwiseRangemaps"
      ],
      [
        "partialResp"
      ],
      [
        "percentTestData"
      ],
      [
        "prevalence"
      ],
      [
        "rangemapSim"
      ],
      [
        "rarity"
      ],
      [
        "selectAbsences"
      ],
      [
        "sharedFav"
      ],
      [
        "simFromSetOps"
      ],
      [
        "simMat"
      ],
      [
        "spCodes"
      ],
      [
        "splist2presabs"
      ],
      [
        "stepByStep"
      ],
      [
        "stepwise"
      ],
      [
        "summaryWald"
      ],
      [
        "timer"
      ],
      [
        "transpose"
      ],
      [
        "triMatInd"
      ],
      [
        "vulnerability"
      ]
    ],
    "topics": [],
    "score": 6.2369,
    "stars": 2,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "fuzzySim Fuzzy Similarity in Species Distributions Functions to compute fuzzy versions of species occurrence\npatterns based on presence-absence data (including inverse\ndistance interpolation, trend surface analysis, and\nprevalence-independent favourability obtained from probability\nof presence), as well as pair-wise fuzzy similarity (based on\nfuzzy logic versions of commonly used similarity indices) among\nthose occurrence patterns. Includes also functions for model\nconsensus and comparison (overlap and fuzzy similarity, fuzzy\nloss, fuzzy gain), and for data preparation, such as obtaining\nunique abbreviations of species names, defining the background\nregion, cleaning and gridding (thinning) point occurrence data\nonto raster maps, selecting among (pseudo)absences to address\nsurvey bias, converting species lists (long format) to\npresence-absence tables (wide format), transposing part of a\ndata frame, selecting relevant variables for models, assessing\nthe false discovery rate, or analysing and dealing with\nmulticollinearity. Initially described in Barbosa (2015)\n<doi:10.1111/2041-210X.12372>. appendData biasLayer bioThreat cleanCoords corSelect distMat distPres dms2dec entropy Fav favClass FDR fuzSim fuzzyConsensus fuzzyOverlay fuzzyRangeChange getPreds getRegion gridRecords integerCols modelTrim modOverlap multConvert multGLM multicol multTSA pairwiseRangemaps partialResp percentTestData prevalence rangemapSim rarity selectAbsences sharedFav simFromSetOps simMat spCodes splist2presabs stepByStep stepwise summaryWald timer transpose triMatInd vulnerability "
  },
  {
    "id": 524,
    "package_name": "epiCo",
    "title": "Statistical and Viz Tools for Vector-Borne Diseases in Colombia",
    "description": "Provides statistical and visualization tools for the\nanalysis of demographic indicators, and spatio-temporal\nbehavior and characterization of outbreaks of vector-borne\ndiseases (VBDs) in Colombia. It implements travel times\nestimated in Bravo-Vega C., Santos-Vega M., & Cordovez J.M.\n(2022), and the endemic channel method (Bortman, M.  (1999)\n<https://iris.paho.org/handle/10665.2/8562>).",
    "version": "1.0.1.9000",
    "maintainer": "Juan D. Uma\u00f1a <jd.umana10@uniandes.edu.co>",
    "author": "Juan D. Uma\u00f1a [aut, cre, cph] (ORCID:\n<https://orcid.org/0000-0003-0316-6164>),\nJuan Montenegro-Torres [aut] (ORCID:\n<https://orcid.org/0000-0003-2755-4743>),\nJulian Otero [aut] (ORCID: <https://orcid.org/0009-0006-0429-7747>),\nHugo Gruson [ctb] (ORCID: <https://orcid.org/0000-0002-4094-1476>)",
    "url": "https://epiverse-trace.github.io/epiCo/,\nhttps://github.com/epiverse-trace/epiCo",
    "bug_reports": "https://github.com/epiverse-trace/epiCo/issues",
    "repository": "",
    "exports": [
      [
        "age_risk"
      ],
      [
        "describe_ethnicity"
      ],
      [
        "describe_occupation"
      ],
      [
        "endemic_channel"
      ],
      [
        "epi_calendar"
      ],
      [
        "geometric_mean"
      ],
      [
        "geometric_sd"
      ],
      [
        "incidence_rate"
      ],
      [
        "morans_index"
      ],
      [
        "neighborhoods"
      ],
      [
        "population_pyramid"
      ]
    ],
    "topics": [
      [
        "colombia"
      ],
      [
        "decision-support"
      ],
      [
        "demographics"
      ],
      [
        "epiverse"
      ],
      [
        "outbreak-analysis"
      ],
      [
        "sdg-3"
      ],
      [
        "spatio-temporal-analysis"
      ],
      [
        "vector-borne-diseases"
      ]
    ],
    "score": 6.1931,
    "stars": 13,
    "primary_category": "epidemiology",
    "source_universe": "epiverse-trace",
    "search_text": "epiCo Statistical and Viz Tools for Vector-Borne Diseases in Colombia Provides statistical and visualization tools for the\nanalysis of demographic indicators, and spatio-temporal\nbehavior and characterization of outbreaks of vector-borne\ndiseases (VBDs) in Colombia. It implements travel times\nestimated in Bravo-Vega C., Santos-Vega M., & Cordovez J.M.\n(2022), and the endemic channel method (Bortman, M.  (1999)\n<https://iris.paho.org/handle/10665.2/8562>). age_risk describe_ethnicity describe_occupation endemic_channel epi_calendar geometric_mean geometric_sd incidence_rate morans_index neighborhoods population_pyramid colombia decision-support demographics epiverse outbreak-analysis sdg-3 spatio-temporal-analysis vector-borne-diseases"
  },
  {
    "id": 886,
    "package_name": "nomisr",
    "title": "Access 'Nomis' UK Labour Market Data",
    "description": "Access UK official statistics from the 'Nomis' database.\n'Nomis' includes data from the Census, the Labour Force Survey,\nDWP benefit statistics and other economic and demographic data\nfrom the Office for National Statistics, based around\nstatistical geographies. See\n<https://www.nomisweb.co.uk/api/v01/help> for full API\ndocumentation.",
    "version": "0.4.7",
    "maintainer": "Evan Odell <evanodell91@gmail.com>",
    "author": "Evan Odell [aut, cre] (ORCID: <https://orcid.org/0000-0003-1845-808X>),\nPaul Egeler [rev, ctb],\nChristophe Dervieux [rev] (ORCID:\n<https://orcid.org/0000-0003-4474-2498>),\nNina Robery [ctb] (Work and Health Indicators with nomisr vignette)",
    "url": "https://github.com/ropensci/nomisr,\nhttps://docs.evanodell.com/nomisr",
    "bug_reports": "https://github.com/ropensci/nomisr/issues",
    "repository": "",
    "exports": [
      [
        "nomis_api_key"
      ],
      [
        "nomis_codelist"
      ],
      [
        "nomis_content_type"
      ],
      [
        "nomis_data_info"
      ],
      [
        "nomis_get_data"
      ],
      [
        "nomis_get_metadata"
      ],
      [
        "nomis_overview"
      ],
      [
        "nomis_search"
      ]
    ],
    "topics": [
      [
        "api-client"
      ],
      [
        "census-data"
      ],
      [
        "demography"
      ],
      [
        "geographic-data"
      ],
      [
        "national-statistics"
      ],
      [
        "official-statistics"
      ],
      [
        "officialstatistics"
      ],
      [
        "peer-reviewed"
      ],
      [
        "uk"
      ]
    ],
    "score": 6.0617,
    "stars": 51,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "nomisr Access 'Nomis' UK Labour Market Data Access UK official statistics from the 'Nomis' database.\n'Nomis' includes data from the Census, the Labour Force Survey,\nDWP benefit statistics and other economic and demographic data\nfrom the Office for National Statistics, based around\nstatistical geographies. See\n<https://www.nomisweb.co.uk/api/v01/help> for full API\ndocumentation. nomis_api_key nomis_codelist nomis_content_type nomis_data_info nomis_get_data nomis_get_metadata nomis_overview nomis_search api-client census-data demography geographic-data national-statistics official-statistics officialstatistics peer-reviewed uk"
  },
  {
    "id": 752,
    "package_name": "leapfrog",
    "title": "Multistate Population Projection Model for Demographic and HIV\nEstimation",
    "description": "Leapfrog is a multistate population projection model for\nestimating population, demographic indicators, and HIV\nepidemic. The model combines a standard cohort component model\nof population projection (CCMPP) with a multistate model for\nHIV infection, disease progression, and treatment. Statistical\ntools are implemented for joint inference from multiple\ndemographic and epidemiologic data sources.",
    "version": "0.1.7",
    "maintainer": "Robert Ashton <robertashton94@gmail.com>",
    "author": "Jeffrey Imai-Eaton [aut] (ORCID:\n<https://orcid.org/0000-0001-7728-728X>),\nMagdalene Walters [aut],\nRobert Ashton [aut, cre],\nMantra Kusumgar [aut]",
    "url": "https://github.com/mrc-ide/leapfrog",
    "bug_reports": "https://github.com/mrc-ide/leapfrog/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "get_time_slice"
      ],
      [
        "list_model_configurations"
      ],
      [
        "process_parameters_to_cpp"
      ],
      [
        "process_parameters_to_r"
      ],
      [
        "process_pjnz"
      ],
      [
        "read_parameters"
      ],
      [
        "run_model"
      ],
      [
        "run_model_from_state"
      ],
      [
        "run_model_single_year"
      ],
      [
        "save_parameters"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 5.2375,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "leapfrog Multistate Population Projection Model for Demographic and HIV\nEstimation Leapfrog is a multistate population projection model for\nestimating population, demographic indicators, and HIV\nepidemic. The model combines a standard cohort component model\nof population projection (CCMPP) with a multistate model for\nHIV infection, disease progression, and treatment. Statistical\ntools are implemented for joint inference from multiple\ndemographic and epidemiologic data sources. %>% get_time_slice list_model_configurations process_parameters_to_cpp process_parameters_to_r process_pjnz read_parameters run_model run_model_from_state run_model_single_year save_parameters cpp"
  },
  {
    "id": 352,
    "package_name": "censo2017",
    "title": "Base de Datos de Facil Acceso del Censo 2017 de Chile (2017\nChilean Census Easy Access Database)",
    "description": "Provee un acceso conveniente a mas de 17 millones de\nregistros de la base de datos del Censo 2017. Los datos fueron\nimportados desde el DVD oficial del INE usando el Convertidor\nREDATAM creado por Pablo De Grande. Esta paquete esta\ndocumentado intencionalmente en castellano asciificado para que\nfuncione sin problema en diferentes plataformas. (Provides\nconvenient access to more than 17 million records from the\nChilean Census 2017 database. The datasets were imported from\nthe official DVD provided by the Chilean National Bureau of\nStatistics by using the REDATAM converter created by Pablo De\nGrande and in addition it includes the maps accompanying these\ndatasets.)",
    "version": "0.6.1",
    "maintainer": "Mauricio Vargas <mavargas11@uc.cl>",
    "author": "Mauricio Vargas [aut, cre] (ORCID:\n<https://orcid.org/0000-0003-1017-7574>),\nJuan Correa [ctb],\nMaria Paula Caldas [rev] (rOpenSci),\nFrans van Dunn\u00e9 [rev] (rOpenSci),\nMelina Vidoni [rev] (rOpenSci),\nConstanza Manriquez [rev] (revision independiente de las vinietas),\nInstituto Nacional de Estadisticas (INE) [dtc]",
    "url": "https://docs.ropensci.org/censo2017/",
    "bug_reports": "https://github.com/ropensci/censo2017/issues/",
    "repository": "",
    "exports": [
      [
        "censo_conectar"
      ],
      [
        "censo_descargar"
      ],
      [
        "censo_desconectar"
      ],
      [
        "censo_eliminar"
      ],
      [
        "censo_tabla"
      ]
    ],
    "topics": [
      [
        "censo"
      ],
      [
        "census"
      ],
      [
        "chile"
      ],
      [
        "demografia"
      ],
      [
        "demographics"
      ],
      [
        "duckdb"
      ],
      [
        "redatam"
      ]
    ],
    "score": 5.1099,
    "stars": 28,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "censo2017 Base de Datos de Facil Acceso del Censo 2017 de Chile (2017\nChilean Census Easy Access Database) Provee un acceso conveniente a mas de 17 millones de\nregistros de la base de datos del Censo 2017. Los datos fueron\nimportados desde el DVD oficial del INE usando el Convertidor\nREDATAM creado por Pablo De Grande. Esta paquete esta\ndocumentado intencionalmente en castellano asciificado para que\nfuncione sin problema en diferentes plataformas. (Provides\nconvenient access to more than 17 million records from the\nChilean Census 2017 database. The datasets were imported from\nthe official DVD provided by the Chilean National Bureau of\nStatistics by using the REDATAM converter created by Pablo De\nGrande and in addition it includes the maps accompanying these\ndatasets.) censo_conectar censo_descargar censo_desconectar censo_eliminar censo_tabla censo census chile demografia demographics duckdb redatam"
  },
  {
    "id": 591,
    "package_name": "frogger",
    "title": "Multistate Population Projection Model for Demographic and HIV\nEstimation",
    "description": "Leapfrog is a multistate population projection model for\nestimating population, demographic indicators, and HIV\nepidemic. The model combines a standard cohort component model\nof population projection (CCMPP) with a multistate model for\nHIV infection, disease progression, and treatment. Statistical\ntools are implemented for joint inference from multiple\ndemographic and epidemiologic data sources.",
    "version": "0.1.5",
    "maintainer": "Robert Ashton <robertashton94@gmail.com>",
    "author": "Jeffrey Imai-Eaton [aut] (ORCID:\n<https://orcid.org/0000-0001-7728-728X>),\nMagdalene Walters [aut],\nRobert Ashton [aut, cre],\nMantra Kusumgar [aut]",
    "url": "https://github.com/mrc-ide/frogger",
    "bug_reports": "https://github.com/mrc-ide/frogger/issues",
    "repository": "",
    "exports": [
      [
        "%>%"
      ],
      [
        "get_time_slice"
      ],
      [
        "list_model_configurations"
      ],
      [
        "prepare_hc_leapfrog_projp"
      ],
      [
        "prepare_leapfrog_demp"
      ],
      [
        "prepare_leapfrog_parameters"
      ],
      [
        "prepare_leapfrog_projp"
      ],
      [
        "process_parameters_to_cpp"
      ],
      [
        "process_parameters_to_r"
      ],
      [
        "read_parameters"
      ],
      [
        "run_model"
      ],
      [
        "run_model_from_state"
      ],
      [
        "run_model_single_year"
      ],
      [
        "save_parameters"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 5.043,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "frogger Multistate Population Projection Model for Demographic and HIV\nEstimation Leapfrog is a multistate population projection model for\nestimating population, demographic indicators, and HIV\nepidemic. The model combines a standard cohort component model\nof population projection (CCMPP) with a multistate model for\nHIV infection, disease progression, and treatment. Statistical\ntools are implemented for joint inference from multiple\ndemographic and epidemiologic data sources. %>% get_time_slice list_model_configurations prepare_hc_leapfrog_projp prepare_leapfrog_demp prepare_leapfrog_parameters prepare_leapfrog_projp process_parameters_to_cpp process_parameters_to_r read_parameters run_model run_model_from_state run_model_single_year save_parameters cpp"
  },
  {
    "id": 212,
    "package_name": "USAboundariesData",
    "title": "Datasets for the 'USAboundaries' package",
    "description": "Contains datasets, including higher resolution boundary\ndata, for use in the 'USAboundaries' package. These datasets\ncome from the U.S. Census Bureau, the Newberry Library's\n'Historical Atlas of U.S. County Boundaries', and Erik\nSteiner's 'United States Historical City Populations,\n1790-2010'.",
    "version": "0.5.1",
    "maintainer": "Jacci Ziebert <jacciziebert@gmail.com>",
    "author": "Lincoln Mullen [aut] (ORCID: <https://orcid.org/0000-0001-5103-6917>),\nDr. William M. Scholl Center for American History and Culture, The\nNewberry Library [cph],\nUnited States Census Bureau [cph],\nErik Steiner [ctb],\nJacci Ziebert [cre]",
    "url": "https://docs.ropensci.org/USAboundaries,\nhttps://github.com/ropensci/USAboundariesdata",
    "bug_reports": "https://github.com/ropensci/USAboundariesData/issues",
    "repository": "",
    "exports": [],
    "topics": [],
    "score": 4.9171,
    "stars": 9,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "USAboundariesData Datasets for the 'USAboundaries' package Contains datasets, including higher resolution boundary\ndata, for use in the 'USAboundaries' package. These datasets\ncome from the U.S. Census Bureau, the Newberry Library's\n'Historical Atlas of U.S. County Boundaries', and Erik\nSteiner's 'United States Historical City Populations,\n1790-2010'.  "
  },
  {
    "id": 933,
    "package_name": "outcomerate",
    "title": "AAPOR Survey Outcome Rates",
    "description": "Standardized survey outcome rate functions, including the\nresponse rate, contact rate, cooperation rate, and refusal\nrate. These outcome rates allow survey researchers to measure\nthe quality of survey data using definitions published by the\nAmerican Association of Public Opinion Research (AAPOR). For\ndetails on these standards, see AAPOR (2016)\n<https://www.aapor.org/Standards-Ethics/Standard-Definitions-(1).aspx>.",
    "version": "1.0.1.9000",
    "maintainer": "Rafael Pilliard Hellwig <rafael.taph@gmail.com>",
    "author": "Rafael Pilliard Hellwig [aut, cre] (ORCID:\n<https://orcid.org/0000-0002-3092-3493>),\nCarl Ganz [rev],\nNeal Richardson [rev]",
    "url": "https://docs.ropensci.org/outcomerate,\nhttps://github.com/ropensci/outcomerate",
    "bug_reports": "https://github.com/ropensci/outcomerate/issues",
    "repository": "",
    "exports": [
      [
        "eligibility_rate"
      ],
      [
        "outcomerate"
      ]
    ],
    "topics": [
      [
        "aapor"
      ],
      [
        "disposition-codes"
      ],
      [
        "peer-reviewed"
      ],
      [
        "standards"
      ],
      [
        "survey"
      ]
    ],
    "score": 4.8751,
    "stars": 5,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "outcomerate AAPOR Survey Outcome Rates Standardized survey outcome rate functions, including the\nresponse rate, contact rate, cooperation rate, and refusal\nrate. These outcome rates allow survey researchers to measure\nthe quality of survey data using definitions published by the\nAmerican Association of Public Opinion Research (AAPOR). For\ndetails on these standards, see AAPOR (2016)\n<https://www.aapor.org/Standards-Ethics/Standard-Definitions-(1).aspx>. eligibility_rate outcomerate aapor disposition-codes peer-reviewed standards survey"
  },
  {
    "id": 1445,
    "package_name": "wmm",
    "title": "World Magnetic Model",
    "description": "Calculate magnetic field at a given location and time\naccording to the World Magnetic Model (WMM). Both the main\nfield and secular variation components are returned. This\nfunctionality is useful for physicists and geophysicists who\nneed orthogonal components from WMM. Currently, this package\nsupports annualized time inputs between 2000-01-01 to\n2029-12-31. If desired, users can specify which WMM version to\nuse, e.g., the original WMM2015 release or the recent\nout-of-cycle WMM2015 release. Methods used to implement WMM,\nincluding the Gauss coefficients for each release, are\ndescribed in the following publications: NOAA NCEI Geomagnetic\nModeling Team and British Geological Survey (2024)\n<doi:10.25921/aqfd-sd83>, Chulliat et al (2020)\n<doi:10.25923/ytk1-yx35>, Chulliat et al (2019)\n<doi:10.25921/xhr3-0t19>, Chulliat et al (2015)\n<doi:10.7289/V5TB14V7>, Maus et al (2010)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/WMM2010_Report.pdf>,\nMcLean et al (2004)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/TRWMM_2005.pdf>,\nand Macmillian et al (2000)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/wmm2000.pdf>.",
    "version": "1.1.3",
    "maintainer": "Will Frierson <will.frierson@gmail.com>",
    "author": "Will Frierson [aut, cre]",
    "url": "https://github.com/wfrierson/wmm",
    "bug_reports": "https://github.com/wfrierson/wmm/issues",
    "repository": "",
    "exports": [
      [
        "GetMagneticFieldWMM"
      ],
      [
        "wmm"
      ]
    ],
    "topics": [],
    "score": 4.8451,
    "stars": 7,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "wmm World Magnetic Model Calculate magnetic field at a given location and time\naccording to the World Magnetic Model (WMM). Both the main\nfield and secular variation components are returned. This\nfunctionality is useful for physicists and geophysicists who\nneed orthogonal components from WMM. Currently, this package\nsupports annualized time inputs between 2000-01-01 to\n2029-12-31. If desired, users can specify which WMM version to\nuse, e.g., the original WMM2015 release or the recent\nout-of-cycle WMM2015 release. Methods used to implement WMM,\nincluding the Gauss coefficients for each release, are\ndescribed in the following publications: NOAA NCEI Geomagnetic\nModeling Team and British Geological Survey (2024)\n<doi:10.25921/aqfd-sd83>, Chulliat et al (2020)\n<doi:10.25923/ytk1-yx35>, Chulliat et al (2019)\n<doi:10.25921/xhr3-0t19>, Chulliat et al (2015)\n<doi:10.7289/V5TB14V7>, Maus et al (2010)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/WMM2010_Report.pdf>,\nMcLean et al (2004)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/TRWMM_2005.pdf>,\nand Macmillian et al (2000)\n<https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/wmm2000.pdf>. GetMagneticFieldWMM wmm "
  },
  {
    "id": 507,
    "package_name": "eDNAjoint",
    "title": "Joint Modeling of Traditional and Environmental DNA Survey Data\nin a Bayesian Framework",
    "description": "Models integrate environmental DNA (eDNA) detection data\nand traditional survey data to jointly estimate species catch\nrate (see package vignette: <https://ednajoint.netlify.app/>).\nModels can be used with count data via traditional survey\nmethods (i.e., trapping, electrofishing, visual) and replicated\neDNA detection/nondetection data via polymerase chain reaction\n(i.e., PCR or qPCR) from multiple survey locations. Estimated\nparameters include probability of a false positive eDNA\ndetection, a site-level covariates that scale the sensitivity\nof eDNA surveys relative to traditional surveys, and gear\nscaling coefficients for traditional gear types. Models are\nimplemented with a Bayesian framework (Markov chain Monte\nCarlo) using the 'Stan' probabilistic programming language.",
    "version": "0.3.3",
    "maintainer": "Abigail G. Keller <agkeller@berkeley.edu>",
    "author": "Abigail G. Keller [aut, cre],\nRyan P. Kelly [ctb],\nChitra M. Saraswati [rev],\nSaras M. Windecker [rev]",
    "url": "https://github.com/ropensci/eDNAjoint,\nhttps://docs.ropensci.org/eDNAjoint/",
    "bug_reports": "https://github.com/ropensci/eDNAjoint/issues",
    "repository": "",
    "exports": [
      [
        "detection_calculate"
      ],
      [
        "detection_plot"
      ],
      [
        "joint_model"
      ],
      [
        "joint_select"
      ],
      [
        "joint_summarize"
      ],
      [
        "mu_critical"
      ],
      [
        "traditional_model"
      ]
    ],
    "topics": [
      [
        "cpp"
      ]
    ],
    "score": 4.7226,
    "stars": 8,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "eDNAjoint Joint Modeling of Traditional and Environmental DNA Survey Data\nin a Bayesian Framework Models integrate environmental DNA (eDNA) detection data\nand traditional survey data to jointly estimate species catch\nrate (see package vignette: <https://ednajoint.netlify.app/>).\nModels can be used with count data via traditional survey\nmethods (i.e., trapping, electrofishing, visual) and replicated\neDNA detection/nondetection data via polymerase chain reaction\n(i.e., PCR or qPCR) from multiple survey locations. Estimated\nparameters include probability of a false positive eDNA\ndetection, a site-level covariates that scale the sensitivity\nof eDNA surveys relative to traditional surveys, and gear\nscaling coefficients for traditional gear types. Models are\nimplemented with a Bayesian framework (Markov chain Monte\nCarlo) using the 'Stan' probabilistic programming language. detection_calculate detection_plot joint_model joint_select joint_summarize mu_critical traditional_model cpp"
  },
  {
    "id": 53,
    "package_name": "FFD",
    "title": "Freedom from Disease",
    "description": "Functions, S4 classes/methods and a graphical user\ninterface (GUI) to design surveys to substantiate freedom from\ndisease using a modified hypergeometric function (see Cameron\nand Baldock, 1997, <doi:10.1016/s0167-5877(97)00081-0>). Herd\nsensitivities are computed according to sampling strategies\n\"individual sampling\" or \"limited sampling\" (see M. Ziller, T.\nSelhorst, J. Teuffert, M. Kramer and H. Schlueter, 2002,\n<doi:10.1016/S0167-5877(01)00245-8>). Methods to compute the\na-posteriori alpha-error are implemented. Risk-based targeted\nsampling is supported.",
    "version": "1.0-9",
    "maintainer": "Ian Kopacka <ian.kopacka@ages.at>",
    "author": "Ian Kopacka",
    "url": "http://ffd.r-forge.r-project.org, https://www.ages.at/startseite/",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "computeAlpha"
      ],
      [
        "computeAlphaLimitedSampling"
      ],
      [
        "computeAposterioriError"
      ],
      [
        "computeAposterioriErrorRiskGroups"
      ],
      [
        "computeOptimalSampleSize"
      ],
      [
        "computeOptimalSampleSizeRiskGroups"
      ],
      [
        "computePValue"
      ],
      [
        "computePValueRiskGroups"
      ],
      [
        "FFD_GUI"
      ],
      [
        "HTML"
      ],
      [
        "indSampling"
      ],
      [
        "indSamplingSummary"
      ],
      [
        "lls"
      ],
      [
        "ltdSampling"
      ],
      [
        "ltdSamplingSummary"
      ],
      [
        "plot"
      ],
      [
        "sample"
      ],
      [
        "show"
      ],
      [
        "summary"
      ],
      [
        "surveyData"
      ]
    ],
    "topics": [],
    "score": 4.2041,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "FFD Freedom from Disease Functions, S4 classes/methods and a graphical user\ninterface (GUI) to design surveys to substantiate freedom from\ndisease using a modified hypergeometric function (see Cameron\nand Baldock, 1997, <doi:10.1016/s0167-5877(97)00081-0>). Herd\nsensitivities are computed according to sampling strategies\n\"individual sampling\" or \"limited sampling\" (see M. Ziller, T.\nSelhorst, J. Teuffert, M. Kramer and H. Schlueter, 2002,\n<doi:10.1016/S0167-5877(01)00245-8>). Methods to compute the\na-posteriori alpha-error are implemented. Risk-based targeted\nsampling is supported. computeAlpha computeAlphaLimitedSampling computeAposterioriError computeAposterioriErrorRiskGroups computeOptimalSampleSize computeOptimalSampleSizeRiskGroups computePValue computePValueRiskGroups FFD_GUI HTML indSampling indSamplingSummary lls ltdSampling ltdSamplingSummary plot sample show summary surveyData "
  },
  {
    "id": 800,
    "package_name": "mbquartR",
    "title": "Finding Manitoba Quarter Sections",
    "description": "This package has four main functions: 1) download the\nManitoba Original Survey Legal Descriptions data set; 2) find\nthe coordinates of a quarter sections given the legal land\ndescription (e.g., \"NE-11-33-29W\"); 3) find the legal land\ndescription using coordinates (lat and long); and 4) plot these\npoints on a map.",
    "version": "0.1.0",
    "maintainer": "Alex Koiter <koitera@brandonu.ca>",
    "author": "Alex Koiter [aut, cre] (ORCID: <https://orcid.org/0000-0002-9355-9561>,\nAssociate Professor, Department of Geography and Environment,\nBrandon University <https://alexkoiter.ca/>),\nEmily H Markowitz [rev] (Research Fisheries Biologist, Alaska Fisheries\nScience Center NOAA Fisheries | U.S. Department of Commerce.\n<https://emilyhmarkowitz.github.io/emilyhmarkowitz> Emily reviewed\nthe package for rOpenSci, see\n<https://github.com/ropensci/software-review/issues/658>),\nSheila M Saia [rev] (Environmental Data Scientist, Tetra Tech.\n<https://sheilasaia.rbind.io/> Sheila reviewed the package for\nrOpenSci, see\n<https://github.com/ropensci/software-review/issues/658>)",
    "url": "https://docs.ropensci.org/mbquartR/,\nhttps://github.com/ropensci/mbquartR",
    "bug_reports": "https://github.com/ropensci/mbquartR/issues",
    "repository": "",
    "exports": [
      [
        "map_quarter"
      ],
      [
        "quarters_dl"
      ],
      [
        "search_coord"
      ],
      [
        "search_legal"
      ]
    ],
    "topics": [],
    "score": 3.9542,
    "stars": 1,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "mbquartR Finding Manitoba Quarter Sections This package has four main functions: 1) download the\nManitoba Original Survey Legal Descriptions data set; 2) find\nthe coordinates of a quarter sections given the legal land\ndescription (e.g., \"NE-11-33-29W\"); 3) find the legal land\ndescription using coordinates (lat and long); and 4) plot these\npoints on a map. map_quarter quarters_dl search_coord search_legal "
  },
  {
    "id": 1383,
    "package_name": "treestartr",
    "title": "Generate Starting Trees For Combined Molecular, Morphological\nand Stratigraphic Data",
    "description": "Combine a list of taxa with a phylogeny to generate a\nstarting tree for use in total evidence dating analyses.",
    "version": "0.1.0",
    "maintainer": "April Wright <april.wright@selu.edu>",
    "author": "April Wright [aut, cre]",
    "url": "https://docs.ropensci.org/treestartr/",
    "bug_reports": "https://github.com/ropensci/treeStartR/issues",
    "repository": "",
    "exports": [
      [
        "absent_tippr"
      ],
      [
        "dataf_parsr"
      ],
      [
        "echo_rb"
      ],
      [
        "echo_subtree"
      ],
      [
        "genera_strippr"
      ],
      [
        "present_tippr"
      ],
      [
        "rand_absent_tippr"
      ],
      [
        "text_placr"
      ]
    ],
    "topics": [],
    "score": 3.9085,
    "stars": 9,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "treestartr Generate Starting Trees For Combined Molecular, Morphological\nand Stratigraphic Data Combine a list of taxa with a phylogeny to generate a\nstarting tree for use in total evidence dating analyses. absent_tippr dataf_parsr echo_rb echo_subtree genera_strippr present_tippr rand_absent_tippr text_placr "
  },
  {
    "id": 298,
    "package_name": "birdsize",
    "title": "Estimate Avian Body Size Distributions",
    "description": "Generate estimated body size distributions for populations\nor communities of birds, given either species ID or species'\nmean body size. Designed to work naturally with the North\nAmerican Breeding Bird Survey, or with any dataset of bird\nspecies, abundance, and/or mean size data.",
    "version": "0.0.0.9000",
    "maintainer": "Renata Diaz <renata.diaz@weecology.org>",
    "author": "Renata Diaz [aut, cre] (ORCID: <https://orcid.org/0000-0003-0803-4734>),\nJohn Dunning [dtc]",
    "url": "https://github.com/diazrenata/birdsize",
    "bug_reports": "https://github.com/diazrenata/birdsize/issues",
    "repository": "",
    "exports": [
      [
        "community_generate"
      ],
      [
        "filter_bbs_survey"
      ],
      [
        "individual_metabolic_rate"
      ],
      [
        "pop_generate"
      ],
      [
        "species_define"
      ],
      [
        "species_lookup"
      ]
    ],
    "topics": [],
    "score": 3.8921,
    "stars": 3,
    "primary_category": "ropensci",
    "source_universe": "ropensci",
    "search_text": "birdsize Estimate Avian Body Size Distributions Generate estimated body size distributions for populations\nor communities of birds, given either species ID or species'\nmean body size. Designed to work naturally with the North\nAmerican Breeding Bird Survey, or with any dataset of bird\nspecies, abundance, and/or mean size data. community_generate filter_bbs_survey individual_metabolic_rate pop_generate species_define species_lookup "
  },
  {
    "id": 111,
    "package_name": "PST",
    "title": "Probabilistic Suffix Trees and Variable Length Markov Chains",
    "description": "Provides a framework for analysing state sequences with\nprobabilistic suffix trees (PST), the construction that stores\nvariable length Markov chains (VLMC). Besides functions for\nlearning and optimizing VLMC models, the PST library includes\nmany additional tools to analyse sequence data with these\nmodels: visualization tools, functions for sequence prediction\nand artificial sequences generation, as well as for context and\npattern mining. The package is specifically adapted to the\nfield of social sciences by allowing to learn VLMC models from\nsets of individual sequences possibly containing missing\nvalues, and by accounting for case weights. The library also\nallows to compute probabilistic divergence between two models,\nand to fit segmented VLMC, where sub-models fitted to distinct\nstrata of the learning sample are stored in a single PST. This\nsoftware results from research work executed within the\nframework of the Swiss National Centre of Competence in\nResearch LIVES, which is financed by the Swiss National Science\nFoundation. The authors are grateful to the Swiss National\nScience Foundation for its financial support.",
    "version": "0.95",
    "maintainer": "Alexis Gabadinho <alexis.gabadinho@wanadoo.fr>",
    "author": "Alexis Gabadinho [aut, cre, cph]",
    "url": "http://r-forge.r-project.org/projects/pst",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "cmine"
      ],
      [
        "cplot"
      ],
      [
        "cprob"
      ],
      [
        "generate"
      ],
      [
        "impute"
      ],
      [
        "logLik"
      ],
      [
        "nobs"
      ],
      [
        "nodenames"
      ],
      [
        "pdist"
      ],
      [
        "plot"
      ],
      [
        "pmine"
      ],
      [
        "ppplot"
      ],
      [
        "pqplot"
      ],
      [
        "predict"
      ],
      [
        "print"
      ],
      [
        "prune"
      ],
      [
        "pstree"
      ],
      [
        "query"
      ],
      [
        "subtree"
      ],
      [
        "summary"
      ],
      [
        "tune"
      ]
    ],
    "topics": [],
    "score": 3.5563,
    "stars": 0,
    "primary_category": "infrastructure",
    "source_universe": "r-forge",
    "search_text": "PST Probabilistic Suffix Trees and Variable Length Markov Chains Provides a framework for analysing state sequences with\nprobabilistic suffix trees (PST), the construction that stores\nvariable length Markov chains (VLMC). Besides functions for\nlearning and optimizing VLMC models, the PST library includes\nmany additional tools to analyse sequence data with these\nmodels: visualization tools, functions for sequence prediction\nand artificial sequences generation, as well as for context and\npattern mining. The package is specifically adapted to the\nfield of social sciences by allowing to learn VLMC models from\nsets of individual sequences possibly containing missing\nvalues, and by accounting for case weights. The library also\nallows to compute probabilistic divergence between two models,\nand to fit segmented VLMC, where sub-models fitted to distinct\nstrata of the learning sample are stored in a single PST. This\nsoftware results from research work executed within the\nframework of the Swiss National Centre of Competence in\nResearch LIVES, which is financed by the Swiss National Science\nFoundation. The authors are grateful to the Swiss National\nScience Foundation for its financial support. cmine cplot cprob generate impute logLik nobs nodenames pdist plot pmine ppplot pqplot predict print prune pstree query subtree summary tune "
  },
  {
    "id": 1002,
    "package_name": "popim",
    "title": "POPulation IMmunity: Run a Demographic Model of Vaccine Exposure\nOver Time",
    "description": "Tools for setting up an age-structured population,\napplying vaccination activities to it, and tracking\nvaccine-induced immunity through time.",
    "version": "0.0.1",
    "maintainer": "Tini Garske <t.garske@imperial.ac.uk>",
    "author": "Tini Garske [aut, cre] (ORCID: <https://orcid.org/0000-0002-8952-4710>)",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "apply_vacc"
      ],
      [
        "as_popim_pop"
      ],
      [
        "as_vacc_activities"
      ],
      [
        "calc_pop_immunity"
      ],
      [
        "complete_vacc_activities"
      ],
      [
        "plot_immunity"
      ],
      [
        "plot_pop_size"
      ],
      [
        "popim_population"
      ],
      [
        "popim_vacc_activities"
      ],
      [
        "read_popim_pop"
      ],
      [
        "read_vacc_activities"
      ],
      [
        "vacc_from_immunity"
      ]
    ],
    "topics": [],
    "score": 3.301,
    "stars": 1,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "popim POPulation IMmunity: Run a Demographic Model of Vaccine Exposure\nOver Time Tools for setting up an age-structured population,\napplying vaccination activities to it, and tracking\nvaccine-induced immunity through time. apply_vacc as_popim_pop as_vacc_activities calc_pop_immunity complete_vacc_activities plot_immunity plot_pop_size popim_population popim_vacc_activities read_popim_pop read_vacc_activities vacc_from_immunity "
  },
  {
    "id": 458,
    "package_name": "demogsurv",
    "title": "Demographic analysis of DHS and other household surveys",
    "description": "This package includes tools for calculating demographic\nindicators from household survey data. Initially developed for\nfor processing and analysis from Demographic and Health Surveys\n(DHS) and Multiple Indicator Cluster Surveys (MICS). The\npackage provides tools to calculate standard child mortality,\nadult mortality, and fertility indicators stratified\narbitrarily by age group, calendar period, pre-survey time\nperiods, birth cohorts and other survey variables (e.g.\nresidence, region, wealth status, education, etc.).\nDesign-based standard errors and sample correlations are\navailable for all indicators via Taylor linearisation or\njackknife.",
    "version": "0.2.6",
    "maintainer": "Jeff Eaton <jeffrey.eaton@imperial.ac.uk>",
    "author": "Jeff Eaton [aut, cre],\nBruno Masquelier [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "calc_asfr"
      ],
      [
        "calc_nqx"
      ],
      [
        "calc_tfr"
      ],
      [
        "demog_pyears"
      ],
      [
        "jackknife"
      ],
      [
        "reshape_sib_data"
      ]
    ],
    "topics": [],
    "score": 3.0881,
    "stars": 7,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "demogsurv Demographic analysis of DHS and other household surveys This package includes tools for calculating demographic\nindicators from household survey data. Initially developed for\nfor processing and analysis from Demographic and Health Surveys\n(DHS) and Multiple Indicator Cluster Surveys (MICS). The\npackage provides tools to calculate standard child mortality,\nadult mortality, and fertility indicators stratified\narbitrarily by age group, calendar period, pre-survey time\nperiods, birth cohorts and other survey variables (e.g.\nresidence, region, wealth status, education, etc.).\nDesign-based standard errors and sample correlations are\navailable for all indicators via Taylor linearisation or\njackknife. calc_asfr calc_nqx calc_tfr demog_pyears jackknife reshape_sib_data "
  },
  {
    "id": 1334,
    "package_name": "threemc",
    "title": "(Matt's) Multi-Level Model of Male Circumcision in Sub-Saharan\nAfrica",
    "description": "Functions and datasets to support, and extend to other\nSub-Saharan African countries, Thomas, M. et. al., 2021, A\nmulti-level model for estimating region-age-time-type specific\nmale circumcision coverage from household survey and health\nsystem data in South Africa, <arXiv:2108.091422>.",
    "version": "0.1.45",
    "maintainer": "Patrick O'Toole <potoole@imperial.ac.uk>",
    "author": "Matthew Thomas [aut] (ORCID: <https://orcid.org/0000-0001-8171-1936>),\nJeffrey Imai-Eaton [aut] (ORCID:\n<https://orcid.org/0000-0001-7728-728X>),\nPatrick O'Toole [cre] (ORCID: <https://orcid.org/0000-0002-1652-6555>),\nImperial College of Science, Technology and Medicine [cph]",
    "url": "https://github.com/mrc-ide/threemc",
    "bug_reports": "https://github.com/mrc-ide/threemc/issues",
    "repository": "",
    "exports": [
      [
        "compare_predictions"
      ],
      [
        "compute_quantiles"
      ],
      [
        "create_dirs_r"
      ],
      [
        "create_shell_dataset"
      ],
      [
        "find_circ_type"
      ],
      [
        "minimise_fit_obj"
      ],
      [
        "normalise_weights_kish"
      ],
      [
        "prepare_survey_data"
      ],
      [
        "read_circ_data"
      ],
      [
        "reassign_survey_level"
      ],
      [
        "spread_areas"
      ],
      [
        "survey_points_dmppt2_convert_convention"
      ],
      [
        "threemc_aggregate"
      ],
      [
        "threemc_empirical_rates"
      ],
      [
        "threemc_fit_model"
      ],
      [
        "threemc_initial_pars"
      ],
      [
        "threemc_ppc"
      ],
      [
        "threemc_ppc2"
      ],
      [
        "threemc_prepare_model_data"
      ]
    ],
    "topics": [],
    "score": 2.3802,
    "stars": 0,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "threemc (Matt's) Multi-Level Model of Male Circumcision in Sub-Saharan\nAfrica Functions and datasets to support, and extend to other\nSub-Saharan African countries, Thomas, M. et. al., 2021, A\nmulti-level model for estimating region-age-time-type specific\nmale circumcision coverage from household survey and health\nsystem data in South Africa, <arXiv:2108.091422>. compare_predictions compute_quantiles create_dirs_r create_shell_dataset find_circ_type minimise_fit_obj normalise_weights_kish prepare_survey_data read_circ_data reassign_survey_level spread_areas survey_points_dmppt2_convert_convention threemc_aggregate threemc_empirical_rates threemc_fit_model threemc_initial_pars threemc_ppc threemc_ppc2 threemc_prepare_model_data "
  },
  {
    "id": 467,
    "package_name": "dfertility",
    "title": "District level estimation of age-specific fertility",
    "description": "This package estimates district-level estimates of\nage-specific fertility from nationally representative household\nsurvey data.",
    "version": "0.1.666",
    "maintainer": "Oli Stevens <o.stevens@imperial.ac.uk>",
    "author": "Oli Stevens [aut, cre] (ORCID: <https://orcid.org/0000-0001-6842-9434>)",
    "url": "",
    "bug_reports": "",
    "repository": "",
    "exports": [
      [
        "area_populations"
      ],
      [
        "assign_cluster_area"
      ],
      [
        "assign_tips"
      ],
      [
        "calculate_dhs_fertility"
      ],
      [
        "calculate_mics_fertility"
      ],
      [
        "convert_age_groups"
      ],
      [
        "create_surveys_mics"
      ],
      [
        "extend_populations"
      ],
      [
        "extract_model_level"
      ],
      [
        "filter_mics"
      ],
      [
        "fit_sample_tmb"
      ],
      [
        "get_areas"
      ],
      [
        "get_boundaries"
      ],
      [
        "get_fertility_surveys"
      ],
      [
        "get_input_files"
      ],
      [
        "get_populations"
      ],
      [
        "ir_by_area"
      ],
      [
        "join_survey_areas"
      ],
      [
        "make_adjacency_matrix"
      ],
      [
        "make_asfr_inputs"
      ],
      [
        "make_model_frames_dev"
      ],
      [
        "make_rw_structure_matrix"
      ],
      [
        "make_tmb_inputs"
      ],
      [
        "make_tmb_obj"
      ],
      [
        "map_ir_to_areas"
      ],
      [
        "rmvnorm_sparseprec"
      ],
      [
        "sample_tmb"
      ],
      [
        "sdreport_joint_precision"
      ],
      [
        "solveSubset"
      ],
      [
        "tmb_outputs"
      ],
      [
        "transform_mics"
      ],
      [
        "updateCholesky"
      ],
      [
        "validate_model_frame"
      ]
    ],
    "topics": [],
    "score": 1,
    "stars": 1,
    "primary_category": "epidemiology",
    "source_universe": "mrc-ide",
    "search_text": "dfertility District level estimation of age-specific fertility This package estimates district-level estimates of\nage-specific fertility from nationally representative household\nsurvey data. area_populations assign_cluster_area assign_tips calculate_dhs_fertility calculate_mics_fertility convert_age_groups create_surveys_mics extend_populations extract_model_level filter_mics fit_sample_tmb get_areas get_boundaries get_fertility_surveys get_input_files get_populations ir_by_area join_survey_areas make_adjacency_matrix make_asfr_inputs make_model_frames_dev make_rw_structure_matrix make_tmb_inputs make_tmb_obj map_ir_to_areas rmvnorm_sparseprec sample_tmb sdreport_joint_precision solveSubset tmb_outputs transform_mics updateCholesky validate_model_frame "
  },
  {
    "id": 3,
    "package_name": "AssociationExplorer2",
    "title": "A User-Friendly 'shiny' Application for Exploring Associations\nand Visual Patterns",
    "description": "A user-friendly 'shiny' application to explore statistical associations and visual patterns in multivariate datasets. The app provides interactive correlation networks, bivariate plots, and summary tables for different types of variables (numeric and categorical). It also supports optional survey weights and range-based filters on association strengths, making it suitable for the exploration of survey and public data by non-technical users, journalists, educators, and researchers. For background and methodological details, see Soetewey et al. (2025) <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5637359>.",
    "version": "0.1.2",
    "maintainer": "Antoine Soetewey <antoine.soetewey@uclouvain.be>",
    "author": "Antoine Soetewey [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8159-0804>),\n  C\u00e9dric Heuchenne [aut] (0000-0002-3150-3044),\n  Arnaud Claes [aut] (0000-0003-0716-0798),\n  Antonin Descampe [aut] (0000-0002-0943-4126)",
    "url": "https://github.com/AntoineSoetewey/AssociationExplorer2",
    "bug_reports": "https://github.com/AntoineSoetewey/AssociationExplorer2/issues",
    "repository": "https://cran.r-project.org/package=AssociationExplorer2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AssociationExplorer2 A User-Friendly 'shiny' Application for Exploring Associations\nand Visual Patterns A user-friendly 'shiny' application to explore statistical associations and visual patterns in multivariate datasets. The app provides interactive correlation networks, bivariate plots, and summary tables for different types of variables (numeric and categorical). It also supports optional survey weights and range-based filters on association strengths, making it suitable for the exploration of survey and public data by non-technical users, journalists, educators, and researchers. For background and methodological details, see Soetewey et al. (2025) <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5637359>.  "
  },
  {
    "id": 183,
    "package_name": "SEMgraph",
    "title": "Network Analysis and Causal Inference Through Structural\nEquation Modeling",
    "description": "Estimate networks and causal relationships in complex systems through\n  Structural Equation Modeling. This package also includes functions for importing,\n  weight, manipulate, and fit biological network models within the\n  Structural Equation Modeling framework as outlined in the Supplementary Material of\n  Grassi M, Palluzzi F, Tarantino B (2022) <doi:10.1093/bioinformatics/btac567>.",
    "version": "1.2.4",
    "maintainer": "Barbara Tarantino <barbara.tarantino01@universitadipavia.it>",
    "author": "Mario Grassi [aut],\n  Fernando Palluzzi [aut],\n  Barbara Tarantino [cre]",
    "url": "https://github.com/fernandoPalluzzi/SEMgraph",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SEMgraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SEMgraph Network Analysis and Causal Inference Through Structural\nEquation Modeling Estimate networks and causal relationships in complex systems through\n  Structural Equation Modeling. This package also includes functions for importing,\n  weight, manipulate, and fit biological network models within the\n  Structural Equation Modeling framework as outlined in the Supplementary Material of\n  Grassi M, Palluzzi F, Tarantino B (2022) <doi:10.1093/bioinformatics/btac567>.  "
  },
  {
    "id": 209,
    "package_name": "TraMineR",
    "title": "Trajectory Miner: a Sequence Analysis Toolkit",
    "description": "Set of sequence analysis tools for manipulating, describing and rendering categorical sequences, and more generally mining sequence data in the field of social sciences. Although this sequence analysis package is primarily intended for state or event sequences that describe time use or life courses such as family formation histories or professional careers, its features also apply to many other kinds of categorical sequence data. It accepts many different sequence representations as input and provides tools for converting sequences from one format to another. It offers several functions for describing and rendering sequences, for computing distances between sequences with different metrics (among which optimal matching), original dissimilarity-based analysis tools, and functions for extracting the most frequent event subsequences and identifying the most discriminating ones among them. A user's guide can be found on the TraMineR web page.",
    "version": "2.2-13",
    "maintainer": "Gilbert Ritschard <gilbert.ritschard@unige.ch>",
    "author": "Alexis Gabadinho [aut, cph],\n  Matthias Studer [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-6269-1412>),\n  Nicolas M\u00fcller [aut],\n  Reto B\u00fcrgin [aut] (ORCID: <https://orcid.org/0000-0002-6212-1567>),\n  Pierre-Alexandre Fonta [ctb],\n  Gilbert Ritschard [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7776-0903>)",
    "url": "http://traminer.unige.ch",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TraMineR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TraMineR Trajectory Miner: a Sequence Analysis Toolkit Set of sequence analysis tools for manipulating, describing and rendering categorical sequences, and more generally mining sequence data in the field of social sciences. Although this sequence analysis package is primarily intended for state or event sequences that describe time use or life courses such as family formation histories or professional careers, its features also apply to many other kinds of categorical sequence data. It accepts many different sequence representations as input and provides tools for converting sequences from one format to another. It offers several functions for describing and rendering sequences, for computing distances between sequences with different metrics (among which optimal matching), original dissimilarity-based analysis tools, and functions for extracting the most frequent event subsequences and identifying the most discriminating ones among them. A user's guide can be found on the TraMineR web page.  "
  },
  {
    "id": 220,
    "package_name": "XYomics",
    "title": "Analysis of Sex Differences in Omics Data for Complex Diseases",
    "description": "Tools to analyze sex differences in omics data for complex diseases. It includes functions for differential expression analysis using the 'limma' method <doi:10.1093/nar/gkv007>, interaction testing between sex and disease, pathway enrichment with 'clusterProfiler' <doi:10.1089/omi.2011.0118>, and gene regulatory network (GRN) construction and analysis using 'igraph'. The package enables a reproducible workflow from raw data processing to biological interpretation. ",
    "version": "0.1.2",
    "maintainer": "Enrico Glaab <enrico.glaab@uni.lu>",
    "author": "Enrico Glaab [aut, cre],\n  Sophie Le Bars [aut],\n  Mohamed Soudy [aut],\n  Murodzhon Akhmedov [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=XYomics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "XYomics Analysis of Sex Differences in Omics Data for Complex Diseases Tools to analyze sex differences in omics data for complex diseases. It includes functions for differential expression analysis using the 'limma' method <doi:10.1093/nar/gkv007>, interaction testing between sex and disease, pathway enrichment with 'clusterProfiler' <doi:10.1089/omi.2011.0118>, and gene regulatory network (GRN) construction and analysis using 'igraph'. The package enables a reproducible workflow from raw data processing to biological interpretation.   "
  },
  {
    "id": 233,
    "package_name": "alarmdata",
    "title": "Download, Merge, and Process Redistricting Data",
    "description": "\n    Utility functions to download and process data produced by the ALARM Project,\n    including 2020 redistricting files Kenny and McCartan (2021) \n    <https://alarm-redist.org/posts/2021-08-10-census-2020/> and the 50-State \n    Redistricting Simulations of McCartan, Kenny, Simko, Garcia, Wang, Wu, \n    Kuriwaki, and Imai (2022) <doi:10.7910/DVN/SLCD3E>. The package extends \n    the data introduced in McCartan, Kenny, Simko, Garcia, Wang, Wu, Kuriwaki,\n    and Imai (2022) <doi:10.1038/s41597-022-01808-2> to also include states with \n    only a single district. The package also includes the Japanese 2022 \n    redistricting files from the 47-Prefecture Redistricting Simulations of \n    Miyazaki, Yamada, Yatsuhashi, and Imai (2022) <doi:10.7910/DVN/Z9UKSH>.",
    "version": "0.2.4",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Cory McCartan [aut] (ORCID: <https://orcid.org/0000-0002-6251-669X>),\n  Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>),\n  Tyler Simko [aut] (ORCID: <https://orcid.org/0000-0001-9382-7346>),\n  Michael Zhao [aut] (ORCID: <https://orcid.org/0000-0001-8435-2078>),\n  Sho Miyazaki [aut] (ORCID: <https://orcid.org/0009-0009-7838-9005>),\n  Kosuke Imai [aut] (ORCID: <https://orcid.org/0000-0002-2748-1022>)",
    "url": "https://github.com/alarm-redist/alarmdata/,\nhttps://alarm-redist.org/alarmdata/",
    "bug_reports": "https://github.com/alarm-redist/alarmdata/issues/",
    "repository": "https://cran.r-project.org/package=alarmdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "alarmdata Download, Merge, and Process Redistricting Data \n    Utility functions to download and process data produced by the ALARM Project,\n    including 2020 redistricting files Kenny and McCartan (2021) \n    <https://alarm-redist.org/posts/2021-08-10-census-2020/> and the 50-State \n    Redistricting Simulations of McCartan, Kenny, Simko, Garcia, Wang, Wu, \n    Kuriwaki, and Imai (2022) <doi:10.7910/DVN/SLCD3E>. The package extends \n    the data introduced in McCartan, Kenny, Simko, Garcia, Wang, Wu, Kuriwaki,\n    and Imai (2022) <doi:10.1038/s41597-022-01808-2> to also include states with \n    only a single district. The package also includes the Japanese 2022 \n    redistricting files from the 47-Prefecture Redistricting Simulations of \n    Miyazaki, Yamada, Yatsuhashi, and Imai (2022) <doi:10.7910/DVN/Z9UKSH>.  "
  },
  {
    "id": 525,
    "package_name": "epiR",
    "title": "Tools for the Analysis of Epidemiological Data",
    "description": "Tools for the analysis of epidemiological and surveillance data. Contains functions for directly and indirectly adjusting measures of disease frequency, quantifying measures of association on the basis of single or multiple strata of count data presented in a contingency table, computation of confidence intervals around incidence risk and incidence rate estimates and sample size calculations for cross-sectional, case-control and cohort studies. Surveillance tools include functions to calculate an appropriate sample size for 1- and 2-stage representative freedom surveys, functions to estimate surveillance system sensitivity and functions to support scenario tree modelling analyses.   ",
    "version": "2.0.89",
    "maintainer": "Mark Stevenson <mark.stevenson1@unimelb.edu.au>",
    "author": "Mark Stevenson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1890-9784>),\n  Evan Sergeant [aut],\n  Cord Heuer [ctb],\n  Telmo Nunes [ctb],\n  Cord Heuer [ctb],\n  Jonathon Marshall [ctb],\n  Javier Sanchez [ctb],\n  Ron Thornton [ctb],\n  Jeno Reiczigel [ctb],\n  Jim Robison-Cox [ctb],\n  Paola Sebastiani [ctb],\n  Peter Solymos [ctb],\n  Kazuki Yoshida [ctb],\n  Geoff Jones [ctb],\n  Sarah Pirikahu [ctb],\n  Simon Firestone [ctb],\n  Ryan Kyle [ctb],\n  Johann Popp [ctb],\n  Mathew Jay [ctb],\n  Allison Cheung [ctb],\n  Nagendra Singanallur [ctb],\n  Aniko Szabo [ctb],\n  Ahmad Rabiee [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=epiR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epiR Tools for the Analysis of Epidemiological Data Tools for the analysis of epidemiological and surveillance data. Contains functions for directly and indirectly adjusting measures of disease frequency, quantifying measures of association on the basis of single or multiple strata of count data presented in a contingency table, computation of confidence intervals around incidence risk and incidence rate estimates and sample size calculations for cross-sectional, case-control and cohort studies. Surveillance tools include functions to calculate an appropriate sample size for 1- and 2-stage representative freedom surveys, functions to estimate surveillance system sensitivity and functions to support scenario tree modelling analyses.     "
  },
  {
    "id": 671,
    "package_name": "guess",
    "title": "Adjust Estimates of Learning for Guessing",
    "description": "Provides tools to adjust estimates of learning for guessing-related \n    bias in educational and survey research. Implements standard guessing \n    correction methods and a sophisticated latent class model that leverages \n    informative pre-post test transitions to account for guessing behavior. \n    The package helps researchers obtain more accurate estimates of actual \n    learning when respondents may guess on closed-ended knowledge items. \n    For theoretical background and empirical validation, see Cor and Sood (2018) \n    <https://gsood.com/research/papers/guess.pdf>.",
    "version": "0.2.1",
    "maintainer": "Gaurav Sood <gsood07@gmail.com>",
    "author": "Gaurav Sood [aut, cre],\n  Ken Cor [aut]",
    "url": "https://github.com/finite-sample/guess,\nhttps://finite-sample.github.io/guess/",
    "bug_reports": "https://github.com/finite-sample/guess/issues",
    "repository": "https://cran.r-project.org/package=guess",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "guess Adjust Estimates of Learning for Guessing Provides tools to adjust estimates of learning for guessing-related \n    bias in educational and survey research. Implements standard guessing \n    correction methods and a sophisticated latent class model that leverages \n    informative pre-post test transitions to account for guessing behavior. \n    The package helps researchers obtain more accurate estimates of actual \n    learning when respondents may guess on closed-ended knowledge items. \n    For theoretical background and empirical validation, see Cor and Sood (2018) \n    <https://gsood.com/research/papers/guess.pdf>.  "
  },
  {
    "id": 725,
    "package_name": "jollofR",
    "title": "Small Area Population Estimation by Demographics",
    "description": "Automatic disaggregation of small-area population estimates by demographic groups (e.g., age, sex, race, marital status, educational level, etc) along with the estimates of uncertainty, using advanced Bayesian statistical modelling approaches based on integrated nested Laplace approximation (INLA) Rue et al. (2009) <doi:10.1111/j.1467-9868.2008.00700.x> and stochastic partial differential equation (SPDE) methods Lindgren et al. (2011) <doi:10.1111/j.1467-9868.2011.00777.x>. The package implements hierarchical Bayesian modeling frameworks for small area estimation as described in Leasure et al. (2020) <doi:10.1073/pnas.1913050117> and Nnanatu et al. (2025) <doi:10.1038/s41467-025-59862-4>.",
    "version": "0.6.5",
    "maintainer": "Chibuzor Christopher Nnanatu <cc.nnanatu@soton.ac.uk>",
    "author": "Chibuzor Christopher Nnanatu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5841-3700>),\n  Mohamed A. Yusuf [aut] (ORCID: <https://orcid.org/0000-0002-9339-4613>),\n  Somnath Chaudhuri [aut] (ORCID:\n    <https://orcid.org/0000-0003-4899-1870>),\n  Ortis Yankey [aut] (ORCID: <https://orcid.org/0000-0002-0808-884X>),\n  Attila N Lazar [aut] (ORCID: <https://orcid.org/0000-0003-2033-2013>),\n  Andrew J Tatem [aut] (ORCID: <https://orcid.org/0000-0002-7270-941X>)",
    "url": "https://github.com/wpgp/jollofR/, https://wpgp.github.io/jollofR/",
    "bug_reports": "https://github.com/wpgp/jollofR/issues",
    "repository": "https://cran.r-project.org/package=jollofR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jollofR Small Area Population Estimation by Demographics Automatic disaggregation of small-area population estimates by demographic groups (e.g., age, sex, race, marital status, educational level, etc) along with the estimates of uncertainty, using advanced Bayesian statistical modelling approaches based on integrated nested Laplace approximation (INLA) Rue et al. (2009) <doi:10.1111/j.1467-9868.2008.00700.x> and stochastic partial differential equation (SPDE) methods Lindgren et al. (2011) <doi:10.1111/j.1467-9868.2011.00777.x>. The package implements hierarchical Bayesian modeling frameworks for small area estimation as described in Leasure et al. (2020) <doi:10.1073/pnas.1913050117> and Nnanatu et al. (2025) <doi:10.1038/s41467-025-59862-4>.  "
  },
  {
    "id": 754,
    "package_name": "leidenbase",
    "title": "R and C/C++ Wrappers to Run the Leiden find_partition() Function",
    "description": "An R to C/C++ interface that runs the Leiden community\n    detection algorithm to find a basic partition (). It runs the\n    equivalent of the 'leidenalg' find_partition() function, which is\n    given in the 'leidenalg' distribution file\n    'leiden/src/functions.py'. This package includes the\n    required source code files from the official 'leidenalg'\n    distribution and functions from the R 'igraph'\n    package.  The 'leidenalg' distribution is available from\n    <https://github.com/vtraag/leidenalg/>\n    and the R 'igraph' package is available from\n    <https://igraph.org/r/>.\n    The Leiden algorithm is described in the article by\n    Traag et al. (2019) <doi:10.1038/s41598-019-41695-z>.\n    Leidenbase includes code from the packages:\n       igraph version 0.9.8 with license GPL (>= 2),\n       leidenalg version 0.8.10 with license GPL 3.",
    "version": "0.1.36",
    "maintainer": "Brent Ewing <bge@uw.edu>",
    "author": "Brent Ewing [aut, cre],\n  Vincent Traag [ctb],\n  G\u00e1bor Cs\u00e1rdi [ctb],\n  Tam\u00e1s Nepusz [ctb],\n  Szabolcs Horvat [ctb],\n  Fabio Zanini [ctb]",
    "url": "https://github.com/cole-trapnell-lab/leidenbase",
    "bug_reports": "https://github.com/cole-trapnell-lab/leidenbase/issues",
    "repository": "https://cran.r-project.org/package=leidenbase",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "leidenbase R and C/C++ Wrappers to Run the Leiden find_partition() Function An R to C/C++ interface that runs the Leiden community\n    detection algorithm to find a basic partition (). It runs the\n    equivalent of the 'leidenalg' find_partition() function, which is\n    given in the 'leidenalg' distribution file\n    'leiden/src/functions.py'. This package includes the\n    required source code files from the official 'leidenalg'\n    distribution and functions from the R 'igraph'\n    package.  The 'leidenalg' distribution is available from\n    <https://github.com/vtraag/leidenalg/>\n    and the R 'igraph' package is available from\n    <https://igraph.org/r/>.\n    The Leiden algorithm is described in the article by\n    Traag et al. (2019) <doi:10.1038/s41598-019-41695-z>.\n    Leidenbase includes code from the packages:\n       igraph version 0.9.8 with license GPL (>= 2),\n       leidenalg version 0.8.10 with license GPL 3.  "
  },
  {
    "id": 862,
    "package_name": "nadaverse",
    "title": "Browse Microdata Catalogs Using 'NADA' REST API",
    "description": "Provides a unified, programmatic interface for searching, browsing,\n  and retrieving metadata from various international organization data repositories\n  that use the National Data Archive ('NADA') software, such as the World Bank,\n  'FAO', and the International Household Survey Network ('IHSN'). Functions allow users to\n  discover available data collections, country codes, and access types, perform\n  complex searches using keyword and spatial/temporal filters, and retrieve\n  detailed study information, including file lists and variable-level data\n  dictionaries. It simplifies access to microdata for researchers and policy\n  analysts globally.",
    "version": "0.1.0",
    "maintainer": "Gutama Girja Urago <girjagutama@gmail.com>",
    "author": "Gutama Girja Urago [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-5588-2301>)",
    "url": "https://github.com/guturago/nadaverse",
    "bug_reports": "https://github.com/guturago/nadaverse/issues",
    "repository": "https://cran.r-project.org/package=nadaverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nadaverse Browse Microdata Catalogs Using 'NADA' REST API Provides a unified, programmatic interface for searching, browsing,\n  and retrieving metadata from various international organization data repositories\n  that use the National Data Archive ('NADA') software, such as the World Bank,\n  'FAO', and the International Household Survey Network ('IHSN'). Functions allow users to\n  discover available data collections, country codes, and access types, perform\n  complex searches using keyword and spatial/temporal filters, and retrieve\n  detailed study information, including file lists and variable-level data\n  dictionaries. It simplifies access to microdata for researchers and policy\n  analysts globally.  "
  },
  {
    "id": 889,
    "package_name": "nparACT",
    "title": "Non-Parametric Measures of Actigraphy Data",
    "description": "Computes interdaily stability (IS), intradaily variability (IV) & the relative amplitude (RA) from actigraphy data as described in Blume et al. (2016) <doi: 10.1016/j.mex.2016.05.006> and van Someren et al. (1999) <doi: 10.3109/07420529908998724>. Additionally, it also computes L5 (i.e. the 5 hours with lowest average actigraphy amplitude) and M10 (the 10 hours with highest average amplitude) as well as the respective start times. The flex versions will also compute the L-value for a user-defined number of minutes. IS describes the strength of coupling of a rhythm to supposedly stable zeitgebers. It varies between 0 (Gaussian Noise) and 1 for perfect IS. IV describes the fragmentation of a rhythm, i.e. the frequency and extent of transitions between rest and activity. It is near 0 for a perfect sine wave, about 2 for Gaussian noise and may be even higher when a definite ultradian period of about 2 hrs is present. RA is the relative amplitude of a rhythm. Note that to obtain reliable results, actigraphy data should cover a reasonable number of days.",
    "version": "0.9.1",
    "maintainer": "Christine Blume <christine.blume@unibas.ch>",
    "author": "Christine Blume [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2328-9612>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nparACT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nparACT Non-Parametric Measures of Actigraphy Data Computes interdaily stability (IS), intradaily variability (IV) & the relative amplitude (RA) from actigraphy data as described in Blume et al. (2016) <doi: 10.1016/j.mex.2016.05.006> and van Someren et al. (1999) <doi: 10.3109/07420529908998724>. Additionally, it also computes L5 (i.e. the 5 hours with lowest average actigraphy amplitude) and M10 (the 10 hours with highest average amplitude) as well as the respective start times. The flex versions will also compute the L-value for a user-defined number of minutes. IS describes the strength of coupling of a rhythm to supposedly stable zeitgebers. It varies between 0 (Gaussian Noise) and 1 for perfect IS. IV describes the fragmentation of a rhythm, i.e. the frequency and extent of transitions between rest and activity. It is near 0 for a perfect sine wave, about 2 for Gaussian noise and may be even higher when a definite ultradian period of about 2 hrs is present. RA is the relative amplitude of a rhythm. Note that to obtain reliable results, actigraphy data should cover a reasonable number of days.  "
  },
  {
    "id": 1193,
    "package_name": "serosim",
    "title": "Serosurvey simulation",
    "description": "serosim is an open source R package designed to aid inference",
    "version": "0.0.0.9000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/seroanalytics/serosim",
    "bug_reports": "https://github.com/seroanalytics/serosim/issues",
    "repository": "https://github.com/seroanalytics/serosim",
    "exports": [],
    "topics": [
      "antibodies",
      "infectious-disease-epidemiology",
      "serological-surveys",
      "serology",
      "serosurvey",
      "simulation-framework"
    ],
    "score": "NA",
    "stars": 7,
    "primary_category": "epidemiology",
    "source_universe": "github:seroanalytics",
    "search_text": "serosim Serosurvey simulation serosim is an open source R package designed to aid inference  antibodies infectious-disease-epidemiology serological-surveys serology serosurvey simulation-framework"
  },
  {
    "id": 1276,
    "package_name": "stepsWHSapp",
    "title": "WHO STEPS Depression Self-assessment Tool",
    "description": "The tool generates a real-time assessment of potential depression based on World Health Survey (WHS) algorithm, which is used in STEPS Depressive symptoms module.",
    "version": "0.0.1.0000",
    "maintainer": "",
    "author": "",
    "url": "https://github.com/WorldHealthOrganization/stepsWHSapp",
    "bug_reports": "https://github.com/WorldHealthOrganization/stepsWHSapp/issues",
    "repository": "https://github.com/WorldHealthOrganization/stepsWHSapp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 2,
    "primary_category": "epidemiology",
    "source_universe": "github:WorldHealthOrganization",
    "search_text": "stepsWHSapp WHO STEPS Depression Self-assessment Tool The tool generates a real-time assessment of potential depression based on World Health Survey (WHS) algorithm, which is used in STEPS Depressive symptoms module.  "
  },
  {
    "id": 1534,
    "package_name": "AICcmodavg",
    "title": "Model Selection and Multimodel Inference Based on (Q)AIC(c)",
    "description": "Functions to implement model selection and multimodel inference based on Akaike's information criterion (AIC) and the second-order AIC (AICc), as well as their quasi-likelihood counterparts (QAIC, QAICc) from various model object classes.  The package implements classic model averaging for a given parameter of interest or predicted values, as well as a shrinkage version of model averaging parameter estimates or effect sizes.  The package includes diagnostics and goodness-of-fit statistics for certain model types including those of 'unmarkedFit' classes estimating demographic parameters after accounting for imperfect detection probabilities.  Some functions also allow the creation of model selection tables for Bayesian models of the 'bugs', 'rjags', and 'jagsUI' classes.  Functions also implement model selection using BIC.  Objects following model selection and multimodel inference can be formatted to LaTeX using 'xtable' methods included in the package.",
    "version": "2.3-4",
    "maintainer": "Marc J. Mazerolle <marc.mazerolle@sbf.ulaval.ca>",
    "author": "Marc J. Mazerolle [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0486-0310>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AICcmodavg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AICcmodavg Model Selection and Multimodel Inference Based on (Q)AIC(c) Functions to implement model selection and multimodel inference based on Akaike's information criterion (AIC) and the second-order AIC (AICc), as well as their quasi-likelihood counterparts (QAIC, QAICc) from various model object classes.  The package implements classic model averaging for a given parameter of interest or predicted values, as well as a shrinkage version of model averaging parameter estimates or effect sizes.  The package includes diagnostics and goodness-of-fit statistics for certain model types including those of 'unmarkedFit' classes estimating demographic parameters after accounting for imperfect detection probabilities.  Some functions also allow the creation of model selection tables for Bayesian models of the 'bugs', 'rjags', and 'jagsUI' classes.  Functions also implement model selection using BIC.  Objects following model selection and multimodel inference can be formatted to LaTeX using 'xtable' methods included in the package.  "
  },
  {
    "id": 1564,
    "package_name": "AOUSDOHtools",
    "title": "Analyzing AOU SDOH Survey Data",
    "description": "Functions for processing and analyzing survey data from the All of \n    Us Social Determinants of Health (AOUSDOH) program, including tools for \n    calculating health and well-being scores, recoding variables, and simplifying \n    survey data analysis. For more details see - Koleck TA, Dreisbach C, Zhang C, \n    Grayson S, Lor M, Deng Z, Conway A, Higgins PDR, Bakken S (2024) \n    <doi:10.1093/jamia/ocae214>.",
    "version": "1.0.4",
    "maintainer": "Zhirui Deng <zhd52@pitt.edu>",
    "author": "Zhirui Deng [aut, cre],\n  Theresa A. Koleck [ctb],\n  Caitlin Dreisbach [ctb],\n  Chen Zhang [ctb],\n  Peter D.R. Higgins [ctb],\n  DreisbachLab [cph]",
    "url": "https://github.com/zhd52/AOUSDOHtools",
    "bug_reports": "https://github.com/zhd52/AOUSDOHtools/issues",
    "repository": "https://cran.r-project.org/package=AOUSDOHtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AOUSDOHtools Analyzing AOU SDOH Survey Data Functions for processing and analyzing survey data from the All of \n    Us Social Determinants of Health (AOUSDOH) program, including tools for \n    calculating health and well-being scores, recoding variables, and simplifying \n    survey data analysis. For more details see - Koleck TA, Dreisbach C, Zhang C, \n    Grayson S, Lor M, Deng Z, Conway A, Higgins PDR, Bakken S (2024) \n    <doi:10.1093/jamia/ocae214>.  "
  },
  {
    "id": 1568,
    "package_name": "APCalign",
    "title": "Resolving Plant Taxon Names Using the Australian Plant Census",
    "description": "The process of resolving taxon names is necessary when working with biodiversity data. 'APCalign' uses the Australian Plant Census (APC) and the Australian Plant Name Index (APNI) to align and update plant taxon names to current, accepted standards. 'APCalign' also supplies information about the established status of plant taxa across different states/territories.",
    "version": "1.1.3",
    "maintainer": "Daniel Falster <daniel.falster@unsw.edu.au>",
    "author": "Daniel Falster [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9814-092X>),\n  Elizabeth Wenk [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-5640-5910>),\n  Will Cornwell [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-4080-4073>),\n  Fonti Kar [aut, ctb] (ORCID: <https://orcid.org/0000-0002-2760-3974>),\n  Carl Boettiger [ctb] (ORCID: <https://orcid.org/0000-0002-1642-628X>)",
    "url": "https://traitecoevo.github.io/APCalign/,\nhttps://github.com/traitecoevo/APCalign",
    "bug_reports": "https://github.com/traitecoevo/APCalign/issues",
    "repository": "https://cran.r-project.org/package=APCalign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "APCalign Resolving Plant Taxon Names Using the Australian Plant Census The process of resolving taxon names is necessary when working with biodiversity data. 'APCalign' uses the Australian Plant Census (APC) and the Australian Plant Name Index (APNI) to align and update plant taxon names to current, accepted standards. 'APCalign' also supplies information about the established status of plant taxa across different states/territories.  "
  },
  {
    "id": 1611,
    "package_name": "ATQ",
    "title": "Alert Time Quality - Evaluating Timely Epidemic Metrics",
    "description": "Provides tools for evaluating timely epidemic detection models within school absenteeism-based surveillance systems. Introduces the concept of alert time quality as an evaluation metric. Includes functions to simulate populations, epidemics, and alert metrics associated with epidemic spread using population census data. The methods are based on research published in Vanderkruk et al. (2023) <doi:10.1186/s12889-023-15747-z> and Ward et al. (2019) <doi:10.1186/s12889-019-7521-7>.",
    "version": "0.2.3",
    "maintainer": "Vinay Joshy <joshy@uoguelph.ca>",
    "author": "Vinay Joshy [aut, cre, cph],\n  Zeny Feng [aut, cph, ths],\n  Lorna Deeth [aut, cph, ths],\n  Justin Slater [aut, cph, ths],\n  Kayla Vanderkruk [aut, com, ctb]",
    "url": "https://github.com/vjoshy/ATQ_Surveillance_Package",
    "bug_reports": "https://github.com/vjoshy/ATQ_Surveillance_Package/issues",
    "repository": "https://cran.r-project.org/package=ATQ",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ATQ Alert Time Quality - Evaluating Timely Epidemic Metrics Provides tools for evaluating timely epidemic detection models within school absenteeism-based surveillance systems. Introduces the concept of alert time quality as an evaluation metric. Includes functions to simulate populations, epidemics, and alert metrics associated with epidemic spread using population census data. The methods are based on research published in Vanderkruk et al. (2023) <doi:10.1186/s12889-023-15747-z> and Ward et al. (2019) <doi:10.1186/s12889-019-7521-7>.  "
  },
  {
    "id": 1628,
    "package_name": "ActCR",
    "title": "Extract Circadian Rhythms Metrics from Actigraphy Data",
    "description": "Circadian rhythms are rhythms that oscillate about every 24 h, which has been observed in multiple physiological processes including core body temperature, hormone secretion, heart rate, blood pressure, and many others. Measuring circadian rhythm with wearables is based on a principle that there is increased movement during wake periods and reduced movement during sleep periods, and has been shown to be reliable and valid. This package can be used to extract nonparametric circadian metrics like intradaily variability (IV), interdaily stability (IS), and relative amplitude (RA); and parametric cosinor model and extended cosinor model coefficient. Details can be found in Junrui Di et al (2019) <doi:10.1007/s12561-019-09236-4>.",
    "version": "0.3.0",
    "maintainer": "Junrui Di <dijunrui@gmail.com>",
    "author": "Junrui Di [aut, cre],\n  Vadim zipunnikov [aut],\n  Vincent van Hees [ctb]",
    "url": "https://github.com/junruidi/ActCR",
    "bug_reports": "https://github.com/junruidi/ActCR/issues",
    "repository": "https://cran.r-project.org/package=ActCR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ActCR Extract Circadian Rhythms Metrics from Actigraphy Data Circadian rhythms are rhythms that oscillate about every 24 h, which has been observed in multiple physiological processes including core body temperature, hormone secretion, heart rate, blood pressure, and many others. Measuring circadian rhythm with wearables is based on a principle that there is increased movement during wake periods and reduced movement during sleep periods, and has been shown to be reliable and valid. This package can be used to extract nonparametric circadian metrics like intradaily variability (IV), interdaily stability (IS), and relative amplitude (RA); and parametric cosinor model and extended cosinor model coefficient. Details can be found in Junrui Di et al (2019) <doi:10.1007/s12561-019-09236-4>.  "
  },
  {
    "id": 1629,
    "package_name": "ActFrag",
    "title": "Activity Fragmentation Metrics Extracted from Minute Level\nActivity Data",
    "description": "Recent studies haven shown that, on top of total daily active/sedentary volumes, the time \n  accumulation strategies provide more sensitive information. This package provides functions to extract \n  commonly used fragmentation metrics to quantify such time accumulation strategies based on minute level \n  actigraphy-measured activity counts data. ",
    "version": "0.1.1",
    "maintainer": "Junrui Di <dijunrui@gmail.com>",
    "author": "Junrui Di [aut, cre],\n  John Muschelli [aut],\n  Vadim zipunnikov [aut]",
    "url": "https://github.com/junruidi/ActFrag",
    "bug_reports": "https://github.com/junruidi/ActFrag/issues",
    "repository": "https://cran.r-project.org/package=ActFrag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ActFrag Activity Fragmentation Metrics Extracted from Minute Level\nActivity Data Recent studies haven shown that, on top of total daily active/sedentary volumes, the time \n  accumulation strategies provide more sensitive information. This package provides functions to extract \n  commonly used fragmentation metrics to quantify such time accumulation strategies based on minute level \n  actigraphy-measured activity counts data.   "
  },
  {
    "id": 1630,
    "package_name": "ActiSleep",
    "title": "Sleep Duration Estimate Algorithm",
    "description": "Provides sleep duration estimates using a Pruned Dynamic\n  Programming (PDP) algorithm that efficiently identifies\n  change-points. PDP applied to physical activity data can identify\n  transitions from wakefulness to sleep and vice versa. Baek, Jonggyu, Banker,\n  Margaret, Jansen, Erica C., She, Xichen, Peterson, Karen E., Pitchford,\n  E. Andrew, Song, Peter X. K. (2021) An Efficient Segmentation Algorithm to\n  Estimate Sleep Duration from Actigraphy Data <doi:10.1007/s12561-021-09309-3>.",
    "version": "0.2.2",
    "maintainer": "Nathan Szeto <nszeto@umich.edu>",
    "author": "Jonggyu Baek [aut],\n  Margaret Banker [aut],\n  Nathan Szeto [aut, cre],\n  Alice Cleynen [aut],\n  Guillem Rigaill [aut],\n  Michel Koskas [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ActiSleep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ActiSleep Sleep Duration Estimate Algorithm Provides sleep duration estimates using a Pruned Dynamic\n  Programming (PDP) algorithm that efficiently identifies\n  change-points. PDP applied to physical activity data can identify\n  transitions from wakefulness to sleep and vice versa. Baek, Jonggyu, Banker,\n  Margaret, Jansen, Erica C., She, Xichen, Peterson, Karen E., Pitchford,\n  E. Andrew, Song, Peter X. K. (2021) An Efficient Segmentation Algorithm to\n  Estimate Sleep Duration from Actigraphy Data <doi:10.1007/s12561-021-09309-3>.  "
  },
  {
    "id": 1651,
    "package_name": "AdverseEvents",
    "title": "'shiny' Application for Adverse Event Analysis of 'OnCore' Data",
    "description": "An application for analysis of Adverse Events, as described in Chen, et al., (2023) <doi:10.3390/cancers15092521>.\n             The required data for the application includes demographics, follow up, adverse event, drug administration and optional tumor measurement data.\n             The app can produce swimmers plots of adverse events, Kaplan-Meier plots and Cox Proportional Hazards model results\n             for the association of adverse event biomarkers and overall survival and progression free survival.\n             The adverse event biomarkers include occurrence of grade 3, low grade (1-2), and treatment related adverse events.\n             Plots and tables of results are downloadable.",
    "version": "0.0.4",
    "maintainer": "Z Thompson <zachary.thompson@moffitt.org>",
    "author": "Z Thompson [aut, cre],\n  A Obermayer [aut],\n  DT Chen [aut]",
    "url": "https://github.com/dungtsa/AdverseEvents",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AdverseEvents",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AdverseEvents 'shiny' Application for Adverse Event Analysis of 'OnCore' Data An application for analysis of Adverse Events, as described in Chen, et al., (2023) <doi:10.3390/cancers15092521>.\n             The required data for the application includes demographics, follow up, adverse event, drug administration and optional tumor measurement data.\n             The app can produce swimmers plots of adverse events, Kaplan-Meier plots and Cox Proportional Hazards model results\n             for the association of adverse event biomarkers and overall survival and progression free survival.\n             The adverse event biomarkers include occurrence of grade 3, low grade (1-2), and treatment related adverse events.\n             Plots and tables of results are downloadable.  "
  },
  {
    "id": 1654,
    "package_name": "AgePopDenom",
    "title": "Model Fine-Scale Age-Structured Population Data using\nOpen-Source Data",
    "description": "Automate the modelling of age-structured population data\n  using survey data, grid population estimates and urban-rural extents.",
    "version": "1.2.3",
    "maintainer": "Mohamed A. Yusuf <moyusuf@who.int>",
    "author": "Mohamed A. Yusuf [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9339-4613>),\n  Victor A. Alegana [aut] (ORCID:\n    <https://orcid.org/0000-0001-5177-9227>),\n  Chibuzor Christopher Nnanatu [aut] (ORCID:\n    <https://orcid.org/0000-0002-5841-3700>),\n  Andrew Tatem [aut] (ORCID: <https://orcid.org/0000-0002-7270-941X>)",
    "url": "https://truenomad.github.io/AgePopDenom/,\nhttps://github.com/truenomad/AgePopDenom",
    "bug_reports": "https://github.com/truenomad/AgePopDenom/issues",
    "repository": "https://cran.r-project.org/package=AgePopDenom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AgePopDenom Model Fine-Scale Age-Structured Population Data using\nOpen-Source Data Automate the modelling of age-structured population data\n  using survey data, grid population estimates and urban-rural extents.  "
  },
  {
    "id": 1670,
    "package_name": "AlgeriAPIs",
    "title": "Access Algerian Data via Public APIs",
    "description": "Provides functions to access data from public RESTful APIs including \n    'World Bank API' and 'REST Countries API', retrieving real-time or historical \n    information related to Algeria. The package enables users to query economic \n    indicators and international demographic and geopolitical statistics in a \n    reproducible way. It is designed for researchers, analysts, and developers who \n    require reliable and programmatic access to Algerian data through established APIs. \n    For more information on the APIs, see: \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392> \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/algeriapis,\nhttps://lightbluetitan.github.io/algeriapis/",
    "bug_reports": "https://github.com/lightbluetitan/algeriapis/issues",
    "repository": "https://cran.r-project.org/package=AlgeriAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AlgeriAPIs Access Algerian Data via Public APIs Provides functions to access data from public RESTful APIs including \n    'World Bank API' and 'REST Countries API', retrieving real-time or historical \n    information related to Algeria. The package enables users to query economic \n    indicators and international demographic and geopolitical statistics in a \n    reproducible way. It is designed for researchers, analysts, and developers who \n    require reliable and programmatic access to Algerian data through established APIs. \n    For more information on the APIs, see: \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392> \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 1678,
    "package_name": "AlphaSimR",
    "title": "Breeding Program Simulations",
    "description": "The successor to the 'AlphaSim' software for breeding program \n  simulation [Faux et al. (2016) <doi:10.3835/plantgenome2016.02.0013>]. \n  Used for stochastic simulations of breeding programs to the level of DNA \n  sequence for every individual. Contained is a wide range of functions for \n  modeling common tasks in a breeding program, such as selection and crossing. \n  These functions allow for constructing simulations of highly complex plant and \n  animal breeding programs via scripting in the R software environment. Such \n  simulations can be used to evaluate overall breeding program performance and \n  conduct research into breeding program design, such as implementation of \n  genomic selection. Included is the 'Markovian Coalescent Simulator' ('MaCS') \n  for fast simulation of biallelic sequences according to a population \n  demographic history [Chen et al. (2009) <doi:10.1101/gr.083634.108>].",
    "version": "2.1.0",
    "maintainer": "Chris Gaynor <gaynor.robert@hotmail.com>",
    "author": "Chris Gaynor [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0558-6656>),\n  Gregor Gorjanc [ctb] (ORCID: <https://orcid.org/0000-0001-8008-2787>),\n  John Hickey [ctb] (ORCID: <https://orcid.org/0000-0001-5675-3974>),\n  Daniel Money [ctb] (ORCID: <https://orcid.org/0000-0001-5151-3648>),\n  David Wilson [ctb],\n  Thiago Oliveira [ctb] (ORCID: <https://orcid.org/0000-0002-4555-2584>),\n  Audrey Martin [ctb] (ORCID: <https://orcid.org/0000-0003-2235-0098>),\n  Philip Greenspoon [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6284-7248>),\n  Ros Craddock [ctb] (ORCID: <https://orcid.org/0009-0004-1578-1580>),\n  Jana Obsteter [ctb] (ORCID: <https://orcid.org/0000-0003-1511-3916>)",
    "url": "https://github.com/gaynorr/AlphaSimR,\nhttps://gaynorr.github.io/AlphaSimR/,\nhttps://www.edx.org/learn/animal-breeding/the-university-of-edinburgh-breeding-programme-modelling-with-alphasimr",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AlphaSimR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AlphaSimR Breeding Program Simulations The successor to the 'AlphaSim' software for breeding program \n  simulation [Faux et al. (2016) <doi:10.3835/plantgenome2016.02.0013>]. \n  Used for stochastic simulations of breeding programs to the level of DNA \n  sequence for every individual. Contained is a wide range of functions for \n  modeling common tasks in a breeding program, such as selection and crossing. \n  These functions allow for constructing simulations of highly complex plant and \n  animal breeding programs via scripting in the R software environment. Such \n  simulations can be used to evaluate overall breeding program performance and \n  conduct research into breeding program design, such as implementation of \n  genomic selection. Included is the 'Markovian Coalescent Simulator' ('MaCS') \n  for fast simulation of biallelic sequences according to a population \n  demographic history [Chen et al. (2009) <doi:10.1101/gr.083634.108>].  "
  },
  {
    "id": 1680,
    "package_name": "Amelia",
    "title": "A Program for Missing Data",
    "description": "A tool that \"multiply imputes\" missing data in a single cross-section\n  (such as a survey), from a time series (like variables collected for\n  each year in a country), or from a time-series-cross-sectional data\n  set (such as collected by years for each of several countries).\n  Amelia II implements our bootstrapping-based algorithm that gives\n  essentially the same answers as the standard IP or EMis approaches,\n  is usually considerably faster than existing approaches and can\n  handle many more variables.  Unlike Amelia I and other statistically\n  rigorous imputation software, it virtually never crashes (but please\n  let us know if you find to the contrary!).  The program also\n  generalizes existing approaches by allowing for trends in time series\n  across observations within a cross-sectional unit, as well as priors\n  that allow experts to incorporate beliefs they have about the values\n  of missing cells in their data.  Amelia II also includes useful\n  diagnostics of the fit of multiple imputation models.  The program\n  works from the R command line or via a graphical user interface that\n  does not require users to know R.",
    "version": "1.8.3",
    "maintainer": "Matthew Blackwell <mblackwell@gmail.com>",
    "author": "James Honaker [aut],\n  Gary King [aut],\n  Matthew Blackwell [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3689-9527>)",
    "url": "https://gking.harvard.edu/amelia",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Amelia",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Amelia A Program for Missing Data A tool that \"multiply imputes\" missing data in a single cross-section\n  (such as a survey), from a time series (like variables collected for\n  each year in a country), or from a time-series-cross-sectional data\n  set (such as collected by years for each of several countries).\n  Amelia II implements our bootstrapping-based algorithm that gives\n  essentially the same answers as the standard IP or EMis approaches,\n  is usually considerably faster than existing approaches and can\n  handle many more variables.  Unlike Amelia I and other statistically\n  rigorous imputation software, it virtually never crashes (but please\n  let us know if you find to the contrary!).  The program also\n  generalizes existing approaches by allowing for trends in time series\n  across observations within a cross-sectional unit, as well as priors\n  that allow experts to incorporate beliefs they have about the values\n  of missing cells in their data.  Amelia II also includes useful\n  diagnostics of the fit of multiple imputation models.  The program\n  works from the R command line or via a graphical user interface that\n  does not require users to know R.  "
  },
  {
    "id": 1697,
    "package_name": "AnglerCreelSurveySimulation",
    "title": "Simulate a Bus Route Creel Survey of Anglers",
    "description": "Simulate an angler population, sample the simulated population with a user-specified survey times, and calculate metrics from a bus route-type creel survey.",
    "version": "1.0.3",
    "maintainer": "Ranney Steven H. <Steven.Ranney@gmail.com>",
    "author": "Ranney Steven H. [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6167-1316>)",
    "url": "https://github.com/stevenranney/AnglerCreelSurveySimulation",
    "bug_reports": "https://github.com/stevenranney/AnglerCreelSurveySimulation/issues",
    "repository": "https://cran.r-project.org/package=AnglerCreelSurveySimulation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AnglerCreelSurveySimulation Simulate a Bus Route Creel Survey of Anglers Simulate an angler population, sample the simulated population with a user-specified survey times, and calculate metrics from a bus route-type creel survey.  "
  },
  {
    "id": 1733,
    "package_name": "AsthmaNHANES",
    "title": "Asthma Data Sets from NHANES",
    "description": "Data sets and examples from National Health and Nutritional Examination Survey (NHANES).",
    "version": "1.1.0",
    "maintainer": "Tao Sun <sun.tao@ruc.edu.cn>",
    "author": "Tao Sun [aut, cre],\n  Qiyao Qin [aut],\n  Zihan Qian [aut],\n  Yang Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AsthmaNHANES",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AsthmaNHANES Asthma Data Sets from NHANES Data sets and examples from National Health and Nutritional Examination Survey (NHANES).  "
  },
  {
    "id": 1756,
    "package_name": "AuxSurvey",
    "title": "Survey Analysis with Auxiliary Discretized Variables",
    "description": "Probability surveys often use auxiliary continuous data from administrative records, but the utility of this data is diminished when it is discretized for confidentiality. We provide a set of survey estimators to make full use of information from the discretized variables. See Williams, S.Z., Zou, J., Liu, Y., Si, Y., Galea, S. and Chen, Q. (2024), Improving Survey Inference Using Administrative Records Without Releasing Individual-Level Continuous Data. Statistics in Medicine, 43: 5803-5813. <doi:10.1002/sim.10270> for details.",
    "version": "1.1",
    "maintainer": "Jungang Zou <jungang.zou@gmail.com>",
    "author": "Jungang Zou [aut, cre],\n  Yutao Liu [aut],\n  Sharifa Williams [aut],\n  Qixuan Chen [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=AuxSurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "AuxSurvey Survey Analysis with Auxiliary Discretized Variables Probability surveys often use auxiliary continuous data from administrative records, but the utility of this data is diminished when it is discretized for confidentiality. We provide a set of survey estimators to make full use of information from the discretized variables. See Williams, S.Z., Zou, J., Liu, Y., Si, Y., Galea, S. and Chen, Q. (2024), Improving Survey Inference Using Administrative Records Without Releasing Individual-Level Continuous Data. Statistics in Medicine, 43: 5803-5813. <doi:10.1002/sim.10270> for details.  "
  },
  {
    "id": 1845,
    "package_name": "BIFIEsurvey",
    "title": "Tools for Survey Statistics in Educational Assessment",
    "description": "\n    Contains tools for survey statistics (especially in educational\n    assessment) for datasets with replication designs (jackknife, \n    bootstrap, replicate weights; see Kolenikov, 2010;\n    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,\n    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, \n    <doi:10.1080/02331889708802523>). \n    Descriptive statistics, linear and logistic regression, \n    path models for manifest variables with measurement error \n    correction and two-level hierarchical regressions for weighted \n    samples are included. Statistical inference can be conducted for \n    multiply imputed datasets and nested multiply imputed datasets\n    and is in particularly suited for the analysis of plausible values\n    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; \n    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &\n    Yanagida, 2016). The package development was supported by BIFIE \n    (Federal Institute for Educational Research, Innovation and Development \n    of the Austrian School System; Salzburg, Austria).",
    "version": "3.6-6",
    "maintainer": "Alexander Robitzsch <robitzsch@ipn.uni-kiel.de>",
    "author": "BIFIE [aut], Alexander Robitzsch [aut, cre], \n        Konrad Oberwimmer [aut]",
    "url": "https://github.com/alexanderrobitzsch/BIFIEsurvey,\nhttps://sites.google.com/view/alexander-robitzsch/software",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BIFIEsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BIFIEsurvey Tools for Survey Statistics in Educational Assessment \n    Contains tools for survey statistics (especially in educational\n    assessment) for datasets with replication designs (jackknife, \n    bootstrap, replicate weights; see Kolenikov, 2010;\n    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,\n    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, \n    <doi:10.1080/02331889708802523>). \n    Descriptive statistics, linear and logistic regression, \n    path models for manifest variables with measurement error \n    correction and two-level hierarchical regressions for weighted \n    samples are included. Statistical inference can be conducted for \n    multiply imputed datasets and nested multiply imputed datasets\n    and is in particularly suited for the analysis of plausible values\n    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; \n    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &\n    Yanagida, 2016). The package development was supported by BIFIE \n    (Federal Institute for Educational Research, Innovation and Development \n    of the Austrian School System; Salzburg, Austria).  "
  },
  {
    "id": 1918,
    "package_name": "BTM",
    "title": "Biterm Topic Models for Short Text",
    "description": "Biterm Topic Models find topics in collections of short texts. \n    It is a word co-occurrence based topic model that learns topics by modeling word-word co-occurrences patterns which are called biterms.\n    This in contrast to traditional topic models like Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis \n    which are word-document co-occurrence topic models.\n    A biterm consists of two words co-occurring in the same short text window.  \n    This context window can for example be a twitter message, a short answer on a survey, a sentence of a text or a document identifier. \n    The techniques are explained in detail in the paper 'A Biterm Topic Model For Short Text' by Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Xueqi Cheng (2013) <https://github.com/xiaohuiyan/xiaohuiyan.github.io/blob/master/paper/BTM-WWW13.pdf>.",
    "version": "0.3.8",
    "maintainer": "Jan Wijffels <jwijffels@bnosac.be>",
    "author": "Jan Wijffels [aut, cre, cph] (R wrapper),\n  BNOSAC [cph] (R wrapper),\n  Xiaohui Yan [ctb, cph] (BTM C++ library)",
    "url": "https://github.com/bnosac/BTM",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BTM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BTM Biterm Topic Models for Short Text Biterm Topic Models find topics in collections of short texts. \n    It is a word co-occurrence based topic model that learns topics by modeling word-word co-occurrences patterns which are called biterms.\n    This in contrast to traditional topic models like Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis \n    which are word-document co-occurrence topic models.\n    A biterm consists of two words co-occurring in the same short text window.  \n    This context window can for example be a twitter message, a short answer on a survey, a sentence of a text or a document identifier. \n    The techniques are explained in detail in the paper 'A Biterm Topic Model For Short Text' by Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Xueqi Cheng (2013) <https://github.com/xiaohuiyan/xiaohuiyan.github.io/blob/master/paper/BTM-WWW13.pdf>.  "
  },
  {
    "id": 1933,
    "package_name": "BaSTA",
    "title": "Age-Specific Bayesian Survival Trajectory Analysis from\nIncomplete Census or Capture-Recapture/Recovery Data",
    "description": "Estimates survival and mortality with covariates from census or capture-recapture/recovery data in a Bayesian framework when many individuals are of unknown age. It includes tools for data checking, model diagnostics and outputs such as life-tables and plots, as described in Colchero, Jones, and Rebke (2012) <doi:10.1111/j.2041-210X.2012.00186.x> and Colchero et al. (2021) <doi:10.1038/s41467-021-23894-3>.",
    "version": "2.0.2",
    "maintainer": "Fernando Colchero <fernando_colchero@eva.mpg.de>",
    "author": "Fernando Colchero [aut, cre],\n  Owen Jones [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BaSTA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BaSTA Age-Specific Bayesian Survival Trajectory Analysis from\nIncomplete Census or Capture-Recapture/Recovery Data Estimates survival and mortality with covariates from census or capture-recapture/recovery data in a Bayesian framework when many individuals are of unknown age. It includes tools for data checking, model diagnostics and outputs such as life-tables and plots, as described in Colchero, Jones, and Rebke (2012) <doi:10.1111/j.2041-210X.2012.00186.x> and Colchero et al. (2021) <doi:10.1038/s41467-021-23894-3>.  "
  },
  {
    "id": 1987,
    "package_name": "BayesMoFo",
    "title": "Bayesian Mortality Forecasting",
    "description": "Carry out Bayesian estimation and forecasting for a variety of stochastic mortality models using vague prior distributions. Models supported include numerous well-established approaches introduced in the actuarial and demographic literature, such as the Lee-Carter (1992) <doi:10.1080/01621459.1992.10475265>, the Cairns-Blake-Dowd (2009) <doi:10.1080/10920277.2009.10597538>, the Li-Lee (2005) <doi:10.1353/dem.2005.0021>, and the Plat (2009) <doi:10.1016/j.insmatheco.2009.08.006> models. The package is designed to analyse stratified mortality data structured as a 3-dimensional array of dimensions p \u00d7 A \u00d7 T (strata \u00d7 age \u00d7 year). Stratification can represent factors such as cause of death, country, deprivation level, sex, geographic region, insurance product, marital status, socioeconomic group, or smoking behavior. While the primary focus is on analysing stratified data (p > 1), the package can also handle mortality data that are not stratified (p = 1). Model selection via the Deviance Information Criterion (DIC) is supported.",
    "version": "0.1.0",
    "maintainer": "Jackie Siaw Tze Wong <jw19203@essex.ac.uk>",
    "author": "Jackie Siaw Tze Wong [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0314-6684>),\n  Alex Diana [ctb],\n  Aniketh Pittea [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=BayesMoFo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesMoFo Bayesian Mortality Forecasting Carry out Bayesian estimation and forecasting for a variety of stochastic mortality models using vague prior distributions. Models supported include numerous well-established approaches introduced in the actuarial and demographic literature, such as the Lee-Carter (1992) <doi:10.1080/01621459.1992.10475265>, the Cairns-Blake-Dowd (2009) <doi:10.1080/10920277.2009.10597538>, the Li-Lee (2005) <doi:10.1353/dem.2005.0021>, and the Plat (2009) <doi:10.1016/j.insmatheco.2009.08.006> models. The package is designed to analyse stratified mortality data structured as a 3-dimensional array of dimensions p \u00d7 A \u00d7 T (strata \u00d7 age \u00d7 year). Stratification can represent factors such as cause of death, country, deprivation level, sex, geographic region, insurance product, marital status, socioeconomic group, or smoking behavior. While the primary focus is on analysing stratified data (p > 1), the package can also handle mortality data that are not stratified (p = 1). Model selection via the Deviance Information Criterion (DIC) is supported.  "
  },
  {
    "id": 2025,
    "package_name": "BayesianNetwork",
    "title": "Bayesian Network Modeling and Analysis",
    "description": "A \"Shiny\"\" web application for creating interactive Bayesian Network models,\n    learning the structure and parameters of Bayesian networks, and utilities for classic\n    network analysis.",
    "version": "0.3.2",
    "maintainer": "Paul Govan <paul.govan2@gmail.com>",
    "author": "Paul Govan [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-1821-8492>)",
    "url": "https://github.com/paulgovan/bayesiannetwork,\nhttp://paulgovan.github.io/BayesianNetwork/,\nhttps://github.com/paulgovan/BayesianNetwork",
    "bug_reports": "https://github.com/paulgovan/BayesianNetwork/issues",
    "repository": "https://cran.r-project.org/package=BayesianNetwork",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BayesianNetwork Bayesian Network Modeling and Analysis A \"Shiny\"\" web application for creating interactive Bayesian Network models,\n    learning the structure and parameters of Bayesian networks, and utilities for classic\n    network analysis.  "
  },
  {
    "id": 2097,
    "package_name": "Biodem",
    "title": "Biodemography Functions",
    "description": "The Biodem package provides a number of functions for Biodemographic analysis.",
    "version": "0.5",
    "maintainer": "Federico Calboli <f.calboli@gmail.com>",
    "author": "Alessio Boattini and Federico C. F. Calboli; Vincente Canto Cassola together with Martin Maechler authored the function mtx.exp.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Biodem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Biodem Biodemography Functions The Biodem package provides a number of functions for Biodemographic analysis.  "
  },
  {
    "id": 2150,
    "package_name": "BrazilDataAPI",
    "title": "Access Brazilian Data via APIs and Curated Datasets",
    "description": "Provides functions to access data from the 'BrasilAPI', 'REST Countries API',\n    'Nager.Date API', and 'World Bank API', related to Brazil's postal codes, banks, holidays,\n    company registrations, international country indicators, public holidays information, and\n    economic development data. Additionally, the package includes curated datasets related to\n    Brazil, covering topics such as demographic data (males and females by state and year),\n    river levels, environmental emission factors, film festivals, and yellow fever outbreak\n    records. The package supports research and analysis focused on Brazil by integrating open\n    APIs with high-quality datasets from multiple domains. For more information on the APIs, see: \n    'BrasilAPI' <https://brasilapi.com.br/>, \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.2.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/brazildataapi,\nhttps://lightbluetitan.github.io/brazildataapi/",
    "bug_reports": "https://github.com/lightbluetitan/brazildataapi/issues",
    "repository": "https://cran.r-project.org/package=BrazilDataAPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "BrazilDataAPI Access Brazilian Data via APIs and Curated Datasets Provides functions to access data from the 'BrasilAPI', 'REST Countries API',\n    'Nager.Date API', and 'World Bank API', related to Brazil's postal codes, banks, holidays,\n    company registrations, international country indicators, public holidays information, and\n    economic development data. Additionally, the package includes curated datasets related to\n    Brazil, covering topics such as demographic data (males and females by state and year),\n    river levels, environmental emission factors, film festivals, and yellow fever outbreak\n    records. The package supports research and analysis focused on Brazil by integrating open\n    APIs with high-quality datasets from multiple domains. For more information on the APIs, see: \n    'BrasilAPI' <https://brasilapi.com.br/>, \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 2192,
    "package_name": "CATAcode",
    "title": "Explore and Code Responses to Check-All-that-Apply Survey Items",
    "description": "Analyzing responses to check-all-that-apply survey items often requires \n    data transformations and subjective decisions for combining categories. 'CATAcode'\n    contains tools for exploring response patterns, facilitating data transformations, \n    applying a set of decision rules for coding responses, and summarizing response frequencies.",
    "version": "1.0.0",
    "maintainer": "Kyle Nickodem <kyle.nickodem@gmail.com>",
    "author": "Kyle Nickodem [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4976-3378>),\n  Gabriel J. Merrin [aut]",
    "url": "https://github.com/knickodem/CATAcode",
    "bug_reports": "https://github.com/knickodem/CATAcode/issues",
    "repository": "https://cran.r-project.org/package=CATAcode",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CATAcode Explore and Code Responses to Check-All-that-Apply Survey Items Analyzing responses to check-all-that-apply survey items often requires \n    data transformations and subjective decisions for combining categories. 'CATAcode'\n    contains tools for exploring response patterns, facilitating data transformations, \n    applying a set of decision rules for coding responses, and summarizing response frequencies.  "
  },
  {
    "id": 2258,
    "package_name": "CIM",
    "title": "Compositional Impact of Migration",
    "description": "Produces statistical indicators of the impact of migration on the socio-demographic\n\tcomposition of an area. Three measures can be used: ratios, percentages and the Duncan index\n\tof dissimilarity. The input data files are assumed to be in an  origin-destination matrix format,\n\twith each cell representing a flow count between an origin and a destination area. Columns are expected\n\tto represent origins, and rows are expected to represent destinations. The first row and column are\n\tassumed to contain labels for each area. See Rodriguez-Vignoli and Rowe (2018)\n\t<doi:10.1080/00324728.2017.1416155> for technical details.",
    "version": "1.0.0",
    "maintainer": "Nikos Patias <n.patias@liverpool.ac.uk>",
    "author": "Francisco Rowe [aut],\n  Nikos Patias [aut, cre],\n  Jorge Rodr\u00edguez-Vignoli [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CIM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CIM Compositional Impact of Migration Produces statistical indicators of the impact of migration on the socio-demographic\n\tcomposition of an area. Three measures can be used: ratios, percentages and the Duncan index\n\tof dissimilarity. The input data files are assumed to be in an  origin-destination matrix format,\n\twith each cell representing a flow count between an origin and a destination area. Columns are expected\n\tto represent origins, and rows are expected to represent destinations. The first row and column are\n\tassumed to contain labels for each area. See Rodriguez-Vignoli and Rowe (2018)\n\t<doi:10.1080/00324728.2017.1416155> for technical details.  "
  },
  {
    "id": 2263,
    "package_name": "CINNA",
    "title": "Deciphering Central Informative Nodes in Network Analysis",
    "description": "Computing, comparing, and demonstrating top informative centrality measures within a network. \"CINNA: an R/CRAN package to decipher Central Informative Nodes in Network Analysis\" provides a comprehensive overview of the package functionality Ashtiani et al. (2018) <doi:10.1093/bioinformatics/bty819>.",
    "version": "1.2.2",
    "maintainer": "Minoo Ashtiani <ashtiani.minoo@gmail.com>",
    "author": "Minoo Ashtiani [aut, cre],\n  Mehdi Mirzaie [ctb],\n  Mohieddin Jafari [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CINNA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CINNA Deciphering Central Informative Nodes in Network Analysis Computing, comparing, and demonstrating top informative centrality measures within a network. \"CINNA: an R/CRAN package to decipher Central Informative Nodes in Network Analysis\" provides a comprehensive overview of the package functionality Ashtiani et al. (2018) <doi:10.1093/bioinformatics/bty819>.  "
  },
  {
    "id": 2267,
    "package_name": "CITAN",
    "title": "CITation ANalysis Toolpack",
    "description": "Supports quantitative research in scientometrics and bibliometrics.\n    Provides various tools for preprocessing bibliographic\n    data retrieved, e.g., from Elsevier's Scopus,\n    computing bibliometric impact of individuals,\n    or modelling phenomena encountered in the social sciences.\n    This package is deprecated; see 'agop' instead.",
    "version": "2025.7.1",
    "maintainer": "Marek Gagolewski <marek@gagolewski.com>",
    "author": "Marek Gagolewski [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0637-6028>)",
    "url": "https://github.com/gagolews/CITAN",
    "bug_reports": "https://github.com/gagolews/CITAN/issues",
    "repository": "https://cran.r-project.org/package=CITAN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CITAN CITation ANalysis Toolpack Supports quantitative research in scientometrics and bibliometrics.\n    Provides various tools for preprocessing bibliographic\n    data retrieved, e.g., from Elsevier's Scopus,\n    computing bibliometric impact of individuals,\n    or modelling phenomena encountered in the social sciences.\n    This package is deprecated; see 'agop' instead.  "
  },
  {
    "id": 2283,
    "package_name": "CLVTools",
    "title": "Tools for Customer Lifetime Value Estimation",
    "description": "\n    A set of state-of-the-art probabilistic modeling approaches to derive estimates of individual customer lifetime values (CLV).\n    Commonly, probabilistic approaches focus on modelling 3 processes, i.e. individuals' attrition, transaction, and spending process. \n    Latent customer attrition models, which are also known as \"buy-'til-you-die models\", model the attrition as well as the transaction process. \n    They are used to make inferences and predictions about transactional patterns of individual customers such as their future purchase behavior. \n    Moreover, these models have also been used to predict individuals\u2019 long-term engagement in activities such as playing an online game or \n    posting to a social media platform. The spending process is usually modelled by a separate probabilistic model. Combining these results yields in \n    lifetime values estimates for individual customers.\n    This package includes fast and accurate implementations of various probabilistic models for non-contractual settings \n    (e.g., grocery purchases or hotel visits). All implementations support time-invariant covariates, which can be used to control for e.g., \n    socio-demographics. If such an extension has been proposed in literature, we further provide the possibility to control for time-varying \n    covariates to control for e.g., seasonal patterns. \n    Currently, the package includes the following latent attrition models to model individuals' attrition and transaction process: \n    [1] Pareto/NBD model (Pareto/Negative-Binomial-Distribution), \n    [2] the Extended Pareto/NBD model (Pareto/Negative-Binomial-Distribution with time-varying covariates), \n    [3] the BG/NBD model (Beta-Gamma/Negative-Binomial-Distribution) and the \n    [4] GGom/NBD (Gamma-Gompertz/Negative-Binomial-Distribution). \n    Further, we provide an implementation of the Gamma/Gamma model to model the spending process of individuals.",
    "version": "0.12.1",
    "maintainer": "Patrick Bachmann <pbachma@ethz.ch>",
    "author": "Patrick Bachmann [cre, aut],\n  Niels Kuebler [aut],\n  Markus Meierer [aut],\n  Jeffrey Naef [aut],\n  E. Shin Oblander [aut],\n  Patrik Schilter [aut]",
    "url": "https://github.com/bachmannpatrick/CLVTools",
    "bug_reports": "https://github.com/bachmannpatrick/CLVTools/issues",
    "repository": "https://cran.r-project.org/package=CLVTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CLVTools Tools for Customer Lifetime Value Estimation \n    A set of state-of-the-art probabilistic modeling approaches to derive estimates of individual customer lifetime values (CLV).\n    Commonly, probabilistic approaches focus on modelling 3 processes, i.e. individuals' attrition, transaction, and spending process. \n    Latent customer attrition models, which are also known as \"buy-'til-you-die models\", model the attrition as well as the transaction process. \n    They are used to make inferences and predictions about transactional patterns of individual customers such as their future purchase behavior. \n    Moreover, these models have also been used to predict individuals\u2019 long-term engagement in activities such as playing an online game or \n    posting to a social media platform. The spending process is usually modelled by a separate probabilistic model. Combining these results yields in \n    lifetime values estimates for individual customers.\n    This package includes fast and accurate implementations of various probabilistic models for non-contractual settings \n    (e.g., grocery purchases or hotel visits). All implementations support time-invariant covariates, which can be used to control for e.g., \n    socio-demographics. If such an extension has been proposed in literature, we further provide the possibility to control for time-varying \n    covariates to control for e.g., seasonal patterns. \n    Currently, the package includes the following latent attrition models to model individuals' attrition and transaction process: \n    [1] Pareto/NBD model (Pareto/Negative-Binomial-Distribution), \n    [2] the Extended Pareto/NBD model (Pareto/Negative-Binomial-Distribution with time-varying covariates), \n    [3] the BG/NBD model (Beta-Gamma/Negative-Binomial-Distribution) and the \n    [4] GGom/NBD (Gamma-Gompertz/Negative-Binomial-Distribution). \n    Further, we provide an implementation of the Gamma/Gamma model to model the spending process of individuals.  "
  },
  {
    "id": 2325,
    "package_name": "COVIDIBGE",
    "title": "Downloading, Reading and Analyzing PNAD COVID19 Microdata",
    "description": "Provides tools for downloading, reading and analyzing the COVID19 National\n  Household Sample Survey - PNAD COVID19, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.",
    "version": "0.2.2",
    "maintainer": "Gabriel Assuncao <pacotesipd@ibge.gov.br>",
    "author": "Gabriel Assuncao [aut, cre],\n  Luna Hidalgo [aut],\n  Douglas Braga [ctb],\n  Viviane Quintaes [ctb]",
    "url": "",
    "bug_reports": "https://github.com/Gabriel-Assuncao/COVIDIBGE/issues",
    "repository": "https://cran.r-project.org/package=COVIDIBGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "COVIDIBGE Downloading, Reading and Analyzing PNAD COVID19 Microdata Provides tools for downloading, reading and analyzing the COVID19 National\n  Household Sample Survey - PNAD COVID19, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.  "
  },
  {
    "id": 2391,
    "package_name": "CalibrateSSB",
    "title": "Weighting and Estimation for Panel Data with Non-Response",
    "description": "Functions to calculate weights, estimates of changes and corresponding variance estimates for panel data with non-response. Partially overlapping samples are handled. Initially, weights are calculated by linear calibration. By default, the survey package is used for this purpose. It is also possible to use ReGenesees, which can be installed from <https://github.com/DiegoZardetto/ReGenesees>. Variances of linear combinations (changes and averages) and ratios are calculated from a covariance matrix based on residuals according to the calibration model. The methodology was presented at the conference, The Use of R in Official Statistics, and is described in Langsrud (2016) <http://www.revistadestatistica.ro/wp-content/uploads/2016/06/RRS2_2016_A021.pdf>.  ",
    "version": "1.3.0",
    "maintainer": "Oyvind Langsrud <oyl@ssb.no>",
    "author": "\u00d8yvind Langsrud",
    "url": "https://github.com/statisticsnorway/CalibrateSSB",
    "bug_reports": "https://github.com/statisticsnorway/CalibrateSSB/issues",
    "repository": "https://cran.r-project.org/package=CalibrateSSB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CalibrateSSB Weighting and Estimation for Panel Data with Non-Response Functions to calculate weights, estimates of changes and corresponding variance estimates for panel data with non-response. Partially overlapping samples are handled. Initially, weights are calculated by linear calibration. By default, the survey package is used for this purpose. It is also possible to use ReGenesees, which can be installed from <https://github.com/DiegoZardetto/ReGenesees>. Variances of linear combinations (changes and averages) and ratios are calculated from a covariance matrix based on residuals according to the calibration model. The methodology was presented at the conference, The Use of R in Official Statistics, and is described in Langsrud (2016) <http://www.revistadestatistica.ro/wp-content/uploads/2016/06/RRS2_2016_A021.pdf>.    "
  },
  {
    "id": 2401,
    "package_name": "CareDensity",
    "title": "Calculate the Care Density or Fragmented Care Density Given a\nPatient-Sharing Network",
    "description": "Given a patient-sharing network, calculate either the classic care density as\n\tproposed by Pollack et al. (2013) <doi:10.1007/s11606-012-2104-7> or the\n\tfragmented care density as proposed by Engels et al. (2024) <doi:10.1186/s12874-023-02106-0>.\n\tBy utilizing the 'igraph' and 'data.table' packages, the provided functions scale well for\n\tvery large graphs.",
    "version": "0.1.0",
    "maintainer": "Robin Denz <robin.denz@rub.de>",
    "author": "Robin Denz [aut, cre]",
    "url": "https://github.com/RobinDenz1/CareDensity,\nhttps://robindenz1.github.io/CareDensity/",
    "bug_reports": "https://github.com/RobinDenz1/CareDensity/issues",
    "repository": "https://cran.r-project.org/package=CareDensity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CareDensity Calculate the Care Density or Fragmented Care Density Given a\nPatient-Sharing Network Given a patient-sharing network, calculate either the classic care density as\n\tproposed by Pollack et al. (2013) <doi:10.1007/s11606-012-2104-7> or the\n\tfragmented care density as proposed by Engels et al. (2024) <doi:10.1186/s12874-023-02106-0>.\n\tBy utilizing the 'igraph' and 'data.table' packages, the provided functions scale well for\n\tvery large graphs.  "
  },
  {
    "id": 2428,
    "package_name": "Census2016",
    "title": "Data from the Australian Census 2016",
    "description": "Contains selected variables from the time series profiles for statistical areas level 2 from the 2006, 2011, and 2016 censuses of population and housing, Australia. Also provides methods for viewing the questions asked for convenience during analysis.",
    "version": "0.2.0",
    "maintainer": "Hugh Parsonage <hugh.parsonage@gmail.com>",
    "author": "Hugh Parsonage [aut, cre],\n  Nick Evershed [dtc],\n  Australian Bureau of Statistics [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Census2016",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Census2016 Data from the Australian Census 2016 Contains selected variables from the time series profiles for statistical areas level 2 from the 2006, 2011, and 2016 censuses of population and housing, Australia. Also provides methods for viewing the questions asked for convenience during analysis.  "
  },
  {
    "id": 2456,
    "package_name": "ChileDataAPI",
    "title": "Access Chilean Data via APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including\n    'FINDIC API', 'REST Countries API', 'World Bank API', and 'Nager.Date', \n    retrieving real-time or historical data related to Chile such as financial indicators, \n    holidays, international demographic and geopolitical indicators, and more. \n    Additionally, the package includes curated datasets related to Chile, covering topics \n    such as human rights violations during the Pinochet regime, electoral data, census samples, \n    health surveys, seismic events, territorial codes, and environmental measurements. \n    The package supports research and analysis focused on Chile by integrating open APIs with \n    high-quality datasets from multiple domains. For more information on the APIs, see: \n    'FINDIC' <https://findic.cl/>, \n    'REST Countries' <https://restcountries.com/>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'Nager.Date' <https://date.nager.at/Api>.",
    "version": "0.2.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/chiledataapi,\nhttps://lightbluetitan.github.io/chiledataapi/",
    "bug_reports": "https://github.com/lightbluetitan/chiledataapi/issues",
    "repository": "https://cran.r-project.org/package=ChileDataAPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ChileDataAPI Access Chilean Data via APIs and Curated Datasets Provides functions to access data from public RESTful APIs including\n    'FINDIC API', 'REST Countries API', 'World Bank API', and 'Nager.Date', \n    retrieving real-time or historical data related to Chile such as financial indicators, \n    holidays, international demographic and geopolitical indicators, and more. \n    Additionally, the package includes curated datasets related to Chile, covering topics \n    such as human rights violations during the Pinochet regime, electoral data, census samples, \n    health surveys, seismic events, territorial codes, and environmental measurements. \n    The package supports research and analysis focused on Chile by integrating open APIs with \n    high-quality datasets from multiple domains. For more information on the APIs, see: \n    'FINDIC' <https://findic.cl/>, \n    'REST Countries' <https://restcountries.com/>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'Nager.Date' <https://date.nager.at/Api>.  "
  },
  {
    "id": 2458,
    "package_name": "ChinAPIs",
    "title": "Access Chinese Data via Public APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including 'Nager.Date', \n    'World Bank API', and 'REST Countries API', retrieving real-time or historical data \n    related to China, such as holidays, economic indicators, and international demographic \n    and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on China and Hong Kong, covering topics \n    such as air quality, demographics, input-output tables, epidemiology, political \n    structure, names, and social indicators. The package supports reproducible research \n    and teaching by integrating reliable international APIs and structured datasets from \n    public, academic, and government sources.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/chinapis,\nhttps://lightbluetitan.github.io/chinapis/",
    "bug_reports": "https://github.com/lightbluetitan/chinapis/issues",
    "repository": "https://cran.r-project.org/package=ChinAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ChinAPIs Access Chinese Data via Public APIs and Curated Datasets Provides functions to access data from public RESTful APIs including 'Nager.Date', \n    'World Bank API', and 'REST Countries API', retrieving real-time or historical data \n    related to China, such as holidays, economic indicators, and international demographic \n    and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on China and Hong Kong, covering topics \n    such as air quality, demographics, input-output tables, epidemiology, political \n    structure, names, and social indicators. The package supports reproducible research \n    and teaching by integrating reliable international APIs and structured datasets from \n    public, academic, and government sources.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 2459,
    "package_name": "ChineseNames",
    "title": "Chinese Name Database 1930-2008",
    "description": "\n    A database of Chinese surnames and given names (1930-2008).\n    This database contains nationwide frequency statistics of\n    1,806 Chinese surnames and 2,614 Chinese characters used in given names,\n    covering about 1.2 billion Han Chinese population\n    (96.8 percent of the Han Chinese household-registered population\n    born from 1930 to 2008 and still alive in 2008).\n    This package also contains a function for computing multiple indices of\n    Chinese surnames and given names for social science research (e.g.,\n    name uniqueness, name gender, name valence, and name warmth/competence).\n    Details are provided at\n    <https://psychbruce.github.io/ChineseNames/>.",
    "version": "2025.8",
    "maintainer": "Han Wu Shuang Bao <baohws@foxmail.com>",
    "author": "Han Wu Shuang Bao [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3043-710X>)",
    "url": "https://psychbruce.github.io/ChineseNames/",
    "bug_reports": "https://github.com/psychbruce/ChineseNames/issues",
    "repository": "https://cran.r-project.org/package=ChineseNames",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ChineseNames Chinese Name Database 1930-2008 \n    A database of Chinese surnames and given names (1930-2008).\n    This database contains nationwide frequency statistics of\n    1,806 Chinese surnames and 2,614 Chinese characters used in given names,\n    covering about 1.2 billion Han Chinese population\n    (96.8 percent of the Han Chinese household-registered population\n    born from 1930 to 2008 and still alive in 2008).\n    This package also contains a function for computing multiple indices of\n    Chinese surnames and given names for social science research (e.g.,\n    name uniqueness, name gender, name valence, and name warmth/competence).\n    Details are provided at\n    <https://psychbruce.github.io/ChineseNames/>.  "
  },
  {
    "id": 2472,
    "package_name": "CircaCP",
    "title": "Sleep and Circadian Metrics Estimation from Actigraphy Data",
    "description": "A generic sleep\u2013wake cycle detection algorithm for analyzing unlabeled actigraphy data. \n    The algorithm has been validated against event markers using data from the Multi-Ethnic Study of Atherosclerosis (MESA) Sleep study, \n    and its methodological details are described in Chen and Sun (2024) <doi:10.1098/rsos.231468>. \n    The package provides functions to estimate sleep metrics (e.g., sleep and wake onset times) and circadian rhythm metrics \n    (e.g., mesor, phasor, interdaily stability, intradaily variability), as well as tools for screening actigraphy quality, \n    fitting cosinor models, and performing parametric change point detection. \n    The workflow can also be used to segment long actigraphy sequences into regularized structures for physical activity research.",
    "version": "0.1.2",
    "maintainer": "Shanshan Chen <schen3@vcu.edu>",
    "author": "Shanshan Chen [aut, cre],\n  Jonathon Jacobs [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CircaCP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CircaCP Sleep and Circadian Metrics Estimation from Actigraphy Data A generic sleep\u2013wake cycle detection algorithm for analyzing unlabeled actigraphy data. \n    The algorithm has been validated against event markers using data from the Multi-Ethnic Study of Atherosclerosis (MESA) Sleep study, \n    and its methodological details are described in Chen and Sun (2024) <doi:10.1098/rsos.231468>. \n    The package provides functions to estimate sleep metrics (e.g., sleep and wake onset times) and circadian rhythm metrics \n    (e.g., mesor, phasor, interdaily stability, intradaily variability), as well as tools for screening actigraphy quality, \n    fitting cosinor models, and performing parametric change point detection. \n    The workflow can also be used to segment long actigraphy sequences into regularized structures for physical activity research.  "
  },
  {
    "id": 2527,
    "package_name": "CoDiNA",
    "title": "Co-Expression Differential Network Analysis",
    "description": "Categorize links and nodes from multiple networks in 3 categories: Common links (alpha) specific links (gamma), and different links (beta). Also categorizes the links into sub-categories and groups. The package includes a visualization tool for the networks. More information about the methodology can be found at: Gysi et. al., 2018 <arXiv:1802.00828>.",
    "version": "1.1.2",
    "maintainer": "Deisy Morselli Gysi <deisy.ccnr@gmail.com>",
    "author": "Deisy Morselli Gysi, Tiago de Miranda Fragoso, Eivind Almaas and Katja Nowick.",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=CoDiNA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "CoDiNA Co-Expression Differential Network Analysis Categorize links and nodes from multiple networks in 3 categories: Common links (alpha) specific links (gamma), and different links (beta). Also categorizes the links into sub-categories and groups. The package includes a visualization tool for the networks. More information about the methodology can be found at: Gysi et. al., 2018 <arXiv:1802.00828>.  "
  },
  {
    "id": 2547,
    "package_name": "ColombiAPI",
    "title": "Access Colombian Data via APIs and Curated Datasets",
    "description": "Provides a comprehensive interface to access diverse public data about\n    Colombia through multiple APIs and curated datasets. The package integrates\n    four different APIs: 'API-Colombia' for Colombian-specific data including\n    geography, culture, tourism, and government information; 'World Bank API' \n    for economic and demographic indicators; 'Nager.Date' for public holidays;\n    and 'REST Countries API' for general country information. The package enables\n    users to explore various aspects of Colombia such as geographic locations,\n    cultural attractions, economic indicators, demographic data, and public\n    holidays. Additionally, 'ColombiAPI' includes curated datasets covering\n    Bogota air stations, business and holiday dates, public schools, Colombian\n    coffee exports, cannabis licenses, Medellin rainfall, malls in Bogota, as\n    well as datasets on indigenous languages, student admissions and school\n    statistics, forest liana mortality, municipal and regional data, connectivity\n    and digital infrastructure, program graduates, vehicle counts, international\n    visitors, and GDP projections. These datasets provide users with a rich and\n    multifaceted view of Colombian social, economic, environmental, and\n    technological information, making 'ColombiAPI' a comprehensive tool for\n    exploring Colombia's diverse data landscape. \n    For more information on the APIs, see:\n    'API-Colombia' <https://api-colombia.com/>, \n    'Nager.Date'  <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>,\n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.3.1",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/colombiapi,\nhttps://lightbluetitan.github.io/colombiapi/",
    "bug_reports": "https://github.com/lightbluetitan/colombiapi/issues",
    "repository": "https://cran.r-project.org/package=ColombiAPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ColombiAPI Access Colombian Data via APIs and Curated Datasets Provides a comprehensive interface to access diverse public data about\n    Colombia through multiple APIs and curated datasets. The package integrates\n    four different APIs: 'API-Colombia' for Colombian-specific data including\n    geography, culture, tourism, and government information; 'World Bank API' \n    for economic and demographic indicators; 'Nager.Date' for public holidays;\n    and 'REST Countries API' for general country information. The package enables\n    users to explore various aspects of Colombia such as geographic locations,\n    cultural attractions, economic indicators, demographic data, and public\n    holidays. Additionally, 'ColombiAPI' includes curated datasets covering\n    Bogota air stations, business and holiday dates, public schools, Colombian\n    coffee exports, cannabis licenses, Medellin rainfall, malls in Bogota, as\n    well as datasets on indigenous languages, student admissions and school\n    statistics, forest liana mortality, municipal and regional data, connectivity\n    and digital infrastructure, program graduates, vehicle counts, international\n    visitors, and GDP projections. These datasets provide users with a rich and\n    multifaceted view of Colombian social, economic, environmental, and\n    technological information, making 'ColombiAPI' a comprehensive tool for\n    exploring Colombia's diverse data landscape. \n    For more information on the APIs, see:\n    'API-Colombia' <https://api-colombia.com/>, \n    'Nager.Date'  <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>,\n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 2551,
    "package_name": "ComRiskModel",
    "title": "Fitting of Complementary Risk Models",
    "description": "Evaluates the probability density function (PDF), cumulative distribution function (CDF), quantile function (QF), random numbers and maximum likelihood estimates (MLEs) of well-known complementary binomial-G, complementary negative binomial-G and complementary geometric-G families of distributions taking baseline models such as exponential, extended exponential,  Weibull,  extended Weibull, Fisk, Lomax, Burr-XII and Burr-X. The functions also allow computing the goodness-of-fit measures namely the Akaike-information-criterion (AIC), the Bayesian-information-criterion (BIC), the minimum value of the negative log-likelihood (-2L) function, Anderson-Darling (A) test, Cramer-Von-Mises (W) test, Kolmogorov-Smirnov test, P-value and convergence status. Moreover, some commonly used data sets from the fields of actuarial, reliability, and medical science are also provided. Related works include: \n  a) Tahir, M. H., & Cordeiro, G. M. (2016). Compounding of distributions: a survey and new generalized classes. Journal of Statistical Distributions and Applications, 3, 1-35. \n  <doi:10.1186/s40488-016-0052-1>.  ",
    "version": "0.2.0",
    "maintainer": "Muhammad Imran <imranshakoor84@yahoo.com>",
    "author": "Muhammad Imran [aut, cre],\n  M.H Tahir [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ComRiskModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ComRiskModel Fitting of Complementary Risk Models Evaluates the probability density function (PDF), cumulative distribution function (CDF), quantile function (QF), random numbers and maximum likelihood estimates (MLEs) of well-known complementary binomial-G, complementary negative binomial-G and complementary geometric-G families of distributions taking baseline models such as exponential, extended exponential,  Weibull,  extended Weibull, Fisk, Lomax, Burr-XII and Burr-X. The functions also allow computing the goodness-of-fit measures namely the Akaike-information-criterion (AIC), the Bayesian-information-criterion (BIC), the minimum value of the negative log-likelihood (-2L) function, Anderson-Darling (A) test, Cramer-Von-Mises (W) test, Kolmogorov-Smirnov test, P-value and convergence status. Moreover, some commonly used data sets from the fields of actuarial, reliability, and medical science are also provided. Related works include: \n  a) Tahir, M. H., & Cordeiro, G. M. (2016). Compounding of distributions: a survey and new generalized classes. Journal of Statistical Distributions and Applications, 3, 1-35. \n  <doi:10.1186/s40488-016-0052-1>.    "
  },
  {
    "id": 2715,
    "package_name": "DBR",
    "title": "Discrete Beta Regression",
    "description": "Bayesian Beta Regression, adapted for bounded discrete responses, commonly seen in survey responses.\n  Estimation is done via Markov Chain Monte Carlo sampling, using a Gibbs wrapper around univariate slice sampler \n  (Neal (2003) <DOI:10.1214/aos/1056562461>), as implemented in the R package MfUSampler \n  (Mahani and Sharabiani (2017) <DOI: 10.18637/jss.v078.c01>).",
    "version": "1.4.1",
    "maintainer": "Alireza Mahani <alireza.s.mahani@gmail.com>",
    "author": "Alireza Mahani [cre, aut],\n  Mansour Sharabiani [aut],\n  Alex Bottle [aut],\n  Cathy Price [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DBR Discrete Beta Regression Bayesian Beta Regression, adapted for bounded discrete responses, commonly seen in survey responses.\n  Estimation is done via Markov Chain Monte Carlo sampling, using a Gibbs wrapper around univariate slice sampler \n  (Neal (2003) <DOI:10.1214/aos/1056562461>), as implemented in the R package MfUSampler \n  (Mahani and Sharabiani (2017) <DOI: 10.18637/jss.v078.c01>).  "
  },
  {
    "id": 2724,
    "package_name": "DCG",
    "title": "Data Cloud Geometry (DCG): Using Random Walks to Find Community\nStructure in Social Network Analysis",
    "description": "Data cloud geometry (DCG) applies random walks in finding community structures for social networks. \n    Fushing, VanderWaal, McCowan, & Koehl (2013) (<doi:10.1371/journal.pone.0056259>).",
    "version": "0.9.3",
    "maintainer": "Jessica Vandeleest <vandelee@ucdavis.edu>",
    "author": "Chen Chen [aut],\n  Jian Jin [aut],\n  Jessica Vandeleest [aut, cre],\n  Brianne Beisner [aut],\n  Brenda McCowan [aut, cph],\n  Hsieh Fushing [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DCG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DCG Data Cloud Geometry (DCG): Using Random Walks to Find Community\nStructure in Social Network Analysis Data cloud geometry (DCG) applies random walks in finding community structures for social networks. \n    Fushing, VanderWaal, McCowan, & Koehl (2013) (<doi:10.1371/journal.pone.0056259>).  "
  },
  {
    "id": 2727,
    "package_name": "DCPO",
    "title": "Dynamic Comparative Public Opinion",
    "description": "Estimates latent variables of public opinion cross-nationally and over time from sparse and incomparable survey data.  'DCPO' uses a population-level graded response model with country-specific item bias terms. Sampling is conducted with 'Stan'.  References: Solt (2020) <doi:10.31235/osf.io/d5n9p>.",
    "version": "0.5.3",
    "maintainer": "Frederick Solt <frederick-solt@uiowa.edu>",
    "author": "Frederick Solt [aut, cre],\n  Trustees of Columbia University [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DCPO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DCPO Dynamic Comparative Public Opinion Estimates latent variables of public opinion cross-nationally and over time from sparse and incomparable survey data.  'DCPO' uses a population-level graded response model with country-specific item bias terms. Sampling is conducted with 'Stan'.  References: Solt (2020) <doi:10.31235/osf.io/d5n9p>.  "
  },
  {
    "id": 2736,
    "package_name": "DDM",
    "title": "Death Registration Coverage Estimation",
    "description": "A set of three two-census methods to the estimate the degree of death registration coverage for a population. Implemented methods include the Generalized Growth Balance method (GGB), the Synthetic Extinct Generation method (SEG), and a hybrid of the two, GGB-SEG. Each method offers automatic estimation, but users may also specify exact parameters or use a graphical interface to guess parameters in the traditional way if desired.",
    "version": "1.0-0",
    "maintainer": "Tim Riffe <riffe@demogr.mpg.de>",
    "author": "Tim Riffe, Everton Lima, Bernardo Queiroz",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DDM Death Registration Coverage Estimation A set of three two-census methods to the estimate the degree of death registration coverage for a population. Implemented methods include the Generalized Growth Balance method (GGB), the Synthetic Extinct Generation method (SEG), and a hybrid of the two, GGB-SEG. Each method offers automatic estimation, but users may also specify exact parameters or use a graphical interface to guess parameters in the traditional way if desired.  "
  },
  {
    "id": 2775,
    "package_name": "DHS.rates",
    "title": "Calculates Demographic Indicators",
    "description": "Calculates key indicators such as fertility rates (Total Fertility Rate (TFR), General Fertility Rate (GFR), \n  and Age Specific Fertility Rate (ASFR)) using Demographic and Health Survey (DHS) women/individual data, \n  childhood mortality probabilities and rates such as Neonatal Mortality Rate (NNMR), Post-neonatal Mortality Rate (PNNMR), \n  Infant Mortality Rate (IMR), Child Mortality Rate (CMR), and Under-five Mortality Rate (U5MR), and adult mortality indicators \n  such as the Age Specific Mortality Rate (ASMR), Age Adjusted Mortality Rate (AAMR), Age Specific Maternal Mortality Rate (ASMMR),\n  Age Adjusted Maternal Mortality Rate (AAMMR), Age Specific Pregnancy Related Mortality Rate (ASPRMR), \n  Age Adjusted Pregnancy Related Mortality Rate (AAPRMR), Maternal Mortality Ratio (MMR) and Pregnancy Related Mortality Ratio (PRMR).  \n  In addition to the indicators, the 'DHS.rates' package estimates sampling errors indicators such as Standard Error (SE), \n  Design Effect (DEFT), Relative Standard Error (RSE) and Confidence Interval (CI). \n  The package is developed according to the DHS methodology of calculating the fertility indicators and \n  the childhood mortality rates outlined in the \n  \"Guide to DHS Statistics\" (Croft, Trevor N., Aileen M. J. Marshall, Courtney K. Allen, et al. 2018, <https://dhsprogram.com/Data/Guide-to-DHS-Statistics/index.cfm>) \n  and the DHS methodology of estimating the sampling errors indicators outlined in \n  the \"DHS Sampling and Household Listing Manual\" (ICF International 2012, <https://dhsprogram.com/pubs/pdf/DHSM4/DHS6_Sampling_Manual_Sept2012_DHSM4.pdf>).",
    "version": "0.9.2",
    "maintainer": "Mahmoud Elkasabi <mahmoudelkasabi@gmail.com>",
    "author": "Mahmoud Elkasabi",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DHS.rates",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DHS.rates Calculates Demographic Indicators Calculates key indicators such as fertility rates (Total Fertility Rate (TFR), General Fertility Rate (GFR), \n  and Age Specific Fertility Rate (ASFR)) using Demographic and Health Survey (DHS) women/individual data, \n  childhood mortality probabilities and rates such as Neonatal Mortality Rate (NNMR), Post-neonatal Mortality Rate (PNNMR), \n  Infant Mortality Rate (IMR), Child Mortality Rate (CMR), and Under-five Mortality Rate (U5MR), and adult mortality indicators \n  such as the Age Specific Mortality Rate (ASMR), Age Adjusted Mortality Rate (AAMR), Age Specific Maternal Mortality Rate (ASMMR),\n  Age Adjusted Maternal Mortality Rate (AAMMR), Age Specific Pregnancy Related Mortality Rate (ASPRMR), \n  Age Adjusted Pregnancy Related Mortality Rate (AAPRMR), Maternal Mortality Ratio (MMR) and Pregnancy Related Mortality Ratio (PRMR).  \n  In addition to the indicators, the 'DHS.rates' package estimates sampling errors indicators such as Standard Error (SE), \n  Design Effect (DEFT), Relative Standard Error (RSE) and Confidence Interval (CI). \n  The package is developed according to the DHS methodology of calculating the fertility indicators and \n  the childhood mortality rates outlined in the \n  \"Guide to DHS Statistics\" (Croft, Trevor N., Aileen M. J. Marshall, Courtney K. Allen, et al. 2018, <https://dhsprogram.com/Data/Guide-to-DHS-Statistics/index.cfm>) \n  and the DHS methodology of estimating the sampling errors indicators outlined in \n  the \"DHS Sampling and Household Listing Manual\" (ICF International 2012, <https://dhsprogram.com/pubs/pdf/DHSM4/DHS6_Sampling_Manual_Sept2012_DHSM4.pdf>).  "
  },
  {
    "id": 2776,
    "package_name": "DHSr",
    "title": "Create Large Scale Repeated Regression Summary Statistics\nDataset and Visualization Seamlessly",
    "description": "Mapping, spatial analysis, and statistical modeling of microdata from sources such as the Demographic and Health Surveys <https://www.dhsprogram.com/> and Integrated Public Use Microdata Series <https://www.ipums.org/>. It can also be extended to other datasets. The package supports spatial correlation index construction and visualization, along with empirical Bayes approximation of regression coefficients in a multistage setup.  The main functionality is repeated regression \u2014 for example, if we have to run regression for n groups, the group ID should be vertically composed into the variable for the parameter `location_var`. It can perform various kinds of regression, such as Generalized Regression Models, logit, probit, and more. Additionally, it can incorporate interaction effects. The key benefit of the package is its ability to store the regression results performed repeatedly on a dataset by the group ID, along with respective p-values and map those estimates. ",
    "version": "0.1.0",
    "maintainer": "Arnab Samanta <arnob.shamanta62@gmail.com>",
    "author": "Arnab Samanta [aut, cre] (<arnob.shamanta62@gmail.com>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DHSr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DHSr Create Large Scale Repeated Regression Summary Statistics\nDataset and Visualization Seamlessly Mapping, spatial analysis, and statistical modeling of microdata from sources such as the Demographic and Health Surveys <https://www.dhsprogram.com/> and Integrated Public Use Microdata Series <https://www.ipums.org/>. It can also be extended to other datasets. The package supports spatial correlation index construction and visualization, along with empirical Bayes approximation of regression coefficients in a multistage setup.  The main functionality is repeated regression \u2014 for example, if we have to run regression for n groups, the group ID should be vertically composed into the variable for the parameter `location_var`. It can perform various kinds of regression, such as Generalized Regression Models, logit, probit, and more. Additionally, it can incorporate interaction effects. The key benefit of the package is its ability to store the regression results performed repeatedly on a dataset by the group ID, along with respective p-values and map those estimates.   "
  },
  {
    "id": 2789,
    "package_name": "DIGSS",
    "title": "Determination of Intervals Using Georeferenced Survey Simulation",
    "description": "Simulation tool to estimate the rate of success that surveys possessing user-specific characteristics have in identifying archaeological sites (or any groups of clouds of objects), given specific parameters of survey area, survey methods, and site properties. The survey approach used is largely based on the work of Kintigh (1988) <doi:10.2307/281113>.",
    "version": "1.0.2",
    "maintainer": "Mark Hubbe <hubbe.1@osu.edu>",
    "author": "Mark Hubbe [aut, cre],\n  Cara Hubbell [aut],\n  William Pestle [aut]",
    "url": "https://github.com/markhubbe/DIGSS",
    "bug_reports": "https://github.com/markhubbe/DIGSS/issues",
    "repository": "https://cran.r-project.org/package=DIGSS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DIGSS Determination of Intervals Using Georeferenced Survey Simulation Simulation tool to estimate the rate of success that surveys possessing user-specific characteristics have in identifying archaeological sites (or any groups of clouds of objects), given specific parameters of survey area, survey methods, and site properties. The survey approach used is largely based on the work of Kintigh (1988) <doi:10.2307/281113>.  "
  },
  {
    "id": 2900,
    "package_name": "DasGuptR",
    "title": "Das Gupta Standardisation and Decomposition",
    "description": "Implementation of Das Gupta's standardisation and decomposition of population rates, as set out \"Standardization and decomposition of rates: A user\u2019s manual\", Das Gupta (1993) <https://www2.census.gov/library/publications/1993/demographics/p23-186.pdf>. The goal of these methods is to calculate adjusted rates based on compositional 'factors' and quantify the contribution of each factor to the difference in crude rates between populations. The package offers functionality to handle various scenarios for any number of factors and populations, where said factors can be comprised of vectors across sub-populations (including cross-classified population breakdowns), and with the option to specify user-defined rate functions.  ",
    "version": "2.1.0",
    "maintainer": "Josiah King <josiah.king@ed.ac.uk>",
    "author": "Josiah King [aut, cre],\n  Ben Matthews [aut]",
    "url": "https://github.com/josiahpjking/DasGuptR",
    "bug_reports": "https://github.com/josiahpjking/DasGuptR/issues",
    "repository": "https://cran.r-project.org/package=DasGuptR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DasGuptR Das Gupta Standardisation and Decomposition Implementation of Das Gupta's standardisation and decomposition of population rates, as set out \"Standardization and decomposition of rates: A user\u2019s manual\", Das Gupta (1993) <https://www2.census.gov/library/publications/1993/demographics/p23-186.pdf>. The goal of these methods is to calculate adjusted rates based on compositional 'factors' and quantify the contribution of each factor to the difference in crude rates between populations. The package offers functionality to handle various scenarios for any number of factors and populations, where said factors can be comprised of vectors across sub-populations (including cross-classified population breakdowns), and with the option to specify user-defined rate functions.    "
  },
  {
    "id": 2929,
    "package_name": "DecomposeR",
    "title": "Empirical Mode Decomposition for Cyclostratigraphy",
    "description": "Tools to apply Ensemble Empirical Mode \n    Decomposition (EEMD) for cyclostratigraphy purposes. Mainly: a new \n    algorithm, extricate, that performs EEMD in seconds, a linear interpolation \n    algorithm  using the greatest rational common divisor of depth or time, \n    different algorithms to compute instantaneous amplitude, frequency and  \n    ratios of frequencies, and functions to verify and visualise the outputs.\n    The functions were developed during the CRASH project (Checking the \n    Reproducibility of Astrochronology in the Hauterivian). When using for \n    publication please cite Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, \n    A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X., 2022, \n    \"A decomposition approach to cyclostratigraphic signal processing\". \n    Earth-Science Reviews 225 (103894).\n    <doi:10.1016/j.earscirev.2021.103894>.",
    "version": "1.0.7",
    "maintainer": "Sebastien Wouters <wouterseb@gmail.com>",
    "author": "Sebastien Wouters [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DecomposeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DecomposeR Empirical Mode Decomposition for Cyclostratigraphy Tools to apply Ensemble Empirical Mode \n    Decomposition (EEMD) for cyclostratigraphy purposes. Mainly: a new \n    algorithm, extricate, that performs EEMD in seconds, a linear interpolation \n    algorithm  using the greatest rational common divisor of depth or time, \n    different algorithms to compute instantaneous amplitude, frequency and  \n    ratios of frequencies, and functions to verify and visualise the outputs.\n    The functions were developed during the CRASH project (Checking the \n    Reproducibility of Astrochronology in the Hauterivian). When using for \n    publication please cite Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, \n    A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X., 2022, \n    \"A decomposition approach to cyclostratigraphic signal processing\". \n    Earth-Science Reviews 225 (103894).\n    <doi:10.1016/j.earscirev.2021.103894>.  "
  },
  {
    "id": 2938,
    "package_name": "DemoDecomp",
    "title": "Decompose Demographic Functions",
    "description": "Three general demographic decomposition methods: Pseudo-continuous decomposition proposed by Horiuchi, Wilmoth, and Pletcher (2008) <doi:10.1353/dem.0.0033>, stepwise replacement decomposition proposed by Andreev, Shkolnikov and Begun (2002) <doi:10.4054/DemRes.2002.7.14>, and lifetable response experiments proposed by Caswell (1989) <doi:10.1016/0304-3800(89)90019-7>.",
    "version": "1.14.1",
    "maintainer": "Tim Riffe <tim.riffe@gmail.com>",
    "author": "Tim Riffe [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/timriffe/DemoDecomp/issues",
    "repository": "https://cran.r-project.org/package=DemoDecomp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DemoDecomp Decompose Demographic Functions Three general demographic decomposition methods: Pseudo-continuous decomposition proposed by Horiuchi, Wilmoth, and Pletcher (2008) <doi:10.1353/dem.0.0033>, stepwise replacement decomposition proposed by Andreev, Shkolnikov and Begun (2002) <doi:10.4054/DemRes.2002.7.14>, and lifetable response experiments proposed by Caswell (1989) <doi:10.1016/0304-3800(89)90019-7>.  "
  },
  {
    "id": 2940,
    "package_name": "DemographicTable",
    "title": "Create Demographic Table",
    "description": "To create demographic table with simple summary statistics,\n        with optional comparison(s) over one or more groups.",
    "version": "0.2.3",
    "maintainer": "Tingting Zhan <tingtingzhan@gmail.com>",
    "author": "Tingting Zhan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9971-4844>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DemographicTable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DemographicTable Create Demographic Table To create demographic table with simple summary statistics,\n        with optional comparison(s) over one or more groups.  "
  },
  {
    "id": 2977,
    "package_name": "Diderot",
    "title": "Bibliographic Network Analysis",
    "description": "Enables the user to build a citation network/graph from bibliographic data and, based on modularity and heterocitation metrics, assess the degree of awareness/cross-fertilization between two corpora/communities. This toolset is optimized for Scopus data. ",
    "version": "0.13",
    "maintainer": "Christian Vincenot <christian@vincenot.biz>",
    "author": "Christian Vincenot",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Diderot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Diderot Bibliographic Network Analysis Enables the user to build a citation network/graph from bibliographic data and, based on modularity and heterocitation metrics, assess the degree of awareness/cross-fertilization between two corpora/communities. This toolset is optimized for Scopus data.   "
  },
  {
    "id": 2979,
    "package_name": "DiffNet",
    "title": "Identifying Significant Node Scores using Network Diffusion\nAlgorithm",
    "description": "Designed for network analysis, leveraging the personalized PageRank algorithm to calculate node scores in a given graph. This innovative approach allows users to uncover the importance of nodes based on a customized perspective, making it particularly useful in fields like bioinformatics, social network analysis, and more.",
    "version": "1.0.2",
    "maintainer": "Farzaneh Firoozbakht <faren.firoozbakht@gmail.com>",
    "author": "Farzaneh Firoozbakht [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DiffNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DiffNet Identifying Significant Node Scores using Network Diffusion\nAlgorithm Designed for network analysis, leveraging the personalized PageRank algorithm to calculate node scores in a given graph. This innovative approach allows users to uncover the importance of nodes based on a customized perspective, making it particularly useful in fields like bioinformatics, social network analysis, and more.  "
  },
  {
    "id": 2986,
    "package_name": "DirectedClustering",
    "title": "Directed Weighted Clustering Coefficient",
    "description": "Allows the computation of clustering coefficients for directed and weighted networks by using different approaches. \n    It allows to compute clustering coefficients that are not present in 'igraph' package. \n    A description of clustering coefficients can be found in \"Directed clustering in weighted networks: a new perspective\", Clemente, G.P., Grassi, R. (2017),  \t\n    <doi:10.1016/j.chaos.2017.12.007>.",
    "version": "1.0.0",
    "maintainer": "Gian Paolo Clemente <gianpaolo.clemente@unicatt.it>",
    "author": "Gian Paolo Clemente [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-6795-4595>),\n  Rosanna Grassi [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DirectedClustering",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DirectedClustering Directed Weighted Clustering Coefficient Allows the computation of clustering coefficients for directed and weighted networks by using different approaches. \n    It allows to compute clustering coefficients that are not present in 'igraph' package. \n    A description of clustering coefficients can be found in \"Directed clustering in weighted networks: a new perspective\", Clemente, G.P., Grassi, R. (2017),  \t\n    <doi:10.1016/j.chaos.2017.12.007>.  "
  },
  {
    "id": 2998,
    "package_name": "DiscreteGapStatistic",
    "title": "An Extension of the Gap Statistic for Ordinal/Categorical Data",
    "description": "The gap statistic approach is extended to estimate the number of clusters for categorical response format data. This approach and accompanying software is designed to be used with the output of any clustering algorithm and with distances specifically designed for categorical (i.e. multiple choice) or ordinal survey response data.",
    "version": "1.1.2",
    "maintainer": "Eduardo Cortes <ecortesg@buffalo.edu>",
    "author": "Jeffrey Miecznikowski [aut],\n  Eduardo Cortes [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0966-6488>)",
    "url": "https://github.com/ecortesgomez/DiscreteGapStatistic",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DiscreteGapStatistic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DiscreteGapStatistic An Extension of the Gap Statistic for Ordinal/Categorical Data The gap statistic approach is extended to estimate the number of clusters for categorical response format data. This approach and accompanying software is designed to be used with the output of any clustering algorithm and with distances specifically designed for categorical (i.e. multiple choice) or ordinal survey response data.  "
  },
  {
    "id": 3006,
    "package_name": "Distance",
    "title": "Distance Sampling Detection Function and Abundance Estimation",
    "description": "A simple way of fitting detection functions to distance sampling\n    data for both line and point transects. Adjustment term selection, left and\n    right truncation as well as monotonicity constraints and binning are\n    supported. Abundance and density estimates can also be calculated (via a\n    Horvitz-Thompson-like estimator) if survey area information is provided. See\n    Miller et al. (2019) <doi:10.18637/jss.v089.i01> for more information on\n    methods and <https://distancesampling.org/resources/vignettes.html> for example analyses.",
    "version": "2.0.1",
    "maintainer": "Laura Marshall <lhm@st-andrews.ac.uk>",
    "author": "Laura Marshall [cre],\n  David Miller [aut],\n  T.J. Clark-Wolf [aut],\n  Len Thomas [ctb],\n  Jeff Laake [ctb],\n  Eric Rexstad [rev]",
    "url": "https://github.com/DistanceDevelopment/Distance/",
    "bug_reports": "https://github.com/DistanceDevelopment/Distance/issues",
    "repository": "https://cran.r-project.org/package=Distance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Distance Distance Sampling Detection Function and Abundance Estimation A simple way of fitting detection functions to distance sampling\n    data for both line and point transects. Adjustment term selection, left and\n    right truncation as well as monotonicity constraints and binning are\n    supported. Abundance and density estimates can also be calculated (via a\n    Horvitz-Thompson-like estimator) if survey area information is provided. See\n    Miller et al. (2019) <doi:10.18637/jss.v089.i01> for more information on\n    methods and <https://distancesampling.org/resources/vignettes.html> for example analyses.  "
  },
  {
    "id": 3033,
    "package_name": "DrDimont",
    "title": "Drug Response Prediction from Differential Multi-Omics Networks",
    "description": "While it has been well established that drugs affect and help\n  patients differently, personalized drug response predictions remain \n  challenging. Solutions based on single omics measurements have been proposed, \n  and networks provide means to incorporate molecular interactions into reasoning. \n  However, how to integrate the wealth of information contained in multiple omics \n  layers still poses a complex problem. \n  We present a novel network analysis pipeline, DrDimont, Drug response prediction \n  from Differential analysis of multi-omics networks. It allows for comparative \n  conclusions between two conditions and translates them into differential drug \n  response predictions. DrDimont focuses on molecular interactions. It establishes \n  condition-specific networks from correlation within an omics layer that are \n  then reduced and combined into heterogeneous, multi-omics molecular networks. \n  A novel semi-local, path-based integration step ensures integrative conclusions. \n  Differential predictions are derived from comparing the condition-specific \n  integrated networks. DrDimont's predictions are explainable, i.e., molecular \n  differences that are the source of high differential drug scores can be retrieved.\n  Our proposed pipeline leverages multi-omics data for differential predictions,\n  e.g. on drug response, and includes prior information on interactions.\n  The case study presented in the vignette uses data published by\n  Krug (2020) <doi:10.1016/j.cell.2020.10.036>. The package license applies only\n  to the software and explicitly not to the included data.",
    "version": "0.1.6",
    "maintainer": "Katharina Baum <katharina.baum@fu-berlin.de>",
    "author": "Katharina Baum [cre] (ORCID: <https://orcid.org/0000-0001-7256-0566>),\n  Pauline Hiort [aut] (ORCID: <https://orcid.org/0000-0002-3530-7358>),\n  Julian Hugo [aut] (ORCID: <https://orcid.org/0000-0003-3355-1071>),\n  Spoorthi Kashyap [aut] (ORCID: <https://orcid.org/0000-0002-5474-8183>),\n  Nataniel M\u00fcller [aut] (ORCID: <https://orcid.org/0000-0002-0275-3992>),\n  Justus Zeinert [aut] (ORCID: <https://orcid.org/0000-0003-3918-0507>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=DrDimont",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "DrDimont Drug Response Prediction from Differential Multi-Omics Networks While it has been well established that drugs affect and help\n  patients differently, personalized drug response predictions remain \n  challenging. Solutions based on single omics measurements have been proposed, \n  and networks provide means to incorporate molecular interactions into reasoning. \n  However, how to integrate the wealth of information contained in multiple omics \n  layers still poses a complex problem. \n  We present a novel network analysis pipeline, DrDimont, Drug response prediction \n  from Differential analysis of multi-omics networks. It allows for comparative \n  conclusions between two conditions and translates them into differential drug \n  response predictions. DrDimont focuses on molecular interactions. It establishes \n  condition-specific networks from correlation within an omics layer that are \n  then reduced and combined into heterogeneous, multi-omics molecular networks. \n  A novel semi-local, path-based integration step ensures integrative conclusions. \n  Differential predictions are derived from comparing the condition-specific \n  integrated networks. DrDimont's predictions are explainable, i.e., molecular \n  differences that are the source of high differential drug scores can be retrieved.\n  Our proposed pipeline leverages multi-omics data for differential predictions,\n  e.g. on drug response, and includes prior information on interactions.\n  The case study presented in the vignette uses data published by\n  Krug (2020) <doi:10.1016/j.cell.2020.10.036>. The package license applies only\n  to the software and explicitly not to the included data.  "
  },
  {
    "id": 3203,
    "package_name": "EdSurvey",
    "title": "Analysis of NCES Education Survey and Assessment Data",
    "description": "Read in and analyze functions for education survey and assessment data from the National Center for Education Statistics (NCES) <https://nces.ed.gov/>, including National Assessment of Educational Progress (NAEP) data <https://nces.ed.gov/nationsreportcard/> and data from the International Assessment Database: Organisation for Economic Co-operation and Development (OECD) <https://www.oecd.org/>, including Programme for International Student Assessment (PISA), Teaching and Learning International Survey (TALIS), Programme for the International Assessment of Adult Competencies (PIAAC), and International Association for the Evaluation of Educational Achievement (IEA) <https://www.iea.nl/>, including Trends in International Mathematics and Science Study (TIMSS), TIMSS Advanced, Progress in International Reading Literacy Study (PIRLS), International Civic and Citizenship Study (ICCS), International Computer and Information Literacy Study (ICILS), and Civic Education Study (CivEd).",
    "version": "4.0.7",
    "maintainer": "Paul Bailey <pbailey@air.org>",
    "author": "Paul Bailey [aut, cre] (ORCID: <https://orcid.org/0000-0003-0989-8729>),\n  Ahmad Emad [aut],\n  Huade Huo [aut] (ORCID: <https://orcid.org/0009-0004-5014-646X>),\n  Michael Lee [aut] (ORCID: <https://orcid.org/0009-0006-0959-787X>),\n  Yuqi Liao [aut] (ORCID: <https://orcid.org/0000-0001-9359-6015>),\n  Alex Lishinski [aut] (ORCID: <https://orcid.org/0000-0003-4506-1600>),\n  Trang Nguyen [aut] (ORCID: <https://orcid.org/0009-0001-0167-8775>),\n  Qingshu Xie [aut],\n  Jiao Yu [aut],\n  Ting Zhang [aut] (ORCID: <https://orcid.org/0009-0001-1724-6141>),\n  Eric Buehler [aut] (ORCID: <https://orcid.org/0009-0004-6354-2015>),\n  Sun-joo Lee [aut],\n  Blue Webb [aut] (ORCID: <https://orcid.org/0009-0004-4080-9864>),\n  Thomas Fink [aut] (ORCID: <https://orcid.org/0009-0003-9308-2833>),\n  Emmanuel Sikali [pdr],\n  Claire Kelley [ctb],\n  Jeppe Bundsgaard [ctb],\n  Ren C'deBaca [ctb],\n  Anders Astrup Christensen [ctb]",
    "url": "https://www.air.org/project/nces-data-r-project-edsurvey",
    "bug_reports": "https://github.com/American-Institutes-for-Research/EdSurvey/issues",
    "repository": "https://cran.r-project.org/package=EdSurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EdSurvey Analysis of NCES Education Survey and Assessment Data Read in and analyze functions for education survey and assessment data from the National Center for Education Statistics (NCES) <https://nces.ed.gov/>, including National Assessment of Educational Progress (NAEP) data <https://nces.ed.gov/nationsreportcard/> and data from the International Assessment Database: Organisation for Economic Co-operation and Development (OECD) <https://www.oecd.org/>, including Programme for International Student Assessment (PISA), Teaching and Learning International Survey (TALIS), Programme for the International Assessment of Adult Competencies (PIAAC), and International Association for the Evaluation of Educational Achievement (IEA) <https://www.iea.nl/>, including Trends in International Mathematics and Science Study (TIMSS), TIMSS Advanced, Progress in International Reading Literacy Study (PIRLS), International Civic and Citizenship Study (ICCS), International Computer and Information Literacy Study (ICILS), and Civic Education Study (CivEd).  "
  },
  {
    "id": 3209,
    "package_name": "EgoCor",
    "title": "Simple Presentation of Estimated Exponential Semi-Variograms",
    "description": "User friendly interface based on the R package 'gstat' to fit\n    exponential parametric models to empirical semi-variograms in order to\n    model the spatial correlation structure of health data. Geo-located\n    health outcomes of survey participants may be used to model spatial\n    effects on health in an ego-centred approach.  The package contains a\n    range of functions to help explore the spatial structure of the data\n    as well as visualize the fit of exponential models for various\n    metaparameter combinations with respect to the number of lag intervals\n    and maximal distance.  Furthermore, the outcome of interest can be\n    adjusted for covariates by fitting a linear regression in a\n    preliminary step before the semi-variogram fitting process.",
    "version": "1.3.4",
    "maintainer": "Julia Dyck <j.dyck@uni-bielefeld.de>",
    "author": "Julia Dyck [aut, cre],\n  Odile Sauzet [aut],\n  Jan-Ole Koslik [aut]",
    "url": "https://github.com/julia-dyck/EgoCor",
    "bug_reports": "https://github.com/julia-dyck/EgoCor/issues",
    "repository": "https://cran.r-project.org/package=EgoCor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "EgoCor Simple Presentation of Estimated Exponential Semi-Variograms User friendly interface based on the R package 'gstat' to fit\n    exponential parametric models to empirical semi-variograms in order to\n    model the spatial correlation structure of health data. Geo-located\n    health outcomes of survey participants may be used to model spatial\n    effects on health in an ego-centred approach.  The package contains a\n    range of functions to help explore the spatial structure of the data\n    as well as visualize the fit of exponential models for various\n    metaparameter combinations with respect to the number of lag intervals\n    and maximal distance.  Furthermore, the outcome of interest can be\n    adjusted for covariates by fitting a linear regression in a\n    preliminary step before the semi-variogram fitting process.  "
  },
  {
    "id": 3236,
    "package_name": "Epi",
    "title": "Statistical Analysis in Epidemiology",
    "description": "Functions for demographic and epidemiological analysis in\n  the Lexis diagram, i.e. register and cohort follow-up data. In\n  particular representation, manipulation, rate estimation and\n  simulation for multistate data - the Lexis suite of functions, which\n  includes interfaces to 'mstate', 'etm' and 'cmprsk' packages.\n  Contains functions for Age-Period-Cohort and Lee-Carter modeling and\n  a function for interval censored data. Has functions for extracting\n  and manipulating parameter estimates and predicted values (ci.lin\n  and its cousins), as well as a number of epidemiological data sets.",
    "version": "2.61",
    "maintainer": "Bendix Carstensen <b@bxc.dk>",
    "author": "Bendix Carstensen [aut, cre],\n  Martyn Plummer [aut],\n  Esa Laara [ctb],\n  Michael Hills [ctb]",
    "url": "http://bendixcarstensen.com/Epi/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Epi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Epi Statistical Analysis in Epidemiology Functions for demographic and epidemiological analysis in\n  the Lexis diagram, i.e. register and cohort follow-up data. In\n  particular representation, manipulation, rate estimation and\n  simulation for multistate data - the Lexis suite of functions, which\n  includes interfaces to 'mstate', 'etm' and 'cmprsk' packages.\n  Contains functions for Age-Period-Cohort and Lee-Carter modeling and\n  a function for interval censored data. Has functions for extracting\n  and manipulating parameter estimates and predicted values (ci.lin\n  and its cousins), as well as a number of epidemiological data sets.  "
  },
  {
    "id": 3405,
    "package_name": "FREEtree",
    "title": "Tree Method for High Dimensional Longitudinal Data",
    "description": "This tree-based method deals with high dimensional longitudinal \n\tdata with correlated features through the use of a piecewise random effect \n\tmodel. FREE tree also exploits the network structure of the features, by \n\tfirst clustering them using Weighted Gene Co-expression Network Analysis \n\t('WGCNA'). It then conducts a screening step within each cluster of features \n\tand a selecting step among the surviving features, which provides a relatively\n\tunbiased way to do feature selection. By using dominant principle components \n\tas regression variables at each leaf and the original features as splitting \n\tvariables at splitting nodes, FREE tree delivers easily interpretable results\n\twhile improving computational efficiency.",
    "version": "0.1.0",
    "maintainer": "Athanasse Zafirov <zafirov@gmail.com>",
    "author": "Yuancheng Xu [aut],\n  Athanasse Zafirov [cre],\n  Christina Ramirez [aut],\n  Dan Kojis [aut],\n  Min Tan [aut],\n  Mike Alvarez [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FREEtree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FREEtree Tree Method for High Dimensional Longitudinal Data This tree-based method deals with high dimensional longitudinal \n\tdata with correlated features through the use of a piecewise random effect \n\tmodel. FREE tree also exploits the network structure of the features, by \n\tfirst clustering them using Weighted Gene Co-expression Network Analysis \n\t('WGCNA'). It then conducts a screening step within each cluster of features \n\tand a selecting step among the surviving features, which provides a relatively\n\tunbiased way to do feature selection. By using dominant principle components \n\tas regression variables at each leaf and the original features as splitting \n\tvariables at splitting nodes, FREE tree delivers easily interpretable results\n\twhile improving computational efficiency.  "
  },
  {
    "id": 3468,
    "package_name": "FertNet",
    "title": "Process Data from the Social Networks and Fertility Survey",
    "description": "Processes data from The Social Networks and Fertility Survey,\n    downloaded from <https://dataarchive.lissdata.nl>, including correcting \n    respondent errors and transforming network data into network objects to\n    facilitate analyses and visualisation.",
    "version": "0.1.2",
    "maintainer": "Gert Stulp <g.stulp@rug.nl>",
    "author": "Gert Stulp [aut, cre] (ORCID: <https://orcid.org/0000-0003-0173-5554>)",
    "url": "https://github.com/gertstulp/FertNet",
    "bug_reports": "https://github.com/gertstulp/FertNet/issues",
    "repository": "https://cran.r-project.org/package=FertNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FertNet Process Data from the Social Networks and Fertility Survey Processes data from The Social Networks and Fertility Survey,\n    downloaded from <https://dataarchive.lissdata.nl>, including correcting \n    respondent errors and transforming network data into network objects to\n    facilitate analyses and visualisation.  "
  },
  {
    "id": 3478,
    "package_name": "FinNet",
    "title": "Quickly Build and Manipulate Financial Networks",
    "description": "Providing classes, methods, and functions to deal with financial networks. \n    Users can easily store information about both physical and legal persons by using pre-made classes that are studied for integration with scraping packages such as 'rvest' and 'RSelenium'.\n    Moreover, the package assists in creating various types of financial networks depending on the type of relation between its units depending on the relation under scrutiny (ownership, board interlocks, etc.), the desired tie type (valued or binary), and renders them in the most common formats (adjacency matrix, incidence matrix, edge list, 'igraph', 'network').\n    There are also ad-hoc functions for the Fiedler value, global network efficiency, and cascade-failure analysis.",
    "version": "0.2.1",
    "maintainer": "Fabio Ashtar Telarico <Fabio-Ashtar.Telarico@fdv.uni-lj.si>",
    "author": "Fabio Ashtar Telarico [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8740-7078>)",
    "url": "https://fatelarico.github.io/FinNet.html",
    "bug_reports": "https://github.com/FATelarico/FinNet/issues",
    "repository": "https://cran.r-project.org/package=FinNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FinNet Quickly Build and Manipulate Financial Networks Providing classes, methods, and functions to deal with financial networks. \n    Users can easily store information about both physical and legal persons by using pre-made classes that are studied for integration with scraping packages such as 'rvest' and 'RSelenium'.\n    Moreover, the package assists in creating various types of financial networks depending on the type of relation between its units depending on the relation under scrutiny (ownership, board interlocks, etc.), the desired tie type (valued or binary), and renders them in the most common formats (adjacency matrix, incidence matrix, edge list, 'igraph', 'network').\n    There are also ad-hoc functions for the Fiedler value, global network efficiency, and cascade-failure analysis.  "
  },
  {
    "id": 3503,
    "package_name": "FlowScreen",
    "title": "Daily Streamflow Trend and Change Point Screening",
    "description": "Screens daily streamflow time series for temporal trends and\n    change-points. This package has been primarily developed for assessing the\n    quality of daily streamflow time series. It also contains tools for plotting\n    and calculating many different streamflow metrics. The package can be used to\n    produce summary screening plots showing change-points and significant temporal\n    trends for high flow, low flow, and/or baseflow statistics, or it can be used\n    to perform more detailed hydrological time series analyses. The package was\n    designed for screening daily streamflow time series from Water Survey Canada\n    and the United States Geological Survey but will also work with streamflow time\n    series from many other agencies.  \n    Package update to version 2.0 made updates to read.flows function to allow \n    loading of GRDC and ROBIN streamflow record formats.\n    This package uses the `changepoint` package for change point detection.\n    For more information on change point methods, see the changepoint \n    package at <https://cran.r-project.org/package=changepoint>.",
    "version": "2.1",
    "maintainer": "Jennifer Dierauer <jen.r.brand@gmail.com>",
    "author": "Jennifer Dierauer [aut, cre],\n  Paul Whitfield [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=FlowScreen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "FlowScreen Daily Streamflow Trend and Change Point Screening Screens daily streamflow time series for temporal trends and\n    change-points. This package has been primarily developed for assessing the\n    quality of daily streamflow time series. It also contains tools for plotting\n    and calculating many different streamflow metrics. The package can be used to\n    produce summary screening plots showing change-points and significant temporal\n    trends for high flow, low flow, and/or baseflow statistics, or it can be used\n    to perform more detailed hydrological time series analyses. The package was\n    designed for screening daily streamflow time series from Water Survey Canada\n    and the United States Geological Survey but will also work with streamflow time\n    series from many other agencies.  \n    Package update to version 2.0 made updates to read.flows function to allow \n    loading of GRDC and ROBIN streamflow record formats.\n    This package uses the `changepoint` package for change point detection.\n    For more information on change point methods, see the changepoint \n    package at <https://cran.r-project.org/package=changepoint>.  "
  },
  {
    "id": 3510,
    "package_name": "ForCausality",
    "title": "A Curated Collection of 'Causal Inference' Datasets and Tools",
    "description": "Provides a comprehensive set of datasets and tools for 'causal inference' research. \n    The package includes data from clinical trials, cancer studies, epidemiological surveys, environmental exposures, and health-related observational studies.\n    Designed to facilitate causal analysis, risk assessment, and advanced statistical modeling, \n    it leverages datasets from packages such as 'causalOT', 'survival', 'causalPAF', 'evident', 'melt', and 'sanon'. \n    The package is inspired by the foundational work of Pearl (2009) <doi:10.1017/CBO9780511803161> on causal inference frameworks.",
    "version": "0.1.0",
    "maintainer": "Tom\u00e1s Valderrama <tomasvm2004@gmail.com>",
    "author": "Tom\u00e1s Valderrama [aut, cre]",
    "url": "https://github.com/Toby-codigos/ForCausality,\nhttps://toby-codigos.github.io/ForCausality/",
    "bug_reports": "https://github.com/Toby-codigos/ForCausality/issues",
    "repository": "https://cran.r-project.org/package=ForCausality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ForCausality A Curated Collection of 'Causal Inference' Datasets and Tools Provides a comprehensive set of datasets and tools for 'causal inference' research. \n    The package includes data from clinical trials, cancer studies, epidemiological surveys, environmental exposures, and health-related observational studies.\n    Designed to facilitate causal analysis, risk assessment, and advanced statistical modeling, \n    it leverages datasets from packages such as 'causalOT', 'survival', 'causalPAF', 'evident', 'melt', and 'sanon'. \n    The package is inspired by the foundational work of Pearl (2009) <doi:10.1017/CBO9780511803161> on causal inference frameworks.  "
  },
  {
    "id": 3537,
    "package_name": "Frames2",
    "title": "Estimation in Dual Frame Surveys",
    "description": "Point and interval estimation in dual frame surveys. In contrast\n    to classic sampling theory, where only one sampling frame is considered,\n    dual frame methodology assumes that there are two frames available for\n    sampling and that, overall, they cover the entire target population. Then,\n    two probability samples (one from each frame) are drawn and information\n    collected is suitably combined to get estimators of the parameter of\n    interest.",
    "version": "0.2.1",
    "maintainer": "David Molina <dmolinam@ugr.es>",
    "author": "Antonio Arcos <arcos@ugr.es>, Maria del Mar Rueda <mrueda@ugr.es>,\n    Maria Giovanna Ranalli <giovanna.ranalli@stat.unipg.it> and David Molina\n    <dmolinam@ugr.es>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Frames2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Frames2 Estimation in Dual Frame Surveys Point and interval estimation in dual frame surveys. In contrast\n    to classic sampling theory, where only one sampling frame is considered,\n    dual frame methodology assumes that there are two frames available for\n    sampling and that, overall, they cover the entire target population. Then,\n    two probability samples (one from each frame) are drawn and information\n    collected is suitably combined to get estimators of the parameter of\n    interest.  "
  },
  {
    "id": 3582,
    "package_name": "GAPR",
    "title": "Generalized Association Plots",
    "description": "Provides a comprehensive framework for visualizing associations and interaction structures in matrix-formatted data using Generalized Association Plots (GAP). The package implements multiple proximity computation methods (e.g., correlation, distance metrics), ordering techniques including hierarchical clustering (HCT) and Rank-2-Ellipse (R2E) seriation, and optional flipping strategies to enhance visual symmetry. It supports a variety of covariate-based color annotations, allows flexible customization of layout and output, and is suitable for analyzing multivariate data across domains such as social sciences, genomics, and medical research. The method is based on Generalized Association Plots introduced by Chen (2002) <https://www3.stat.sinica.edu.tw/statistica/J12N1/J12N11/J12N11.html> and further extended by Wu, Tien, and Chen (2010) <doi:10.1016/j.csda.2008.09.029>.",
    "version": "0.1.4",
    "maintainer": "Shu-Yu Lin <shuyuuu89@gmail.com>",
    "author": "Shu-Yu Lin [aut, cre],\n  Chiun-How Kao [aut, ctb],\n  Chun-Houh Chen [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GAPR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GAPR Generalized Association Plots Provides a comprehensive framework for visualizing associations and interaction structures in matrix-formatted data using Generalized Association Plots (GAP). The package implements multiple proximity computation methods (e.g., correlation, distance metrics), ordering techniques including hierarchical clustering (HCT) and Rank-2-Ellipse (R2E) seriation, and optional flipping strategies to enhance visual symmetry. It supports a variety of covariate-based color annotations, allows flexible customization of layout and output, and is suitable for analyzing multivariate data across domains such as social sciences, genomics, and medical research. The method is based on Generalized Association Plots introduced by Chen (2002) <https://www3.stat.sinica.edu.tw/statistica/J12N1/J12N11/J12N11.html> and further extended by Wu, Tien, and Chen (2010) <doi:10.1016/j.csda.2008.09.029>.  "
  },
  {
    "id": 3637,
    "package_name": "GFE",
    "title": "Gross Flows Estimation under Complex Surveys",
    "description": "The philosophy in the package is described in Stasny (1988) <doi:10.2307/1391558> and Gutierrez, A., Trujillo, L. & Silva, N. (2014), <ISSN:1492-0921> to estimate the gross flows under complex surveys using a Markov chain approach with non response.",
    "version": "0.1.1",
    "maintainer": "Acero William <wfaceror@unal.edu.co>",
    "author": "Acero William <wfaceror@unal.edu.co>, Gutierrez Andres <andres.gutierrez@un.org>, Trujillo Leonardo <ltrujillo@unal.edu.co>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GFE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GFE Gross Flows Estimation under Complex Surveys The philosophy in the package is described in Stasny (1988) <doi:10.2307/1391558> and Gutierrez, A., Trujillo, L. & Silva, N. (2014), <ISSN:1492-0921> to estimate the gross flows under complex surveys using a Markov chain approach with non response.  "
  },
  {
    "id": 3643,
    "package_name": "GGIR",
    "title": "Raw Accelerometer Data Analysis",
    "description": "A tool to process and analyse data collected with wearable raw acceleration sensors as described in Migueles and colleagues (JMPB 2019), and van Hees and colleagues (JApplPhysiol 2014; PLoSONE 2015). The package has been developed and tested for binary data from 'GENEActiv' <https://activinsights.com/>, binary (.gt3x) and .csv-export data from  'Actigraph' <https://theactigraph.com> devices, and binary (.cwa) and .csv-export data from 'Axivity' <https://axivity.com>. These devices are currently widely used in research on human daily physical activity. Further, the package can handle accelerometer data file from any other sensor brand providing that the data is stored in csv format. Also the package allows for external function embedding.",
    "version": "3.3-0",
    "maintainer": "Vincent T van Hees <v.vanhees@accelting.com>",
    "author": "Vincent T van Hees [aut, cre],\n  Jairo H Migueles [aut] (ORCID: <https://orcid.org/0000-0003-0366-6935>),\n  Severine Sabia [ctb],\n  Matthew R Patterson [ctb],\n  Zhou Fang [ctb],\n  Joe Heywood [ctb],\n  Joan Capdevila Pujol [ctb],\n  Lena Kushleyeva [ctb],\n  Mathilde Chen [ctb],\n  Manasa Yerramalla [ctb],\n  Patrick Bos [ctb] (ORCID: <https://orcid.org/0000-0002-6033-960X>),\n  Taren Sanders [ctb],\n  Chenxuan Zhao [ctb],\n  Ian Meneghel Danilevicz [ctb] (ORCID:\n    <https://orcid.org/0000-0003-4541-0524>),\n  Victor Barreto Mesquita [ctb],\n  Gaia Segantin [ctb],\n  Medical Research Council UK [cph, fnd],\n  Accelting [cph, fnd],\n  French National Research Agency [cph, fnd]",
    "url": "https://github.com/wadpac/GGIR/, https://wadpac.github.io/GGIR/",
    "bug_reports": "https://github.com/wadpac/GGIR/issues",
    "repository": "https://cran.r-project.org/package=GGIR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GGIR Raw Accelerometer Data Analysis A tool to process and analyse data collected with wearable raw acceleration sensors as described in Migueles and colleagues (JMPB 2019), and van Hees and colleagues (JApplPhysiol 2014; PLoSONE 2015). The package has been developed and tested for binary data from 'GENEActiv' <https://activinsights.com/>, binary (.gt3x) and .csv-export data from  'Actigraph' <https://theactigraph.com> devices, and binary (.cwa) and .csv-export data from 'Axivity' <https://axivity.com>. These devices are currently widely used in research on human daily physical activity. Further, the package can handle accelerometer data file from any other sensor brand providing that the data is stored in csv format. Also the package allows for external function embedding.  "
  },
  {
    "id": 3644,
    "package_name": "GGIRread",
    "title": "Wearable Accelerometer Data File Readers",
    "description": "Reads data collected from wearable acceleratometers as used in sleep and physical activity research. Currently supports file formats: binary data from 'GENEActiv' <https://activinsights.com/>, .bin-format from GENEA devices (not for sale), and .cwa-format from 'Axivity' <https://axivity.com>. Further, it has functions for reading text files with epoch level aggregates from 'Actical', 'Fitbit', 'Actiwatch', 'ActiGraph', and 'PhilipsHealthBand'. Primarily designed to complement R package GGIR <https://CRAN.R-project.org/package=GGIR>.",
    "version": "1.0.7",
    "maintainer": "Vincent T van Hees <v.vanhees@accelting.com>",
    "author": "Vincent T van Hees [aut, cre],\n  Patrick Bos [aut] (ORCID: <https://orcid.org/0000-0002-6033-960X>),\n  Lena Kushleyeva [ctb],\n  Jing Hua Zhao [ctb],\n  Evgeny Mirkes [ctb],\n  Dan Jackson [ctb],\n  Jairo H Migueles [ctb],\n  Medical Research Council UK [cph, fnd],\n  Accelting [cph, fnd]",
    "url": "https://github.com/wadpac/GGIRread/",
    "bug_reports": "https://github.com/wadpac/GGIRread/issues",
    "repository": "https://cran.r-project.org/package=GGIRread",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GGIRread Wearable Accelerometer Data File Readers Reads data collected from wearable acceleratometers as used in sleep and physical activity research. Currently supports file formats: binary data from 'GENEActiv' <https://activinsights.com/>, .bin-format from GENEA devices (not for sale), and .cwa-format from 'Axivity' <https://axivity.com>. Further, it has functions for reading text files with epoch level aggregates from 'Actical', 'Fitbit', 'Actiwatch', 'ActiGraph', and 'PhilipsHealthBand'. Primarily designed to complement R package GGIR <https://CRAN.R-project.org/package=GGIR>.  "
  },
  {
    "id": 3662,
    "package_name": "GISSB",
    "title": "Network Analysis on the Norwegian Road Network",
    "description": "A collection of GIS (Geographic Information System) functions in R, created for use in Statistics Norway. The functions are primarily related to network analysis on the Norwegian road network. ",
    "version": "1.1",
    "maintainer": "Sindre Mikael Haugen <sindre.haugen@ssb.no>",
    "author": "Sindre Mikael Haugen [aut, cre]",
    "url": "https://statisticsnorway.github.io/GISSB/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GISSB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GISSB Network Analysis on the Norwegian Road Network A collection of GIS (Geographic Information System) functions in R, created for use in Statistics Norway. The functions are primarily related to network analysis on the Norwegian road network.   "
  },
  {
    "id": 3713,
    "package_name": "GPRMortality",
    "title": "Gaussian Process Regression for Mortality Rates",
    "description": "A Bayesian statistical model for estimating child (under-five age group) and adult (15-60 age group) mortality.  The main challenge is how to combine and integrate these different time series and how to produce unified estimates of mortality rates during a specified time span. GPR is a Bayesian statistical model for estimating child and adult mortality rates which its data likelihood is mortality rates from different data sources such as: Death Registration System, Censuses or surveys. There are also various hyper-parameters for completeness of DRS, mean, covariance functions and variances as priors. This function produces estimations and uncertainty (95% or any desirable percentiles) based on sampling and non-sampling errors due to variation in data sources. The GP model utilizes Bayesian inference to update predicted mortality rates as a posterior in Bayes rule by combining data and a prior probability distribution over parameters in mean, covariance function, and the regression model. This package uses Markov Chain Monte Carlo (MCMC) to sample from posterior probability distribution by 'rstan' package in R. Details are given in Wang H, Dwyer-Lindgren L, Lofgren KT, et al. (2012) <doi:10.1016/S0140-6736(12)61719-X>, Wang H, Liddell CA, Coates MM, et al. (2014) <doi:10.1016/S0140-6736(14)60497-9> and Mohammadi, Parsaeian, Mehdipour et al. (2017) <doi:10.1016/S2214-109X(17)30105-5>.",
    "version": "0.1.0",
    "maintainer": "Ali Ghanbari <a.ghanbari541@gmail.com>",
    "author": "Parinaz Mehdipour <mehdipoor.p@gmail.com> [aut], Ali Ghanbari <a.ghanbari541@gmail.com> [cre,aut] , Iman Navidi <iman.navidi.1988@gmail.com> [aut], Farshad Farzadfar <farzadfar3@yahoo.com> [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GPRMortality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GPRMortality Gaussian Process Regression for Mortality Rates A Bayesian statistical model for estimating child (under-five age group) and adult (15-60 age group) mortality.  The main challenge is how to combine and integrate these different time series and how to produce unified estimates of mortality rates during a specified time span. GPR is a Bayesian statistical model for estimating child and adult mortality rates which its data likelihood is mortality rates from different data sources such as: Death Registration System, Censuses or surveys. There are also various hyper-parameters for completeness of DRS, mean, covariance functions and variances as priors. This function produces estimations and uncertainty (95% or any desirable percentiles) based on sampling and non-sampling errors due to variation in data sources. The GP model utilizes Bayesian inference to update predicted mortality rates as a posterior in Bayes rule by combining data and a prior probability distribution over parameters in mean, covariance function, and the regression model. This package uses Markov Chain Monte Carlo (MCMC) to sample from posterior probability distribution by 'rstan' package in R. Details are given in Wang H, Dwyer-Lindgren L, Lofgren KT, et al. (2012) <doi:10.1016/S0140-6736(12)61719-X>, Wang H, Liddell CA, Coates MM, et al. (2014) <doi:10.1016/S0140-6736(14)60497-9> and Mohammadi, Parsaeian, Mehdipour et al. (2017) <doi:10.1016/S2214-109X(17)30105-5>.  "
  },
  {
    "id": 3729,
    "package_name": "GRCRegression",
    "title": "Modified Poisson Regression of Grouped and Right-Censored Counts",
    "description": "Implement maximum likelihood estimation for Poisson generalized\n  linear models with grouped and right-censored count data. Intended to be used\n  for analyzing grouped and right-censored data, which is widely applied in\n  many branches of social sciences. The algorithm implemented is described\n  in Fu et al., (2021) <doi:10.1111/rssa.12678>.",
    "version": "1.0",
    "maintainer": "Xin Guo <xin.guo@uq.edu.au>",
    "author": "Xin Guo [aut, cph, cre],\n  Qiang Fu [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GRCRegression",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GRCRegression Modified Poisson Regression of Grouped and Right-Censored Counts Implement maximum likelihood estimation for Poisson generalized\n  linear models with grouped and right-censored count data. Intended to be used\n  for analyzing grouped and right-censored data, which is widely applied in\n  many branches of social sciences. The algorithm implemented is described\n  in Fu et al., (2021) <doi:10.1111/rssa.12678>.  "
  },
  {
    "id": 3730,
    "package_name": "GRCdata",
    "title": "Parameter Inference and Optimal Designs for Grouped and/or\nRight-Censored Count Data",
    "description": "We implement two main functions.\n    The first function uses a given grouped and/or\n    right-censored grouping scheme and empirical data to infer parameters,\n    and implements chi-square goodness-of-fit tests.\n    The second function searches for the global optimal grouping\n    scheme of grouped and/or right-censored count responses in surveys.",
    "version": "1.0",
    "maintainer": "Xin Guo <x.guo@polyu.edu.hk>",
    "author": "Xin Guo <x.guo@polyu.edu.hk>, Qiang Fu <qiang.fu@ubc.ca>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GRCdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GRCdata Parameter Inference and Optimal Designs for Grouped and/or\nRight-Censored Count Data We implement two main functions.\n    The first function uses a given grouped and/or\n    right-censored grouping scheme and empirical data to infer parameters,\n    and implements chi-square goodness-of-fit tests.\n    The second function searches for the global optimal grouping\n    scheme of grouped and/or right-censored count responses in surveys.  "
  },
  {
    "id": 3827,
    "package_name": "GeoAdjust",
    "title": "Accounting for Random Displacements of True GPS Coordinates of\nData",
    "description": "The purpose is to account for the random displacements \n (jittering) of true survey household cluster center coordinates in geostatistical \n analyses of Demographic and Health Surveys program (DHS) data. Adjustment for \n jittering can be implemented either in the spatial random effect, or in the \n raster/distance based covariates, or in both. Detailed information about the methods \n behind the package functionality can be found in our two papers.\n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2024) <doi:10.32614/RJ-2024-027>. \n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2023) <doi:10.1177/1471082X231219847>. ",
    "version": "2.0.1",
    "maintainer": "Umut Altay <altayumut.ua@gmail.com>",
    "author": "Umut Altay [cre, aut],\n  John Paige [aut],\n  Geir-Arne Fuglstad [aut],\n  Andrea Riebler [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=GeoAdjust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "GeoAdjust Accounting for Random Displacements of True GPS Coordinates of\nData The purpose is to account for the random displacements \n (jittering) of true survey household cluster center coordinates in geostatistical \n analyses of Demographic and Health Surveys program (DHS) data. Adjustment for \n jittering can be implemented either in the spatial random effect, or in the \n raster/distance based covariates, or in both. Detailed information about the methods \n behind the package functionality can be found in our two papers.\n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2024) <doi:10.32614/RJ-2024-027>. \n Umut Altay, John Paige, Andrea Riebler, Geir-Arne Fuglstad (2023) <doi:10.1177/1471082X231219847>.   "
  },
  {
    "id": 3957,
    "package_name": "HK80",
    "title": "Conversion Tools for HK80 Geographical Coordinate System",
    "description": "This is a collection of functions for converting coordinates between WGS84UTM, WGS84GEO, HK80UTM, HK80GEO and HK1980GRID Coordinate Systems used in Hong Kong SAR, based on the algorithms described in Explanatory Notes on Geodetic Datums in Hong Kong by Survey and Mapping Office Lands Department, Hong Kong Government (1995).",
    "version": "0.0.2",
    "maintainer": "Jinlong Zhang <jinlongzhang01@gmail.com>",
    "author": "Jinlong Zhang [aut, cre]",
    "url": "https://github.com/helixcn/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HK80",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HK80 Conversion Tools for HK80 Geographical Coordinate System This is a collection of functions for converting coordinates between WGS84UTM, WGS84GEO, HK80UTM, HK80GEO and HK1980GRID Coordinate Systems used in Hong Kong SAR, based on the algorithms described in Explanatory Notes on Geodetic Datums in Hong Kong by Survey and Mapping Office Lands Department, Hong Kong Government (1995).  "
  },
  {
    "id": 3964,
    "package_name": "HMDHFDplus",
    "title": "Read Human Mortality Database and Human Fertility Database Data\nfrom the Web",
    "description": "Utilities for reading data from the Human Mortality Database (<https://www.mortality.org>), Human Fertility Database (<https://www.humanfertility.org>), and similar databases from the web or locally into an R session as data.frame objects. These are the two most widely used sources of demographic data to study basic demographic change, trends, and develop new demographic methods. Other supported databases at this time include the Human Fertility Collection (<https://www.fertilitydata.org>), The Japanese Mortality Database (<https://www.ipss.go.jp/p-toukei/JMD/index-en.html>), and the Canadian Human Mortality Database (<http://www.bdlc.umontreal.ca/chmd/>). Arguments and data are standardized.",
    "version": "2.0.8",
    "maintainer": "Tim Riffe <tim.riffe@gmail.com>",
    "author": "Tim Riffe [aut, cre],\n  Carl Boe [aut],\n  Jason Hilton [aut],\n  Josh Goldstein [ctb],\n  Stephen Holzman [ctb],\n  Sam Hyun Yoo [ctb]",
    "url": "https://github.com/timriffe/HMDHFDplus",
    "bug_reports": "https://github.com/timriffe/HMDHFDplus/issues",
    "repository": "https://cran.r-project.org/package=HMDHFDplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HMDHFDplus Read Human Mortality Database and Human Fertility Database Data\nfrom the Web Utilities for reading data from the Human Mortality Database (<https://www.mortality.org>), Human Fertility Database (<https://www.humanfertility.org>), and similar databases from the web or locally into an R session as data.frame objects. These are the two most widely used sources of demographic data to study basic demographic change, trends, and develop new demographic methods. Other supported databases at this time include the Human Fertility Collection (<https://www.fertilitydata.org>), The Japanese Mortality Database (<https://www.ipss.go.jp/p-toukei/JMD/index-en.html>), and the Canadian Human Mortality Database (<http://www.bdlc.umontreal.ca/chmd/>). Arguments and data are standardized.  "
  },
  {
    "id": 3975,
    "package_name": "HOasso",
    "title": "Higher Order Assortativity for Complex Networks",
    "description": "Allows to evaluate Higher Order Assortativity of complex networks defined through objects of class 'igraph' from the package of the same name. The package returns a result also for directed and weighted graphs. References, Arcagni, A., Grassi, R., Stefani, S., & Torriero, A. (2017) <doi:10.1016/j.ejor.2017.04.028> Arcagni, A., Grassi, R., Stefani, S., & Torriero, A. (2021) <doi:10.1016/j.jbusres.2019.10.008> Arcagni, A., Cerqueti, R., & Grassi, R. (2023) <doi:10.48550/arXiv.2304.01737>.",
    "version": "1.0.1",
    "maintainer": "Alberto Arcagni <alberto.arcagni@uniroma1.it>",
    "author": "Alberto Arcagni [aut, cre],\n  Roy Cerqueti [aut],\n  Rosanna Grassi [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HOasso",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HOasso Higher Order Assortativity for Complex Networks Allows to evaluate Higher Order Assortativity of complex networks defined through objects of class 'igraph' from the package of the same name. The package returns a result also for directed and weighted graphs. References, Arcagni, A., Grassi, R., Stefani, S., & Torriero, A. (2017) <doi:10.1016/j.ejor.2017.04.028> Arcagni, A., Grassi, R., Stefani, S., & Torriero, A. (2021) <doi:10.1016/j.jbusres.2019.10.008> Arcagni, A., Cerqueti, R., & Grassi, R. (2023) <doi:10.48550/arXiv.2304.01737>.  "
  },
  {
    "id": 4027,
    "package_name": "HiCociety",
    "title": "Inferring Chromatin Interaction Modules from 3C-Based Data",
    "description": "Identifies chromatin interaction modules by constructing a Hi-C contact network based on statistically significant interactions, followed by network clustering. The method enables comparison of module connectivity across two Hi-C datasets and is capable of detecting cell-type-specific regulatory modules. By integrating network analysis with chromatin conformation data, this approach provides insights into the spatial organization of the genome and its functional implications in gene regulation. Author: Sora Yoon (2025) <https://github.com/ysora/HiCociety>.",
    "version": "0.1.38",
    "maintainer": "Sora Yoon <sora.yoon@pennmedicine.upenn.edu>",
    "author": "Sora Yoon [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=HiCociety",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "HiCociety Inferring Chromatin Interaction Modules from 3C-Based Data Identifies chromatin interaction modules by constructing a Hi-C contact network based on statistically significant interactions, followed by network clustering. The method enables comparison of module connectivity across two Hi-C datasets and is capable of detecting cell-type-specific regulatory modules. By integrating network analysis with chromatin conformation data, this approach provides insights into the spatial organization of the genome and its functional implications in gene regulation. Author: Sora Yoon (2025) <https://github.com/ysora/HiCociety>.  "
  },
  {
    "id": 4133,
    "package_name": "IFTPredictor",
    "title": "Predictions Using Item-Focused Tree Models",
    "description": "This function predicts item response probabilities and item \n  responses using the item-focused tree model. The item-focused tree model\n  combines logistic regression with recursive partitioning to detect \n  Differential Item Functioning in dichotomous items. The model applies \n  partitioning rules to the data, splitting it into homogeneous subgroups, and \n  uses logistic regression within each subgroup to explain the data. \n  Differential Item Functioning detection is achieved by examining potential \n  group differences in item response patterns. This method is useful for \n  understanding how different predictors, such as demographic or psychological \n  factors, influence item responses across subgroups.",
    "version": "0.1.0",
    "maintainer": "Muditha L. Bodawatte Gedara <muditha.lakmali.1993@gmail.com>",
    "author": "Muditha L. Bodawatte Gedara [aut, cre],\n  Barret A. Monchka [aut],\n  Lisa M. Lix [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IFTPredictor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IFTPredictor Predictions Using Item-Focused Tree Models This function predicts item response probabilities and item \n  responses using the item-focused tree model. The item-focused tree model\n  combines logistic regression with recursive partitioning to detect \n  Differential Item Functioning in dichotomous items. The model applies \n  partitioning rules to the data, splitting it into homogeneous subgroups, and \n  uses logistic regression within each subgroup to explain the data. \n  Differential Item Functioning detection is achieved by examining potential \n  group differences in item response patterns. This method is useful for \n  understanding how different predictors, such as demographic or psychological \n  factors, influence item responses across subgroups.  "
  },
  {
    "id": 4170,
    "package_name": "IPEDS",
    "title": "Data from the Integrated Post-Secondary Education Data System",
    "description": "Contains data on Post-Secondary Institution Statistics in 2020 <https://nces.ed.gov/ipeds/use-the-data>. The package allows easy access to a wide variety of information regarding Post-secondary Institutions, its students, faculty, and their demographics, financial aid, educational and recreational offerings, and completions. This package can be used by students, college counselors, or involved parents interested in pursuing higher education, considering their options, and securing admission into their school of choice.",
    "version": "0.1.0",
    "maintainer": "Aushanae Haller <aushanaenhaller@gmail.com>",
    "author": "Aushanae Haller [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2090-1952>),\n  Alejandra Munoz [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IPEDS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IPEDS Data from the Integrated Post-Secondary Education Data System Contains data on Post-Secondary Institution Statistics in 2020 <https://nces.ed.gov/ipeds/use-the-data>. The package allows easy access to a wide variety of information regarding Post-secondary Institutions, its students, faculty, and their demographics, financial aid, educational and recreational offerings, and completions. This package can be used by students, college counselors, or involved parents interested in pursuing higher education, considering their options, and securing admission into their school of choice.  "
  },
  {
    "id": 4171,
    "package_name": "IPEDSuploadables",
    "title": "Transforms Institutional Data into Text Files for IPEDS\nAutomated Import/Upload",
    "description": "Starting from user-supplied institutional data, these scripts \n    transform, aggregate, and reshape the information to produce \n    key-value pair data files that are able to be uploaded to IPEDS (Integrated Postsecondary Education Data System) \n    through their submission portal <https://surveys.nces.ed.gov/ipeds/>. Starting data specifications can be found in the vignettes.  \n    Final files are saved locally to a location of the user's choice. \n    User-friendly readable files can also be produced for purposes of data review and validation. ",
    "version": "3.0.0",
    "maintainer": "Alison Lanski <alanski@nd.edu>",
    "author": "Alison Lanski [aut, cre],\n  Shiloh Fling [aut],\n  Edwin Welch [aut]",
    "url": "https://github.com/AlisonLanski/IPEDSuploadables,\nhttps://alisonlanski.github.io/IPEDSuploadables/",
    "bug_reports": "https://github.com/AlisonLanski/IPEDSuploadables/issues",
    "repository": "https://cran.r-project.org/package=IPEDSuploadables",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IPEDSuploadables Transforms Institutional Data into Text Files for IPEDS\nAutomated Import/Upload Starting from user-supplied institutional data, these scripts \n    transform, aggregate, and reshape the information to produce \n    key-value pair data files that are able to be uploaded to IPEDS (Integrated Postsecondary Education Data System) \n    through their submission portal <https://surveys.nces.ed.gov/ipeds/>. Starting data specifications can be found in the vignettes.  \n    Final files are saved locally to a location of the user's choice. \n    User-friendly readable files can also be produced for purposes of data review and validation.   "
  },
  {
    "id": 4204,
    "package_name": "ISRaD",
    "title": "Tools and Data for the International Soil Radiocarbon Database",
    "description": "This is the central location for data and tools for the development,\n    maintenance, analysis, and deployment of the International Soil Radiocarbon Database\n    (ISRaD). ISRaD was developed as a collaboration between the U.S. Geological Survey\n    Powell Center and the Max Planck Institute for Biogeochemistry. This R package provides\n    tools for accessing and manipulating ISRaD data, compiling local data using the ISRaD\n    data structure, and simple query and reporting functions for ISRaD. For more detailed\n    information visit the ISRaD website at: <https://soilradiocarbon.org/>.",
    "version": "2.5.5",
    "maintainer": "Jeffrey Beem-Miller <jbeem@bgc-jena.mpg.de>",
    "author": "Alison Hoyt [aut],\n  Jeffrey Beem-Miller [aut, cre],\n  Shane Stoner [aut],\n  J. Grey Monroe [aut],\n  Caitlin Hicks-Pries [aut],\n  Paul A. Levine [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ISRaD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ISRaD Tools and Data for the International Soil Radiocarbon Database This is the central location for data and tools for the development,\n    maintenance, analysis, and deployment of the International Soil Radiocarbon Database\n    (ISRaD). ISRaD was developed as a collaboration between the U.S. Geological Survey\n    Powell Center and the Max Planck Institute for Biogeochemistry. This R package provides\n    tools for accessing and manipulating ISRaD data, compiling local data using the ISRaD\n    data structure, and simple query and reporting functions for ISRaD. For more detailed\n    information visit the ISRaD website at: <https://soilradiocarbon.org/>.  "
  },
  {
    "id": 4214,
    "package_name": "ImCluster",
    "title": "Efficiency of Cluster Sampling for Crop Surveys",
    "description": "Cluster sampling is a valuable approach when constructing a comprehensive list of individual units is challenging. It provides operational and cost advantages. This package is designed to test the efficiency of cluster sampling in terms cluster variance and design effect in context to crop surveys. This package has been developed using the algorithm of Iqbal et al. (2018) <doi:10.19080/BBOAJ.2018.05.555673>.",
    "version": "0.1.0",
    "maintainer": "M. Iqbal Jeelani <jeelani.miqbal@gmail.com>",
    "author": "M. Iqbal Jeelani [aut, cre],\n  Fehim Jeelani [aut],\n  Shakeel Ahmad Mir [aut],\n  Showkat Maqbool [aut],\n  Syed Naseem Geelani [aut],\n  Mushtaq Ahmad Lone [aut],\n  Md Yeasin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ImCluster",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ImCluster Efficiency of Cluster Sampling for Crop Surveys Cluster sampling is a valuable approach when constructing a comprehensive list of individual units is challenging. It provides operational and cost advantages. This package is designed to test the efficiency of cluster sampling in terms cluster variance and design effect in context to crop surveys. This package has been developed using the algorithm of Iqbal et al. (2018) <doi:10.19080/BBOAJ.2018.05.555673>.  "
  },
  {
    "id": 4237,
    "package_name": "IndexNumber",
    "title": "Index Numbers in Social Sciences",
    "description": "We provide an R tool for teaching in Social Sciences. It allows the computation of index numbers. It is a measure of the evolution of a fixed magnitude for only a product of for several products. It is very useful in Social Sciences. Among others, we obtain simple index numbers (in chain or in serie), index numbers for not only a product or weighted index numbers as the Laspeyres index (Laspeyres, 1864), the Paasche index (Paasche, 1874) or the Fisher index (Lapedes, 1978).",
    "version": "1.3.2",
    "maintainer": "Alejandro Saavedra-Nieves <alejandro.saavedra.nieves@gmail.com>",
    "author": "Alejandro Saavedra-Nieves, Paula Saavedra-Nieves",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=IndexNumber",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IndexNumber Index Numbers in Social Sciences We provide an R tool for teaching in Social Sciences. It allows the computation of index numbers. It is a measure of the evolution of a fixed magnitude for only a product of for several products. It is very useful in Social Sciences. Among others, we obtain simple index numbers (in chain or in serie), index numbers for not only a product or weighted index numbers as the Laspeyres index (Laspeyres, 1864), the Paasche index (Paasche, 1874) or the Fisher index (Lapedes, 1978).  "
  },
  {
    "id": 4240,
    "package_name": "IndiAPIs",
    "title": "Access Indian Data via Public APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including \n    'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to India, such as economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on India, covering topics such as population, economy, weather, politics, health, biodiversity, sports, agriculture, cybercrime, infrastructure, and more. The package supports reproducible research and teaching by integrating \n    reliable international APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/indiapis,\nhttps://lightbluetitan.github.io/indiapis/",
    "bug_reports": "https://github.com/lightbluetitan/indiapis/issues",
    "repository": "https://cran.r-project.org/package=IndiAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IndiAPIs Access Indian Data via Public APIs and Curated Datasets Provides functions to access data from public RESTful APIs including \n    'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to India, such as economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on India, covering topics such as population, economy, weather, politics, health, biodiversity, sports, agriculture, cybercrime, infrastructure, and more. The package supports reproducible research and teaching by integrating \n    reliable international APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 4242,
    "package_name": "IndonesiAPIs",
    "title": "Access Indonesian Data via Public APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Indonesia, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. The package also includes a curated collection of \n    open datasets focused on Indonesia, covering topics such as consumer prices, poverty \n    probability, food prices by region, tourism destinations, and minimum wage statistics. \n    The package supports reproducible research and teaching by integrating reliable \n    international APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.1",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/indonesiapis,\nhttps://lightbluetitan.github.io/indonesiapis/,\nhttps://doi.org/10.5281/zenodo.17731434",
    "bug_reports": "https://github.com/lightbluetitan/indonesiapis/issues",
    "repository": "https://cran.r-project.org/package=IndonesiAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "IndonesiAPIs Access Indonesian Data via Public APIs and Curated Datasets Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Indonesia, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. The package also includes a curated collection of \n    open datasets focused on Indonesia, covering topics such as consumer prices, poverty \n    probability, food prices by region, tourism destinations, and minimum wage statistics. \n    The package supports reproducible research and teaching by integrating reliable \n    international APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 4326,
    "package_name": "JapanAPIs",
    "title": "Access Japanese Data via Public APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Japan, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on Japan, covering topics such as natural disasters, \n    economic production, vehicle industry, air quality, demographics, and administrative divisions. \n    The package supports reproducible research and teaching by integrating reliable international \n    APIs and structured datasets from public, academic, and government sources.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.1",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/japanapis,\nhttps://lightbluetitan.github.io/japanapis/",
    "bug_reports": "https://github.com/lightbluetitan/japanapis/issues",
    "repository": "https://cran.r-project.org/package=JapanAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "JapanAPIs Access Japanese Data via Public APIs and Curated Datasets Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Japan, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes one of the largest \n    curated collections of open datasets focused on Japan, covering topics such as natural disasters, \n    economic production, vehicle industry, air quality, demographics, and administrative divisions. \n    The package supports reproducible research and teaching by integrating reliable international \n    APIs and structured datasets from public, academic, and government sources.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 4350,
    "package_name": "KHQ",
    "title": "Methods for Calculating 'KHQ' Scores and 'KHQ5D' Utility Index\nScores",
    "description": "The King's Health Questionnaire (KHQ) is a disease-specific, \n  self-administered questionnaire designed specific to assess the impact of \n  Urinary Incontinence (UI) on Quality of Life. The questionnaire was developed \n  by Kelleher and collaborators (1997) <doi:10.1111/j.1471-0528.1997.tb11006.x>. \n  It is a simple, acceptable and reliable measure to use in the clinical setting \n  and a research tool that is useful in evaluating UI treatment outcomes. \n  The KHQ five dimensions (KHQ5D) is a condition-specific preference-based \n  measure developed by Brazier and collaborators (2008) <doi:10.1177/0272989X07301820>. \n  Although not as popular as the SF6D <doi:10.1016/S0895-4356(98)00103-6> and \n  EQ-5D <https://euroqol.org/>, the KHQ5D measures health-related quality of \n  life (HRQoL) specifically for UI, not general conditions like the others \n  two instruments mentioned. The KHQ5D ca be used in the clinical and economic \n  evaluation of health care. The subject self-rates their health in terms of \n  five dimensions: Role Limitation (RL), Physical Limitations (PL), Social \n  Limitations (SL), Emotions (E), and Sleep (S). Frequently the states on these \n  five dimensions are converted to a single utility index using country specific \n  value sets, which can be used in the clinical and economic evaluation of \n  health care as well as in population health surveys. This package provides \n  methods to calculate scores for each dimension of the KHQ; converts KHQ item \n  scores to KHQ5D scores; and also calculates the utility index of the KHQ5D.",
    "version": "0.2.0",
    "maintainer": "Luiz Augusto Brusaca <augustobrusaca@gmail.com>",
    "author": "Luiz Augusto Brusaca [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8201-6433>)",
    "url": "https://github.com/augustobrusaca/KHQ",
    "bug_reports": "https://github.com/augustobrusaca/KHQ/issues",
    "repository": "https://cran.r-project.org/package=KHQ",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KHQ Methods for Calculating 'KHQ' Scores and 'KHQ5D' Utility Index\nScores The King's Health Questionnaire (KHQ) is a disease-specific, \n  self-administered questionnaire designed specific to assess the impact of \n  Urinary Incontinence (UI) on Quality of Life. The questionnaire was developed \n  by Kelleher and collaborators (1997) <doi:10.1111/j.1471-0528.1997.tb11006.x>. \n  It is a simple, acceptable and reliable measure to use in the clinical setting \n  and a research tool that is useful in evaluating UI treatment outcomes. \n  The KHQ five dimensions (KHQ5D) is a condition-specific preference-based \n  measure developed by Brazier and collaborators (2008) <doi:10.1177/0272989X07301820>. \n  Although not as popular as the SF6D <doi:10.1016/S0895-4356(98)00103-6> and \n  EQ-5D <https://euroqol.org/>, the KHQ5D measures health-related quality of \n  life (HRQoL) specifically for UI, not general conditions like the others \n  two instruments mentioned. The KHQ5D ca be used in the clinical and economic \n  evaluation of health care. The subject self-rates their health in terms of \n  five dimensions: Role Limitation (RL), Physical Limitations (PL), Social \n  Limitations (SL), Emotions (E), and Sleep (S). Frequently the states on these \n  five dimensions are converted to a single utility index using country specific \n  value sets, which can be used in the clinical and economic evaluation of \n  health care as well as in population health surveys. This package provides \n  methods to calculate scores for each dimension of the KHQ; converts KHQ item \n  scores to KHQ5D scores; and also calculates the utility index of the KHQ5D.  "
  },
  {
    "id": 4403,
    "package_name": "KnowBR",
    "title": "Discriminating Well Surveyed Spatial Units from Exhaustive\nBiodiversity Databases",
    "description": "It uses species accumulation curves and diverse estimators to assess, at the same time, the levels of survey coverage in multiple geographic cells of a size defined by the user or polygons. It also enables the geographical depiction of observed species richness, survey effort and completeness values including a background with administrative areas.",
    "version": "2.2",
    "maintainer": "Castor Guisande Gonzalez <castor@uvigo.es>",
    "author": "Castor Guisande Gonzalez and Jorge M. Lobo",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=KnowBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "KnowBR Discriminating Well Surveyed Spatial Units from Exhaustive\nBiodiversity Databases It uses species accumulation curves and diverse estimators to assess, at the same time, the levels of survey coverage in multiple geographic cells of a size defined by the user or polygons. It also enables the geographical depiction of observed species richness, survey effort and completeness values including a background with administrative areas.  "
  },
  {
    "id": 4413,
    "package_name": "L1centrality",
    "title": "Graph/Network Analysis Based on L1 Centrality",
    "description": "Analyze graph/network data using L1 centrality and prestige. Functions for deriving global, local, and group L1 centrality/prestige are provided. Routines for visual inspection of a graph/network are also provided. Details are in Kang and Oh (2025a) <doi:10.1080/01621459.2025.2520467>, Kang and Oh (2025b) <doi:10.1080/00031305.2025.2563730>, and Kang (2025) <doi:10.23170/snu.000000188358.11032.0001856>.",
    "version": "0.4.0",
    "maintainer": "Seungwoo Kang <kangsw0401@snu.ac.kr>",
    "author": "Seungwoo Kang [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8082-0794>),\n  Hee-Seok Oh [aut]",
    "url": "https://github.com/seungwoo-stat/L1centrality",
    "bug_reports": "https://github.com/seungwoo-stat/L1centrality/issues",
    "repository": "https://cran.r-project.org/package=L1centrality",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "L1centrality Graph/Network Analysis Based on L1 Centrality Analyze graph/network data using L1 centrality and prestige. Functions for deriving global, local, and group L1 centrality/prestige are provided. Routines for visual inspection of a graph/network are also provided. Details are in Kang and Oh (2025a) <doi:10.1080/01621459.2025.2520467>, Kang and Oh (2025b) <doi:10.1080/00031305.2025.2563730>, and Kang (2025) <doi:10.23170/snu.000000188358.11032.0001856>.  "
  },
  {
    "id": 4468,
    "package_name": "LLMTranslate",
    "title": "'shiny' App for TRAPD/ISPOR Survey Translation with LLMs",
    "description": "A 'shiny' application to automate forward and back survey translation\n    with optional reconciliation using large language models (LLMs). Supports\n    OpenAI (GPT), Google Gemini, and Anthropic Claude models. It follows\n    the TRAPD (Translation, Review, Adjudication, Pretesting, Documentation)\n    framework and ISPOR (International Society for Pharmacoeconomics and\n    Outcomes Research) recommendations. See Harkness et al. (2010)\n    <doi:10.1002/9780470609927.ch7> and Wild et al. (2005)\n    <doi:10.1111/j.1524-4733.2005.04054.x>.",
    "version": "0.2.0",
    "maintainer": "Jonas R. Kunst <jonas.r.kunst@bi.no>",
    "author": "Jonas R. Kunst [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LLMTranslate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LLMTranslate 'shiny' App for TRAPD/ISPOR Survey Translation with LLMs A 'shiny' application to automate forward and back survey translation\n    with optional reconciliation using large language models (LLMs). Supports\n    OpenAI (GPT), Google Gemini, and Anthropic Claude models. It follows\n    the TRAPD (Translation, Review, Adjudication, Pretesting, Documentation)\n    framework and ISPOR (International Society for Pharmacoeconomics and\n    Outcomes Research) recommendations. See Harkness et al. (2010)\n    <doi:10.1002/9780470609927.ch7> and Wild et al. (2005)\n    <doi:10.1111/j.1524-4733.2005.04054.x>.  "
  },
  {
    "id": 4553,
    "package_name": "Latamverse",
    "title": "Latin American Data via 'RESTful' APIs and Curated Datasets",
    "description": "Brings together a comprehensive collection \n    of R packages providing access to API functions and curated datasets from Argentina, Brazil, \n    Chile, Colombia, and Peru. Includes real-time and historical data through public \n    'RESTful' APIs ('Nager.Date', World Bank API, REST Countries API, and country-specific APIs) and \n    extensive curated collections of open datasets covering economics, demographics, public health, \n    environmental data, political indicators, social metrics, and cultural information. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to Latin American data sources, facilitating \n    reproducible research, comparative analysis, and teaching applications focused \n    on these five major Latin American countries.\n    Included packages:\n    - 'ArgentinAPI': API functions and curated datasets for Argentina covering exchange rates, inflation, political figures, national holidays and more.\n    - 'BrazilDataAPI': API functions and curated datasets for Brazil covering postal codes, banks, economic indicators, holidays, company registrations and more.\n    - 'ChileDataAPI': API functions and curated datasets for Chile covering financial indicators ('UF', UTM, Dollar, Euro, Yen, Copper, Bitcoin, 'IPSA' index), holidays and more.\n    - 'ColombiAPI': API functions and curated datasets for Colombia covering geographic locations, cultural attractions, economic indicators, demographic data, national holidays and more.\n    - 'PeruAPIs': API functions and curated datasets for Peru covering economic indicators, demographics, national holidays, administrative divisions, electoral data, biodiversity and more.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    World Bank API <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    REST Countries API <https://restcountries.com/>,\n    'ArgentinaDatos' API <https://argentinadatos.com/>,\n    'BrasilAPI' <https://brasilapi.com.br/>,\n    'FINDIC' <https://findic.cl/>,\n    and API-Colombia <https://api-colombia.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/latamverse,\nhttps://lightbluetitan.github.io/latamverse/",
    "bug_reports": "https://github.com/lightbluetitan/latamverse/issues",
    "repository": "https://cran.r-project.org/package=Latamverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Latamverse Latin American Data via 'RESTful' APIs and Curated Datasets Brings together a comprehensive collection \n    of R packages providing access to API functions and curated datasets from Argentina, Brazil, \n    Chile, Colombia, and Peru. Includes real-time and historical data through public \n    'RESTful' APIs ('Nager.Date', World Bank API, REST Countries API, and country-specific APIs) and \n    extensive curated collections of open datasets covering economics, demographics, public health, \n    environmental data, political indicators, social metrics, and cultural information. \n    Designed to provide researchers, analysts, educators, and data scientists with \n    centralized access to Latin American data sources, facilitating \n    reproducible research, comparative analysis, and teaching applications focused \n    on these five major Latin American countries.\n    Included packages:\n    - 'ArgentinAPI': API functions and curated datasets for Argentina covering exchange rates, inflation, political figures, national holidays and more.\n    - 'BrazilDataAPI': API functions and curated datasets for Brazil covering postal codes, banks, economic indicators, holidays, company registrations and more.\n    - 'ChileDataAPI': API functions and curated datasets for Chile covering financial indicators ('UF', UTM, Dollar, Euro, Yen, Copper, Bitcoin, 'IPSA' index), holidays and more.\n    - 'ColombiAPI': API functions and curated datasets for Colombia covering geographic locations, cultural attractions, economic indicators, demographic data, national holidays and more.\n    - 'PeruAPIs': API functions and curated datasets for Peru covering economic indicators, demographics, national holidays, administrative divisions, electoral data, biodiversity and more.\n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    World Bank API <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    REST Countries API <https://restcountries.com/>,\n    'ArgentinaDatos' API <https://argentinadatos.com/>,\n    'BrasilAPI' <https://brasilapi.com.br/>,\n    'FINDIC' <https://findic.cl/>,\n    and API-Colombia <https://api-colombia.com/>.  "
  },
  {
    "id": 4574,
    "package_name": "LexisPlotR",
    "title": "Plot Lexis Diagrams for Demographic Purposes",
    "description": "Plots empty Lexis grids, adds lifelines and highlights certain areas of the grid, like cohorts and age groups.",
    "version": "0.4.0",
    "maintainer": "Philipp Ottolinger <philipp@ottolinger.de>",
    "author": "Philipp Ottolinger [cre, aut],\n  Marieke Smilde-Becker [ctb]",
    "url": "https://github.com/ottlngr/LexisPlotR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LexisPlotR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LexisPlotR Plot Lexis Diagrams for Demographic Purposes Plots empty Lexis grids, adds lifelines and highlights certain areas of the grid, like cohorts and age groups.  "
  },
  {
    "id": 4581,
    "package_name": "Lifertable",
    "title": "Life and Fertility Tables Specially for Insects",
    "description": "Life and Fertility Tables are appropriate to study the dynamics of \n    arthropods populations. This package provides utilities for constructing\n    Life Tables and Fertility Tables, related demographic parameters, and some\n    simple graphs of interest. It also offers functions to transform the\n    obtained data into a known format for better manipulation. In addition,\n    two methods for obtaining the confidence interval are included.",
    "version": "1.0.1",
    "maintainer": "Carlos Abimael Sarmiento Sanchez <cass9918@hotmail.com>",
    "author": "Carlos Abimael Sarmiento Sanchez [aut, cre],\n  Lauro Soto Rojas [ctb],\n  Alejandro Corona Ambriz [ctb],\n  Gabriel Arcangel Rodriguez Yam [ctb],\n  Yolanda Franco Islas [ctb],\n  Noe Ramirez Negrete [ctb],\n  Adriana Acevedo Alcala [ctb],\n  Esteban Rodriguez Leyva [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Lifertable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Lifertable Life and Fertility Tables Specially for Insects Life and Fertility Tables are appropriate to study the dynamics of \n    arthropods populations. This package provides utilities for constructing\n    Life Tables and Fertility Tables, related demographic parameters, and some\n    simple graphs of interest. It also offers functions to transform the\n    obtained data into a known format for better manipulation. In addition,\n    two methods for obtaining the confidence interval are included.  "
  },
  {
    "id": 4585,
    "package_name": "LikertEZ",
    "title": "Easy Analysis and Visualization of Likert Scale Data",
    "description": "Provides functions for summarizing, visualizing, and analyzing \n    Likert-scale survey data. Includes support for computing descriptive statistics, \n    Relative Importance Index (RII), reliability analysis (Cronbach's Alpha), \n    and response distribution plots.",
    "version": "0.1.0",
    "maintainer": "Mohammad Mollazehi <mmolazehi@lu.edu.qa>",
    "author": "Mohammad Mollazehi [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LikertEZ",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LikertEZ Easy Analysis and Visualization of Likert Scale Data Provides functions for summarizing, visualizing, and analyzing \n    Likert-scale survey data. Includes support for computing descriptive statistics, \n    Relative Importance Index (RII), reliability analysis (Cronbach's Alpha), \n    and response distribution plots.  "
  },
  {
    "id": 4624,
    "package_name": "LoopDetectR",
    "title": "Comprehensive Feedback Loop Detection in ODE Models",
    "description": "Detect feedback loops (cycles, circuits) between species (nodes) in ordinary differential equation (ODE) models. Feedback loops are paths from a node to itself without visiting any other node twice, and they have important regulatory functions. Loops are reported with their order of participating nodes and their length, and whether the loop is a positive or a negative feedback loop. An upper limit of the number of feedback loops limits runtime (which scales with feedback loop count). Model parametrizations and values of the modelled variables are accounted for. Computation uses the characteristics of the Jacobian matrix as described e.g. in Thomas and Kaufman (2002) <doi:10.1016/s1631-0691(02)01452-x>. Input can be the Jacobian matrix of the ODE model or the ODE function definition; in the latter case, the Jacobian matrix is determined using 'numDeriv'. Graph-based algorithms from 'igraph' are employed for path detection. ",
    "version": "0.1.2",
    "maintainer": "Katharina Baum <katharina.baum@hpi.de>",
    "author": "Katharina Baum [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7256-0566>),\n  Sandra Kr\u00fcger [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=LoopDetectR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "LoopDetectR Comprehensive Feedback Loop Detection in ODE Models Detect feedback loops (cycles, circuits) between species (nodes) in ordinary differential equation (ODE) models. Feedback loops are paths from a node to itself without visiting any other node twice, and they have important regulatory functions. Loops are reported with their order of participating nodes and their length, and whether the loop is a positive or a negative feedback loop. An upper limit of the number of feedback loops limits runtime (which scales with feedback loop count). Model parametrizations and values of the modelled variables are accounted for. Computation uses the characteristics of the Jacobian matrix as described e.g. in Thomas and Kaufman (2002) <doi:10.1016/s1631-0691(02)01452-x>. Input can be the Jacobian matrix of the ODE model or the ODE function definition; in the latter case, the Jacobian matrix is determined using 'numDeriv'. Graph-based algorithms from 'igraph' are employed for path detection.   "
  },
  {
    "id": 4655,
    "package_name": "MAPCtools",
    "title": "Multivariate Age-Period-Cohort (MAPC) Modeling for Health Data",
    "description": "Bayesian multivariate age-period-cohort (MAPC) models for analyzing health data, with support for model fitting, visualization, stratification, and model comparison. Inference focuses on identifiable cross-strata differences, as described by Riebler and Held (2010) <doi:10.1093/biostatistics/kxp037>. Methods for handling complex survey data via the 'survey' package are included, as described in Mercer et al. (2014) <doi:10.1016/j.spasta.2013.12.001>.",
    "version": "0.1.0",
    "maintainer": "Lars Vatten <lavatt99@gmail.com>",
    "author": "Lars Vatten [aut, cre]",
    "url": "https://github.com/LarsVatten/MAPCtools",
    "bug_reports": "https://github.com/LarsVatten/MAPCtools/issues",
    "repository": "https://cran.r-project.org/package=MAPCtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MAPCtools Multivariate Age-Period-Cohort (MAPC) Modeling for Health Data Bayesian multivariate age-period-cohort (MAPC) models for analyzing health data, with support for model fitting, visualization, stratification, and model comparison. Inference focuses on identifiable cross-strata differences, as described by Riebler and Held (2010) <doi:10.1093/biostatistics/kxp037>. Methods for handling complex survey data via the 'survey' package are included, as described in Mercer et al. (2014) <doi:10.1016/j.spasta.2013.12.001>.  "
  },
  {
    "id": 4676,
    "package_name": "MBESS",
    "title": "The MBESS R Package",
    "description": "Implements methods that are useful in designing research studies and analyzing data, with \n\tparticular emphasis on methods that are developed for or used within the behavioral, \n\teducational, and social sciences (broadly defined). That being said, many of the methods \n\timplemented within MBESS are applicable to a wide variety of disciplines. MBESS has a \n\tsuite of functions for a variety of related topics, such as effect sizes, confidence intervals \n\tfor effect sizes (including standardized effect sizes and noncentral effect sizes), sample size\n\tplanning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and \n\tminimum-risk point estimation perspectives), mediation analysis, various properties of \n\tdistributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally \n\tan acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became\n\tmore general and now contains methods applicable and used in a wide variety of fields and is an \n\torphan acronym, in the sense that what was an acronym is now literally its name. MBESS has \n\tgreatly benefited from others, see <https://www3.nd.edu/~kkelley/r-packages.html> for a detailed \n\tlist of those that have contributed and other details.",
    "version": "4.9.41",
    "maintainer": "Ken Kelley <kkelley@nd.edu>",
    "author": "Ken Kelley [aut, cre]",
    "url": "https://www3.nd.edu/~kkelley/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MBESS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MBESS The MBESS R Package Implements methods that are useful in designing research studies and analyzing data, with \n\tparticular emphasis on methods that are developed for or used within the behavioral, \n\teducational, and social sciences (broadly defined). That being said, many of the methods \n\timplemented within MBESS are applicable to a wide variety of disciplines. MBESS has a \n\tsuite of functions for a variety of related topics, such as effect sizes, confidence intervals \n\tfor effect sizes (including standardized effect sizes and noncentral effect sizes), sample size\n\tplanning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and \n\tminimum-risk point estimation perspectives), mediation analysis, various properties of \n\tdistributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally \n\tan acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became\n\tmore general and now contains methods applicable and used in a wide variety of fields and is an \n\torphan acronym, in the sense that what was an acronym is now literally its name. MBESS has \n\tgreatly benefited from others, see <https://www3.nd.edu/~kkelley/r-packages.html> for a detailed \n\tlist of those that have contributed and other details.  "
  },
  {
    "id": 4677,
    "package_name": "MBHdesign",
    "title": "Spatial Designs for Ecological and Environmental Surveys",
    "description": "Provides spatially survey balanced designs using the quasi-random number method described Robinson et al. (2013) <doi:10.1111/biom.12059> and adjusted in Robinson et al. (2017) <doi:10.1016/j.spl.2017.05.004>. Designs using MBHdesign can: 1) accommodate, without substantial detrimental effects on spatial balance, legacy sites (Foster et al., 2017 <doi:10.1111/2041-210X.12782>); 2) be based on points or transects (foster et al. 2020 <doi:10.1111/2041-210X.13321> and produce clustered samples (Foster et al. (in press). Additional information about the package use itself is given in Foster (2021) <doi:10.1111/2041-210X.13535>.",
    "version": "2.3.15",
    "maintainer": "Scott Foster <scott.foster@data61.csiro.au>",
    "author": "Scott D. Foster",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MBHdesign",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MBHdesign Spatial Designs for Ecological and Environmental Surveys Provides spatially survey balanced designs using the quasi-random number method described Robinson et al. (2013) <doi:10.1111/biom.12059> and adjusted in Robinson et al. (2017) <doi:10.1016/j.spl.2017.05.004>. Designs using MBHdesign can: 1) accommodate, without substantial detrimental effects on spatial balance, legacy sites (Foster et al., 2017 <doi:10.1111/2041-210X.12782>); 2) be based on points or transects (foster et al. 2020 <doi:10.1111/2041-210X.13321> and produce clustered samples (Foster et al. (in press). Additional information about the package use itself is given in Foster (2021) <doi:10.1111/2041-210X.13535>.  "
  },
  {
    "id": 4733,
    "package_name": "MEGENA",
    "title": "Multiscale Clustering of Geometrical Network",
    "description": "Co-Expression Network Analysis by adopting network embedding technique. Song W.-M., Zhang B. (2015) Multiscale Embedded Gene Co-expression Network Analysis. PLoS Comput Biol 11(11): e1004574. <doi: 10.1371/journal.pcbi.1004574>.",
    "version": "1.3.7",
    "maintainer": "Won-Min Song <wonmin1984@gmail.com>",
    "author": "Won-Min Song, Bin Zhang",
    "url": "https://github.com/songw01/MEGENA",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MEGENA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MEGENA Multiscale Clustering of Geometrical Network Co-Expression Network Analysis by adopting network embedding technique. Song W.-M., Zhang B. (2015) Multiscale Embedded Gene Co-expression Network Analysis. PLoS Comput Biol 11(11): e1004574. <doi: 10.1371/journal.pcbi.1004574>.  "
  },
  {
    "id": 4746,
    "package_name": "MGBT",
    "title": "Multiple Grubbs-Beck Low-Outlier Test",
    "description": "Compute the multiple Grubbs-Beck low-outlier test on positively distributed\n data and utilities for noninterpretive U.S. Geological Survey annual peak-streamflow\n data processing discussed in Cohn et al. (2013) <doi:10.1002/wrcr.20392> and\n England et al. (2017) <doi:10.3133/tm4B5>.",
    "version": "1.0.7",
    "maintainer": "William H. Asquith <wasquith@usgs.gov>",
    "author": "William H. Asquith [aut, cre], John F. England [aut, ctb], George R. Herrmann [ctb]",
    "url": "https://doi.org/10.5066/P9CW9EF0",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MGBT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MGBT Multiple Grubbs-Beck Low-Outlier Test Compute the multiple Grubbs-Beck low-outlier test on positively distributed\n data and utilities for noninterpretive U.S. Geological Survey annual peak-streamflow\n data processing discussed in Cohn et al. (2013) <doi:10.1002/wrcr.20392> and\n England et al. (2017) <doi:10.3133/tm4B5>.  "
  },
  {
    "id": 4832,
    "package_name": "MNP",
    "title": "Fitting the Multinomial Probit Model",
    "description": "Fits the Bayesian multinomial probit model via Markov chain\n Monte Carlo.  The multinomial probit model is often used to analyze \n the discrete choices made by individuals recorded in survey data. \n Examples where the multinomial probit model may be useful include the \n analysis of product choice by consumers in market research and the \n analysis of candidate or party choice by voters in electoral studies.  \n The MNP package can also fit the model with different choice sets for \n each individual, and complete or partial individual choice orderings \n of the available alternatives from the choice set. The estimation is\n based on the efficient marginal data augmentation algorithm that is \n developed by Imai and van Dyk (2005). \"A Bayesian Analysis of the \n Multinomial Probit Model Using the Data Augmentation.\" Journal of \n Econometrics, Vol. 124, No. 2 (February), pp. 311-334. \n <doi:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in \n Imai and van Dyk (2005). \"MNP: R Package for Fitting the Multinomial \n Probit Model.\"  Journal of Statistical Software, Vol. 14, No. 3 (May), \n pp. 1-32. <doi:10.18637/jss.v014.i03>.",
    "version": "3.1-5",
    "maintainer": "Kosuke Imai <imai@harvard.edu>",
    "author": "Kosuke Imai [aut, cre],\n  David van Dyk [aut],\n  Hubert Jin [ctb]",
    "url": "https://github.com/kosukeimai/MNP",
    "bug_reports": "https://github.com/kosukeimai/MNP/issues",
    "repository": "https://cran.r-project.org/package=MNP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MNP Fitting the Multinomial Probit Model Fits the Bayesian multinomial probit model via Markov chain\n Monte Carlo.  The multinomial probit model is often used to analyze \n the discrete choices made by individuals recorded in survey data. \n Examples where the multinomial probit model may be useful include the \n analysis of product choice by consumers in market research and the \n analysis of candidate or party choice by voters in electoral studies.  \n The MNP package can also fit the model with different choice sets for \n each individual, and complete or partial individual choice orderings \n of the available alternatives from the choice set. The estimation is\n based on the efficient marginal data augmentation algorithm that is \n developed by Imai and van Dyk (2005). \"A Bayesian Analysis of the \n Multinomial Probit Model Using the Data Augmentation.\" Journal of \n Econometrics, Vol. 124, No. 2 (February), pp. 311-334. \n <doi:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in \n Imai and van Dyk (2005). \"MNP: R Package for Fitting the Multinomial \n Probit Model.\"  Journal of Statistical Software, Vol. 14, No. 3 (May), \n pp. 1-32. <doi:10.18637/jss.v014.i03>.  "
  },
  {
    "id": 4864,
    "package_name": "MRG",
    "title": "Create Non-Confidential Multi-Resolution Grids",
    "description": "The need for anonymization of individual survey responses often leads to many suppressed grid cells in a regular grid. Here we provide functionality for creating multi-resolution gridded data, respecting the confidentiality rules, such as a minimum number of units and dominance by one or more units for each  grid cell. The functions also include the possibility for contextual suppression of data. For more details see Skoien et al. (2025) <doi:10.48550/arXiv.2410.17601>.",
    "version": "0.3.21",
    "maintainer": "Jon Olav Skoien <jon.skoien@gmail.com>",
    "author": "Jon Olav Skoien [aut, cre],\n  Nicolas Lampach [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MRG",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MRG Create Non-Confidential Multi-Resolution Grids The need for anonymization of individual survey responses often leads to many suppressed grid cells in a regular grid. Here we provide functionality for creating multi-resolution gridded data, respecting the confidentiality rules, such as a minimum number of units and dominance by one or more units for each  grid cell. The functions also include the possibility for contextual suppression of data. For more details see Skoien et al. (2025) <doi:10.48550/arXiv.2410.17601>.  "
  },
  {
    "id": 4888,
    "package_name": "MSIMST",
    "title": "Bayesian Monotonic Single-Index Regression Model with the Skew-T\nLikelihood",
    "description": "Incorporates a Bayesian monotonic single-index mixed-effect model with a multivariate skew-t likelihood, specifically designed to handle survey weights adjustments. Features include a simulation program and an associated Gibbs sampler for model estimation. The single-index function is constrained to be monotonic increasing, utilizing a customized Gaussian process prior for precise estimation. The model assumes random effects follow a canonical skew-t distribution, while residuals are represented by a multivariate Student-t distribution. Offers robust Bayesian adjustments to integrate survey weight information effectively.",
    "version": "1.1",
    "maintainer": "Qingyang Liu <rh8liuqy@gmail.com>",
    "author": "Qingyang Liu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3265-6330>),\n  Debdeep Pati [aut],\n  Dipankar Bandyopadhyay [aut]",
    "url": "https://github.com/rh8liuqy/MSIMST",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MSIMST",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MSIMST Bayesian Monotonic Single-Index Regression Model with the Skew-T\nLikelihood Incorporates a Bayesian monotonic single-index mixed-effect model with a multivariate skew-t likelihood, specifically designed to handle survey weights adjustments. Features include a simulation program and an associated Gibbs sampler for model estimation. The single-index function is constrained to be monotonic increasing, utilizing a customized Gaussian process prior for precise estimation. The model assumes random effects follow a canonical skew-t distribution, while residuals are represented by a multivariate Student-t distribution. Offers robust Bayesian adjustments to integrate survey weight information effectively.  "
  },
  {
    "id": 4955,
    "package_name": "ManyIVsNets",
    "title": "Environmental Phillips Curve Analysis with Multiple Instrumental\nVariables and Networks",
    "description": "Comprehensive toolkit for Environmental Phillips Curve analysis \n    featuring multidimensional instrumental variable creation, transfer entropy \n    causal discovery, network analysis, and state-of-the-art econometric methods.\n    Implements geographic, technological, migration, geopolitical, financial, \n    and natural risk instruments with robust diagnostics and visualization.\n    Provides 24 different instrumental variable approaches with empirical validation.\n    Methods based on Phillips (1958) <doi:10.1111/j.1468-0335.1958.tb00003.x>,\n    transfer entropy by Schreiber (2000) <doi:10.1103/PhysRevLett.85.461>, and \n    weak instrument tests by Stock and Yogo (2005) <doi:10.1017/CBO9780511614491.006>.",
    "version": "0.1.1",
    "maintainer": "Avishek Bhandari <bavisek@gmail.com>",
    "author": "Avishek Bhandari [aut, cre, cph]",
    "url": "https://github.com/avishekb9/ManyIVsNets,\nhttps://avishekb9.github.io/ManyIVsNets/",
    "bug_reports": "https://github.com/avishekb9/ManyIVsNets/issues",
    "repository": "https://cran.r-project.org/package=ManyIVsNets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ManyIVsNets Environmental Phillips Curve Analysis with Multiple Instrumental\nVariables and Networks Comprehensive toolkit for Environmental Phillips Curve analysis \n    featuring multidimensional instrumental variable creation, transfer entropy \n    causal discovery, network analysis, and state-of-the-art econometric methods.\n    Implements geographic, technological, migration, geopolitical, financial, \n    and natural risk instruments with robust diagnostics and visualization.\n    Provides 24 different instrumental variable approaches with empirical validation.\n    Methods based on Phillips (1958) <doi:10.1111/j.1468-0335.1958.tb00003.x>,\n    transfer entropy by Schreiber (2000) <doi:10.1103/PhysRevLett.85.461>, and \n    weak instrument tests by Stock and Yogo (2005) <doi:10.1017/CBO9780511614491.006>.  "
  },
  {
    "id": 5021,
    "package_name": "MetaNet",
    "title": "Network Analysis for Omics Data",
    "description": "Comprehensive network analysis package.\n    Calculate correlation network fastly, accelerate lots of analysis by parallel computing.\n    Support for multi-omics data, search sub-nets fluently.\n    Handle bigger data, more than 10,000 nodes in each omics.\n    Offer various layout method for multi-omics network and some interfaces to other software ('Gephi', 'Cytoscape', 'ggplot2'), easy to visualize.\n    Provide comprehensive topology indexes calculation, including ecological network stability.",
    "version": "0.2.7",
    "maintainer": "Chen Peng <pengchen2001@zju.edu.cn>",
    "author": "Chen Peng [aut, cre] (ORCID: <https://orcid.org/0000-0002-9449-7606>)",
    "url": "https://github.com/Asa12138/MetaNet",
    "bug_reports": "https://github.com/Asa12138/MetaNet/issues",
    "repository": "https://cran.r-project.org/package=MetaNet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MetaNet Network Analysis for Omics Data Comprehensive network analysis package.\n    Calculate correlation network fastly, accelerate lots of analysis by parallel computing.\n    Support for multi-omics data, search sub-nets fluently.\n    Handle bigger data, more than 10,000 nodes in each omics.\n    Offer various layout method for multi-omics network and some interfaces to other software ('Gephi', 'Cytoscape', 'ggplot2'), easy to visualize.\n    Provide comprehensive topology indexes calculation, including ecological network stability.  "
  },
  {
    "id": 5041,
    "package_name": "MexicoDataAPI",
    "title": "Access Mexican Data via APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including\n    'REST Countries API', 'World Bank API', and 'Nager.Date API', covering Mexico's economic\n    indicators, population statistics, literacy rates, international geopolitical\n    information and official public holidays. The package also includes curated\n    datasets related to Mexico such as air quality monitoring stations, pollution\n    zones, income surveys, postal abbreviations, election studies, forest\n    productivity and demographic data by state. It supports research and analysis\n    focused on Mexico by integrating reliable global APIs with structured national\n    datasets drawn from open and academic sources. \n    For more information on the APIs, see: \n        'REST Countries API' <https://restcountries.com/>, \n        'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n        and 'Nager.Date API' <https://date.nager.at/Api>.",
    "version": "0.2.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/mexicodataapi,\nhttps://lightbluetitan.github.io/mexicodataapi/",
    "bug_reports": "https://github.com/lightbluetitan/mexicodataapi/issues",
    "repository": "https://cran.r-project.org/package=MexicoDataAPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MexicoDataAPI Access Mexican Data via APIs and Curated Datasets Provides functions to access data from public RESTful APIs including\n    'REST Countries API', 'World Bank API', and 'Nager.Date API', covering Mexico's economic\n    indicators, population statistics, literacy rates, international geopolitical\n    information and official public holidays. The package also includes curated\n    datasets related to Mexico such as air quality monitoring stations, pollution\n    zones, income surveys, postal abbreviations, election studies, forest\n    productivity and demographic data by state. It supports research and analysis\n    focused on Mexico by integrating reliable global APIs with structured national\n    datasets drawn from open and academic sources. \n    For more information on the APIs, see: \n        'REST Countries API' <https://restcountries.com/>, \n        'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n        and 'Nager.Date API' <https://date.nager.at/Api>.  "
  },
  {
    "id": 5048,
    "package_name": "MicSim",
    "title": "Performing Continuous-Time Microsimulation",
    "description": "This toolkit allows performing continuous-time microsimulation for a wide range of life science (demography, social sciences, epidemiology) applications. Individual life-courses are specified by a continuous-time multi-state model as described in Zinn (2014) <doi:10.34196/IJM.00105>. ",
    "version": "3.0.0",
    "maintainer": "Sabine Zinn <szinn@diw.de>",
    "author": "Sabine Zinn [aut, cre],\n  Felix von Heusinger [ctb],\n  Camila Weber [ctb],\n  Claudio Bosco [ctb],\n  Maurizio Teobaldell [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MicSim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MicSim Performing Continuous-Time Microsimulation This toolkit allows performing continuous-time microsimulation for a wide range of life science (demography, social sciences, epidemiology) applications. Individual life-courses are specified by a continuous-time multi-state model as described in Zinn (2014) <doi:10.34196/IJM.00105>.   "
  },
  {
    "id": 5098,
    "package_name": "MoNAn",
    "title": "Mobility Network Analysis",
    "description": "Implements the method to analyse weighted mobility networks or distribution networks as outlined in: \n    Block, P., Stadtfeld, C., & Robins, G. (2022) <doi:10.1016/j.socnet.2021.08.003>. \n    The purpose of the model is to analyse the structure of mobility, \n    incorporating exogenous predictors pertaining to individuals and locations \n    known from classical mobility analyses, as well as modelling emergent mobility \n    patterns akin to structural patterns known from the statistical analysis of social networks.",
    "version": "1.1.0",
    "maintainer": "Per Block <block@soziologie.uzh.ch>",
    "author": "Per Block [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-7583-2392>),\n  Christoph Stadtfeld [aut] (ORCID:\n    <https://orcid.org/0000-0002-2704-2134>),\n  Nico Keiser [aut] (ORCID: <https://orcid.org/0009-0007-3403-278X>),\n  Marion Hoffman [aut] (ORCID: <https://orcid.org/0000-0002-0741-7760>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MoNAn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MoNAn Mobility Network Analysis Implements the method to analyse weighted mobility networks or distribution networks as outlined in: \n    Block, P., Stadtfeld, C., & Robins, G. (2022) <doi:10.1016/j.socnet.2021.08.003>. \n    The purpose of the model is to analyse the structure of mobility, \n    incorporating exogenous predictors pertaining to individuals and locations \n    known from classical mobility analyses, as well as modelling emergent mobility \n    patterns akin to structural patterns known from the statistical analysis of social networks.  "
  },
  {
    "id": 5167,
    "package_name": "MultiTraits",
    "title": "Analyzing and Visualizing Multidimensional Plant Traits",
    "description": "Implements analytical methods for multidimensional plant traits, including Competitors-Stress tolerators-Ruderals strategy analysis using leaf traits, Leaf-Height-Seed strategy analysis, Niche Periodicity Table analysis, and Trait Network analysis. Provides functions for data analysis, visualization, and network metrics calculation. Methods are based on Grime (1974) <doi:10.1038/250026a0>, Pierce et al. (2017) <doi:10.1111/1365-2435.12882>, Westoby (1998) <doi:10.1023/A:1004327224729>, Winemiller et al. (2015) <doi:10.1111/ele.12462>, He et al. (2020) <doi:10.1016/j.tree.2020.06.003>.",
    "version": "0.6.0",
    "maintainer": "Yan He <heyan@njfu.edu.cn>",
    "author": "Yan He [aut, cre],\n  Zhaogang Liu [aut],\n  Jiangshan Lai [aut],\n  Lingfeng Mao [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=MultiTraits",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultiTraits Analyzing and Visualizing Multidimensional Plant Traits Implements analytical methods for multidimensional plant traits, including Competitors-Stress tolerators-Ruderals strategy analysis using leaf traits, Leaf-Height-Seed strategy analysis, Niche Periodicity Table analysis, and Trait Network analysis. Provides functions for data analysis, visualization, and network metrics calculation. Methods are based on Grime (1974) <doi:10.1038/250026a0>, Pierce et al. (2017) <doi:10.1111/1365-2435.12882>, Westoby (1998) <doi:10.1023/A:1004327224729>, Winemiller et al. (2015) <doi:10.1111/ele.12462>, He et al. (2020) <doi:10.1016/j.tree.2020.06.003>.  "
  },
  {
    "id": 5175,
    "package_name": "MultisiteMediation",
    "title": "Causal Mediation Analysis in Multisite Trials",
    "description": "Multisite causal mediation analysis using the methods proposed by Qin and Hong (2017) <doi:10.3102/1076998617694879>, Qin, Hong, Deutsch, and Bein (2019) <doi:10.1111/rssa.12446>, and Qin, Deutsch, and Hong (2021) <doi:10.1002/pam.22268>. It enables causal mediation analysis in multisite trials, in which individuals are assigned to a treatment or a control group at each site. It allows for estimation and hypothesis testing for not only the population average but also the between-site variance of direct and indirect effects transmitted through one single mediator or two concurrent (conditionally independent) mediators. This strategy conveniently relaxes the assumption of no treatment-by-mediator interaction while greatly simplifying the outcome model specification without invoking strong distributional assumptions. This package also provides a function that can further incorporate a sample weight and a nonresponse weight for multisite causal mediation analysis in the presence of complex sample and survey designs and non-random nonresponse, to enhance both the internal validity and external validity. The package also provides a weighting-based balance checking function for assessing the remaining overt bias.",
    "version": "0.0.4",
    "maintainer": "Xu Qin <xuqin@pitt.edu>",
    "author": "Xu Qin, Guanglei Hong, Jonah Deutsch, and Edward Bein",
    "url": "https://github.com/Xu-Qin/MultisiteMediation",
    "bug_reports": "https://github.com/Xu-Qin/MultisiteMediation/issues",
    "repository": "https://cran.r-project.org/package=MultisiteMediation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "MultisiteMediation Causal Mediation Analysis in Multisite Trials Multisite causal mediation analysis using the methods proposed by Qin and Hong (2017) <doi:10.3102/1076998617694879>, Qin, Hong, Deutsch, and Bein (2019) <doi:10.1111/rssa.12446>, and Qin, Deutsch, and Hong (2021) <doi:10.1002/pam.22268>. It enables causal mediation analysis in multisite trials, in which individuals are assigned to a treatment or a control group at each site. It allows for estimation and hypothesis testing for not only the population average but also the between-site variance of direct and indirect effects transmitted through one single mediator or two concurrent (conditionally independent) mediators. This strategy conveniently relaxes the assumption of no treatment-by-mediator interaction while greatly simplifying the outcome model specification without invoking strong distributional assumptions. This package also provides a function that can further incorporate a sample weight and a nonresponse weight for multisite causal mediation analysis in the presence of complex sample and survey designs and non-random nonresponse, to enhance both the internal validity and external validity. The package also provides a weighting-based balance checking function for assessing the remaining overt bias.  "
  },
  {
    "id": 5222,
    "package_name": "NHANES",
    "title": "Data from the US National Health and Nutrition Examination Study",
    "description": "Body Shape and related measurements from the US National Health\n    and Nutrition Examination Survey (NHANES, 1999-2004).  See\n    http://www.cdc.gov/nchs/nhanes.htm for details.",
    "version": "2.1.0",
    "maintainer": "Randall Pruim <rpruim@calvin.edu>",
    "author": "Randall Pruim <rpruim@calvin.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NHANES",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NHANES Data from the US National Health and Nutrition Examination Study Body Shape and related measurements from the US National Health\n    and Nutrition Examination Survey (NHANES, 1999-2004).  See\n    http://www.cdc.gov/nchs/nhanes.htm for details.  "
  },
  {
    "id": 5244,
    "package_name": "NMI",
    "title": "Normalized Mutual Information of Community Structure in Network",
    "description": "Calculates the normalized mutual information (NMI) of two community structures in network analysis.",
    "version": "2.0",
    "maintainer": "Tianhao Wu <tianhao.wu@yale.edu>",
    "author": "Tianhao Wu [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NMI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NMI Normalized Mutual Information of Community Structure in Network Calculates the normalized mutual information (NMI) of two community structures in network analysis.  "
  },
  {
    "id": 5306,
    "package_name": "NetExplorer",
    "title": "Network Explorer",
    "description": "Social network analysis has become an essential tool in the study of complex systems. 'NetExplorer' allows to visualize and explore complex systems. It is based on 'd3js' library that brings 1) Graphical user interface;  2) Circular, linear, multilayer and force Layout; 3) Network live exploration and 4) SVG exportation.",
    "version": "0.0.2",
    "maintainer": "Sosa Sebastian <s.sosa@live.fr>",
    "author": "Sosa Sebastian [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NetExplorer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NetExplorer Network Explorer Social network analysis has become an essential tool in the study of complex systems. 'NetExplorer' allows to visualize and explore complex systems. It is based on 'd3js' library that brings 1) Graphical user interface;  2) Circular, linear, multilayer and force Layout; 3) Network live exploration and 4) SVG exportation.  "
  },
  {
    "id": 5327,
    "package_name": "NetworkToolbox",
    "title": "Methods and Measures for Brain, Cognitive, and Psychometric\nNetwork Analysis",
    "description": "Implements network analysis and graph theory measures used in neuroscience, cognitive science, and psychology. Methods include various filtering methods and approaches such as threshold, dependency (Kenett, Tumminello, Madi, Gur-Gershgoren, Mantegna, & Ben-Jacob, 2010 <doi:10.1371/journal.pone.0015032>), Information Filtering Networks (Barfuss, Massara, Di Matteo, & Aste, 2016 <doi:10.1103/PhysRevE.94.062306>), and Efficiency-Cost Optimization (Fallani, Latora, & Chavez, 2017 <doi:10.1371/journal.pcbi.1005305>). Brain methods include the recently developed Connectome Predictive Modeling (see references in package). Also implements several network measures including local network characteristics (e.g., centrality), community-level network characteristics (e.g., community centrality), global network characteristics (e.g., clustering coefficient), and various other measures associated with the reliability and reproducibility of network analysis. ",
    "version": "1.4.4",
    "maintainer": "Alexander Christensen <alexpaulchristensen@gmail.com>",
    "author": "Alexander Christensen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9798-7037>),\n  Guido Previde Massara [ctb] (ORCID:\n    <https://orcid.org/0000-0003-0502-2789>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=NetworkToolbox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NetworkToolbox Methods and Measures for Brain, Cognitive, and Psychometric\nNetwork Analysis Implements network analysis and graph theory measures used in neuroscience, cognitive science, and psychology. Methods include various filtering methods and approaches such as threshold, dependency (Kenett, Tumminello, Madi, Gur-Gershgoren, Mantegna, & Ben-Jacob, 2010 <doi:10.1371/journal.pone.0015032>), Information Filtering Networks (Barfuss, Massara, Di Matteo, & Aste, 2016 <doi:10.1103/PhysRevE.94.062306>), and Efficiency-Cost Optimization (Fallani, Latora, & Chavez, 2017 <doi:10.1371/journal.pcbi.1005305>). Brain methods include the recently developed Connectome Predictive Modeling (see references in package). Also implements several network measures including local network characteristics (e.g., centrality), community-level network characteristics (e.g., community centrality), global network characteristics (e.g., clustering coefficient), and various other measures associated with the reliability and reproducibility of network analysis.   "
  },
  {
    "id": 5341,
    "package_name": "NlsyLinks",
    "title": "Utilities and Kinship Information for Research with the NLSY",
    "description": "Utilities and kinship information for behavior genetics and\n    developmental research using the National Longitudinal Survey of Youth\n    (NLSY; <https://www.nlsinfo.org/>).",
    "version": "2.2.3",
    "maintainer": "S. Mason Garrison <garrissm@wfu.edu>",
    "author": "William Howard Beasley [aut] (ORCID:\n    <https://orcid.org/0000-0002-5613-5006>),\n  Joseph Lee Rodgers [aut] (ORCID:\n    <https://orcid.org/0000-0002-8615-6713>),\n  David Bard [aut],\n  Michael D. Hunter [aut] (ORCID:\n    <https://orcid.org/0000-0002-3651-6709>),\n  Patrick O'Keefe [aut] (ORCID: <https://orcid.org/0000-0002-5343-0130>),\n  Kelly Meredith Williams [aut],\n  S. Mason Garrison [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4804-6003>)",
    "url": "https://nlsy-links.github.io/NlsyLinks/,\nhttps://github.com/nlsy-links/NlsyLinks",
    "bug_reports": "https://github.com/nlsy-links/NlsyLinks/issues",
    "repository": "https://cran.r-project.org/package=NlsyLinks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "NlsyLinks Utilities and Kinship Information for Research with the NLSY Utilities and kinship information for behavior genetics and\n    developmental research using the National Longitudinal Survey of Youth\n    (NLSY; <https://www.nlsinfo.org/>).  "
  },
  {
    "id": 5532,
    "package_name": "PAutilities",
    "title": "Streamline Physical Activity Research",
    "description": "Functions that support a broad range of common tasks in physical\n    activity research, including but not limited to creation of Bland-Altman\n    plots (<doi:10.1136/bmj.313.7049.106>), metabolic calculations such as basal\n    metabolic rate predictions (<https://europepmc.org/article/med/4044297/reloa>),\n    demographic calculations such as age-for-body-mass-index percentile\n    (<https://www.cdc.gov/growthcharts/cdc_charts.htm>), and analysis of bout\n    detection algorithm performance (<https://pubmed.ncbi.nlm.nih.gov/34258524/>).",
    "version": "1.2.1",
    "maintainer": "Paul R. Hibbing <paulhibbing@gmail.com>",
    "author": "Paul R. Hibbing [aut, cre],\n  Centers for Disease Control and Prevention [ctb]",
    "url": "https://github.com/paulhibbing/PAutilities",
    "bug_reports": "https://github.com/paulhibbing/PAutilities/issues",
    "repository": "https://cran.r-project.org/package=PAutilities",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PAutilities Streamline Physical Activity Research Functions that support a broad range of common tasks in physical\n    activity research, including but not limited to creation of Bland-Altman\n    plots (<doi:10.1136/bmj.313.7049.106>), metabolic calculations such as basal\n    metabolic rate predictions (<https://europepmc.org/article/med/4044297/reloa>),\n    demographic calculations such as age-for-body-mass-index percentile\n    (<https://www.cdc.gov/growthcharts/cdc_charts.htm>), and analysis of bout\n    detection algorithm performance (<https://pubmed.ncbi.nlm.nih.gov/34258524/>).  "
  },
  {
    "id": 5534,
    "package_name": "PBIBD",
    "title": "Partially Balanced Incomplete Block Designs",
    "description": "The PBIB designs are important type of incomplete block designs\n having wide area of their applications for example in agricultural\n experiments, in plant breeding, in sample surveys etc. This package\n constructs various series of PBIB designs and assists in checking all the\n necessary conditions of PBIB designs and the association scheme on which\n these designs are based on. It also assists in calculating the efficiencies\n of PBIB designs with any number of associate classes. The package also\n constructs Youden-m square designs which are Row-Column designs for the\n two-way elimination of heterogeneity. The incomplete columns of these\n Youden-m square designs constitute PBIB designs. With the present\n functionality, the package will be of immense importance for the researchers\n as it will help them to construct PBIB designs, to check if their PBIB\n designs and association scheme satisfy various necessary conditions for the\n existence, to calculate the efficiencies of PBIB designs based on any\n association scheme and to construct Youden-m square designs for the two-way\n elimination of heterogeneity. R. C. Bose and K. R. Nair (1939)\n <http://www.jstor.org/stable/40383923>.",
    "version": "1.4",
    "maintainer": "Kush Sharma <kush.vashishtha@gmail.com>",
    "author": "Parneet Kaur [aut],\n  Kush Sharma [aut, cre],\n  Davinder Kumar Garg [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PBIBD",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PBIBD Partially Balanced Incomplete Block Designs The PBIB designs are important type of incomplete block designs\n having wide area of their applications for example in agricultural\n experiments, in plant breeding, in sample surveys etc. This package\n constructs various series of PBIB designs and assists in checking all the\n necessary conditions of PBIB designs and the association scheme on which\n these designs are based on. It also assists in calculating the efficiencies\n of PBIB designs with any number of associate classes. The package also\n constructs Youden-m square designs which are Row-Column designs for the\n two-way elimination of heterogeneity. The incomplete columns of these\n Youden-m square designs constitute PBIB designs. With the present\n functionality, the package will be of immense importance for the researchers\n as it will help them to construct PBIB designs, to check if their PBIB\n designs and association scheme satisfy various necessary conditions for the\n existence, to calculate the efficiencies of PBIB designs based on any\n association scheme and to construct Youden-m square designs for the two-way\n elimination of heterogeneity. R. C. Bose and K. R. Nair (1939)\n <http://www.jstor.org/stable/40383923>.  "
  },
  {
    "id": 5615,
    "package_name": "PL94171",
    "title": "Tabulate P.L. 94-171 Redistricting Data Summary Files",
    "description": "Tools to process legacy format summary redistricting data files\n    produced by the United States Census Bureau pursuant to P.L. 94-171. These\n    files are generally available earlier but are difficult to work with as-is.",
    "version": "1.1.3",
    "maintainer": "Cory McCartan <mccartan@psu.edu>",
    "author": "Cory McCartan [aut, cre],\n  Christopher T. Kenny [aut]",
    "url": "https://corymccartan.com/PL94171/,\nhttps://github.com/CoryMcCartan/PL94171/",
    "bug_reports": "https://github.com/CoryMcCartan/PL94171/issues",
    "repository": "https://cran.r-project.org/package=PL94171",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PL94171 Tabulate P.L. 94-171 Redistricting Data Summary Files Tools to process legacy format summary redistricting data files\n    produced by the United States Census Bureau pursuant to P.L. 94-171. These\n    files are generally available earlier but are difficult to work with as-is.  "
  },
  {
    "id": 5616,
    "package_name": "PLEXI",
    "title": "Multiplex Network Analysis",
    "description": "Interactions between different biological entities are crucial for the function of biological systems. \n    In such networks, nodes represent biological elements, such as genes, proteins and microbes, and their interactions can be defined by edges, which can be either binary or weighted.\n    The dysregulation of these networks can be associated with different clinical conditions such as diseases and response to treatments. \n    However, such variations often occur locally and do not concern the whole network. \n    To capture local variations of such networks, we propose multiplex network differential analysis (MNDA). \n    MNDA allows to quantify the variations in the local neighborhood of each node (e.g. gene) between the two given clinical states, and to test for statistical significance of such variation.\n    Yousefi et al. (2023) <doi:10.1101/2023.01.22.525058>.",
    "version": "1.0.0",
    "maintainer": "Behnam Yousefi <yousefi.bme@gmail.com>",
    "author": "Behnam Yousefi [aut, cre, cph],\n  Farzaneh Firoozbakht [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PLEXI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PLEXI Multiplex Network Analysis Interactions between different biological entities are crucial for the function of biological systems. \n    In such networks, nodes represent biological elements, such as genes, proteins and microbes, and their interactions can be defined by edges, which can be either binary or weighted.\n    The dysregulation of these networks can be associated with different clinical conditions such as diseases and response to treatments. \n    However, such variations often occur locally and do not concern the whole network. \n    To capture local variations of such networks, we propose multiplex network differential analysis (MNDA). \n    MNDA allows to quantify the variations in the local neighborhood of each node (e.g. gene) between the two given clinical states, and to test for statistical significance of such variation.\n    Yousefi et al. (2023) <doi:10.1101/2023.01.22.525058>.  "
  },
  {
    "id": 5633,
    "package_name": "PNADcIBGE",
    "title": "Downloading, Reading and Analyzing PNADC Microdata",
    "description": "Provides tools for downloading, reading and analyzing the Continuous National\n  Household Sample Survey - PNADC, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.",
    "version": "0.7.5",
    "maintainer": "Gabriel Assuncao <pacotesipd@ibge.gov.br>",
    "author": "Douglas Braga [aut],\n  Gabriel Assuncao [aut, cre],\n  Luna Hidalgo [ctb],\n  Viviane Quintaes [ctb]",
    "url": "",
    "bug_reports": "https://github.com/Gabriel-Assuncao/PNADcIBGE/issues",
    "repository": "https://cran.r-project.org/package=PNADcIBGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PNADcIBGE Downloading, Reading and Analyzing PNADC Microdata Provides tools for downloading, reading and analyzing the Continuous National\n  Household Sample Survey - PNADC, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.  "
  },
  {
    "id": 5637,
    "package_name": "PNDSIBGE",
    "title": "Downloading, Reading and Analyzing PNDS Microdata - Package in\nDevelopment",
    "description": "Provides tools for downloading, reading and analyzing the National\n  Survey of Demographic and Health - PNDS, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.",
    "version": "0.1.1",
    "maintainer": "Gabriel Assuncao <pacotesipd@ibge.gov.br>",
    "author": "Gabriel Assuncao [aut, cre],\n  Luna Hidalgo [aut],\n  Douglas Braga [ctb],\n  Viviane Quintaes [ctb]",
    "url": "",
    "bug_reports": "https://github.com/Gabriel-Assuncao/PNDSIBGE/issues",
    "repository": "https://cran.r-project.org/package=PNDSIBGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PNDSIBGE Downloading, Reading and Analyzing PNDS Microdata - Package in\nDevelopment Provides tools for downloading, reading and analyzing the National\n  Survey of Demographic and Health - PNDS, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.  "
  },
  {
    "id": 5638,
    "package_name": "PNSIBGE",
    "title": "Downloading, Reading and Analyzing PNS Microdata",
    "description": "Provides tools for downloading, reading and analyzing the National\n  Survey of Health - PNS, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.",
    "version": "0.2.1",
    "maintainer": "Gabriel Assuncao <pacotesipd@ibge.gov.br>",
    "author": "Gabriel Assuncao [aut, cre],\n  Luna Hidalgo [aut],\n  Douglas Braga [ctb],\n  Viviane Quintaes [ctb]",
    "url": "",
    "bug_reports": "https://github.com/Gabriel-Assuncao/PNSIBGE/issues",
    "repository": "https://cran.r-project.org/package=PNSIBGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PNSIBGE Downloading, Reading and Analyzing PNS Microdata Provides tools for downloading, reading and analyzing the National\n  Survey of Health - PNS, a household survey from Brazilian Institute\n  of Geography and Statistics - IBGE. The data must be downloaded from the official\n  website <https://www.ibge.gov.br/>. Further analysis must be made using package 'survey'.  "
  },
  {
    "id": 5668,
    "package_name": "PRANA",
    "title": "Pseudo-Value Regression Approach for Network Analysis (PRANA)",
    "description": "A novel pseudo-value regression approach for the differential co-expression network analysis in expression data, which can incorporate additional clinical variables in the model. This is a direct regression modeling for the differential network analysis, and it is therefore computationally amenable for the most users. The full methodological details can be found in Ahn S et al (2023) <doi:10.1186/s12859-022-05123-w>.",
    "version": "1.0.6",
    "maintainer": "Seungjun Ahn <seungjun.ahn@mountsinai.org>",
    "author": "Seungjun Ahn [cre, aut, trl] (ORCID:\n    <https://orcid.org/0000-0002-4816-8924>),\n  Somnath Datta [ctb, ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PRANA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PRANA Pseudo-Value Regression Approach for Network Analysis (PRANA) A novel pseudo-value regression approach for the differential co-expression network analysis in expression data, which can incorporate additional clinical variables in the model. This is a direct regression modeling for the differential network analysis, and it is therefore computationally amenable for the most users. The full methodological details can be found in Ahn S et al (2023) <doi:10.1186/s12859-022-05123-w>.  "
  },
  {
    "id": 5701,
    "package_name": "PSLM2015",
    "title": "Pakistan Social and Living Standards Measurement Survey 2014-15",
    "description": "Data and statistics of Pakistan Social and Living Standards Measurement (PSLM) survey 2014-15 from Pakistan Bureau of Statistics (<http://www.pbs.gov.pk/>).",
    "version": "0.2.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Arfan Dilber [ctb]",
    "url": "https://github.com/MYaseen208/PSLM2015",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PSLM2015",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PSLM2015 Pakistan Social and Living Standards Measurement Survey 2014-15 Data and statistics of Pakistan Social and Living Standards Measurement (PSLM) survey 2014-15 from Pakistan Bureau of Statistics (<http://www.pbs.gov.pk/>).  "
  },
  {
    "id": 5703,
    "package_name": "PSPManalysis",
    "title": "Analysis of Physiologically Structured Population Models",
    "description": "Performs demographic, bifurcation and evolutionary analysis of physiologically structured population models, which is a class of models that consistently translates continuous-time models of individual life history to the population level.\n    A model of individual life history has to be implemented specifying the individual-level functions that determine the life history, such as development and mortality rates and fecundity. \n    M.A. Kirkilionis, O. Diekmann, B. Lisser, M. Nool, B. Sommeijer & A.M. de Roos (2001) <doi:10.1142/S0218202501001264>.\n    O.Diekmann, M.Gyllenberg & J.A.J.Metz (2003) <doi:10.1016/S0040-5809(02)00058-8>.\n    A.M. de Roos (2008) <doi:10.1111/j.1461-0248.2007.01121.x>.",
    "version": "0.3.9",
    "maintainer": "Andre M. de Roos <A.M.deRoos@uva.nl>",
    "author": "Andre M. de Roos [aut, cre],\n  Ernst Hairer [ctb],\n  Gerhard Wanner [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PSPManalysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PSPManalysis Analysis of Physiologically Structured Population Models Performs demographic, bifurcation and evolutionary analysis of physiologically structured population models, which is a class of models that consistently translates continuous-time models of individual life history to the population level.\n    A model of individual life history has to be implemented specifying the individual-level functions that determine the life history, such as development and mortality rates and fecundity. \n    M.A. Kirkilionis, O. Diekmann, B. Lisser, M. Nool, B. Sommeijer & A.M. de Roos (2001) <doi:10.1142/S0218202501001264>.\n    O.Diekmann, M.Gyllenberg & J.A.J.Metz (2003) <doi:10.1016/S0040-5809(02)00058-8>.\n    A.M. de Roos (2008) <doi:10.1111/j.1461-0248.2007.01121.x>.  "
  },
  {
    "id": 5740,
    "package_name": "PakPC",
    "title": "'shiny' App to Analyze Pakistan's Population Census Data",
    "description": "Provides tools for analyzing Pakistan's Population Censuses data via the 'PakPC2023' and 'PakPC2017' R packages. Designed for researchers, policymakers, and professionals, the app enables in-depth numerical and graphical analysis, including detailed cross-tabulations and insights. With diverse statistical models and visualization options, it supports informed decision-making in social and economic policy. This tool enhances users' ability to explore and interpret census data, providing valuable insights for effective planning and analysis across various fields.",
    "version": "0.3.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5923-1714>),\n  Muhammad Arfan Dilber [ctb],\n  Zahid Asghar [ctb]",
    "url": "https://myaseen208.com/PakPC/\nhttps://myaseen208.shinyapps.io/PakPC/\nhttps://CRAN.R-project.org/package=PakPC",
    "bug_reports": "https://github.com/myaseen208/PakPC/issues",
    "repository": "https://cran.r-project.org/package=PakPC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPC 'shiny' App to Analyze Pakistan's Population Census Data Provides tools for analyzing Pakistan's Population Censuses data via the 'PakPC2023' and 'PakPC2017' R packages. Designed for researchers, policymakers, and professionals, the app enables in-depth numerical and graphical analysis, including detailed cross-tabulations and insights. With diverse statistical models and visualization options, it supports informed decision-making in social and economic policy. This tool enhances users' ability to explore and interpret census data, providing valuable insights for effective planning and analysis across various fields.  "
  },
  {
    "id": 5741,
    "package_name": "PakPC2017",
    "title": "Pakistan Population Census 2017",
    "description": "Provides data sets and functions for exploration of Pakistan Population Census 2017 (<http://www.pbscensus.gov.pk/>).",
    "version": "1.0.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Arfan Dilber [ctb]",
    "url": "https://github.com/MYaseen208/PakPC2017",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPC2017",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPC2017 Pakistan Population Census 2017 Provides data sets and functions for exploration of Pakistan Population Census 2017 (<http://www.pbscensus.gov.pk/>).  "
  },
  {
    "id": 5742,
    "package_name": "PakPC2023",
    "title": "Pakistan Population Census 2023",
    "description": "Provides data sets and functions for exploration of Pakistan Population Census 2023 (<https://www.pbs.gov.pk/>).",
    "version": "0.2.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5923-1714>),\n  Muhammad Arfan Dilber [ctb],\n  Zahid Asghar [ctb]",
    "url": "https://github.com/myaseen208/PakPC2023\nhttps://myaseen208.com/PakPC2023/",
    "bug_reports": "https://github.com/myaseen208/PakPC2023/issues",
    "repository": "https://cran.r-project.org/package=PakPC2023",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPC2023 Pakistan Population Census 2023 Provides data sets and functions for exploration of Pakistan Population Census 2023 (<https://www.pbs.gov.pk/>).  "
  },
  {
    "id": 5743,
    "package_name": "PakPMICS2014Ch",
    "title": "Multiple Indicator Cluster Survey (MICS) 2014 Child\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and functions for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Child questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/MYaseen208/PakPMICS2014Ch",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2014Ch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2014Ch Multiple Indicator Cluster Survey (MICS) 2014 Child\nQuestionnaire Data for Punjab, Pakistan Provides data set and functions for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Child questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5744,
    "package_name": "PakPMICS2014HH",
    "title": "Multiple Indicator Cluster Survey (MICS) 2014 Household\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/MYaseen208/PakPMICS2014HH",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2014HH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2014HH Multiple Indicator Cluster Survey (MICS) 2014 Household\nQuestionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5745,
    "package_name": "PakPMICS2014HL",
    "title": "Multiple Indicator Cluster Survey (MICS) 2014 Household Listing\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey 2014 Household Listing questionnaire data for Punjab, Pakistan.",
    "version": "0.1.1",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/MYaseen208/PakPMICS2014HL",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2014HL",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2014HL Multiple Indicator Cluster Survey (MICS) 2014 Household Listing\nQuestionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey 2014 Household Listing questionnaire data for Punjab, Pakistan.  "
  },
  {
    "id": 5746,
    "package_name": "PakPMICS2014Wm",
    "title": "Multiple Indicator Cluster Survey (MICS) 2014 Women\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey 2014 Women (age 15-49 years) questionnaire data for Punjab, Pakistan.",
    "version": "0.1.1",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/MYaseen208/PakPMICS2014Wm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2014Wm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2014Wm Multiple Indicator Cluster Survey (MICS) 2014 Women\nQuestionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey 2014 Women (age 15-49 years) questionnaire data for Punjab, Pakistan.  "
  },
  {
    "id": 5747,
    "package_name": "PakPMICS2018",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Data for\nPunjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of SDG monitoring, as the survey produces information on 32 global SDG indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using Probability Proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household. ",
    "version": "1.2.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5923-1714>)",
    "url": "https://myaseen208.com/PakPMICS2018/\nhttps://CRAN.R-project.org/package=PakPMICS2018\nhttps://github.com/myaseen208/PakPMICS2018",
    "bug_reports": "https://github.com/myaseen208/PakPMICS2018/issues",
    "repository": "https://cran.r-project.org/package=PakPMICS2018",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018 Multiple Indicator Cluster Survey (MICS) 2017-18 Data for\nPunjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of SDG monitoring, as the survey produces information on 32 global SDG indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using Probability Proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household.   "
  },
  {
    "id": 5748,
    "package_name": "PakPMICS2018bh",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Birth History\nof Children Questionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Household questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of SDG monitoring, as the survey produces information on 32 global SDG indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using Probability Proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre]\n      , Muhammad Usman [ctb]",
    "url": "https://github.com/myaseen208/PakPMICS2018bh,\nhttps://myaseen208.github.io/PakPMICS2018bh/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2018bh",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018bh Multiple Indicator Cluster Survey (MICS) 2017-18 Birth History\nof Children Questionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Household questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of SDG monitoring, as the survey produces information on 32 global SDG indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using Probability Proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5749,
    "package_name": "PakPMICS2018fs",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Children Age\n5-17 Questionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Children Age 5-17 questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre], Muhammad Usman [ctb]",
    "url": "https://github.com/myaseen208/PakPMICS2018fs,\nhttps://myaseen208.github.io/PakPMICS2018fs/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2018fs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018fs Multiple Indicator Cluster Survey (MICS) 2017-18 Children Age\n5-17 Questionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Children Age 5-17 questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5750,
    "package_name": "PakPMICS2018hh",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Household\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Household questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/myaseen208/PakPMICS2018hh,\nhttps://myaseen208.github.io/PakPMICS2018hh/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2018hh",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018hh Multiple Indicator Cluster Survey (MICS) 2017-18 Household\nQuestionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Household questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5751,
    "package_name": "PakPMICS2018mm",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Maternal\nMortality Questionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Maternal Mortality questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/myaseen208/PakPMICS2018mm,\nhttps://myaseen208.github.io/PakPMICS2018mm/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2018mm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018mm Multiple Indicator Cluster Survey (MICS) 2017-18 Maternal\nMortality Questionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Maternal Mortality questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5752,
    "package_name": "PakPMICS2018mn",
    "title": "Multiple Indicator Cluster Survey (MICS) 2017-18 Men\nQuestionnaire Data for Punjab, Pakistan",
    "description": "Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Men questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).",
    "version": "0.1.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Usman [ctb]",
    "url": "https://github.com/myaseen208/PakPMICS2018mn,\nhttps://myaseen208.github.io/PakPMICS2018mn/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PakPMICS2018mn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PakPMICS2018mn Multiple Indicator Cluster Survey (MICS) 2017-18 Men\nQuestionnaire Data for Punjab, Pakistan Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2017-18 Men questionnaire data for Punjab, Pakistan. The results of the present survey are critically important for the purposes of Sustainable Development Goals (SDGs) monitoring, as the survey produces information on 32 global Sustainable Development Goals (SDGs) indicators. The data was collected from 53,840 households selected at the second stage with systematic random sampling out of a sample of 2,692 clusters selected using probability proportional to size sampling. Six questionnaires were used in the survey: (1) a household questionnaire to collect basic demographic information on all de jure household members (usual residents), the household, and the dwelling; (2) a water quality testing questionnaire administered in three households in each cluster of the sample; (3) a questionnaire for individual women administered in each household to all women age 15-49 years; (4) a questionnaire for individual men administered in every second household to all men age 15-49 years; (5) an under-5 questionnaire, administered to mothers (or caretakers) of all children under 5 living in the household; and (6) a questionnaire for children age 5-17 years, administered to the mother (or caretaker) of one randomly selected child age 5-17 years living in the household (<http://www.mics.unicef.org/surveys>).  "
  },
  {
    "id": 5805,
    "package_name": "PeruAPIs",
    "title": "Access Peruvian Data via Public APIs and Curated Datasets",
    "description": "Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Peru, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes \n    curated datasets focused on Peru, covering topics such as administrative \n    divisions, electoral data, demographics, biodiversity and educational classifications. \n    The package supports reproducible research and teaching by integrating reliable international \n    APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre] (ORCID:\n    <https://orcid.org/0009-0005-0744-854X>)",
    "url": "https://github.com/lightbluetitan/peruapis,\nhttps://lightbluetitan.github.io/peruapis/",
    "bug_reports": "https://github.com/lightbluetitan/peruapis/issues",
    "repository": "https://cran.r-project.org/package=PeruAPIs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PeruAPIs Access Peruvian Data via Public APIs and Curated Datasets Provides functions to access data from public RESTful APIs including \n    'Nager.Date', 'World Bank API', and 'REST Countries API', retrieving real-time or historical \n    data related to Peru, such as holidays, economic indicators, and international \n    demographic and geopolitical indicators. Additionally, the package includes \n    curated datasets focused on Peru, covering topics such as administrative \n    divisions, electoral data, demographics, biodiversity and educational classifications. \n    The package supports reproducible research and teaching by integrating reliable international \n    APIs and structured datasets from public, academic, and government sources. \n    For more information on the APIs, see: \n    'Nager.Date' <https://date.nager.at/Api>, \n    'World Bank API' <https://datahelpdesk.worldbank.org/knowledgebase/articles/889392>, \n    and 'REST Countries API' <https://restcountries.com/>.  "
  },
  {
    "id": 5829,
    "package_name": "PhysActBedRest",
    "title": "Marks Periods of 'Bedrest' in Actigraph Accelerometer Data",
    "description": "Contains a function to categorize accelerometer readings collected in free-living (e.g., for 24 hours/day for 7 days), preprocessed and compressed as counts (unit-less value) in a specified time period termed epoch (e.g., 1 minute) as either bedrest (sleep) or active.  The input is a matrix with a timestamp column and a column with number of counts per epoch. The output is the same dataframe with an additional column termed bedrest. In the bedrest column each line (epoch) contains a function-generated classification 'br' or 'a' denoting bedrest/sleep and activity, respectively.  The package is designed to be used after wear/nonwear marking function in the 'PhysicalActivity' package.  Version 1.1 adds preschool thresholds and corrects for possible errors in algorithm implementation.    ",
    "version": "1.1",
    "maintainer": "J. Dustin Tracy <tracy@chapman.edu>",
    "author": "J. Dustin Tracy, Zhiyi Xu, Sari Acra, Kong Y. Chen, Maciej S. Buchowski, Thomas Donnelly",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PhysActBedRest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PhysActBedRest Marks Periods of 'Bedrest' in Actigraph Accelerometer Data Contains a function to categorize accelerometer readings collected in free-living (e.g., for 24 hours/day for 7 days), preprocessed and compressed as counts (unit-less value) in a specified time period termed epoch (e.g., 1 minute) as either bedrest (sleep) or active.  The input is a matrix with a timestamp column and a column with number of counts per epoch. The output is the same dataframe with an additional column termed bedrest. In the bedrest column each line (epoch) contains a function-generated classification 'br' or 'a' denoting bedrest/sleep and activity, respectively.  The package is designed to be used after wear/nonwear marking function in the 'PhysicalActivity' package.  Version 1.1 adds preschool thresholds and corrects for possible errors in algorithm implementation.      "
  },
  {
    "id": 5830,
    "package_name": "PhysicalActivity",
    "title": "Process Accelerometer Data for Physical Activity Measurement",
    "description": "It provides a function \"wearingMarking\" for classification of monitor\n    wear and nonwear time intervals in accelerometer data collected to assess\n    physical activity. The package also contains functions for making plot for \n    accelerometer data and obtaining the summary of various information including \n    daily monitor wear time and the mean monitor wear time during valid days.      \n    \"deliveryPred\" and \"markDelivery\" can classify days for ActiGraph delivery by mail;\n    \"deliveryPreprocess\" can process accelerometry data for analysis by zeropadding incomplete \n    days and removing low activity days; \"markPAI\" can categorize physical activity\n    intensity level based on user-defined cut-points of accelerometer counts. It also\n    supports importing ActiGraph AGD files with \"readActigraph\" and \"queryActigraph\" functions.",
    "version": "0.2-4",
    "maintainer": "Leena Choi <leena.choi@Vanderbilt.Edu>",
    "author": "Leena Choi [aut, cre] (ORCID: <https://orcid.org/0000-0002-2544-7090>),\n  Cole Beck [aut] (ORCID: <https://orcid.org/0000-0002-6849-6255>),\n  Zhouwen Liu [aut],\n  Ryan Moore [aut],\n  Charles E. Matthews [aut],\n  Maciej S. Buchowski [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PhysicalActivity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PhysicalActivity Process Accelerometer Data for Physical Activity Measurement It provides a function \"wearingMarking\" for classification of monitor\n    wear and nonwear time intervals in accelerometer data collected to assess\n    physical activity. The package also contains functions for making plot for \n    accelerometer data and obtaining the summary of various information including \n    daily monitor wear time and the mean monitor wear time during valid days.      \n    \"deliveryPred\" and \"markDelivery\" can classify days for ActiGraph delivery by mail;\n    \"deliveryPreprocess\" can process accelerometry data for analysis by zeropadding incomplete \n    days and removing low activity days; \"markPAI\" can categorize physical activity\n    intensity level based on user-defined cut-points of accelerometer counts. It also\n    supports importing ActiGraph AGD files with \"readActigraph\" and \"queryActigraph\" functions.  "
  },
  {
    "id": 5832,
    "package_name": "PhytoIn",
    "title": "Vegetation Analysis and Forest Inventory",
    "description": "Provides functions and example datasets for phytosociological \n    analysis, forest inventory, biomass and carbon estimation, and visualization \n    of vegetation data. Includes functions to compute structural parameters \n    [phytoparam(), summary.param(), stats()], estimate above-ground biomass \n    and carbon [AGB()], stratify wood volume by diameter at breast height (DBH) \n    classes [stratvol()], generate collector and rarefaction curves [collector.curve(), \n    rarefaction()], and visualize basal areas on quadrat maps [BAplot(), including \n    rectangular plots and individual coordinates]. Several example datasets are provided \n    to demonstrate the functionality of these tools. For more details see FAO \n    (1981, ISBN:92-5-101132-X) \"Manual of forest inventory\", IBGE (2012, ISBN:9788524042720) \n    \"Manual t\u00e9cnico da vegeta\u00e7\u00e3o brasileira\" and Heringer et al. (2020) \"Phytosociology in \n    R: A routine to estimate phytosociological parameters\" <doi:10.22533/at.ed.3552009033>.",
    "version": "0.2.0",
    "maintainer": "Rodrigo Augusto Santinelo Pereira <raspereira@usp.br>",
    "author": "Rodrigo Augusto Santinelo Pereira [aut, cre]",
    "url": "https://github.com/PhytoIn/PhytoIn",
    "bug_reports": "https://github.com/PhytoIn/PhytoIn/issues",
    "repository": "https://cran.r-project.org/package=PhytoIn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PhytoIn Vegetation Analysis and Forest Inventory Provides functions and example datasets for phytosociological \n    analysis, forest inventory, biomass and carbon estimation, and visualization \n    of vegetation data. Includes functions to compute structural parameters \n    [phytoparam(), summary.param(), stats()], estimate above-ground biomass \n    and carbon [AGB()], stratify wood volume by diameter at breast height (DBH) \n    classes [stratvol()], generate collector and rarefaction curves [collector.curve(), \n    rarefaction()], and visualize basal areas on quadrat maps [BAplot(), including \n    rectangular plots and individual coordinates]. Several example datasets are provided \n    to demonstrate the functionality of these tools. For more details see FAO \n    (1981, ISBN:92-5-101132-X) \"Manual of forest inventory\", IBGE (2012, ISBN:9788524042720) \n    \"Manual t\u00e9cnico da vegeta\u00e7\u00e3o brasileira\" and Heringer et al. (2020) \"Phytosociology in \n    R: A routine to estimate phytosociological parameters\" <doi:10.22533/at.ed.3552009033>.  "
  },
  {
    "id": 5910,
    "package_name": "PracTools",
    "title": "Designing and Weighting Survey Samples",
    "description": "Functions and datasets to support Valliant, Dever, and Kreuter (2018), <doi:10.1007/978-3-319-93632-1>, \"Practical Tools for Designing and Weighting Survey Samples\". Contains functions for sample size calculation for survey samples using stratified or clustered one-, two-, and three-stage sample designs, and single-stage audit sample designs. Functions are included that will group geographic units accounting for distances apart and measures of size. Other functions compute variance components for multistage designs, sample sizes in two-phase designs, and a stopping rule for ending data collection. A number of example data sets are included.",
    "version": "1.7",
    "maintainer": "Richard Valliant <valliant@umich.edu>",
    "author": "Richard Valliant [aut, cre],\n  Jill A. Dever [ctb],\n  Frauke Kreuter [ctb],\n  George Zipf [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PracTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PracTools Designing and Weighting Survey Samples Functions and datasets to support Valliant, Dever, and Kreuter (2018), <doi:10.1007/978-3-319-93632-1>, \"Practical Tools for Designing and Weighting Survey Samples\". Contains functions for sample size calculation for survey samples using stratified or clustered one-, two-, and three-stage sample designs, and single-stage audit sample designs. Functions are included that will group geographic units accounting for distances apart and measures of size. Other functions compute variance components for multistage designs, sample sizes in two-phase designs, and a stopping rule for ending data collection. A number of example data sets are included.  "
  },
  {
    "id": 5952,
    "package_name": "PropClust",
    "title": "Propensity Clustering and Decomposition",
    "description": "Implementation of propensity clustering and\n        decomposition as described in Ranola et al. (2013) <doi:10.1186/1752-0509-7-21>. \n        Propensity decomposition can be viewed on the\n        one hand as a generalization of the eigenvector-based\n        approximation of correlation networks, and on the other hand as\n        a generalization of random multigraph models and\n        conformity-based decompositions.",
    "version": "1.4-7",
    "maintainer": "Peter Langfelder <Peter.Langfelder@gmail.com>",
    "author": "John Michael O Ranola, Kenneth Lange, Steve Horvath, Peter Langfelder",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=PropClust",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "PropClust Propensity Clustering and Decomposition Implementation of propensity clustering and\n        decomposition as described in Ranola et al. (2013) <doi:10.1186/1752-0509-7-21>. \n        Propensity decomposition can be viewed on the\n        one hand as a generalization of the eigenvector-based\n        approximation of correlation networks, and on the other hand as\n        a generalization of random multigraph models and\n        conformity-based decompositions.  "
  },
  {
    "id": 5983,
    "package_name": "QCA",
    "title": "Qualitative Comparative Analysis",
    "description": "An extensive set of functions to perform Qualitative Comparative Analysis:\n       crisp sets ('csQCA'), temporal ('tQCA'), multi-value ('mvQCA')\n       and fuzzy sets ('fsQCA'), using a GUI - graphical user interface.\n       'QCA' is a methodology that bridges the qualitative and quantitative\n       divide in social science research. It uses a Boolean minimization\n       algorithm, resulting in a minimal causal configuration associated\n       with a given phenomenon.",
    "version": "3.23",
    "maintainer": "Adrian Dusa <dusa.adrian@unibuc.ro>",
    "author": "Adrian Dusa [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-3525-9253>),\n  Ciprian Paduraru [ctb] (ORCID: <https://orcid.org/0000-0002-4518-374X>),\n  jQuery Foundation [cph] (jQuery library and jQuery UI library),\n  jQuery contributors [ctb, cph] (jQuery library; authors listed in\n    inst/gui/www/lib/jquery-AUTHORS.txt),\n  Vasil Dinkov [ctb, cph] (jquery.smartmenus.js library),\n  Dmitry Baranovskiy [ctb, cph] (raphael.js library),\n  Emmanuel Quentin [ctb, cph] (raphael.inline_text_editing.js library),\n  Jimmy Breck-McKye [ctb, cph] (raphael-paragraph.js library),\n  Alrik Thiem [aut] (from version 1.0-0 up to version 1.1-3)",
    "url": "https://github.com/dusadrian/QCA",
    "bug_reports": "https://github.com/dusadrian/QCA/issues",
    "repository": "https://cran.r-project.org/package=QCA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "QCA Qualitative Comparative Analysis An extensive set of functions to perform Qualitative Comparative Analysis:\n       crisp sets ('csQCA'), temporal ('tQCA'), multi-value ('mvQCA')\n       and fuzzy sets ('fsQCA'), using a GUI - graphical user interface.\n       'QCA' is a methodology that bridges the qualitative and quantitative\n       divide in social science research. It uses a Boolean minimization\n       algorithm, resulting in a minimal causal configuration associated\n       with a given phenomenon.  "
  },
  {
    "id": 6081,
    "package_name": "R6causal",
    "title": "R6 Class for Structural Causal Models",
    "description": "The implemented R6 class 'SCM' aims to simplify working with structural causal models. The missing data mechanism can be defined as a part of the structural model. The class contains methods for 1) defining a structural causal model via functions, text or conditional probability tables, 2) printing basic information on the model, 3) plotting the graph for the model using packages 'igraph' or 'qgraph', 4) simulating data from the model, 5) applying an intervention, 6) checking the identifiability of a query using the R packages 'causaleffect' and 'dosearch', 7) defining the missing data mechanism, 8) simulating incomplete data from the model according to the specified missing data mechanism and 9) checking the identifiability in a missing data problem using the R package 'dosearch'. In addition, there are functions for running experiments and doing counterfactual inference using simulation.",
    "version": "0.8.3",
    "maintainer": "Juha Karvanen <juha.karvanen@iki.fi>",
    "author": "Juha Karvanen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5530-769X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=R6causal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "R6causal R6 Class for Structural Causal Models The implemented R6 class 'SCM' aims to simplify working with structural causal models. The missing data mechanism can be defined as a part of the structural model. The class contains methods for 1) defining a structural causal model via functions, text or conditional probability tables, 2) printing basic information on the model, 3) plotting the graph for the model using packages 'igraph' or 'qgraph', 4) simulating data from the model, 5) applying an intervention, 6) checking the identifiability of a query using the R packages 'causaleffect' and 'dosearch', 7) defining the missing data mechanism, 8) simulating incomplete data from the model according to the specified missing data mechanism and 9) checking the identifiability in a missing data problem using the R package 'dosearch'. In addition, there are functions for running experiments and doing counterfactual inference using simulation.  "
  },
  {
    "id": 6084,
    "package_name": "RADanalysis",
    "title": "Normalization and Analysis of Rank Abundance Distributions",
    "description": "Implementation of the MaxRank normalization method, which enables \n     standardization of Rank Abundance Distributions (RADs) to a specified \n     number of ranks. Rank abundance distributions are widely used in biology \n     and ecology to describe species abundances, and are mathematically \n     equivalent to complementary cumulative distribution functions (CCDFs) used \n     in physics, linguistics, sociology, and other fields. The method is \n     described in Saeedghalati et al. (2017) <doi:10.1371/journal.pcbi.1005362>.",
    "version": "1.0.1",
    "maintainer": "Mohmmadkarim Saeedghalati <arsham@gmail.com>",
    "author": "Mohmmadkarim Saeedghalati [aut, cre],\n  Farnoush Farahpour [aut],\n  Daniel Hoffmann [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RADanalysis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RADanalysis Normalization and Analysis of Rank Abundance Distributions Implementation of the MaxRank normalization method, which enables \n     standardization of Rank Abundance Distributions (RADs) to a specified \n     number of ranks. Rank abundance distributions are widely used in biology \n     and ecology to describe species abundances, and are mathematically \n     equivalent to complementary cumulative distribution functions (CCDFs) used \n     in physics, linguistics, sociology, and other fields. The method is \n     described in Saeedghalati et al. (2017) <doi:10.1371/journal.pcbi.1005362>.  "
  },
  {
    "id": 6089,
    "package_name": "RALSA",
    "title": "R Analyzer for Large-Scale Assessments",
    "description": "\n    Download, prepare and analyze data from large-scale assessments and\n    surveys with complex sampling and assessment design (see 'Rutkowski',\n    2010 <doi:10.3102/0013189X10363170>). Such studies are, for example,\n    international assessments like 'TIMSS', 'PIRLS' and 'PISA'. A graphical\n    interface is available for the non-technical user.The package includes\n    functions to covert the original data from 'SPSS' into 'R' data sets\n    keeping the user-defined missing values, merge data from different\n    respondents and/or countries, generate variable dictionaries, modify\n    data, produce descriptive statistics (percentages, means, percentiles,\n    benchmarks) and multivariate statistics (correlations, linear\n    regression, binary logistic regression). The number of supported\n    studies and analysis types will increase in future. For a general\n    presentation of the package, see 'Mirazchiyski', 2021a\n    (<doi:10.1186/s40536-021-00114-4>). For detailed technical aspects of\n    the package, see 'Mirazchiyski', 2021b (<doi:10.3390/psych3020018>).",
    "version": "1.6.0",
    "maintainer": "Plamen V. Mirazchiyski <plamen.mirazchiyski@ineri.org>",
    "author": "Plamen V. Mirazchiyski [aut, cre],\n  INERI [aut]",
    "url": "https://ralsa.ineri.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RALSA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RALSA R Analyzer for Large-Scale Assessments \n    Download, prepare and analyze data from large-scale assessments and\n    surveys with complex sampling and assessment design (see 'Rutkowski',\n    2010 <doi:10.3102/0013189X10363170>). Such studies are, for example,\n    international assessments like 'TIMSS', 'PIRLS' and 'PISA'. A graphical\n    interface is available for the non-technical user.The package includes\n    functions to covert the original data from 'SPSS' into 'R' data sets\n    keeping the user-defined missing values, merge data from different\n    respondents and/or countries, generate variable dictionaries, modify\n    data, produce descriptive statistics (percentages, means, percentiles,\n    benchmarks) and multivariate statistics (correlations, linear\n    regression, binary logistic regression). The number of supported\n    studies and analysis types will increase in future. For a general\n    presentation of the package, see 'Mirazchiyski', 2021a\n    (<doi:10.1186/s40536-021-00114-4>). For detailed technical aspects of\n    the package, see 'Mirazchiyski', 2021b (<doi:10.3390/psych3020018>).  "
  },
  {
    "id": 6166,
    "package_name": "REDCapDM",
    "title": "'REDCap' Data Management",
    "description": "REDCap Data Management - 'REDCap' (Research Electronic Data CAPture; <https://projectredcap.org>) is a web application developed at Vanderbilt University, designed for creating and managing online surveys and databases and the REDCap API is an interface that allows external applications to connect to REDCap remotely, and is used to programmatically retrieve or modify project data or settings within REDCap, such as importing or exporting data. REDCapDM is an R package that allows users to manage data exported directly from REDCap or using an API connection. This package includes several functions designed for pre-processing data, generating reports of queries such as outliers or missing values, and following up on previously identified queries. ",
    "version": "1.0.0",
    "maintainer": "Jo\u00e3o Carmezim <jcarmezim@igtp.cat>",
    "author": "Jo\u00e3o Carmezim [aut, cre],\n  Pau Satorra [aut],\n  Judith Pe\u00f1afiel [aut],\n  Esther Garc\u00eda [aut],\n  Nat\u00e0lia Pallar\u00e8s [aut],\n  Cristian Teb\u00e9 [aut]",
    "url": "https://bruigtp.github.io/REDCapDM/,\nhttps://doi.org/10.1186/s12874-024-02178-6",
    "bug_reports": "https://github.com/bruigtp/REDCapDM/issues",
    "repository": "https://cran.r-project.org/package=REDCapDM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REDCapDM 'REDCap' Data Management REDCap Data Management - 'REDCap' (Research Electronic Data CAPture; <https://projectredcap.org>) is a web application developed at Vanderbilt University, designed for creating and managing online surveys and databases and the REDCap API is an interface that allows external applications to connect to REDCap remotely, and is used to programmatically retrieve or modify project data or settings within REDCap, such as importing or exporting data. REDCapDM is an R package that allows users to manage data exported directly from REDCap or using an API connection. This package includes several functions designed for pre-processing data, generating reports of queries such as outliers or missing values, and following up on previously identified queries.   "
  },
  {
    "id": 6168,
    "package_name": "REDCapR",
    "title": "Interaction Between R and REDCap",
    "description": "Encapsulates functions to streamline calls from R to the REDCap\n    API.  REDCap (Research Electronic Data CAPture) is a web application for\n    building and managing online surveys and databases developed at Vanderbilt\n    University.  The Application Programming Interface (API) offers an avenue\n    to access and modify data programmatically, improving the capacity for\n    literate and reproducible programming.",
    "version": "1.6.0",
    "maintainer": "Will Beasley <wibeasley@hotmail.com>",
    "author": "Will Beasley [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5613-5006>),\n  David Bard [ctb] (ORCID: <https://orcid.org/0000-0002-3922-8489>),\n  Thomas Wilson [ctb],\n  John J Aponte [ctb],\n  Rollie Parrish [ctb] (ORCID: <https://orcid.org/0000-0001-8858-6381>),\n  Benjamin Nutter [ctb],\n  Andrew Peters [ctb] (ORCID: <https://orcid.org/0000-0003-2487-1268>),\n  Hao Zhu [ctb] (ORCID: <https://orcid.org/0000-0002-3386-6076>),\n  Janosch Linkersd\u00f6rfer [ctb] (ORCID:\n    <https://orcid.org/0000-0002-1577-1233>),\n  Jonathan Mang [ctb] (ORCID: <https://orcid.org/0000-0003-0518-4710>),\n  Felix Torres [ctb],\n  Philip Chase [ctb] (ORCID: <https://orcid.org/0000-0002-5318-9420>),\n  Victor Castro [ctb] (ORCID: <https://orcid.org/0000-0001-7390-6354>),\n  Greg Botwin [ctb],\n  Stephan Kadauke [ctb] (ORCID: <https://orcid.org/0000-0003-2996-8034>),\n  Ezra Porter [ctb] (ORCID: <https://orcid.org/0000-0002-4690-8343>),\n  Matthew Schuelke [ctb] (ORCID: <https://orcid.org/0000-0001-5755-1725>)",
    "url": "https://ouhscbbmc.github.io/REDCapR/,\nhttps://github.com/OuhscBbmc/REDCapR,\nhttps://www.ouhsc.edu/bbmc/, https://projectredcap.org",
    "bug_reports": "https://github.com/OuhscBbmc/REDCapR/issues",
    "repository": "https://cran.r-project.org/package=REDCapR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "REDCapR Interaction Between R and REDCap Encapsulates functions to streamline calls from R to the REDCap\n    API.  REDCap (Research Electronic Data CAPture) is a web application for\n    building and managing online surveys and databases developed at Vanderbilt\n    University.  The Application Programming Interface (API) offers an avenue\n    to access and modify data programmatically, improving the capacity for\n    literate and reproducible programming.  "
  },
  {
    "id": 6220,
    "package_name": "RGraphSpace",
    "title": "A Lightweight Interface Between 'igraph' and 'ggplot2' Graphics",
    "description": "Interface to integrate 'igraph' and 'ggplot2' graphics in a normalized coordinate system. 'RGraphSpace' implements new geometric objects using 'ggplot2' prototypes, customized for side-by-side visualization of multiple graphs. By scaling shapes and graph elements, 'RGraphSpace' can provide a framework for layered visualizations.",
    "version": "1.1.0",
    "maintainer": "Mauro Castro <mauro.a.castro@gmail.com>",
    "author": "Victor Apolonio [ctb],\n  Vinicius Chagas [ctb],\n  Mauro Castro [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4942-8131>)",
    "url": "https://github.com/sysbiolab/RGraphSpace",
    "bug_reports": "https://github.com/sysbiolab/RGraphSpace/issues",
    "repository": "https://cran.r-project.org/package=RGraphSpace",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RGraphSpace A Lightweight Interface Between 'igraph' and 'ggplot2' Graphics Interface to integrate 'igraph' and 'ggplot2' graphics in a normalized coordinate system. 'RGraphSpace' implements new geometric objects using 'ggplot2' prototypes, customized for side-by-side visualization of multiple graphs. By scaling shapes and graph elements, 'RGraphSpace' can provide a framework for layered visualizations.  "
  },
  {
    "id": 6271,
    "package_name": "RM.weights",
    "title": "Weighted Rasch Modeling and Extensions using Conditional Maximum\nLikelihood",
    "description": "Rasch model and extensions for survey data, using Conditional Maximum likelihood (CML). Carlo Cafiero, Sara Viviani, Mark Nord (2018) <doi:10.1016/j.measurement.2017.10.065>.",
    "version": "2.0",
    "maintainer": "Sara Viviani <sara.viviani@yahoo.it>",
    "author": "Carlo Cafiero, Sara Viviani, Mark Nord ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RM.weights",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RM.weights Weighted Rasch Modeling and Extensions using Conditional Maximum\nLikelihood Rasch model and extensions for survey data, using Conditional Maximum likelihood (CML). Carlo Cafiero, Sara Viviani, Mark Nord (2018) <doi:10.1016/j.measurement.2017.10.065>.  "
  },
  {
    "id": 6276,
    "package_name": "RMCLab",
    "title": "Lab for Matrix Completion and Imputation of Discrete Rating Data",
    "description": "Collection of methods for rating matrix completion, which is a statistical framework for recommender systems. Another relevant application is the imputation of rating-scale survey data in the social and behavioral sciences. Note that matrix completion and imputation are synonymous terms used in different streams of the literature. The main functionality implements robust matrix completion for discrete rating-scale data with a low-rank constraint on a latent continuous matrix (Archimbaud, Alfons, and Wilms (2025) <doi:10.48550/arXiv.2412.20802>). In addition, the package provides wrapper functions for 'softImpute' (Mazumder, Hastie, and Tibshirani, 2010, <https://www.jmlr.org/papers/v11/mazumder10a.html>; Hastie, Mazumder, Lee, Zadeh, 2015, <https://www.jmlr.org/papers/v16/hastie15a.html>) for easy tuning of the regularization parameter, as well as benchmark methods such as median imputation and mode imputation.",
    "version": "0.1.0",
    "maintainer": "Andreas Alfons <alfons@ese.eur.nl>",
    "author": "Andreas Alfons [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2513-3788>),\n  Aurore Archimbaud [aut] (ORCID:\n    <https://orcid.org/0000-0002-6511-9091>)",
    "url": "https://github.com/aalfons/RMCLab",
    "bug_reports": "https://github.com/aalfons/RMCLab/issues",
    "repository": "https://cran.r-project.org/package=RMCLab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RMCLab Lab for Matrix Completion and Imputation of Discrete Rating Data Collection of methods for rating matrix completion, which is a statistical framework for recommender systems. Another relevant application is the imputation of rating-scale survey data in the social and behavioral sciences. Note that matrix completion and imputation are synonymous terms used in different streams of the literature. The main functionality implements robust matrix completion for discrete rating-scale data with a low-rank constraint on a latent continuous matrix (Archimbaud, Alfons, and Wilms (2025) <doi:10.48550/arXiv.2412.20802>). In addition, the package provides wrapper functions for 'softImpute' (Mazumder, Hastie, and Tibshirani, 2010, <https://www.jmlr.org/papers/v11/mazumder10a.html>; Hastie, Mazumder, Lee, Zadeh, 2015, <https://www.jmlr.org/papers/v16/hastie15a.html>) for easy tuning of the regularization parameter, as well as benchmark methods such as median imputation and mode imputation.  "
  },
  {
    "id": 6379,
    "package_name": "RRTCS",
    "title": "Randomized Response Techniques for Complex Surveys",
    "description": "Point and interval estimation of linear parameters with data\n    obtained from complex surveys (including stratified and clustered samples)\n    when randomization techniques are used. The randomized response technique\n    was developed to obtain estimates that are more valid when studying\n    sensitive topics. Estimators and variances for 14 randomized response\n    methods for qualitative variables and 7 randomized response methods for\n    quantitative variables are also implemented. In addition, some data sets\n    from surveys with these randomization methods are included in the package.",
    "version": "0.0.4",
    "maintainer": "Beatriz Cobo Rodr\u00edguez <beacr@ugr.es>",
    "author": "Beatriz Cobo Rodr\u00edguez, Mar\u00eda del Mar Rueda Garc\u00eda, Antonio Arcos\n    Cebri\u00e1n",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RRTCS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RRTCS Randomized Response Techniques for Complex Surveys Point and interval estimation of linear parameters with data\n    obtained from complex surveys (including stratified and clustered samples)\n    when randomization techniques are used. The randomized response technique\n    was developed to obtain estimates that are more valid when studying\n    sensitive topics. Estimators and variances for 14 randomized response\n    methods for qualitative variables and 7 randomized response methods for\n    quantitative variables are also implemented. In addition, some data sets\n    from surveys with these randomization methods are included in the package.  "
  },
  {
    "id": 6385,
    "package_name": "RRreg",
    "title": "Correlation and Regression Analyses for Randomized Response Data",
    "description": "\n    Univariate and multivariate methods to analyze randomized response \n    (RR) survey designs (e.g., Warner, S. L. (1965). Randomized response: A \n    survey technique for eliminating evasive answer bias. Journal of the \n    American Statistical Association, 60, 63\u201369, <doi:10.2307/2283137>). \n    Besides univariate estimates of true proportions, RR variables can be used \n    for correlations, as dependent variable in a logistic regression (with or \n    without random effects), or as predictors in a linear regression\n    (Heck, D. W., & Moshagen, M. (2018). RRreg: An R package for correlation and \n    regression analyses of randomized response data. Journal of Statistical \n    Software, 85(2), 1\u201329, <doi:10.18637/jss.v085.i02>). For simulations and \n    the estimation of statistical power, RR data can be generated according to \n    several models. The implemented methods also allow to test the link between \n    continuous covariates and dishonesty in cheating paradigms such as the \n    coin-toss or dice-roll task (Moshagen, M., & Hilbig, B. E. (2017). \n    The statistical analysis of cheating paradigms. Behavior Research Methods, \n    49, 724\u2013732, <doi:10.3758/s13428-016-0729-x>).",
    "version": "0.7.6",
    "maintainer": "Daniel W. Heck <daniel.heck@uni-marburg.de>",
    "author": "Daniel W. Heck [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-6302-9252>),\n  Morten Moshagen [ctb]",
    "url": "https://github.com/danheck/RRreg",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RRreg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RRreg Correlation and Regression Analyses for Randomized Response Data \n    Univariate and multivariate methods to analyze randomized response \n    (RR) survey designs (e.g., Warner, S. L. (1965). Randomized response: A \n    survey technique for eliminating evasive answer bias. Journal of the \n    American Statistical Association, 60, 63\u201369, <doi:10.2307/2283137>). \n    Besides univariate estimates of true proportions, RR variables can be used \n    for correlations, as dependent variable in a logistic regression (with or \n    without random effects), or as predictors in a linear regression\n    (Heck, D. W., & Moshagen, M. (2018). RRreg: An R package for correlation and \n    regression analyses of randomized response data. Journal of Statistical \n    Software, 85(2), 1\u201329, <doi:10.18637/jss.v085.i02>). For simulations and \n    the estimation of statistical power, RR data can be generated according to \n    several models. The implemented methods also allow to test the link between \n    continuous covariates and dishonesty in cheating paradigms such as the \n    coin-toss or dice-roll task (Moshagen, M., & Hilbig, B. E. (2017). \n    The statistical analysis of cheating paradigms. Behavior Research Methods, \n    49, 724\u2013732, <doi:10.3758/s13428-016-0729-x>).  "
  },
  {
    "id": 6411,
    "package_name": "RSiena",
    "title": "Siena - Simulation Investigation for Empirical Network Analysis",
    "description": "The main purpose of this package is to perform simulation-based\n   estimation of stochastic actor-oriented models for longitudinal network\n   data collected as panel data. Dependent variables can be single or\n   multivariate networks, which can be directed, non-directed, or two-mode;\n   and associated actor variables.\n   There are also functions for testing parameters and checking goodness of fit.\n   An overview of these models is given in Snijders (2017),\n   <doi:10.1146/annurev-statistics-060116-054035>.",
    "version": "1.5.0",
    "maintainer": "Christian Steglich <c.e.g.steglich@rug.nl>",
    "author": "Tom A.B. Snijders [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-3157-4157>),\n  Ruth M. Ripley [aut],\n  Krists Boitmanis [aut, ctb],\n  Christian Steglich [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-9097-0873>),\n  Johan Koskinen [ctb] (ORCID: <https://orcid.org/0000-0002-6860-325X>),\n  Nynke M.D. Niezink [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-4199-4841>),\n  Viviana Amati [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-1190-1237>),\n  Christoph Stadtfeld [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2704-2134>),\n  James Hollway [ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0002-8361-9647>),\n  Per Block [ctb] (ORCID: <https://orcid.org/0000-0002-7583-2392>),\n  Robert Krause [ctb] (ORCID: <https://orcid.org/0000-0003-4288-4732>),\n  Charlotte Greenan [ctb],\n  Josh Lospinoso [ctb],\n  Michael Schweinberger [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3649-5386>),\n  Mark Huisman [ctb] (ORCID: <https://orcid.org/0000-0002-9009-7859>),\n  Felix Schoenenberger [aut, ctb],\n  Mark Ortmann [ctb],\n  Marion Hoffman [ctb] (ORCID: <https://orcid.org/0000-0002-0741-7760>),\n  Robert Hellpap [ctb],\n  Alvaro Uzaheta [ctb] (ORCID: <https://orcid.org/0000-0003-4367-3670>),\n  Steffen Triebel [ctb]",
    "url": "https://www.stats.ox.ac.uk/~snijders/siena/",
    "bug_reports": "https://github.com/stocnet/rsiena/issues",
    "repository": "https://cran.r-project.org/package=RSiena",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSiena Siena - Simulation Investigation for Empirical Network Analysis The main purpose of this package is to perform simulation-based\n   estimation of stochastic actor-oriented models for longitudinal network\n   data collected as panel data. Dependent variables can be single or\n   multivariate networks, which can be directed, non-directed, or two-mode;\n   and associated actor variables.\n   There are also functions for testing parameters and checking goodness of fit.\n   An overview of these models is given in Snijders (2017),\n   <doi:10.1146/annurev-statistics-060116-054035>.  "
  },
  {
    "id": 6421,
    "package_name": "RSurveillance",
    "title": "Design and Analysis of Disease Surveillance Activities",
    "description": "A range of functions for the design and\n    analysis of disease surveillance activities. These functions were\n    originally developed for animal health surveillance activities but can be\n    equally applied to aquatic animal, wildlife, plant and human health\n    surveillance activities. Utilities are included for sample size calculation\n    and analysis of representative surveys for disease freedom, risk-based\n    studies for disease freedom and for prevalence estimation.\n    This package is based on Cameron A., Conraths F., Frohlich A., Schauer B.,\n    Schulz K., Sergeant E., Sonnenburg J., Staubach C. (2015). R package of \n    functions for risk-based surveillance. Deliverable 6.24, WP 6 - Decision \n    making tools for implementing risk-based surveillance, Grant Number \n    no. 310806, RISKSUR (<https://www.fp7-risksur.eu/sites/default/files/documents/Deliverables/RISKSUR_%28310806%29_D6.24.pdf>). \n    Many of the 'RSurveillance' functions are incorporated into the 'epitools'\n    website: Sergeant, ESG, 2019. Epitools epidemiological calculators. \n    Ausvet Pty Ltd. Available at: <http://epitools.ausvet.com.au>.",
    "version": "0.2.1",
    "maintainer": "Rohan Sadler <rohan.sadler@ausvet.com.au>",
    "author": "Evan Sergeant",
    "url": "https://github.com/roStats/RSurveillance",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RSurveillance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RSurveillance Design and Analysis of Disease Surveillance Activities A range of functions for the design and\n    analysis of disease surveillance activities. These functions were\n    originally developed for animal health surveillance activities but can be\n    equally applied to aquatic animal, wildlife, plant and human health\n    surveillance activities. Utilities are included for sample size calculation\n    and analysis of representative surveys for disease freedom, risk-based\n    studies for disease freedom and for prevalence estimation.\n    This package is based on Cameron A., Conraths F., Frohlich A., Schauer B.,\n    Schulz K., Sergeant E., Sonnenburg J., Staubach C. (2015). R package of \n    functions for risk-based surveillance. Deliverable 6.24, WP 6 - Decision \n    making tools for implementing risk-based surveillance, Grant Number \n    no. 310806, RISKSUR (<https://www.fp7-risksur.eu/sites/default/files/documents/Deliverables/RISKSUR_%28310806%29_D6.24.pdf>). \n    Many of the 'RSurveillance' functions are incorporated into the 'epitools'\n    website: Sergeant, ESG, 2019. Epitools epidemiological calculators. \n    Ausvet Pty Ltd. Available at: <http://epitools.ausvet.com.au>.  "
  },
  {
    "id": 6487,
    "package_name": "RapidPolygonLookup",
    "title": "POLYGON LOOKUP USING KD TREES",
    "description": "Facilitates efficient polygon search using kd trees.\n    Coordinate level spatial data can be aggregated to higher geographical\n    identities like census blocks, ZIP codes or police district boundaries.\n    This process requires mapping each point in the given data set to a\n    particular identity of the desired geographical hierarchy. Unless efficient\n    data structures are used, this can be a daunting task. The operation\n    point.in.polygon() from the package sp is computationally expensive.\n    Here, we exploit kd-trees as efficient nearest neighbor search algorithm\n    to dramatically reduce the effective number of polygons being searched.",
    "version": "0.1.1",
    "maintainer": "Markus Loecher <markus.loecher@gmail.com>",
    "author": "Markus Loecher <markus.loecher@gmail.com> and Madhav Kumar <madhavkumar2005@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RapidPolygonLookup",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RapidPolygonLookup POLYGON LOOKUP USING KD TREES Facilitates efficient polygon search using kd trees.\n    Coordinate level spatial data can be aggregated to higher geographical\n    identities like census blocks, ZIP codes or police district boundaries.\n    This process requires mapping each point in the given data set to a\n    particular identity of the desired geographical hierarchy. Unless efficient\n    data structures are used, this can be a daunting task. The operation\n    point.in.polygon() from the package sp is computationally expensive.\n    Here, we exploit kd-trees as efficient nearest neighbor search algorithm\n    to dramatically reduce the effective number of polygons being searched.  "
  },
  {
    "id": 6508,
    "package_name": "Rcapture",
    "title": "Loglinear Models for Capture-Recapture Experiments",
    "description": "Estimation of abundance and other demographic parameters for closed \n             populations, open populations and the robust design in capture-recapture  \n             experiments using loglinear models.   ",
    "version": "1.4-4",
    "maintainer": "Louis-Paul Rivest <Louis-Paul.Rivest@mat.ulaval.ca>",
    "author": "Louis-Paul Rivest [aut, cre],\n  Sophie Baillargeon [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rcapture",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rcapture Loglinear Models for Capture-Recapture Experiments Estimation of abundance and other demographic parameters for closed \n             populations, open populations and the robust design in capture-recapture  \n             experiments using loglinear models.     "
  },
  {
    "id": 6511,
    "package_name": "RcensusPkg",
    "title": "Easily Access US Census Bureau Survey and Geographic Data",
    "description": "The key function 'get_vintage_data()' returns a dataframe and is \n    the window into the Census Bureau API requiring just a dataset name, \n    vintage(year), and vector of variable names for survey estimates/percentages. \n    Other functions assist in searching for available datasets, geographies, \n    group/variable concepts of interest.  Also provided are functions to access \n    and layer (via standard piping) displayable geometries for the US, states, \n    counties, blocks/tracts, roads, landmarks, places, and bodies of water. \n    Joining survey data with many of the geometry functions is built-in to \n    produce choropleth maps.",
    "version": "0.1.5",
    "maintainer": "Rick Dean <deanr3@bardstown.com>",
    "author": "Rick Dean [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0005-8086-8436>)",
    "url": "https://github.com/deandevl/RcensusPkg",
    "bug_reports": "https://github.com/deandevl/RcensusPkg/issues",
    "repository": "https://cran.r-project.org/package=RcensusPkg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcensusPkg Easily Access US Census Bureau Survey and Geographic Data The key function 'get_vintage_data()' returns a dataframe and is \n    the window into the Census Bureau API requiring just a dataset name, \n    vintage(year), and vector of variable names for survey estimates/percentages. \n    Other functions assist in searching for available datasets, geographies, \n    group/variable concepts of interest.  Also provided are functions to access \n    and layer (via standard piping) displayable geometries for the US, states, \n    counties, blocks/tracts, roads, landmarks, places, and bodies of water. \n    Joining survey data with many of the geometry functions is built-in to \n    produce choropleth maps.  "
  },
  {
    "id": 6518,
    "package_name": "RcmdrPlugin.BWS1",
    "title": "R Commander Plug-in for Case 1 Best-Worst Scaling",
    "description": "Adds menu items to the R Commander for implementing case 1 (object case) best-worst scaling (BWS1) from designing choice sets to measuring preferences for items. BWS1 is a question-based survey method that constructs various combinations of items (choice sets) using the experimental designs, asks respondents to select the best and worst items in each choice set, and then measures preferences for the items by analyzing the responses. For details, refer to Aizaki and Fogarty (2023) <doi:10.1016/j.jocm.2022.100394>.",
    "version": "0.3-0",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki [aut, cre]",
    "url": "https://sites.google.com/view/r4sp/rcmdrplugin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.BWS1",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.BWS1 R Commander Plug-in for Case 1 Best-Worst Scaling Adds menu items to the R Commander for implementing case 1 (object case) best-worst scaling (BWS1) from designing choice sets to measuring preferences for items. BWS1 is a question-based survey method that constructs various combinations of items (choice sets) using the experimental designs, asks respondents to select the best and worst items in each choice set, and then measures preferences for the items by analyzing the responses. For details, refer to Aizaki and Fogarty (2023) <doi:10.1016/j.jocm.2022.100394>.  "
  },
  {
    "id": 6519,
    "package_name": "RcmdrPlugin.BWS2",
    "title": "R Commander Plug-in for Case 2 Best-Worst Scaling",
    "description": "Adds menu items for case 2 (profile case) best-worst scaling (BWS2) to the R Commander. BWS2 is a question-based survey method that constructs profiles (combinations of attribute levels) using an orthogonal array, asks respondents to select the best and worst levels in each profile, and measures preferences for attribute levels by analyzing the responses. For details, see Aizaki and Fogarty (2019) <doi:10.1016/j.jocm.2019.100171>.",
    "version": "0.3-0",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki [aut, cre]",
    "url": "https://sites.google.com/view/r4sp/rcmdrplugin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.BWS2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.BWS2 R Commander Plug-in for Case 2 Best-Worst Scaling Adds menu items for case 2 (profile case) best-worst scaling (BWS2) to the R Commander. BWS2 is a question-based survey method that constructs profiles (combinations of attribute levels) using an orthogonal array, asks respondents to select the best and worst levels in each profile, and measures preferences for attribute levels by analyzing the responses. For details, see Aizaki and Fogarty (2019) <doi:10.1016/j.jocm.2019.100171>.  "
  },
  {
    "id": 6520,
    "package_name": "RcmdrPlugin.BWS3",
    "title": "R Commander Plug-in for Case 3 Best-Worst Scaling",
    "description": "Adds menu items for case 3 (multi-profile) best-worst scaling (BWS3) to the R Commander. BWS3 is a question-based survey method that designs various combinations of attribute levels (profiles), asks respondents to select the best and worst profiles in each choice set, and then measures preferences for the attribute levels by analyzing the responses. For details on BWS3, refer to Louviere et al. (2015) <doi:10.1017/CBO9781107337855>.",
    "version": "0.3-1",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki [aut, cre]",
    "url": "https://sites.google.com/view/r4sp/rcmdrplugin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.BWS3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.BWS3 R Commander Plug-in for Case 3 Best-Worst Scaling Adds menu items for case 3 (multi-profile) best-worst scaling (BWS3) to the R Commander. BWS3 is a question-based survey method that designs various combinations of attribute levels (profiles), asks respondents to select the best and worst profiles in each choice set, and then measures preferences for the attribute levels by analyzing the responses. For details on BWS3, refer to Louviere et al. (2015) <doi:10.1017/CBO9781107337855>.  "
  },
  {
    "id": 6521,
    "package_name": "RcmdrPlugin.DCCV",
    "title": "R Commander Plug-in for Dichotomous Choice Contingent Valuation",
    "description": "Adds menu items to the R Commander for parametric analysis of dichotomous choice contingent valuation (DCCV) data. CV is a question-based survey method to elicit individuals' preferences for goods and services. This package depends on functions regarding parametric DCCV analysis in the package DCchoice. See Carson and Hanemann (2005) <doi:10.1016/S1574-0099(05)02017-6> for DCCV.",
    "version": "0.2-0",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki [aut, cre]",
    "url": "https://sites.google.com/view/r4sp/rcmdrplugin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.DCCV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.DCCV R Commander Plug-in for Dichotomous Choice Contingent Valuation Adds menu items to the R Commander for parametric analysis of dichotomous choice contingent valuation (DCCV) data. CV is a question-based survey method to elicit individuals' preferences for goods and services. This package depends on functions regarding parametric DCCV analysis in the package DCchoice. See Carson and Hanemann (2005) <doi:10.1016/S1574-0099(05)02017-6> for DCCV.  "
  },
  {
    "id": 6522,
    "package_name": "RcmdrPlugin.DCE",
    "title": "R Commander Plug-in for Discrete Choice Experiments",
    "description": "Adds menu items for discrete choice experiments (DCEs) to the R Commander. DCE is a question-based survey method that designs various combinations (profiles) of attribute levels using the experimental designs, asks respondents to select the most preferred profile in each choice set, and then measures preferences for the attribute levels by analyzing the responses. For details on DCEs, refer to Louviere et al. (2000) <doi:10.1017/CBO9780511753831>.",
    "version": "0.3-1",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki [aut, cre]",
    "url": "https://sites.google.com/view/r4sp/rcmdrplugin",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RcmdrPlugin.DCE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RcmdrPlugin.DCE R Commander Plug-in for Discrete Choice Experiments Adds menu items for discrete choice experiments (DCEs) to the R Commander. DCE is a question-based survey method that designs various combinations (profiles) of attribute levels using the experimental designs, asks respondents to select the most preferred profile in each choice set, and then measures preferences for the attribute levels by analyzing the responses. For details on DCEs, refer to Louviere et al. (2000) <doi:10.1017/CBO9780511753831>.  "
  },
  {
    "id": 6620,
    "package_name": "Rdistance",
    "title": "Density and Abundance from Distance-Sampling Surveys",
    "description": "Distance-sampling (<doi:10.1007/978-3-319-19219-2>) \n  is a field survey and analytical method that estimates density and \n  abundance of survey targets (e.g., animals) when \n  detection probability declines with observation distance. \n  Distance-sampling is popular in ecology, \n  especially when survey targets are observed from aerial platforms (e.g., \n  airplane or drone), surface vessels (e.g., boat or truck), or along \n  walking transects. Analysis involves fitting smooth (parametric) curves to \n  histograms of observation distances and using those functions to \n  adjust density estimates for missed targets.  Routines included here \n  fit curves to observation distance histograms, estimate effective \n  sampling area, density of targets in surveyed areas, and the abundance \n  of targets in a surrounding study area. Confidence interval estimation\n  uses built-in bootstrap resampling. Help files are extensive and have been \n  vetted by multiple authors. Many tutorials are available on the package's \n  website (URL below).",
    "version": "4.1.1",
    "maintainer": "Trent McDonald <trent@mcdonalddatasciences.com>",
    "author": "Trent McDonald [cre, aut],\n  Jason Carlisle [aut],\n  Aidan McDonald [aut] (point transect methods),\n  Ryan Nielson [ctb] (smoothed likelihood),\n  Ben Augustine [ctb] (maximization method),\n  James Griswald [ctb] (maximization method),\n  Patrick McKann [ctb] (maximization method),\n  Lacey Jeroue [ctb] (vignettes),\n  Hoffman Abigail [ctb] (vignettes),\n  Kleinsausser Michael [ctb] (vignettes),\n  Joel Reynolds [ctb] (Gamma likelihood),\n  Pham Quang [ctb] (Gamma likelihood),\n  Earl Becker [ctb] (Gamma likelihood),\n  Aaron Christ [ctb] (Gamma likelihood),\n  Brook Russelland [ctb] (Gamma likelihood),\n  Stefan Emmons [ctb] (Automated tests),\n  Will McDonald [ctb] (Automated tests),\n  Reid Olson [ctb] (Automated tests and bug fixes)",
    "url": "https://mcdonalddata.science/Rdistance.html",
    "bug_reports": "https://github.com/tmcd82070/Rdistance/issues",
    "repository": "https://cran.r-project.org/package=Rdistance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rdistance Density and Abundance from Distance-Sampling Surveys Distance-sampling (<doi:10.1007/978-3-319-19219-2>) \n  is a field survey and analytical method that estimates density and \n  abundance of survey targets (e.g., animals) when \n  detection probability declines with observation distance. \n  Distance-sampling is popular in ecology, \n  especially when survey targets are observed from aerial platforms (e.g., \n  airplane or drone), surface vessels (e.g., boat or truck), or along \n  walking transects. Analysis involves fitting smooth (parametric) curves to \n  histograms of observation distances and using those functions to \n  adjust density estimates for missed targets.  Routines included here \n  fit curves to observation distance histograms, estimate effective \n  sampling area, density of targets in surveyed areas, and the abundance \n  of targets in a surrounding study area. Confidence interval estimation\n  uses built-in bootstrap resampling. Help files are extensive and have been \n  vetted by multiple authors. Many tutorials are available on the package's \n  website (URL below).  "
  },
  {
    "id": 6681,
    "package_name": "ResIN",
    "title": "Response Item Networks",
    "description": "Contains various tools to perform and visualize Response Item Networks ('ResIN's'). 'ResIN' binarizes ordered-categorical and qualitative response choices from (survey) data, calculates pairwise associations and maps the location of each item response as a node in a force-directed network. Please refer to <https://www.resinmethod.net/> for more details.",
    "version": "2.2.1",
    "maintainer": "Philip Warncke <philip.warncke@ul.ie>",
    "author": "Philip Warncke [cre, aut],\n  Dino Carpentras [aut],\n  Adrian L\u00fcders [aut]",
    "url": "https://pwarncke77.github.io/ResIN/",
    "bug_reports": "https://github.com/pwarncke77/ResIN/issues",
    "repository": "https://cran.r-project.org/package=ResIN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ResIN Response Item Networks Contains various tools to perform and visualize Response Item Networks ('ResIN's'). 'ResIN' binarizes ordered-categorical and qualitative response choices from (survey) data, calculates pairwise associations and maps the location of each item response as a node in a force-directed network. Please refer to <https://www.resinmethod.net/> for more details.  "
  },
  {
    "id": 6764,
    "package_name": "RobPC",
    "title": "Robust Panel Clustering Algorithm",
    "description": "Performs both classical and robust panel clustering by applying Principal Component Analysis (PCA) for dimensionality reduction and clustering via standard K-Means or Trimmed K-Means. The method is designed to ensure stable and reliable clustering, even in the presence of outliers. Suitable for analyzing panel data in domains such as economic research, financial time-series, healthcare analytics, and social sciences. The package allows users to choose between classical K-Means for standard clustering and Trimmed K-Means for robust clustering, making it a flexible tool for various applications. For this package, we have benefited from the studies Rencher (2003), Wang and Lu (2021) <DOI:10.25236/AJBM.2021.031018>, Cuesta-Albertos et al. (1997) <https://www.jstor.org/stable/2242558?seq=1>.",
    "version": "1.4",
    "maintainer": "Hasan Bulut <hasan.bulut@omu.edu.tr>",
    "author": "Hasan Bulut [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=RobPC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "RobPC Robust Panel Clustering Algorithm Performs both classical and robust panel clustering by applying Principal Component Analysis (PCA) for dimensionality reduction and clustering via standard K-Means or Trimmed K-Means. The method is designed to ensure stable and reliable clustering, even in the presence of outliers. Suitable for analyzing panel data in domains such as economic research, financial time-series, healthcare analytics, and social sciences. The package allows users to choose between classical K-Means for standard clustering and Trimmed K-Means for robust clustering, making it a flexible tool for various applications. For this package, we have benefited from the studies Rencher (2003), Wang and Lu (2021) <DOI:10.25236/AJBM.2021.031018>, Cuesta-Albertos et al. (1997) <https://www.jstor.org/stable/2242558?seq=1>.  "
  },
  {
    "id": 6814,
    "package_name": "Rrepest",
    "title": "An Analyzer of International Large Scale Assessments in\nEducation",
    "description": "An easy way to analyze international large-scale assessments and surveys in education or any other dataset that includes replicated weights (Balanced Repeated Replication (BRR) weights, Jackknife replicate weights,...) while also allowing for analysis with multiply imputed variables (plausible values). It supports the estimation of univariate statistics (e.g. mean, variance, standard deviation, quantiles), frequencies, correlation, linear regression and any other model already implemented in R that takes a data frame and weights as parameters. It also includes  options to prepare the results for publication, following the table formatting standards of the Organization for Economic Cooperation and Development (OECD).",
    "version": "1.5.4",
    "maintainer": "Rodolfo Ilizaliturri <rodolfo.ilizaliturri@oecd.org>",
    "author": "Rodolfo Ilizaliturri [aut, cre],\n  Francesco Avvisati [aut],\n  Francois Keslair [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Rrepest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Rrepest An Analyzer of International Large Scale Assessments in\nEducation An easy way to analyze international large-scale assessments and surveys in education or any other dataset that includes replicated weights (Balanced Repeated Replication (BRR) weights, Jackknife replicate weights,...) while also allowing for analysis with multiply imputed variables (plausible values). It supports the estimation of univariate statistics (e.g. mean, variance, standard deviation, quantiles), frequencies, correlation, linear regression and any other model already implemented in R that takes a data frame and weights as parameters. It also includes  options to prepare the results for publication, following the table formatting standards of the Organization for Economic Cooperation and Development (OECD).  "
  },
  {
    "id": 6863,
    "package_name": "SAKERNAS",
    "title": "A National Labor Force Survey of Indonesia",
    "description": "Surveys to collect employment data so as to obtain data estimates on the number of employed people, the number of unemployed, and other employment indicators.",
    "version": "0.1.0",
    "maintainer": "Fadhlul Mubarak <mubarakfadhlul@gmail.com>",
    "author": "Fadhlul Mubarak [aut, cre],\n  Nurniswah [aut],\n  Vinny Yuliani Sundara [aut],\n  Arsyad Lubis [aut],\n  Ahmad Syukron Prasaja [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SAKERNAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SAKERNAS A National Labor Force Survey of Indonesia Surveys to collect employment data so as to obtain data estimates on the number of employed people, the number of unemployed, and other employment indicators.  "
  },
  {
    "id": 6894,
    "package_name": "SBSDiff",
    "title": "Satorra-Bentler Scaled Chi-Squared Difference Test",
    "description": "Calculates a Satorra-Bentler scaled chi-squared difference test between nested models that were estimated using maximum likelihood (ML) with robust standard errors, which cannot be calculated the traditional way. For details see Satorra & Bentler (2001) <doi:10.1007/bf02296192> and Satorra & Bentler (2010) <doi:10.1007/s11336-009-9135-y>. This package may be particularly helpful when used in conjunction with 'Mplus' software, specifically when implementing the complex survey option. In such cases, the model estimator in 'Mplus' defaults to ML with robust standard errors.    ",
    "version": "0.1.0",
    "maintainer": "Frank D. Mann <frankdmann@gmail.com>",
    "author": "Frank D. Mann <frankdmann@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SBSDiff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SBSDiff Satorra-Bentler Scaled Chi-Squared Difference Test Calculates a Satorra-Bentler scaled chi-squared difference test between nested models that were estimated using maximum likelihood (ML) with robust standard errors, which cannot be calculated the traditional way. For details see Satorra & Bentler (2001) <doi:10.1007/bf02296192> and Satorra & Bentler (2010) <doi:10.1007/s11336-009-9135-y>. This package may be particularly helpful when used in conjunction with 'Mplus' software, specifically when implementing the complex survey option. In such cases, the model estimator in 'Mplus' defaults to ML with robust standard errors.      "
  },
  {
    "id": 6927,
    "package_name": "SDAR",
    "title": "Stratigraphic Data Analysis",
    "description": "A fast, consistent tool for plotting and facilitating the analysis of stratigraphic\n    and sedimentological data. Taking advantage of the flexible plotting tools available in R, \n    'SDAR' uses stratigraphic and sedimentological data to produce detailed graphic logs for \n    outcrop sections and borehole logs. These logs can include multiple features (e.g., bed thickness,\n    lithology, samples, sedimentary structures, colors, fossil content, bioturbation index, \n    gamma ray logs) (Johnson, 1992, <ISSN 0037-0738>).",
    "version": "0.9-55",
    "maintainer": "John R. Ortiz <jrortizt@unal.edu.co>",
    "author": "John R. Ortiz [aut, cre],\n  Carlos Jaramillo [aut],\n  Carlos Moreno [ctb]",
    "url": "https://doi.org/10.25573/data.13118426.v2",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SDAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SDAR Stratigraphic Data Analysis A fast, consistent tool for plotting and facilitating the analysis of stratigraphic\n    and sedimentological data. Taking advantage of the flexible plotting tools available in R, \n    'SDAR' uses stratigraphic and sedimentological data to produce detailed graphic logs for \n    outcrop sections and borehole logs. These logs can include multiple features (e.g., bed thickness,\n    lithology, samples, sedimentary structures, colors, fossil content, bioturbation index, \n    gamma ray logs) (Johnson, 1992, <ISSN 0037-0738>).  "
  },
  {
    "id": 6996,
    "package_name": "SIPDIBGE",
    "title": "Collection of Household Survey Packages Conducted by IBGE",
    "description": "Provides access to packages developed for downloading, reading and analyzing\n  microdata from household surveys in Integrated System of Household Surveys - SIPD\n  conducted by Brazilian Institute of Geography and Statistics - IBGE.\n\tMore information can be obtained from the official website <https://www.ibge.gov.br/>.",
    "version": "0.2.1",
    "maintainer": "Gabriel Assuncao <pacotesipd@ibge.gov.br>",
    "author": "Gabriel Assuncao [aut, cre],\n  Luna Hidalgo [aut],\n  Douglas Braga [ctb],\n  Viviane Quintaes [ctb]",
    "url": "",
    "bug_reports": "https://github.com/Gabriel-Assuncao/SIPDIBGE/issues",
    "repository": "https://cran.r-project.org/package=SIPDIBGE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SIPDIBGE Collection of Household Survey Packages Conducted by IBGE Provides access to packages developed for downloading, reading and analyzing\n  microdata from household surveys in Integrated System of Household Surveys - SIPD\n  conducted by Brazilian Institute of Geography and Statistics - IBGE.\n\tMore information can be obtained from the official website <https://www.ibge.gov.br/>.  "
  },
  {
    "id": 7063,
    "package_name": "SOHPIE",
    "title": "Statistical Approach via Pseudo-Value Information and Estimation",
    "description": "'SOHPIE' (pronounced as SOFIE) is a novel pseudo-value regression approach for differential co-abundance network analysis of microbiome data, which can include additional clinical covariate in the model. The full methodological details can be found in Ahn S and Datta S (2023) <arXiv:2303.13702v1>.",
    "version": "1.0.6",
    "maintainer": "Seungjun Ahn <seungjun.ahn@mountsinai.org>",
    "author": "Seungjun Ahn [cre, aut, trl] (ORCID:\n    <https://orcid.org/0000-0002-4816-8924>),\n  Somnath Datta [ctb, ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SOHPIE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SOHPIE Statistical Approach via Pseudo-Value Information and Estimation 'SOHPIE' (pronounced as SOFIE) is a novel pseudo-value regression approach for differential co-abundance network analysis of microbiome data, which can include additional clinical covariate in the model. The full methodological details can be found in Ahn S and Datta S (2023) <arXiv:2303.13702v1>.  "
  },
  {
    "id": 7074,
    "package_name": "SP2000",
    "title": "Catalogue of Life Toolkit",
    "description": "A programmatic interface to <http://sp2000.org.cn>, re-written based on an accompanying 'Species 2000' API. Access tables describing catalogue of the Chinese known species of animals, plants, fungi, micro-organisms, and more. This package also supports access to catalogue of life global <http://catalogueoflife.org>, China animal scientific database <http://zoology.especies.cn> and catalogue of life Taiwan <https://taibnet.sinica.edu.tw/home_eng.php>. The development of 'SP2000' package were supported by Biodiversity Survey and Assessment Project of the Ministry of Ecology and Environment, China <2019HJ2096001006>,Yunnan University's \"Double First Class\" Project <C176240405> and Yunnan University's Research Innovation Fund for Graduate Students <2019227>.",
    "version": "0.2.0",
    "maintainer": "Liuyong Ding <ly_ding@126.com>",
    "author": "Liuyong Ding [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5490-182X>),\n  Minrui Huang [ctb],\n  Ke Yang [ctb],\n  Jun Wang [ctb] (ORCID: <https://orcid.org/0000-0003-2481-1409>),\n  Juan Tao [ctb],\n  Chengzhi Ding [ctb] (ORCID: <https://orcid.org/0000-0001-5215-7374>),\n  Daming He [ctb]",
    "url": "https://otoliths.github.io/SP2000/",
    "bug_reports": "https://github.com/Otoliths/SP2000/issues",
    "repository": "https://cran.r-project.org/package=SP2000",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SP2000 Catalogue of Life Toolkit A programmatic interface to <http://sp2000.org.cn>, re-written based on an accompanying 'Species 2000' API. Access tables describing catalogue of the Chinese known species of animals, plants, fungi, micro-organisms, and more. This package also supports access to catalogue of life global <http://catalogueoflife.org>, China animal scientific database <http://zoology.especies.cn> and catalogue of life Taiwan <https://taibnet.sinica.edu.tw/home_eng.php>. The development of 'SP2000' package were supported by Biodiversity Survey and Assessment Project of the Ministry of Ecology and Environment, China <2019HJ2096001006>,Yunnan University's \"Double First Class\" Project <C176240405> and Yunnan University's Research Innovation Fund for Graduate Students <2019227>.  "
  },
  {
    "id": 7076,
    "package_name": "SPARRAfairness",
    "title": "Analysis of Differential Behaviour of SPARRA Score Across\nDemographic Groups",
    "description": "The SPARRA risk score (Scottish Patients At Risk of admission and Re-Admission) estimates yearly risk of emergency hospital admission using electronic health records on a monthly basis for most of the Scottish population. This package implements a suite of functions used to analyse the behaviour and performance of the score, focusing particularly on differential performance over demographically-defined groups. It includes useful utility functions to plot receiver-operator-characteristic, precision-recall and calibration curves, draw stock human figures, estimate counterfactual quantities without the need to re-compute risk scores, to simulate a semi-realistic dataset. Our manuscript can be found at: <doi:10.1371/journal.pdig.0000675>.",
    "version": "0.1.0.0",
    "maintainer": "James Liley <james.liley@durham.ac.uk>",
    "author": "Ioanna Thoma [aut] (ORCID: <https://orcid.org/0000-0001-6928-2198>),\n  Catalina Vallejos [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3638-1960>),\n  Louis Aslett [ctb] (ORCID: <https://orcid.org/0000-0003-2211-233X>),\n  Jill Ireland [ctb] (ORCID: <https://orcid.org/0009-0009-5324-6630>),\n  Simon Rogers [ctb] (ORCID: <https://orcid.org/0000-0003-3578-4477>),\n  James Liley [cre, aut] (ORCID: <https://orcid.org/0000-0002-0049-8238>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SPARRAfairness",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SPARRAfairness Analysis of Differential Behaviour of SPARRA Score Across\nDemographic Groups The SPARRA risk score (Scottish Patients At Risk of admission and Re-Admission) estimates yearly risk of emergency hospital admission using electronic health records on a monthly basis for most of the Scottish population. This package implements a suite of functions used to analyse the behaviour and performance of the score, focusing particularly on differential performance over demographically-defined groups. It includes useful utility functions to plot receiver-operator-characteristic, precision-recall and calibration curves, draw stock human figures, estimate counterfactual quantities without the need to re-compute risk scores, to simulate a semi-realistic dataset. Our manuscript can be found at: <doi:10.1371/journal.pdig.0000675>.  "
  },
  {
    "id": 7160,
    "package_name": "SUMMER",
    "title": "Small-Area-Estimation Unit/Area Models and Methods for\nEstimation in R",
    "description": "Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>, Li et al. (2019) <doi:10.1371/journal.pone.0210645>, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) <doi:10.48550/arXiv.2007.05117>. ",
    "version": "2.0.0",
    "maintainer": "Zehang R Li <lizehang@gmail.com>",
    "author": "Zehang R Li [cre, aut],\n  Bryan D Martin [aut],\n  Yuan Hsiao [aut],\n  Jessica Godwin [aut],\n  John Paige [aut],\n  Peter Gao [aut],\n  Jon Wakefield [aut],\n  Samuel J Clark [aut],\n  Geir-Arne Fuglstad [aut],\n  Andrea Riebler [aut]",
    "url": "https://github.com/richardli/SUMMER,\nhttps://richardli.github.io/SUMMER/",
    "bug_reports": "https://github.com/richardli/SUMMER/issues",
    "repository": "https://cran.r-project.org/package=SUMMER",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SUMMER Small-Area-Estimation Unit/Area Models and Methods for\nEstimation in R Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>, Li et al. (2019) <doi:10.1371/journal.pone.0210645>, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) <doi:10.48550/arXiv.2007.05117>.   "
  },
  {
    "id": 7162,
    "package_name": "SUSENAS",
    "title": "National Socio-Economic Survey Data Collection Indonesia",
    "description": "Survey to collect data about the social and economic conditions of Indonesian society. This activity aims to include: As a data source for planning and evaluating national, sectoral development programs, and providing indicators for Sustainable Development Goals (TPB), National Medium Term Development Plan (RPJMN), and Nawacita, GDP/GRDP and annual Integrated Institutional Balance Sheet.",
    "version": "0.1.0",
    "maintainer": "Fadhlul Mubarak <mubarakfadhlul@gmail.com>",
    "author": "Fadhlul Mubarak [aut, cre],\n  Nurniswah [aut],\n  Vinny Yuliani Sundara [aut],\n  Yusma Damayanti [aut],\n  Ahmad Syukron Prasaja [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SUSENAS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SUSENAS National Socio-Economic Survey Data Collection Indonesia Survey to collect data about the social and economic conditions of Indonesian society. This activity aims to include: As a data source for planning and evaluating national, sectoral development programs, and providing indicators for Sustainable Development Goals (TPB), National Medium Term Development Plan (RPJMN), and Nawacita, GDP/GRDP and annual Integrated Institutional Balance Sheet.  "
  },
  {
    "id": 7178,
    "package_name": "SampleSizeCalculator",
    "title": "Sample Size Calculator under Complex Survey Design",
    "description": "It helps in determination of sample size for estimating population mean or proportion under simple random sampling with or without replacement and stratified random sampling without replacement.\n             When prior information on the population coefficient of variation (CV) is unavailable, then a preliminary sample is drawn to estimate the CV which is used to compute the final sample size. If the final\n             size exceeds the preliminary sample size, then additional units are drawn; otherwise, the preliminary sample size is considered as final sample size. For stratified random sampling without replacement design,\n             it also calculates the sample size in each stratum under different allocation methods for estimation of population mean and proportion based upon the availability of prior information on sizes of the strata,\n             standard deviations of the strata and costs of drawing a sampling unit in the strata.For details on sampling methodology, see, Cochran (1977) \"Sampling Techniques\" <https://archive.org/details/samplingtechniqu0000coch_t4x6>. ",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <ncp375@gmail.com>",
    "author": "Nobin Chandra Paul [aut, cre, cph],\n  Pradip Basak [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SampleSizeCalculator",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SampleSizeCalculator Sample Size Calculator under Complex Survey Design It helps in determination of sample size for estimating population mean or proportion under simple random sampling with or without replacement and stratified random sampling without replacement.\n             When prior information on the population coefficient of variation (CV) is unavailable, then a preliminary sample is drawn to estimate the CV which is used to compute the final sample size. If the final\n             size exceeds the preliminary sample size, then additional units are drawn; otherwise, the preliminary sample size is considered as final sample size. For stratified random sampling without replacement design,\n             it also calculates the sample size in each stratum under different allocation methods for estimation of population mean and proportion based upon the availability of prior information on sizes of the strata,\n             standard deviations of the strata and costs of drawing a sampling unit in the strata.For details on sampling methodology, see, Cochran (1977) \"Sampling Techniques\" <https://archive.org/details/samplingtechniqu0000coch_t4x6>.   "
  },
  {
    "id": 7183,
    "package_name": "SamplingStrata",
    "title": "Optimal Stratification of Sampling Frames for Multipurpose\nSampling Surveys",
    "description": "Tools for the optimization of stratified sampling design. It determines a stratification of a sampling frame that minimizes sample cost while satisfying precision constraints in a multivariate and multidomain context. The approach relies on a genetic algorithm; each candidate partition of the frame is an individual whose fitness is evaluated via the Bethel-Chromy allocation to meet target precisions. Functions support analysis of optimization results, labeling of the frame with new strata, and drawing a sample according to the optimal allocation. Algorithmic components adapt code from the 'genalg' package. See M. Ballin and G. Barcaroli (2020) \"R package SamplingStrata: new developments and extension to Spatial Sampling\" <doi:10.48550/arXiv.2004.09366>.",
    "version": "1.5-5",
    "maintainer": "Giulio Barcaroli <gbarcaroli@gmail.com>",
    "author": "Giulio Barcaroli [aut, cre],\n  Marco Ballin [aut],\n  Hanjo Odendaal [aut],\n  Daniela Pagliuca [aut],\n  Egon Willighagen [aut],\n  Diego Zardetto [aut]",
    "url": "https://barcaroli.github.io/SamplingStrata/,\nhttps://github.com/barcaroli/SamplingStrata/",
    "bug_reports": "https://github.com/barcaroli/SamplingStrata/issues",
    "repository": "https://cran.r-project.org/package=SamplingStrata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SamplingStrata Optimal Stratification of Sampling Frames for Multipurpose\nSampling Surveys Tools for the optimization of stratified sampling design. It determines a stratification of a sampling frame that minimizes sample cost while satisfying precision constraints in a multivariate and multidomain context. The approach relies on a genetic algorithm; each candidate partition of the frame is an individual whose fitness is evaluated via the Bethel-Chromy allocation to meet target precisions. Functions support analysis of optimization results, labeling of the frame with new strata, and drawing a sample according to the optimal allocation. Algorithmic components adapt code from the 'genalg' package. See M. Ballin and G. Barcaroli (2020) \"R package SamplingStrata: new developments and extension to Spatial Sampling\" <doi:10.48550/arXiv.2004.09366>.  "
  },
  {
    "id": 7216,
    "package_name": "SemNeT",
    "title": "Methods and Measures for Semantic Network Analysis",
    "description": "Implements several functions for the analysis of semantic networks including different network estimation algorithms, partial node bootstrapping (Kenett, Anaki, & Faust, 2014 <doi:10.3389/fnhum.2014.00407>), random walk simulation (Kenett & Austerweil, 2016 <http://alab.psych.wisc.edu/papers/files/Kenett16CreativityRW.pdf>), and a function to compute global network measures. Significance tests and plotting features are also implemented. ",
    "version": "1.4.5",
    "maintainer": "Alexander P. Christensen <alexpaulchristensen@gmail.com>",
    "author": "Alexander P. Christensen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9798-7037>),\n  Yoed N. Kenett [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0003-3872-7689>)",
    "url": "https://github.com/AlexChristensen/SemNeT",
    "bug_reports": "https://github.com/AlexChristensen/SemNeT/issues",
    "repository": "https://cran.r-project.org/package=SemNeT",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SemNeT Methods and Measures for Semantic Network Analysis Implements several functions for the analysis of semantic networks including different network estimation algorithms, partial node bootstrapping (Kenett, Anaki, & Faust, 2014 <doi:10.3389/fnhum.2014.00407>), random walk simulation (Kenett & Austerweil, 2016 <http://alab.psych.wisc.edu/papers/files/Kenett16CreativityRW.pdf>), and a function to compute global network measures. Significance tests and plotting features are also implemented.   "
  },
  {
    "id": 7217,
    "package_name": "SemNetCleaner",
    "title": "An Automated Cleaning Tool for Semantic and Linguistic Data",
    "description": "Implements several functions that automates the cleaning and spell-checking of text data. Also converges, finalizes, removes plurals and continuous strings, and puts text data in binary format for semantic network analysis. Uses the 'SemNetDictionaries' package to make the cleaning process more accurate, efficient, and reproducible.",
    "version": "1.3.7",
    "maintainer": "Alexander P. Christensen <alexpaulchristensen@gmail.com>",
    "author": "Alexander P. Christensen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9798-7037>)",
    "url": "https://github.com/AlexChristensen/SemNetCleaner",
    "bug_reports": "https://github.com/AlexChristensen/SemNetCleaner/issues",
    "repository": "https://cran.r-project.org/package=SemNetCleaner",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SemNetCleaner An Automated Cleaning Tool for Semantic and Linguistic Data Implements several functions that automates the cleaning and spell-checking of text data. Also converges, finalizes, removes plurals and continuous strings, and puts text data in binary format for semantic network analysis. Uses the 'SemNetDictionaries' package to make the cleaning process more accurate, efficient, and reproducible.  "
  },
  {
    "id": 7243,
    "package_name": "SetMethods",
    "title": "Functions for Set-Theoretic Multi-Method Research and Advanced\nQCA",
    "description": "Functions for performing set-theoretic multi-method research, QCA for clustered data, theory evaluation, Enhanced Standard Analysis, indirect calibration, radar visualisations. Additionally it includes data to replicate the \texamples in the books by Oana, I.E, C. Q. Schneider, and E. Thomann. Qualitative Comparative Analysis (QCA) using R: A Beginner's Guide. Cambridge University Press and C. Q. Schneider and C. Wagemann \"Set Theoretic Methods for the Social Sciences\", Cambridge University Press.",
    "version": "4.1",
    "maintainer": "Ioana-Elena Oana <ioana.oana@eui.eu>",
    "author": "Ioana-Elena Oana [aut, cre],\n  Juraj Medzihorsky [aut],\n  Mario Quaranta [aut],\n  Carsten Q. Schneider [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SetMethods",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SetMethods Functions for Set-Theoretic Multi-Method Research and Advanced\nQCA Functions for performing set-theoretic multi-method research, QCA for clustered data, theory evaluation, Enhanced Standard Analysis, indirect calibration, radar visualisations. Additionally it includes data to replicate the \texamples in the books by Oana, I.E, C. Q. Schneider, and E. Thomann. Qualitative Comparative Analysis (QCA) using R: A Beginner's Guide. Cambridge University Press and C. Q. Schneider and C. Wagemann \"Set Theoretic Methods for the Social Sciences\", Cambridge University Press.  "
  },
  {
    "id": 7252,
    "package_name": "SharkDemography",
    "title": "Shark Demographic Analyses Using Leslie Matrix Models",
    "description": "Run Leslie Matrix models using Monte Carlo simulations for any specified shark species. \n    This package was developed during the publication of Smart, JJ, White, WT, Baje, L, et al. (2020)\n    \"Can multi-species shark longline fisheries be managed sustainably using size limits? \n    Theoretically, yes. Realistically, no\".J Appl Ecol. 2020; 57; 1847\u20131860. \n    <doi:10.1111/1365-2664.13659>.",
    "version": "1.1.0",
    "maintainer": "Jonathan Smart <jonsmartphd@gmail.com>",
    "author": "Jonathan Smart [aut, cre, ctb, cph] (ORCID:\n    <https://orcid.org/0000-0003-2070-3208>)",
    "url": "https://github.com/jonathansmart/SharkDemography",
    "bug_reports": "https://github.com/jonathansmart/SharkDemography/issues",
    "repository": "https://cran.r-project.org/package=SharkDemography",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SharkDemography Shark Demographic Analyses Using Leslie Matrix Models Run Leslie Matrix models using Monte Carlo simulations for any specified shark species. \n    This package was developed during the publication of Smart, JJ, White, WT, Baje, L, et al. (2020)\n    \"Can multi-species shark longline fisheries be managed sustainably using size limits? \n    Theoretically, yes. Realistically, no\".J Appl Ecol. 2020; 57; 1847\u20131860. \n    <doi:10.1111/1365-2664.13659>.  "
  },
  {
    "id": 7275,
    "package_name": "SightabilityModel",
    "title": "Wildlife Sightability Modeling",
    "description": "Uses logistic regression to model the probability of detection as a function of covariates. \n             This model is then used with observational survey data to estimate population size, while\n             accounting for uncertain detection.  See Steinhorst and Samuel (1989).",
    "version": "1.5.5",
    "maintainer": "Schwarz Carl James <cschwarz.stat.sfu.ca@gmail.com>",
    "author": "Fieberg John [aut],\n  Schwarz Carl James [aut, cre]",
    "url": "https://github.com/jfieberg/SightabilityModel",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SightabilityModel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SightabilityModel Wildlife Sightability Modeling Uses logistic regression to model the probability of detection as a function of covariates. \n             This model is then used with observational survey data to estimate population size, while\n             accounting for uncertain detection.  See Steinhorst and Samuel (1989).  "
  },
  {
    "id": 7295,
    "package_name": "SimKid",
    "title": "Simulate Virtual Pediatrics using Anthropometric Growth Charts",
    "description": "Simulate a virtual population of subjects that has demographic distributions (height, weight, and BMI) and correlations (height and weight), by sex and age, which mimic those reported in real-world anthropometric growth charts (CDC, WHO, or Fenton).",
    "version": "1.0.0",
    "maintainer": "Andrew Santulli <asantulli@epd-llc.com>",
    "author": "Andrew Santulli [aut, cre],\n  Enhanced Pharmacodynamics LLC [cph, fnd]",
    "url": "https://github.com/Andy00000000000/SimKid",
    "bug_reports": "https://github.com/Andy00000000000/SimKid/issues",
    "repository": "https://cran.r-project.org/package=SimKid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimKid Simulate Virtual Pediatrics using Anthropometric Growth Charts Simulate a virtual population of subjects that has demographic distributions (height, weight, and BMI) and correlations (height and weight), by sex and age, which mimic those reported in real-world anthropometric growth charts (CDC, WHO, or Fenton).  "
  },
  {
    "id": 7303,
    "package_name": "SimSurvey",
    "title": "Test Surveys by Simulating Spatially-Correlated Populations",
    "description": "Simulate age-structured populations that vary in space and time and \n    explore the efficacy of a range of built-in or user-defined sampling \n    protocols to reproduce the population parameters of the known population. \n    (See Regular et al. (2020) <doi:10.1371/journal.pone.0232822> for more\n    details).",
    "version": "0.1.8",
    "maintainer": "Paul Regular <Paul.Regular@dfo-mpo.gc.ca>",
    "author": "Paul Regular [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0318-2615>),\n  Jonathan Babyn [ctb],\n  Greg Robertson [ctb]",
    "url": "https://paulregular.github.io/SimSurvey/",
    "bug_reports": "https://github.com/PaulRegular/SimSurvey/issues",
    "repository": "https://cran.r-project.org/package=SimSurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SimSurvey Test Surveys by Simulating Spatially-Correlated Populations Simulate age-structured populations that vary in space and time and \n    explore the efficacy of a range of built-in or user-defined sampling \n    protocols to reproduce the population parameters of the known population. \n    (See Regular et al. (2020) <doi:10.1371/journal.pone.0232822> for more\n    details).  "
  },
  {
    "id": 7349,
    "package_name": "SoilTaxonomy",
    "title": "A System of Soil Classification for Making and Interpreting Soil\nSurveys",
    "description": "Taxonomic dictionaries, formative element lists, and functions related to the maintenance, development and application of U.S. Soil Taxonomy. \n   Data and functionality are based on official U.S. Department of Agriculture sources including the latest edition of the Keys to Soil Taxonomy. Descriptions and metadata are obtained from the National Soil Information System or Soil Survey Geographic databases. Other sources are referenced in the data documentation. \n   Provides tools for understanding and interacting with concepts in the U.S. Soil Taxonomic System. Most of the current utilities are for working with taxonomic concepts at the \"higher\" taxonomic levels: Order, Suborder, Great Group, and Subgroup.",
    "version": "0.2.8",
    "maintainer": "Andrew Brown <andrew.g.brown@usda.gov>",
    "author": "Andrew Brown [aut, cre],\n  Dylan Beaudette [aut]",
    "url": "https://github.com/ncss-tech/SoilTaxonomy,\nhttps://ncss-tech.github.io/SoilTaxonomy/",
    "bug_reports": "https://github.com/ncss-tech/SoilTaxonomy/issues",
    "repository": "https://cran.r-project.org/package=SoilTaxonomy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SoilTaxonomy A System of Soil Classification for Making and Interpreting Soil\nSurveys Taxonomic dictionaries, formative element lists, and functions related to the maintenance, development and application of U.S. Soil Taxonomy. \n   Data and functionality are based on official U.S. Department of Agriculture sources including the latest edition of the Keys to Soil Taxonomy. Descriptions and metadata are obtained from the National Soil Information System or Soil Survey Geographic databases. Other sources are referenced in the data documentation. \n   Provides tools for understanding and interacting with concepts in the U.S. Soil Taxonomic System. Most of the current utilities are for working with taxonomic concepts at the \"higher\" taxonomic levels: Order, Suborder, Great Group, and Subgroup.  "
  },
  {
    "id": 7351,
    "package_name": "Sojourn",
    "title": "Apply Sojourn Methods for Processing ActiGraph Accelerometer\nData",
    "description": "Provides a simple way for utilizing Sojourn methods for\n    accelerometer processing, as detailed in Lyden K, Keadle S,\n    Staudenmayer J, & Freedson P (2014) <doi:10.1249/MSS.0b013e3182a42a2d>,\n    Ellingson LD, Schwabacher IJ, Kim Y, Welk GJ, & Cook DB (2016)\n    <doi:10.1249/MSS.0000000000000915>, and Hibbing PR, Ellingson LD,\n    Dixon PM, & Welk GJ (2018) <doi:10.1249/MSS.0000000000001486>.",
    "version": "1.2.1",
    "maintainer": "Paul R. Hibbing <paulhibbing@gmail.com>",
    "author": "Paul R. Hibbing [aut, cre],\n  Kate Lyden [aut],\n  Isaac J. Schwabacher [aut]",
    "url": "https://github.com/paulhibbing/Sojourn",
    "bug_reports": "https://github.com/paulhibbing/Sojourn/issues",
    "repository": "https://cran.r-project.org/package=Sojourn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Sojourn Apply Sojourn Methods for Processing ActiGraph Accelerometer\nData Provides a simple way for utilizing Sojourn methods for\n    accelerometer processing, as detailed in Lyden K, Keadle S,\n    Staudenmayer J, & Freedson P (2014) <doi:10.1249/MSS.0b013e3182a42a2d>,\n    Ellingson LD, Schwabacher IJ, Kim Y, Welk GJ, & Cook DB (2016)\n    <doi:10.1249/MSS.0000000000000915>, and Hibbing PR, Ellingson LD,\n    Dixon PM, & Welk GJ (2018) <doi:10.1249/MSS.0000000000001486>.  "
  },
  {
    "id": 7396,
    "package_name": "SpatialGraph",
    "title": "The SpatialGraph Class and Utilities",
    "description": "Provision of the S4 SpatialGraph class built on top of objects provided by 'igraph' and 'sp' packages, and associated utilities. See the documentation of the SpatialGraph-class within this package for further description. An example of how from a few points one can arrive to a SpatialGraph is provided in the function sl2sg().  ",
    "version": "1.0-4",
    "maintainer": "Javier Garcia-Pintado <jgarciapintado@marum.de>",
    "author": "Javier Garcia-Pintado",
    "url": "https://github.com/garciapintado/SpatialGraph",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpatialGraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpatialGraph The SpatialGraph Class and Utilities Provision of the S4 SpatialGraph class built on top of objects provided by 'igraph' and 'sp' packages, and associated utilities. See the documentation of the SpatialGraph-class within this package for further description. An example of how from a few points one can arrive to a SpatialGraph is provided in the function sl2sg().    "
  },
  {
    "id": 7407,
    "package_name": "SpatialVS",
    "title": "Spatial Variable Selection",
    "description": "Perform variable selection for the spatial Poisson regression model under the adaptive elastic net penalty. Spatial count data with covariates is the input. We use a spatial Poisson regression model to link the spatial counts and covariates. For maximization of the likelihood under adaptive elastic net penalty, we implemented the penalized quasi-likelihood (PQL) and the approximate penalized loglikelihood (APL) methods. The proposed methods can automatically select important covariates, while adjusting for possible spatial correlations among the responses. More details are available in Xie et al. (2018, <arXiv:1809.06418>). The package also contains the Lyme disease dataset, which consists of the disease case data from 2006 to 2011, and demographic data and land cover data in Virginia. The Lyme disease case data were collected by the Virginia Department of Health. The demographic data (e.g., population density, median income, and average age) are from the 2010 census. Land cover data were obtained from the Multi-Resolution Land Cover Consortium for 2006.",
    "version": "1.1",
    "maintainer": "Yili Hong <yilihong@vt.edu>",
    "author": "Yili Hong, Li Xu, Yimeng Xie, and Zhongnan Jin",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SpatialVS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SpatialVS Spatial Variable Selection Perform variable selection for the spatial Poisson regression model under the adaptive elastic net penalty. Spatial count data with covariates is the input. We use a spatial Poisson regression model to link the spatial counts and covariates. For maximization of the likelihood under adaptive elastic net penalty, we implemented the penalized quasi-likelihood (PQL) and the approximate penalized loglikelihood (APL) methods. The proposed methods can automatically select important covariates, while adjusting for possible spatial correlations among the responses. More details are available in Xie et al. (2018, <arXiv:1809.06418>). The package also contains the Lyme disease dataset, which consists of the disease case data from 2006 to 2011, and demographic data and land cover data in Virginia. The Lyme disease case data were collected by the Virginia Department of Health. The demographic data (e.g., population density, median income, and average age) are from the 2010 census. Land cover data were obtained from the Multi-Resolution Land Cover Consortium for 2006.  "
  },
  {
    "id": 7439,
    "package_name": "StMoMo",
    "title": "Stochastic Mortality Modelling",
    "description": "Implementation of the family of generalised age-period-cohort\n    stochastic mortality models. This family of models encompasses many models\n    proposed in the actuarial and demographic literature including the \n    Lee-Carter (1992) <doi:10.2307/2290201> and\n    the Cairns-Blake-Dowd (2006) <doi:10.1111/j.1539-6975.2006.00195.x> models. \n    It includes functions for fitting mortality models, analysing their \n    goodness-of-fit and performing mortality projections and simulations.",
    "version": "0.4.1",
    "maintainer": "Andres Villegas <andresmauriciovillegas@gmail.com>",
    "author": "Andres Villegas <andresmauriciovillegas@gmail.com>,\n    Pietro Millossovich <Pietro.Millossovich.1@city.ac.uk>,\n    Vladimir Kaishev <Vladimir.Kaishev.1@city.ac.uk>",
    "url": "http://github.com/amvillegas/StMoMo",
    "bug_reports": "http://github.com/amvillegas/StMoMo/issues",
    "repository": "https://cran.r-project.org/package=StMoMo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StMoMo Stochastic Mortality Modelling Implementation of the family of generalised age-period-cohort\n    stochastic mortality models. This family of models encompasses many models\n    proposed in the actuarial and demographic literature including the \n    Lee-Carter (1992) <doi:10.2307/2290201> and\n    the Cairns-Blake-Dowd (2006) <doi:10.1111/j.1539-6975.2006.00195.x> models. \n    It includes functions for fitting mortality models, analysing their \n    goodness-of-fit and performing mortality projections and simulations.  "
  },
  {
    "id": 7448,
    "package_name": "StanMoMo",
    "title": "Bayesian Mortality Modelling with 'Stan'",
    "description": "Implementation of popular mortality models using the 'rstan' \n    package, which provides the R interface to the 'Stan' C++ library for \n    Bayesian estimation. The package supports well-known models proposed in the \n    actuarial and demographic literature including the Lee-Carter (1992) \n    <doi:10.1080/01621459.1992.10475265> and the Cairns-Blake-Dowd (2006) \n    <doi:10.1111/j.1539-6975.2006.00195.x> models. By a simple call, the user \n    inputs deaths and exposures and the package outputs the MCMC simulations for\n    each parameter, the log likelihoods and predictions. Moreover, the package \n    includes tools for model selection and Bayesian model averaging by leave \n    future-out validation.",
    "version": "1.2.0",
    "maintainer": "Karim Barigou <karim290492@gmail.com>",
    "author": "Karim Barigou [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3389-9596>),\n  Pierre-Olivier Goffard [aut] (ORCID:\n    <https://orcid.org/0000-0002-2667-6207>)",
    "url": "https://github.com/kabarigou/StanMoMo",
    "bug_reports": "https://github.com/kabarigou/StanMoMo/issues",
    "repository": "https://cran.r-project.org/package=StanMoMo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StanMoMo Bayesian Mortality Modelling with 'Stan' Implementation of popular mortality models using the 'rstan' \n    package, which provides the R interface to the 'Stan' C++ library for \n    Bayesian estimation. The package supports well-known models proposed in the \n    actuarial and demographic literature including the Lee-Carter (1992) \n    <doi:10.1080/01621459.1992.10475265> and the Cairns-Blake-Dowd (2006) \n    <doi:10.1111/j.1539-6975.2006.00195.x> models. By a simple call, the user \n    inputs deaths and exposures and the package outputs the MCMC simulations for\n    each parameter, the log likelihoods and predictions. Moreover, the package \n    includes tools for model selection and Bayesian model averaging by leave \n    future-out validation.  "
  },
  {
    "id": 7452,
    "package_name": "StatMatch",
    "title": "Statistical Matching or Data Fusion",
    "description": "Integration of two data sources referred to the same target population which share a number of variables. Some functions can also be used to impute missing values in data sets through hot deck imputation methods. Methods to perform statistical matching when dealing  with data from complex sample surveys are available too.",
    "version": "1.4.3",
    "maintainer": "Marcello D'Orazio <mdo.statmatch@gmail.com>",
    "author": "Marcello D'Orazio [aut, cre]",
    "url": "https://github.com/marcellodo/StatMatch,\nhttps://github.com/marcellodo/StatMatch/tree/master/Tutorials_Vignette_OtherDocs",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StatMatch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StatMatch Statistical Matching or Data Fusion Integration of two data sources referred to the same target population which share a number of variables. Some functions can also be used to impute missing values in data sets through hot deck imputation methods. Methods to perform statistical matching when dealing  with data from complex sample surveys are available too.  "
  },
  {
    "id": 7477,
    "package_name": "StrainRanking",
    "title": "Ranking of Pathogen Strains",
    "description": "Regression-based ranking of pathogen strains with respect to their contributions to natural epidemics, using demographic and genetic data sampled in the curse of the epidemics. This package also includes the GMCPIC test.",
    "version": "1.2",
    "maintainer": "Samuel Soubeyrand <samuel.soubeyrand@inra.fr>",
    "author": "Soubeyrand, S., Tollenaere, C., Haon-Lasportes, E. and Laine, A.-L. ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StrainRanking",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StrainRanking Ranking of Pathogen Strains Regression-based ranking of pathogen strains with respect to their contributions to natural epidemics, using demographic and genetic data sampled in the curse of the epidemics. This package also includes the GMCPIC test.  "
  },
  {
    "id": 7478,
    "package_name": "StratPal",
    "title": "Stratigraphic Paleobiology Modeling Pipelines",
    "description": "The fossil record is a joint expression of ecological, taphonomic, \n    evolutionary, and stratigraphic processes (Holland and Patzkowsky, 2012, ISBN:978-0226649382).\n    This package allowing to simulate biological processes in the time domain\n    (e.g., trait evolution, fossil abundance, phylogenetic trees), and examine how their expression\n    in the rock record (stratigraphic domain) is influenced based on \n    age-depth models, ecological niche models, and taphonomic effects.\n    Functions simulating common processes used in modeling trait evolution, biostratigraphy or \n    event type data such as first/last occurrences are provided and can be used \n    standalone or as part of a pipeline. The package comes with example \n    data sets and tutorials in several vignettes, which can be used as a \n    template to set up one's own simulation.",
    "version": "0.7.1",
    "maintainer": "Niklas Hohmann <N.H.Hohmann@uu.nl>",
    "author": "Niklas Hohmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1559-1838>)",
    "url": "https://mindthegap-erc.github.io/StratPal/ ,\nhttps://github.com/MindTheGap-ERC/StratPal",
    "bug_reports": "https://github.com/MindTheGap-ERC/StratPal/issues",
    "repository": "https://cran.r-project.org/package=StratPal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StratPal Stratigraphic Paleobiology Modeling Pipelines The fossil record is a joint expression of ecological, taphonomic, \n    evolutionary, and stratigraphic processes (Holland and Patzkowsky, 2012, ISBN:978-0226649382).\n    This package allowing to simulate biological processes in the time domain\n    (e.g., trait evolution, fossil abundance, phylogenetic trees), and examine how their expression\n    in the rock record (stratigraphic domain) is influenced based on \n    age-depth models, ecological niche models, and taphonomic effects.\n    Functions simulating common processes used in modeling trait evolution, biostratigraphy or \n    event type data such as first/last occurrences are provided and can be used \n    standalone or as part of a pipeline. The package comes with example \n    data sets and tutorials in several vignettes, which can be used as a \n    template to set up one's own simulation.  "
  },
  {
    "id": 7486,
    "package_name": "StratigrapheR",
    "title": "Integrated Stratigraphy",
    "description": "Includes bases for litholog generation: graphical functions\n    based on R base graphics, interval management functions and svg importation \n    functions among others. Also include stereographic projection functions, \n    and other functions made to deal with large datasets while keeping options\n    to get into the details of the data.\n    When using for publication please cite \n    Sebastien Wouters, Anne-Christine Da Silva, Frederic Boulvain and \n    Xavier Devleeschouwer, 2021. The R Journal 13:2, 153-178.\n    The palaeomagnetism functions are based on:\n    Tauxe, L., 2010. Essentials of Paleomagnetism. University of California \n    Press. <https://earthref.org/MagIC/books/Tauxe/Essentials/>;\n    Allmendinger, R. W., Cardozo, N. C., and Fisher, D., 2013, Structural \n    Geology Algorithms: Vectors & Tensors: Cambridge, England, Cambridge\n    University Press, 289 pp.;\n    Cardozo, N., and Allmendinger, R. W., 2013, Spherical projections\n    with OSXStereonet: Computers & Geosciences, v. 51, no. 0, p. 193 - 205,\n    <doi: 10.1016/j.cageo.2012.07.021>.",
    "version": "1.3.1",
    "maintainer": "Sebastien Wouters <wouterseb@gmail.com>",
    "author": "Sebastien Wouters [aut, cre], Adam D. Smith [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=StratigrapheR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "StratigrapheR Integrated Stratigraphy Includes bases for litholog generation: graphical functions\n    based on R base graphics, interval management functions and svg importation \n    functions among others. Also include stereographic projection functions, \n    and other functions made to deal with large datasets while keeping options\n    to get into the details of the data.\n    When using for publication please cite \n    Sebastien Wouters, Anne-Christine Da Silva, Frederic Boulvain and \n    Xavier Devleeschouwer, 2021. The R Journal 13:2, 153-178.\n    The palaeomagnetism functions are based on:\n    Tauxe, L., 2010. Essentials of Paleomagnetism. University of California \n    Press. <https://earthref.org/MagIC/books/Tauxe/Essentials/>;\n    Allmendinger, R. W., Cardozo, N. C., and Fisher, D., 2013, Structural \n    Geology Algorithms: Vectors & Tensors: Cambridge, England, Cambridge\n    University Press, 289 pp.;\n    Cardozo, N., and Allmendinger, R. W., 2013, Spherical projections\n    with OSXStereonet: Computers & Geosciences, v. 51, no. 0, p. 193 - 205,\n    <doi: 10.1016/j.cageo.2012.07.021>.  "
  },
  {
    "id": 7490,
    "package_name": "String2AdjMatrix",
    "title": "Creates an Adjacency Matrix from a List of Strings",
    "description": "Takes a list of character strings and forms an adjacency matrix for\n    the times the specified characters appear together in the strings provided. For\n    use in social network analysis and data wrangling. Simple package, comprised of\n    three functions.",
    "version": "0.1.0",
    "maintainer": "Tom Drake <t.drake@ed.ac.uk>",
    "author": "Tom Drake",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=String2AdjMatrix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "String2AdjMatrix Creates an Adjacency Matrix from a List of Strings Takes a list of character strings and forms an adjacency matrix for\n    the times the specified characters appear together in the strings provided. For\n    use in social network analysis and data wrangling. Simple package, comprised of\n    three functions.  "
  },
  {
    "id": 7541,
    "package_name": "SurveyCC",
    "title": "Canonical Correlation for Survey Data",
    "description": "Performs canonical correlation for survey data, including \n  multiple tests of significance for secondary canonical correlations. \n  A key feature of this package is that it incorporates survey data structure \n  directly in a novel test of significance via a sequence of simple linear \n  regression models on the canonical variates. See reference - Cruz-Cano, \n  Cohen, and Mead-Morse (2024) \"Canonical Correlation Analysis of Survey data: the SurveyCC R package\" \n  The R Journal under review.",
    "version": "0.2.1",
    "maintainer": "Raul Cruz-Cano <raulcruz@iu.edu>",
    "author": "Raul Cruz-Cano [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7715-1198>)",
    "url": "https://github.com/237triangle/SurveyCC",
    "bug_reports": "https://github.com/237triangle/SurveyCC/issues",
    "repository": "https://cran.r-project.org/package=SurveyCC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SurveyCC Canonical Correlation for Survey Data Performs canonical correlation for survey data, including \n  multiple tests of significance for secondary canonical correlations. \n  A key feature of this package is that it incorporates survey data structure \n  directly in a novel test of significance via a sequence of simple linear \n  regression models on the canonical variates. See reference - Cruz-Cano, \n  Cohen, and Mead-Morse (2024) \"Canonical Correlation Analysis of Survey data: the SurveyCC R package\" \n  The R Journal under review.  "
  },
  {
    "id": 7542,
    "package_name": "SurveyDefense",
    "title": "Survey Defense Tool",
    "description": "This tool is designed to analyze up to 5 Fraud Detection Questions integrated into a survey, focusing on potential fraudulent participants to clean the survey dataset from potential fraud. Fraud Detection Questions and further information available at <https://surveydefense.org>.",
    "version": "0.2.0",
    "maintainer": "Philipp Br\u00fcggemann <philippbrueggemann@web.de>",
    "author": "Philipp Br\u00fcggemann [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SurveyDefense",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SurveyDefense Survey Defense Tool This tool is designed to analyze up to 5 Fraud Detection Questions integrated into a survey, focusing on potential fraudulent participants to clean the survey dataset from potential fraud. Fraud Detection Questions and further information available at <https://surveydefense.org>.  "
  },
  {
    "id": 7547,
    "package_name": "SvyNom",
    "title": "Nomograms for Right-Censored Outcomes from Survey Designs",
    "description": "Builds, evaluates and validates a nomogram with survey data\n    and right-censored outcomes. As described in Capanu (2015)\n    <doi:10.18637/jss.v064.c01>, the package contains functions to create\n    the nomogram, validate it using bootstrap, as well as produce the\n    calibration plots.",
    "version": "1.2",
    "maintainer": "Mithat Gonen <gonenm@mskcc.org>",
    "author": "Mithat Gonen [aut, cre],\n  Marinela Capanu [aut]",
    "url": "https://github.com/MSKCC-Epi-Bio/SvyNom,\nhttps://mskcc-epi-bio.github.io/SvyNom/",
    "bug_reports": "https://github.com/MSKCC-Epi-Bio/SvyNom/issues",
    "repository": "https://cran.r-project.org/package=SvyNom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SvyNom Nomograms for Right-Censored Outcomes from Survey Designs Builds, evaluates and validates a nomogram with survey data\n    and right-censored outcomes. As described in Capanu (2015)\n    <doi:10.18637/jss.v064.c01>, the package contains functions to create\n    the nomogram, validate it using bootstrap, as well as produce the\n    calibration plots.  "
  },
  {
    "id": 7548,
    "package_name": "SwPcIndex",
    "title": "Computation of Survey Weighted PC Based Composite Index",
    "description": "An index is created using a mathematical model that transforms multi-dimensional variables into a single value. These variables are often correlated, and while PCA-based indices can address the issue of multicollinearity, they typically do not account for survey weights, which can lead to inaccurate rankings of survey units such as households, districts, or states. To resolve this, the current package facilitates the development of a principal component analysis-based composite index by incorporating survey weights for each sample observation. This ensures the generation of a survey-weighted principal component-based normalized composite index. Additionally, the package provides a normalized principal component-based composite index and ranks the sample observations based on the values of the composite indices.\n            For method details see, Skinner, C. J., Holmes, D. J. and Smith, T. M. F. (1986) <DOI:10.1080/01621459.1986.10478336>, Singh, D., Basak, P., Kumar, R. and Ahmad, T. (2023) <DOI:10.3389/fams.2023.1274530>.",
    "version": "0.1.0",
    "maintainer": "Pradip Basak <pradip@ubkv.ac.in>",
    "author": "Pradip Basak [aut, cph, cre],\n  Deepak Singh [aut, cph],\n  Raju Kumar [aut, cph],\n  Tauqueer Ahmad [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=SwPcIndex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "SwPcIndex Computation of Survey Weighted PC Based Composite Index An index is created using a mathematical model that transforms multi-dimensional variables into a single value. These variables are often correlated, and while PCA-based indices can address the issue of multicollinearity, they typically do not account for survey weights, which can lead to inaccurate rankings of survey units such as households, districts, or states. To resolve this, the current package facilitates the development of a principal component analysis-based composite index by incorporating survey weights for each sample observation. This ensures the generation of a survey-weighted principal component-based normalized composite index. Additionally, the package provides a normalized principal component-based composite index and ranks the sample observations based on the values of the composite indices.\n            For method details see, Skinner, C. J., Holmes, D. J. and Smith, T. M. F. (1986) <DOI:10.1080/01621459.1986.10478336>, Singh, D., Basak, P., Kumar, R. and Ahmad, T. (2023) <DOI:10.3389/fams.2023.1274530>.  "
  },
  {
    "id": 7658,
    "package_name": "TSE",
    "title": "Total Survey Error",
    "description": "Calculates total survey error (TSE) for one or more surveys, using common scale-dependent and/or scale-independent metrics.  On TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>.",
    "version": "0.1.0",
    "maintainer": "Joshua Miller <joshlmiller@msn.com>",
    "author": "Joshua Miller [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSE Total Survey Error Calculates total survey error (TSE) for one or more surveys, using common scale-dependent and/or scale-independent metrics.  On TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>.  "
  },
  {
    "id": 7660,
    "package_name": "TSEind",
    "title": "Total Survey Error (Independent Samples)",
    "description": "Calculates total survey error (TSE) for one or more surveys, using both scale-dependent and scale-independent metrics.  Package works directly from the data set, with no hand calculations required: just upload a properly structured data set (see TESTIND and its documentation), properly input column names (see functions documentation), and run your functions.  For more on TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>; Biemer, Paul et.al. (2017, ISBN:9781119041672); etc.",
    "version": "0.1.0",
    "maintainer": "Joshua Miller <joshlmiller@msn.com>",
    "author": "Joshua Miller [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSEind",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSEind Total Survey Error (Independent Samples) Calculates total survey error (TSE) for one or more surveys, using both scale-dependent and scale-independent metrics.  Package works directly from the data set, with no hand calculations required: just upload a properly structured data set (see TESTIND and its documentation), properly input column names (see functions documentation), and run your functions.  For more on TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>; Biemer, Paul et.al. (2017, ISBN:9781119041672); etc.  "
  },
  {
    "id": 7663,
    "package_name": "TSEwgt",
    "title": "Total Survey Error Under Multiple, Different Weighting Schemes",
    "description": "Calculates total survey error (TSE) for a survey under multiple, different weighting schemes, using both scale-dependent and scale-independent metrics.  Package works directly from the data set, with no hand calculations required: just upload a properly structured data set (see TESTWGT and its documentation), properly input column names (see functions documentation), and run your functions.  For more on TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>; Biemer, Paul et.al. (2017, ISBN:9781119041672); etc.",
    "version": "0.1.0",
    "maintainer": "Joshua Miller <joshlmiller@msn.com>",
    "author": "Joshua Miller [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TSEwgt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TSEwgt Total Survey Error Under Multiple, Different Weighting Schemes Calculates total survey error (TSE) for a survey under multiple, different weighting schemes, using both scale-dependent and scale-independent metrics.  Package works directly from the data set, with no hand calculations required: just upload a properly structured data set (see TESTWGT and its documentation), properly input column names (see functions documentation), and run your functions.  For more on TSE, see: Weisberg, Herbert (2005, ISBN:0-226-89128-3); Biemer, Paul (2010) <doi:10.1093/poq/nfq058>; Biemer, Paul et.al. (2017, ISBN:9781119041672); etc.  "
  },
  {
    "id": 7739,
    "package_name": "TestGardener",
    "title": "Information Analysis for Test and Rating Scale Data",
    "description": "Develop, evaluate, and score multiple choice examinations, \n psychological scales, questionnaires, and similar types of data involving\n sequences of choices among one or more sets of answers.\n This version of the package should be considered as brand new.  Almost all\n of the functions have been changed, including their argument list.\n See the file NEWS.Rd in the Inst folder for more information.\n Using the package does not require any formal statistical knowledge \n beyond what would be provided by a first course in statistics in a \n social science department.  There the user would encounter the concept \n of probability and how it is used to model data and make decisions, \n and would become familiar with basic mathematical and statistical notation.\n Most of the output is in graphical form. ",
    "version": "3.3.6",
    "maintainer": "James Ramsay <james.ramsay@mcgill.ca>",
    "author": "James Ramsay [aut, cre],\n  Juan Li [ctb],\n  Marie Wiberg [ctb],\n  Joakim Wallmark [ctb],\n  Spencer Graves [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=TestGardener",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "TestGardener Information Analysis for Test and Rating Scale Data Develop, evaluate, and score multiple choice examinations, \n psychological scales, questionnaires, and similar types of data involving\n sequences of choices among one or more sets of answers.\n This version of the package should be considered as brand new.  Almost all\n of the functions have been changed, including their argument list.\n See the file NEWS.Rd in the Inst folder for more information.\n Using the package does not require any formal statistical knowledge \n beyond what would be provided by a first course in statistics in a \n social science department.  There the user would encounter the concept \n of probability and how it is used to model data and make decisions, \n and would become familiar with basic mathematical and statistical notation.\n Most of the output is in graphical form.   "
  },
  {
    "id": 7880,
    "package_name": "USpopcenters",
    "title": "United States Centers of Population (Centroids)",
    "description": "Centers of population (centroid) data for census areas in the\n    United States.",
    "version": "0.2.0",
    "maintainer": "Nik Krieger <nk@case.edu>",
    "author": "Nik Krieger [aut, cre]",
    "url": "https://www.census.gov/geographies/reference-files/time-series/geo/centers-population.html,\nhttps://github.com/NikKrieger/USpopcenters",
    "bug_reports": "https://github.com/NikKrieger/USpopcenters/issues",
    "repository": "https://cran.r-project.org/package=USpopcenters",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "USpopcenters United States Centers of Population (Centroids) Centers of population (centroid) data for census areas in the\n    United States.  "
  },
  {
    "id": 8010,
    "package_name": "WGCNA",
    "title": "Weighted Correlation Network Analysis",
    "description": "Functions necessary to perform Weighted Correlation Network Analysis on high-dimensional data as originally described in Horvath and Zhang (2005) <doi:10.2202/1544-6115.1128> and Langfelder and Horvath (2008) <doi:10.1186/1471-2105-9-559>. Includes functions for rudimentary data cleaning, construction of correlation networks, module identification, summarization, and relating of variables and modules to sample traits. Also includes a number of utility functions for data manipulation and visualization.",
    "version": "1.73",
    "maintainer": "Peter Langfelder <Peter.Langfelder@gmail.com>",
    "author": "Peter Langfelder [aut, cre],\n  Steve Horvath [aut],\n  Chaochao Cai [aut],\n  Jun Dong [aut],\n  Jeremy Miller [aut],\n  Lin Song [aut],\n  Andy Yip [aut],\n  Bin Zhang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WGCNA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WGCNA Weighted Correlation Network Analysis Functions necessary to perform Weighted Correlation Network Analysis on high-dimensional data as originally described in Horvath and Zhang (2005) <doi:10.2202/1544-6115.1128> and Langfelder and Horvath (2008) <doi:10.1186/1471-2105-9-559>. Includes functions for rudimentary data cleaning, construction of correlation networks, module identification, summarization, and relating of variables and modules to sample traits. Also includes a number of utility functions for data manipulation and visualization.  "
  },
  {
    "id": 8048,
    "package_name": "WaverideR",
    "title": "Extracting Signals from Wavelet Spectra",
    "description": "The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.",
    "version": "0.4.1",
    "maintainer": "Michiel Arts <michiel.arts@stratigraphy.eu>",
    "author": "Michiel Arts [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3181-4608>)",
    "url": "https://github.com/stratigraphy/WaverideR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WaverideR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WaverideR Extracting Signals from Wavelet Spectra The continuous wavelet transform enables the observation of transient/non-stationary cyclicity in time-series. The goal of cyclostratigraphic studies is to define frequency/period in the depth/time domain. By conducting the continuous wavelet transform on cyclostratigraphic data series one can observe and extract cyclic signals/signatures from signals. These results can then be visualized and interpreted enabling one to identify/interpret cyclicity in the geological record, which can be used to construct astrochronological age-models and identify and interpret cyclicity in past and present climate systems. The 'WaverideR' R package builds upon existing literature and existing codebase. The list of articles which are relevant can be grouped in four subjects; cyclostratigraphic data analysis,example data sets,the (continuous) wavelet transform and astronomical solutions. References for the cyclostratigraphic data analysis articles are: Stephen Meyers (2019) <doi:10.1016/j.earscirev.2018.11.015>. Mingsong Li, Linda Hinnov, Lee Kump (2019) <doi:10.1016/j.cageo.2019.02.011> Stephen Meyers (2012)<doi:10.1029/2012PA002307> Mingsong Li, Lee R. Kump, Linda A. Hinnov, Michael E. Mann (2018) <doi:10.1016/j.epsl.2018.08.041>. Wouters, S., Crucifix, M., Sinnesael, M., Da Silva, A.C., Zeeden, C., Zivanovic, M., Boulvain, F., Devleeschouwer, X. (2022) <doi:10.1016/j.earscirev.2021.103894>. Wouters, S., Da Silva, A.-C., Boulvain, F., and Devleeschouwer, X. (2021) <doi:10.32614/RJ-2021-039>. Huang, Norden E., Zhaohua Wu, Steven R. Long, Kenneth C. Arnold, Xianyao Chen, and Karin Blank  (2009) <doi:10.1142/S1793536909000096>. Cleveland, W. S. (1979)<doi:10.1080/01621459.1979.10481038> Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998) <doi:10.1111/1467-9868.00125>, Golub, G., Heath, M. and Wahba, G. (1979) <doi:10.2307/1268518>. References for the example data articles are: Damien Pas, Linda Hinnov, James E. (Jed) Day, Kenneth Kodama, Matthias Sinnesael, Wei Liu (2018) <doi:10.1016/j.epsl.2018.02.010>. Steinhilber, Friedhelm, Abreu, Jacksiel, Beer, Juerg , Brunner, Irene, Christl, Marcus, Fischer, Hubertus, HeikkilA, U., Kubik,  Peter, Mann, Mathias, Mccracken, K. , Miller, Heinrich, Miyahara, Hiroko, Oerter, Hans , Wilhelms, Frank. (2012 <doi:10.1073/pnas.1118965109>. Christian Zeeden, Frederik Hilgen, Thomas Westerhold, Lucas Lourens, Ursula R\u00f6hl, Torsten Bickert (2013) <doi:10.1016/j.palaeo.2012.11.009>. References for the (continuous) wavelet transform articles are: Morlet, Jean, Georges Arens, Eliane Fourgeau, and Dominique Glard  (1982a) <doi:10.1190/1.1441328>. J. Morlet, G. Arens, E. Fourgeau, D. Giard (1982b) <doi:10.1190/1.1441329>. Torrence, C., and G. P. Compo (1998)<https://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf>, Gouhier TC, Grinsted A, Simko V (2021) <https://github.com/tgouhier/biwavelet>. Angi Roesch and Harald Schmidbauer (2018) <https://CRAN.R-project.org/package=WaveletComp>. Russell, Brian, and Jiajun Han (2016)<https://www.crewes.org/Documents/ResearchReports/2016/CRR201668.pdf>. Gabor, Dennis (1946) <http://genesis.eecg.toronto.edu/gabor1946.pdf>. J. Laskar, P. Robutel, F. Joutel, M. Gastineau, A.C.M. Correia, and B. Levrard, B. (2004) <doi:10.1051/0004-6361:20041335>. Laskar, J., Fienga, A., Gastineau, M., Manche, H. (2011a) <doi:10.1051/0004-6361/201116836>. References for the astronomical solutions articles are: Laskar, J., Gastineau, M., Delisle, J.-B., Farres, A., Fienga, A. (2011b <doi:10.1051/0004-6361/201117504>. J. Laskar (2019) <doi:10.1016/B978-0-12-824360-2.00004-8>. Zeebe, Richard E (2017) <doi:10.3847/1538-3881/aa8cce>. Zeebe, R. E. and Lourens, L. J. (2019) <doi:10.1016/j.epsl.2022.117595>. Richard E. Zeebe Lucas J. Lourens (2022) <doi:10.1126/science.aax0612>.  "
  },
  {
    "id": 8049,
    "package_name": "WayFindR",
    "title": "Computing Graph Structures on WikiPathways",
    "description": "Converts pathways from 'WikiPathways' GPML format or\n  'KEGG' KGML format into 'igraph' objects. Includes tools to find all\n  cycles in the resulting graphs and determine which ones involve\n  negative feedback (inhibition).",
    "version": "0.5.0",
    "maintainer": "Kevin R. Coombes <krc@silicovore.com>",
    "author": "Kevin R. Coombes [aut, cre],\n  Polina Bombina [aut]",
    "url": "http://oompa.r-forge.r-project.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WayFindR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WayFindR Computing Graph Structures on WikiPathways Converts pathways from 'WikiPathways' GPML format or\n  'KEGG' KGML format into 'igraph' objects. Includes tools to find all\n  cycles in the resulting graphs and determine which ones involve\n  negative feedback (inhibition).  "
  },
  {
    "id": 8052,
    "package_name": "WeMix",
    "title": "Weighted Mixed-Effects Models Using Multilevel Pseudo Maximum\nLikelihood Estimation",
    "description": "Run mixed-effects models that include weights at every level. The WeMix package fits a weighted mixed model, also known as a multilevel, mixed, or hierarchical linear model (HLM). The weights could be inverse selection probabilities, such as those developed for an education survey where schools are sampled probabilistically, and then students inside of those schools are sampled probabilistically. Although mixed-effects models are already available in R, WeMix is unique in implementing methods for mixed models using weights at multiple levels. Both linear and logit models are supported. Models may have up to three levels. Random effects are estimated using the PIRLS algorithm from 'lme4pureR' (Walker and Bates (2013) <https://github.com/lme4/lme4pureR>).",
    "version": "4.0.3",
    "maintainer": "Paul Bailey <pbailey@air.org>",
    "author": "Emmanuel Sikali [pdr],\n  Paul Bailey [aut, cre],\n  Blue Webb [aut],\n  Claire Kelley [aut],\n  Trang Nguyen [aut],\n  Huade Huo [aut],\n  Steve Walker [cph] (lme4pureR PIRLS function),\n  Doug Bates [cph] (lme4pureR PIRLS function),\n  Eric Buehler [ctb],\n  Christian Christrup Kjeldsen [ctb]",
    "url": "https://american-institutes-for-research.github.io/WeMix/",
    "bug_reports": "https://github.com/American-Institutes-for-Research/WeMix/issues",
    "repository": "https://cran.r-project.org/package=WeMix",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WeMix Weighted Mixed-Effects Models Using Multilevel Pseudo Maximum\nLikelihood Estimation Run mixed-effects models that include weights at every level. The WeMix package fits a weighted mixed model, also known as a multilevel, mixed, or hierarchical linear model (HLM). The weights could be inverse selection probabilities, such as those developed for an education survey where schools are sampled probabilistically, and then students inside of those schools are sampled probabilistically. Although mixed-effects models are already available in R, WeMix is unique in implementing methods for mixed models using weights at multiple levels. Both linear and logit models are supported. Models may have up to three levels. Random effects are estimated using the PIRLS algorithm from 'lme4pureR' (Walker and Bates (2013) <https://github.com/lme4/lme4pureR>).  "
  },
  {
    "id": 8070,
    "package_name": "WgtEff",
    "title": "Functions for Weighting Effects",
    "description": "Functions for determining the effect of data weights on the variance of survey data: users will load a data set which has a weights column, and the package will calculate the design effect (DEFF), weighting loss, root design effect (DEFT), effective sample size (ESS), and/or weighted margin of error.",
    "version": "0.1.2",
    "maintainer": "Joshua Miller <joshlmiller@msn.com>",
    "author": "Joshua Miller [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=WgtEff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "WgtEff Functions for Weighting Effects Functions for determining the effect of data weights on the variance of survey data: users will load a data set which has a weights column, and the package will calculate the design effect (DEFF), weighting loss, root design effect (DEFT), effective sample size (ESS), and/or weighted margin of error.  "
  },
  {
    "id": 8109,
    "package_name": "Xplortext",
    "title": "Statistical Analysis of Textual Data",
    "description": "Provides a set of functions devoted to multivariate exploratory statistics on textual data. Classical methods such as correspondence analysis and agglomerative hierarchical clustering are available. Chronologically constrained agglomerative hierarchical clustering enriched with labelled-by-words trees is offered. Given a division of the corpus into parts, their characteristic words and documents are identified. Further, accessing to 'FactoMineR' functions is very easy. Two of them are relevant in textual domain. MFA() addresses multiple lexical table allowing applications such as dealing with multilingual corpora as well as simultaneously analyzing both open-ended and closed questions in surveys. See <http://xplortext.unileon.es> for examples.",
    "version": "1.5.5",
    "maintainer": "Ram\u00f3n Alvarez-Esteban <ramon.alvarez@unileon.es>",
    "author": "Ram\u00f3n Alvarez-Esteban [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4751-2797>),\n  M\u00f3nica B\u00e9cue-Bertaut [aut] (ORCID:\n    <https://orcid.org/0000-0002-6027-3655>),\n  Josep-Anton S\u00e1nchez-Espigares [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8195-1913>),\n  Belchin Adriyanov Kostov [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2126-3892>)",
    "url": "https://xplortext.unileon.es",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=Xplortext",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "Xplortext Statistical Analysis of Textual Data Provides a set of functions devoted to multivariate exploratory statistics on textual data. Classical methods such as correspondence analysis and agglomerative hierarchical clustering are available. Chronologically constrained agglomerative hierarchical clustering enriched with labelled-by-words trees is offered. Given a division of the corpus into parts, their characteristic words and documents are identified. Further, accessing to 'FactoMineR' functions is very easy. Two of them are relevant in textual domain. MFA() addresses multiple lexical table allowing applications such as dealing with multilingual corpora as well as simultaneously analyzing both open-ended and closed questions in surveys. See <http://xplortext.unileon.es> for examples.  "
  },
  {
    "id": 8177,
    "package_name": "abn",
    "title": "Modelling Multivariate Data with Additive Bayesian Networks",
    "description": "The 'abn' R package facilitates Bayesian network analysis, a\n    probabilistic graphical model that derives from empirical data a\n    directed acyclic graph (DAG). This DAG describes the dependency\n    structure between random variables. The R package 'abn' provides\n    routines to help determine optimal Bayesian network models for a given\n    data set. These models are used to identify statistical dependencies\n    in messy, complex data. Their additive formulation is equivalent to\n    multivariate generalised linear modelling, including mixed models with\n    independent and identically distributed (iid) random effects. The core\n    functionality of the 'abn' package revolves around model selection,\n    also known as structure discovery. It supports both exact and\n    heuristic structure learning algorithms and does not restrict the data\n    distribution of parent-child combinations, providing flexibility in\n    model creation and analysis. The 'abn' package uses Laplace\n    approximations for metric estimation and includes wrappers to the\n    'INLA' package. It also employs 'JAGS' for data simulation purposes.\n    For more resources and information, visit the 'abn' website.",
    "version": "3.1.12",
    "maintainer": "Matteo Delucchi <matteo.delucchi@math.uzh.ch>",
    "author": "Matteo Delucchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9327-1496>),\n  Reinhard Furrer [aut] (ORCID: <https://orcid.org/0000-0002-6319-2332>),\n  Gilles Kratzer [aut] (ORCID: <https://orcid.org/0000-0002-5929-8935>),\n  Fraser Iain Lewis [aut] (ORCID:\n    <https://orcid.org/0000-0003-4580-2712>),\n  Jonas I. Liechti [ctb] (ORCID: <https://orcid.org/0000-0003-3447-3060>),\n  Marta Pittavino [ctb] (ORCID: <https://orcid.org/0000-0002-1232-1034>),\n  Kalina Cherneva [ctb]",
    "url": "https://r-bayesian-networks.org/,\nhttps://github.com/furrer-lab/abn",
    "bug_reports": "https://github.com/furrer-lab/abn/issues",
    "repository": "https://cran.r-project.org/package=abn",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "abn Modelling Multivariate Data with Additive Bayesian Networks The 'abn' R package facilitates Bayesian network analysis, a\n    probabilistic graphical model that derives from empirical data a\n    directed acyclic graph (DAG). This DAG describes the dependency\n    structure between random variables. The R package 'abn' provides\n    routines to help determine optimal Bayesian network models for a given\n    data set. These models are used to identify statistical dependencies\n    in messy, complex data. Their additive formulation is equivalent to\n    multivariate generalised linear modelling, including mixed models with\n    independent and identically distributed (iid) random effects. The core\n    functionality of the 'abn' package revolves around model selection,\n    also known as structure discovery. It supports both exact and\n    heuristic structure learning algorithms and does not restrict the data\n    distribution of parent-child combinations, providing flexibility in\n    model creation and analysis. The 'abn' package uses Laplace\n    approximations for metric estimation and includes wrappers to the\n    'INLA' package. It also employs 'JAGS' for data simulation purposes.\n    For more resources and information, visit the 'abn' website.  "
  },
  {
    "id": 8225,
    "package_name": "actilifecounts",
    "title": "Generate Activity Counts from Raw Accelerometer Data",
    "description": "A tool to obtain activity counts, originally a translation of the \n  'python' package 'agcounts' <https://github.com/actigraph/agcounts>. This tool\n  allows the processing of data from any accelerometer brand, with a more flexible \n  approach to handle different sampling frequencies.",
    "version": "1.1.1",
    "maintainer": "Jairo Hidalgo Migueles <jairo.hidalgo.migueles@gmail.com>",
    "author": "Jairo Hidalgo Migueles",
    "url": "https://github.com/jhmigueles/actilifecounts",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=actilifecounts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "actilifecounts Generate Activity Counts from Raw Accelerometer Data A tool to obtain activity counts, originally a translation of the \n  'python' package 'agcounts' <https://github.com/actigraph/agcounts>. This tool\n  allows the processing of data from any accelerometer brand, with a more flexible \n  approach to handle different sampling frequencies.  "
  },
  {
    "id": 8226,
    "package_name": "activAnalyzer",
    "title": "A 'Shiny' App to Analyze Accelerometer-Measured Daily Physical\nBehavior Data",
    "description": "A tool to analyse 'ActiGraph' accelerometer data and to implement \n    the use of the PROactive Physical Activity in COPD (chronic obstructive pulmonary disease) instruments. Once analysis\n    is completed, the app allows to export results to .csv files and to generate\n    a report of the measurement. All the configured inputs relevant for interpreting\n    the results are recorded in the report. In addition to the existing 'R' packages \n    that are fully integrated with the app, the app uses some functions from the \n    'actigraph.sleepr' package developed by Petkova (2021) <https://github.com/dipetkov/actigraph.sleepr/>.",
    "version": "2.1.2",
    "maintainer": "Pierre-Yves de M\u00fcllenheim <pydemull@uco.fr>",
    "author": "Pierre-Yves de M\u00fcllenheim [cre, aut] (ORCID:\n    <https://orcid.org/0000-0001-9157-7371>)",
    "url": "https://pydemull.github.io/activAnalyzer/,\nhttps://github.com/pydemull/activAnalyzer",
    "bug_reports": "https://github.com/pydemull/activAnalyzer/issues",
    "repository": "https://cran.r-project.org/package=activAnalyzer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "activAnalyzer A 'Shiny' App to Analyze Accelerometer-Measured Daily Physical\nBehavior Data A tool to analyse 'ActiGraph' accelerometer data and to implement \n    the use of the PROactive Physical Activity in COPD (chronic obstructive pulmonary disease) instruments. Once analysis\n    is completed, the app allows to export results to .csv files and to generate\n    a report of the measurement. All the configured inputs relevant for interpreting\n    the results are recorded in the report. In addition to the existing 'R' packages \n    that are fully integrated with the app, the app uses some functions from the \n    'actigraph.sleepr' package developed by Petkova (2021) <https://github.com/dipetkov/actigraph.sleepr/>.  "
  },
  {
    "id": 8231,
    "package_name": "activityCounts",
    "title": "Generate ActiLife Counts",
    "description": "ActiLife software generates activity counts from data collected by Actigraph accelerometers <https://s3.amazonaws.com/actigraphcorp.com/wp-content/uploads/2017/11/26205758/ActiGraph-White-Paper_What-is-a-Count_.pdf>.\n  Actigraph is one of the most common research-grade accelerometers. There is considerable research\n  validating and developing algorithms for human activity using ActiLife counts. Unfortunately,\n  ActiLife counts are proprietary and difficult to implement if researchers use different accelerometer brands.\n  The code  creates ActiLife counts from raw acceleration data for different accelerometer brands and it is developed\n  based on the study done by Brond and others (2017) <doi:10.1249/MSS.0000000000001344>.",
    "version": "0.2.1",
    "maintainer": "Daniel Fuller <daniel.fuller@usask.ca>",
    "author": "Ruben Brondeel [aut],\n  Javad Rahimipour Anaraki [aut],\n  Daniel Fuller [aut, cph, cre],\n  SeyedJavad KhataeiPour [aut],\n  Beap Lab [cph]",
    "url": "https://github.com/walkabillylab/activityCounts,\nhttps://github.com/jbrond/ActigraphCounts",
    "bug_reports": "https://github.com/walkabillylab/activityCounts/issues",
    "repository": "https://cran.r-project.org/package=activityCounts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "activityCounts Generate ActiLife Counts ActiLife software generates activity counts from data collected by Actigraph accelerometers <https://s3.amazonaws.com/actigraphcorp.com/wp-content/uploads/2017/11/26205758/ActiGraph-White-Paper_What-is-a-Count_.pdf>.\n  Actigraph is one of the most common research-grade accelerometers. There is considerable research\n  validating and developing algorithms for human activity using ActiLife counts. Unfortunately,\n  ActiLife counts are proprietary and difficult to implement if researchers use different accelerometer brands.\n  The code  creates ActiLife counts from raw acceleration data for different accelerometer brands and it is developed\n  based on the study done by Brond and others (2017) <doi:10.1249/MSS.0000000000001344>.  "
  },
  {
    "id": 8316,
    "package_name": "admtools",
    "title": "Estimate and Manipulate Age-Depth Models",
    "description": "Estimate age-depth models from stratigraphic and sedimentological data,\n    and transform data\n    between the time and stratigraphic domain.",
    "version": "0.6.0",
    "maintainer": "Niklas Hohmann <N.H.Hohmann@uu.nl>",
    "author": "Niklas Hohmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1559-1838>)",
    "url": "https://github.com/MindTheGap-ERC/admtools,\nhttps://mindthegap-erc.github.io/admtools/",
    "bug_reports": "https://github.com/MindTheGap-ERC/admtools/issues",
    "repository": "https://cran.r-project.org/package=admtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "admtools Estimate and Manipulate Age-Depth Models Estimate age-depth models from stratigraphic and sedimentological data,\n    and transform data\n    between the time and stratigraphic domain.  "
  },
  {
    "id": 8331,
    "package_name": "adwave",
    "title": "Wavelet Analysis of Genomic Data from Admixed Populations",
    "description": "Implements wavelet-based approaches for describing population admixture. Principal Components Analysis (PCA) is used to define the population structure and produce a localized admixture signal for each individual. Wavelet summaries of the PCA output describe variation present in the data and can be related to population-level demographic processes. For more details, see J Sanderson, H Sudoyo, TM Karafet, MF Hammer and MP Cox. 2015. Reconstructing past admixture processes from local genomic ancestry using wavelet transformation. Genetics 200:469-481 <doi:10.1534/genetics.115.176842>.",
    "version": "1.4",
    "maintainer": "Murray Cox <murray.p.cox@gmail.com>",
    "author": "Jean Sanderson [aut],\n  Murray Cox [aut, cre]",
    "url": "https://doi.org/10.1534/genetics.115.176842",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=adwave",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "adwave Wavelet Analysis of Genomic Data from Admixed Populations Implements wavelet-based approaches for describing population admixture. Principal Components Analysis (PCA) is used to define the population structure and produce a localized admixture signal for each individual. Wavelet summaries of the PCA output describe variation present in the data and can be related to population-level demographic processes. For more details, see J Sanderson, H Sudoyo, TM Karafet, MF Hammer and MP Cox. 2015. Reconstructing past admixture processes from local genomic ancestry using wavelet transformation. Genetics 200:469-481 <doi:10.1534/genetics.115.176842>.  "
  },
  {
    "id": 8357,
    "package_name": "agcounts",
    "title": "Calculate 'ActiGraph' Counts from Accelerometer Data",
    "description": "Calculate 'ActiGraph' counts from the X, Y, and Z axes of a triaxial \n    accelerometer. This work was inspired by Neishabouri et al. who published the \n    article \"Quantification of Acceleration as Activity Counts in 'ActiGraph' Wearables\" \n    on February 24, 2022. The link to the article (<https://pubmed.ncbi.nlm.nih.gov/35831446>) \n    and 'python' implementation of this code (<https://github.com/actigraph/agcounts>).",
    "version": "0.6.6",
    "maintainer": "Brian C. Helsel <bhelsel@kumc.edu>",
    "author": "Brian C. Helsel [aut, cre],\n  Paul R. Hibbing [ctb],\n  Robert N. Montgomery [ctb],\n  Eric D. Vidoni [ctb],\n  Jonathan Clutton [ctb],\n  University of Kansas [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=agcounts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "agcounts Calculate 'ActiGraph' Counts from Accelerometer Data Calculate 'ActiGraph' counts from the X, Y, and Z axes of a triaxial \n    accelerometer. This work was inspired by Neishabouri et al. who published the \n    article \"Quantification of Acceleration as Activity Counts in 'ActiGraph' Wearables\" \n    on February 24, 2022. The link to the article (<https://pubmed.ncbi.nlm.nih.gov/35831446>) \n    and 'python' implementation of this code (<https://github.com/actigraph/agcounts>).  "
  },
  {
    "id": 8390,
    "package_name": "aifeducation",
    "title": "Artificial Intelligence for Education",
    "description": "In social and educational settings, the use of Artificial\n    Intelligence (AI) is a challenging task. Relevant data is often only\n    available in handwritten forms, or the use of data is restricted by\n    privacy policies. This often leads to small data sets. Furthermore, in\n    the educational and social sciences, data is often unbalanced in terms\n    of frequencies. To support educators as well as educational and social\n    researchers in using the potentials of AI for their work, this package\n    provides a unified interface for neural nets in 'PyTorch' to deal with\n    natural language problems. In addition, the package ships with a shiny\n    app, providing a graphical user interface.  This allows the usage of\n    AI for people without skills in writing python/R scripts.  The tools\n    integrate existing mathematical and statistical methods for dealing\n    with small data sets via pseudo-labeling (e.g. Cascante-Bonilla et al.\n    (2020) <doi:10.48550/arXiv.2001.06001>) and imbalanced data via the\n    creation of synthetic cases (e.g.  Islam et al. (2012)\n    <doi:10.1016/j.asoc.2021.108288>).  Performance evaluation of AI is\n    connected to measures from content analysis which educational and\n    social researchers are generally more familiar with (e.g. Berding &\n    Pargmann (2022) <doi:10.30819/5581>, Gwet (2014)\n    <ISBN:978-0-9708062-8-4>, Krippendorff (2019)\n    <doi:10.4135/9781071878781>). Estimation of energy consumption and CO2\n    emissions during model training is done with the 'python' library\n    'codecarbon'.  Finally, all objects created with this package allow to\n    share trained AI models with other people.",
    "version": "1.1.3",
    "maintainer": "Berding Florian <florian.berding@uni-hamburg.de>",
    "author": "Berding Florian [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3593-1695>),\n  Tykhonova Yuliia [aut] (ORCID: <https://orcid.org/0009-0006-9015-1006>),\n  Pargmann Julia [ctb] (ORCID: <https://orcid.org/0000-0003-3616-0172>),\n  Leube Anna [ctb] (ORCID: <https://orcid.org/0009-0001-6949-1608>),\n  Riebenbauer Elisabeth [ctb] (ORCID:\n    <https://orcid.org/0000-0002-8535-3694>),\n  Rebmann Karin [ctb],\n  Slopinski Andreas [ctb]",
    "url": "https://fberding.github.io/aifeducation/",
    "bug_reports": "https://github.com/FBerding/aifeducation/issues",
    "repository": "https://cran.r-project.org/package=aifeducation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aifeducation Artificial Intelligence for Education In social and educational settings, the use of Artificial\n    Intelligence (AI) is a challenging task. Relevant data is often only\n    available in handwritten forms, or the use of data is restricted by\n    privacy policies. This often leads to small data sets. Furthermore, in\n    the educational and social sciences, data is often unbalanced in terms\n    of frequencies. To support educators as well as educational and social\n    researchers in using the potentials of AI for their work, this package\n    provides a unified interface for neural nets in 'PyTorch' to deal with\n    natural language problems. In addition, the package ships with a shiny\n    app, providing a graphical user interface.  This allows the usage of\n    AI for people without skills in writing python/R scripts.  The tools\n    integrate existing mathematical and statistical methods for dealing\n    with small data sets via pseudo-labeling (e.g. Cascante-Bonilla et al.\n    (2020) <doi:10.48550/arXiv.2001.06001>) and imbalanced data via the\n    creation of synthetic cases (e.g.  Islam et al. (2012)\n    <doi:10.1016/j.asoc.2021.108288>).  Performance evaluation of AI is\n    connected to measures from content analysis which educational and\n    social researchers are generally more familiar with (e.g. Berding &\n    Pargmann (2022) <doi:10.30819/5581>, Gwet (2014)\n    <ISBN:978-0-9708062-8-4>, Krippendorff (2019)\n    <doi:10.4135/9781071878781>). Estimation of energy consumption and CO2\n    emissions during model training is done with the 'python' library\n    'codecarbon'.  Finally, all objects created with this package allow to\n    share trained AI models with other people.  "
  },
  {
    "id": 8418,
    "package_name": "alcyon",
    "title": "Spatial Network Analysis",
    "description": "Interface package for 'sala', the spatial network analysis library\n    from the 'depthmapX' software application. The R parts of the code are based\n    on the 'rdepthmap' package. Allows for the analysis of urban and\n    building-scale networks and provides metrics and methods usually found\n    within the Space Syntax domain. Methods in this package are described by K.\n    Al-Sayed, A. Turner, B. Hillier, S. Iida and A. Penn (2014) \"Space Syntax\n    methodology\", and also by A. Turner (2004)\n    <https://discovery.ucl.ac.uk/id/eprint/2651> \"Depthmap 4: a researcher's\n    handbook\".",
    "version": "0.8.1",
    "maintainer": "Petros Koutsolampros <r-devel@pklampros.net>",
    "author": "Petros Koutsolampros [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-2842-9899>, 'sala' library contributor\n    through 'depthmapX'),\n  Fani Kostourou [ctb] (ORCID: <https://orcid.org/0000-0002-6544-7693>),\n  Kimon Krenz [ctb] (ORCID: <https://orcid.org/0000-0001-6077-7282>),\n  Alasdair Turner [ctb] ('sala' library contributor through 'depthmapX'),\n  Tasos Varoudis [ctb] (ORCID: <https://orcid.org/0000-0001-7790-5623>,\n    'sala' library contributor through 'depthmapX'),\n  Christian Sailer [ctb] ('sala' library contributor through 'depthmapX'),\n  Eva Friedrich [ctb] ('sala' library contributor through 'depthmapX'),\n  University College London [fnd, cph] (2015 - 2020),\n  Spacelab UK [fnd] (2015 - 2020)",
    "url": "https://github.com/spatialnous/alcyon,\nhttps://spatialnous.github.io/alcyon/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=alcyon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "alcyon Spatial Network Analysis Interface package for 'sala', the spatial network analysis library\n    from the 'depthmapX' software application. The R parts of the code are based\n    on the 'rdepthmap' package. Allows for the analysis of urban and\n    building-scale networks and provides metrics and methods usually found\n    within the Space Syntax domain. Methods in this package are described by K.\n    Al-Sayed, A. Turner, B. Hillier, S. Iida and A. Penn (2014) \"Space Syntax\n    methodology\", and also by A. Turner (2004)\n    <https://discovery.ucl.ac.uk/id/eprint/2651> \"Depthmap 4: a researcher's\n    handbook\".  "
  },
  {
    "id": 8424,
    "package_name": "algaeClassify",
    "title": "Tools to Query the 'Algaebase' Online Database, Standardize\nPhytoplankton Taxonomic Data, and Perform Functional Group\nClassifications",
    "description": "Functions that facilitate the use of accepted taxonomic nomenclature, collection of\n\tfunctional trait data, and assignment of functional group classifications to phytoplankton\n\tspecies. Possible classifications include Morpho-functional group (MFG; Salmaso et al. 2015 \n\t<doi:10.1111/fwb.12520>) and CSR (Reynolds 1988; Functional morphology and the \n\tadaptive strategies of phytoplankton. In C.D. Sandgren (ed). Growth and reproductive \n\tstrategies of freshwater phytoplankton, 388-433. Cambridge University Press, New York). \n\tVersions 2.0.0 and later includes new functions for querying the \n\t'algaebase' online taxonomic database (www.algaebase.org), however these functions require\n\ta valid API key that must be acquired from the 'algaebase' administrators. \n\tNote that none of the 'algaeClassify' authors are affiliated with 'algaebase' in any way. Taxonomic \n\tnames can also be checked against a variety of taxonomic databases using \n\tthe 'Global Names Resolver' service via its API (<https://resolver.globalnames.org/api>). In addition,\n\tcurrently accepted and outdated synonyms, and higher taxonomy, can be extracted for lists of \n\tspecies from the 'ITIS' database using wrapper functions for the ritis package.\n\tThe 'algaeClassify' package is a product of the GEISHA (Global Evaluation of the Impacts of \n\tStorms on freshwater Habitat and Structure of phytoplankton Assemblages), funded by CESAB \n    (Centre for Synthesis and Analysis of Biodiversity) and the U.S. Geological Survey John Wesley Powell Center for\n\tSynthesis and Analysis, with data and other support provided by members of GLEON \n\t(Global Lake Ecology Observation Network). \n\tDISCLAIMER: This software has been approved for release by the \n\tU.S. Geological Survey (USGS). Although the software has been subjected to rigorous review, \n\tthe USGS reserves the right to update the software as needed pursuant to further analysis and \n\treview. No warranty, expressed or implied, is made by the USGS or the U.S. Government as to the \n\tfunctionality of the software and related material nor shall the fact of release constitute \n\tany such warranty. Furthermore, the software is released on condition that neither the USGS \n\tnor the U.S. Government shall be held liable for any damages resulting from its authorized \n\tor unauthorized use.",
    "version": "2.0.5",
    "maintainer": "Vijay Patil <vij.patil@gmail.com>",
    "author": "Vijay Patil [aut, cre],\n  Torsten Seltmann [aut],\n  Nico Salmaso [aut],\n  Orlane Anneville [aut],\n  Marc Lajeunesse [aut],\n  Dietmar Straile [aut]",
    "url": "https://doi.org/10.5066/F7S46Q3F",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=algaeClassify",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "algaeClassify Tools to Query the 'Algaebase' Online Database, Standardize\nPhytoplankton Taxonomic Data, and Perform Functional Group\nClassifications Functions that facilitate the use of accepted taxonomic nomenclature, collection of\n\tfunctional trait data, and assignment of functional group classifications to phytoplankton\n\tspecies. Possible classifications include Morpho-functional group (MFG; Salmaso et al. 2015 \n\t<doi:10.1111/fwb.12520>) and CSR (Reynolds 1988; Functional morphology and the \n\tadaptive strategies of phytoplankton. In C.D. Sandgren (ed). Growth and reproductive \n\tstrategies of freshwater phytoplankton, 388-433. Cambridge University Press, New York). \n\tVersions 2.0.0 and later includes new functions for querying the \n\t'algaebase' online taxonomic database (www.algaebase.org), however these functions require\n\ta valid API key that must be acquired from the 'algaebase' administrators. \n\tNote that none of the 'algaeClassify' authors are affiliated with 'algaebase' in any way. Taxonomic \n\tnames can also be checked against a variety of taxonomic databases using \n\tthe 'Global Names Resolver' service via its API (<https://resolver.globalnames.org/api>). In addition,\n\tcurrently accepted and outdated synonyms, and higher taxonomy, can be extracted for lists of \n\tspecies from the 'ITIS' database using wrapper functions for the ritis package.\n\tThe 'algaeClassify' package is a product of the GEISHA (Global Evaluation of the Impacts of \n\tStorms on freshwater Habitat and Structure of phytoplankton Assemblages), funded by CESAB \n    (Centre for Synthesis and Analysis of Biodiversity) and the U.S. Geological Survey John Wesley Powell Center for\n\tSynthesis and Analysis, with data and other support provided by members of GLEON \n\t(Global Lake Ecology Observation Network). \n\tDISCLAIMER: This software has been approved for release by the \n\tU.S. Geological Survey (USGS). Although the software has been subjected to rigorous review, \n\tthe USGS reserves the right to update the software as needed pursuant to further analysis and \n\treview. No warranty, expressed or implied, is made by the USGS or the U.S. Government as to the \n\tfunctionality of the software and related material nor shall the fact of release constitute \n\tany such warranty. Furthermore, the software is released on condition that neither the USGS \n\tnor the U.S. Government shall be held liable for any damages resulting from its authorized \n\tor unauthorized use.  "
  },
  {
    "id": 8429,
    "package_name": "align",
    "title": "A Modified DTW Algorithm for Stratigraphic Time Series Alignment",
    "description": "A dynamic time warping (DTW) algorithm for stratigraphic alignment,\n    translated into R from the original published 'MATLAB' code by Hay et al. (2019)\n    <doi:10.1130/G46019.1>. The DTW algorithm incorporates two geologically relevant\n    parameters (g and edge) for augmenting the typical DTW cost matrix, allowing\n    for a range of sedimentologic and chronologic conditions to be explored, as \n    well as the generation of an alignment library (as opposed to a single alignment\n    solution). The g parameter relates to the relative sediment accumulation rate\n    between the two time series records,  while the edge parameter relates to the \n    amount of total shared time between the records. Note that this algorithm is\n    used for all DTW alignments in the Align Shiny application, detailed in Hagen\n    et al. (in review).",
    "version": "0.1.0",
    "maintainer": "Cedric Hagen <ch0934@princeton.edu>",
    "author": "Cedric Hagen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=align",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "align A Modified DTW Algorithm for Stratigraphic Time Series Alignment A dynamic time warping (DTW) algorithm for stratigraphic alignment,\n    translated into R from the original published 'MATLAB' code by Hay et al. (2019)\n    <doi:10.1130/G46019.1>. The DTW algorithm incorporates two geologically relevant\n    parameters (g and edge) for augmenting the typical DTW cost matrix, allowing\n    for a range of sedimentologic and chronologic conditions to be explored, as \n    well as the generation of an alignment library (as opposed to a single alignment\n    solution). The g parameter relates to the relative sediment accumulation rate\n    between the two time series records,  while the edge parameter relates to the \n    amount of total shared time between the records. Note that this algorithm is\n    used for all DTW alignments in the Align Shiny application, detailed in Hagen\n    et al. (in review).  "
  },
  {
    "id": 8502,
    "package_name": "aniSNA",
    "title": "Statistical Network Analysis of Animal Social Networks",
    "description": "Obtain network structures from animal GPS telemetry observations and \n    statistically analyse them to assess their adequacy for social network analysis. Methods include \n    pre-network data permutations, bootstrapping techniques to obtain confidence intervals \n    for global and node-level network metrics, and correlation and regression analysis of the local network metrics. ",
    "version": "1.1.1",
    "maintainer": "Prabhleen Kaur <prabhleen.kaur.ucd@gmail.com>",
    "author": "Prabhleen Kaur [aut, cre],\n  Michael Salter-Townshend [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=aniSNA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "aniSNA Statistical Network Analysis of Animal Social Networks Obtain network structures from animal GPS telemetry observations and \n    statistically analyse them to assess their adequacy for social network analysis. Methods include \n    pre-network data permutations, bootstrapping techniques to obtain confidence intervals \n    for global and node-level network metrics, and correlation and regression analysis of the local network metrics.   "
  },
  {
    "id": 8506,
    "package_name": "animation",
    "title": "A Gallery of Animations in Statistics and Utilities to Create\nAnimations",
    "description": "Provides functions for animations in statistics, covering topics\n    in probability theory, mathematical statistics, multivariate statistics,\n    non-parametric statistics, sampling survey, linear models, time series,\n    computational statistics, data mining and machine learning. These functions\n    may be helpful in teaching statistics and data analysis. Also provided in this\n    package are a series of functions to save animations to various formats, e.g.\n    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted\n    into 'Sweave' / 'knitr' easily.",
    "version": "2.8",
    "maintainer": "Yihui Xie <xie@yihui.name>",
    "author": "Yihui Xie [aut, cre] (ORCID: <https://orcid.org/0000-0003-0645-5666>,\n    URL: https://yihui.org),\n  Christian Mueller [ctb],\n  Lijia Yu [ctb],\n  Xinyuan Chu [ctb],\n  Weicheng Zhu [ctb]",
    "url": "https://yihui.org/animation/",
    "bug_reports": "https://github.com/yihui/animation/issues",
    "repository": "https://cran.r-project.org/package=animation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "animation A Gallery of Animations in Statistics and Utilities to Create\nAnimations Provides functions for animations in statistics, covering topics\n    in probability theory, mathematical statistics, multivariate statistics,\n    non-parametric statistics, sampling survey, linear models, time series,\n    computational statistics, data mining and machine learning. These functions\n    may be helpful in teaching statistics and data analysis. Also provided in this\n    package are a series of functions to save animations to various formats, e.g.\n    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted\n    into 'Sweave' / 'knitr' easily.  "
  },
  {
    "id": 8507,
    "package_name": "animbook",
    "title": "Visualizing Changes in Performance Measures and Demographic\nAffiliations using Animation",
    "description": "Create an interactive visualization to be used for communication purposes. Providing the function for preparing, plotting, and animating the data. Krisanat Anukarnsakulchularp (2023) <https://github.com/KrisanatA/animbook-journal>.",
    "version": "1.0.1",
    "maintainer": "Krisanat Anukarnsakulchularp <krisanat.anu@gmail.com>",
    "author": "Krisanat Anukarnsakulchularp [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0008-5638-7124>),\n  Dianne Cook [aut] (ORCID: <https://orcid.org/0000-0002-3813-7155>)",
    "url": "https://github.com/KrisanatA/animbook",
    "bug_reports": "https://github.com/KrisanatA/animbook/issues",
    "repository": "https://cran.r-project.org/package=animbook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "animbook Visualizing Changes in Performance Measures and Demographic\nAffiliations using Animation Create an interactive visualization to be used for communication purposes. Providing the function for preparing, plotting, and animating the data. Krisanat Anukarnsakulchularp (2023) <https://github.com/KrisanatA/animbook-journal>.  "
  },
  {
    "id": 8570,
    "package_name": "apportion",
    "title": "Apportion Seats",
    "description": "Convert populations into integer number of seats for legislative \n    bodies. Implements apportionment methods used historically and currently in the\n    United States for reapportionment after the Census, as described in \n    <https://www.census.gov/history/www/reference/apportionment/methods_of_apportionment.html>. ",
    "version": "0.0.2",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>)",
    "url": "https://github.com/christopherkenny/apportion,\nhttp://christophertkenny.com/apportion/",
    "bug_reports": "https://github.com/christopherkenny/apportion/issues",
    "repository": "https://cran.r-project.org/package=apportion",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "apportion Apportion Seats Convert populations into integer number of seats for legislative \n    bodies. Implements apportionment methods used historically and currently in the\n    United States for reapportionment after the Census, as described in \n    <https://www.census.gov/history/www/reference/apportionment/methods_of_apportionment.html>.   "
  },
  {
    "id": 8580,
    "package_name": "apyramid",
    "title": "Visualize Population Pyramids Aggregated by Age",
    "description": "Provides a quick method for visualizing non-aggregated line-list\n    or aggregated census data stratified by age and one or two categorical\n    variables (e.g. gender and health status) with any number of values. It\n    returns a 'ggplot' object, allowing the user to further customize the\n    output. This package is part of the 'R4Epis' project \n    <https://r4epis.netlify.app/>.",
    "version": "0.1.3",
    "maintainer": "Zhian N. Kamvar <zkamvar@gmail.com>",
    "author": "Zhian N. Kamvar [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1458-7108>),\n  Alex Spina [ctb]",
    "url": "https://github.com/R4EPI/apyramid, https://r4epis.netlify.app/",
    "bug_reports": "https://github.com/R4EPI/apyramid/issues",
    "repository": "https://cran.r-project.org/package=apyramid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "apyramid Visualize Population Pyramids Aggregated by Age Provides a quick method for visualizing non-aggregated line-list\n    or aggregated census data stratified by age and one or two categorical\n    variables (e.g. gender and health status) with any number of values. It\n    returns a 'ggplot' object, allowing the user to further customize the\n    output. This package is part of the 'R4Epis' project \n    <https://r4epis.netlify.app/>.  "
  },
  {
    "id": 8598,
    "package_name": "archeofrag",
    "title": "Spatial Analysis in Archaeology from Refitting Fragments",
    "description": "Methods to analyse spatial units in archaeology from the relationships between refitting fragmented objects scattered in these units (e.g. stratigraphic layers). Graphs are used to model archaeological observations. The package is mainly based on the 'igraph' package for graph analysis. Functions can: 1) create, manipulate, visualise, and simulate fragmentation graphs, 2) measure the cohesion and admixture of archaeological spatial units, and 3) characterise the topology of a specific set of refitting relationships. A series of published empirical datasets is included. Documentation about 'archeofrag' is provided by a vignette and by the accompanying scientific papers: Plutniak (2021, Journal of Archaeological Science, <doi:10.1016/j.jas.2021.105501>) and Plutniak (2022, Journal of Open Source Software, <doi:10.21105/joss.04335>). This package is complemented by the 'archeofrag.gui' R package, a companion GUI application available at <https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/>.",
    "version": "1.2.3",
    "maintainer": "Sebastien Plutniak <sebastien.plutniak@posteo.net>",
    "author": "Sebastien Plutniak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6674-3806>)",
    "url": "https://github.com/sebastien-plutniak/archeofrag",
    "bug_reports": "https://github.com/sebastien-plutniak/archeofrag/issues",
    "repository": "https://cran.r-project.org/package=archeofrag",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "archeofrag Spatial Analysis in Archaeology from Refitting Fragments Methods to analyse spatial units in archaeology from the relationships between refitting fragmented objects scattered in these units (e.g. stratigraphic layers). Graphs are used to model archaeological observations. The package is mainly based on the 'igraph' package for graph analysis. Functions can: 1) create, manipulate, visualise, and simulate fragmentation graphs, 2) measure the cohesion and admixture of archaeological spatial units, and 3) characterise the topology of a specific set of refitting relationships. A series of published empirical datasets is included. Documentation about 'archeofrag' is provided by a vignette and by the accompanying scientific papers: Plutniak (2021, Journal of Archaeological Science, <doi:10.1016/j.jas.2021.105501>) and Plutniak (2022, Journal of Open Source Software, <doi:10.21105/joss.04335>). This package is complemented by the 'archeofrag.gui' R package, a companion GUI application available at <https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/>.  "
  },
  {
    "id": 8608,
    "package_name": "arctools",
    "title": "Processing and Physical Activity Summaries of Minute Level\nActivity Data",
    "description": "Provides functions to process minute level actigraphy-measured activity counts data and extract commonly used physical activity volume and fragmentation metrics.",
    "version": "1.1.6",
    "maintainer": "Marta Karas <marta.karass@gmail.com>",
    "author": "Marta Karas [aut, cre] (ORCID: <https://orcid.org/0000-0001-5889-3970>),\n  Jennifer Schrack [aut] (ORCID: <https://orcid.org/0000-0001-9244-9267>),\n  Jacek Urbanek [aut] (ORCID: <https://orcid.org/0000-0002-1890-8899>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=arctools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arctools Processing and Physical Activity Summaries of Minute Level\nActivity Data Provides functions to process minute level actigraphy-measured activity counts data and extract commonly used physical activity volume and fragmentation metrics.  "
  },
  {
    "id": 8614,
    "package_name": "arealDB",
    "title": "Harmonise and Integrate Heterogeneous Areal Data",
    "description": "Many relevant applications in the environmental and socioeconomic \n    sciences use areal data, such as biodiversity checklists, agricultural statistics, \n    or socioeconomic surveys. For applications that surpass the spatial, temporal or \n    thematic scope of any single data source, data must be integrated from several \n    heterogeneous sources. Inconsistent concepts, definitions, or messy data tables \n    make this a tedious and error-prone process. 'arealDB' tackles those problems and \n    helps the user to integrate a harmonised databases of areal data. Read the paper\n    at Ehrmann, Seppelt & Meyer (2020) <doi:10.1016/j.envsoft.2020.104799>.",
    "version": "0.9.4",
    "maintainer": "Steffen Ehrmann <steffen.ehrmann@posteo.de>",
    "author": "Steffen Ehrmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2958-0796>),\n  Arne R\u00fcmmler [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0001-8637-9071>),\n  Felipe Melges [ctb] (ORCID: <https://orcid.org/0000-0003-0833-8973>),\n  Carsten Meyer [aut] (ORCID: <https://orcid.org/0000-0003-3927-5856>)",
    "url": "https://github.com/luckinet/arealDB",
    "bug_reports": "https://github.com/luckinet/arealDB/issues",
    "repository": "https://cran.r-project.org/package=arealDB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arealDB Harmonise and Integrate Heterogeneous Areal Data Many relevant applications in the environmental and socioeconomic \n    sciences use areal data, such as biodiversity checklists, agricultural statistics, \n    or socioeconomic surveys. For applications that surpass the spatial, temporal or \n    thematic scope of any single data source, data must be integrated from several \n    heterogeneous sources. Inconsistent concepts, definitions, or messy data tables \n    make this a tedious and error-prone process. 'arealDB' tackles those problems and \n    helps the user to integrate a harmonised databases of areal data. Read the paper\n    at Ehrmann, Seppelt & Meyer (2020) <doi:10.1016/j.envsoft.2020.104799>.  "
  },
  {
    "id": 8633,
    "package_name": "arlclustering",
    "title": "Exploring Social Network Structures Through Friendship-Driven\nCommunity Detection with Association Rules Mining",
    "description": "Implements an innovative approach to community detection in social networks using Association Rules Learning. The package provides tools for processing graph and rules objects, generating association rules, and detecting communities based on node interactions. Designed to facilitate advanced research in Social Network Analysis, this package leverages association rules learning for enhanced community detection. This approach is described in El-Moussaoui et al. (2021) <doi:10.1007/978-3-030-66840-2_3>.",
    "version": "1.0.5",
    "maintainer": "Mohamed El-Moussaoui <med.elmoussaoui.ced@gmail.com>",
    "author": "Mohamed El-Moussaoui [aut, cre],\n  Mohamed Hanine [aut],\n  Ali Kartit [ths],\n  Tarik Agouti [rev]",
    "url": "https://github.com/assuom44/arlclustering",
    "bug_reports": "https://github.com/assuom44/arlclustering/issues",
    "repository": "https://cran.r-project.org/package=arlclustering",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arlclustering Exploring Social Network Structures Through Friendship-Driven\nCommunity Detection with Association Rules Mining Implements an innovative approach to community detection in social networks using Association Rules Learning. The package provides tools for processing graph and rules objects, generating association rules, and detecting communities based on node interactions. Designed to facilitate advanced research in Social Network Analysis, this package leverages association rules learning for enhanced community detection. This approach is described in El-Moussaoui et al. (2021) <doi:10.1007/978-3-030-66840-2_3>.  "
  },
  {
    "id": 8651,
    "package_name": "arthistory",
    "title": "Art History Textbook Data",
    "description": "Data from Gardner and Janson art history textbooks about both the artists featured in these books as well as their works.\n    See Helen Gardner (\"Art through the ages; an introduction to its history and significance,\" 1926, <https://find.library.duke.edu/catalog/DUKE000104481>.\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1980, ISBN: 0155037587).\n    Fred S. Kleiner (\"Gardner\u2019s art through the ages: a global history,\" 2020, ISBN: 9781337630702).\n    Horst de la Croix and Richard G. Tansey (\"Gardner's art through the ages,\" 1986, ISBN: 0155037633).\n    Helen Gardner (\"Art through the ages; an introduction to its history and significance,\" 1936, <https://find.library.duke.edu/catalog/DUKE001199463>).\n    Helen Gardner (\"Art through the ages,\" 1948, <https://find.library.duke.edu/catalog/DUKE001199466>).\n    Helen Gardner, revised under the editorship of Sumner M. Crosby (\"Art through the ages,\" 1959, <https://find.library.duke.edu/catalog/DUKE001199469>).\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1975, ISBN: 0155037560).\n    Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2013, ISBN: 9780495915423.\n    Fred S. Kleiner, Christin J. Mamiya, Richard G. Tansey (\"Gardner\u2019s art through the ages,\" 2001, ISBN: 0155083155).\n    Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2016, ISBN: 9781285837840).\n    Fred S. Kleiner, Christin J. Mamiya (\"Gardner\u2019s art through the ages,\" 2005, ISBN: 0534640958).\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1970, ISBN: 0155037528).\n    Helen Gardner, Richard G. Tansey, Fred S. Kleiner (\"Gardner\u2019s Art through the ages,\" 1996, ISBN: 0155011413).\n    Helen Gardner, Horst de la Croix, Richard G. Tansey, Diane Kirkpatrick (\"Gardner\u2019s Art through the ages,\" 1991, ISBN: 0155037692).\n    Helen Gardner, Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2009, ISBN: 9780495093077).\n    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (\"Janson\u2019s history of art: the western tradition,\" 2007, ISBN: 0131934554).\n    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (\"Janson\u2019s history of art: the western tradition,\" 2011, ISBN: 9780205685172).\n    H. W. Janson, Anthony F. Janson (\"History of Art,\" 2001, ISBN: 0810934469).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1986, ISBN: 013389388).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1977, ISBN: 0810910527).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1969, <https://find.library.duke.edu/catalog/DUKE000005734>).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1963, <https://find.library.duke.edu/catalog/DUKE001521852>).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1991, ISBN: 0810934019).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1995, ISBN: 0810934213).",
    "version": "0.1.0",
    "maintainer": "Sara Lemus <saralemus70@gmail.com>",
    "author": "Sara Lemus [aut, cre],\n  Holland Stam [aut] (ORCID: <https://orcid.org/0000-0003-0868-5342>)",
    "url": "https://github.com/saralemus7/arthistory,\nhttps://saralemus7.github.io/arthistory/",
    "bug_reports": "https://github.com/saralemus7/arthistory/issues",
    "repository": "https://cran.r-project.org/package=arthistory",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "arthistory Art History Textbook Data Data from Gardner and Janson art history textbooks about both the artists featured in these books as well as their works.\n    See Helen Gardner (\"Art through the ages; an introduction to its history and significance,\" 1926, <https://find.library.duke.edu/catalog/DUKE000104481>.\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1980, ISBN: 0155037587).\n    Fred S. Kleiner (\"Gardner\u2019s art through the ages: a global history,\" 2020, ISBN: 9781337630702).\n    Horst de la Croix and Richard G. Tansey (\"Gardner's art through the ages,\" 1986, ISBN: 0155037633).\n    Helen Gardner (\"Art through the ages; an introduction to its history and significance,\" 1936, <https://find.library.duke.edu/catalog/DUKE001199463>).\n    Helen Gardner (\"Art through the ages,\" 1948, <https://find.library.duke.edu/catalog/DUKE001199466>).\n    Helen Gardner, revised under the editorship of Sumner M. Crosby (\"Art through the ages,\" 1959, <https://find.library.duke.edu/catalog/DUKE001199469>).\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1975, ISBN: 0155037560).\n    Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2013, ISBN: 9780495915423.\n    Fred S. Kleiner, Christin J. Mamiya, Richard G. Tansey (\"Gardner\u2019s art through the ages,\" 2001, ISBN: 0155083155).\n    Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2016, ISBN: 9781285837840).\n    Fred S. Kleiner, Christin J. Mamiya (\"Gardner\u2019s art through the ages,\" 2005, ISBN: 0534640958).\n    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (\"Gardner\u2019s Art through the ages,\" 1970, ISBN: 0155037528).\n    Helen Gardner, Richard G. Tansey, Fred S. Kleiner (\"Gardner\u2019s Art through the ages,\" 1996, ISBN: 0155011413).\n    Helen Gardner, Horst de la Croix, Richard G. Tansey, Diane Kirkpatrick (\"Gardner\u2019s Art through the ages,\" 1991, ISBN: 0155037692).\n    Helen Gardner, Fred S. Kleiner (\"Gardner\u2019s Art through the ages: a global history,\" 2009, ISBN: 9780495093077).\n    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (\"Janson\u2019s history of art: the western tradition,\" 2007, ISBN: 0131934554).\n    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (\"Janson\u2019s history of art: the western tradition,\" 2011, ISBN: 9780205685172).\n    H. W. Janson, Anthony F. Janson (\"History of Art,\" 2001, ISBN: 0810934469).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1986, ISBN: 013389388).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1977, ISBN: 0810910527).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1969, <https://find.library.duke.edu/catalog/DUKE000005734>).\n    H. W. Janson, Dora Jane Janson (\"History of art: a survey of the major visual arts from the dawn of history to present day,\" 1963, <https://find.library.duke.edu/catalog/DUKE001521852>).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1991, ISBN: 0810934019).\n    H. W. Janson, revised and expanded by Anthony F. Janson (\"History of art,\" 1995, ISBN: 0810934213).  "
  },
  {
    "id": 8677,
    "package_name": "asnipe",
    "title": "Animal Social Network Inference and Permutations for Ecologists",
    "description": "Implements several tools that are used in animal social network analysis, as described in Whitehead (2007) Analyzing Animal Societies <University of Chicago Press> and Farine & Whitehead (2015) <doi: 10.1111/1365-2656.12418>. In particular, this package provides the tools to infer groups and generate networks from observation data, perform permutation tests on the data, calculate lagged association rates, and performed multiple regression analysis on social network data.",
    "version": "1.1.17",
    "maintainer": "Damien R. Farine <dfarine@ab.mpg.de>",
    "author": "Damien R. Farine <dfarine@ab.mpg.de>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=asnipe",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "asnipe Animal Social Network Inference and Permutations for Ecologists Implements several tools that are used in animal social network analysis, as described in Whitehead (2007) Analyzing Animal Societies <University of Chicago Press> and Farine & Whitehead (2015) <doi: 10.1111/1365-2656.12418>. In particular, this package provides the tools to infer groups and generate networks from observation data, perform permutation tests on the data, calculate lagged association rates, and performed multiple regression analysis on social network data.  "
  },
  {
    "id": 8771,
    "package_name": "auxvecLASSO",
    "title": "LASSO Auxiliary Variable Selection and Auxiliary Vector\nDiagnostics",
    "description": "Provides tools for assessing and selecting auxiliary variables using LASSO. \n    The package includes functions for variable selection and diagnostics, facilitating \n    survey calibration analysis with emphasis on robust auxiliary vector selection. For \n    more details see Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x> and \n    Caughrey and Hartman (2017) <doi:10.2139/ssrn.3494436>.",
    "version": "0.2.0",
    "maintainer": "Gustaf Andersson <gustafanderssons@gmail.com>",
    "author": "Gustaf Andersson [aut, cre, cph]",
    "url": "https://github.com/gustafanderssons/auxvecLASSO-R-Package",
    "bug_reports": "https://github.com/gustafanderssons/auxvecLASSO-R-Package/issues",
    "repository": "https://cran.r-project.org/package=auxvecLASSO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "auxvecLASSO LASSO Auxiliary Variable Selection and Auxiliary Vector\nDiagnostics Provides tools for assessing and selecting auxiliary variables using LASSO. \n    The package includes functions for variable selection and diagnostics, facilitating \n    survey calibration analysis with emphasis on robust auxiliary vector selection. For \n    more details see Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x> and \n    Caughrey and Hartman (2017) <doi:10.2139/ssrn.3494436>.  "
  },
  {
    "id": 8807,
    "package_name": "bSims",
    "title": "Agent-Based Bird Point Count Simulator",
    "description": "A highly scientific and utterly addictive \n  bird point count simulator\n  to test statistical assumptions, aid survey design,\n  and have fun while doing it (Solymos 2024 <doi:10.1007/s42977-023-00183-2>).\n  The simulations follow time-removal and distance sampling models \n  based on Matsuoka et al. (2012) <doi:10.1525/auk.2012.11190>,\n  Solymos et al. (2013) <doi:10.1111/2041-210X.12106>,\n  and Solymos et al. (2018) <doi:10.1650/CONDOR-18-32.1>,\n  and sound attenuation experiments by \n  Yip et al. (2017) <doi:10.1650/CONDOR-16-93.1>.",
    "version": "0.3-3",
    "maintainer": "Peter Solymos <psolymos@gmail.com>",
    "author": "Peter Solymos [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7337-1740>)",
    "url": "https://github.com/psolymos/bSims",
    "bug_reports": "https://github.com/psolymos/bSims/issues",
    "repository": "https://cran.r-project.org/package=bSims",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bSims Agent-Based Bird Point Count Simulator A highly scientific and utterly addictive \n  bird point count simulator\n  to test statistical assumptions, aid survey design,\n  and have fun while doing it (Solymos 2024 <doi:10.1007/s42977-023-00183-2>).\n  The simulations follow time-removal and distance sampling models \n  based on Matsuoka et al. (2012) <doi:10.1525/auk.2012.11190>,\n  Solymos et al. (2013) <doi:10.1111/2041-210X.12106>,\n  and Solymos et al. (2018) <doi:10.1650/CONDOR-18-32.1>,\n  and sound attenuation experiments by \n  Yip et al. (2017) <doi:10.1650/CONDOR-16-93.1>.  "
  },
  {
    "id": 8826,
    "package_name": "baf",
    "title": "Block Assignment Files",
    "description": "Download and read US Census Bureau data relationship files. Provides \n    support for cleaning and using block assignment files since 2010, as described in \n    <https://www.census.gov/geographies/reference-files/time-series/geo/block-assignment-files.html>. \n    Also includes support for working with block equivalency files, used for years \n    outside of decennial census years.",
    "version": "0.0.4",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>),\n  Cory McCartan [ctb] (ORCID: <https://orcid.org/0000-0002-6251-669X>)",
    "url": "http://christophertkenny.com/baf/,\nhttps://github.com/christopherkenny/baf",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=baf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "baf Block Assignment Files Download and read US Census Bureau data relationship files. Provides \n    support for cleaning and using block assignment files since 2010, as described in \n    <https://www.census.gov/geographies/reference-files/time-series/geo/block-assignment-files.html>. \n    Also includes support for working with block equivalency files, used for years \n    outside of decennial census years.  "
  },
  {
    "id": 8889,
    "package_name": "basicspace",
    "title": "Recovering a Basic Space from Issue Scales",
    "description": "Provides functions to estimate latent dimensions of choice and judgment using Aldrich-McKelvey and Blackbox scaling methods, as described in Poole et al. (2016, <doi:10.18637/jss.v069.i07>). These techniques allow researchers (particularly those analyzing political attitudes, public opinion, and legislative behavior) to recover spatial estimates of political actors' ideal points and stimuli from issue scale data, accounting for perceptual bias, multidimensional spaces, and missing data. The package uses singular value decomposition and alternating least squares (ALS) procedures to scale self-placement and perceptual data into a common latent space for the analysis of ideological or evaluative dimensions. Functionality also include tools for assessing model fit, handling complex survey data structures, and reproducing simulated datasets for methodological validation. ",
    "version": "0.25",
    "maintainer": "Christopher Hare <cdhare@ucdavis.edu>",
    "author": "Royce Carroll [aut],\n  Christopher Hare [aut, cre],\n  Jeffrey B. Lewis [aut],\n  James Lo [aut],\n  Keith T. Poole [aut],\n  Howard Rosenthal [aut]",
    "url": "https://CRAN.R-project.org/package=basicspace",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=basicspace",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "basicspace Recovering a Basic Space from Issue Scales Provides functions to estimate latent dimensions of choice and judgment using Aldrich-McKelvey and Blackbox scaling methods, as described in Poole et al. (2016, <doi:10.18637/jss.v069.i07>). These techniques allow researchers (particularly those analyzing political attitudes, public opinion, and legislative behavior) to recover spatial estimates of political actors' ideal points and stimuli from issue scale data, accounting for perceptual bias, multidimensional spaces, and missing data. The package uses singular value decomposition and alternating least squares (ALS) procedures to scale self-placement and perceptual data into a common latent space for the analysis of ideological or evaluative dimensions. Functionality also include tools for assessing model fit, handling complex survey data structures, and reproducing simulated datasets for methodological validation.   "
  },
  {
    "id": 8903,
    "package_name": "batman",
    "title": "Convert Categorical Representations of Logicals to Actual\nLogicals",
    "description": "Survey systems and other third-party data sources commonly use non-standard representations of logical values when\n    it comes to qualitative data - \"Yes\", \"No\" and \"N/A\", say. batman is a package designed to seamlessly convert these into logicals.\n    It is highly localised, and contains equivalents to boolean values in languages including German, French, Spanish, Italian,\n    Turkish, Chinese and Polish.",
    "version": "0.1.0",
    "maintainer": "Oliver Keyes <ironholds@gmail.com>",
    "author": "Oliver Keyes [aut, cre], Ruben C. Arslan [ctb], Christopher Akiki [ctb], Mine Cetinkaya-Rundel [ctb], Peter Meissner [ctb],\n        Ilaria Prosdocimi [ctb], Thomas Leeper [ctb], Amy Lee [ctb], Adolfo \u00c1lvarez [ctb]",
    "url": "https://github.com/ironholds/batman",
    "bug_reports": "https://github.com/ironholds/batman/issues",
    "repository": "https://cran.r-project.org/package=batman",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "batman Convert Categorical Representations of Logicals to Actual\nLogicals Survey systems and other third-party data sources commonly use non-standard representations of logical values when\n    it comes to qualitative data - \"Yes\", \"No\" and \"N/A\", say. batman is a package designed to seamlessly convert these into logicals.\n    It is highly localised, and contains equivalents to boolean values in languages including German, French, Spanish, Italian,\n    Turkish, Chinese and Polish.  "
  },
  {
    "id": 8924,
    "package_name": "bayesQRsurvey",
    "title": "Bayesian Quantile Regression Models for Complex Survey Data\nAnalysis",
    "description": "Provides Bayesian quantile regression models for complex survey data \n    under informative sampling using survey-weighted estimators. Both single- and \n    multiple-output models are supported. To accelerate computation, all algorithms \n    are implemented in 'C++' using 'Rcpp', 'RcppArmadillo', and 'RcppEigen', and \n    are called from 'R'. See Nascimento and Gon\u00e7alves (2024) <doi:10.1093/jssam/smae015> \n    and Nascimento and Gon\u00e7alves (2025, in press) <https://academic.oup.com/jssam>.",
    "version": "0.1.4",
    "maintainer": "Tom\u00e1s Rodr\u00edguez Taborda <torodriguezt@unal.edu.co>",
    "author": "Tom\u00e1s Rodr\u00edguez Taborda [aut, cre],\n  Johnatan Cardona Jim\u00e9nez [aut],\n  Marcus L. Nascimento [aut],\n  Kelly Cristina Mota Gon\u00e7alves [aut]",
    "url": "https://github.com/torodriguezt/bayesQRsurvey",
    "bug_reports": "https://github.com/torodriguezt/bayesQRsurvey/issues",
    "repository": "https://cran.r-project.org/package=bayesQRsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesQRsurvey Bayesian Quantile Regression Models for Complex Survey Data\nAnalysis Provides Bayesian quantile regression models for complex survey data \n    under informative sampling using survey-weighted estimators. Both single- and \n    multiple-output models are supported. To accelerate computation, all algorithms \n    are implemented in 'C++' using 'Rcpp', 'RcppArmadillo', and 'RcppEigen', and \n    are called from 'R'. See Nascimento and Gon\u00e7alves (2024) <doi:10.1093/jssam/smae015> \n    and Nascimento and Gon\u00e7alves (2025, in press) <https://academic.oup.com/jssam>.  "
  },
  {
    "id": 8947,
    "package_name": "bayesm",
    "title": "Bayesian Inference for Marketing/Micro-Econometrics",
    "description": "Covers many important models used\n  in marketing and micro-econometrics applications. \n  The package includes:\n  Bayes Regression (univariate or multivariate dep var),\n  Bayes Seemingly Unrelated Regression (SUR),\n  Binary and Ordinal Probit,\n  Multinomial Logit (MNL) and Multinomial Probit (MNP),\n  Multivariate Probit,\n  Negative Binomial (Poisson) Regression,\n  Multivariate Mixtures of Normals (including clustering),\n  Dirichlet Process Prior Density Estimation with normal base,\n  Hierarchical Linear Models with normal prior and covariates,\n  Hierarchical Linear Models with a mixture of normals prior and covariates,\n  Hierarchical Multinomial Logits with a mixture of normals prior\n     and covariates,\n  Hierarchical Multinomial Logits with a Dirichlet Process prior and covariates,\n  Hierarchical Negative Binomial Regression Models,\n  Bayesian analysis of choice-based conjoint data,\n  Bayesian treatment of linear instrumental variables models,\n  Analysis of Multivariate Ordinal survey data with scale\n     usage heterogeneity (as in Rossi et al, JASA (01)),\n  Bayesian Analysis of Aggregate Random Coefficient Logit Models as in BLP (see\n  Jiang, Manchanda, Rossi 2009)\n  For further reference, consult our book, Bayesian Statistics and\n  Marketing by Rossi, Allenby and McCulloch (Wiley second edition 2024) and Bayesian Non- and Semi-Parametric\n  Methods and Applications (Princeton U Press 2014).",
    "version": "3.1-7",
    "maintainer": "Peter Rossi <perossichi@gmail.com>",
    "author": "Peter Rossi [aut, cre],\n  Robert McCulloch [ctb],\n  Wayne Taylor [ctb],\n  Dan Yavorsky [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bayesm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bayesm Bayesian Inference for Marketing/Micro-Econometrics Covers many important models used\n  in marketing and micro-econometrics applications. \n  The package includes:\n  Bayes Regression (univariate or multivariate dep var),\n  Bayes Seemingly Unrelated Regression (SUR),\n  Binary and Ordinal Probit,\n  Multinomial Logit (MNL) and Multinomial Probit (MNP),\n  Multivariate Probit,\n  Negative Binomial (Poisson) Regression,\n  Multivariate Mixtures of Normals (including clustering),\n  Dirichlet Process Prior Density Estimation with normal base,\n  Hierarchical Linear Models with normal prior and covariates,\n  Hierarchical Linear Models with a mixture of normals prior and covariates,\n  Hierarchical Multinomial Logits with a mixture of normals prior\n     and covariates,\n  Hierarchical Multinomial Logits with a Dirichlet Process prior and covariates,\n  Hierarchical Negative Binomial Regression Models,\n  Bayesian analysis of choice-based conjoint data,\n  Bayesian treatment of linear instrumental variables models,\n  Analysis of Multivariate Ordinal survey data with scale\n     usage heterogeneity (as in Rossi et al, JASA (01)),\n  Bayesian Analysis of Aggregate Random Coefficient Logit Models as in BLP (see\n  Jiang, Manchanda, Rossi 2009)\n  For further reference, consult our book, Bayesian Statistics and\n  Marketing by Rossi, Allenby and McCulloch (Wiley second edition 2024) and Bayesian Non- and Semi-Parametric\n  Methods and Applications (Princeton U Press 2014).  "
  },
  {
    "id": 8976,
    "package_name": "bbw",
    "title": "Blocked Weighted Bootstrap",
    "description": "The blocked weighted bootstrap (BBW) is an estimation technique \n    for use with data from two-stage cluster sampled surveys in which either \n    prior weighting (e.g. population-proportional sampling or PPS as used in \n    Standardized Monitoring and Assessment of Relief and Transitions or SMART \n    surveys) or posterior weighting (e.g. as used in rapid assessment method or\n    RAM and simple spatial sampling method or S3M surveys) is implemented. See \n    Cameron et al (2008) <doi:10.1162/rest.90.3.414> for application of \n    bootstrap to cluster samples. See Aaron et al (2016) \n    <doi:10.1371/journal.pone.0163176> and Aaron et al (2016) \n    <doi:10.1371/journal.pone.0162462> for application of the blocked weighted \n    bootstrap to estimate indicators from two-stage cluster sampled surveys.",
    "version": "0.3.0",
    "maintainer": "Ernest Guevarra <ernestgmd@gmail.com>",
    "author": "Mark Myatt [aut, cph],\n  Ernest Guevarra [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4887-4415>)",
    "url": "https://github.com/rapidsurveys/bbw, https://rapidsurveys.io/bbw/",
    "bug_reports": "https://github.com/rapidsurveys/bbw/issues",
    "repository": "https://cran.r-project.org/package=bbw",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bbw Blocked Weighted Bootstrap The blocked weighted bootstrap (BBW) is an estimation technique \n    for use with data from two-stage cluster sampled surveys in which either \n    prior weighting (e.g. population-proportional sampling or PPS as used in \n    Standardized Monitoring and Assessment of Relief and Transitions or SMART \n    surveys) or posterior weighting (e.g. as used in rapid assessment method or\n    RAM and simple spatial sampling method or S3M surveys) is implemented. See \n    Cameron et al (2008) <doi:10.1162/rest.90.3.414> for application of \n    bootstrap to cluster samples. See Aaron et al (2016) \n    <doi:10.1371/journal.pone.0163176> and Aaron et al (2016) \n    <doi:10.1371/journal.pone.0162462> for application of the blocked weighted \n    bootstrap to estimate indicators from two-stage cluster sampled surveys.  "
  },
  {
    "id": 8985,
    "package_name": "bcmaps",
    "title": "Map Layers and Spatial Utilities for British Columbia",
    "description": "Various layers of B.C., including administrative boundaries,\n    natural resource management boundaries, census boundaries etc. All\n    layers are available in BC Albers\n    (<https://spatialreference.org/ref/epsg/3005/>) equal-area projection,\n    which is the B.C. government standard. The layers are sourced from the\n    British Columbia and Canadian government under open licenses,\n    including B.C. Data Catalogue (<https://data.gov.bc.ca>), the\n    Government of Canada Open Data Portal\n    (<https://open.canada.ca/en/using-open-data>), and Statistics Canada\n    (<https://www.statcan.gc.ca/en/reference/licence>).",
    "version": "2.2.1",
    "maintainer": "Andy Teucher <andy.teucher@gmail.com>",
    "author": "Andy Teucher [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7840-692X>),\n  Sam Albers [aut, ctb] (ORCID: <https://orcid.org/0000-0002-9270-7884>),\n  Stephanie Hazlitt [aut, ctb] (ORCID:\n    <https://orcid.org/0000-0002-3161-2304>),\n  Province of British Columbia [cph]",
    "url": "https://github.com/bcgov/bcmaps, https://bcgov.github.io/bcmaps/",
    "bug_reports": "https://github.com/bcgov/bcmaps/issues",
    "repository": "https://cran.r-project.org/package=bcmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bcmaps Map Layers and Spatial Utilities for British Columbia Various layers of B.C., including administrative boundaries,\n    natural resource management boundaries, census boundaries etc. All\n    layers are available in BC Albers\n    (<https://spatialreference.org/ref/epsg/3005/>) equal-area projection,\n    which is the B.C. government standard. The layers are sourced from the\n    British Columbia and Canadian government under open licenses,\n    including B.C. Data Catalogue (<https://data.gov.bc.ca>), the\n    Government of Canada Open Data Portal\n    (<https://open.canada.ca/en/using-open-data>), and Statistics Canada\n    (<https://www.statcan.gc.ca/en/reference/licence>).  "
  },
  {
    "id": 9176,
    "package_name": "bio3d",
    "title": "Biological Structure Analysis",
    "description": "Utilities to process, organize and explore protein structure,\n    sequence and dynamics data. Features include the ability to read and write\n    structure, sequence and dynamic trajectory data, perform sequence and structure\n    database searches, data summaries, atom selection, alignment, superposition,\n    rigid core identification, clustering, torsion analysis, distance matrix\n    analysis, structure and sequence conservation analysis, normal mode analysis,\n    principal component analysis of heterogeneous structure data, and correlation\n    network analysis from normal mode and molecular dynamics data. In addition,\n    various utility functions are provided to enable the statistical and graphical\n    power of the R environment to work with biological sequence and structural data.\n    Please refer to the URLs below for more information.",
    "version": "2.4-5",
    "maintainer": "Barry Grant <bjgrant@ucsd.edu>",
    "author": "Barry Grant [aut, cre],\n  Xin-Qiu Yao [aut],\n  Lars Skjaerven [aut],\n  Julien Ide [aut]",
    "url": "http://thegrantlab.org/bio3d/,\nhttps://bitbucket.org/Grantlab/bio3d/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bio3d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bio3d Biological Structure Analysis Utilities to process, organize and explore protein structure,\n    sequence and dynamics data. Features include the ability to read and write\n    structure, sequence and dynamic trajectory data, perform sequence and structure\n    database searches, data summaries, atom selection, alignment, superposition,\n    rigid core identification, clustering, torsion analysis, distance matrix\n    analysis, structure and sequence conservation analysis, normal mode analysis,\n    principal component analysis of heterogeneous structure data, and correlation\n    network analysis from normal mode and molecular dynamics data. In addition,\n    various utility functions are provided to enable the statistical and graphical\n    power of the R environment to work with biological sequence and structural data.\n    Please refer to the URLs below for more information.  "
  },
  {
    "id": 9242,
    "package_name": "blaise",
    "title": "Read and Write FWF Files in the 'Blaise' Format",
    "description": "Can be used to read and write a fwf with an accompanying 'Blaise' datamodel.\n    Blaise is the software suite built by Statistics Netherlands (CBS). It is essentially a \n    way to write and collect surveys and perform statistical analysis on the data. It stores its data in \n    fixed width format with an accompanying metadata file, this is the Blaise format. The package automatically \n    interprets this metadata and reads the file into an R dataframe.\n    When supplying a datamodel for writing, the dataframe will be automatically converted \n    to that format and checked for compatibility.\n    Supports dataframes, tibbles and LaF objects.\n    For more information about 'Blaise', see <https://blaise.com/products/general-information>. ",
    "version": "1.3.11",
    "maintainer": "Sjoerd Ophof <sjoerd.ophof@gmail.com>",
    "author": "Sjoerd Ophof [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=blaise",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "blaise Read and Write FWF Files in the 'Blaise' Format Can be used to read and write a fwf with an accompanying 'Blaise' datamodel.\n    Blaise is the software suite built by Statistics Netherlands (CBS). It is essentially a \n    way to write and collect surveys and perform statistical analysis on the data. It stores its data in \n    fixed width format with an accompanying metadata file, this is the Blaise format. The package automatically \n    interprets this metadata and reads the file into an R dataframe.\n    When supplying a datamodel for writing, the dataframe will be automatically converted \n    to that format and checked for compatibility.\n    Supports dataframes, tibbles and LaF objects.\n    For more information about 'Blaise', see <https://blaise.com/products/general-information>.   "
  },
  {
    "id": 9277,
    "package_name": "blsR",
    "title": "Make Requests from the Bureau of Labor Statistics API",
    "description": "Implements v2 of the B.L.S. API for requests of survey information\n  and time series data through 3-tiered API that allows users to interact with\n  the raw API directly, create queries through a functional interface, and\n  re-shape the data structures returned to fit common uses. The API definition \n  is located at: <https://www.bls.gov/developers/api_signature_v2.htm>.",
    "version": "0.5.0",
    "maintainer": "Guillermo Roditi Dominguez <guillermo@newriverinvestments.com>",
    "author": "Guillermo Roditi Dominguez [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7127-8742>)",
    "url": "https://github.com/groditi/blsR",
    "bug_reports": "https://github.com/groditi/blsR/issues",
    "repository": "https://cran.r-project.org/package=blsR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "blsR Make Requests from the Bureau of Labor Statistics API Implements v2 of the B.L.S. API for requests of survey information\n  and time series data through 3-tiered API that allows users to interact with\n  the raw API directly, create queries through a functional interface, and\n  re-shape the data structures returned to fit common uses. The API definition \n  is located at: <https://www.bls.gov/developers/api_signature_v2.htm>.  "
  },
  {
    "id": 9349,
    "package_name": "bootstrapFP",
    "title": "Bootstrap Algorithms for Finite Population Inference",
    "description": "Finite Population bootstrap algorithms to estimate the variance\n    of the Horvitz-Thompson estimator for single-stage sampling. \n    For a survey of bootstrap methods for finite populations, see Mashreghi et Al. (2016) <doi:10.1214/16-SS113>.",
    "version": "0.4.6",
    "maintainer": "Roberto Sichera <rob.sichera@gmail.com>",
    "author": "Roberto Sichera [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/rhobis/bootstrapFP/issues",
    "repository": "https://cran.r-project.org/package=bootstrapFP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bootstrapFP Bootstrap Algorithms for Finite Population Inference Finite Population bootstrap algorithms to estimate the variance\n    of the Horvitz-Thompson estimator for single-stage sampling. \n    For a survey of bootstrap methods for finite populations, see Mashreghi et Al. (2016) <doi:10.1214/16-SS113>.  "
  },
  {
    "id": 9350,
    "package_name": "bootsurv",
    "title": "Bootstrap Methods for Complete Survey Data",
    "description": "Bootstrap resampling methods have been widely studied in the context of survey data. This package implements various bootstrap resampling techniques tailored for survey data, with a focus on stratified simple random sampling and stratified two-stage cluster sampling. It provides tools for precise and consistent bootstrap variance estimation for population totals, means, and quartiles. Additionally, it enables easy generation of bootstrap samples for in-depth analysis.",
    "version": "0.0.1",
    "maintainer": "Zeinab Mashreghi <z.mashreghi@uwinnipeg.ca>",
    "author": "Zeinab Mashreghi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0563-0792>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=bootsurv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bootsurv Bootstrap Methods for Complete Survey Data Bootstrap resampling methods have been widely studied in the context of survey data. This package implements various bootstrap resampling techniques tailored for survey data, with a focus on stratified simple random sampling and stratified two-stage cluster sampling. It provides tools for precise and consistent bootstrap variance estimation for population totals, means, and quartiles. Additionally, it enables easy generation of bootstrap samples for in-depth analysis.  "
  },
  {
    "id": 9439,
    "package_name": "bruneimap",
    "title": "Maps and Spatial Data of Brunei",
    "description": "Provides spatial data for mapping Brunei, including boundaries for districts, mukims, and kampongs, as well as locations of key infrastructure such as masjids, hospitals, clinics, and schools. The package supports researchers, analysts, and developers working with Brunei\u2019s geographic and demographic data, offering a quick and accessible foundation for creating maps and conducting spatial studies.",
    "version": "0.3.1",
    "maintainer": "Haziq Jamil <haziq.jamil@gmail.com>",
    "author": "Haziq Jamil [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3298-1010>),\n  Hafeezul Raziq [ctb],\n  Alvin Bong [ctb],\n  Aniq Najwa Ariffin [ctb],\n  Danish Ikhwan Mohamad Zainin [ctb],\n  Muhammad Rayme Hijazi Jassrie [ctb],\n  Angela Chan [ctb],\n  Irdina Batrisyia Norharddyman [ctb],\n  Nursyafiqah Mohammad Yusuf [ctb],\n  Ahmad Syafi Mohammad Hilmy [ctb],\n  Mohammad Syahir Deedat Al Jufri [ctb]",
    "url": "https://github.com/Bruneiverse/bruneimap,\nhttps://bruneiverse.github.io/bruneimap/",
    "bug_reports": "https://github.com/Bruneiverse/bruneimap/issues",
    "repository": "https://cran.r-project.org/package=bruneimap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bruneimap Maps and Spatial Data of Brunei Provides spatial data for mapping Brunei, including boundaries for districts, mukims, and kampongs, as well as locations of key infrastructure such as masjids, hospitals, clinics, and schools. The package supports researchers, analysts, and developers working with Brunei\u2019s geographic and demographic data, offering a quick and accessible foundation for creating maps and conducting spatial studies.  "
  },
  {
    "id": 9488,
    "package_name": "bumblebee",
    "title": "Quantify Disease Transmission Within and Between Population\nGroups",
    "description": "A simple tool to quantify the amount of transmission\n   of an infectious disease of interest occurring within and between \n   population groups. 'bumblebee' uses counts of observed directed \n   transmission pairs, identified phylogenetically from deep-sequence data or \n   from epidemiological contacts, to quantify transmission flows within and \n   between population groups accounting for sampling heterogeneity. Population \n   groups might include: geographical areas (e.g. communities, regions), \n   demographic groups (e.g. age, gender) or arms of a randomized clinical \n   trial. See the 'bumblebee' website for statistical theory, documentation \n   and examples <https://magosil86.github.io/bumblebee/>.",
    "version": "0.1.0",
    "maintainer": "Lerato E Magosi <magosil86@gmail.com>",
    "author": "Lerato E Magosi [aut] (ORCID: <https://orcid.org/0000-0002-3388-9892>),\n  Marc Lipsitch [aut],\n  Lerato E Magosi [cre]",
    "url": "https://magosil86.github.io/bumblebee/",
    "bug_reports": "https://github.com/magosil86/bumblebee/issues",
    "repository": "https://cran.r-project.org/package=bumblebee",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "bumblebee Quantify Disease Transmission Within and Between Population\nGroups A simple tool to quantify the amount of transmission\n   of an infectious disease of interest occurring within and between \n   population groups. 'bumblebee' uses counts of observed directed \n   transmission pairs, identified phylogenetically from deep-sequence data or \n   from epidemiological contacts, to quantify transmission flows within and \n   between population groups accounting for sampling heterogeneity. Population \n   groups might include: geographical areas (e.g. communities, regions), \n   demographic groups (e.g. age, gender) or arms of a randomized clinical \n   trial. See the 'bumblebee' website for statistical theory, documentation \n   and examples <https://magosil86.github.io/bumblebee/>.  "
  },
  {
    "id": 9557,
    "package_name": "calidad",
    "title": "Assesses the Quality of Estimates Made by Complex Sample Designs",
    "description": "Assesses the quality of estimates made by complex sample designs,\n  following the methodology developed by the National Institute of Statistics Chile (Household Survey Standard 2020, <https://www.ine.cl/docs/default-source/institucionalidad/buenas-pr%C3%A1cticas/clasificaciones-y-estandares/est%C3%A1ndar-evaluaci%C3%B3n-de-calidad-de-estimaciones-publicaci%C3%B3n-27022020.pdf>), (Economics Survey Standard 2024, <https://www.ine.gob.cl/docs/default-source/buenas-practicas/directrices-metodologicas/estandares/documentos/est%C3%A1ndar-evaluaci%C3%B3n-de-calidad-de-estimaciones-econ%C3%B3micas.pdf?sfvrsn=201fbeb9_2>)\n  and by Economic Commission  for Latin America and \n  Caribbean (2020, <https://repositorio.cepal.org/bitstream/handle/11362/45681/1/S2000293_es.pdf>), (2024, <https://repositorio.cepal.org/server/api/core/bitstreams/f04569e6-4f38-42e7-a32b-e0b298e0ab9c/content>).",
    "version": "0.8.2",
    "maintainer": "Klaus Lehmann <klehmann@fen.uchile.cl>",
    "author": "Klaus Lehmann [aut, cre],\n  Ricardo Pizarro [aut],\n  Ignacio Agloni [ctb],\n  Andrea L\u00f3pez [ctb],\n  Javiera Preuss [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=calidad",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "calidad Assesses the Quality of Estimates Made by Complex Sample Designs Assesses the quality of estimates made by complex sample designs,\n  following the methodology developed by the National Institute of Statistics Chile (Household Survey Standard 2020, <https://www.ine.cl/docs/default-source/institucionalidad/buenas-pr%C3%A1cticas/clasificaciones-y-estandares/est%C3%A1ndar-evaluaci%C3%B3n-de-calidad-de-estimaciones-publicaci%C3%B3n-27022020.pdf>), (Economics Survey Standard 2024, <https://www.ine.gob.cl/docs/default-source/buenas-practicas/directrices-metodologicas/estandares/documentos/est%C3%A1ndar-evaluaci%C3%B3n-de-calidad-de-estimaciones-econ%C3%B3micas.pdf?sfvrsn=201fbeb9_2>)\n  and by Economic Commission  for Latin America and \n  Caribbean (2020, <https://repositorio.cepal.org/bitstream/handle/11362/45681/1/S2000293_es.pdf>), (2024, <https://repositorio.cepal.org/server/api/core/bitstreams/f04569e6-4f38-42e7-a32b-e0b298e0ab9c/content>).  "
  },
  {
    "id": 9571,
    "package_name": "camtrapR",
    "title": "Camera Trap Data Management and Analysis Framework",
    "description": "Management and analysis of camera trap wildlife data through an integrated workflow. Provides functions for image/video organization and metadata extraction, species/individual identification. Creates detection histories for occupancy and spatial capture-recapture analyses, with support for multi-season studies. Includes tools for fitting community occupancy models in JAGS and NIMBLE, and an interactive dashboard for survey data visualization and analysis. Features visualization of species distributions and activity patterns, plus export capabilities for GIS and reports. Emphasizes automation and reproducibility while maintaining flexibility for different study designs.",
    "version": "3.0.0",
    "maintainer": "Juergen Niedballa <camtrapr@gmail.com>",
    "author": "Juergen Niedballa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9187-2116>),\n  Alexandre Courtiol [aut] (ORCID:\n    <https://orcid.org/0000-0003-0637-2959>),\n  Rahel Sollmann [aut] (ORCID: <https://orcid.org/0000-0002-1607-2039>),\n  John Mathai [ctb],\n  Seth Timothy Wong [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8083-9268>),\n  An The Truong Nguyen [ctb] (ORCID:\n    <https://orcid.org/0009-0000-2861-2672>),\n  Azlan bin Mohamed [ctb] (ORCID:\n    <https://orcid.org/0000-0003-3788-4383>),\n  Andrew Tilker [ctb] (ORCID: <https://orcid.org/0000-0003-3630-8691>),\n  Roshan Guharajan [ctb] (ORCID: <https://orcid.org/0000-0001-8124-5461>),\n  Ioannis Alexiou [ctb] (ORCID: <https://orcid.org/0000-0001-5095-4767>),\n  Andreas Wilting [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0001-5073-9186>)",
    "url": "https://github.com/jniedballa/camtrapR,\nhttps://jniedballa.github.io/camtrapR/,\nhttps://groups.google.com/forum/#!forum/camtrapr",
    "bug_reports": "https://groups.google.com/forum/#!forum/camtrapr",
    "repository": "https://cran.r-project.org/package=camtrapR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "camtrapR Camera Trap Data Management and Analysis Framework Management and analysis of camera trap wildlife data through an integrated workflow. Provides functions for image/video organization and metadata extraction, species/individual identification. Creates detection histories for occupancy and spatial capture-recapture analyses, with support for multi-season studies. Includes tools for fitting community occupancy models in JAGS and NIMBLE, and an interactive dashboard for survey data visualization and analysis. Features visualization of species distributions and activity patterns, plus export capabilities for GIS and reports. Emphasizes automation and reproducibility while maintaining flexibility for different study designs.  "
  },
  {
    "id": 9573,
    "package_name": "canadamaps",
    "title": "Maps of the Political and Administrative Divisions of Canada",
    "description": "Terrestrial maps with simplified topologies for Census Divisions,\n    Agricultural Regions, Economic Regions, Federal Electoral Divisions and\n    Provinces.",
    "version": "0.1",
    "maintainer": "Mauricio Vargas Sepulveda <mv.sepulveda@mail.utoronto.ca>",
    "author": "Mauricio Vargas Sepulveda [aut, cre],\n  Statistics Canada [dtc]",
    "url": "https://github.com/pachadotdev/canadamaps/",
    "bug_reports": "https://github.com/pachadotdev/canadamaps/issues",
    "repository": "https://cran.r-project.org/package=canadamaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "canadamaps Maps of the Political and Administrative Divisions of Canada Terrestrial maps with simplified topologies for Census Divisions,\n    Agricultural Regions, Economic Regions, Federal Electoral Divisions and\n    Provinces.  "
  },
  {
    "id": 9574,
    "package_name": "canadianmaps",
    "title": "Effortlessly Create Stunning Canadian Maps",
    "description": "Simple and seamless access to a variety of 'StatCan' shapefiles for mapping Canadian provinces, regions, forward sortation areas, census divisions, and subdivisions using the popular 'ggplot2' package.",
    "version": "2.0.0",
    "maintainer": "Joelle Cayen <joelle.cayen@phac-aspc.gc.ca>",
    "author": "Joelle Cayen [aut, cre]",
    "url": "https://github.com/joellecayen/canadianmaps",
    "bug_reports": "https://github.com/joellecayen/canadianmaps/issues",
    "repository": "https://cran.r-project.org/package=canadianmaps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "canadianmaps Effortlessly Create Stunning Canadian Maps Simple and seamless access to a variety of 'StatCan' shapefiles for mapping Canadian provinces, regions, forward sortation areas, census divisions, and subdivisions using the popular 'ggplot2' package.  "
  },
  {
    "id": 9575,
    "package_name": "cancensus",
    "title": "Access, Retrieve, and Work with Canadian Census Data and\nGeography",
    "description": "Integrated, convenient, and uniform access to Canadian\n    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready \n    tidy data frames and spatial data in multiple formats, as well as convenience functions\n    for working with Census variables, variable hierarchies, and region selection. API\n    keys are freely available with free registration at <https://censusmapper.ca/api>.\n    Census data and boundary geometries are reproduced and distributed on an \"as\n    is\" basis with the permission of Statistics Canada (Statistics Canada 1996; 2001; 2006;\n    2011; 2016; 2021).",
    "version": "0.5.10",
    "maintainer": "Dmitry Shkolnik <shkolnikd@gmail.com>",
    "author": "Jens von Bergmann [aut] (API creator and maintainer),\n  Dmitry Shkolnik [aut, cre] (Package maintainer, responsible for\n    correspondence),\n  Aaron Jacobs [aut]",
    "url": "https://github.com/mountainMath/cancensus,\nhttps://mountainmath.github.io/cancensus/,\nhttps://censusmapper.ca/api",
    "bug_reports": "https://github.com/mountainMath/cancensus/issues",
    "repository": "https://cran.r-project.org/package=cancensus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cancensus Access, Retrieve, and Work with Canadian Census Data and\nGeography Integrated, convenient, and uniform access to Canadian\n    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready \n    tidy data frames and spatial data in multiple formats, as well as convenience functions\n    for working with Census variables, variable hierarchies, and region selection. API\n    keys are freely available with free registration at <https://censusmapper.ca/api>.\n    Census data and boundary geometries are reproduced and distributed on an \"as\n    is\" basis with the permission of Statistics Canada (Statistics Canada 1996; 2001; 2006;\n    2011; 2016; 2021).  "
  },
  {
    "id": 9593,
    "package_name": "captr",
    "title": "Client for the Captricity API",
    "description": "Get text from images of text using Captricity Optical Character\n    Recognition (OCR) API. Captricity allows you to get text from handwritten\n    forms --- think surveys --- and other structured paper documents. And it can\n    output data in form a delimited file keeping field information intact. For more\n    information, read <https://shreddr.captricity.com/developer/overview/>.",
    "version": "0.3.0",
    "maintainer": "Gaurav Sood <gsood07@gmail.com>",
    "author": "Gaurav Sood [aut, cre]",
    "url": "http://github.com/soodoku/captR",
    "bug_reports": "http://github.com/soodoku/captR/issues",
    "repository": "https://cran.r-project.org/package=captr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "captr Client for the Captricity API Get text from images of text using Captricity Optical Character\n    Recognition (OCR) API. Captricity allows you to get text from handwritten\n    forms --- think surveys --- and other structured paper documents. And it can\n    output data in form a delimited file keeping field information intact. For more\n    information, read <https://shreddr.captricity.com/developer/overview/>.  "
  },
  {
    "id": 9610,
    "package_name": "careless",
    "title": "Procedures for Computing Indices of Careless Responding",
    "description": "When taking online surveys, participants sometimes respond to items\n    without regard to their content. These types of responses, referred to as \n    careless or insufficient effort responding, constitute significant problems \n    for data quality, leading to distortions in data analysis and hypothesis \n    testing, such as spurious correlations. The 'R' package 'careless' provides \n    solutions designed to detect such careless / insufficient effort responses \n    by allowing easy calculation of indices proposed in the literature. It \n    currently supports the calculation of longstring, even-odd consistency, \n    psychometric synonyms/antonyms, Mahalanobis distance, and intra-individual \n    response variability (also termed inter-item standard deviation). \n    For a review of these methods, see Curran (2016) <doi:10.1016/j.jesp.2015.07.006>.",
    "version": "1.2.2",
    "maintainer": "Richard Yentes <ryentes@gmail.com>",
    "author": "Richard Yentes [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-6767-8065>),\n  Francisco Wilhelm [aut]",
    "url": "https://github.com/ryentes/careless/",
    "bug_reports": "https://github.com/ryentes/careless/issues",
    "repository": "https://cran.r-project.org/package=careless",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "careless Procedures for Computing Indices of Careless Responding When taking online surveys, participants sometimes respond to items\n    without regard to their content. These types of responses, referred to as \n    careless or insufficient effort responding, constitute significant problems \n    for data quality, leading to distortions in data analysis and hypothesis \n    testing, such as spurious correlations. The 'R' package 'careless' provides \n    solutions designed to detect such careless / insufficient effort responses \n    by allowing easy calculation of indices proposed in the literature. It \n    currently supports the calculation of longstring, even-odd consistency, \n    psychometric synonyms/antonyms, Mahalanobis distance, and intra-individual \n    response variability (also termed inter-item standard deviation). \n    For a review of these methods, see Curran (2016) <doi:10.1016/j.jesp.2015.07.006>.  "
  },
  {
    "id": 9643,
    "package_name": "catSurv",
    "title": "Computerized Adaptive Testing for Survey Research",
    "description": "Provides methods of computerized adaptive testing for survey researchers.  See Montgomery and Rossiter (2020) <doi:10.1093/jssam/smz027>. Includes functionality for data fit with the classic item response methods including the latent trait model, the Birnbaum three parameter model, the graded response, and the generalized partial credit model.  Additionally, includes several ability parameter estimation and item selection routines.  During item selection, all calculations are done in compiled C++ code.",
    "version": "1.6.0",
    "maintainer": "Erin Rossiter <erossite@nd.edu>",
    "author": "Jacob Montgomery [aut],\n  Erin Rossiter [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/erossiter/catSurv/issues",
    "repository": "https://cran.r-project.org/package=catSurv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "catSurv Computerized Adaptive Testing for Survey Research Provides methods of computerized adaptive testing for survey researchers.  See Montgomery and Rossiter (2020) <doi:10.1093/jssam/smz027>. Includes functionality for data fit with the classic item response methods including the latent trait model, the Birnbaum three parameter model, the graded response, and the generalized partial credit model.  Additionally, includes several ability parameter estimation and item selection routines.  During item selection, all calculations are done in compiled C++ code.  "
  },
  {
    "id": 9691,
    "package_name": "cbcTools",
    "title": "Design and Analyze Choice-Based Conjoint Experiments",
    "description": "Design and evaluate choice-based conjoint survey experiments. Generate a variety of survey designs, including random designs, frequency-based designs, and D-optimal designs, as well as \"labeled\" designs (also known as \"alternative-specific designs\"), designs with \"no choice\" options, and designs with dominant alternatives removed. Conveniently inspect and compare designs using a variety of metrics, including design balance, overlap, and D-error, and simulate choice data for a survey design either randomly or according to a utility model defined by user-provided prior parameters. Conduct a power analysis for a given survey design by estimating the same model on different subsets of the data to simulate different sample sizes. Bayesian D-efficient designs using the 'cea' and 'modfed' methods are obtained using the 'idefix' package by Traets et al (2020) <doi:10.18637/jss.v096.i03>. Choice simulation and model estimation in power analyses are handled using the 'logitr' package by Helveston (2023) <doi:10.18637/jss.v105.i10>.",
    "version": "0.7.1",
    "maintainer": "John Helveston <john.helveston@gmail.com>",
    "author": "John Helveston [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-2657-9191>)",
    "url": "https://github.com/jhelvy/cbcTools,\nhttps://jhelvy.github.io/cbcTools/",
    "bug_reports": "https://github.com/jhelvy/cbcTools/issues",
    "repository": "https://cran.r-project.org/package=cbcTools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cbcTools Design and Analyze Choice-Based Conjoint Experiments Design and evaluate choice-based conjoint survey experiments. Generate a variety of survey designs, including random designs, frequency-based designs, and D-optimal designs, as well as \"labeled\" designs (also known as \"alternative-specific designs\"), designs with \"no choice\" options, and designs with dominant alternatives removed. Conveniently inspect and compare designs using a variety of metrics, including design balance, overlap, and D-error, and simulate choice data for a survey design either randomly or according to a utility model defined by user-provided prior parameters. Conduct a power analysis for a given survey design by estimating the same model on different subsets of the data to simulate different sample sizes. Bayesian D-efficient designs using the 'cea' and 'modfed' methods are obtained using the 'idefix' package by Traets et al (2020) <doi:10.18637/jss.v096.i03>. Choice simulation and model estimation in power analyses are handled using the 'logitr' package by Helveston (2023) <doi:10.18637/jss.v105.i10>.  "
  },
  {
    "id": 9702,
    "package_name": "cccd",
    "title": "Class Cover Catch Digraphs",
    "description": "Class Cover Catch Digraphs, neighborhood graphs, and\n        relatives.",
    "version": "1.6",
    "maintainer": "David J. Marchette <dmarchette@gmail.com>",
    "author": "David J. Marchette <dmarchette@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cccd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cccd Class Cover Catch Digraphs Class Cover Catch Digraphs, neighborhood graphs, and\n        relatives.  "
  },
  {
    "id": 9709,
    "package_name": "cchsflow",
    "title": "Transforming and Harmonizing CCHS Variables",
    "description": "Supporting the use of the Canadian Community Health Survey \n             (CCHS) by transforming variables from each cycle into harmonized, \n             consistent versions that span survey cycles (currently, 2001 to \n             2018). CCHS data used in this library is accessed and adapted in \n             accordance to the Statistics Canada Open Licence Agreement. This \n             package uses rec_with_table(), which was developed from 'sjmisc' \n             rec(). L\u00fcdecke D (2018). \"sjmisc: Data and Variable Transformation \n             Functions\". Journal of Open Source Software, 3(26), 754. \n             <doi:10.21105/joss.00754>.",
    "version": "2.1.0",
    "maintainer": "Kitty Chen <kitchen@ohri.ca>",
    "author": "Doug Manuel [aut, cph] (ORCID: <https://orcid.org/0000-0003-0912-0845>),\n  Warsame Yusuf [aut],\n  Rostyslav Vyuha [aut],\n  Kitty Chen [aut, cre],\n  Carol Bennett [aut],\n  Yulric Sequeira [ctb],\n  The Ottawa Hospital [cph]",
    "url": "https://github.com/Big-Life-Lab/cchsflow",
    "bug_reports": "https://github.com/Big-Life-Lab/cchsflow/issues",
    "repository": "https://cran.r-project.org/package=cchsflow",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cchsflow Transforming and Harmonizing CCHS Variables Supporting the use of the Canadian Community Health Survey \n             (CCHS) by transforming variables from each cycle into harmonized, \n             consistent versions that span survey cycles (currently, 2001 to \n             2018). CCHS data used in this library is accessed and adapted in \n             accordance to the Statistics Canada Open Licence Agreement. This \n             package uses rec_with_table(), which was developed from 'sjmisc' \n             rec(). L\u00fcdecke D (2018). \"sjmisc: Data and Variable Transformation \n             Functions\". Journal of Open Source Software, 3(26), 754. \n             <doi:10.21105/joss.00754>.  "
  },
  {
    "id": 9753,
    "package_name": "cencrne",
    "title": "Consistent Estimation of the Number of Communities via\nRegularized Network Embedding",
    "description": "The network analysis plays an important role in numerous application domains including biomedicine. \n             Estimation of the number of communities is a fundamental and critical issue in network analysis. Most existing studies assume that the number of communities is known a priori, or lack of rigorous theoretical guarantee on the estimation consistency. This method proposes a regularized network embedding model to simultaneously estimate the community structure and the number of communities in a unified formulation. \n\t           The proposed model equips network embedding with a novel composite regularization term, which pushes the embedding vector towards its center and collapses similar community centers with each other. A rigorous theoretical analysis is conducted, establishing asymptotic consistency in terms of community detection and estimation of the number of communities. \n\t           Reference: \n             Ren, M., Zhang S. and Wang J. (2022). \"Consistent Estimation of the Number of Communities via Regularized Network Embedding\". Biometrics, <doi:10.1111/biom.13815>.",
    "version": "1.0.0",
    "maintainer": "Mingyang Ren <renmingyang17@mails.ucas.ac.cn>",
    "author": "Mingyang Ren [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8061-9940>),\n  Sanguo Zhang [aut],\n  Junhui Wang [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cencrne",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cencrne Consistent Estimation of the Number of Communities via\nRegularized Network Embedding The network analysis plays an important role in numerous application domains including biomedicine. \n             Estimation of the number of communities is a fundamental and critical issue in network analysis. Most existing studies assume that the number of communities is known a priori, or lack of rigorous theoretical guarantee on the estimation consistency. This method proposes a regularized network embedding model to simultaneously estimate the community structure and the number of communities in a unified formulation. \n\t           The proposed model equips network embedding with a novel composite regularization term, which pushes the embedding vector towards its center and collapses similar community centers with each other. A rigorous theoretical analysis is conducted, establishing asymptotic consistency in terms of community detection and estimation of the number of communities. \n\t           Reference: \n             Ren, M., Zhang S. and Wang J. (2022). \"Consistent Estimation of the Number of Communities via Regularized Network Embedding\". Biometrics, <doi:10.1111/biom.13815>.  "
  },
  {
    "id": 9755,
    "package_name": "censable",
    "title": "Making Census Data More Usable",
    "description": "Creates a common framework for organizing, naming, and gathering \n    population, age, race, and ethnicity data from the Census Bureau. Accesses \n    the API <https://www.census.gov/data/developers/data-sets.html>. Provides \n    tools for adding information to existing data to line up with Census data.",
    "version": "0.0.8",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>)",
    "url": "https://christophertkenny.com/censable/,\nhttps://github.com/christopherkenny/censable",
    "bug_reports": "https://github.com/christopherkenny/censable/issues",
    "repository": "https://cran.r-project.org/package=censable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censable Making Census Data More Usable Creates a common framework for organizing, naming, and gathering \n    population, age, race, and ethnicity data from the Census Bureau. Accesses \n    the API <https://www.census.gov/data/developers/data-sets.html>. Provides \n    tools for adding information to existing data to line up with Census data.  "
  },
  {
    "id": 9756,
    "package_name": "censobr",
    "title": "Download Data from Brazil's Population Census",
    "description": "Easy access to data from Brazil's population censuses. The package\n             provides a simple and efficient way to download and read the data \n             sets and the documentation of all the population censuses taken in \n             and after 1960 in the country. The package is built on top of the \n             'Arrow' platform <https://arrow.apache.org/docs/r/>,  which allows \n             users to work with larger-than-memory census data using 'dplyr' \n             familiar functions. <https://arrow.apache.org/docs/r/articles/arrow.html#analyzing-arrow-data-with-dplyr>.",
    "version": "0.5.0",
    "maintainer": "Rafael H. M. Pereira <rafa.pereira.br@gmail.com>",
    "author": "Rafael H. M. Pereira [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2125-7465>),\n  Rog\u00e9rio J. Barbosa [aut] (ORCID:\n    <https://orcid.org/0000-0002-6796-4547>),\n  Diego Rabatone Oliveira [ctb],\n  Neal Richardson [ctb],\n  Ipea - Institute for Applied Economic Research [cph, fnd]",
    "url": "https://github.com/ipeaGIT/censobr,\nhttps://ipeagit.github.io/censobr/",
    "bug_reports": "https://github.com/ipeaGIT/censobr/issues",
    "repository": "https://cran.r-project.org/package=censobr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censobr Download Data from Brazil's Population Census Easy access to data from Brazil's population censuses. The package\n             provides a simple and efficient way to download and read the data \n             sets and the documentation of all the population censuses taken in \n             and after 1960 in the country. The package is built on top of the \n             'Arrow' platform <https://arrow.apache.org/docs/r/>,  which allows \n             users to work with larger-than-memory census data using 'dplyr' \n             familiar functions. <https://arrow.apache.org/docs/r/articles/arrow.html#analyzing-arrow-data-with-dplyr>.  "
  },
  {
    "id": 9758,
    "package_name": "censoredAIDS",
    "title": "Estimation of Censored AI/QUAI Demand System via Maximum\nLikelihood Estimation (MLE)",
    "description": "Tools for estimating censored Almost Ideal (AI) and Quadratic Almost Ideal (QUAI) demand systems using Maximum Likelihood Estimation (MLE). It includes functions for calculating demand share equations and the truncated log-likelihood function for a system of equations, incorporating demographic variables. The package is designed to handle censored data, where some observations may be zero due to non-purchase of certain goods. Package also contains a procedure to approximate demand elasticities numerically and estimate standard errors via Delta Method. It is particularly useful for applied researchers analyzing household consumption data.",
    "version": "1.0.0",
    "maintainer": "No\u00e9 J Nava <noejnava2@gmail.com>",
    "author": "No\u00e9 J Nava [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=censoredAIDS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censoredAIDS Estimation of Censored AI/QUAI Demand System via Maximum\nLikelihood Estimation (MLE) Tools for estimating censored Almost Ideal (AI) and Quadratic Almost Ideal (QUAI) demand systems using Maximum Likelihood Estimation (MLE). It includes functions for calculating demand share equations and the truncated log-likelihood function for a system of equations, incorporating demographic variables. The package is designed to handle censored data, where some observations may be zero due to non-purchase of certain goods. Package also contains a procedure to approximate demand elasticities numerically and estimate standard errors via Delta Method. It is particularly useful for applied researchers analyzing household consumption data.  "
  },
  {
    "id": 9759,
    "package_name": "censusapi",
    "title": "Retrieve Data from the Census APIs",
    "description": "A wrapper for the U.S. Census Bureau APIs that returns data frames of \n\tCensus data and metadata. Available datasets include the \n\tDecennial Census, American Community Survey, Small Area Health Insurance Estimates,\n\tSmall Area Income and Poverty Estimates, Population Estimates and Projections, and more.",
    "version": "0.9.0",
    "maintainer": "Hannah Recht <censusapi.rstats@gmail.com>",
    "author": "Hannah Recht [aut, cre]",
    "url": "https://www.hrecht.com/censusapi/,\nhttps://github.com/hrecht/censusapi",
    "bug_reports": "https://github.com/hrecht/censusapi/issues",
    "repository": "https://cran.r-project.org/package=censusapi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censusapi Retrieve Data from the Census APIs A wrapper for the U.S. Census Bureau APIs that returns data frames of \n\tCensus data and metadata. Available datasets include the \n\tDecennial Census, American Community Survey, Small Area Health Insurance Estimates,\n\tSmall Area Income and Poverty Estimates, Population Estimates and Projections, and more.  "
  },
  {
    "id": 9760,
    "package_name": "censuspyrID",
    "title": "Explorer of Indonesian Population Pyramids from Harmonized and\nNon-Harmonized Census Data",
    "description": "Provides harmonized and non-harmonized population pyramid datasets from the Indonesian population censuses (1971\u20132020), along with tools for visualization and an interactive 'shiny'-based explorer application. Data are processed from IPUMS International (1971\u20132010) and the Population Census 2020 (BPS Indonesia).",
    "version": "1.0.2",
    "maintainer": "Ari Purwanto Sarwo Prasojo <ari.prasojo18@gmail.com>",
    "author": "Ari Purwanto Sarwo Prasojo [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4862-5523>),\n  Puguh Prasetyoputra [aut] (ORCID:\n    <https://orcid.org/0000-0001-5494-7003>),\n  Nur Fitri Mustika Ayu [aut]",
    "url": "https://github.com/aripurwantosp/censuspyrID",
    "bug_reports": "https://github.com/aripurwantosp/censuspyrID/issues",
    "repository": "https://cran.r-project.org/package=censuspyrID",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censuspyrID Explorer of Indonesian Population Pyramids from Harmonized and\nNon-Harmonized Census Data Provides harmonized and non-harmonized population pyramid datasets from the Indonesian population censuses (1971\u20132020), along with tools for visualization and an interactive 'shiny'-based explorer application. Data are processed from IPUMS International (1971\u20132010) and the Population Census 2020 (BPS Indonesia).  "
  },
  {
    "id": 9761,
    "package_name": "censusr",
    "title": "Collect Data from the Census API",
    "description": "Use the US Census API to collect summary data tables\n    for SF1 and ACS datasets at arbitrary geographies.",
    "version": "0.0.4",
    "maintainer": "Greg Macfarlane <greg@transportfoundry.com>",
    "author": "Greg Macfarlane [cre, aut],\n  Josie Kressner [aut]",
    "url": "https://github.com/transportfoundry/censusr",
    "bug_reports": "https://github.com/transportfoundry/censusr/issues",
    "repository": "https://cran.r-project.org/package=censusr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "censusr Collect Data from the Census API Use the US Census API to collect summary data tables\n    for SF1 and ACS datasets at arbitrary geographies.  "
  },
  {
    "id": 9763,
    "package_name": "centiserve",
    "title": "Find Graph Centrality Indices",
    "description": "Calculates centrality indices additional to the 'igraph' package centrality functions.",
    "version": "1.0.0",
    "maintainer": "Mahdi Jalili <m_jalili@farabi.tums.ac.ir>",
    "author": "Mahdi Jalili <m_jalili@farabi.tums.ac.ir>",
    "url": "http://www.centiserver.org/",
    "bug_reports": "http://www.centiserver.org/?q1=contact",
    "repository": "https://cran.r-project.org/package=centiserve",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "centiserve Find Graph Centrality Indices Calculates centrality indices additional to the 'igraph' package centrality functions.  "
  },
  {
    "id": 9770,
    "package_name": "cepumd",
    "title": "Calculate Consumer Expenditure Survey (CE) Annual Estimates",
    "description": "Provides functions and data files to help CE Public-Use\n    Microdata (PUMD) users calculate annual estimated expenditure means,\n    standard errors, and quantiles according to the methods used by the CE with\n    PUMD. For more information on the CE please visit <https://www.bls.gov/cex>.\n    For further reading on CE estimate calculations please see the CE\n    Calculation section of the U.S. Bureau of Labor Statistics (BLS) Handbook of\n    Methods at <https://www.bls.gov/opub/hom/cex/calculation.htm>. For\n    further information about CE PUMD please visit\n    <https://www.bls.gov/cex/pumd.htm>.",
    "version": "2.1.0",
    "maintainer": "Arcenis Rojas <arcenis.rojas@gmail.com>",
    "author": "Arcenis Rojas [aut, cre, cph]",
    "url": "https://arcenis-r.github.io/cepumd/,\nhttps://github.com/arcenis-r/cepumd",
    "bug_reports": "https://github.com/arcenis-r/cepumd/issues",
    "repository": "https://cran.r-project.org/package=cepumd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cepumd Calculate Consumer Expenditure Survey (CE) Annual Estimates Provides functions and data files to help CE Public-Use\n    Microdata (PUMD) users calculate annual estimated expenditure means,\n    standard errors, and quantiles according to the methods used by the CE with\n    PUMD. For more information on the CE please visit <https://www.bls.gov/cex>.\n    For further reading on CE estimate calculations please see the CE\n    Calculation section of the U.S. Bureau of Labor Statistics (BLS) Handbook of\n    Methods at <https://www.bls.gov/opub/hom/cex/calculation.htm>. For\n    further information about CE PUMD please visit\n    <https://www.bls.gov/cex/pumd.htm>.  "
  },
  {
    "id": 9774,
    "package_name": "ces",
    "title": "Access to Canadian Election Study Data",
    "description": "Provides tools to easily access and analyze Canadian Election Study data.\n    The package simplifies the process of downloading, cleaning, and using 'CES' datasets\n    for political science research and analysis. The Canadian Election Study ('CES')\n    has been conducted during federal elections since 1965, surveying Canadians\n    on their political preferences, engagement, and demographics. Data is accessed\n    from multiple sources including the 'Borealis' Data repository \n    <https://borealisdata.ca/> and the official 'Canadian Election Study' website \n    <https://ces-eec.arts.ubc.ca/>. This package is not officially affiliated \n    with the Canadian Election Study, 'Borealis' Data, or the University of British \n    Columbia, and users should cite the original data sources in their work.",
    "version": "1.0.2",
    "maintainer": "Laurence-Olivier M. Foisy <mail@mfoisy.com>",
    "author": "Laurence-Olivier M. Foisy [aut, cre] (ORCID:\n    <https://orcid.org/0009-0004-7505-9477>)",
    "url": "https://github.com/laurenceomfoisy/ces",
    "bug_reports": "https://github.com/laurenceomfoisy/ces/issues",
    "repository": "https://cran.r-project.org/package=ces",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ces Access to Canadian Election Study Data Provides tools to easily access and analyze Canadian Election Study data.\n    The package simplifies the process of downloading, cleaning, and using 'CES' datasets\n    for political science research and analysis. The Canadian Election Study ('CES')\n    has been conducted during federal elections since 1965, surveying Canadians\n    on their political preferences, engagement, and demographics. Data is accessed\n    from multiple sources including the 'Borealis' Data repository \n    <https://borealisdata.ca/> and the official 'Canadian Election Study' website \n    <https://ces-eec.arts.ubc.ca/>. This package is not officially affiliated \n    with the Canadian Election Study, 'Borealis' Data, or the University of British \n    Columbia, and users should cite the original data sources in their work.  "
  },
  {
    "id": 9857,
    "package_name": "childfree",
    "title": "Access and Harmonize Childfree Demographic Data",
    "description": "Reads demographic data from a variety of public data sources, extracting and harmonizing variables useful for the study of childfree individuals. The identification of childfree individuals and those with other family statuses uses Neal & Neal's (2024) \"A Framework for Studying Adults who Neither have Nor Want Children\" <doi:10.1177/10664807231198869>; A pre-print is available at <doi:10.31234/osf.io/fa89m>.",
    "version": "0.0.4",
    "maintainer": "Zachary Neal <zpneal@msu.edu>",
    "author": "Zachary Neal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3076-4995>),\n  Jennifer Watling Neal [aut] (ORCID:\n    <https://orcid.org/0000-0002-7749-8121>)",
    "url": "https://www.zacharyneal.com/childfree-home,\nhttps://github.com/zpneal/childfree",
    "bug_reports": "https://github.com/zpneal/childfree/issues",
    "repository": "https://cran.r-project.org/package=childfree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "childfree Access and Harmonize Childfree Demographic Data Reads demographic data from a variety of public data sources, extracting and harmonizing variables useful for the study of childfree individuals. The identification of childfree individuals and those with other family statuses uses Neal & Neal's (2024) \"A Framework for Studying Adults who Neither have Nor Want Children\" <doi:10.1177/10664807231198869>; A pre-print is available at <doi:10.31234/osf.io/fa89m>.  "
  },
  {
    "id": 9876,
    "package_name": "choroplethr",
    "title": "Create Color-Coded Choropleth Maps in R",
    "description": "Easily create color-coded (choropleth) maps in R. No knowledge of\n  cartography or shapefiles needed; go directly from your geographically\n  identified data to a highly customizable map with a single line of code!\n  Supported geographies: U.S. states, counties, census tracts, and zip codes, \n  world countries and sub-country regions (e.g., provinces, prefectures, etc.).",
    "version": "5.0.1",
    "maintainer": "Zhaochen He <zhaochen.he@cnu.edu>",
    "author": "Ari Lamstein [aut],\n  Zhaochen He [ctb, cre],\n  Brian Johnson [ctb],\n  Trulia, Inc. [cph]",
    "url": "<https://github.com/eastnile/choroplethr>",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=choroplethr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "choroplethr Create Color-Coded Choropleth Maps in R Easily create color-coded (choropleth) maps in R. No knowledge of\n  cartography or shapefiles needed; go directly from your geographically\n  identified data to a highly customizable map with a single line of code!\n  Supported geographies: U.S. states, counties, census tracts, and zip codes, \n  world countries and sub-country regions (e.g., provinces, prefectures, etc.).  "
  },
  {
    "id": 9942,
    "package_name": "clarabel",
    "title": "Interior Point Conic Optimization Solver",
    "description": "A versatile interior point solver that solves linear programs (LPs), quadratic programs (QPs), second-order cone programs (SOCPs), semidefinite programs (SDPs), and problems with exponential and power cone constraints (<https://clarabel.org/stable/>). For quadratic objectives, unlike interior point solvers based on the standard homogeneous self-dual embedding (HSDE) model, Clarabel handles quadratic objective without requiring any epigraphical reformulation of its objective function. It can therefore be significantly faster than other HSDE-based solvers for problems with quadratic objective functions. Infeasible problems are detected using using a homogeneous embedding technique.",
    "version": "0.11.1",
    "maintainer": "Balasubramanian Narasimhan <naras@stanford.edu>",
    "author": "Balasubramanian Narasimhan [aut, cre],\n  Paul Goulart [aut, cph],\n  Yuwen Chen [aut],\n  Hiroaki Yutani [ctb] (For vendoring/Makefile hints/R scripts for\n    generating crate authors/licenses),\n  David Zimmermann-Kollenda [ctb] (For configure scripts and tools/msvr.R\n    lifted from rtiktoken package),\n  The authors of the dependency Rust crates [ctb] (see inst/AUTHORS file\n    for details)",
    "url": "https://oxfordcontrol.github.io/clarabel-r/",
    "bug_reports": "https://github.com/oxfordcontrol/clarabel-r/issues",
    "repository": "https://cran.r-project.org/package=clarabel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clarabel Interior Point Conic Optimization Solver A versatile interior point solver that solves linear programs (LPs), quadratic programs (QPs), second-order cone programs (SOCPs), semidefinite programs (SDPs), and problems with exponential and power cone constraints (<https://clarabel.org/stable/>). For quadratic objectives, unlike interior point solvers based on the standard homogeneous self-dual embedding (HSDE) model, Clarabel handles quadratic objective without requiring any epigraphical reformulation of its objective function. It can therefore be significantly faster than other HSDE-based solvers for problems with quadratic objective functions. Infeasible problems are detected using using a homogeneous embedding technique.  "
  },
  {
    "id": 9999,
    "package_name": "cliot",
    "title": "Clinical Indices and Outcomes Tools",
    "description": "Collection of indices and tools relating to clinical research that aid epidemiological cohort or retrospective chart review with big data. All indices and tools take commonly used lab values, patient demographics, and clinical measurements to compute various risk and predictive values for survival or further classification/stratification. References to original literature and validation contained in each function documentation. Includes all commonly available calculators available online. ",
    "version": "1.0.0",
    "maintainer": "Neel Agarwal <neel.agarwal.216@gmail.com>",
    "author": "Neel Agarwal [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=cliot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cliot Clinical Indices and Outcomes Tools Collection of indices and tools relating to clinical research that aid epidemiological cohort or retrospective chart review with big data. All indices and tools take commonly used lab values, patient demographics, and clinical measurements to compute various risk and predictive values for survival or further classification/stratification. References to original literature and validation contained in each function documentation. Includes all commonly available calculators available online.   "
  },
  {
    "id": 10028,
    "package_name": "clustAnalytics",
    "title": "Cluster Evaluation on Graphs",
    "description": "Evaluates the stability and significance of clusters on 'igraph' graphs.\n    Supports weighted and unweighted graphs. Implements the cluster evaluation methods\n    defined by Arratia A, Renedo M (2021) <doi:10.7717/peerj-cs.600>. Also includes an\n    implementation of the Reduced Mutual Information introduced by Newman et al. (2020) \n    <doi:10.1103/PhysRevE.101.042304>.",
    "version": "0.5.5",
    "maintainer": "Mart\u00ed Renedo Mirambell <marti.renedo@gmail.com>",
    "author": "Mart\u00ed Renedo Mirambell",
    "url": "https://github.com/martirm/clustAnalytics",
    "bug_reports": "https://github.com/martirm/clustAnalytics/issues",
    "repository": "https://cran.r-project.org/package=clustAnalytics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clustAnalytics Cluster Evaluation on Graphs Evaluates the stability and significance of clusters on 'igraph' graphs.\n    Supports weighted and unweighted graphs. Implements the cluster evaluation methods\n    defined by Arratia A, Renedo M (2021) <doi:10.7717/peerj-cs.600>. Also includes an\n    implementation of the Reduced Mutual Information introduced by Newman et al. (2020) \n    <doi:10.1103/PhysRevE.101.042304>.  "
  },
  {
    "id": 10059,
    "package_name": "clustringr",
    "title": "Cluster Strings by Edit-Distance",
    "description": "Returns an edit-distance based clusterization of an input vector of strings.\n    Each cluster will contain a set of strings w/ small mutual edit-distance\n    (e.g., Levenshtein, optimum-sequence-alignment, Damerau-Levenshtein), as computed by\n    stringdist::stringdist(). The set of all mutual edit-distances is then used by\n    graph algorithms (from package 'igraph') to single out subsets of high connectivity.",
    "version": "1.0",
    "maintainer": "Dan S. Reznik <dreznik@gmail.com>",
    "author": "Dan S. Reznik",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=clustringr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "clustringr Cluster Strings by Edit-Distance Returns an edit-distance based clusterization of an input vector of strings.\n    Each cluster will contain a set of strings w/ small mutual edit-distance\n    (e.g., Levenshtein, optimum-sequence-alignment, Damerau-Levenshtein), as computed by\n    stringdist::stringdist(). The set of all mutual edit-distances is then used by\n    graph algorithms (from package 'igraph') to single out subsets of high connectivity.  "
  },
  {
    "id": 10139,
    "package_name": "codified",
    "title": "Produce Standard/Formalized Demographics Tables",
    "description": "Augment clinical data with metadata to create\n    output used in conventional publications and reports.",
    "version": "0.3.0",
    "maintainer": "Will Beasley <wibeasley@hotmail.com>",
    "author": "Will Beasley [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5613-5006>),\n  Peter Higgins [ctb]",
    "url": "https://ouhscbbmc.github.io/codified/,\nhttps://github.com/OuhscBbmc/codified,\nhttps://github.com/higgi13425/nih_enrollment_table",
    "bug_reports": "https://github.com/OuhscBbmc/codified/issues",
    "repository": "https://cran.r-project.org/package=codified",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "codified Produce Standard/Formalized Demographics Tables Augment clinical data with metadata to create\n    output used in conventional publications and reports.  "
  },
  {
    "id": 10274,
    "package_name": "concom",
    "title": "Connected Components of an Undirected Graph",
    "description": "Provides a function for fast computation of the connected\n    components of an undirected graph (though not faster than the\n    components() function of the 'igraph' package) from the edges or the\n    adjacency matrix of the graph. Based on this one, a function to\n    compute the connected components of a triangle 'rgl' mesh is also\n    provided.",
    "version": "1.0.0",
    "maintainer": "St\u00e9phane Laurent <laurent_step@outlook.fr>",
    "author": "St\u00e9phane Laurent [cre, aut]",
    "url": "https://github.com/stla/concom",
    "bug_reports": "https://github.com/stla/concom/issues",
    "repository": "https://cran.r-project.org/package=concom",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "concom Connected Components of an Undirected Graph Provides a function for fast computation of the connected\n    components of an undirected graph (though not faster than the\n    components() function of the 'igraph' package) from the edges or the\n    adjacency matrix of the graph. Based on this one, a function to\n    compute the connected components of a triangle 'rgl' mesh is also\n    provided.  "
  },
  {
    "id": 10275,
    "package_name": "concorR",
    "title": "CONCOR and Supplemental Functions",
    "description": "Contains the CONCOR (CONvergence of iterated CORrelations) \n    algorithm and a series of supplemental functions for easy running, \n    plotting, and blockmodeling. The CONCOR algorithm is used on social network\n    data to identify network positions based off a definition of structural \n    equivalence; see Breiger, Boorman, and Arabie (1975) \n    <doi:10.1016/0022-2496(75)90028-0> and Wasserman and Faust's book Social \n    Network Analysis: Methods and Applications (1994). This version allows \n    multiple relationships for the same set of nodes and uses both incoming and\n    outgoing ties to find positions.",
    "version": "0.2.1",
    "maintainer": "Adrienne Traxler <adrienne.traxler@wright.edu>",
    "author": "Tyme Suda [aut],\n  Adrienne Traxler [cre] (ORCID: <https://orcid.org/0000-0003-2725-0686>),\n  Carter Butts [ctb] (Author of sna::plot.blockmodel(), adapted for\n    plot_blk())",
    "url": "https://github.com/ATraxLab/concorR",
    "bug_reports": "https://github.com/ATraxLab/concorR/issues",
    "repository": "https://cran.r-project.org/package=concorR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "concorR CONCOR and Supplemental Functions Contains the CONCOR (CONvergence of iterated CORrelations) \n    algorithm and a series of supplemental functions for easy running, \n    plotting, and blockmodeling. The CONCOR algorithm is used on social network\n    data to identify network positions based off a definition of structural \n    equivalence; see Breiger, Boorman, and Arabie (1975) \n    <doi:10.1016/0022-2496(75)90028-0> and Wasserman and Faust's book Social \n    Network Analysis: Methods and Applications (1994). This version allows \n    multiple relationships for the same set of nodes and uses both incoming and\n    outgoing ties to find positions.  "
  },
  {
    "id": 10319,
    "package_name": "conmet",
    "title": "Construct Measurement Evaluation Tool",
    "description": "With this package you can run 'ConMET' locally in R. 'ConMET' is an R-shiny application that facilitates performing and evaluating confirmatory factor analyses (CFAs) and is useful for running and reporting typical measurement models in applied psychology and management journals. 'ConMET' automatically creates, compares and summarizes CFA models. Most common fit indices (E.g., CFI and SRMR) are put in an overview table. ConMET also allows to test for common method variance. The application is particularly useful for teaching and instruction of measurement issues in survey research. The application uses the 'lavaan' package (Rosseel, 2012) to run CFAs.",
    "version": "0.1.0",
    "maintainer": "Leander De Schutter <deschutter@rsm.nl>",
    "author": "Leander De Schutter [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9826-4896>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=conmet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "conmet Construct Measurement Evaluation Tool With this package you can run 'ConMET' locally in R. 'ConMET' is an R-shiny application that facilitates performing and evaluating confirmatory factor analyses (CFAs) and is useful for running and reporting typical measurement models in applied psychology and management journals. 'ConMET' automatically creates, compares and summarizes CFA models. Most common fit indices (E.g., CFI and SRMR) are put in an overview table. ConMET also allows to test for common method variance. The application is particularly useful for teaching and instruction of measurement issues in survey research. The application uses the 'lavaan' package (Rosseel, 2012) to run CFAs.  "
  },
  {
    "id": 10344,
    "package_name": "contactdata",
    "title": "Social Contact Matrices for 177 Countries",
    "description": "Data package for the supplementary data in Prem et al. (2017)\n    <doi:10.1371/journal.pcbi.1005697> and Prem et al. \n    <doi:10.1371/journal.pcbi.1009098>.\n    Provides easy access to contact data for 177 countries, for use in\n    epidemiological, demographic or social sciences research.",
    "version": "1.1.0",
    "maintainer": "Hugo Gruson <hugo.gruson+R@normalesup.org>",
    "author": "Hugo Gruson [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-4094-1476>),\n  Kiesha Prem [dtc] (ORCID: <https://orcid.org/0000-0003-0528-798X>),\n  Alex Richard Cook [dtc] (ORCID:\n    <https://orcid.org/0000-0002-6271-5832>),\n  Mark Jit [dtc] (ORCID: <https://orcid.org/0000-0001-6658-8255>)",
    "url": "https://hugogruson.fr/contactdata/,\nhttps://github.com/bisaloo/contactdata",
    "bug_reports": "https://github.com/bisaloo/contactdata/issues",
    "repository": "https://cran.r-project.org/package=contactdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "contactdata Social Contact Matrices for 177 Countries Data package for the supplementary data in Prem et al. (2017)\n    <doi:10.1371/journal.pcbi.1005697> and Prem et al. \n    <doi:10.1371/journal.pcbi.1009098>.\n    Provides easy access to contact data for 177 countries, for use in\n    epidemiological, demographic or social sciences research.  "
  },
  {
    "id": 10353,
    "package_name": "contoso",
    "title": "Dataset of the 'Contoso' Company",
    "description": "A collection of synthetic datasets simulating sales transactions from a fictional company. The dataset includes various related tables that contain essential business and operational data, useful for analyzing sales performance and other business insights. Key tables included in the package are:\n  - \"sales\": Contains data on individual sales transactions, including order details, pricing, quantities, and customer information.\n  - \"customer\": Stores customer-specific details such as demographics, geographic location, occupation, and birthday.\n  - \"store\": Provides information about stores, including location, size, status, and operational dates.\n  - \"orders\": Contains details about customer orders, including order and delivery dates, store, and customer data.\n  - \"product\": Contains data on products, including attributes such as product name, category, price, cost, and weight.\n  - \"date\": A time-based table that includes date-related attributes like year, month, quarter, day, and working day indicators.\n  This dataset is ideal for practicing data analysis, performing time-series analysis, creating reports, or simulating business intelligence scenarios.",
    "version": "1.2.1",
    "maintainer": "Alejandro Hagan <alejandro.hagan@outlook.com>",
    "author": "Alejandro Hagan [aut, cre]",
    "url": "https://usrbinr.github.io/contoso/,\nhttps://github.com/usrbinr/contoso",
    "bug_reports": "https://github.com/usrbinr/contoso/issues",
    "repository": "https://cran.r-project.org/package=contoso",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "contoso Dataset of the 'Contoso' Company A collection of synthetic datasets simulating sales transactions from a fictional company. The dataset includes various related tables that contain essential business and operational data, useful for analyzing sales performance and other business insights. Key tables included in the package are:\n  - \"sales\": Contains data on individual sales transactions, including order details, pricing, quantities, and customer information.\n  - \"customer\": Stores customer-specific details such as demographics, geographic location, occupation, and birthday.\n  - \"store\": Provides information about stores, including location, size, status, and operational dates.\n  - \"orders\": Contains details about customer orders, including order and delivery dates, store, and customer data.\n  - \"product\": Contains data on products, including attributes such as product name, category, price, cost, and weight.\n  - \"date\": A time-based table that includes date-related attributes like year, month, quarter, day, and working day indicators.\n  This dataset is ideal for practicing data analysis, performing time-series analysis, creating reports, or simulating business intelligence scenarios.  "
  },
  {
    "id": 10372,
    "package_name": "convey",
    "title": "Income Concentration Analysis with Complex Survey Samples",
    "description": "Variance estimation on indicators of income concentration and\n    poverty using complex sample survey designs. Wrapper around the\n    'survey' package.",
    "version": "1.0.1",
    "maintainer": "Anthony Damico <ajdamico@gmail.com>",
    "author": "Djalma Pessoa [aut],\n  Anthony Damico [aut, cre],\n  Guilherme Jacob [aut]",
    "url": "https://www.convey-r.org/",
    "bug_reports": "https://github.com/ajdamico/convey/issues",
    "repository": "https://cran.r-project.org/package=convey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "convey Income Concentration Analysis with Complex Survey Samples Variance estimation on indicators of income concentration and\n    poverty using complex sample survey designs. Wrapper around the\n    'survey' package.  "
  },
  {
    "id": 10486,
    "package_name": "covidcast",
    "title": "Client for Delphi's 'COVIDcast Epidata' API",
    "description": "Tools for Delphi's 'COVIDcast Epidata' API: data access, maps and\n    time series plotting, and basic signal processing. The API includes a\n    collection of numerous indicators relevant to the COVID-19 pandemic in the\n    United States, including official reports, de-identified aggregated medical\n    claims data, large-scale surveys of symptoms and public behavior, and\n    mobility data, typically updated daily and at the county level. All data\n    sources are documented at\n    <https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html>.",
    "version": "0.5.3",
    "maintainer": "Alex Reinhart <areinhar@stat.cmu.edu>",
    "author": "Taylor Arnold [aut],\n  Jacob Bien [aut],\n  Logan Brooks [aut],\n  Sarah Colquhoun [aut],\n  David Farrow [aut],\n  Jed Grabman [ctb],\n  Pedrito Maynard-Zhang [ctb],\n  Kathryn Mazaitis [aut],\n  Alex Reinhart [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6658-514X>),\n  Ryan Tibshirani [aut]",
    "url": "https://cmu-delphi.github.io/covidcast/covidcastR/,\nhttps://github.com/cmu-delphi/covidcast",
    "bug_reports": "https://github.com/cmu-delphi/covidcast/issues",
    "repository": "https://cran.r-project.org/package=covidcast",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "covidcast Client for Delphi's 'COVIDcast Epidata' API Tools for Delphi's 'COVIDcast Epidata' API: data access, maps and\n    time series plotting, and basic signal processing. The API includes a\n    collection of numerous indicators relevant to the COVID-19 pandemic in the\n    United States, including official reports, de-identified aggregated medical\n    claims data, large-scale surveys of symptoms and public behavior, and\n    mobility data, typically updated daily and at the county level. All data\n    sources are documented at\n    <https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html>.  "
  },
  {
    "id": 10532,
    "package_name": "cpsR",
    "title": "Load CPS Microdata into R Using the 'Census Bureau Data' API",
    "description": "Load Current Population Survey (CPS) microdata into R using the\n    'Census Bureau Data' API\n    (<https://www.census.gov/data/developers/data-sets.html>), including basic\n    monthly CPS and CPS ASEC microdata.",
    "version": "1.0.0",
    "maintainer": "Matt Saenz <mattsaenz165@gmail.com>",
    "author": "Matt Saenz [aut, cre]",
    "url": "https://github.com/matt-saenz/cpsR",
    "bug_reports": "https://github.com/matt-saenz/cpsR/issues",
    "repository": "https://cran.r-project.org/package=cpsR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cpsR Load CPS Microdata into R Using the 'Census Bureau Data' API Load Current Population Survey (CPS) microdata into R using the\n    'Census Bureau Data' API\n    (<https://www.census.gov/data/developers/data-sets.html>), including basic\n    monthly CPS and CPS ASEC microdata.  "
  },
  {
    "id": 10535,
    "package_name": "cpsvote",
    "title": "A Toolbox for Using the CPS\u2019s Voting and Registration Supplement",
    "description": "Provides automated methods for downloading, recoding, and merging \n    selected years of the Current Population Survey's Voting and Registration \n    Supplement, a large N national survey about registration, voting, and \n    non-voting in United States federal elections. Provides documentation for \n    appropriate use of sample weights to generate statistical estimates, \n    drawing from Hur & Achen (2013) <doi:10.1093/poq/nft042> and McDonald (2018) \n    <http://www.electproject.org/home/voter-turnout/voter-turnout-data>.",
    "version": "0.1.0",
    "maintainer": "Jay Lee <jaylee@reed.edu>",
    "author": "Jay Lee [aut, cre],\n  Paul Gronke [aut],\n  Canyon Foot [ctb]",
    "url": "https://github.com/Reed-EVIC/cpsvote",
    "bug_reports": "https://github.com/Reed-EVIC/cpsvote/issues",
    "repository": "https://cran.r-project.org/package=cpsvote",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cpsvote A Toolbox for Using the CPS\u2019s Voting and Registration Supplement Provides automated methods for downloading, recoding, and merging \n    selected years of the Current Population Survey's Voting and Registration \n    Supplement, a large N national survey about registration, voting, and \n    non-voting in United States federal elections. Provides documentation for \n    appropriate use of sample weights to generate statistical estimates, \n    drawing from Hur & Achen (2013) <doi:10.1093/poq/nft042> and McDonald (2018) \n    <http://www.electproject.org/home/voter-turnout/voter-turnout-data>.  "
  },
  {
    "id": 10543,
    "package_name": "crandep",
    "title": "Network Analysis of Dependencies of CRAN Packages",
    "description": "The dependencies of CRAN packages can be analysed in a network fashion. For each package we can obtain the packages that it depends, imports, suggests, etc. By iterating this procedure over a number of packages, we can build, visualise, and analyse the dependency network, enabling us to have a bird's-eye view of the CRAN ecosystem. One aspect of interest is the number of reverse dependencies of the packages, or equivalently the in-degree distribution of the dependency network. This can be fitted by the power law and/or an extreme value mixture distribution <doi:10.1111/stan.12355>, of which functions are provided.",
    "version": "0.3.13",
    "maintainer": "Clement Lee <clement.lee.tm@outlook.com>",
    "author": "Clement Lee [aut, cre] (ORCID: <https://orcid.org/0000-0003-1785-8671>)",
    "url": "https://github.com/clement-lee/crandep",
    "bug_reports": "https://github.com/clement-lee/crandep/issues",
    "repository": "https://cran.r-project.org/package=crandep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crandep Network Analysis of Dependencies of CRAN Packages The dependencies of CRAN packages can be analysed in a network fashion. For each package we can obtain the packages that it depends, imports, suggests, etc. By iterating this procedure over a number of packages, we can build, visualise, and analyse the dependency network, enabling us to have a bird's-eye view of the CRAN ecosystem. One aspect of interest is the number of reverse dependencies of the packages, or equivalently the in-degree distribution of the dependency network. This can be fitted by the power law and/or an extreme value mixture distribution <doi:10.1111/stan.12355>, of which functions are provided.  "
  },
  {
    "id": 10546,
    "package_name": "cranly",
    "title": "Package Directives and Collaboration Networks in CRAN",
    "description": "Core visualizations and summaries for the CRAN package database. The package provides comprehensive methods for cleaning up and organizing the information in the CRAN package database, for building package directives networks (depends, imports, suggests, enhances, linking to) and collaboration networks, producing package dependence trees, and for computing useful summaries and producing interactive visualizations from the resulting networks and summaries. The resulting networks can be coerced to 'igraph' <https://CRAN.R-project.org/package=igraph> objects for further analyses and modelling.",
    "version": "0.6.0",
    "maintainer": "Ioannis Kosmidis <ioannis.kosmidis@warwick.ac.uk>",
    "author": "Ioannis Kosmidis [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1556-0302>)",
    "url": "https://github.com/ikosmidis/cranly",
    "bug_reports": "https://github.com/ikosmidis/cranly/issues",
    "repository": "https://cran.r-project.org/package=cranly",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cranly Package Directives and Collaboration Networks in CRAN Core visualizations and summaries for the CRAN package database. The package provides comprehensive methods for cleaning up and organizing the information in the CRAN package database, for building package directives networks (depends, imports, suggests, enhances, linking to) and collaboration networks, producing package dependence trees, and for computing useful summaries and producing interactive visualizations from the resulting networks and summaries. The resulting networks can be coerced to 'igraph' <https://CRAN.R-project.org/package=igraph> objects for further analyses and modelling.  "
  },
  {
    "id": 10570,
    "package_name": "criticalpath",
    "title": "An Implementation of the Critical Path Method",
    "description": "\n    An R implementation of the Critical Path Method (CPM).\n    CPM is a method used to estimate the minimum project duration and determine \n    the amount of scheduling flexibility on the logical network paths within the \n    schedule model. The flexibility is in terms of early start, early finish, \n    late start, late finish, total float and free float. Beside, it permits \n    to quantify the complexity of network diagram through the analysis of \n    topological indicators. Finally, it permits to change the activities duration \n    to perform what-if scenario analysis. The package was built based on following \n    references: To make topological sorting and other graph operation, we use \n    Csardi, G. & Nepusz, T. (2005) \n    <https://www.researchgate.net/publication/221995787_The_Igraph_Software_Package_for_Complex_Network_Research>;\n    For schedule concept, the reference was Project Management Institute (2017) \n    <https://www.pmi.org/pmbok-guide-standards/foundational/pmbok>;\n    For standards terms, we use Project Management Institute (2017) \n    <https://www.pmi.org/pmbok-guide-standards/lexicon>;\n    For algorithms on Critical Path Method development, we use \n    Vanhoucke, M. (2013) <doi:10.1007/978-3-642-40438-2> and \n    Vanhoucke, M. (2014) <doi:10.1007/978-3-319-04331-9>; \n    And, finally, for topological definitions, we use\n    Vanhoucke, M. (2009) <doi:10.1007/978-1-4419-1014-1>.",
    "version": "0.2.1",
    "maintainer": "Rubens Jose Rosa <rubens@rubensjoserosa.com>",
    "author": "Rubens Jose Rosa [aut, cre],\n  Marcos dos Santos [aut],\n  Thiago Marques [aut]",
    "url": "https://rubensjoserosa.com/criticalpath,\nhttps://github.com/rubens2005/criticalpath",
    "bug_reports": "https://github.com/rubens2005/criticalpath/issues",
    "repository": "https://cran.r-project.org/package=criticalpath",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "criticalpath An Implementation of the Critical Path Method \n    An R implementation of the Critical Path Method (CPM).\n    CPM is a method used to estimate the minimum project duration and determine \n    the amount of scheduling flexibility on the logical network paths within the \n    schedule model. The flexibility is in terms of early start, early finish, \n    late start, late finish, total float and free float. Beside, it permits \n    to quantify the complexity of network diagram through the analysis of \n    topological indicators. Finally, it permits to change the activities duration \n    to perform what-if scenario analysis. The package was built based on following \n    references: To make topological sorting and other graph operation, we use \n    Csardi, G. & Nepusz, T. (2005) \n    <https://www.researchgate.net/publication/221995787_The_Igraph_Software_Package_for_Complex_Network_Research>;\n    For schedule concept, the reference was Project Management Institute (2017) \n    <https://www.pmi.org/pmbok-guide-standards/foundational/pmbok>;\n    For standards terms, we use Project Management Institute (2017) \n    <https://www.pmi.org/pmbok-guide-standards/lexicon>;\n    For algorithms on Critical Path Method development, we use \n    Vanhoucke, M. (2013) <doi:10.1007/978-3-642-40438-2> and \n    Vanhoucke, M. (2014) <doi:10.1007/978-3-319-04331-9>; \n    And, finally, for topological definitions, we use\n    Vanhoucke, M. (2009) <doi:10.1007/978-1-4419-1014-1>.  "
  },
  {
    "id": 10590,
    "package_name": "crosshap",
    "title": "Local Haplotype Clustering and Visualization",
    "description": "A local haplotyping visualization toolbox to capture major patterns \n    of co-inheritance between clusters of linked variants, whilst connecting findings \n    to phenotypic and demographic traits across individuals. 'crosshap' enables users \n    to explore and understand genomic variation across a trait-associated region. \n    For an example of successful local haplotype analysis, see Marsh et al. (2022) \n    <doi:10.1007/s00122-022-04045-8>.",
    "version": "1.4.0",
    "maintainer": "Jacob Marsh <jake.marsh@live.com.au>",
    "author": "Jacob Marsh [aut, cre] (ORCID: <https://orcid.org/0000-0003-3734-2023>),\n  Brady Johnston [aut] (ORCID: <https://orcid.org/0000-0001-6301-2269>),\n  Jakob Petereit [aut] (ORCID: <https://orcid.org/0000-0003-2159-0380>)",
    "url": "https://jacobimarsh.github.io/crosshap/",
    "bug_reports": "https://github.com/jacobimarsh/crosshap/issues",
    "repository": "https://cran.r-project.org/package=crosshap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crosshap Local Haplotype Clustering and Visualization A local haplotyping visualization toolbox to capture major patterns \n    of co-inheritance between clusters of linked variants, whilst connecting findings \n    to phenotypic and demographic traits across individuals. 'crosshap' enables users \n    to explore and understand genomic variation across a trait-associated region. \n    For an example of successful local haplotype analysis, see Marsh et al. (2022) \n    <doi:10.1007/s00122-022-04045-8>.  "
  },
  {
    "id": 10607,
    "package_name": "crs",
    "title": "Categorical Regression Splines",
    "description": "Regression splines that handle a mix of continuous and categorical (discrete) data often encountered in applied settings. I would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <https://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <https://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://www.sharcnet.ca>). We would also like to acknowledge the contributions of the GNU GSL authors. In particular, we adapt the GNU GSL B-spline routine gsl_bspline.c adding automated support for quantile knots (in addition to uniform knots), providing missing functionality for derivatives, and for extending the splines beyond their endpoints.",
    "version": "0.15-38",
    "maintainer": "Jeffrey S. Racine <racinej@mcmaster.ca>",
    "author": "Jeffrey S. Racine [aut, cre],\n  Zhenghua Nie [aut],\n  Brian D. Ripley [ctb] (stepCV.R)",
    "url": "https://github.com/JeffreyRacine/R-Package-crs",
    "bug_reports": "https://github.com/JeffreyRacine/R-Package-crs/issues",
    "repository": "https://cran.r-project.org/package=crs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crs Categorical Regression Splines Regression splines that handle a mix of continuous and categorical (discrete) data often encountered in applied settings. I would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <https://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <https://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://www.sharcnet.ca>). We would also like to acknowledge the contributions of the GNU GSL authors. In particular, we adapt the GNU GSL B-spline routine gsl_bspline.c adding automated support for quantile knots (in addition to uniform knots), providing missing functionality for derivatives, and for extending the splines beyond their endpoints.  "
  },
  {
    "id": 10609,
    "package_name": "crsmeta",
    "title": "Extract Coordinate System Metadata",
    "description": "Obtain coordinate system metadata from various data formats. There \n are functions to extract a 'CRS' (coordinate reference system, \n <https://en.wikipedia.org/wiki/Spatial_reference_system>) in 'EPSG' (European \n Petroleum Survey Group, <http://www.epsg.org/>), 'PROJ4' <https://proj.org/>, \n or 'WKT2' (Well-Known Text 2, \n <http://docs.opengeospatial.org/is/12-063r5/12-063r5.html>) forms. This is \n purely for getting simple metadata from in-memory formats, please use other \n tools for out of memory data sources. ",
    "version": "0.3.0",
    "maintainer": "Michael Sumner <mdsumner@gmail.com>",
    "author": "Michael Sumner [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2471-7511>)",
    "url": "https://github.com/hypertidy/crsmeta",
    "bug_reports": "https://github.com/hypertidy/crsmeta/issues",
    "repository": "https://cran.r-project.org/package=crsmeta",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "crsmeta Extract Coordinate System Metadata Obtain coordinate system metadata from various data formats. There \n are functions to extract a 'CRS' (coordinate reference system, \n <https://en.wikipedia.org/wiki/Spatial_reference_system>) in 'EPSG' (European \n Petroleum Survey Group, <http://www.epsg.org/>), 'PROJ4' <https://proj.org/>, \n or 'WKT2' (Well-Known Text 2, \n <http://docs.opengeospatial.org/is/12-063r5/12-063r5.html>) forms. This is \n purely for getting simple metadata from in-memory formats, please use other \n tools for out of memory data sources.   "
  },
  {
    "id": 10647,
    "package_name": "csurvey",
    "title": "Constrained Regression for Survey Data",
    "description": "Domain mean estimation with monotonicity or block monotone constraints. See Xu X, Meyer MC and Opsomer JD (2021)<doi:10.1016/j.jspi.2021.02.004> for more details. ",
    "version": "1.14",
    "maintainer": "Xiyue Liao <xliao@sdsu.edu>",
    "author": "Xiyue Liao [aut, cre] (ORCID: <https://orcid.org/0000-0002-4508-9219>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=csurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "csurvey Constrained Regression for Survey Data Domain mean estimation with monotonicity or block monotone constraints. See Xu X, Meyer MC and Opsomer JD (2021)<doi:10.1016/j.jspi.2021.02.004> for more details.   "
  },
  {
    "id": 10653,
    "package_name": "ctablerseh",
    "title": "Processing Survey Data with Confidence Intervals Like 'SPSS'\nSoftware",
    "description": "Processes survey data and displays estimation results along with the relative standard error in a table, including the number of samples and also uses a t-distribution approach to compute confidence intervals, similar to 'SPSS' (Statistical Package for the Social Sciences) software.",
    "version": "1.1.2",
    "maintainer": "Asy-Syaja'ul Haqqul Amin <haqqul.amin06@gmail.com>",
    "author": "Asy-Syaja'ul Haqqul Amin [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ctablerseh",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ctablerseh Processing Survey Data with Confidence Intervals Like 'SPSS'\nSoftware Processes survey data and displays estimation results along with the relative standard error in a table, including the number of samples and also uses a t-distribution approach to compute confidence intervals, similar to 'SPSS' (Statistical Package for the Social Sciences) software.  "
  },
  {
    "id": 10724,
    "package_name": "cvap",
    "title": "Citizen Voting Age Population",
    "description": "Works with the Citizen Voting Age Population special tabulation from the US Census Bureau <https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.html>. Provides tools to download and process raw data. Also provides a downloading interface to processed data. Implements a very basic approach to estimate block level citizen voting age population from block group data.",
    "version": "0.1.6",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>)",
    "url": "https://github.com/christopherkenny/cvap,\nhttps://christophertkenny.com/cvap/",
    "bug_reports": "https://github.com/christopherkenny/cvap/issues",
    "repository": "https://cran.r-project.org/package=cvap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "cvap Citizen Voting Age Population Works with the Citizen Voting Age Population special tabulation from the US Census Bureau <https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.html>. Provides tools to download and process raw data. Also provides a downloading interface to processed data. Implements a very basic approach to estimate block level citizen voting age population from block group data.  "
  },
  {
    "id": 10755,
    "package_name": "d3r",
    "title": "'d3.js' Utilities for R",
    "description": "Provides a suite of functions to help ease the use of 'd3.js' in R.\n              These helpers include 'htmltools::htmlDependency' functions, hierarchy\n              builders, and conversion tools for 'partykit', 'igraph,' 'table',\n              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.",
    "version": "1.1.0",
    "maintainer": "Kent Russell <kent.russell@timelyportfolio.com>",
    "author": "Mike Bostock [aut, cph] (d3.js library in htmlwidgets/lib,\n    http://d3js.org),\n  Kent Russell [aut, cre, cph] (R interface),\n  Gregor Aisch [aut, cph] (d3-jetpack creator,\n    https://github.com/gka/d3-jetpack),\n  Adam Pearce [aut] (core contributor to d3-jetpack),\n  Ben Ortiz [ctb]",
    "url": "https://github.com/timelyportfolio/d3r",
    "bug_reports": "https://github.com/timelyportfolio/d3r/issues",
    "repository": "https://cran.r-project.org/package=d3r",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "d3r 'd3.js' Utilities for R Provides a suite of functions to help ease the use of 'd3.js' in R.\n              These helpers include 'htmltools::htmlDependency' functions, hierarchy\n              builders, and conversion tools for 'partykit', 'igraph,' 'table',\n              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.  "
  },
  {
    "id": 10826,
    "package_name": "dataRetrieval",
    "title": "Retrieval Functions for USGS and EPA Hydrology and Water Quality\nData",
    "description": "Collection of functions to help retrieve U.S. Geological Survey\n    and U.S. Environmental Protection Agency water quality and\n    hydrology data from web services. ",
    "version": "2.7.21",
    "maintainer": "Laura DeCicco <ldecicco@usgs.gov>",
    "author": "Laura DeCicco [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3915-9487>),\n  Robert Hirsch [aut] (ORCID: <https://orcid.org/0000-0002-4534-075X>),\n  David Lorenz [aut],\n  Jordan Read [ctb],\n  Jordan Walker [ctb],\n  Lindsay Platt [ctb],\n  David Watkins [aut] (ORCID: <https://orcid.org/0000-0002-7544-0700>),\n  David Blodgett [aut] (ORCID: <https://orcid.org/0000-0001-9489-1710>),\n  Mike Johnson [aut] (ORCID: <https://orcid.org/0000-0002-5288-8350>),\n  Aliesha Krall [ctb] (ORCID: <https://orcid.org/0000-0003-2521-5043>),\n  Lee Stanish [ctb] (ORCID: <https://orcid.org/0000-0002-9775-6861>),\n  Joeseph Zemmels [ctb] (ORCID: <https://orcid.org/0009-0008-1463-6313>),\n  Elise Hinman [ctb] (ORCID: <https://orcid.org/0000-0001-5396-1583>),\n  Michael Mahoney [ctb] (ORCID: <https://orcid.org/0000-0003-2402-304X>)",
    "url": "",
    "bug_reports": "https://github.com/DOI-USGS/dataRetrieval/issues",
    "repository": "https://cran.r-project.org/package=dataRetrieval",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dataRetrieval Retrieval Functions for USGS and EPA Hydrology and Water Quality\nData Collection of functions to help retrieve U.S. Geological Survey\n    and U.S. Environmental Protection Agency water quality and\n    hydrology data from web services.   "
  },
  {
    "id": 10829,
    "package_name": "datacommons",
    "title": "Client for the 'Google Data Commons API V2'",
    "description": "Access the 'Google Data Commons API V2' <https://docs.datacommons.org/api/rest/v2/>.\n    Data Commons provides programmatic access to statistical and demographic data from\n    dozens of sources organized in a knowledge graph. ",
    "version": "0.1.0",
    "maintainer": "Christoph Scheuch <christoph@tidy-intelligence.com>",
    "author": "Christoph Scheuch [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0004-0423-6819>),\n  Teal Emery [aut]",
    "url": "https://github.com/tidy-intelligence/r-datacommons,\nhttps://tidy-intelligence.github.io/r-datacommons/",
    "bug_reports": "https://github.com/tidy-intelligence/r-datacommons/issues",
    "repository": "https://cran.r-project.org/package=datacommons",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "datacommons Client for the 'Google Data Commons API V2' Access the 'Google Data Commons API V2' <https://docs.datacommons.org/api/rest/v2/>.\n    Data Commons provides programmatic access to statistical and demographic data from\n    dozens of sources organized in a knowledge graph.   "
  },
  {
    "id": 10898,
    "package_name": "dc3net",
    "title": "Inferring Condition-Specific Networks via Differential Network\nInference",
    "description": "Performs differential network analysis to infer disease specific gene networks.",
    "version": "1.2.0",
    "maintainer": "Gokmen Altay <altaylabs@gmail.com>",
    "author": "Gokmen Altay",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dc3net",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dc3net Inferring Condition-Specific Networks via Differential Network\nInference Performs differential network analysis to infer disease specific gene networks.  "
  },
  {
    "id": 10922,
    "package_name": "ddi",
    "title": "The Data Defect Index for Samples that May not be IID",
    "description": "Implements Meng's data defect index (ddi), which represents\n    the degree of sample bias relative to an iid sample. The data defect \n    correlation (ddc) represents the correlation between the outcome of interest\n    and the selection into the sample; when the sample selection is independent\n    across the population, the ddc is zero. Details are in Meng (2018) \n    <doi:10.1214/18-AOAS1161SF>, \"Statistical Paradises and Paradoxes in Big Data (I): \n    Law of Large Populations, Big Data Paradox, and the 2016 US Presidential \n    Election.\" Survey estimates from the Cooperative Congressional Election Study \n    (CCES) is included to replicate the article's results. ",
    "version": "0.1.0",
    "maintainer": "Shiro Kuriwaki <shirokuriwaki@gmail.com>",
    "author": "Shiro Kuriwaki [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5687-2647>)",
    "url": "https://github.com/kuriwaki/ddi",
    "bug_reports": "http://github.com/kuriwaki/ddi/issues",
    "repository": "https://cran.r-project.org/package=ddi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ddi The Data Defect Index for Samples that May not be IID Implements Meng's data defect index (ddi), which represents\n    the degree of sample bias relative to an iid sample. The data defect \n    correlation (ddc) represents the correlation between the outcome of interest\n    and the selection into the sample; when the sample selection is independent\n    across the population, the ddc is zero. Details are in Meng (2018) \n    <doi:10.1214/18-AOAS1161SF>, \"Statistical Paradises and Paradoxes in Big Data (I): \n    Law of Large Populations, Big Data Paradox, and the 2016 US Presidential \n    Election.\" Survey estimates from the Cooperative Congressional Election Study \n    (CCES) is included to replicate the article's results.   "
  },
  {
    "id": 10924,
    "package_name": "ddp",
    "title": "Desirable Dietary Pattern",
    "description": "The desirable Dietary Pattern (DDP)/ PPH score\n  measures the variety of food consumption. The (weighted) score is calculated \n  based on the type of food. This package is intended to calculate\n  the DDP/ PPH score that is faster than traditional method via \n  a manual calculation by BKP (2017) <http://bkp.pertanian.go.id/storage/app/uploads/public/5bf/ca9/06b/5bfca906bc654274163456.pdf> and is simpler than the nutrition survey \n  <http://www.nutrisurvey.de>. The database to create weights and baseline values\n  is the Indonesia national survey in 2017.",
    "version": "0.0.3",
    "maintainer": "Weksi Budiaji <budiaji@untirta.ac.id>",
    "author": "Weksi Budiaji [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ddp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ddp Desirable Dietary Pattern The desirable Dietary Pattern (DDP)/ PPH score\n  measures the variety of food consumption. The (weighted) score is calculated \n  based on the type of food. This package is intended to calculate\n  the DDP/ PPH score that is faster than traditional method via \n  a manual calculation by BKP (2017) <http://bkp.pertanian.go.id/storage/app/uploads/public/5bf/ca9/06b/5bfca906bc654274163456.pdf> and is simpler than the nutrition survey \n  <http://www.nutrisurvey.de>. The database to create weights and baseline values\n  is the Indonesia national survey in 2017.  "
  },
  {
    "id": 10951,
    "package_name": "decompositionLE",
    "title": "Provides Easy Methods to Perform Life Expectancy Decomposition",
    "description": "Provides an easy to use implementation of life expectancy decomposition formulas for age bands, derived from Ponnapalli, K. (2005). A comparison of different methods for decomposition of changes in expectation of life at birth and differentials in life expectancy at birth. Demographic Research, 12, pp.141\u2013172. <doi:10.4054/demres.2005.12.7> In addition, there is a decomposition function for disease cause breakdown and a couple helpful plot functions.",
    "version": "1.0.0",
    "maintainer": "Victor Yu <victor.yu@hertfordshire.gov.uk>",
    "author": "Victor Yu [aut, cre, cph],\n  Will Yuill [ctb] (ORCID: <https://orcid.org/0009-0003-6270-4273>),\n  Emily Dickson [ctb]",
    "url": "https://github.com/herts-phei/decompositionLE",
    "bug_reports": "https://github.com/herts-phei/decompositionLE/issues",
    "repository": "https://cran.r-project.org/package=decompositionLE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "decompositionLE Provides Easy Methods to Perform Life Expectancy Decomposition Provides an easy to use implementation of life expectancy decomposition formulas for age bands, derived from Ponnapalli, K. (2005). A comparison of different methods for decomposition of changes in expectation of life at birth and differentials in life expectancy at birth. Demographic Research, 12, pp.141\u2013172. <doi:10.4054/demres.2005.12.7> In addition, there is a decomposition function for disease cause breakdown and a couple helpful plot functions.  "
  },
  {
    "id": 10984,
    "package_name": "degreenet",
    "title": "Models for Skewed Count Distributions Relevant to Networks",
    "description": "Likelihood-based inference for skewed count distributions, typically of degrees used in network modeling. \"degreenet\" is a part of the \"statnet\" suite of packages for network analysis. See Jones and Handcock <doi:10.1098/rspb.2003.2369>.",
    "version": "1.3-6",
    "maintainer": "Mark S. Handcock <handcock@stat.ucla.edu>",
    "author": "Mark S. Handcock [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9985-2785>)",
    "url": "https://statnet.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=degreenet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "degreenet Models for Skewed Count Distributions Relevant to Networks Likelihood-based inference for skewed count distributions, typically of degrees used in network modeling. \"degreenet\" is a part of the \"statnet\" suite of packages for network analysis. See Jones and Handcock <doi:10.1098/rspb.2003.2369>.  "
  },
  {
    "id": 10997,
    "package_name": "demoGraphic",
    "title": "Providing Demographic Table with the P-Value, Standardized Mean\nDifference Value",
    "description": "The Demographic Table in R combines contingency table for categorical variables, mean and standard deviation for continuous variables. t-test, chi-square test and Fisher's exact test calculated the p-value of two groups. The standardized mean difference were performed with 95 % confident interval, and writing table into document file.",
    "version": "0.1.0",
    "maintainer": "Loan Robinson <loankimrobinson@gmail.com>",
    "author": "Loan Robinson [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=demoGraphic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "demoGraphic Providing Demographic Table with the P-Value, Standardized Mean\nDifference Value The Demographic Table in R combines contingency table for categorical variables, mean and standard deviation for continuous variables. t-test, chi-square test and Fisher's exact test calculated the p-value of two groups. The standardized mean difference were performed with 95 % confident interval, and writing table into document file.  "
  },
  {
    "id": 11001,
    "package_name": "demogR",
    "title": "Analysis of Age-Structured Demographic Models",
    "description": "Construction and analysis of matrix population models in R.",
    "version": "0.6.0",
    "maintainer": "Hana Sevcikova <hanas@uw.edu>",
    "author": "James Holland Jones [aut] <jhj1@stanford.edu>, Jim Oeppen [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=demogR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "demogR Analysis of Age-Structured Demographic Models Construction and analysis of matrix population models in R.  "
  },
  {
    "id": 11002,
    "package_name": "demography",
    "title": "Forecasting Mortality, Fertility, Migration and Population Data",
    "description": "Functions for demographic analysis including lifetable\n        calculations; Lee-Carter modelling; functional data analysis of\n        mortality rates, fertility rates, net migration numbers; and\n        stochastic population forecasting.",
    "version": "2.0.1",
    "maintainer": "Rob Hyndman <Rob.Hyndman@monash.edu>",
    "author": "Rob Hyndman [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2140-5352>),\n  Heather Booth [ctb] (ORCID: <https://orcid.org/0000-0002-8356-0534>),\n  Leonie Tickle [ctb] (ORCID: <https://orcid.org/0000-0002-6612-2401>),\n  John Maindonald [ctb],\n  Simon Wood [ctb],\n  R Core Team [ctb]",
    "url": "https://pkg.robjhyndman.com/demography/,\nhttps://github.com/robjhyndman/demography",
    "bug_reports": "https://github.com/robjhyndman/demography/issues",
    "repository": "https://cran.r-project.org/package=demography",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "demography Forecasting Mortality, Fertility, Migration and Population Data Functions for demographic analysis including lifetable\n        calculations; Lee-Carter modelling; functional data analysis of\n        mortality rates, fertility rates, net migration numbers; and\n        stochastic population forecasting.  "
  },
  {
    "id": 11033,
    "package_name": "deprivateR",
    "title": "Calculating and Analyzing Measures of Deprivation in the United\nStates",
    "description": "Provides a unified framework to building Area Deprivation Index (ADI), \n    Social Vulnerability Index (SVI), and Neighborhood Deprivation Index (NDI)  \n    deprivation measures and accessing related data from the U.S. Census Bureau \n    such as Gini coefficient data. Tools are also available for calculating percentiles,\n    quantiles, and for creating clear map breaks for data visualization.",
    "version": "0.1.0",
    "maintainer": "Christopher Prener <christopher.prener@pfizer.com>",
    "author": "Christopher Prener [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4310-9888>),\n  Timothy Wiemken [aut] (ORCID: <https://orcid.org/0000-0002-8251-3007>)",
    "url": "https://pfizer-opensource.github.io/deprivateR/",
    "bug_reports": "https://github.com/pfizer-opensource/deprivateR/issues",
    "repository": "https://cran.r-project.org/package=deprivateR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "deprivateR Calculating and Analyzing Measures of Deprivation in the United\nStates Provides a unified framework to building Area Deprivation Index (ADI), \n    Social Vulnerability Index (SVI), and Neighborhood Deprivation Index (NDI)  \n    deprivation measures and accessing related data from the U.S. Census Bureau \n    such as Gini coefficient data. Tools are also available for calculating percentiles,\n    quantiles, and for creating clear map breaks for data visualization.  "
  },
  {
    "id": 11107,
    "package_name": "dhga",
    "title": "Differential Hub Gene Analysis",
    "description": "Identification of hub genes in a gene co-expression network from gene expression data. The differential network analysis for two contrasting conditions leads to the identification of various types of hubs like Housekeeping, Unique to stress (Disease) and Unique to control (Normal) hub genes. ",
    "version": "0.1",
    "maintainer": "Samarendra Das <samarendra4849@gmail.com>",
    "author": "Samarendra Das <samarendra4849@gmail.com> and Baidya Nath Mandal <mandal.stat@gmail.com> ",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dhga",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dhga Differential Hub Gene Analysis Identification of hub genes in a gene co-expression network from gene expression data. The differential network analysis for two contrasting conditions leads to the identification of various types of hubs like Housekeeping, Unique to stress (Disease) and Unique to control (Normal) hub genes.   "
  },
  {
    "id": 11109,
    "package_name": "dhsage",
    "title": "Reproductive Age Female Data of Various Demographic Health\nSurveys",
    "description": "We provide 70 data sets of females of reproductive age from 19 Asian countries, ranging in age from 15 to 49. The data sets are extracted from demographic and health surveys that were conducted over an extended period of time. Moreover, the functions also provide Whipple\u2019s index as well as age reporting quality such as very rough, rough, approximate, accurate, and highly accurate.",
    "version": "0.1.0",
    "maintainer": "Muhammad Imran <imranshakoor84@yahoo.com>",
    "author": "Jamal Abdul Nasir [aut],\n  Andleeb Rani [aut],\n  Muhammad Imran [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dhsage",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dhsage Reproductive Age Female Data of Various Demographic Health\nSurveys We provide 70 data sets of females of reproductive age from 19 Asian countries, ranging in age from 15 to 49. The data sets are extracted from demographic and health surveys that were conducted over an extended period of time. Moreover, the functions also provide Whipple\u2019s index as well as age reporting quality such as very rough, rough, approximate, accurate, and highly accurate.  "
  },
  {
    "id": 11199,
    "package_name": "discursive",
    "title": "Measuring Discursive Sophistication in Open-Ended Survey\nResponses",
    "description": "A simple approach to measure political sophistication based on open-ended survey responses. Discursive sophistication captures the complexity of individual attitude expression by quantifying its relative size, range, and constraint. For more information on the measurement approach see: Kraft, Patrick W. 2023. \"Women Also Know Stuff: Challenging the Gender Gap in Political Sophistication.\" American Political Science Review (forthcoming).",
    "version": "0.1.1",
    "maintainer": "Patrick Kraft <kraft.pw@gmail.com>",
    "author": "Patrick Kraft [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0123-221X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=discursive",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "discursive Measuring Discursive Sophistication in Open-Ended Survey\nResponses A simple approach to measure political sophistication based on open-ended survey responses. Discursive sophistication captures the complexity of individual attitude expression by quantifying its relative size, range, and constraint. For more information on the measurement approach see: Kraft, Patrick W. 2023. \"Women Also Know Stuff: Challenging the Gender Gap in Political Sophistication.\" American Political Science Review (forthcoming).  "
  },
  {
    "id": 11239,
    "package_name": "distrr",
    "title": "Estimate and Manage Empirical Distributions",
    "description": "Tools to estimate and manage empirical distributions,\n    which should work with survey data. One of the main features is the \n    possibility to create data cubes of estimated statistics, that include\n    all the combinations of the variables of interest (see for example functions\n    dcc5() and dcc6()).",
    "version": "0.0.6",
    "maintainer": "Sandro Petrillo Burri <gibo.gaf@gmail.com>",
    "author": "Sandro Petrillo Burri [aut, cre]",
    "url": "https://gibonet.github.io/distrr,\nhttps://github.com/gibonet/distrr",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=distrr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "distrr Estimate and Manage Empirical Distributions Tools to estimate and manage empirical distributions,\n    which should work with survey data. One of the main features is the \n    possibility to create data cubes of estimated statistics, that include\n    all the combinations of the variables of interest (see for example functions\n    dcc5() and dcc6()).  "
  },
  {
    "id": 11319,
    "package_name": "dogesr",
    "title": "Work with the Doges/Dogaresse Dataset",
    "description": "Work with data on Venetian doges and dogaresse and the noble families of the Republic of Venice, and use it for social network analysis, as used in Merelo (2022) <doi:10.48550/arXiv.2209.07334>.",
    "version": "0.5.2",
    "maintainer": "Juan Juli\u00e1n Merelo-Guerv\u00f3s <jjmerelo@gmail.com>",
    "author": "Juan Juli\u00e1n Merelo-Guerv\u00f3s [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dogesr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dogesr Work with the Doges/Dogaresse Dataset Work with data on Venetian doges and dogaresse and the noble families of the Republic of Venice, and use it for social network analysis, as used in Merelo (2022) <doi:10.48550/arXiv.2209.07334>.  "
  },
  {
    "id": 11388,
    "package_name": "drhutools",
    "title": "Political Science Academic Research Gears",
    "description": "Using these tools to simplify the research process of political science and other social sciences. The current version can create folder system for academic project in political science, calculate psychological trait scores, visualize experimental and spatial data, and set up color-blind palette, functions used in academic research of political psychology or political science in general.",
    "version": "1.0.1",
    "maintainer": "Yue Hu <yuehu@tsinghua.edu.cn>",
    "author": "Yue Hu [aut, cre],\n  Qian Qiu [ctb],\n  Wen Deng [ctb]",
    "url": "https://www.drhuyue.site/software/drhutools/",
    "bug_reports": "https://github.com/sammo3182/drhutools/issues",
    "repository": "https://cran.r-project.org/package=drhutools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "drhutools Political Science Academic Research Gears Using these tools to simplify the research process of political science and other social sciences. The current version can create folder system for academic project in political science, calculate psychological trait scores, visualize experimental and spatial data, and set up color-blind palette, functions used in academic research of political psychology or political science in general.  "
  },
  {
    "id": 11394,
    "package_name": "dropR",
    "title": "Dropout Analysis by Condition",
    "description": "Analysis and visualization of dropout between conditions in surveys and (online) experiments. Features include computation of dropout statistics, comparing dropout between conditions (e.g. Chi square), analyzing survival (e.g. Kaplan-Meier estimation), comparing conditions with the most different rates of dropout (Kolmogorov-Smirnov) and visualizing the result of each in designated plotting functions. Sources: Andrea Frick, Marie-Terese Baechtiger & Ulf-Dietrich Reips (2001) <https://www.researchgate.net/publication/223956222_Financial_incentives_personal_information_and_drop-out_in_online_studies>; Ulf-Dietrich Reips (2002) \"Standards for Internet-Based Experimenting\" <doi:10.1027//1618-3169.49.4.243>.",
    "version": "1.0.3",
    "maintainer": "Annika Tave Overlander <annika-tave.overlander@uni.kn>",
    "author": "Annika Tave Overlander [aut, cre],\n  Matthias Bannert [aut],\n  Ulf-Dietrich Reips [ctb]",
    "url": "https://iscience-kn.github.io/dropR/,\nhttps://github.com/iscience-kn/dropR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dropR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dropR Dropout Analysis by Condition Analysis and visualization of dropout between conditions in surveys and (online) experiments. Features include computation of dropout statistics, comparing dropout between conditions (e.g. Chi square), analyzing survival (e.g. Kaplan-Meier estimation), comparing conditions with the most different rates of dropout (Kolmogorov-Smirnov) and visualizing the result of each in designated plotting functions. Sources: Andrea Frick, Marie-Terese Baechtiger & Ulf-Dietrich Reips (2001) <https://www.researchgate.net/publication/223956222_Financial_incentives_personal_information_and_drop-out_in_online_studies>; Ulf-Dietrich Reips (2002) \"Standards for Internet-Based Experimenting\" <doi:10.1027//1618-3169.49.4.243>.  "
  },
  {
    "id": 11395,
    "package_name": "dropout",
    "title": "Handling Incomplete Responses in Survey Data Analysis",
    "description": "Offers robust tools to identify and manage incomplete responses in survey datasets, thereby enhancing the quality and reliability of research findings.",
    "version": "2.2.0",
    "maintainer": "Hendrik Mann <hendrik.mann@uni-wuppertal.de>",
    "author": "Hendrik Mann [aut, cre]",
    "url": "https://github.com/hendr1km/dropout,\nhttps://hendr1km.github.io/dropout/",
    "bug_reports": "https://github.com/hendr1km/dropout/issues",
    "repository": "https://cran.r-project.org/package=dropout",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dropout Handling Incomplete Responses in Survey Data Analysis Offers robust tools to identify and manage incomplete responses in survey datasets, thereby enhancing the quality and reliability of research findings.  "
  },
  {
    "id": 11406,
    "package_name": "ds4psy",
    "title": "Data Science for Psychologists",
    "description": "All datasets and functions required for the examples and exercises of the book \"Data Science for Psychologists\" (by Hansjoerg Neth, Konstanz University, 2025, <doi:10.5281/zenodo.7229812>), freely available at <https://bookdown.org/hneth/ds4psy/>. The book and corresponding courses introduce principles and methods of data science to students of psychology and other biological or social sciences. The 'ds4psy' package primarily provides datasets, but also functions for data generation and manipulation (e.g., of text and time data) and graphics that are used in the book and its exercises. All functions included in 'ds4psy' are designed to be explicit and instructive, rather than efficient or elegant. ",
    "version": "1.2.0",
    "maintainer": "Hansjoerg Neth <h.neth@uni.kn>",
    "author": "Hansjoerg Neth [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5427-3141>)",
    "url": "https://bookdown.org/hneth/ds4psy/,\nhttps://github.com/hneth/ds4psy/",
    "bug_reports": "https://github.com/hneth/ds4psy/issues",
    "repository": "https://cran.r-project.org/package=ds4psy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ds4psy Data Science for Psychologists All datasets and functions required for the examples and exercises of the book \"Data Science for Psychologists\" (by Hansjoerg Neth, Konstanz University, 2025, <doi:10.5281/zenodo.7229812>), freely available at <https://bookdown.org/hneth/ds4psy/>. The book and corresponding courses introduce principles and methods of data science to students of psychology and other biological or social sciences. The 'ds4psy' package primarily provides datasets, but also functions for data generation and manipulation (e.g., of text and time data) and graphics that are used in the book and its exercises. All functions included in 'ds4psy' are designed to be explicit and instructive, rather than efficient or elegant.   "
  },
  {
    "id": 11415,
    "package_name": "dsims",
    "title": "Distance Sampling Simulations",
    "description": "Performs distance sampling simulations. 'dsims' repeatedly generates\n    instances of a user defined population within a given survey region. It then \n    generates realisations of a survey design and simulates the detection process. \n    The data are then analysed so that the results can be compared for accuracy \n    and precision across all replications. This process allows users to optimise \n    survey designs for their specific set of survey conditions. The effects of \n    uncertainty in population distribution or parameters can be investigated\n    under a number of simulations so that users can be confident that they have\n    achieved a robust survey design before deploying vessels into the field. The\n    distance sampling designs used in this package from 'dssd' are detailed in\n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, ISBN-13: \n    978-0199225873). General distance sampling methods are detailed in Introduction \n    to Distance Sampling: Estimating Abundance of Biological Populations, Buckland \n    et. al. (2004, ISBN-13: 978-0198509271). Find out more about estimating \n    animal/plant abundance with distance sampling at <https://distancesampling.org/>.",
    "version": "1.0.6",
    "maintainer": "Laura Marshall <lhm@st-and.ac.uk>",
    "author": "Laura Marshall [aut, cre],\n  Thomas Len [ctb]",
    "url": "https://github.com/DistanceDevelopment/dsims",
    "bug_reports": "https://github.com/DistanceDevelopment/dsims/issues",
    "repository": "https://cran.r-project.org/package=dsims",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dsims Distance Sampling Simulations Performs distance sampling simulations. 'dsims' repeatedly generates\n    instances of a user defined population within a given survey region. It then \n    generates realisations of a survey design and simulates the detection process. \n    The data are then analysed so that the results can be compared for accuracy \n    and precision across all replications. This process allows users to optimise \n    survey designs for their specific set of survey conditions. The effects of \n    uncertainty in population distribution or parameters can be investigated\n    under a number of simulations so that users can be confident that they have\n    achieved a robust survey design before deploying vessels into the field. The\n    distance sampling designs used in this package from 'dssd' are detailed in\n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, ISBN-13: \n    978-0199225873). General distance sampling methods are detailed in Introduction \n    to Distance Sampling: Estimating Abundance of Biological Populations, Buckland \n    et. al. (2004, ISBN-13: 978-0198509271). Find out more about estimating \n    animal/plant abundance with distance sampling at <https://distancesampling.org/>.  "
  },
  {
    "id": 11426,
    "package_name": "dssd",
    "title": "Distance Sampling Survey Design",
    "description": "Creates survey designs for distance sampling surveys. These\n    designs can be assessed for various effort and coverage statistics.\n    Once the user is satisfied with the design characteristics they can \n    generate a set of transects to use in their distance sampling survey.\n    Many of the designs implemented in this R package were first made \n    available in our 'Distance' for Windows software and are detailed in \n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, \n    ISBN-13: 978-0199225873). Find out more about estimating animal/plant \n    abundance with distance sampling at <https://distancesampling.org/>. ",
    "version": "1.0.3",
    "maintainer": "Laura Marshall <lhm@st-andrews.ac.uk>",
    "author": "Laura Marshall [aut, cre],\n  Rexstad Eric [ctb]",
    "url": "",
    "bug_reports": "https://github.com/DistanceDevelopment/dssd/issues",
    "repository": "https://cran.r-project.org/package=dssd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dssd Distance Sampling Survey Design Creates survey designs for distance sampling surveys. These\n    designs can be assessed for various effort and coverage statistics.\n    Once the user is satisfied with the design characteristics they can \n    generate a set of transects to use in their distance sampling survey.\n    Many of the designs implemented in this R package were first made \n    available in our 'Distance' for Windows software and are detailed in \n    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, \n    ISBN-13: 978-0199225873). Find out more about estimating animal/plant \n    abundance with distance sampling at <https://distancesampling.org/>.   "
  },
  {
    "id": 11436,
    "package_name": "dtlg",
    "title": "A Performance-Focused Package for Clinical Trial Tables",
    "description": "Create high-performance clinical reporting tables (TLGs) from\n    ADaM-like inputs. The package provides a consistent, programmatic API\n    to generate common tables such as demographics, adverse event incidence,\n    and laboratory summaries, using 'data.table' for fast aggregation over\n    large populations. Functions support flexible target-variable selection,\n    stratification by treatment, and customizable summary statistics, and\n    return tidy, machine-readable results ready to render with downstream\n    table/formatting packages in analysis pipelines.",
    "version": "0.0.2",
    "maintainer": "Ramiro Magno <ramiro.morgado@ascent.io>",
    "author": "Max Ebenezer-Brown [aut],\n  Max Norman [aut],\n  Xinye Li [aut],\n  Anja Peebles-Brown [aut],\n  Ramiro Magno [aut, cre]",
    "url": "https://AscentSoftware.github.io/dtlg/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dtlg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dtlg A Performance-Focused Package for Clinical Trial Tables Create high-performance clinical reporting tables (TLGs) from\n    ADaM-like inputs. The package provides a consistent, programmatic API\n    to generate common tables such as demographics, adverse event incidence,\n    and laboratory summaries, using 'data.table' for fast aggregation over\n    large populations. Functions support flexible target-variable selection,\n    stratification by treatment, and customizable summary statistics, and\n    return tidy, machine-readable results ready to render with downstream\n    table/formatting packages in analysis pipelines.  "
  },
  {
    "id": 11449,
    "package_name": "dualScale",
    "title": "Dual Scaling Analysis of Data",
    "description": "Dual Scaling, developed by Professor Shizuhiko Nishisato (1994, ISBN: 0-9691785-3-6), is a fundamental technique in multivariate analysis used for data scaling and correspondence analysis. Its utility lies in its ability to represent multidimensional data in a lower-dimensional space, making it easier to visualize and understand underlying patterns in complex data. This technique has been implemented to handle various types of data, including Contingency and Frequency data (CF), Multiple-Choice data (MC), Sorting data (SO), Paired-Comparison data (PC), and Rank-Order data (RO), providing users with a powerful tool to explore relationships between variables and observations in various fields, from sociology to ecology, enabling deeper and more efficient analysis of multivariate datasets.",
    "version": "1.0.0",
    "maintainer": "Roberto de la Banda <dualScale@gmail.com>",
    "author": "Jose G. Clavel [aut] (ORCID: <https://orcid.org/0000-0001-5800-319X>),\n  Shizuiko Nishisato [aut] (ORCID:\n    <https://orcid.org/0000-0002-6471-3128>),\n  Roberto de la Banda [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9027-2282>),\n  Antonio Pita [ctb] (ORCID: <https://orcid.org/0000-0003-2134-1800>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dualScale",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dualScale Dual Scaling Analysis of Data Dual Scaling, developed by Professor Shizuhiko Nishisato (1994, ISBN: 0-9691785-3-6), is a fundamental technique in multivariate analysis used for data scaling and correspondence analysis. Its utility lies in its ability to represent multidimensional data in a lower-dimensional space, making it easier to visualize and understand underlying patterns in complex data. This technique has been implemented to handle various types of data, including Contingency and Frequency data (CF), Multiple-Choice data (MC), Sorting data (SO), Paired-Comparison data (PC), and Rank-Order data (RO), providing users with a powerful tool to explore relationships between variables and observations in various fields, from sociology to ecology, enabling deeper and more efficient analysis of multivariate datasets.  "
  },
  {
    "id": 11473,
    "package_name": "dyads",
    "title": "Dyadic Network Analysis",
    "description": "Contains functions for the MCMC simulation of dyadic network models j2 (Zijlstra, 2017, <doi:10.1080/0022250X.2017.1387858>) and p2 (Van Duijn, Snijders & Zijlstra, 2004, <doi: 10.1046/j.0039-0402.2003.00258.x>), the multilevel p2 model (Zijlstra, Van Duijn & Snijders (2009) <doi: 10.1348/000711007X255336>), and the bidirectional (multilevel) counterpart of the the multilevel p2 model as described in Zijlstra, Van Duijn & Snijders (2009) <doi: 10.1348/000711007X255336>, the (multilevel) b2 model. ",
    "version": "1.2.1",
    "maintainer": "Bonne J.H. Zijlstra <B.J.H.Zijlstra@uva.nl>",
    "author": "Bonne J.H. Zijlstra <B.J.H.Zijlstra@uva.nl>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=dyads",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "dyads Dyadic Network Analysis Contains functions for the MCMC simulation of dyadic network models j2 (Zijlstra, 2017, <doi:10.1080/0022250X.2017.1387858>) and p2 (Van Duijn, Snijders & Zijlstra, 2004, <doi: 10.1046/j.0039-0402.2003.00258.x>), the multilevel p2 model (Zijlstra, Van Duijn & Snijders (2009) <doi: 10.1348/000711007X255336>), and the bidirectional (multilevel) counterpart of the the multilevel p2 model as described in Zijlstra, Van Duijn & Snijders (2009) <doi: 10.1348/000711007X255336>, the (multilevel) b2 model.   "
  },
  {
    "id": 11557,
    "package_name": "easycensus",
    "title": "Quickly Find, Extract, and Marginalize U.S. Census Tables",
    "description": "Extracting desired data using the proper Census variable names can \n    be time-consuming. This package takes the pain out of that process by \n    providing functions to quickly locate variables and download labeled tables \n    from the Census APIs (<https://www.census.gov/data/developers/data-sets.html>).",
    "version": "1.1.3",
    "maintainer": "Cory McCartan <mccartan@psu.edu>",
    "author": "Cory McCartan [aut, cre]",
    "url": "https://corymccartan.com/easycensus/,\nhttps://github.com/CoryMcCartan/easycensus/,\nhttp://corymccartan.com/easycensus/",
    "bug_reports": "https://github.com/CoryMcCartan/easycensus/issues",
    "repository": "https://cran.r-project.org/package=easycensus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "easycensus Quickly Find, Extract, and Marginalize U.S. Census Tables Extracting desired data using the proper Census variable names can \n    be time-consuming. This package takes the pain out of that process by \n    providing functions to quickly locate variables and download labeled tables \n    from the Census APIs (<https://www.census.gov/data/developers/data-sets.html>).  "
  },
  {
    "id": 11572,
    "package_name": "eatRep",
    "title": "Educational Assessment Tools for Replication Methods",
    "description": "Replication methods to compute some basic statistic operations (means, standard deviations,\n  frequency tables, percentiles, mean comparisons using weighted effect coding, generalized linear models,\n  and linear multilevel models) in complex survey designs comprising multiple imputed or nested imputed\n  variables and/or a clustered sampling structure which both deserve special procedures at least in\n  estimating standard errors. See the package documentation for a more detailed description along with references.",
    "version": "0.15.2",
    "maintainer": "Sebastian Weirich <sebastian.weirich@iqb.hu-berlin.de>",
    "author": "Sebastian Weirich [aut, cre],\n  Martin Hecht [aut],\n  Karoline Sachse [aut],\n  Benjamin Becker [aut],\n  Edna Grewers [ctb]",
    "url": "https://github.com/weirichs/eatRep,\nhttps://weirichs.github.io/eatRep/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=eatRep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eatRep Educational Assessment Tools for Replication Methods Replication methods to compute some basic statistic operations (means, standard deviations,\n  frequency tables, percentiles, mean comparisons using weighted effect coding, generalized linear models,\n  and linear multilevel models) in complex survey designs comprising multiple imputed or nested imputed\n  variables and/or a clustered sampling structure which both deserve special procedures at least in\n  estimating standard errors. See the package documentation for a more detailed description along with references.  "
  },
  {
    "id": 11577,
    "package_name": "ebal",
    "title": "Entropy Reweighting to Create Balanced Samples",
    "description": "Package implements entropy balancing, a data preprocessing procedure described in Hainmueller (2008, <doi:10.1093/pan/mpr025>) that allows users to reweight a dataset such that the covariate distributions in the reweighted data satisfy a set of user specified moment conditions. This can be useful to create balanced samples in observational studies with a binary treatment where the control group data can be reweighted to match the covariate moments in the treatment group. Entropy balancing can also be used to reweight a survey sample to known characteristics from a target population.",
    "version": "0.1-8",
    "maintainer": "Jens Hainmueller <jhain@stanford.edu>",
    "author": "Jens Hainmueller",
    "url": "https://web.stanford.edu/~jhain/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ebal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ebal Entropy Reweighting to Create Balanced Samples Package implements entropy balancing, a data preprocessing procedure described in Hainmueller (2008, <doi:10.1093/pan/mpr025>) that allows users to reweight a dataset such that the covariate distributions in the reweighted data satisfy a set of user specified moment conditions. This can be useful to create balanced samples in observational studies with a binary treatment where the control group data can be reweighted to match the covariate moments in the treatment group. Entropy balancing can also be used to reweight a survey sample to known characteristics from a target population.  "
  },
  {
    "id": 11611,
    "package_name": "ecocomDP",
    "title": "Tools to Create, Use, and Convert ecocomDP Data",
    "description": "Work with the Ecological Community Data Design Pattern. 'ecocomDP' \n    is a flexible data model for harmonizing ecological community surveys, in a \n    research question agnostic format, from source data published across \n    repositories, and with methods that keep the derived data up-to-date as the \n    underlying sources change. Described in O'Brien et al. (2021), \n    <doi:10.1016/j.ecoinf.2021.101374>.",
    "version": "1.3.2",
    "maintainer": "Colin Smith <colin.smith@wisc.edu>",
    "author": "Colin Smith [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2261-9931>),\n  Eric Sokol [aut] (ORCID: <https://orcid.org/0000-0001-5923-0917>),\n  Margaret O'Brien [aut] (ORCID: <https://orcid.org/0000-0002-1693-8322>),\n  Matt Bitters [ctb],\n  Melissa Chen [ctb],\n  Savannah Gonzales [ctb],\n  Matt Helmus [ctb],\n  Brendan Hobart [ctb],\n  Ruvi Jaimes [ctb],\n  Lara Janson [ctb],\n  Marta Jarzyna [ctb],\n  Michael Just [ctb],\n  Daijiang Li [ctb],\n  Wynne Moss [ctb],\n  Kari Norman [ctb],\n  Stephanie Parker [ctb],\n  Rafael Rangel [ctb] (ORCID: <https://orcid.org/0009-0000-6265-3064>),\n  Natalie Robinson [ctb],\n  Thilina Surasinghe [ctb],\n  Kyle Zollo-Venecek [ctb] (ORCID:\n    <https://orcid.org/0000-0002-1615-590X>)",
    "url": "https://github.com/EDIorg/ecocomDP",
    "bug_reports": "https://github.com/EDIorg/ecocomDP/issues",
    "repository": "https://cran.r-project.org/package=ecocomDP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ecocomDP Tools to Create, Use, and Convert ecocomDP Data Work with the Ecological Community Data Design Pattern. 'ecocomDP' \n    is a flexible data model for harmonizing ecological community surveys, in a \n    research question agnostic format, from source data published across \n    repositories, and with methods that keep the derived data up-to-date as the \n    underlying sources change. Described in O'Brien et al. (2021), \n    <doi:10.1016/j.ecoinf.2021.101374>.  "
  },
  {
    "id": 11624,
    "package_name": "econtools",
    "title": "Enrich and Analyze Sovereign-Level Economic Data",
    "description": "Provides a consistent set of functions for enriching and analyzing \n    sovereign-level economic data. Economists, data scientists, and financial \n    professionals can use the package to add standardized identifiers, \n    demographic and macroeconomic indicators, and derived metrics such as \n    gross domestic product per capita or government expenditure shares.",
    "version": "0.1.0",
    "maintainer": "Christoph Scheuch <christoph@tidy-intelligence.com>",
    "author": "Christoph Scheuch [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0004-0423-6819>)",
    "url": "https://github.com/tidy-intelligence/r-econtools,\nhttps://tidy-intelligence.github.io/r-econtools/",
    "bug_reports": "https://github.com/tidy-intelligence/r-econtools/issues",
    "repository": "https://cran.r-project.org/package=econtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "econtools Enrich and Analyze Sovereign-Level Economic Data Provides a consistent set of functions for enriching and analyzing \n    sovereign-level economic data. Economists, data scientists, and financial \n    professionals can use the package to add standardized identifiers, \n    demographic and macroeconomic indicators, and derived metrics such as \n    gross domestic product per capita or government expenditure shares.  "
  },
  {
    "id": 11625,
    "package_name": "econullnetr",
    "title": "Null Model Analysis for Ecological Networks",
    "description": "Null models to analyse ecological networks (e.g. food webs, \n    flower-visitation networks, seed-dispersal networks) and detect resource \n    preferences or non-random interactions among network nodes. Tools are \n    provided to run null models, test for and plot preferences, plot and \n    analyse bipartite networks, and export null model results in a form \n    compatible with other network analysis packages. The underlying null model \n    was developed by Agusti et al. (2003) Molecular Ecology \n    <doi:10.1046/j.1365-294X.2003.02014.x> and the full application to \n    ecological networks by Vaughan et al. (2018) econullnetr: an R package \n    using null models to analyse the structure of ecological networks and \n    identify resource selection. Methods in Ecology & Evolution, \n    <doi:10.1111/2041-210X.12907>.",
    "version": "0.2.2",
    "maintainer": "Ian Vaughan <vaughanip@cardiff.ac.uk>",
    "author": "Ian Vaughan [aut, cre] (ORCID: <https://orcid.org/0000-0002-7263-3822>)",
    "url": "",
    "bug_reports": "https://github.com/ivaughan/econullnetr/issues",
    "repository": "https://cran.r-project.org/package=econullnetr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "econullnetr Null Model Analysis for Ecological Networks Null models to analyse ecological networks (e.g. food webs, \n    flower-visitation networks, seed-dispersal networks) and detect resource \n    preferences or non-random interactions among network nodes. Tools are \n    provided to run null models, test for and plot preferences, plot and \n    analyse bipartite networks, and export null model results in a form \n    compatible with other network analysis packages. The underlying null model \n    was developed by Agusti et al. (2003) Molecular Ecology \n    <doi:10.1046/j.1365-294X.2003.02014.x> and the full application to \n    ecological networks by Vaughan et al. (2018) econullnetr: an R package \n    using null models to analyse the structure of ecological networks and \n    identify resource selection. Methods in Ecology & Evolution, \n    <doi:10.1111/2041-210X.12907>.  "
  },
  {
    "id": 11659,
    "package_name": "edfinr",
    "title": "Access Tidy Education Finance Data",
    "description": "Provides easy access to tidy education finance data using Bellwether's methodology \n    to combine NCES F-33 Survey, Census Bureau Small Area Income Poverty Estimates (SAIPE),\n    and community data from the ACS 5-Year Estimates. The package simplifies\n    downloading, caching, and filtering education finance data by year and state,\n    enabling researchers and analysts to explore K-12 education funding patterns,\n    revenue sources, expenditure categories, and demographic factors across \n    U.S. school districts.",
    "version": "0.1.1",
    "maintainer": "Alex Spurrier <alex.spurrier@bellwether.org>",
    "author": "Alex Spurrier [aut, cre],\n  Krista Kaput [aut],\n  Michael Chrzan [ctb],\n  Bellwether [cph]",
    "url": "https://github.com/bellwetherorg/edfinr,\nhttps://bellwetherorg.github.io/edfinr/",
    "bug_reports": "https://github.com/bellwetherorg/edfinr/issues",
    "repository": "https://cran.r-project.org/package=edfinr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "edfinr Access Tidy Education Finance Data Provides easy access to tidy education finance data using Bellwether's methodology \n    to combine NCES F-33 Survey, Census Bureau Small Area Income Poverty Estimates (SAIPE),\n    and community data from the ACS 5-Year Estimates. The package simplifies\n    downloading, caching, and filtering education finance data by year and state,\n    enabling researchers and analysts to explore K-12 education funding patterns,\n    revenue sources, expenditure categories, and demographic factors across \n    U.S. school districts.  "
  },
  {
    "id": 11672,
    "package_name": "editrules",
    "title": "Parsing, Applying, and Manipulating Data Cleaning Rules",
    "description": "Please note: active development has moved to packages 'validate'\n    and 'errorlocate'. Facilitates reading and manipulating (multivariate) data\n    restrictions (edit rules) on numerical and categorical data. Rules can be\n    defined with common R syntax and parsed to an internal (matrix-like format).\n    Rules can be manipulated with variable elimination and value substitution\n    methods, allowing for feasibility checks and more. Data can be tested against\n    the rules and erroneous fields can be found based on Fellegi and Holt's\n    generalized principle. Rules dependencies can be visualized with using the\n    'igraph' package. ",
    "version": "2.9.6",
    "maintainer": "Edwin de Jonge <edwindjonge@gmail.com>",
    "author": "Edwin de Jonge [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6580-4718>),\n  Mark van der Loo [aut]",
    "url": "https://github.com/data-cleaning/editrules",
    "bug_reports": "https://github.com/data-cleaning/editrules/issues",
    "repository": "https://cran.r-project.org/package=editrules",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "editrules Parsing, Applying, and Manipulating Data Cleaning Rules Please note: active development has moved to packages 'validate'\n    and 'errorlocate'. Facilitates reading and manipulating (multivariate) data\n    restrictions (edit rules) on numerical and categorical data. Rules can be\n    defined with common R syntax and parsed to an internal (matrix-like format).\n    Rules can be manipulated with variable elimination and value substitution\n    methods, allowing for feasibility checks and more. Data can be tested against\n    the rules and erroneous fields can be found based on Fellegi and Holt's\n    generalized principle. Rules dependencies can be visualized with using the\n    'igraph' package.   "
  },
  {
    "id": 11705,
    "package_name": "ehymet",
    "title": "Methodologies for Functional Data Based on the Epigraph and\nHypograph Indices",
    "description": "Implements methods for functional data analysis based on the epigraph \n  and hypograph indices. These methods transform \n  functional datasets, whether in one or multiple dimensions, into multivariate \n  datasets. The transformation involves applying the epigraph, hypograph, and \n  their modified versions to both the original curves and their first and second \n  derivatives. The calculation of these indices is tailored to the dimensionality \n  of the functional dataset, with special considerations for dependencies between \n  dimensions in multidimensional cases. This approach extends traditional multivariate\n  data analysis techniques to the functional data setting. A key application of \n  this package is the EHyClus method, which enhances clustering analysis for \n  functional data across one or multiple dimensions using the epigraph and \n  hypograph indices. See Pulido et al. (2023) <doi:10.1007/s11222-023-10213-7>\n  and Pulido et al. (2024) <doi:10.48550/arXiv.2307.16720>.",
    "version": "0.1.1",
    "maintainer": "Belen Pulido <bpulidob4@gmail.com>",
    "author": "Belen Pulido [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2105-959X>),\n  Jose Ignacio Diez [ctr]",
    "url": "https://github.com/bpulidob/ehymet,\nhttps://bpulidob.github.io/ehymet/",
    "bug_reports": "https://github.com/bpulidob/ehymet/issues",
    "repository": "https://cran.r-project.org/package=ehymet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ehymet Methodologies for Functional Data Based on the Epigraph and\nHypograph Indices Implements methods for functional data analysis based on the epigraph \n  and hypograph indices. These methods transform \n  functional datasets, whether in one or multiple dimensions, into multivariate \n  datasets. The transformation involves applying the epigraph, hypograph, and \n  their modified versions to both the original curves and their first and second \n  derivatives. The calculation of these indices is tailored to the dimensionality \n  of the functional dataset, with special considerations for dependencies between \n  dimensions in multidimensional cases. This approach extends traditional multivariate\n  data analysis techniques to the functional data setting. A key application of \n  this package is the EHyClus method, which enhances clustering analysis for \n  functional data across one or multiple dimensions using the epigraph and \n  hypograph indices. See Pulido et al. (2023) <doi:10.1007/s11222-023-10213-7>\n  and Pulido et al. (2024) <doi:10.48550/arXiv.2307.16720>.  "
  },
  {
    "id": 11764,
    "package_name": "emdi",
    "title": "Estimating and Mapping Disaggregated Indicators",
    "description": "Functions that support estimating, assessing and mapping regional\n    disaggregated indicators. So far, estimation methods comprise direct estimation,\n    the model-based unit-level approach Empirical Best Prediction (see \"Small area\n    estimation of poverty indicators\" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), \n    the area-level model (see \"Estimates of income for small places: An \n    application of James-Stein procedures to Census Data\" by Fay and Herriot (1979) \n    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance \n    estimation methods, log and arcsin transformation, spatial, robust and measurement \n    error models), as well as their precision estimates. The assessment of the used model\n    is supported by a summary and diagnostic plots. For a suitable presentation of\n    estimates, map plots can be easily created. Furthermore, results can easily be\n    exported to excel. For a detailed description of the package and the methods used\n    see \"The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators\" \n    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette \n    \"A Framework for Producing Small Area Estimates Based on Area-Level Models in R\".",
    "version": "2.2.3",
    "maintainer": "Soeren Pannier <soeren.pannier@fu-berlin.de>",
    "author": "Sylvia Harmening [aut],\n  Ann-Kristin Kreutzmann [aut],\n  Soeren Pannier [aut, cre],\n  Felix Skarke [aut],\n  Natalia Rojas-Perilla [aut],\n  Nicola Salvati [aut],\n  Timo Schmid [aut],\n  Matthias Templ [aut],\n  Nikos Tzavidis [aut],\n  Nora W\u00fcrz [aut]",
    "url": "https://github.com/SoerenPannier/emdi",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=emdi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "emdi Estimating and Mapping Disaggregated Indicators Functions that support estimating, assessing and mapping regional\n    disaggregated indicators. So far, estimation methods comprise direct estimation,\n    the model-based unit-level approach Empirical Best Prediction (see \"Small area\n    estimation of poverty indicators\" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), \n    the area-level model (see \"Estimates of income for small places: An \n    application of James-Stein procedures to Census Data\" by Fay and Herriot (1979) \n    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance \n    estimation methods, log and arcsin transformation, spatial, robust and measurement \n    error models), as well as their precision estimates. The assessment of the used model\n    is supported by a summary and diagnostic plots. For a suitable presentation of\n    estimates, map plots can be easily created. Furthermore, results can easily be\n    exported to excel. For a detailed description of the package and the methods used\n    see \"The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators\" \n    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette \n    \"A Framework for Producing Small Area Estimates Based on Area-Level Models in R\".  "
  },
  {
    "id": 11773,
    "package_name": "emon",
    "title": "Tools for Environmental and Ecological Survey Design",
    "description": "Statistical tools for environmental and ecological surveys.\n    Simulation-based power and precision analysis; detection probabilities from\n    different survey designs; visual fast count estimation.",
    "version": "1.3.2",
    "maintainer": "Jon Barry <jon.barry@cefas.co.uk>",
    "author": "Jon Barry and David Maxwell",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=emon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "emon Tools for Environmental and Ecological Survey Design Statistical tools for environmental and ecological surveys.\n    Simulation-based power and precision analysis; detection probabilities from\n    different survey designs; visual fast count estimation.  "
  },
  {
    "id": 11783,
    "package_name": "enaho",
    "title": "Encuesta Nacional de Hogares (Peruvian Home National Survey)",
    "description": "Descarga, lee y analiza bases de la Encuesta Nacional de Hogares (ENAHO) y otras encuestas del Instituto Nacional de Estad\u00edstica e Inform\u00e1tica (INEI) del Per\u00fa. (Downloads, reads, and combines data from the Peruvian Home National Survey and other surveys from the National Institute for Statistics (INEI).)",
    "version": "0.2.5",
    "maintainer": "Andr\u00e9s Christiansen <andres.christiansen@iea-hamburg.de>",
    "author": "Andr\u00e9s Christiansen [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2692-7843>)",
    "url": "https://dopatendo.github.io/enaho/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=enaho",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "enaho Encuesta Nacional de Hogares (Peruvian Home National Survey) Descarga, lee y analiza bases de la Encuesta Nacional de Hogares (ENAHO) y otras encuestas del Instituto Nacional de Estad\u00edstica e Inform\u00e1tica (INEI) del Per\u00fa. (Downloads, reads, and combines data from the Peruvian Home National Survey and other surveys from the National Institute for Statistics (INEI).)  "
  },
  {
    "id": 11790,
    "package_name": "endorse",
    "title": "Bayesian Measurement Models for Analyzing Endorsement\nExperiments",
    "description": "Fit the hierarchical and non-hierarchical Bayesian measurement models proposed by Bullock, Imai, and Shapiro (2011) <DOI:10.1093/pan/mpr031> to analyze endorsement experiments.  Endorsement experiments are a survey methodology for eliciting truthful responses to sensitive questions.  This methodology is helpful when measuring support for socially sensitive political actors such as militant groups.  The model is fitted with a Markov chain Monte Carlo algorithm and produces the output containing draws from the posterior distribution. ",
    "version": "1.6.2",
    "maintainer": "Yuki Shiraito <shiraito@umich.edu>",
    "author": "Yuki Shiraito [aut, cre],\n  Kosuke Imai [aut],\n  Bryn Rosenfeld [ctb]",
    "url": "https://github.com/SensitiveQuestions/endorse/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=endorse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "endorse Bayesian Measurement Models for Analyzing Endorsement\nExperiments Fit the hierarchical and non-hierarchical Bayesian measurement models proposed by Bullock, Imai, and Shapiro (2011) <DOI:10.1093/pan/mpr031> to analyze endorsement experiments.  Endorsement experiments are a survey methodology for eliciting truthful responses to sensitive questions.  This methodology is helpful when measuring support for socially sensitive political actors such as militant groups.  The model is fitted with a Markov chain Monte Carlo algorithm and produces the output containing draws from the posterior distribution.   "
  },
  {
    "id": 11841,
    "package_name": "epidata",
    "title": "Tools to Retrieve Economic Policy Institute Data Library\nExtracts",
    "description": "The Economic Policy Institute (<https://www.epi.org/>) provides\n    researchers, media, and the public with easily accessible, up-to-date, and\n    comprehensive historical data on the American labor force. It is compiled\n    from Economic Policy Institute analysis of government data sources. Use\n    it to research wages, inequality, and other economic indicators over time\n    and among demographic groups. Data is usually updated monthly.",
    "version": "0.4.0",
    "maintainer": "Bob Rudis <bob@rud.is>",
    "author": "Bob Rudis [aut, cre]",
    "url": "https://gitlab.com/hrbrmstr/epidata",
    "bug_reports": "https://github.com/hrbrmstr/epidata/issues",
    "repository": "https://cran.r-project.org/package=epidata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epidata Tools to Retrieve Economic Policy Institute Data Library\nExtracts The Economic Policy Institute (<https://www.epi.org/>) provides\n    researchers, media, and the public with easily accessible, up-to-date, and\n    comprehensive historical data on the American labor force. It is compiled\n    from Economic Policy Institute analysis of government data sources. Use\n    it to research wages, inequality, and other economic indicators over time\n    and among demographic groups. Data is usually updated monthly.  "
  },
  {
    "id": 11843,
    "package_name": "epidict",
    "title": "Epidemiology Data Dictionaries and Random Data Generators",
    "description": "The 'R4EPIs' project <https://r4epi.github.io/sitrep/> seeks\n    to provide a set of standardized tools for analysis of outbreak and\n    survey data in humanitarian aid settings. This package currently\n    provides standardized data dictionaries from Medecins Sans Frontieres\n    Operational Centre Amsterdam for outbreak scenarios (Acute Jaundice\n    Syndrome, Cholera, Diphtheria, Measles, Meningitis) and surveys\n    (Retrospective mortality and access to care, Malnutrition, Vaccination\n    coverage and Event Based Surveillance) - as described in the following\n    <https://scienceportal.msf.org/assets/standardised-mortality-surveys?utm_source=chatgpt.com>.\n    In addition, a data generator from these dictionaries is provided. It\n    is also possible to read in any Open Data Kit format data dictionary.",
    "version": "0.1.0",
    "maintainer": "Alexander Spina <aspina@appliedepi.org>",
    "author": "Alexander Spina [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8425-1867>),\n  Zhian N. Kamvar [aut] (ORCID: <https://orcid.org/0000-0003-1458-7108>),\n  Lukas Richter [aut],\n  Patrick Keating [aut],\n  Annick Lenglet [ctb],\n  Applied Epi Incorporated [cph],\n  Medecins Sans Frontieres Operational Centre Amsterdam [fnd]",
    "url": "https://github.com/R4EPI/epidict/,\nhttps://r4epi.github.io/epidict/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=epidict",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epidict Epidemiology Data Dictionaries and Random Data Generators The 'R4EPIs' project <https://r4epi.github.io/sitrep/> seeks\n    to provide a set of standardized tools for analysis of outbreak and\n    survey data in humanitarian aid settings. This package currently\n    provides standardized data dictionaries from Medecins Sans Frontieres\n    Operational Centre Amsterdam for outbreak scenarios (Acute Jaundice\n    Syndrome, Cholera, Diphtheria, Measles, Meningitis) and surveys\n    (Retrospective mortality and access to care, Malnutrition, Vaccination\n    coverage and Event Based Surveillance) - as described in the following\n    <https://scienceportal.msf.org/assets/standardised-mortality-surveys?utm_source=chatgpt.com>.\n    In addition, a data generator from these dictionaries is provided. It\n    is also possible to read in any Open Data Kit format data dictionary.  "
  },
  {
    "id": 11846,
    "package_name": "epigraphdb",
    "title": "Interface Package for the 'EpiGraphDB' Platform",
    "description": "The interface package to access data from the\n    'EpiGraphDB' <https://epigraphdb.org> platform.\n    It provides easy access to the 'EpiGraphDB' platform with functions that\n    query the corresponding REST endpoints on the API <https://api.epigraphdb.org>\n    and return the response data in the 'tibble' data frame format.",
    "version": "0.2.3",
    "maintainer": "Yi Liu <yi6240.liu@bristol.ac.uk>",
    "author": "Yi Liu [cre, aut],\n  Valeriia Haberland [aut],\n  Marina Vabistsevits [aut],\n  Tom Gaunt [aut],\n  MRC IEU [cph]",
    "url": "https://mrcieu.github.io/epigraphdb-r/",
    "bug_reports": "https://github.com/MRCIEU/epigraphdb-r/issues",
    "repository": "https://cran.r-project.org/package=epigraphdb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epigraphdb Interface Package for the 'EpiGraphDB' Platform The interface package to access data from the\n    'EpiGraphDB' <https://epigraphdb.org> platform.\n    It provides easy access to the 'EpiGraphDB' platform with functions that\n    query the corresponding REST endpoints on the API <https://api.epigraphdb.org>\n    and return the response data in the 'tibble' data frame format.  "
  },
  {
    "id": 11848,
    "package_name": "epikit",
    "title": "Miscellaneous Helper Tools for Epidemiologists",
    "description": "Contains tools for formatting inline code, renaming redundant\n  columns, aggregating age categories, adding survey weights, finding the earliest\n  date of an event, plotting z-curves, generating population counts and \n  formatting proportions with confidence intervals. This is part of the \n  'R4Epis' project <https://r4epi.github.io/sitrep/>.",
    "version": "0.2.0",
    "maintainer": "Alexander Spina <aspina@appliedepi.org>",
    "author": "Alexander Spina [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8425-1867>),\n  Zhian N. Kamvar [aut] (ORCID: <https://orcid.org/0000-0003-1458-7108>),\n  Dirk Schumacher [aut],\n  Kate Doyle [ctb],\n  Applied Epi Incorporated [cph],\n  Medecins Sans Frontieres Operational Centre Amsterdam [fnd]",
    "url": "https://github.com/R4EPI/epikit/, https://r4epi.github.io/epikit/",
    "bug_reports": "https://github.com/R4EPI/epikit/issues",
    "repository": "https://cran.r-project.org/package=epikit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "epikit Miscellaneous Helper Tools for Epidemiologists Contains tools for formatting inline code, renaming redundant\n  columns, aggregating age categories, adding survey weights, finding the earliest\n  date of an event, plotting z-curves, generating population counts and \n  formatting proportions with confidence intervals. This is part of the \n  'R4Epis' project <https://r4epi.github.io/sitrep/>.  "
  },
  {
    "id": 11878,
    "package_name": "eq5d",
    "title": "Methods for Analysing 'EQ-5D' Data and Calculating 'EQ-5D' Index\nScores",
    "description": "EQ-5D is a popular health related quality of life instrument used \n    in the clinical and economic evaluation of health care. Developed by the \n    EuroQol group <https://euroqol.org/>, the instrument consists of two \n    components: health state description and evaluation. For the description \n    component a subject self-rates their health in terms of five dimensions; \n    mobility, self-care, usual activities, pain/discomfort, and \n    anxiety/depression using either a three-level (EQ-5D-3L,\n    <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-3l/>) or a five-level\n    (EQ-5D-5L, <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-5l/>) \n    scale. Frequently the scores on these five dimensions are converted to a \n    single utility index using country specific value sets, which can be used\n    in the clinical and economic evaluation of health care as well as in \n    population health surveys. The eq5d package provides methods to calculate \n    index scores from a subject's dimension scores. 32 TTO and 11 VAS EQ-5D-3L\n    value sets including those for countries in Szende et al (2007) \n    <doi:10.1007/1-4020-5511-0> and Szende et al (2014) \n    <doi:10.1007/978-94-007-7596-1>, 48 EQ-5D-5L EQ-VT value sets, the \n    EQ-5D-5L crosswalk value sets developed by van Hout et al. (2012) \n    <doi:10.1016/j.jval.2012.02.008>, the crosswalk value sets for Bermuda, Jordan and \n    Russia and the van Hout (2021) reverse crosswalk value sets. 11 EQ-5D-Y3L \n    value sets are also included as are the NICE 'DSU' age-sex based EQ-5D-3L \n    to EQ-5D-5L and EQ-5D-5L to EQ-5D-3L mappings. Methods are also included \n    for the analysis of EQ-5D profiles, including those from the book \"Methods \n    for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) \n    <doi:10.1007/978-3-030-47622-9>. Additionally a shiny web tool is included \n    to enable the calculation, visualisation and automated statistical analysis \n    of EQ-5D data via a web browser using EQ-5D dimension scores stored in CSV \n    or Excel files. ",
    "version": "0.16.1",
    "maintainer": "Fraser Morton <fraser.morton@glasgow.ac.uk>",
    "author": "Fraser Morton [aut, cre],\n  Jagtar Singh Nijjar [aut]",
    "url": "https://github.com/fragla/eq5d",
    "bug_reports": "https://github.com/fragla/eq5d/issues",
    "repository": "https://cran.r-project.org/package=eq5d",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eq5d Methods for Analysing 'EQ-5D' Data and Calculating 'EQ-5D' Index\nScores EQ-5D is a popular health related quality of life instrument used \n    in the clinical and economic evaluation of health care. Developed by the \n    EuroQol group <https://euroqol.org/>, the instrument consists of two \n    components: health state description and evaluation. For the description \n    component a subject self-rates their health in terms of five dimensions; \n    mobility, self-care, usual activities, pain/discomfort, and \n    anxiety/depression using either a three-level (EQ-5D-3L,\n    <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-3l/>) or a five-level\n    (EQ-5D-5L, <https://euroqol.org/information-and-support/euroqol-instruments/eq-5d-5l/>) \n    scale. Frequently the scores on these five dimensions are converted to a \n    single utility index using country specific value sets, which can be used\n    in the clinical and economic evaluation of health care as well as in \n    population health surveys. The eq5d package provides methods to calculate \n    index scores from a subject's dimension scores. 32 TTO and 11 VAS EQ-5D-3L\n    value sets including those for countries in Szende et al (2007) \n    <doi:10.1007/1-4020-5511-0> and Szende et al (2014) \n    <doi:10.1007/978-94-007-7596-1>, 48 EQ-5D-5L EQ-VT value sets, the \n    EQ-5D-5L crosswalk value sets developed by van Hout et al. (2012) \n    <doi:10.1016/j.jval.2012.02.008>, the crosswalk value sets for Bermuda, Jordan and \n    Russia and the van Hout (2021) reverse crosswalk value sets. 11 EQ-5D-Y3L \n    value sets are also included as are the NICE 'DSU' age-sex based EQ-5D-3L \n    to EQ-5D-5L and EQ-5D-5L to EQ-5D-3L mappings. Methods are also included \n    for the analysis of EQ-5D profiles, including those from the book \"Methods \n    for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) \n    <doi:10.1007/978-3-030-47622-9>. Additionally a shiny web tool is included \n    to enable the calculation, visualisation and automated statistical analysis \n    of EQ-5D data via a web browser using EQ-5D dimension scores stored in CSV \n    or Excel files.   "
  },
  {
    "id": 11879,
    "package_name": "eq5dsuite",
    "title": "Handling and Analysing EQ-5d Data",
    "description": "The EQ-5D is a widely-used standarized instrument for measuring Health Related Quality Of Life (HRQOL), \n    developed by the EuroQol group <https://euroqol.org/>. It assesses five dimensions; mobility, self-care, \n    usual activities, pain/discomfort, and anxiety/depression, using either a three-level (EQ-5D-3L) or five-level (EQ-5D-5L) scale.\n    Scores from these dimensions are commonly converted into a single utility index using country-specific value sets, \n    which are critical in clinical and economic evaluations of healthcare and in population health surveys. \n    The eq5dsuite package enables users to calculate utility index values for the EQ-5D instruments, \n    including crosswalk utilities using the original crosswalk developed by van Hout et al. (2012) <doi:10.1016/j.jval.2012.02.008> \n    (mapping EQ-5D-5L responses to EQ-5D-3L index values), or the recently developed reverse crosswalk \n    by van Hout et al. (2021) <doi:10.1016/j.jval.2021.03.009> (mapping EQ-5D-3L responses\n    to EQ-5D-5L index values). Users are allowed to add and/or remove user-defined value sets. \n    Additionally, the package provides tools to analyze EQ-5D data according to the recommended \n    guidelines outlined in \"Methods for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) <doi:10.1007/978-3-030-47622-9>.",
    "version": "1.0.1",
    "maintainer": "Kim Rand <krand@mathsinhealth.com>",
    "author": "Kim Rand [aut, cre] (ORCID: <https://orcid.org/0000-0001-7692-4099>),\n  Iryna Schlackow [aut] (ORCID: <https://orcid.org/0000-0002-4154-1431>),\n  Anabel Est\u00e9vez-Carrillo [aut] (ORCID:\n    <https://orcid.org/0000-0001-8778-5055>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=eq5dsuite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "eq5dsuite Handling and Analysing EQ-5d Data The EQ-5D is a widely-used standarized instrument for measuring Health Related Quality Of Life (HRQOL), \n    developed by the EuroQol group <https://euroqol.org/>. It assesses five dimensions; mobility, self-care, \n    usual activities, pain/discomfort, and anxiety/depression, using either a three-level (EQ-5D-3L) or five-level (EQ-5D-5L) scale.\n    Scores from these dimensions are commonly converted into a single utility index using country-specific value sets, \n    which are critical in clinical and economic evaluations of healthcare and in population health surveys. \n    The eq5dsuite package enables users to calculate utility index values for the EQ-5D instruments, \n    including crosswalk utilities using the original crosswalk developed by van Hout et al. (2012) <doi:10.1016/j.jval.2012.02.008> \n    (mapping EQ-5D-5L responses to EQ-5D-3L index values), or the recently developed reverse crosswalk \n    by van Hout et al. (2021) <doi:10.1016/j.jval.2021.03.009> (mapping EQ-5D-3L responses\n    to EQ-5D-5L index values). Users are allowed to add and/or remove user-defined value sets. \n    Additionally, the package provides tools to analyze EQ-5D data according to the recommended \n    guidelines outlined in \"Methods for Analyzing and Reporting EQ-5D data\" by Devlin et al. (2020) <doi:10.1007/978-3-030-47622-9>.  "
  },
  {
    "id": 11900,
    "package_name": "ergm",
    "title": "Fit, Simulate and Diagnose Exponential-Family Models for\nNetworks",
    "description": "An integrated set of tools to analyze and simulate networks based on exponential-family random graph models (ERGMs). 'ergm' is a part of the Statnet suite of packages for network analysis. See Hunter, Handcock, Butts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and Krivitsky, Hunter, Morris, and Klumb (2023) <doi:10.18637/jss.v105.i06>.",
    "version": "4.10.1",
    "maintainer": "Pavel N. Krivitsky <pavel@statnet.org>",
    "author": "Mark S. Handcock [aut],\n  David R. Hunter [aut],\n  Carter T. Butts [aut],\n  Steven M. Goodreau [aut],\n  Pavel N. Krivitsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9101-3362>),\n  Martina Morris [aut],\n  Li Wang [ctb],\n  Kirk Li [ctb],\n  Skye Bender-deMoll [ctb],\n  Chad Klumb [ctb],\n  Micha\u0142 Bojanowski [ctb] (ORCID:\n    <https://orcid.org/0000-0001-7503-852X>),\n  Ben Bolker [ctb],\n  Christian Schmid [ctb],\n  Joyce Cheng [ctb],\n  Arya Karami [ctb],\n  Adrien Le Guillou [ctb] (ORCID:\n    <https://orcid.org/0000-0002-4791-418X>)",
    "url": "https://statnet.org",
    "bug_reports": "https://github.com/statnet/ergm/issues",
    "repository": "https://cran.r-project.org/package=ergm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ergm Fit, Simulate and Diagnose Exponential-Family Models for\nNetworks An integrated set of tools to analyze and simulate networks based on exponential-family random graph models (ERGMs). 'ergm' is a part of the Statnet suite of packages for network analysis. See Hunter, Handcock, Butts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and Krivitsky, Hunter, Morris, and Klumb (2023) <doi:10.18637/jss.v105.i06>.  "
  },
  {
    "id": 11903,
    "package_name": "ergm.multi",
    "title": "Fit, Simulate and Diagnose Exponential-Family Models for\nMultiple or Multilayer Networks",
    "description": "A set of extensions for the 'ergm' package to fit multilayer/multiplex/multirelational networks and samples of multiple networks. 'ergm.multi' is a part of the Statnet suite of packages for network analysis. See Krivitsky, Koehly, and Marcum (2020) <doi:10.1007/s11336-020-09720-7> and Krivitsky, Coletti, and Hens (2023) <doi:10.1080/01621459.2023.2242627>.",
    "version": "0.3.0",
    "maintainer": "Pavel N. Krivitsky <pavel@statnet.org>",
    "author": "Pavel N. Krivitsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9101-3362>),\n  Mark S. Handcock [ctb],\n  David R. Hunter [ctb],\n  Chad Klumb [ctb],\n  Pietro Coletti [ctb],\n  Joyce Cheng [ctb]",
    "url": "https://statnet.org",
    "bug_reports": "https://github.com/statnet/ergm.multi/issues",
    "repository": "https://cran.r-project.org/package=ergm.multi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ergm.multi Fit, Simulate and Diagnose Exponential-Family Models for\nMultiple or Multilayer Networks A set of extensions for the 'ergm' package to fit multilayer/multiplex/multirelational networks and samples of multiple networks. 'ergm.multi' is a part of the Statnet suite of packages for network analysis. See Krivitsky, Koehly, and Marcum (2020) <doi:10.1007/s11336-020-09720-7> and Krivitsky, Coletti, and Hens (2023) <doi:10.1080/01621459.2023.2242627>.  "
  },
  {
    "id": 12021,
    "package_name": "exactLTRE",
    "title": "An Exact Method for Life Table Response Experiment (LTRE)\nAnalysis",
    "description": "Life Table Response Experiments (LTREs) are a method of comparative demographic analysis. The purpose is to quantify how the difference or variance in vital rates (stage-specific survival, growth, and fertility) among populations contributes to difference or variance in the population growth rate, \"lambda.\" We provide functions for one-way fixed design and random design LTRE, using either the classical methods that have been in use for several decades, or an fANOVA-based exact method that directly calculates the impact on lambda of changes in matrix elements, for matrix elements and their interactions. The equations and descriptions for the classical methods of LTRE analysis can be found in Caswell (2001, ISBN: 0878930965), and the fANOVA-based exact methods are described in Hernandez et al. (2023) <doi:10.1111/2041-210X.14065>. We also provide some demographic functions, including generation time from Bienvenu and Legendre (2015) <doi:10.1086/681104>. For implementation of exactLTRE where all possible interactions are calculated, we use an operator matrix presented in Poelwijk, Krishna, and Ranganathan (2016) <doi:10.1371/journal.pcbi.1004771>.",
    "version": "0.1.2",
    "maintainer": "Christina Hernandez <christinahernan@gmail.com>",
    "author": "Christina Hernandez [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-7188-8217>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=exactLTRE",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exactLTRE An Exact Method for Life Table Response Experiment (LTRE)\nAnalysis Life Table Response Experiments (LTREs) are a method of comparative demographic analysis. The purpose is to quantify how the difference or variance in vital rates (stage-specific survival, growth, and fertility) among populations contributes to difference or variance in the population growth rate, \"lambda.\" We provide functions for one-way fixed design and random design LTRE, using either the classical methods that have been in use for several decades, or an fANOVA-based exact method that directly calculates the impact on lambda of changes in matrix elements, for matrix elements and their interactions. The equations and descriptions for the classical methods of LTRE analysis can be found in Caswell (2001, ISBN: 0878930965), and the fANOVA-based exact methods are described in Hernandez et al. (2023) <doi:10.1111/2041-210X.14065>. We also provide some demographic functions, including generation time from Bienvenu and Legendre (2015) <doi:10.1086/681104>. For implementation of exactLTRE where all possible interactions are calculated, we use an operator matrix presented in Poelwijk, Krishna, and Ranganathan (2016) <doi:10.1371/journal.pcbi.1004771>.  "
  },
  {
    "id": 12026,
    "package_name": "exametrika",
    "title": "Test Theory Analysis and Biclustering",
    "description": "Implements comprehensive test data engineering methods as described in \n    Shojima (2022, ISBN:978-9811699856). Provides statistical techniques for \n    engineering and processing test data: Classical Test Theory (CTT) with \n    reliability coefficients for continuous ability assessment; Item Response \n    Theory (IRT) including Rasch, 2PL, and 3PL models with item/test information \n    functions; Latent Class Analysis (LCA) for nominal clustering; Latent Rank \n    Analysis (LRA) for ordinal clustering with automatic determination of cluster \n    numbers; Biclustering methods including infinite relational models for \n    simultaneous clustering of examinees and items without predefined cluster \n    numbers; and Bayesian Network Models (BNM) for visualizing inter-item \n    dependencies. Features local dependence analysis through LRA and biclustering, \n    parameter estimation, dimensionality assessment, and network structure \n    visualization for educational, psychological, and social science research.",
    "version": "1.8.0",
    "maintainer": "Koji Kosugi <kosugitti@gmail.com>",
    "author": "Koji Kosugi [aut, cre] (ORCID: <https://orcid.org/0000-0001-5816-0099>)",
    "url": "https://kosugitti.github.io/exametrika/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=exametrika",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "exametrika Test Theory Analysis and Biclustering Implements comprehensive test data engineering methods as described in \n    Shojima (2022, ISBN:978-9811699856). Provides statistical techniques for \n    engineering and processing test data: Classical Test Theory (CTT) with \n    reliability coefficients for continuous ability assessment; Item Response \n    Theory (IRT) including Rasch, 2PL, and 3PL models with item/test information \n    functions; Latent Class Analysis (LCA) for nominal clustering; Latent Rank \n    Analysis (LRA) for ordinal clustering with automatic determination of cluster \n    numbers; Biclustering methods including infinite relational models for \n    simultaneous clustering of examinees and items without predefined cluster \n    numbers; and Bayesian Network Models (BNM) for visualizing inter-item \n    dependencies. Features local dependence analysis through LRA and biclustering, \n    parameter estimation, dimensionality assessment, and network structure \n    visualization for educational, psychological, and social science research.  "
  },
  {
    "id": 12054,
    "package_name": "experimentr",
    "title": "Datasets Used in Social Science Experiments: A Hands-on\nIntroduction",
    "description": "Contains all the datasets that were used in Social Science Experiments: A Hands-On Introduction and in its R Companion. Relevant materials can be found at <https://osf.io/b78je>.",
    "version": "0.1.0",
    "maintainer": "Kerem Tuncer <kt2716@columbia.edu>",
    "author": "Kerem Tuncer [cre],\n  Donald Green Green [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=experimentr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "experimentr Datasets Used in Social Science Experiments: A Hands-on\nIntroduction Contains all the datasets that were used in Social Science Experiments: A Hands-On Introduction and in its R Companion. Relevant materials can be found at <https://osf.io/b78je>.  "
  },
  {
    "id": 12066,
    "package_name": "expss",
    "title": "Tables, Labels and Some Useful Functions from Spreadsheets and\n'SPSS' Statistics",
    "description": "Package computes and displays tables with support for 'SPSS'-style \n        labels, multiple and nested banners, weights, multiple-response variables \n        and significance testing. There are facilities for nice output of tables \n        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods \n        for labelled variables add value labels support to base R functions and to \n        some functions from other packages. Additionally, the package brings \n        popular data transformation functions from 'SPSS' Statistics and 'Excel': \n        'RECODE', 'COUNT', 'COUNTIF', 'VLOOKUP' and etc. \n        These functions are very useful for data processing in marketing research \n        surveys. Package intended to help people to move data \n        processing from 'Excel' and 'SPSS' to R.",
    "version": "0.11.7",
    "maintainer": "Gregory Demin <gdemin@gmail.com>",
    "author": "Gregory Demin [aut, cre],\n  Sebastian Jeworutzki [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2671-5253>),\n  Dan Chaltiel [ctb],\n  John Williams [ctb],\n  Tom Elliott [ctb]",
    "url": "https://gdemin.github.io/expss/",
    "bug_reports": "https://github.com/gdemin/expss/issues",
    "repository": "https://cran.r-project.org/package=expss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "expss Tables, Labels and Some Useful Functions from Spreadsheets and\n'SPSS' Statistics Package computes and displays tables with support for 'SPSS'-style \n        labels, multiple and nested banners, weights, multiple-response variables \n        and significance testing. There are facilities for nice output of tables \n        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods \n        for labelled variables add value labels support to base R functions and to \n        some functions from other packages. Additionally, the package brings \n        popular data transformation functions from 'SPSS' Statistics and 'Excel': \n        'RECODE', 'COUNT', 'COUNTIF', 'VLOOKUP' and etc. \n        These functions are very useful for data processing in marketing research \n        surveys. Package intended to help people to move data \n        processing from 'Excel' and 'SPSS' to R.  "
  },
  {
    "id": 12149,
    "package_name": "facerec",
    "title": "An Interface for Face Recognition",
    "description": "Provides an interface to the 'Kairos' Face Recognition API <https://kairos.com/face-recognition-api>. The API detects faces in images and returns estimates for demographics like gender, ethnicity and age.  ",
    "version": "0.1.0",
    "maintainer": "Carsten Schwemmer <c.schwem2er@gmail.com>",
    "author": "Carsten Schwemmer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9084-946X>)",
    "url": "https://github.com/methodds/facerec",
    "bug_reports": "https://github.com/methodds/facerec/issues",
    "repository": "https://cran.r-project.org/package=facerec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "facerec An Interface for Face Recognition Provides an interface to the 'Kairos' Face Recognition API <https://kairos.com/face-recognition-api>. The API detects faces in images and returns estimates for demographics like gender, ethnicity and age.    "
  },
  {
    "id": 12160,
    "package_name": "factorH",
    "title": "Multifactor Nonparametric Rank-Based ANOVA with Post Hoc Tests",
    "description": "Multifactor nonparametric analysis of variance based on ranks.\n    Builds on the Kruskal-Wallis H test and its 2x2 Scheirer-Ray-Hare\n    extension to handle any factorial designs. Provides effect sizes,\n    Dunn-Bonferroni pairwise-comparison matrices, and simple-effects\n    analyses. Tailored for psychology and the social sciences, with\n    beginner-friendly R syntax and outputs that can be dropped into\n    journal reports. Includes helpers to export tab-separated results and\n    compact tables of descriptive statistics (to APA-style reports).",
    "version": "0.5.0",
    "maintainer": "Tomasz Rak <tomasz.rak@upjp2.edu.pl>",
    "author": "Tomasz Rak [aut, cre],\n  Szymon Wrzesniowski [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=factorH",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "factorH Multifactor Nonparametric Rank-Based ANOVA with Post Hoc Tests Multifactor nonparametric analysis of variance based on ranks.\n    Builds on the Kruskal-Wallis H test and its 2x2 Scheirer-Ray-Hare\n    extension to handle any factorial designs. Provides effect sizes,\n    Dunn-Bonferroni pairwise-comparison matrices, and simple-effects\n    analyses. Tailored for psychology and the social sciences, with\n    beginner-friendly R syntax and outputs that can be dropped into\n    journal reports. Includes helpers to export tab-separated results and\n    compact tables of descriptive statistics (to APA-style reports).  "
  },
  {
    "id": 12203,
    "package_name": "fasstr",
    "title": "Analyze, Summarize, and Visualize Daily Streamflow Data",
    "description": "The Flow Analysis Summary Statistics Tool for R, 'fasstr', provides various functions to tidy and screen daily stream discharge data, calculate and visualize various summary statistics and metrics, and compute annual trending and volume frequency analyses. \n     It features useful function arguments for filtering of and handling dates, customizing data and metrics, and the ability to pull daily data directly from the Water Survey of Canada hydrometric database (<https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>).",
    "version": "0.5.3",
    "maintainer": "Jon Goetz <jon.goetz@gov.bc.ca>",
    "author": "Jon Goetz [aut, cre] (ORCID: <https://orcid.org/0000-0002-4993-1119>),\n  Carl James Schwarz [aut],\n  Sam Albers [ctb] (ORCID: <https://orcid.org/0000-0002-9270-7884>),\n  Robin Pike [ctb],\n  Province of British Columbia [cph]",
    "url": "https://bcgov.github.io/fasstr/, https://github.com/bcgov/fasstr",
    "bug_reports": "https://github.com/bcgov/fasstr/issues",
    "repository": "https://cran.r-project.org/package=fasstr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fasstr Analyze, Summarize, and Visualize Daily Streamflow Data The Flow Analysis Summary Statistics Tool for R, 'fasstr', provides various functions to tidy and screen daily stream discharge data, calculate and visualize various summary statistics and metrics, and compute annual trending and volume frequency analyses. \n     It features useful function arguments for filtering of and handling dates, customizing data and metrics, and the ability to pull daily data directly from the Water Survey of Canada hydrometric database (<https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>).  "
  },
  {
    "id": 12253,
    "package_name": "fastnet",
    "title": "Large-Scale Social Network Analysis",
    "description": "We present an implementation of the algorithms required to simulate\n  large-scale social networks and retrieve their most relevant metrics. Details \n  can be found in the accompanying scientific paper on the Journal \n  of Statistical Software, <doi:10.18637/jss.v096.i07>.",
    "version": "1.0.0",
    "maintainer": "Nazrul Shaikh <networkgroupr@gmail.com>",
    "author": "Nazrul Shaikh [aut, cre],\n  Xu Dong [aut],\n  Luis Castro [aut],\n  Christian Llano [ctb]",
    "url": "",
    "bug_reports": "https://github.com/networkgroupR/fastnet/issues",
    "repository": "https://cran.r-project.org/package=fastnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fastnet Large-Scale Social Network Analysis We present an implementation of the algorithms required to simulate\n  large-scale social networks and retrieve their most relevant metrics. Details \n  can be found in the accompanying scientific paper on the Journal \n  of Statistical Software, <doi:10.18637/jss.v096.i07>.  "
  },
  {
    "id": 12346,
    "package_name": "fence",
    "title": "Using Fence Methods for Model Selection",
    "description": "This method is a new class of model selection strategies, \n    for mixed model selection, which includes linear and generalized linear \n    mixed models. The idea involves a procedure to isolate a subgroup of what \n    are known as correct models (of which the optimal model is a member). This is \n    accomplished by constructing a statistical fence, or barrier, to carefully \n    eliminate incorrect models. Once the fence is constructed, the optimal model is \n    selected from among those within the fence according to a criterion which can \n    be made flexible.\n    References: \n    1. Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. \n    The Annals of Statistics, 36(4): 1669-1692.  \n    <DOI:10.1214/07-AOS517> <https://projecteuclid.org/euclid.aos/1216237296>.\n    2. Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. \n    Statistics and Probability Letters, 79, 625-629.  \n    <DOI:10.1016/j.spl.2008.10.014> <https://www.researchgate.net/publication/23991417_A_simplified_adaptive_fence_procedure>\n    3. Jiang J., Nguyen T., Rao J.S. (2010), Fence Method for Nonparametric Small Area Estimation. \n    Survey Methodology, 36(1), 3-11.  \n    <http://publications.gc.ca/collections/collection_2010/statcan/12-001-X/12-001-x2010001-eng.pdf>.\n    4. Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. \n    Statistics and Its Interface, Volume 4, 403-415.\n    <http://www.intlpress.com/site/pub/files/_fulltext/journals/sii/2011/0004/0003/SII-2011-0004-0003-a014.pdf>.\n    5. Thuan Nguyen & Jiming Jiang (2012), Restricted fence method for covariate selection in longitudinal data analysis. \n    Biostatistics, 13(2), 303-314.  \n    <DOI:10.1093/biostatistics/kxr046> <https://academic.oup.com/biostatistics/article/13/2/303/263903/Restricted-fence-method-for-covariate-selection-in>.\n    6. Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  \n    Statistical Computation and Simulation, 84(3), 644-662.  \n    <DOI:10.1080/00949655.2012.721885> <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3891925/>.\n    7. Jiang, J. (2014), The fence methods, in Advances in Statistics, Hindawi Publishing Corp., Cairo.  \n    <DOI:10.1155/2014/830821>.\n    8. Jiming Jiang and Thuan Nguyen (2015), The Fence Methods, World Scientific, Singapore.  \n    <https://www.abebooks.com/9789814596060/Fence-Methods-Jiming-Jiang-981459606X/plp>.",
    "version": "1.0",
    "maintainer": "Thuan Nguyen <nguythua@ohsu.edu>",
    "author": "Jiming Jiang, Jianyang Zhao, J. Sunil Rao, Thuan Nguyen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fence",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fence Using Fence Methods for Model Selection This method is a new class of model selection strategies, \n    for mixed model selection, which includes linear and generalized linear \n    mixed models. The idea involves a procedure to isolate a subgroup of what \n    are known as correct models (of which the optimal model is a member). This is \n    accomplished by constructing a statistical fence, or barrier, to carefully \n    eliminate incorrect models. Once the fence is constructed, the optimal model is \n    selected from among those within the fence according to a criterion which can \n    be made flexible.\n    References: \n    1. Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. \n    The Annals of Statistics, 36(4): 1669-1692.  \n    <DOI:10.1214/07-AOS517> <https://projecteuclid.org/euclid.aos/1216237296>.\n    2. Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. \n    Statistics and Probability Letters, 79, 625-629.  \n    <DOI:10.1016/j.spl.2008.10.014> <https://www.researchgate.net/publication/23991417_A_simplified_adaptive_fence_procedure>\n    3. Jiang J., Nguyen T., Rao J.S. (2010), Fence Method for Nonparametric Small Area Estimation. \n    Survey Methodology, 36(1), 3-11.  \n    <http://publications.gc.ca/collections/collection_2010/statcan/12-001-X/12-001-x2010001-eng.pdf>.\n    4. Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. \n    Statistics and Its Interface, Volume 4, 403-415.\n    <http://www.intlpress.com/site/pub/files/_fulltext/journals/sii/2011/0004/0003/SII-2011-0004-0003-a014.pdf>.\n    5. Thuan Nguyen & Jiming Jiang (2012), Restricted fence method for covariate selection in longitudinal data analysis. \n    Biostatistics, 13(2), 303-314.  \n    <DOI:10.1093/biostatistics/kxr046> <https://academic.oup.com/biostatistics/article/13/2/303/263903/Restricted-fence-method-for-covariate-selection-in>.\n    6. Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  \n    Statistical Computation and Simulation, 84(3), 644-662.  \n    <DOI:10.1080/00949655.2012.721885> <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3891925/>.\n    7. Jiang, J. (2014), The fence methods, in Advances in Statistics, Hindawi Publishing Corp., Cairo.  \n    <DOI:10.1155/2014/830821>.\n    8. Jiming Jiang and Thuan Nguyen (2015), The Fence Methods, World Scientific, Singapore.  \n    <https://www.abebooks.com/9789814596060/Fence-Methods-Jiming-Jiang-981459606X/plp>.  "
  },
  {
    "id": 12349,
    "package_name": "fertilmodel",
    "title": "Fertility Models",
    "description": "Four fertility models are fitted using non-linear least squares. These are the Hadwiger, the Gamma, the Model1 and Model2, following the terminology of the following paper: Peristera P. and Kostaki A. (2007). \"Modeling fertility in modern populations\". Demographic Research, 16(6): 141--194. <doi:10.4054/DemRes.2007.16.6>. Model based averaging is also supported.",
    "version": "1.4",
    "maintainer": "Michail Tsagris <mtsagris@uoc.gr>",
    "author": "Michail Tsagris [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fertilmodel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fertilmodel Fertility Models Four fertility models are fitted using non-linear least squares. These are the Hadwiger, the Gamma, the Model1 and Model2, following the terminology of the following paper: Peristera P. and Kostaki A. (2007). \"Modeling fertility in modern populations\". Demographic Research, 16(6): 141--194. <doi:10.4054/DemRes.2007.16.6>. Model based averaging is also supported.  "
  },
  {
    "id": 12408,
    "package_name": "findSVI",
    "title": "Calculate Social Vulnerability Index for Communities",
    "description": "Developed by CDC/ATSDR (Centers for Disease Control and Prevention/\n    Agency for Toxic Substances and Disease Registry), \n    Social Vulnerability Index (SVI) serves as a tool to assess the resilience \n    of communities by taking into account socioeconomic and demographic factors. \n    Provided with year(s), region(s) and a geographic level of interest, \n    'findSVI' retrieves required variables from US census data and calculates SVI \n    for communities in the specified area based on CDC/ATSDR SVI documentation. \n    Reference for the calculation methods: Flanagan BE, Gregory EW, Hallisey EJ, \n    Heitgerd JL, Lewis B (2011) <doi:10.2202/1547-7355.1792>.",
    "version": "0.2.0",
    "maintainer": "Heli Xu <xuheli91@gmail.com>",
    "author": "Heli Xu [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9792-2727>),\n  Ran Li [aut] (ORCID: <https://orcid.org/0000-0002-4699-4755>),\n  Usama Bilal [aut] (ORCID: <https://orcid.org/0000-0002-9868-7773>)",
    "url": "https://github.com/heli-xu/findSVI,\nhttps://heli-xu.github.io/findSVI/",
    "bug_reports": "https://github.com/heli-xu/findSVI/issues",
    "repository": "https://cran.r-project.org/package=findSVI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "findSVI Calculate Social Vulnerability Index for Communities Developed by CDC/ATSDR (Centers for Disease Control and Prevention/\n    Agency for Toxic Substances and Disease Registry), \n    Social Vulnerability Index (SVI) serves as a tool to assess the resilience \n    of communities by taking into account socioeconomic and demographic factors. \n    Provided with year(s), region(s) and a geographic level of interest, \n    'findSVI' retrieves required variables from US census data and calculates SVI \n    for communities in the specified area based on CDC/ATSDR SVI documentation. \n    Reference for the calculation methods: Flanagan BE, Gregory EW, Hallisey EJ, \n    Heitgerd JL, Lewis B (2011) <doi:10.2202/1547-7355.1792>.  "
  },
  {
    "id": 12417,
    "package_name": "finnsurveytext",
    "title": "Analyse Open-Ended Survey Responses in Finnish",
    "description": "Annotates Finnish textual survey responses into CoNLL-U format using Finnish treebanks from <https://universaldependencies.org/format.html> using UDPipe as described in Straka and Strakov\u00e1 (2017) <doi:10.18653/v1/K17-3009>. Formatted data is then analysed using single or comparison n-gram plots, wordclouds, summary tables and Concept Network plots. The Concept Network plots use the TextRank algorithm as outlined in Mihalcea, Rada & Tarau, Paul (2004) <https://aclanthology.org/W04-3252/>.",
    "version": "2.1.1",
    "maintainer": "Adeline Clarke <adelinepclarke@gmail.com>",
    "author": "Adeline Clarke [cre, aut],\n  Krista Lagus [aut],\n  Katja Laine [aut],\n  Maria Litova [aut],\n  Matti Nelimarkka [aut],\n  Joni Oksanen [aut],\n  Jaakko Peltonen [aut],\n  Tuukka Oikarinen [aut],\n  Jani-Matti Tirkkonen [aut],\n  Ida Toivanen [aut],\n  Maria Valaste [aut],\n  Shannon Emilia Carson [ctb],\n  Sirpa Lappalainen [ctb],\n  Tuukka Puonti [ctb],\n  Kimmo Vehkalahti [ctb],\n  DARIAH-FI [cph, fnd]",
    "url": "https://dariah-fi-survey-concept-network.github.io/finnsurveytext/,\nhttps://github.com/DARIAH-FI-Survey-Concept-Network/finnsurveytext",
    "bug_reports": "https://github.com/DARIAH-FI-Survey-Concept-Network/finnsurveytext/issues",
    "repository": "https://cran.r-project.org/package=finnsurveytext",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "finnsurveytext Analyse Open-Ended Survey Responses in Finnish Annotates Finnish textual survey responses into CoNLL-U format using Finnish treebanks from <https://universaldependencies.org/format.html> using UDPipe as described in Straka and Strakov\u00e1 (2017) <doi:10.18653/v1/K17-3009>. Formatted data is then analysed using single or comparison n-gram plots, wordclouds, summary tables and Concept Network plots. The Concept Network plots use the TextRank algorithm as outlined in Mihalcea, Rada & Tarau, Paul (2004) <https://aclanthology.org/W04-3252/>.  "
  },
  {
    "id": 12447,
    "package_name": "fitPS",
    "title": "Fit Zeta Distributions to Forensic Data",
    "description": "Fits Zeta distributions (discrete power laws) to data that arises\n    from forensic surveys of clothing on the presence of glass and paint in\n    various populations. The general method is described to some extent in\n    Coulson, S.A., Buckleton, J.S., Gummer, A.B., and Triggs, C.M. (2001) \n    <doi:10.1016/S1355-0306(01)71847-3>, although the implementation differs.",
    "version": "1.0.1",
    "maintainer": "James Curran <j.curran@auckland.ac.nz>",
    "author": "James Curran [aut, cre]",
    "url": "https://github.com/jmcurran/fitPS",
    "bug_reports": "https://github.com/jmcurran/fitPS/issues",
    "repository": "https://cran.r-project.org/package=fitPS",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fitPS Fit Zeta Distributions to Forensic Data Fits Zeta distributions (discrete power laws) to data that arises\n    from forensic surveys of clothing on the presence of glass and paint in\n    various populations. The general method is described to some extent in\n    Coulson, S.A., Buckleton, J.S., Gummer, A.B., and Triggs, C.M. (2001) \n    <doi:10.1016/S1355-0306(01)71847-3>, although the implementation differs.  "
  },
  {
    "id": 12558,
    "package_name": "fmsb",
    "title": "Functions for Medical Statistics Book with some Demographic Data",
    "description": "Several utility functions for the book entitled \n\t\"Practices of Medical and Health Data Analysis using R\"\n\t(Pearson Education Japan, 2007) with Japanese demographic\n\tdata and some demographic analysis related functions.",
    "version": "0.7.6",
    "maintainer": "Minato Nakazawa <minatonakazawa@gmail.com>",
    "author": "Minato Nakazawa <minatonakazawa@gmail.com>",
    "url": "https://minato.sip21c.org/msb/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=fmsb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fmsb Functions for Medical Statistics Book with some Demographic Data Several utility functions for the book entitled \n\t\"Practices of Medical and Health Data Analysis using R\"\n\t(Pearson Education Japan, 2007) with Japanese demographic\n\tdata and some demographic analysis related functions.  "
  },
  {
    "id": 12632,
    "package_name": "forwards",
    "title": "Data from Surveys Conducted by Forwards",
    "description": "Anonymized data from surveys conducted by Forwards <https://forwards.github.io/>, the R Foundation task force on women and other under-represented groups. Currently, a single data set of responses to a survey of attendees at useR! 2016 <https://www.r-project.org/useR-2016/>, the R user conference held at Stanford University, Stanford, California, USA, June 27 - June 30 2016.",
    "version": "0.1.3",
    "maintainer": "Heather Turner <ht@heatherturner.net>",
    "author": "Heather Turner [aut, cre],\n  Oliver Keyes [aut]",
    "url": "https://github.com/forwards/forwards",
    "bug_reports": "https://github.com/forwards/forwards/issues",
    "repository": "https://cran.r-project.org/package=forwards",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "forwards Data from Surveys Conducted by Forwards Anonymized data from surveys conducted by Forwards <https://forwards.github.io/>, the R Foundation task force on women and other under-represented groups. Currently, a single data set of responses to a survey of attendees at useR! 2016 <https://www.r-project.org/useR-2016/>, the R user conference held at Stanford University, Stanford, California, USA, June 27 - June 30 2016.  "
  },
  {
    "id": 12634,
    "package_name": "fossilbrush",
    "title": "Automated Cleaning of Fossil Occurrence Data",
    "description": "Functions to automate the detection and resolution of taxonomic and stratigraphic errors in fossil occurrence datasets. Functions were developed using data from the Paleobiology Database.",
    "version": "1.0.6",
    "maintainer": "Joe Flannery-Sutherland <josephflannerysutherland@gmail.com>",
    "author": "Joe Flannery-Sutherland [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8232-6773>),\n  Nussa\u00efbah Raja-Schoob [aut, ctb],\n  \u00c1dam Kocsis [aut, ctb],\n  Wolfgang Kiessling [aut]",
    "url": "https://cran.r-project.org/package=fossilbrush",
    "bug_reports": "https://cran.r-project.org/package=fossilbrush",
    "repository": "https://cran.r-project.org/package=fossilbrush",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "fossilbrush Automated Cleaning of Fossil Occurrence Data Functions to automate the detection and resolution of taxonomic and stratigraphic errors in fossil occurrence datasets. Functions were developed using data from the Paleobiology Database.  "
  },
  {
    "id": 12708,
    "package_name": "friends",
    "title": "The Entire Transcript from Friends in Tidy Format",
    "description": "The complete scripts from the American sitcom Friends in tibble \n    format. Use this package to practice data wrangling, text analysis and \n    network analysis.",
    "version": "0.1.0",
    "maintainer": "Emil Hvitfeldt <emilhhvitfeldt@gmail.com>",
    "author": "Emil Hvitfeldt [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0679-1945>)",
    "url": "https://github.com/EmilHvitfeldt/friends",
    "bug_reports": "https://github.com/EmilHvitfeldt/friends/issues",
    "repository": "https://cran.r-project.org/package=friends",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "friends The Entire Transcript from Friends in Tidy Format The complete scripts from the American sitcom Friends in tibble \n    format. Use this package to practice data wrangling, text analysis and \n    network analysis.  "
  },
  {
    "id": 12767,
    "package_name": "funmediation",
    "title": "Functional Mediation for a Distal Outcome",
    "description": "Fits a functional mediation model with a scalar distal outcome. The method is described in detail by Coffman, Dziak, Litson, Chakraborti, Piper & Li (2021) <arXiv:2112.03960>. The model is similar to that of Lindquist (2012) <doi:10.1080/01621459.2012.695640> although allowing a binary outcome as an alternative to a numerical outcome.  The current version is a minor bug fix in the vignette. The development of this package was part of a research project supported by National Institutes of Health grants P50 DA039838 from the National Institute of Drug Abuse and 1R01 CA229542-01 from the National Cancer Institute and the NIH Office of Behavioral and Social Science Research. Content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions mentioned above. This software is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.",
    "version": "1.0.2",
    "maintainer": "John J. Dziak <dziakj1@gmail.com>",
    "author": "John J. Dziak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0762-5495>),\n  Donna L. Coffman [aut] (ORCID: <https://orcid.org/0000-0001-6305-6579>),\n  Kaylee Litson [aut],\n  Yajnaseni Chakraborti [aut],\n  Runze Li [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=funmediation",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "funmediation Functional Mediation for a Distal Outcome Fits a functional mediation model with a scalar distal outcome. The method is described in detail by Coffman, Dziak, Litson, Chakraborti, Piper & Li (2021) <arXiv:2112.03960>. The model is similar to that of Lindquist (2012) <doi:10.1080/01621459.2012.695640> although allowing a binary outcome as an alternative to a numerical outcome.  The current version is a minor bug fix in the vignette. The development of this package was part of a research project supported by National Institutes of Health grants P50 DA039838 from the National Institute of Drug Abuse and 1R01 CA229542-01 from the National Cancer Institute and the NIH Office of Behavioral and Social Science Research. Content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions mentioned above. This software is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.  "
  },
  {
    "id": 12893,
    "package_name": "gapclosing",
    "title": "Estimate Gaps Under an Intervention",
    "description": "Provides functions to estimate the disparities across categories (e.g. Black and white) that persists if a treatment variable (e.g. college) is equalized. Makes estimates by treatment modeling, outcome modeling, and doubly-robust augmented inverse probability weighting estimation, with standard errors calculated by a nonparametric bootstrap. Cross-fitting is supported. Survey weights are supported for point estimation but not for standard error estimation; those applying this package with complex survey samples should consult the data distributor to select an appropriate approach for standard error construction, which may involve calling the functions repeatedly for many sets of replicate weights provided by the data distributor. The methods in this package are described in Lundberg (2021) <doi:10.31235/osf.io/gx4y3>.",
    "version": "1.0.2",
    "maintainer": "Ian Lundberg <ianlundberg@ucla.edu>",
    "author": "Ian Lundberg [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1909-2270>)",
    "url": "https://ilundberg.github.io/gapclosing/",
    "bug_reports": "https://github.com/ilundberg/gapclosing/issues",
    "repository": "https://cran.r-project.org/package=gapclosing",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gapclosing Estimate Gaps Under an Intervention Provides functions to estimate the disparities across categories (e.g. Black and white) that persists if a treatment variable (e.g. college) is equalized. Makes estimates by treatment modeling, outcome modeling, and doubly-robust augmented inverse probability weighting estimation, with standard errors calculated by a nonparametric bootstrap. Cross-fitting is supported. Survey weights are supported for point estimation but not for standard error estimation; those applying this package with complex survey samples should consult the data distributor to select an appropriate approach for standard error construction, which may involve calling the functions repeatedly for many sets of replicate weights provided by the data distributor. The methods in this package are described in Lundberg (2021) <doi:10.31235/osf.io/gx4y3>.  "
  },
  {
    "id": 12904,
    "package_name": "gastempt",
    "title": "Analyzing Gastric Emptying from MRI or Scintigraphy",
    "description": "Fits gastric emptying time series from MRI or 'scintigraphic' measurements\n   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with \n   Stan; computes derived parameters such as t50 and AUC.",
    "version": "0.7.0",
    "maintainer": "Dieter Menne <dieter.menne@menne-biomed.de>",
    "author": "Dieter Menne [aut, cre]",
    "url": "https://github.com/dmenne/gastempt,\nhttp://dmenne.github.io/gastempt/",
    "bug_reports": "https://github.com/dmenne/gastempt/issues",
    "repository": "https://cran.r-project.org/package=gastempt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gastempt Analyzing Gastric Emptying from MRI or Scintigraphy Fits gastric emptying time series from MRI or 'scintigraphic' measurements\n   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with \n   Stan; computes derived parameters such as t50 and AUC.  "
  },
  {
    "id": 12998,
    "package_name": "genderBR",
    "title": "Predict Gender from Brazilian First Names",
    "description": "A method to predict and report gender from Brazilian first names\n    using the Brazilian Institute of Geography and Statistics' Census data (<https://censo2010.ibge.gov.br/nomes/>).",
    "version": "1.1.2",
    "maintainer": "Fernando Meireles <fmeireles@ufmg.br>",
    "author": "Fernando Meireles [aut, cre]",
    "url": "https://github.com/meirelesff/genderBR",
    "bug_reports": "https://github.com/meirelesff/genderBR/issues",
    "repository": "https://cran.r-project.org/package=genderBR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "genderBR Predict Gender from Brazilian First Names A method to predict and report gender from Brazilian first names\n    using the Brazilian Institute of Geography and Statistics' Census data (<https://censo2010.ibge.gov.br/nomes/>).  "
  },
  {
    "id": 13042,
    "package_name": "geoAr",
    "title": "Argentina's Spatial Data Toolbox",
    "description": "Collection of tools that facilitates data access and workflow for spatial analysis of Argentina. Includes historical information from censuses, administrative limits at different levels of aggregation, location of human settlements, among others. Since it is expected that the majority of users will be Spanish-speaking, the documentation of the package prioritizes this language, although an effort is made to also offer annotations in English. ",
    "version": "1.0.0",
    "maintainer": "Juan Pablo Ruiz Nicolini <juanpabloruiznicolini@gmail.com>",
    "author": "Juan Pablo Ruiz Nicolini [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-3138-6343>),\n  Patricio Del Boca [aut],\n  Juan Gabriel Juara [aut]",
    "url": "https://github.com/PoliticaArgentina/geoAr",
    "bug_reports": "https://github.com/PoliticaArgentina/geoAr/issues",
    "repository": "https://cran.r-project.org/package=geoAr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geoAr Argentina's Spatial Data Toolbox Collection of tools that facilitates data access and workflow for spatial analysis of Argentina. Includes historical information from censuses, administrative limits at different levels of aggregation, location of human settlements, among others. Since it is expected that the majority of users will be Spanish-speaking, the documentation of the package prioritizes this language, although an effort is made to also offer annotations in English.   "
  },
  {
    "id": 13067,
    "package_name": "geogenr",
    "title": "Generator from American Community Survey Geodatabases",
    "description": "The American Community Survey (ACS)\n    <https://www.census.gov/programs-surveys/acs> offers geodatabases with\n    geographic information and associated data of interest to researchers\n    in the area. The goal of this package is to generate objects that\n    allow us to access and consult the information available in various\n    formats, such as in 'GeoPackage' format or in multidimensional 'ROLAP'\n    (Relational On-Line Analytical Processing) star format.",
    "version": "2.0.1",
    "maintainer": "Jose Samos <jsamos@ugr.es>",
    "author": "Jose Samos [aut, cre] (ORCID: <https://orcid.org/0000-0002-4457-3439>),\n  Universidad de Granada [cph]",
    "url": "https://josesamos.github.io/geogenr/,\nhttps://github.com/josesamos/geogenr",
    "bug_reports": "https://github.com/josesamos/geogenr/issues",
    "repository": "https://cran.r-project.org/package=geogenr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geogenr Generator from American Community Survey Geodatabases The American Community Survey (ACS)\n    <https://www.census.gov/programs-surveys/acs> offers geodatabases with\n    geographic information and associated data of interest to researchers\n    in the area. The goal of this package is to generate objects that\n    allow us to access and consult the information available in various\n    formats, such as in 'GeoPackage' format or in multidimensional 'ROLAP'\n    (Relational On-Line Analytical Processing) star format.  "
  },
  {
    "id": 13069,
    "package_name": "geohabnet",
    "title": "Geographical Risk Analysis Based on Habitat Connectivity",
    "description": "\n    The 'geohabnet' package is designed to perform a geographically or spatially explicit risk analysis of habitat connectivity. Xing et al (2021) <doi:10.1093/biosci/biaa067> proposed the concept of cropland connectivity as a risk factor for plant pathogen or pest invasions. As the functions in 'geohabnet' were initially developed thinking on cropland connectivity, users are recommended to first be familiar with the concept by looking at the Xing et al paper. In a nutshell, a habitat connectivity analysis combines information from maps of host density, estimates the relative likelihood of pathogen movement between habitat locations in the area of interest, and applies network analysis to calculate the connectivity of habitat locations.\n    The functions of 'geohabnet' are built to conduct a habitat connectivity analysis relying on geographic parameters (spatial resolution and spatial extent), dispersal parameters (in two commonly used dispersal kernels: inverse power law and negative exponential models), and network parameters (link weight thresholds and network metrics).\n    The functionality and main extensions provided by the functions in 'geohabnet' to habitat connectivity analysis are \n    a) Capability to easily calculate the connectivity of locations in a landscape using a single function, such as sensitivity_analysis() or msean().\n    b) As backbone datasets, the 'geohabnet' package supports the use of two publicly available global datasets to calculate cropland density. The backbone datasets in the 'geohabnet' package include crop distribution maps from Monfreda, C., N. Ramankutty, and J. A. Foley (2008) <doi:10.1029/2007gb002947> \"Farming the planet: 2. Geographic distribution of crop areas, yields, physiological types, and net primary production in the year 2000, Global Biogeochem. Cycles, 22, GB1022\" and International Food Policy Research Institute (2019) <doi:10.7910/DVN/PRFF8V> \"Global Spatially-Disaggregated Crop Production Statistics Data for 2010 Version 2.0, Harvard Dataverse, V4\". Users can also provide any other geographic dataset that represents host density.\n    c) Because the 'geohabnet' package allows R users to provide maps of host density (as originally in Xing et al (2021)), host landscape density (representing the geographic distribution of either crops or wild species), or habitat distribution (such as host landscape density adjusted by climate suitability) as inputs, we propose the term habitat connectivity.\n    d) The 'geohabnet' package allows R users to customize parameter values in the habitat connectivity analysis, facilitating context-specific (pathogen- or pest-specific) analyses.\n    e) The 'geohabnet' package allows users to automatically visualize maps of the habitat connectivity of locations resulting from a sensitivity analysis across all customized parameter combinations.\n    The primary functions are msean() and sensitivity analysis().\n    Most functions in 'geohabnet' provide three main outcomes: i) A map of mean habitat connectivity across parameters selected by the user, ii) a map of variance of habitat connectivity across the selected parameters, and iii) a map of the difference between the ranks of habitat connectivity and habitat density.\n    Each function can be used to generate these maps as 'final' outcomes. \n    Each function can also provide intermediate outcomes, such as the adjacency matrices built to perform the analysis, which can be used in other network analysis.\n    Refer to article at <https://garrettlab.github.io/HabitatConnectivity/articles/analysis.html> to see examples of each function and how to access each of these outcome types.\n    To change parameter values, the file called 'parameters.yaml' stores the parameters and their values, can be accessed using 'get_parameters()' and set new parameter values with 'set_parameters()'.\n    Users can modify up to ten parameters.",
    "version": "2.2",
    "maintainer": "Krishna Keshav <krishnakeshav.pes@gmail.com>",
    "author": "Krishna Keshav [aut, cre],\n  Aaron Plex [aut] (ORCID: <https://orcid.org/0000-0001-7317-3090>),\n  Garrett Lab [ctb] (https://garrettlab.com),\n  Karen Garrett [aut] (ORCID: <https://orcid.org/0000-0002-6578-1616>),\n  University of Florida [cph, fnd] (https://www.ufl.edu)",
    "url": "https://garrettlab.github.io/HabitatConnectivity/,\nhttps://CRAN.R-project.org/package=geohabnet/,\nhttps://github.com/GarrettLab/HabitatConnectivity/tree/main/geohabnet/,\nhttps://www.garrettlab.com/",
    "bug_reports": "https://github.com/GarrettLab/HabitatConnectivity/issues",
    "repository": "https://cran.r-project.org/package=geohabnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geohabnet Geographical Risk Analysis Based on Habitat Connectivity \n    The 'geohabnet' package is designed to perform a geographically or spatially explicit risk analysis of habitat connectivity. Xing et al (2021) <doi:10.1093/biosci/biaa067> proposed the concept of cropland connectivity as a risk factor for plant pathogen or pest invasions. As the functions in 'geohabnet' were initially developed thinking on cropland connectivity, users are recommended to first be familiar with the concept by looking at the Xing et al paper. In a nutshell, a habitat connectivity analysis combines information from maps of host density, estimates the relative likelihood of pathogen movement between habitat locations in the area of interest, and applies network analysis to calculate the connectivity of habitat locations.\n    The functions of 'geohabnet' are built to conduct a habitat connectivity analysis relying on geographic parameters (spatial resolution and spatial extent), dispersal parameters (in two commonly used dispersal kernels: inverse power law and negative exponential models), and network parameters (link weight thresholds and network metrics).\n    The functionality and main extensions provided by the functions in 'geohabnet' to habitat connectivity analysis are \n    a) Capability to easily calculate the connectivity of locations in a landscape using a single function, such as sensitivity_analysis() or msean().\n    b) As backbone datasets, the 'geohabnet' package supports the use of two publicly available global datasets to calculate cropland density. The backbone datasets in the 'geohabnet' package include crop distribution maps from Monfreda, C., N. Ramankutty, and J. A. Foley (2008) <doi:10.1029/2007gb002947> \"Farming the planet: 2. Geographic distribution of crop areas, yields, physiological types, and net primary production in the year 2000, Global Biogeochem. Cycles, 22, GB1022\" and International Food Policy Research Institute (2019) <doi:10.7910/DVN/PRFF8V> \"Global Spatially-Disaggregated Crop Production Statistics Data for 2010 Version 2.0, Harvard Dataverse, V4\". Users can also provide any other geographic dataset that represents host density.\n    c) Because the 'geohabnet' package allows R users to provide maps of host density (as originally in Xing et al (2021)), host landscape density (representing the geographic distribution of either crops or wild species), or habitat distribution (such as host landscape density adjusted by climate suitability) as inputs, we propose the term habitat connectivity.\n    d) The 'geohabnet' package allows R users to customize parameter values in the habitat connectivity analysis, facilitating context-specific (pathogen- or pest-specific) analyses.\n    e) The 'geohabnet' package allows users to automatically visualize maps of the habitat connectivity of locations resulting from a sensitivity analysis across all customized parameter combinations.\n    The primary functions are msean() and sensitivity analysis().\n    Most functions in 'geohabnet' provide three main outcomes: i) A map of mean habitat connectivity across parameters selected by the user, ii) a map of variance of habitat connectivity across the selected parameters, and iii) a map of the difference between the ranks of habitat connectivity and habitat density.\n    Each function can be used to generate these maps as 'final' outcomes. \n    Each function can also provide intermediate outcomes, such as the adjacency matrices built to perform the analysis, which can be used in other network analysis.\n    Refer to article at <https://garrettlab.github.io/HabitatConnectivity/articles/analysis.html> to see examples of each function and how to access each of these outcome types.\n    To change parameter values, the file called 'parameters.yaml' stores the parameters and their values, can be accessed using 'get_parameters()' and set new parameter values with 'set_parameters()'.\n    Users can modify up to ten parameters.  "
  },
  {
    "id": 13090,
    "package_name": "georefdatar",
    "title": "Geosciences Reference Datasets",
    "description": "Reference datasets commonly used in the geosciences. These include \n  standard atomic weights of the elements, a periodic table, a list of minerals \n  including their abbreviations and chemistry, geochemical data of reservoirs \n  (primitive mantle, continental crust, mantle, basalts, etc.), decay constants \n  and isotopic ratios frequently used in geochronology, color codes of the \n  chronostratigraphic chart. In addition, the package provides functions for \n  basic queries of atomic weights, the list of minerals, and chronostratigraphic\n  chart colors. All datasets are fully referenced, and a BibTeX file containing \n  the references is included.",
    "version": "0.6.5",
    "maintainer": "Gerald Schuberth-Hlava\u010d <abuseki@synapticgap.com>",
    "author": "Gerald Schuberth-Hlava\u010d [aut, cre]",
    "url": "https://github.com/abuseki/georefdatar",
    "bug_reports": "https://github.com/abuseki/georefdatar/issues",
    "repository": "https://cran.r-project.org/package=georefdatar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "georefdatar Geosciences Reference Datasets Reference datasets commonly used in the geosciences. These include \n  standard atomic weights of the elements, a periodic table, a list of minerals \n  including their abbreviations and chemistry, geochemical data of reservoirs \n  (primitive mantle, continental crust, mantle, basalts, etc.), decay constants \n  and isotopic ratios frequently used in geochronology, color codes of the \n  chronostratigraphic chart. In addition, the package provides functions for \n  basic queries of atomic weights, the list of minerals, and chronostratigraphic\n  chart colors. All datasets are fully referenced, and a BibTeX file containing \n  the references is included.  "
  },
  {
    "id": 13100,
    "package_name": "geostan",
    "title": "Bayesian Spatial Analysis",
    "description": "For spatial data analysis; provides exploratory spatial analysis tools, spatial regression, spatial econometric, and disease mapping models, model diagnostics, and special methods for inference with small area survey data (e.g., the America Community Survey (ACS)) and censored population health monitoring data. Models are pre-specified using the Stan programming language, a platform for Bayesian inference using Markov chain Monte Carlo (MCMC). References: Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>; Donegan (2021) <doi:10.31219/osf.io/3ey65>; Donegan (2022) <doi:10.21105/joss.04716>; Donegan, Chun and Hughes (2020) <doi:10.1016/j.spasta.2020.100450>; Donegan, Chun and Griffith (2021) <doi:10.3390/ijerph18136856>; Morris et al. (2019) <doi:10.1016/j.sste.2019.100301>.",
    "version": "0.8.2",
    "maintainer": "Connor Donegan <connor.donegan@gmail.com>",
    "author": "Connor Donegan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9698-5443>),\n  Mitzi Morris [ctb],\n  Amy Tims [ctb]",
    "url": "https://connordonegan.github.io/geostan/",
    "bug_reports": "https://github.com/ConnorDonegan/geostan/issues",
    "repository": "https://cran.r-project.org/package=geostan",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "geostan Bayesian Spatial Analysis For spatial data analysis; provides exploratory spatial analysis tools, spatial regression, spatial econometric, and disease mapping models, model diagnostics, and special methods for inference with small area survey data (e.g., the America Community Survey (ACS)) and censored population health monitoring data. Models are pre-specified using the Stan programming language, a platform for Bayesian inference using Markov chain Monte Carlo (MCMC). References: Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>; Donegan (2021) <doi:10.31219/osf.io/3ey65>; Donegan (2022) <doi:10.21105/joss.04716>; Donegan, Chun and Hughes (2020) <doi:10.1016/j.spasta.2020.100450>; Donegan, Chun and Griffith (2021) <doi:10.3390/ijerph18136856>; Morris et al. (2019) <doi:10.1016/j.sste.2019.100301>.  "
  },
  {
    "id": 13111,
    "package_name": "gerda",
    "title": "German Election Database (GERDA)",
    "description": "Provides tools to download comprehensive datasets of local, \n    state, and federal election results in Germany from 1990 to 2025. The package \n    facilitates access to data on turnout, vote shares for major parties, and \n    demographic information across different levels of government (municipal, state, \n    and federal). It offers access to geographically harmonized datasets \n    that account for changes in municipal boundaries over time and incorporate \n    mail-in voting districts. Users can easily retrieve, clean, and standardize \n    German electoral data, making it ready for analysis. Data is sourced from \n    <https://github.com/awiedem/german_election_data>.",
    "version": "0.4.0",
    "maintainer": "Hanno Hilbig <hhilbig@ucdavis.edu>",
    "author": "Hanno Hilbig [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5849-9172>)",
    "url": "https://github.com/hhilbig/gerda,\nhttps://github.com/awiedem/german_election_data",
    "bug_reports": "https://github.com/hhilbig/gerda/issues",
    "repository": "https://cran.r-project.org/package=gerda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gerda German Election Database (GERDA) Provides tools to download comprehensive datasets of local, \n    state, and federal election results in Germany from 1990 to 2025. The package \n    facilitates access to data on turnout, vote shares for major parties, and \n    demographic information across different levels of government (municipal, state, \n    and federal). It offers access to geographically harmonized datasets \n    that account for changes in municipal boundaries over time and incorporate \n    mail-in voting districts. Users can easily retrieve, clean, and standardize \n    German electoral data, making it ready for analysis. Data is sourced from \n    <https://github.com/awiedem/german_election_data>.  "
  },
  {
    "id": 13219,
    "package_name": "gggda",
    "title": "A 'ggplot2' Extension for Geometric Data Analysis",
    "description": "A variety of multivariable data summary statistics and \n    constructions have been proposed, either to generalize univariable analogs \n    or to exploit multivariable properties.\n    Notable among these are the bivariate peelings surveyed by Green \n    (1981, ISBN:978-0-471-28039-2),\n    the bag-and-bolster plots proposed by Rousseeuw &al (1999) \n    <doi:10.1080/00031305.1999.10474494>, and the minimum spanning trees used by\n    Jolliffe (2002) <doi:10.1007/b98835> to represent high-dimensional \n    relationships among data in a low-dimensional plot.\n    Additionally, biplots of singular value--decomposed tabular data, such as\n    from principal components analysis, make use of vectors, calibrated axes,\n    and other representations of variable elements to complement point markers\n    for case elements; see Gabriel (1971) <doi:10.1093/biomet/58.3.453> and\n    Gower & Harding (1988) <doi:10.1093/biomet/75.3.445> for original proposals.\n    Because they treat the abscissa and ordinate as commensurate or the data\n    elements themselves as point masses or unit vectors, these multivariable\n    tools can be thought of as belonging to geometric data analysis; see Podani\n    (2000, ISBN:90-5782-067-6) for techniques and applications and Le Roux &\n    Rouanet (2005) <doi:10.1007/1-4020-2236-0> for foundations. 'gggda' extends\n    Wickham's (2010) <doi:10.1198/jcgs.2009.07098> layered grammar of graphics\n    with statistical transformation (\"stat\") and geometric construction (\"geom\")\n    layers for many of these tools, as well as convenience coordinate systems\n    to emphasize intrinsic geometry of the data.",
    "version": "0.1.1",
    "maintainer": "Jason Cory Brunson <cornelioid@gmail.com>",
    "author": "Jason Cory Brunson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3126-9494>),\n  Emily Paul [ctb],\n  John Gracey [aut]",
    "url": "https://github.com/corybrunson/gggda,\nhttps://corybrunson.github.io/gggda/",
    "bug_reports": "https://github.com/corybrunson/gggda/issues",
    "repository": "https://cran.r-project.org/package=gggda",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gggda A 'ggplot2' Extension for Geometric Data Analysis A variety of multivariable data summary statistics and \n    constructions have been proposed, either to generalize univariable analogs \n    or to exploit multivariable properties.\n    Notable among these are the bivariate peelings surveyed by Green \n    (1981, ISBN:978-0-471-28039-2),\n    the bag-and-bolster plots proposed by Rousseeuw &al (1999) \n    <doi:10.1080/00031305.1999.10474494>, and the minimum spanning trees used by\n    Jolliffe (2002) <doi:10.1007/b98835> to represent high-dimensional \n    relationships among data in a low-dimensional plot.\n    Additionally, biplots of singular value--decomposed tabular data, such as\n    from principal components analysis, make use of vectors, calibrated axes,\n    and other representations of variable elements to complement point markers\n    for case elements; see Gabriel (1971) <doi:10.1093/biomet/58.3.453> and\n    Gower & Harding (1988) <doi:10.1093/biomet/75.3.445> for original proposals.\n    Because they treat the abscissa and ordinate as commensurate or the data\n    elements themselves as point masses or unit vectors, these multivariable\n    tools can be thought of as belonging to geometric data analysis; see Podani\n    (2000, ISBN:90-5782-067-6) for techniques and applications and Le Roux &\n    Rouanet (2005) <doi:10.1007/1-4020-2236-0> for foundations. 'gggda' extends\n    Wickham's (2010) <doi:10.1198/jcgs.2009.07098> layered grammar of graphics\n    with statistical transformation (\"stat\") and geometric construction (\"geom\")\n    layers for many of these tools, as well as convenience coordinate systems\n    to emphasize intrinsic geometry of the data.  "
  },
  {
    "id": 13333,
    "package_name": "ggsurvey",
    "title": "Simplifying 'ggplot2' for Survey Data",
    "description": "Functions for survey data including svydesign objects from the 'survey' package that call 'ggplot2' to make bar charts, histograms, boxplots, and hexplots of survey data.  ",
    "version": "1.0.0",
    "maintainer": "Brittany Alexander <balexanderstatistics@gmail.com>",
    "author": "Brittany Alexander",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ggsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ggsurvey Simplifying 'ggplot2' for Survey Data Functions for survey data including svydesign objects from the 'survey' package that call 'ggplot2' to make bar charts, histograms, boxplots, and hexplots of survey data.    "
  },
  {
    "id": 13416,
    "package_name": "glm.predict",
    "title": "Predicted Values and Discrete Changes for Regression Models",
    "description": "Functions to calculate predicted values and the difference between\n    the two cases with confidence interval for lm() [linear model], glm() [generalized linear model], glm.nb() [negative binomial model],\n\tpolr() [ordinal logistic model], vglm() [generalized ordinal logistic model],\tmultinom() [multinomial model], tobit() [tobit model],\n\tsvyglm() [survey-weighted generalised linear models] and lmer() [linear multilevel models] using Monte Carlo simulations or bootstrap. Reference: Bennet A. Zelner (2009) <doi:10.1002/smj.783>.",
    "version": "4.3-2",
    "maintainer": "Benjamin E. Schlegel <kontakt@benjaminschlegel.ch>",
    "author": "Benjamin E. Schlegel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5789-8996>)",
    "url": "https://github.com/benjaminschlegel/glm.predict/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glm.predict",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glm.predict Predicted Values and Discrete Changes for Regression Models Functions to calculate predicted values and the difference between\n    the two cases with confidence interval for lm() [linear model], glm() [generalized linear model], glm.nb() [negative binomial model],\n\tpolr() [ordinal logistic model], vglm() [generalized ordinal logistic model],\tmultinom() [multinomial model], tobit() [tobit model],\n\tsvyglm() [survey-weighted generalised linear models] and lmer() [linear multilevel models] using Monte Carlo simulations or bootstrap. Reference: Bennet A. Zelner (2009) <doi:10.1002/smj.783>.  "
  },
  {
    "id": 13461,
    "package_name": "glorenz",
    "title": "Transformed and Relative Lorenz Curves for Survey Weighted Data",
    "description": "Functions for constructing Transformed and Relative Lorenz curves with survey sampling weights. Given a variable of interest measured in two groups with scaled survey weights so that their hypothetical populations are of equal size, tlorenz() computes the proportion of members of the group with smaller values (ordered from smallest to largest) needed for their sum to match the sum of the top qth percentile of the group with higher values. rlorenz() shows the fraction of the total value of the group with larger values held by the pth percentile of those in the group with smaller values. Fd() is a survey weighted cumulative distribution function and Eps() is a survey weighted inverse cdf used in rlorenz(). Ramos, Graubard, and Gastwirth (2025) <doi:10.1093/jrsssa/qnaf044>. ",
    "version": "0.1.1",
    "maintainer": "Mark Ramos <mlr6219@psu.edu>",
    "author": "Mark Ramos [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=glorenz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "glorenz Transformed and Relative Lorenz Curves for Survey Weighted Data Functions for constructing Transformed and Relative Lorenz curves with survey sampling weights. Given a variable of interest measured in two groups with scaled survey weights so that their hypothetical populations are of equal size, tlorenz() computes the proportion of members of the group with smaller values (ordered from smallest to largest) needed for their sum to match the sum of the top qth percentile of the group with higher values. rlorenz() shows the fraction of the total value of the group with larger values held by the pth percentile of those in the group with smaller values. Fd() is a survey weighted cumulative distribution function and Eps() is a survey weighted inverse cdf used in rlorenz(). Ramos, Graubard, and Gastwirth (2025) <doi:10.1093/jrsssa/qnaf044>.   "
  },
  {
    "id": 13499,
    "package_name": "gnm",
    "title": "Generalized Nonlinear Models",
    "description": "Functions to specify and fit generalized nonlinear models,\n    including models with multiplicative interaction terms such as the\n    UNIDIFF model from sociology and the AMMI model from crop science, and\n    many others.  Over-parameterized representations of models are used\n    throughout; functions are provided for inference on estimable\n    parameter combinations, as well as standard methods for diagnostics\n    etc.",
    "version": "1.1-5",
    "maintainer": "Heather Turner <ht@heatherturner.net>",
    "author": "Heather Turner [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1256-3375>),\n  David Firth [aut] (ORCID: <https://orcid.org/0000-0003-0302-2312>),\n  Brian Ripley [ctb],\n  Bill Venables [ctb],\n  Douglas M. Bates [ctb],\n  Martin Maechler [ctb] (ORCID: <https://orcid.org/0000-0002-8685-9910>)",
    "url": "https://github.com/hturner/gnm",
    "bug_reports": "https://github.com/hturner/gnm/issues",
    "repository": "https://cran.r-project.org/package=gnm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gnm Generalized Nonlinear Models Functions to specify and fit generalized nonlinear models,\n    including models with multiplicative interaction terms such as the\n    UNIDIFF model from sociology and the AMMI model from crop science, and\n    many others.  Over-parameterized representations of models are used\n    throughout; functions are provided for inference on estimable\n    parameter combinations, as well as standard methods for diagnostics\n    etc.  "
  },
  {
    "id": 13550,
    "package_name": "govStatJPN",
    "title": "functions to get public survey data in Japan",
    "description": "This package purposes to deal with public survey data of\n        Japanese government via their Application Programming Interface\n        (http://statdb.nstac.go.jp/)",
    "version": "0.1",
    "maintainer": "Yuichiro Otani <yuichiro@otani.co>",
    "author": "Yuichiro Otani",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=govStatJPN",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "govStatJPN functions to get public survey data in Japan This package purposes to deal with public survey data of\n        Japanese government via their Application Programming Interface\n        (http://statdb.nstac.go.jp/)  "
  },
  {
    "id": 13589,
    "package_name": "grand",
    "title": "Guidelines for Reporting About Network Data",
    "description": "Interactively applies the Guidelines for Reporting About Network Data (GRAND) to an 'igraph' object, and generates a uniform narrative or tabular description of the object.",
    "version": "0.9.1",
    "maintainer": "Zachary Neal <zpneal@msu.edu>",
    "author": "Zachary Neal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3076-4995>)",
    "url": "https://github.com/zpneal/grand",
    "bug_reports": "https://github.com/zpneal/grand/issues",
    "repository": "https://cran.r-project.org/package=grand",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "grand Guidelines for Reporting About Network Data Interactively applies the Guidelines for Reporting About Network Data (GRAND) to an 'igraph' object, and generates a uniform narrative or tabular description of the object.  "
  },
  {
    "id": 13598,
    "package_name": "graph4lg",
    "title": "Build Graphs for Landscape Genetics Analysis",
    "description": "Build graphs for landscape genetics analysis. This set of \n\tfunctions can be used to import and convert spatial and genetic data \n\tinitially in different formats, import landscape graphs created with \n\t'GRAPHAB' software (Foltete et al., 2012) <doi:10.1016/j.envsoft.2012.07.002>, \n\tmake diagnosis plots of isolation by distance relationships in order to \n\tchoose how to build genetic graphs, create graphs with a large range of \n\tpruning methods, weight their links with several genetic distances, plot \n\tand analyse graphs,\tcompare them with other graphs. It uses functions from \n\tother packages such as 'adegenet' \n\t(Jombart, 2008) <doi:10.1093/bioinformatics/btn129> and 'igraph' (Csardi\n\tet Nepusz, 2006) <https://igraph.org/>. It also implements methods \n\tcommonly used in landscape genetics to create graphs, described by Dyer et \n\tNason (2004) <doi:10.1111/j.1365-294X.2004.02177.x> and Greenbaum et \n\tFefferman (2017) <doi:10.1111/mec.14059>, and to analyse distance data \n\t(van Strien et al., 2015) <doi:10.1038/hdy.2014.62>.",
    "version": "1.8.0",
    "maintainer": "Paul Savary <psavary@protonmail.com>",
    "author": "Paul Savary [aut, cre] (ORCID: <https://orcid.org/0000-0002-2104-9941>),\n  Gilles Vuidel [ctb] (ORCID: <https://orcid.org/0000-0001-6330-6136>),\n  Tyler Rudolph [ctb],\n  Alexandrine Daniel [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=graph4lg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "graph4lg Build Graphs for Landscape Genetics Analysis Build graphs for landscape genetics analysis. This set of \n\tfunctions can be used to import and convert spatial and genetic data \n\tinitially in different formats, import landscape graphs created with \n\t'GRAPHAB' software (Foltete et al., 2012) <doi:10.1016/j.envsoft.2012.07.002>, \n\tmake diagnosis plots of isolation by distance relationships in order to \n\tchoose how to build genetic graphs, create graphs with a large range of \n\tpruning methods, weight their links with several genetic distances, plot \n\tand analyse graphs,\tcompare them with other graphs. It uses functions from \n\tother packages such as 'adegenet' \n\t(Jombart, 2008) <doi:10.1093/bioinformatics/btn129> and 'igraph' (Csardi\n\tet Nepusz, 2006) <https://igraph.org/>. It also implements methods \n\tcommonly used in landscape genetics to create graphs, described by Dyer et \n\tNason (2004) <doi:10.1111/j.1365-294X.2004.02177.x> and Greenbaum et \n\tFefferman (2017) <doi:10.1111/mec.14059>, and to analyse distance data \n\t(van Strien et al., 2015) <doi:10.1038/hdy.2014.62>.  "
  },
  {
    "id": 13607,
    "package_name": "graphlayouts",
    "title": "Additional Layout Algorithms for Network Visualizations",
    "description": "Several new layout algorithms to visualize networks are provided which are not part of 'igraph'. \n    Most are based on the concept of stress majorization by Gansner et al. (2004) <doi:10.1007/978-3-540-31843-9_25>. \n    Some more specific algorithms allow the user to emphasize hidden group structures in networks or focus on specific nodes.",
    "version": "1.2.2",
    "maintainer": "David Schoch <david@schochastics.net>",
    "author": "David Schoch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://github.com/schochastics/graphlayouts,\nhttps://schochastics.github.io/graphlayouts/",
    "bug_reports": "https://github.com/schochastics/graphlayouts/issues",
    "repository": "https://cran.r-project.org/package=graphlayouts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "graphlayouts Additional Layout Algorithms for Network Visualizations Several new layout algorithms to visualize networks are provided which are not part of 'igraph'. \n    Most are based on the concept of stress majorization by Gansner et al. (2004) <doi:10.1007/978-3-540-31843-9_25>. \n    Some more specific algorithms allow the user to emphasize hidden group structures in networks or focus on specific nodes.  "
  },
  {
    "id": 13611,
    "package_name": "graphsim",
    "title": "Simulate Expression Data from 'igraph' Networks",
    "description": "Functions to develop simulated continuous data (e.g., gene expression) from a sigma covariance matrix derived from a graph structure in 'igraph' objects. Intended to extend 'mvtnorm' to take 'igraph'  structures rather than sigma matrices as input. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. Here we present a versatile statistical framework to simulate  correlated gene expression data from biological pathways, by sampling from a multivariate normal distribution derived from a graph structure. This package allows the simulation of biological pathways from a graph structure based on a statistical model of gene expression. For example methods to infer biological pathways and gene regulatory networks from gene expression data can be tested on simulated datasets using this framework. This also allows for pathway structures to be considered as a confounding variable when simulating gene expression data to test the performance of genomic analyses.",
    "version": "1.0.4",
    "maintainer": "S. Thomas Kelly <tomkellygenetics@gmail.com>",
    "author": "S. Thomas Kelly [aut, cre],\n  Michael A. Black [aut, ths],\n  Robrecht Cannoodt [ctb],\n  Jason Cory Brunson [ctb]",
    "url": "https://github.com/TomKellyGenetics/graphsim/",
    "bug_reports": "https://github.com/TomKellyGenetics/graphsim/issues/",
    "repository": "https://cran.r-project.org/package=graphsim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "graphsim Simulate Expression Data from 'igraph' Networks Functions to develop simulated continuous data (e.g., gene expression) from a sigma covariance matrix derived from a graph structure in 'igraph' objects. Intended to extend 'mvtnorm' to take 'igraph'  structures rather than sigma matrices as input. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. Here we present a versatile statistical framework to simulate  correlated gene expression data from biological pathways, by sampling from a multivariate normal distribution derived from a graph structure. This package allows the simulation of biological pathways from a graph structure based on a statistical model of gene expression. For example methods to infer biological pathways and gene regulatory networks from gene expression data can be tested on simulated datasets using this framework. This also allows for pathway structures to be considered as a confounding variable when simulating gene expression data to test the performance of genomic analyses.  "
  },
  {
    "id": 13633,
    "package_name": "gregRy",
    "title": "GREGORY Estimation",
    "description": "Functions which make using the Generalized Regression Estimator(GREG)\n    J.N.K. Rao, Isabel Molina, (2015) <doi:10.3390/f11020244> \n    and the Generalized Regression Estimator Operating on Resolutions of Y (GREGORY) easier. \n    The functions are designed to work well within a forestry context, and estimate multiple \n    estimation units at once. Compared to other survey estimation packages, this function has greater flexibility when \n    describing the linear model.",
    "version": "0.1.0",
    "maintainer": "Olek Wojcik <olkowaty@gmail.com>",
    "author": "Olek Wojcik [cre, aut],\n  Sam Olson [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=gregRy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gregRy GREGORY Estimation Functions which make using the Generalized Regression Estimator(GREG)\n    J.N.K. Rao, Isabel Molina, (2015) <doi:10.3390/f11020244> \n    and the Generalized Regression Estimator Operating on Resolutions of Y (GREGORY) easier. \n    The functions are designed to work well within a forestry context, and estimate multiple \n    estimation units at once. Compared to other survey estimation packages, this function has greater flexibility when \n    describing the linear model.  "
  },
  {
    "id": 13743,
    "package_name": "guideR",
    "title": "Miscellaneous Statistical Functions Used in 'guide-R'",
    "description": "Companion package for the manual\n  'guide-R : Guide pour l\u2019analyse de donn\u00e9es d\u2019enqu\u00eates avec R' available at\n  <https://larmarange.github.io/guide-R/>. 'guideR' implements miscellaneous\n  functions introduced in 'guide-R' to facilitate statistical analysis and\n  manipulation of survey data.",
    "version": "0.8.0",
    "maintainer": "Joseph Larmarange <joseph@larmarange.net>",
    "author": "Joseph Larmarange [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7097-700X>)",
    "url": "https://larmarange.github.io/guideR/,\nhttps://github.com/larmarange/guideR",
    "bug_reports": "https://github.com/larmarange/guideR/issues",
    "repository": "https://cran.r-project.org/package=guideR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "guideR Miscellaneous Statistical Functions Used in 'guide-R' Companion package for the manual\n  'guide-R : Guide pour l\u2019analyse de donn\u00e9es d\u2019enqu\u00eates avec R' available at\n  <https://larmarange.github.io/guide-R/>. 'guideR' implements miscellaneous\n  functions introduced in 'guide-R' to facilitate statistical analysis and\n  manipulation of survey data.  "
  },
  {
    "id": 13752,
    "package_name": "gustave",
    "title": "A User-Oriented Statistical Toolkit for Analytical Variance\nEstimation",
    "description": "Provides a toolkit for analytical variance estimation in survey sampling. Apart from the implementation of standard variance estimators, its main feature is to help the sampling expert produce easy-to-use variance estimation \"wrappers\", where systematic operations (linearization, domain estimation) are handled in a consistent and transparent way.",
    "version": "1.0.0",
    "maintainer": "Khaled Larbi <khaled.larbi@insee.fr>",
    "author": "Martin Chevalier [aut] (Creator),\n  Khaled Larbi [cre],\n  Institut national de la statistique et des \u00e9tudes \u00e9conomiques [cph]",
    "url": "https://github.com/InseeFr/gustave",
    "bug_reports": "https://github.com/InseeFr/gustave/issues",
    "repository": "https://cran.r-project.org/package=gustave",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "gustave A User-Oriented Statistical Toolkit for Analytical Variance\nEstimation Provides a toolkit for analytical variance estimation in survey sampling. Apart from the implementation of standard variance estimators, its main feature is to help the sampling expert produce easy-to-use variance estimation \"wrappers\", where systematic operations (linearization, domain estimation) are handled in a consistent and transparent way.  "
  },
  {
    "id": 13786,
    "package_name": "hagis",
    "title": "Analysis of Plant Pathogen Pathotype Complexities, Distributions\nand Diversity",
    "description": "Analysis of plant pathogen pathotype survey data.  Functions\n    provided calculate distribution of susceptibilities, distribution of\n    complexities with statistics, pathotype frequency distribution, as\n    well as diversity indices for pathotypes.  This package is meant to be\n    a direct replacement for Herrmann, L\u00f6wer and Schachtel's (1999)\n    <doi:10.1046/j.1365-3059.1999.00325.x> Habgood-Gilmour Spreadsheet,\n    'HaGiS', previously used for pathotype analysis.",
    "version": "4.0.0",
    "maintainer": "Adam H. Sparks <adamhsparks@gmail.com>",
    "author": "Austin G. McCoy [aut, ccp] (ORCID:\n    <https://orcid.org/0000-0003-2483-4184>),\n  Zachary Noel [aut, ccp] (ORCID:\n    <https://orcid.org/0000-0001-6375-8300>),\n  Adam H. Sparks [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0061-8359>),\n  Martin Chilvers [aut, ths] (ORCID:\n    <https://orcid.org/0000-0001-8832-1666>),\n  Jari Oksanen [aut] (Contributed fix for the use of 'vegan' in\n    betadiversity vignette.),\n  Zhian N. Kamvar [ctb, rev] (ORCID:\n    <https://orcid.org/0000-0003-1458-7108>),\n  Michigan Soybean Promotion Committee [fnd, cph],\n  Project GREEEN [fnd, cph],\n  North Central Soybean Research Program [fnd, cph],\n  Grains Research and Development Corporation [fnd, cph] (GRDC Project\n    DAQ00186 and GRDC Project CUR2210-005OPX (AAGI-CU), ROR:\n    <https://ror.org/02xwr1996>),\n  Michigan State University [fnd, cph] (MSU AgBioResearch and MSU\n    Extension, ROR: <https://ror.org/05hs6h993>),\n  University of Southern Queensland [fnd, cph] (ROR:\n    <https://ror.org/04sjbnx57>),\n  Curtin University [fnd, cph] (ROR: <https://ror.org/02n415q13>)",
    "url": "https://github.com/openplantpathology/hagis,\nhttps://openplantpathology.github.io/hagis/",
    "bug_reports": "https://github.com/openplantpathology/hagis/issues",
    "repository": "https://cran.r-project.org/package=hagis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hagis Analysis of Plant Pathogen Pathotype Complexities, Distributions\nand Diversity Analysis of plant pathogen pathotype survey data.  Functions\n    provided calculate distribution of susceptibilities, distribution of\n    complexities with statistics, pathotype frequency distribution, as\n    well as diversity indices for pathotypes.  This package is meant to be\n    a direct replacement for Herrmann, L\u00f6wer and Schachtel's (1999)\n    <doi:10.1046/j.1365-3059.1999.00325.x> Habgood-Gilmour Spreadsheet,\n    'HaGiS', previously used for pathotype analysis.  "
  },
  {
    "id": 13794,
    "package_name": "ham",
    "title": "Healthcare Analysis Methods",
    "description": "Conducts analyses for healthcare program evaluations or intervention \n    studies. Calculates regression analyses for standard ordinary least squares \n    (OLS or linear) or logistic models. Performs regression models used for \n    causal modeling such as differences-in-differences (DID) and interrupted \n    time series (ITS) models. Provides limited interpretations of model \n    results and a ranking of variable importance in models. Performs \n    propensity score models, top-coding of model outcome variables, and \n    can return new data with the newly formed variables. Also performs Cronbach's \n    alpha for various scale items (e.g., survey questions). See Github URL for \n    examples in the README file. For more details on the statistical methods, see \n    Allen & Yen (1979, ISBN:0-8185-0283-5), \n    Angrist & Pischke (2009, ISBN:9780691120355), \n    Harrell (2016, ISBN:978-3-319-19424-0), \n    Kline (1999, ISBN:9780415211581),  \n    Linden (2015) <doi:10.1177/1536867X1501500208>,\n    Merlo (2006) <doi:10.1136/jech.2004.029454>\n    Muthen & Satorra (1995) <doi:10.2307/271070>, and\n    Rabe-Hesketh & Skrondal (2008, ISBN:978-1-59718-040-5).",
    "version": "1.1.0",
    "maintainer": "Stephen Zuniga <rms.shiny@gmail.com>",
    "author": "Stephen Zuniga [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1458-3924>)",
    "url": "https://github.com/szuniga07/ham",
    "bug_reports": "https://github.com/szuniga07/ham/issues",
    "repository": "https://cran.r-project.org/package=ham",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ham Healthcare Analysis Methods Conducts analyses for healthcare program evaluations or intervention \n    studies. Calculates regression analyses for standard ordinary least squares \n    (OLS or linear) or logistic models. Performs regression models used for \n    causal modeling such as differences-in-differences (DID) and interrupted \n    time series (ITS) models. Provides limited interpretations of model \n    results and a ranking of variable importance in models. Performs \n    propensity score models, top-coding of model outcome variables, and \n    can return new data with the newly formed variables. Also performs Cronbach's \n    alpha for various scale items (e.g., survey questions). See Github URL for \n    examples in the README file. For more details on the statistical methods, see \n    Allen & Yen (1979, ISBN:0-8185-0283-5), \n    Angrist & Pischke (2009, ISBN:9780691120355), \n    Harrell (2016, ISBN:978-3-319-19424-0), \n    Kline (1999, ISBN:9780415211581),  \n    Linden (2015) <doi:10.1177/1536867X1501500208>,\n    Merlo (2006) <doi:10.1136/jech.2004.029454>\n    Muthen & Satorra (1995) <doi:10.2307/271070>, and\n    Rabe-Hesketh & Skrondal (2008, ISBN:978-1-59718-040-5).  "
  },
  {
    "id": 13827,
    "package_name": "hbamr",
    "title": "Hierarchical Bayesian Aldrich-McKelvey Scaling via 'Stan'",
    "description": "Perform hierarchical Bayesian Aldrich-McKelvey scaling using Hamiltonian Monte\n    Carlo via 'Stan'. Aldrich-McKelvey ('AM') scaling is a method for estimating the ideological \n    positions of survey respondents and political actors on a common scale using positional survey \n    data. The hierarchical versions of the Bayesian 'AM' model included in this package outperform \n    other versions both in terms of yielding meaningful posterior distributions for respondent \n    positions and in terms of recovering true respondent positions in simulations. The package \n    contains functions for preparing data, fitting models, extracting estimates, plotting key \n    results, and comparing models using cross-validation. The original version of the default \n    model is described in B\u00f8lstad (2024) <doi:10.1017/pan.2023.18>.",
    "version": "2.4.4",
    "maintainer": "J\u00f8rgen B\u00f8lstad <jorgen.bolstad@stv.uio.no>",
    "author": "J\u00f8rgen B\u00f8lstad [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7623-5741>)",
    "url": "https://jbolstad.github.io/hbamr/",
    "bug_reports": "https://github.com/jbolstad/hbamr/issues",
    "repository": "https://cran.r-project.org/package=hbamr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hbamr Hierarchical Bayesian Aldrich-McKelvey Scaling via 'Stan' Perform hierarchical Bayesian Aldrich-McKelvey scaling using Hamiltonian Monte\n    Carlo via 'Stan'. Aldrich-McKelvey ('AM') scaling is a method for estimating the ideological \n    positions of survey respondents and political actors on a common scale using positional survey \n    data. The hierarchical versions of the Bayesian 'AM' model included in this package outperform \n    other versions both in terms of yielding meaningful posterior distributions for respondent \n    positions and in terms of recovering true respondent positions in simulations. The package \n    contains functions for preparing data, fitting models, extracting estimates, plotting key \n    results, and comparing models using cross-validation. The original version of the default \n    model is described in B\u00f8lstad (2024) <doi:10.1017/pan.2023.18>.  "
  },
  {
    "id": 13875,
    "package_name": "healthequal",
    "title": "Compute Summary Measures of Health Inequality",
    "description": "Compute 21 summary measures of health inequality and its\n    corresponding confidence intervals for ordered and non-ordered\n    dimensions using disaggregated data. Measures for ordered dimensions\n    (e.g., Slope Index of Inequality, Absolute Concentration Index) also\n    accept individual and survey data.",
    "version": "1.0.1",
    "maintainer": "Katherine Kirkby <kirkbyk@who.int>",
    "author": "Daniel A. Antiporta [aut] (ORCID:\n    <https://orcid.org/0000-0002-5143-3776>),\n  Patricia Men\u00e9ndez [aut] (ORCID:\n    <https://orcid.org/0000-0003-0701-6315>),\n  Katherine Kirkby [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6881-409X>),\n  Ahmad Hosseinpoor [aut] (ORCID:\n    <https://orcid.org/0000-0001-7322-672X>),\n  World Health Organization [cph]",
    "url": "https://github.com/WHOequity/healthequal,\nhttps://whoequity.github.io/healthequal/",
    "bug_reports": "https://github.com/WHOequity/healthequal/issues",
    "repository": "https://cran.r-project.org/package=healthequal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "healthequal Compute Summary Measures of Health Inequality Compute 21 summary measures of health inequality and its\n    corresponding confidence intervals for ordered and non-ordered\n    dimensions using disaggregated data. Measures for ordered dimensions\n    (e.g., Slope Index of Inequality, Absolute Concentration Index) also\n    accept individual and survey data.  "
  },
  {
    "id": 13900,
    "package_name": "heiscore",
    "title": "Score and Plot the Healthy Eating Index from NHANES Data",
    "description": "Calculate and visualize Healthy Eating Index (HEI) scores\n    from National Health and Nutrition Examination Survey 24-hour dietary\n    recall data utilizing three methods recommended by the National Cancer\n    Institute (2024)\n    <https://epi.grants.cancer.gov/hei/hei-methods-and-calculations.html#:~:text=To%20use%20the%20simple%20HEI,the%20total%20scores%20across%20individuals.>.\n    Effortlessly analyze HEI scores across different demographic groups\n    and years.",
    "version": "0.1.4",
    "maintainer": "Vijetha Ramdas <vramdas06@gmail.com>",
    "author": "Vijetha Ramdas [aut, cre],\n  Berkeley Ho [aut],\n  Abhra Sarkar [aut]",
    "url": "https://github.com/abhrastat/heiscore",
    "bug_reports": "https://github.com/abhrastat/heiscore/issues",
    "repository": "https://cran.r-project.org/package=heiscore",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "heiscore Score and Plot the Healthy Eating Index from NHANES Data Calculate and visualize Healthy Eating Index (HEI) scores\n    from National Health and Nutrition Examination Survey 24-hour dietary\n    recall data utilizing three methods recommended by the National Cancer\n    Institute (2024)\n    <https://epi.grants.cancer.gov/hei/hei-methods-and-calculations.html#:~:text=To%20use%20the%20simple%20HEI,the%20total%20scores%20across%20individuals.>.\n    Effortlessly analyze HEI scores across different demographic groups\n    and years.  "
  },
  {
    "id": 13901,
    "package_name": "heiscore.data",
    "title": "Data Only Package to 'heiscore'",
    "description": "Contains the National Health and Nutrition Examination Survey\n    24-hour dietary recall data and Healthy Eating Index scoring standards\n    used by the 'heiscore' package.",
    "version": "0.0.1",
    "maintainer": "Vijetha Ramdas <vramdas06@gmail.com>",
    "author": "Vijetha Ramdas [aut, cre],\n  Berkeley Ho [aut],\n  Abhra Sarkar [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=heiscore.data",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "heiscore.data Data Only Package to 'heiscore' Contains the National Health and Nutrition Examination Survey\n    24-hour dietary recall data and Healthy Eating Index scoring standards\n    used by the 'heiscore' package.  "
  },
  {
    "id": 13948,
    "package_name": "hhh4contacts",
    "title": "Age-Structured Spatio-Temporal Models for Infectious Disease\nCounts",
    "description": "Meyer and Held (2017) <doi:10.1093/biostatistics/kxw051> present an\n    age-structured spatio-temporal model for infectious disease counts. The\n    approach is illustrated in a case study on norovirus gastroenteritis in\n    Berlin, 2011-2015, by age group, city district and week, using additional\n    contact data from the POLYMOD survey. This package contains the data and\n    code to reproduce the results from the paper, see 'demo(\"hhh4contacts\")'.",
    "version": "0.13.4",
    "maintainer": "Sebastian Meyer <seb.meyer@fau.de>",
    "author": "Sebastian Meyer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1791-9449>),\n  Leonhard Held [ctb, ths] (ORCID:\n    <https://orcid.org/0000-0002-8686-5325>)",
    "url": "https://codeberg.org/EE-hub/hhh4contacts",
    "bug_reports": "https://codeberg.org/EE-hub/hhh4contacts/issues",
    "repository": "https://cran.r-project.org/package=hhh4contacts",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hhh4contacts Age-Structured Spatio-Temporal Models for Infectious Disease\nCounts Meyer and Held (2017) <doi:10.1093/biostatistics/kxw051> present an\n    age-structured spatio-temporal model for infectious disease counts. The\n    approach is illustrated in a case study on norovirus gastroenteritis in\n    Berlin, 2011-2015, by age group, city district and week, using additional\n    contact data from the POLYMOD survey. This package contains the data and\n    code to reproduce the results from the paper, see 'demo(\"hhh4contacts\")'.  "
  },
  {
    "id": 13984,
    "package_name": "hildareadR",
    "title": "Extract Variables from HILDA",
    "description": "Makes it easy to extract and combine variables from the HILDA (Household, Income and Labour Dynamics in Australia) survey maintained by the Melbourne Institute <https://melbourneinstitute.unimelb.edu.au/hilda>.",
    "version": "0.2.0",
    "maintainer": "Sebastian Kalucza <sebastian.kalucza@gmail.com>",
    "author": "Sebastian Kalucza [aut, cre],\n  Sara Kalucza [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hildareadR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hildareadR Extract Variables from HILDA Makes it easy to extract and combine variables from the HILDA (Household, Income and Labour Dynamics in Australia) survey maintained by the Melbourne Institute <https://melbourneinstitute.unimelb.edu.au/hilda>.  "
  },
  {
    "id": 13993,
    "package_name": "hipread",
    "title": "Read Hierarchical Fixed Width Files",
    "description": "Read hierarchical fixed width files like those commonly used by \n    many census data providers. Also allows for reading of data in chunks,\n    and reading 'gzipped' files without storing the full file in memory.",
    "version": "0.2.5",
    "maintainer": "Derek Burk <ipums+cran@umn.edu>",
    "author": "Greg Freedman Ellis [aut],\n  Derek Burk [aut, cre],\n  Joe Grover [ctb],\n  Mark Padgham [ctb],\n  Hadley Wickham [ctb] (Code adapted from readr),\n  Jim Hester [ctb] (Code adapted from readr),\n  Romain Francois [ctb] (Code adapted from readr),\n  R Core Team [ctb] (Code adapted from readr),\n  RStudio [cph, fnd] (Code adapted from readr),\n  Jukka Jyl\u00e4nki [ctb, cph] (Code adapted from readr),\n  Mikkel J\u00f8rgensen [ctb, cph] (Code adapted from readr),\n  University of Minnesota [cph]",
    "url": "https://github.com/ipums/hipread",
    "bug_reports": "https://github.com/ipums/hipread/issues",
    "repository": "https://cran.r-project.org/package=hipread",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hipread Read Hierarchical Fixed Width Files Read hierarchical fixed width files like those commonly used by \n    many census data providers. Also allows for reading of data in chunks,\n    and reading 'gzipped' files without storing the full file in memory.  "
  },
  {
    "id": 14037,
    "package_name": "hopit",
    "title": "Hierarchical Ordered Probit Models with Application to Reporting\nHeterogeneity",
    "description": "Self-reported health, happiness, attitudes, and other statuses or perceptions are often the subject of biases that may come from different sources. For example, the evaluation of an individual\u2019s own health may depend on previous medical diagnoses, functional status, and symptoms and signs of illness; as on well as life-style behaviors, including contextual social, gender, age-specific, linguistic and other cultural factors (Jylha 2009 <doi:10.1016/j.socscimed.2009.05.013>; Oksuzyan et al. 2019 <doi:10.1016/j.socscimed.2019.03.002>). The hopit package offers versatile functions for analyzing different self-reported ordinal variables, and for helping to estimate their biases. Specifically, the package provides the function to fit a generalized ordered probit model that regresses original self-reported status measures on two sets of independent variables (King et al. 2004 <doi:10.1017/S0003055403000881>; Jurges 2007  <doi:10.1002/hec.1134>; Oksuzyan et al. 2019  <doi:10.1016/j.socscimed.2019.03.002>). The first set of variables (e.g., health variables) included in the regression are individual statuses and characteristics that are directly related to the self-reported variable. In the case of self-reported health, these could be chronic conditions, mobility level, difficulties with daily activities, performance on grip strength tests, anthropometric measures, and lifestyle behaviors. The second set of independent variables (threshold variables) is used to model cut-points between adjacent self-reported response categories as functions of individual characteristics, such as gender, age group, education, and country (Oksuzyan et al. 2019 <doi:10.1016/j.socscimed.2019.03.002>). The model helps to adjust for specific socio-demographic and cultural differences in how the continuous latent health is projected onto the ordinal self-rated measure. The fitted model can be used to calculate an individual predicted latent status variable, a latent index, and standardized latent coefficients; and makes it possible to reclassify a categorical status measure that has been adjusted for inter-individual differences in reporting behavior.",
    "version": "0.11.6",
    "maintainer": "Maciej J. Danko <Maciej.Danko@gmail.com>",
    "author": "Maciej J. Danko [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7924-9022>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=hopit",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "hopit Hierarchical Ordered Probit Models with Application to Reporting\nHeterogeneity Self-reported health, happiness, attitudes, and other statuses or perceptions are often the subject of biases that may come from different sources. For example, the evaluation of an individual\u2019s own health may depend on previous medical diagnoses, functional status, and symptoms and signs of illness; as on well as life-style behaviors, including contextual social, gender, age-specific, linguistic and other cultural factors (Jylha 2009 <doi:10.1016/j.socscimed.2009.05.013>; Oksuzyan et al. 2019 <doi:10.1016/j.socscimed.2019.03.002>). The hopit package offers versatile functions for analyzing different self-reported ordinal variables, and for helping to estimate their biases. Specifically, the package provides the function to fit a generalized ordered probit model that regresses original self-reported status measures on two sets of independent variables (King et al. 2004 <doi:10.1017/S0003055403000881>; Jurges 2007  <doi:10.1002/hec.1134>; Oksuzyan et al. 2019  <doi:10.1016/j.socscimed.2019.03.002>). The first set of variables (e.g., health variables) included in the regression are individual statuses and characteristics that are directly related to the self-reported variable. In the case of self-reported health, these could be chronic conditions, mobility level, difficulties with daily activities, performance on grip strength tests, anthropometric measures, and lifestyle behaviors. The second set of independent variables (threshold variables) is used to model cut-points between adjacent self-reported response categories as functions of individual characteristics, such as gender, age group, education, and country (Oksuzyan et al. 2019 <doi:10.1016/j.socscimed.2019.03.002>). The model helps to adjust for specific socio-demographic and cultural differences in how the continuous latent health is projected onto the ordinal self-rated measure. The fitted model can be used to calculate an individual predicted latent status variable, a latent index, and standardized latent coefficients; and makes it possible to reclassify a categorical status measure that has been adjusted for inter-individual differences in reporting behavior.  "
  },
  {
    "id": 14175,
    "package_name": "iDINGO",
    "title": "Integrative Differential Network Analysis in Genomics",
    "description": "Fits covariate dependent partial correlation matrices for integrative models to identify differential networks between two groups. The methods are described in Class et. al., (2018) <doi:10.1093/bioinformatics/btx750> and Ha et. al., (2015) <doi:10.1093/bioinformatics/btv406>.",
    "version": "1.0.4",
    "maintainer": "Caleb A. Class <cclass@butler.edu>",
    "author": "Caleb A. Class <cclass@butler.edu>, Min Jin Ha <mjha@mdanderson.org>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=iDINGO",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iDINGO Integrative Differential Network Analysis in Genomics Fits covariate dependent partial correlation matrices for integrative models to identify differential networks between two groups. The methods are described in Class et. al., (2018) <doi:10.1093/bioinformatics/btx750> and Ha et. al., (2015) <doi:10.1093/bioinformatics/btv406>.  "
  },
  {
    "id": 14181,
    "package_name": "iGraphMatch",
    "title": "Tools for Graph Matching",
    "description": "Versatile tools and data for graph matching analysis with various forms of prior information\n    that supports working with 'igraph' objects, matrix objects, or lists of either.",
    "version": "2.0.5",
    "maintainer": "Daniel Sussman <sussman@bu.edu>",
    "author": "Daniel Sussman [aut, cre],\n  Zihuan Qiao [aut],\n  Joshua Agterberg [ctb],\n  Lujia Wang [ctb],\n  Vince Lyzinski [ctb]",
    "url": "https://github.com/dpmcsuss/iGraphMatch,\nhttps://dpmcsuss.github.io/iGraphMatch/",
    "bug_reports": "https://github.com/dpmcsuss/iGraphMatch/issues",
    "repository": "https://cran.r-project.org/package=iGraphMatch",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "iGraphMatch Tools for Graph Matching Versatile tools and data for graph matching analysis with various forms of prior information\n    that supports working with 'igraph' objects, matrix objects, or lists of either.  "
  },
  {
    "id": 14224,
    "package_name": "ibmcraftr",
    "title": "Toolkits to Develop Individual-Based Models in Infectious\nDisease",
    "description": "It provides a generic set of tools for initializing a synthetic\n         population with each individual in specific disease states, and\n         making transitions between those disease states according to the rates\n         calculated on each timestep. The new version 1.0.0 has C++ code \n         integration to make the functions run faster. It has also a higher level\n         function to actually run the transitions for the number of timesteps\n         that users specify. Additional functions will follow for changing\n         attributes on demographic, health belief and movement.",
    "version": "1.0.0",
    "maintainer": "Sai Thein Than Tun <theinthantun.sai@gmail.com>",
    "author": "Sai Thein Than Tun [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ibmcraftr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ibmcraftr Toolkits to Develop Individual-Based Models in Infectious\nDisease It provides a generic set of tools for initializing a synthetic\n         population with each individual in specific disease states, and\n         making transitions between those disease states according to the rates\n         calculated on each timestep. The new version 1.0.0 has C++ code \n         integration to make the functions run faster. It has also a higher level\n         function to actually run the transitions for the number of timesteps\n         that users specify. Additional functions will follow for changing\n         attributes on demographic, health belief and movement.  "
  },
  {
    "id": 14234,
    "package_name": "icarus",
    "title": "Calibrates and Reweights Units in Samples",
    "description": "Provides user-friendly tools for calibration in survey sampling.\n    The package is production-oriented, and its interface is inspired by the famous\n    popular macro 'Calmar' for SAS, so that 'Calmar' users can quickly get used to\n    'icarus'. In addition to calibration (with linear, raking and logit methods),\n    'icarus' features functions for calibration on tight bounds and penalized\n    calibration.",
    "version": "0.3.3",
    "maintainer": "Khaled Larbi <khaled.larbi@insee.fr>",
    "author": "Antoine Rebecq [aut] (Creator),\n  Khaled Larbi [cre],\n  Institut national de la statistique et des \u00e9tudes \u00e9conomiques [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=icarus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "icarus Calibrates and Reweights Units in Samples Provides user-friendly tools for calibration in survey sampling.\n    The package is production-oriented, and its interface is inspired by the famous\n    popular macro 'Calmar' for SAS, so that 'Calmar' users can quickly get used to\n    'icarus'. In addition to calibration (with linear, raking and logit methods),\n    'icarus' features functions for calibration on tight bounds and penalized\n    calibration.  "
  },
  {
    "id": 14252,
    "package_name": "icesDatras",
    "title": "DATRAS Trawl Survey Database Web Services",
    "description": "R interface to access the web services of the ICES (International\n             Council for the Exploration of the Sea) DATRAS trawl survey\n             database <https://datras.ices.dk/WebServices/Webservices.aspx>.",
    "version": "1.4.1",
    "maintainer": "Colin Millar <colin.millar@ices.dk>",
    "author": "Colin Millar [aut, cre],\n  Cecilia Kvaavik [aut],\n  Adriana Villamor [aut],\n  Scott Large [aut],\n  Arni Magnusson [aut],\n  Vaishav Soni [ctb]",
    "url": "https://datras.ices.dk/WebServices/Webservices.aspx,\nhttps://github.com/ices-tools-prod/icesDatras",
    "bug_reports": "https://github.com/ices-tools-prod/icesDatras/issues",
    "repository": "https://cran.r-project.org/package=icesDatras",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "icesDatras DATRAS Trawl Survey Database Web Services R interface to access the web services of the ICES (International\n             Council for the Exploration of the Sea) DATRAS trawl survey\n             database <https://datras.ices.dk/WebServices/Webservices.aspx>.  "
  },
  {
    "id": 14268,
    "package_name": "idbr",
    "title": "R Interface to the US Census Bureau International Data Base API",
    "description": "Use R to make requests to the US Census Bureau's International Data Base API.\n             Results are returned as R data frames.  For more information about the IDB API, visit\n             <https://www.census.gov/data/developers/data-sets/international-database.html>.",
    "version": "1.2",
    "maintainer": "Kyle Walker <kyle.walker@tcu.edu>",
    "author": "Kyle Walker [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=idbr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "idbr R Interface to the US Census Bureau International Data Base API Use R to make requests to the US Census Bureau's International Data Base API.\n             Results are returned as R data frames.  For more information about the IDB API, visit\n             <https://www.census.gov/data/developers/data-sets/international-database.html>.  "
  },
  {
    "id": 14269,
    "package_name": "idcnrba",
    "title": "Interactive Application for Analyzing Representativeness and\nNonresponse Bias",
    "description": "Provides access to the \n    Idea Data Center (IDC) application for conducting \n    nonresponse bias analysis (NRBA). The IDC NRBA app is an\n    interactive, browser-based Shiny application that can be used to \n    analyze survey data with respect to response rates,\n    representativeness, and nonresponse bias. This app provides a user-friendly\n    interface to statistical methods implemented by the 'nrba' package.\n    Krenzke, Van de Kerckhove, and Mohadjer (2005) \n    <http://www.asasrms.org/Proceedings/y2005/files/JSM2005-000572.pdf>\n    and Lohr and Riddles (2016) \n    <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2016002/article/14677-eng.pdf?st=q7PyNsGR>\n    provide an overview of the statistical methods implemented in the application.",
    "version": "1.1.0",
    "maintainer": "Ben Schneider <BenjaminSchneider@westat.com>",
    "author": "Ben Schneider [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0406-8470>),\n  Tamara Nimkoff [aut],\n  Anthony Fucci [aut],\n  Andy Cruse [aut],\n  Alexander Cates [aut],\n  Jim Green [aut],\n  Westat [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=idcnrba",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "idcnrba Interactive Application for Analyzing Representativeness and\nNonresponse Bias Provides access to the \n    Idea Data Center (IDC) application for conducting \n    nonresponse bias analysis (NRBA). The IDC NRBA app is an\n    interactive, browser-based Shiny application that can be used to \n    analyze survey data with respect to response rates,\n    representativeness, and nonresponse bias. This app provides a user-friendly\n    interface to statistical methods implemented by the 'nrba' package.\n    Krenzke, Van de Kerckhove, and Mohadjer (2005) \n    <http://www.asasrms.org/Proceedings/y2005/files/JSM2005-000572.pdf>\n    and Lohr and Riddles (2016) \n    <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2016002/article/14677-eng.pdf?st=q7PyNsGR>\n    provide an overview of the statistical methods implemented in the application.  "
  },
  {
    "id": 14271,
    "package_name": "ideanet",
    "title": "Integrating Data Exchange and Analysis for Networks ('ideanet')",
    "description": "A suite of convenient tools for social network analysis geared toward students, entry-level users, and non-expert practitioners. \u2018ideanet\u2019 features unique functions for the processing and measurement of sociocentric and egocentric network data. These functions automatically generate node- and system-level measures commonly used in the analysis of these types of networks. Outputs from these functions maximize the ability of novice users to employ network measurements in further analyses while making all users less prone to common data analytic errors. Additionally, \u2018ideanet\u2019 features an R Shiny graphic user interface that allows novices to explore network data with minimal need for coding.",
    "version": "1.1.1",
    "maintainer": "Tom Wolff <tom.wolff@northwestern.edu>",
    "author": "Tom Wolff [aut, cre] (ORCID: <https://orcid.org/0000-0002-4884-251X>),\n  Jonathan Howard Morgan [aut] (ORCID:\n    <https://orcid.org/0000-0001-5181-9903>),\n  Gabriel Varela [aut] (ORCID: <https://orcid.org/0000-0003-2800-1577>),\n  Kieran Lele [aut],\n  Ethan Bhojani [aut],\n  Emily Heraty [aut],\n  Dana Pasquale [aut] (ORCID: <https://orcid.org/0000-0001-6686-7844>),\n  Peter Mucha [aut] (ORCID: <https://orcid.org/0000-0002-0648-7230>),\n  James Moody [aut] (ORCID: <https://orcid.org/0000-0002-3311-4173>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ideanet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ideanet Integrating Data Exchange and Analysis for Networks ('ideanet') A suite of convenient tools for social network analysis geared toward students, entry-level users, and non-expert practitioners. \u2018ideanet\u2019 features unique functions for the processing and measurement of sociocentric and egocentric network data. These functions automatically generate node- and system-level measures commonly used in the analysis of these types of networks. Outputs from these functions maximize the ability of novice users to employ network measurements in further analyses while making all users less prone to common data analytic errors. Additionally, \u2018ideanet\u2019 features an R Shiny graphic user interface that allows novices to explore network data with minimal need for coding.  "
  },
  {
    "id": 14285,
    "package_name": "ie2misc",
    "title": "Irucka Embry's Miscellaneous USGS Functions",
    "description": "A collection of Irucka Embry's miscellaneous USGS functions\n    (processing .exp and .psf files, statistical error functions,\n    \"+\" dyadic operator for use with NA, creating ADAPS and QW\n    spreadsheet files, calculating saturated enthalpy). Irucka created these\n    functions while a Cherokee Nation Technology Solutions (CNTS) United States\n    Geological Survey (USGS) Contractor and/or USGS employee.",
    "version": "0.9.2",
    "maintainer": "Irucka Embry <iembry@ecoccs.com>",
    "author": "Irucka Embry [aut, cre],\n  Anne Hoos [ctb],\n  Timothy H. Diehl [ctb]",
    "url": "https://gitlab.com/iembry/ie2misc",
    "bug_reports": "https://gitlab.com/iembry/ie2misc/-/issues",
    "repository": "https://cran.r-project.org/package=ie2misc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ie2misc Irucka Embry's Miscellaneous USGS Functions A collection of Irucka Embry's miscellaneous USGS functions\n    (processing .exp and .psf files, statistical error functions,\n    \"+\" dyadic operator for use with NA, creating ADAPS and QW\n    spreadsheet files, calculating saturated enthalpy). Irucka created these\n    functions while a Cherokee Nation Technology Solutions (CNTS) United States\n    Geological Survey (USGS) Contractor and/or USGS employee.  "
  },
  {
    "id": 14286,
    "package_name": "ie2miscdata",
    "title": "Irucka Embry's Miscellaneous USGS Data Collection",
    "description": "A collection of Irucka Embry's miscellaneous USGS data sets (USGS\n    Parameter codes with fixed values, USGS global time zone codes, and US Air\n    Force Global Engineering Weather Data). Irucka created these data sets\n    while a Cherokee Nation Technology Solutions (CNTS) United States\n    Geological Survey (USGS) Contractor and/or USGS employee.",
    "version": "1.0.4",
    "maintainer": "Irucka Embry <iembry@ecoccs.com>",
    "author": "Irucka Embry [aut, cre]",
    "url": "https://gitlab.com/iembry/ie2miscdata",
    "bug_reports": "https://gitlab.com/iembry/ie2miscdata/-/issues",
    "repository": "https://cran.r-project.org/package=ie2miscdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ie2miscdata Irucka Embry's Miscellaneous USGS Data Collection A collection of Irucka Embry's miscellaneous USGS data sets (USGS\n    Parameter codes with fixed values, USGS global time zone codes, and US Air\n    Force Global Engineering Weather Data). Irucka created these data sets\n    while a Cherokee Nation Technology Solutions (CNTS) United States\n    Geological Survey (USGS) Contractor and/or USGS employee.  "
  },
  {
    "id": 14297,
    "package_name": "ifo",
    "title": "Client for the Ifo Institute Time Series",
    "description": "Download ifo business survey data and more time series from\n    ifo institute <https://www.ifo.de/en/ifo-time-series>.",
    "version": "0.2.2",
    "maintainer": "Maximilian M\u00fccke <muecke.maximilian@gmail.com>",
    "author": "Maximilian M\u00fccke [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-9432-9795>)",
    "url": "https://m-muecke.github.io/ifo/, https://github.com/m-muecke/ifo",
    "bug_reports": "https://github.com/m-muecke/ifo/issues",
    "repository": "https://cran.r-project.org/package=ifo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ifo Client for the Ifo Institute Time Series Download ifo business survey data and more time series from\n    ifo institute <https://www.ifo.de/en/ifo-time-series>.  "
  },
  {
    "id": 14300,
    "package_name": "ig.degree.betweenness",
    "title": "\"Smith-Pittman Community Detection Algorithm for 'igraph'\nObjects (2024)\"",
    "description": "Implements the \"Smith-Pittman\" community detection algorithm  \n    for network analysis using 'igraph' objects. This algorithm combines node \n    degree and betweenness centrality measures to identify communities within \n    networks, with a gradient evident in social partitioning. The package \n    provides functions for community detection, visualization, and analysis of \n    the resulting community structure. Methods are based on results from Smith, \n    Pittman and Xu (2024) <doi:10.48550/arXiv.2411.01394>.",
    "version": "0.2.0",
    "maintainer": "Benjamin Smith <benyamin.smith@mail.utoronto.ca>",
    "author": "Benjamin Smith [aut, cre] (ORCID:\n    <https://orcid.org/0009-0007-2206-0177>),\n  Tyler Pittman [aut] (ORCID: <https://orcid.org/0000-0002-5013-6980>),\n  Wei Xu [aut] (ORCID: <https://orcid.org/0000-0002-0257-8856>)",
    "url": "https://github.com/benyamindsmith/ig.degree.betweenness",
    "bug_reports": "https://github.com/benyamindsmith/ig.degree.betweenness/issues",
    "repository": "https://cran.r-project.org/package=ig.degree.betweenness",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ig.degree.betweenness \"Smith-Pittman Community Detection Algorithm for 'igraph'\nObjects (2024)\" Implements the \"Smith-Pittman\" community detection algorithm  \n    for network analysis using 'igraph' objects. This algorithm combines node \n    degree and betweenness centrality measures to identify communities within \n    networks, with a gradient evident in social partitioning. The package \n    provides functions for community detection, visualization, and analysis of \n    the resulting community structure. Methods are based on results from Smith, \n    Pittman and Xu (2024) <doi:10.48550/arXiv.2411.01394>.  "
  },
  {
    "id": 14309,
    "package_name": "igraph",
    "title": "Network Analysis and Visualization",
    "description": "Routines for simple graphs and network analysis. It can\n    handle large graphs very well and provides functions for generating\n    random and regular graphs, graph visualization, centrality methods and\n    much more.",
    "version": "2.2.1",
    "maintainer": "Kirill M\u00fcller <kirill@cynkra.com>",
    "author": "G\u00e1bor Cs\u00e1rdi [aut] (ORCID: <https://orcid.org/0000-0001-7098-9676>),\n  Tam\u00e1s Nepusz [aut] (ORCID: <https://orcid.org/0000-0002-1451-338X>),\n  Vincent Traag [aut] (ORCID: <https://orcid.org/0000-0003-3170-3879>),\n  Szabolcs Horv\u00e1t [aut] (ORCID: <https://orcid.org/0000-0002-3100-523X>),\n  Fabio Zanini [aut] (ORCID: <https://orcid.org/0000-0001-7097-8539>),\n  Daniel Noom [aut],\n  Kirill M\u00fcller [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1416-3412>),\n  Michael Antonov [ctb],\n  Chan Zuckerberg Initiative [fnd] (ROR: <https://ror.org/02qenvm24>),\n  David Schoch [aut] (ORCID: <https://orcid.org/0000-0003-2952-4812>),\n  Ma\u00eblle Salmon [aut] (ORCID: <https://orcid.org/0000-0002-2815-0399>)",
    "url": "https://r.igraph.org/, https://igraph.org/,\nhttps://igraph.discourse.group/",
    "bug_reports": "https://github.com/igraph/rigraph/issues",
    "repository": "https://cran.r-project.org/package=igraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igraph Network Analysis and Visualization Routines for simple graphs and network analysis. It can\n    handle large graphs very well and provides functions for generating\n    random and regular graphs, graph visualization, centrality methods and\n    much more.  "
  },
  {
    "id": 14310,
    "package_name": "igraphdata",
    "title": "A Collection of Network Data Sets for the 'igraph' Package",
    "description": "A small collection of various network data sets,\n    to use with the 'igraph' package: the Enron email network, various food webs,\n    interactions in the immunoglobulin protein, the karate club network,\n    Koenigsberg's bridges, visuotactile brain areas of the macaque monkey,\n    UK faculty friendship network, domestic US flights network, etc.",
    "version": "1.0.1",
    "maintainer": "Gabor Csardi <csardi.gabor@gmail.com>",
    "author": "Gabor Csardi <csardi.gabor@gmail.com>",
    "url": "http://igraph.org",
    "bug_reports": "https://github.com/igraph/igraphdata/issues",
    "repository": "https://cran.r-project.org/package=igraphdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igraphdata A Collection of Network Data Sets for the 'igraph' Package A small collection of various network data sets,\n    to use with the 'igraph' package: the Enron email network, various food webs,\n    interactions in the immunoglobulin protein, the karate club network,\n    Koenigsberg's bridges, visuotactile brain areas of the macaque monkey,\n    UK faculty friendship network, domestic US flights network, etc.  "
  },
  {
    "id": 14311,
    "package_name": "igraphinshiny",
    "title": "Use 'shiny' to Demo 'igraph'",
    "description": "Using 'shiny' to demo 'igraph' package makes learning graph theory easy and fun.",
    "version": "0.1",
    "maintainer": "Ming-Jer Lee <mingjerli@gmail.com>",
    "author": "Ming-Jer Lee [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=igraphinshiny",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igraphinshiny Use 'shiny' to Demo 'igraph' Using 'shiny' to demo 'igraph' package makes learning graph theory easy and fun.  "
  },
  {
    "id": 14312,
    "package_name": "igraphtosonia",
    "title": "Convert iGraph graps to SoNIA .son files",
    "description": "This program facilitates exporting igraph graphs to the\n        SoNIA file format",
    "version": "1.0",
    "maintainer": "Sean J Westwood <seanjw@stanford.edu>",
    "author": "Sean J Westwood <seanjw@stanford.edu>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=igraphtosonia",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igraphtosonia Convert iGraph graps to SoNIA .son files This program facilitates exporting igraph graphs to the\n        SoNIA file format  "
  },
  {
    "id": 14313,
    "package_name": "igraphwalshdata",
    "title": "'igraph' Datasets from Melanie Walsh",
    "description": "Interesting 'igraph' datasets from Melanie Walsh's sample social network datasets repository <https://github.com/melaniewalsh/sample-social-network-datasets>.",
    "version": "0.1.0",
    "maintainer": "Benjamin Smith <benyamin.smith@mail.utoronto.ca>",
    "author": "Benjamin Smith [aut, cre] (ORCID:\n    <https://orcid.org/0009-0007-2206-0177>)",
    "url": "https://github.com/benyamindsmith/igraphwalshdata",
    "bug_reports": "https://github.com/benyamindsmith/igraphwalshdata/issues",
    "repository": "https://cran.r-project.org/package=igraphwalshdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "igraphwalshdata 'igraph' Datasets from Melanie Walsh Interesting 'igraph' datasets from Melanie Walsh's sample social network datasets repository <https://github.com/melaniewalsh/sample-social-network-datasets>.  "
  },
  {
    "id": 14319,
    "package_name": "ilabelled",
    "title": "Simple Handling of Labelled Data",
    "description": "Simple handling of survey data. Smart handling of meta-information like e.g. variable-labels value-labels and scale-levels. Easy access and validation of meta-information. Useage of value labels and values respectively for subsetting and recoding data. ",
    "version": "1.0.1",
    "maintainer": "Christof Lewerenz <christof.lewerenz@gmx.net>",
    "author": "Christof Lewerenz [aut, cre]",
    "url": "https://github.com/clewerenz/ilabelled",
    "bug_reports": "https://github.com/clewerenz/ilabelled/issues",
    "repository": "https://cran.r-project.org/package=ilabelled",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ilabelled Simple Handling of Labelled Data Simple handling of survey data. Smart handling of meta-information like e.g. variable-labels value-labels and scale-levels. Easy access and validation of meta-information. Useage of value labels and values respectively for subsetting and recoding data.   "
  },
  {
    "id": 14340,
    "package_name": "imanr",
    "title": "Identify the Racial Complex of Native Corns from Mexico",
    "description": "A model that provides researchers with a powerful tool for the classification\n    and study of native corn by aiding in the identification of racial complexes\n    which are fundamental to Mexico's agriculture and culture. This package has been\n    developed based on data collected by \"Proyecto Global de Ma\u00edces Nativos M\u00e9xico\",\n    which has conducted exhaustive surveys across the country to document the\n    qualitative and quantitative characteristics of different types of native maize.\n    The trained model uses a robust and diverse dataset, enabling it to achieve an\n    80% accuracy in classifying maize racial complexes. The characteristics included\n    in the analysis comprise geographic location, grain and cob colors, as well as\n    various physical measurements, such as lengths and widths.",
    "version": "2.0.0",
    "maintainer": "Rafael Nieves-Alvarez <nievesalvarez1618@gmail.com>",
    "author": "Rafael Nieves-Alvarez [aut, cre] (ORCID:\n    <https://orcid.org/0009-0002-8016-1412>),\n  Arturo Sanchez-Porras [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-1691-286X>),\n  Aline Romero-Natale [aut] (ORCID:\n    <https://orcid.org/0000-0003-4267-1913>),\n  Otilio Arturo Acevedo-Sandoval [aut] (ORCID:\n    <https://orcid.org/0000-0003-0475-7003>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=imanr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imanr Identify the Racial Complex of Native Corns from Mexico A model that provides researchers with a powerful tool for the classification\n    and study of native corn by aiding in the identification of racial complexes\n    which are fundamental to Mexico's agriculture and culture. This package has been\n    developed based on data collected by \"Proyecto Global de Ma\u00edces Nativos M\u00e9xico\",\n    which has conducted exhaustive surveys across the country to document the\n    qualitative and quantitative characteristics of different types of native maize.\n    The trained model uses a robust and diverse dataset, enabling it to achieve an\n    80% accuracy in classifying maize racial complexes. The characteristics included\n    in the analysis comprise geographic location, grain and cob colors, as well as\n    various physical measurements, such as lengths and widths.  "
  },
  {
    "id": 14342,
    "package_name": "imbalanceDatRel",
    "title": "Relocated Data Oversampling for Imbalanced Data Classification",
    "description": "Relocates oversampled data from a specific oversampling method to\n    cover area determined by pure and proper class cover catch digraphs (PCCCD). \n    It prevents any data to be generated in class overlapping area.\n    For more details, see the corresponding publication: \n    F. Sa\u011flam (2025) <doi:10.1007/s10994-025-06755-8>.",
    "version": "0.1.6",
    "maintainer": "Fatih Saglam <saglamf89@gmail.com>",
    "author": "Fatih Saglam [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2084-2008>)",
    "url": "https://doi.org/10.1007/s10994-025-06755-8",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=imbalanceDatRel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "imbalanceDatRel Relocated Data Oversampling for Imbalanced Data Classification Relocates oversampled data from a specific oversampling method to\n    cover area determined by pure and proper class cover catch digraphs (PCCCD). \n    It prevents any data to be generated in class overlapping area.\n    For more details, see the corresponding publication: \n    F. Sa\u011flam (2025) <doi:10.1007/s10994-025-06755-8>.  "
  },
  {
    "id": 14359,
    "package_name": "impactr",
    "title": "Mechanical Loading Prediction Through Accelerometer Data",
    "description": "Functions to read, process and analyse accelerometer\n    data related to mechanical loading variables. This package is\n    developed and tested for use with raw accelerometer data from\n    triaxial 'ActiGraph' <https://theactigraph.com> accelerometers.",
    "version": "0.4.2",
    "maintainer": "Lucas Veras <lucasdsveras@gmail.com>",
    "author": "Lucas Veras [aut, cre] (ORCID: <https://orcid.org/0000-0003-0562-5803>)",
    "url": "https://lveras.com/impactr/",
    "bug_reports": "https://github.com/verasls/impactr/issues/",
    "repository": "https://cran.r-project.org/package=impactr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "impactr Mechanical Loading Prediction Through Accelerometer Data Functions to read, process and analyse accelerometer\n    data related to mechanical loading variables. This package is\n    developed and tested for use with raw accelerometer data from\n    triaxial 'ActiGraph' <https://theactigraph.com> accelerometers.  "
  },
  {
    "id": 14389,
    "package_name": "inca",
    "title": "Integer Calibration",
    "description": "Specific functions are provided for rounding real weights to integers and performing an integer programming algorithm for calibration problems. These functions are useful for census-weights adjustments, survey calibration, or for performing linear regression with integer parameters <https://www.nass.usda.gov/Education_and_Outreach/Reports,_Presentations_and_Conferences/reports/New_Integer_Calibration_%20Procedure_2016.pdf>. This research was supported in part by the U.S. Department of Agriculture, National Agriculture Statistics Service. The findings and conclusions in this publication are those of the authors and should not be construed to represent any official USDA, or US Government determination or policy.",
    "version": "0.1.0",
    "maintainer": "Luca Sartore <drwolf85@gmail.com>",
    "author": "Luca Sartore [aut] (ORCID = \"0000-0002-0446-1328\"),\n  Luca Sartore [cre] (ORCID = \"0000-0002-0446-1328\"),\n  Kelly Toppin [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=inca",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inca Integer Calibration Specific functions are provided for rounding real weights to integers and performing an integer programming algorithm for calibration problems. These functions are useful for census-weights adjustments, survey calibration, or for performing linear regression with integer parameters <https://www.nass.usda.gov/Education_and_Outreach/Reports,_Presentations_and_Conferences/reports/New_Integer_Calibration_%20Procedure_2016.pdf>. This research was supported in part by the U.S. Department of Agriculture, National Agriculture Statistics Service. The findings and conclusions in this publication are those of the authors and should not be construed to represent any official USDA, or US Government determination or policy.  "
  },
  {
    "id": 14395,
    "package_name": "inctools",
    "title": "Incidence Estimation Tools",
    "description": "Tools for estimating incidence from biomarker data in cross-\n    sectional surveys, and for calibrating tests for recent infection. \n    Implements and extends the method of Kassanjee et al. (2012)\n    <doi:10.1097/EDE.0b013e3182576c07>.",
    "version": "1.0.15",
    "maintainer": "Eduard Grebe <Eduard.Grebe@ucsf.edu>",
    "author": "Eduard Grebe [cre, aut],\n  Alex Welte [aut],\n  Avery McIntosh [aut],\n  Petra B\u00e4umler [aut],\n  Reshma Kassanjee [ctb],\n  Hilmarie Brand [ctb],\n  Cari Van Schalkwyk [ctb],\n  Yuruo Li [ctb],\n  Simon Daniel [ctb],\n  Stefano Ongarello [aut],\n  Yusuke Asai [ctb],\n  Jeffrey Eaton [ctb]",
    "url": "http://www.incidence-estimation.org/page/inctools",
    "bug_reports": "https://github.com/SACEMA/inctools/issues",
    "repository": "https://cran.r-project.org/package=inctools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inctools Incidence Estimation Tools Tools for estimating incidence from biomarker data in cross-\n    sectional surveys, and for calibrating tests for recent infection. \n    Implements and extends the method of Kassanjee et al. (2012)\n    <doi:10.1097/EDE.0b013e3182576c07>.  "
  },
  {
    "id": 14407,
    "package_name": "ineAtlas",
    "title": "Access to Spanish Household Income Distribution Atlas Data",
    "description": "Provides access to granular socioeconomic indicators from the\n    Spanish Statistical Office (INE) Household Income Distribution Atlas.\n    The package downloads and processes data from a companion 'GitHub'\n    repository (<https://github.com/pablogguz/ineAtlas.data/>) which\n    contains processed versions of the official INE Atlas data. Functions\n    are provided to fetch data at multiple geographic levels\n    (municipalities, districts, and census tracts), including income\n    indicators, demographic characteristics, and inequality metrics. The\n    data repository is updated every year when new releases are published\n    by INE.",
    "version": "0.1.4",
    "maintainer": "Pablo Garc\u00eda Guzm\u00e1n <garciagp@ebrd.com>",
    "author": "Pablo Garc\u00eda Guzm\u00e1n [aut, cre, cph]",
    "url": "https://github.com/pablogguz/ineAtlas,\nhttps://pablogguz.github.io/ineAtlas/",
    "bug_reports": "https://github.com/pablogguz/ineAtlas/issues",
    "repository": "https://cran.r-project.org/package=ineAtlas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ineAtlas Access to Spanish Household Income Distribution Atlas Data Provides access to granular socioeconomic indicators from the\n    Spanish Statistical Office (INE) Household Income Distribution Atlas.\n    The package downloads and processes data from a companion 'GitHub'\n    repository (<https://github.com/pablogguz/ineAtlas.data/>) which\n    contains processed versions of the official INE Atlas data. Functions\n    are provided to fetch data at multiple geographic levels\n    (municipalities, districts, and census tracts), including income\n    indicators, demographic characteristics, and inequality metrics. The\n    data repository is updated every year when new releases are published\n    by INE.  "
  },
  {
    "id": 14415,
    "package_name": "infectiousR",
    "title": "Access Infectious and Epidemiological Data via 'disease.sh API'",
    "description": "Provides functions to access real-time infectious disease data from the 'disease.sh API',\n    including COVID-19 global, US states, continent, and country statistics, vaccination coverage,\n    influenza-like illness data from the Centers for Disease Control and Prevention (CDC), and more. \n    Also includes curated datasets on a variety of infectious diseases such as influenza, measles, dengue, \n    Ebola, tuberculosis, meningitis, AIDS, and others. The package supports epidemiological research \n    and data analysis by combining API access with high-quality historical and survey datasets on infectious diseases. \n    For more details on the 'disease.sh API', see <https://disease.sh/>.",
    "version": "0.1.1",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/infectiousr,\nhttps://lightbluetitan.github.io/infectiousr/",
    "bug_reports": "https://github.com/lightbluetitan/infectiousr/issues",
    "repository": "https://cran.r-project.org/package=infectiousR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "infectiousR Access Infectious and Epidemiological Data via 'disease.sh API' Provides functions to access real-time infectious disease data from the 'disease.sh API',\n    including COVID-19 global, US states, continent, and country statistics, vaccination coverage,\n    influenza-like illness data from the Centers for Disease Control and Prevention (CDC), and more. \n    Also includes curated datasets on a variety of infectious diseases such as influenza, measles, dengue, \n    Ebola, tuberculosis, meningitis, AIDS, and others. The package supports epidemiological research \n    and data analysis by combining API access with high-quality historical and survey datasets on infectious diseases. \n    For more details on the 'disease.sh API', see <https://disease.sh/>.  "
  },
  {
    "id": 14428,
    "package_name": "influential",
    "title": "Identification and Classification of the Most Influential Nodes",
    "description": "Contains functions for the classification and ranking of top candidate features, reconstruction of networks from\n    adjacency matrices and data frames, analysis of the topology of the network \n    and calculation of centrality measures, and identification of the most\n    influential nodes. Also, a function is provided for running SIRIR model, which \n    is the combination of leave-one-out cross validation technique and the conventional SIR model, on a network to unsupervisedly rank the true influence of vertices. Additionally, some functions have been provided for the assessment \n    of dependence and correlation of two network centrality measures as well as \n    the conditional probability of deviation from their corresponding means in opposite direction.\n    Fred Viole and David Nawrocki (2013, ISBN:1490523995).\n    Csardi G, Nepusz T (2006). \"The igraph software package for complex network research.\" InterJournal, Complex Systems, 1695.\n    Adopted algorithms and sources are referenced in function document.",
    "version": "2.2.9",
    "maintainer": "Adrian Salavaty <abbas.salavaty@gmail.com>",
    "author": "Abbas (Adrian) Salavaty [aut, cre], Mirana Ramialison [ths], Peter D. Currie [ths]",
    "url": "https://github.com/asalavaty/influential,\nhttps://asalavaty.github.io/influential/",
    "bug_reports": "https://github.com/asalavaty/influential/issues",
    "repository": "https://cran.r-project.org/package=influential",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "influential Identification and Classification of the Most Influential Nodes Contains functions for the classification and ranking of top candidate features, reconstruction of networks from\n    adjacency matrices and data frames, analysis of the topology of the network \n    and calculation of centrality measures, and identification of the most\n    influential nodes. Also, a function is provided for running SIRIR model, which \n    is the combination of leave-one-out cross validation technique and the conventional SIR model, on a network to unsupervisedly rank the true influence of vertices. Additionally, some functions have been provided for the assessment \n    of dependence and correlation of two network centrality measures as well as \n    the conditional probability of deviation from their corresponding means in opposite direction.\n    Fred Viole and David Nawrocki (2013, ISBN:1490523995).\n    Csardi G, Nepusz T (2006). \"The igraph software package for complex network research.\" InterJournal, Complex Systems, 1695.\n    Adopted algorithms and sources are referenced in function document.  "
  },
  {
    "id": 14441,
    "package_name": "inlabru",
    "title": "Bayesian Latent Gaussian Modelling using INLA and Extensions",
    "description": "Facilitates spatial and general latent Gaussian modeling using\n  integrated nested Laplace approximation via the INLA package (<https://www.r-inla.org>).\n  Additionally, extends the GAM-like model class to more general nonlinear predictor\n  expressions, and implements a log Gaussian Cox process likelihood for \n  modeling univariate and spatial point processes based on ecological survey data.\n  Model components are specified with general inputs and mapping methods to the\n  latent variables, and the predictors are specified via general R expressions,\n  with separate expressions for each observation likelihood model in\n  multi-likelihood models. A prediction method based on fast Monte Carlo sampling\n  allows posterior prediction of general expressions of the latent variables.\n  Ecology-focused introduction in Bachl, Lindgren, Borchers, and Illian (2019)\n  <doi:10.1111/2041-210X.13168>.",
    "version": "2.13.0",
    "maintainer": "Finn Lindgren <finn.lindgren@gmail.com>",
    "author": "Finn Lindgren [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5833-2011>, Finn Lindgren continued\n    development of the main code),\n  Fabian E. Bachl [aut, cph] (Fabian Bachl wrote the main code),\n  David L. Borchers [ctb, dtc, cph] (David Borchers wrote code for\n    Gorilla data import and sampling, multiplot tool),\n  Daniel Simpson [ctb, cph] (Daniel Simpson wrote the basic LGCP sampling\n    method),\n  Lindesay Scott-Howard [ctb, dtc, cph] (Lindesay Scott-Howard provided\n    MRSea data import code),\n  Seaton Andy [ctb] (Andy Seaton provided testing, bugfixes, and\n    vignettes),\n  Suen Man Ho [ctb, cph] (Man Ho Suen contributed features for aggregated\n    responses and vignette updates),\n  Roudier Pierre [ctb, cph] (Pierre Roudier contributed general quantile\n    summaries),\n  Meehan Tim [ctb, cph] (Tim Meehan contributed the SVC vignette and\n    robins data),\n  Reddy Peddinenikalva Niharika [ctb, cph] (Niharika Peddinenikalva\n    contributed the LGCP residuals vignette),\n  Perepolkin Dmytro [ctb, cph] (Dmytro Perepolkin contributed the ZIP/ZAP\n    vignette)",
    "url": "http://www.inlabru.org, https://inlabru-org.github.io/inlabru/,\nhttps://github.com/inlabru-org/inlabru",
    "bug_reports": "https://github.com/inlabru-org/inlabru/issues",
    "repository": "https://cran.r-project.org/package=inlabru",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inlabru Bayesian Latent Gaussian Modelling using INLA and Extensions Facilitates spatial and general latent Gaussian modeling using\n  integrated nested Laplace approximation via the INLA package (<https://www.r-inla.org>).\n  Additionally, extends the GAM-like model class to more general nonlinear predictor\n  expressions, and implements a log Gaussian Cox process likelihood for \n  modeling univariate and spatial point processes based on ecological survey data.\n  Model components are specified with general inputs and mapping methods to the\n  latent variables, and the predictors are specified via general R expressions,\n  with separate expressions for each observation likelihood model in\n  multi-likelihood models. A prediction method based on fast Monte Carlo sampling\n  allows posterior prediction of general expressions of the latent variables.\n  Ecology-focused introduction in Bachl, Lindgren, Borchers, and Illian (2019)\n  <doi:10.1111/2041-210X.13168>.  "
  },
  {
    "id": 14443,
    "package_name": "inlcolor",
    "title": "Color Schemes for the USGS Idaho National Laboratory Project\nOffice",
    "description": "A collection of functions for creating color schemes.\n    Used to support packages and scripts written\n    by researchers at the United States Geological Survey (USGS)\n    Idaho National Laboratory Project Office.",
    "version": "1.0.6",
    "maintainer": "Jason C. Fisher <jfisher@usgs.gov>",
    "author": "Jason C. Fisher [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9032-8912>)",
    "url": "https://rconnect.usgs.gov/INLPO/inlcolor-main/,\nhttps://code.usgs.gov/inl/inlcolor",
    "bug_reports": "https://code.usgs.gov/inl/inlcolor/-/issues",
    "repository": "https://cran.r-project.org/package=inlcolor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inlcolor Color Schemes for the USGS Idaho National Laboratory Project\nOffice A collection of functions for creating color schemes.\n    Used to support packages and scripts written\n    by researchers at the United States Geological Survey (USGS)\n    Idaho National Laboratory Project Office.  "
  },
  {
    "id": 14446,
    "package_name": "inlpubs",
    "title": "USGS INL Project Office Publications",
    "description": "Contains bibliographic information for the U.S. Geological Survey\n    (USGS) Idaho National Laboratory (INL) Project Office.",
    "version": "1.3.0",
    "maintainer": "Jason C. Fisher <jfisher@usgs.gov>",
    "author": "Jason C. Fisher [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9032-8912>),\n  Kerri C. Treinen [aut] (ORCID: <https://orcid.org/0000-0003-0645-6810>),\n  Allison R. Trcka [aut] (ORCID: <https://orcid.org/0000-0001-8498-4737>)",
    "url": "https://rconnect.usgs.gov/INLPO/inlpubs-main/,\nhttps://code.usgs.gov/inl/inlpubs",
    "bug_reports": "https://code.usgs.gov/inl/inlpubs/-/issues",
    "repository": "https://cran.r-project.org/package=inlpubs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "inlpubs USGS INL Project Office Publications Contains bibliographic information for the U.S. Geological Survey\n    (USGS) Idaho National Laboratory (INL) Project Office.  "
  },
  {
    "id": 14488,
    "package_name": "intergraph",
    "title": "Coercion Routines for Network Data Objects",
    "description": "Functions implemented in this package allow to coerce (i.e.\n\tconvert) network data between classes provided by other R packages.\n\tCurrently supported classes are those defined in packages: network and\n\tigraph.",
    "version": "2.0-4",
    "maintainer": "Micha\u0142 Bojanowski <michal2992@gmail.com>",
    "author": "Micha\u0142 Bojanowski [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7503-852X>)",
    "url": "https://mbojan.github.io/intergraph/",
    "bug_reports": "https://github.com/mbojan/intergraph/issues",
    "repository": "https://cran.r-project.org/package=intergraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "intergraph Coercion Routines for Network Data Objects Functions implemented in this package allow to coerce (i.e.\n\tconvert) network data between classes provided by other R packages.\n\tCurrently supported classes are those defined in packages: network and\n\tigraph.  "
  },
  {
    "id": 14494,
    "package_name": "interplex",
    "title": "Coercion Methods for Simplicial Complex Data Structures",
    "description": "Computational topology, which enables topological data analysis\n    (TDA), makes pervasive use of abstract mathematical objects called\n    simplicial complexes; see Edelsbrunner and Harer (2010)\n    <doi:10.1090/mbk/069>.\n    Several R packages and other software libraries used through an R interface\n    construct and use data structures that represent simplicial complexes,\n    including mathematical graphs viewed as 1-dimensional complexes.\n    This package provides coercers (converters) between these data structures.\n    Currently supported structures are complete lists of simplices as used by\n    'TDA'; the simplex trees of Boissonnat and Maria (2014)\n    <doi:10.1007/s00453-014-9887-3> as implemented in 'simplextree' and in\n    Python GUDHI (by way of 'reticulate'); and the graph classes of 'igraph' and\n    'network', by way of the 'intergraph' package.",
    "version": "0.1.2",
    "maintainer": "Jason Cory Brunson <cornelioid@gmail.com>",
    "author": "Jason Cory Brunson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3126-9494>),\n  Yara Skaf [ctb]",
    "url": "https://github.com/tdaverse/interplex",
    "bug_reports": "https://github.com/tdaverse/interplex/issues",
    "repository": "https://cran.r-project.org/package=interplex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "interplex Coercion Methods for Simplicial Complex Data Structures Computational topology, which enables topological data analysis\n    (TDA), makes pervasive use of abstract mathematical objects called\n    simplicial complexes; see Edelsbrunner and Harer (2010)\n    <doi:10.1090/mbk/069>.\n    Several R packages and other software libraries used through an R interface\n    construct and use data structures that represent simplicial complexes,\n    including mathematical graphs viewed as 1-dimensional complexes.\n    This package provides coercers (converters) between these data structures.\n    Currently supported structures are complete lists of simplices as used by\n    'TDA'; the simplex trees of Boissonnat and Maria (2014)\n    <doi:10.1007/s00453-014-9887-3> as implemented in 'simplextree' and in\n    Python GUDHI (by way of 'reticulate'); and the graph classes of 'igraph' and\n    'network', by way of the 'intergraph' package.  "
  },
  {
    "id": 14534,
    "package_name": "ionet",
    "title": "Network Analysis for Input-Output Tables",
    "description": "Network functionalities specialized for data generated from input-output tables.",
    "version": "0.2.2",
    "maintainer": "Shiying Xiao <shiying.xiao@outlook.com>",
    "author": "Shiying Xiao [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8846-3258>),\n  Jun Yan [aut] (ORCID: <https://orcid.org/0000-0003-4401-7296>),\n  Panpan Zhang [aut] (ORCID: <https://orcid.org/0000-0002-8211-5930>)",
    "url": "https://github.com/Carol-seven/ionet",
    "bug_reports": "https://github.com/Carol-seven/ionet/issues",
    "repository": "https://cran.r-project.org/package=ionet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ionet Network Analysis for Input-Output Tables Network functionalities specialized for data generated from input-output tables.  "
  },
  {
    "id": 14548,
    "package_name": "ipanema",
    "title": "Read Data from 'LimeSurvey'",
    "description": "Read data from 'LimeSurvey'\n    (<https://www.limesurvey.org/>)\n    in a comfortable way.\n    Heavily inspired by 'limer'\n    (<https://github.com/cloudyr/limer/>),\n    which lacked a few comfort features for me.",
    "version": "1.2.0",
    "maintainer": "Maximilian Hagspiel <maxhag@mailbox.org>",
    "author": "Maximilian Hagspiel [aut, cre, cph]",
    "url": "https://gitlab.com/REDS1736/ipanema",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ipanema",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipanema Read Data from 'LimeSurvey' Read data from 'LimeSurvey'\n    (<https://www.limesurvey.org/>)\n    in a comfortable way.\n    Heavily inspired by 'limer'\n    (<https://github.com/cloudyr/limer/>),\n    which lacked a few comfort features for me.  "
  },
  {
    "id": 14558,
    "package_name": "ipfr",
    "title": "List Balancing for Reweighting and Population Synthesis",
    "description": "Performs iterative proportional updating given a seed table and\n  an arbitrary number of marginal distributions. This is commonly used in\n  population synthesis, survey raking, matrix rebalancing, and other\n  applications. For example, a household survey may be weighted to match the\n  known distribution of households by size from the census. An origin/\n  destination trip matrix might be balanced to match traffic counts.\n  The approach used by this package is based on a paper from\n  Arizona State University (Ye, Xin, et. al. (2009)\n  <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.537.723&rep=rep1&type=pdf>).\n  Some enhancements have been made to their work including primary and \n  secondary target balance/importance, general marginal agreement, and weight \n  restriction.",
    "version": "1.0.2",
    "maintainer": "Kyle Ward <kyleward084@gmail.com>",
    "author": "Kyle Ward [aut, cre, cph],\n  Greg Macfarlane [ctb]",
    "url": "https://github.com/dkyleward/ipfr",
    "bug_reports": "https://github.com/dkyleward/ipfr/issues",
    "repository": "https://cran.r-project.org/package=ipfr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipfr List Balancing for Reweighting and Population Synthesis Performs iterative proportional updating given a seed table and\n  an arbitrary number of marginal distributions. This is commonly used in\n  population synthesis, survey raking, matrix rebalancing, and other\n  applications. For example, a household survey may be weighted to match the\n  known distribution of households by size from the census. An origin/\n  destination trip matrix might be balanced to match traffic counts.\n  The approach used by this package is based on a paper from\n  Arizona State University (Ye, Xin, et. al. (2009)\n  <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.537.723&rep=rep1&type=pdf>).\n  Some enhancements have been made to their work including primary and \n  secondary target balance/importance, general marginal agreement, and weight \n  restriction.  "
  },
  {
    "id": 14571,
    "package_name": "ipumsr",
    "title": "An R Interface for Downloading, Reading, and Handling IPUMS Data",
    "description": "An easy way to work with census, survey, and geographic data\n    provided by IPUMS in R. Generate and download data through the IPUMS\n    API and load IPUMS files into R with their associated metadata to\n    make analysis easier. IPUMS data describing 1.4 billion individuals\n    drawn from over 750 censuses and surveys is available free of charge\n    from the IPUMS website <https://www.ipums.org>.",
    "version": "0.9.0",
    "maintainer": "Derek Burk <ipums+cran@umn.edu>",
    "author": "Greg Freedman Ellis [aut],\n  Derek Burk [aut, cre],\n  Finn Roberts [aut],\n  Joe Grover [ctb],\n  Dan Ehrlich [ctb],\n  Renae Rodgers [ctb],\n  Institute for Social Research and Data Innovation [cph]",
    "url": "https://tech.popdata.org/ipumsr/, https://github.com/ipums/ipumsr,\nhttps://www.ipums.org",
    "bug_reports": "https://github.com/ipums/ipumsr/issues",
    "repository": "https://cran.r-project.org/package=ipumsr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ipumsr An R Interface for Downloading, Reading, and Handling IPUMS Data An easy way to work with census, survey, and geographic data\n    provided by IPUMS in R. Generate and download data through the IPUMS\n    API and load IPUMS files into R with their associated metadata to\n    make analysis easier. IPUMS data describing 1.4 billion individuals\n    drawn from over 750 censuses and surveys is available free of charge\n    from the IPUMS website <https://www.ipums.org>.  "
  },
  {
    "id": 14632,
    "package_name": "italy",
    "title": "The Italian Survey on Household and Wealth, 2008 and 2010",
    "description": "Provides two record linkage data sets on the Italian Survey on Household and Wealth, 2008 and 2010, a sample survey conducted by the Bank of Italy every two years. The 2010 survey covered 13,702 individuals, while the 2008 survey covered 13,734 individuals. The following categorical variables are included in this data set: year of birth, working status, employment status, branch of activity, town size, geographical area of birth, sex, whether or not Italian national, and highest educational level obtained. Unique identifiers are available to assess the accuracy of one\u2019s method. Please see Steorts (2015) <DOI:10.1214/15-BA965SI> to find more details about the data set. ",
    "version": "0.1.0",
    "maintainer": "Rebecca Steorts <beka@stat.duke.edu>",
    "author": "Rebecca Steorts [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=italy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "italy The Italian Survey on Household and Wealth, 2008 and 2010 Provides two record linkage data sets on the Italian Survey on Household and Wealth, 2008 and 2010, a sample survey conducted by the Bank of Italy every two years. The 2010 survey covered 13,702 individuals, while the 2008 survey covered 13,734 individuals. The following categorical variables are included in this data set: year of birth, working status, employment status, branch of activity, town size, geographical area of birth, sex, whether or not Italian national, and highest educational level obtained. Unique identifiers are available to assess the accuracy of one\u2019s method. Please see Steorts (2015) <DOI:10.1214/15-BA965SI> to find more details about the data set.   "
  },
  {
    "id": 14676,
    "package_name": "jaatha",
    "title": "Simulation-Based Maximum Likelihood Parameter Estimation",
    "description": "An estimation method that can use computer simulations to\n    approximate maximum-likelihood estimates even when the likelihood function can not\n    be evaluated directly. It can be applied whenever it is feasible to conduct many\n    simulations, but works best when the data is approximately Poisson distributed.\n    It was originally designed for demographic inference in evolutionary\n    biology (Naduvilezhath et al., 2011 <doi:10.1111/j.1365-294X.2011.05131.x>,\n    Mathew et al., 2013 <doi:10.1002/ece3.722>).\n    It has optional support for conducting coalescent simulation using\n    the 'coala' package.",
    "version": "3.2.5",
    "maintainer": "Dirk Metzler <metzler@bio.lmu.de>",
    "author": "Paul Staab [aut],\n  Lisha Mathew [aut],\n  Dirk Metzler [aut, ths, cre]",
    "url": "https://github.com/statgenlmu/jaatha",
    "bug_reports": "https://github.com/statgenlmu/jaatha/issues",
    "repository": "https://cran.r-project.org/package=jaatha",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jaatha Simulation-Based Maximum Likelihood Parameter Estimation An estimation method that can use computer simulations to\n    approximate maximum-likelihood estimates even when the likelihood function can not\n    be evaluated directly. It can be applied whenever it is feasible to conduct many\n    simulations, but works best when the data is approximately Poisson distributed.\n    It was originally designed for demographic inference in evolutionary\n    biology (Naduvilezhath et al., 2011 <doi:10.1111/j.1365-294X.2011.05131.x>,\n    Mathew et al., 2013 <doi:10.1002/ece3.722>).\n    It has optional support for conducting coalescent simulation using\n    the 'coala' package.  "
  },
  {
    "id": 14680,
    "package_name": "jackalope",
    "title": "A Swift, Versatile Phylogenomic and High-Throughput Sequencing\nSimulator",
    "description": "Simply and efficiently\n    simulates (i) variants from reference genomes and (ii) reads from both Illumina \n    <https://www.illumina.com/>\n    and Pacific Biosciences (PacBio) <https://www.pacb.com/> platforms. \n    It can either read reference genomes from FASTA files or simulate new ones.\n    Genomic variants can be simulated using summary statistics, phylogenies, \n    Variant Call Format (VCF) files, and coalescent simulations\u2014the latter of which\n    can include selection, recombination, and demographic fluctuations.\n    'jackalope' can simulate single, paired-end, or mate-pair Illumina reads, \n    as well as PacBio reads.\n    These simulations include sequencing errors, mapping qualities, multiplexing,\n    and optical/polymerase chain reaction (PCR) duplicates.\n    Simulating Illumina sequencing is based on ART\n    by Huang et al. (2012) <doi:10.1093/bioinformatics/btr708>.\n    PacBio sequencing simulation is based on \n    SimLoRD  by St\u00f6cker et al. (2016) <doi:10.1093/bioinformatics/btw286>.\n    All outputs can be written to standard file formats.",
    "version": "1.1.6",
    "maintainer": "Lucas A. Nell <lucnell@gmail.com>",
    "author": "Lucas A. Nell [cph, aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3209-0517>)",
    "url": "https://github.com/lucasnell/jackalope",
    "bug_reports": "https://github.com/lucasnell/jackalope/issues",
    "repository": "https://cran.r-project.org/package=jackalope",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jackalope A Swift, Versatile Phylogenomic and High-Throughput Sequencing\nSimulator Simply and efficiently\n    simulates (i) variants from reference genomes and (ii) reads from both Illumina \n    <https://www.illumina.com/>\n    and Pacific Biosciences (PacBio) <https://www.pacb.com/> platforms. \n    It can either read reference genomes from FASTA files or simulate new ones.\n    Genomic variants can be simulated using summary statistics, phylogenies, \n    Variant Call Format (VCF) files, and coalescent simulations\u2014the latter of which\n    can include selection, recombination, and demographic fluctuations.\n    'jackalope' can simulate single, paired-end, or mate-pair Illumina reads, \n    as well as PacBio reads.\n    These simulations include sequencing errors, mapping qualities, multiplexing,\n    and optical/polymerase chain reaction (PCR) duplicates.\n    Simulating Illumina sequencing is based on ART\n    by Huang et al. (2012) <doi:10.1093/bioinformatics/btr708>.\n    PacBio sequencing simulation is based on \n    SimLoRD  by St\u00f6cker et al. (2016) <doi:10.1093/bioinformatics/btw286>.\n    All outputs can be written to standard file formats.  "
  },
  {
    "id": 14715,
    "package_name": "jipApprox",
    "title": "Approximate Inclusion Probabilities for Survey Sampling",
    "description": "Approximate joint-inclusion probabilities in Unequal Probability Sampling, or compute Monte Carlo approximations of the first and second-order inclusion probabilities of a general sampling design as in Fattorini (2006) <doi:10.1093/biomet/93.2.269>.",
    "version": "0.1.5",
    "maintainer": "Roberto Sichera <rob.sichera@gmail.com>",
    "author": "Roberto Sichera [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/rhobis/jipApprox/issues",
    "repository": "https://cran.r-project.org/package=jipApprox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jipApprox Approximate Inclusion Probabilities for Survey Sampling Approximate joint-inclusion probabilities in Unequal Probability Sampling, or compute Monte Carlo approximations of the first and second-order inclusion probabilities of a general sampling design as in Fattorini (2006) <doi:10.1093/biomet/93.2.269>.  "
  },
  {
    "id": 14738,
    "package_name": "jointCalib",
    "title": "A Joint Calibration of Totals and Quantiles",
    "description": "A small package containing functions to perform a joint calibration of totals and quantiles. The calibration for totals is based on Deville and S\u00e4rndal (1992) <doi:10.1080/01621459.1992.10475217>, the calibration for quantiles is based on Harms and Duchesne (2006) <https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X20060019255>. The package uses standard calibration via the 'survey', 'sampling' or 'laeken' packages. In addition, entropy balancing via the 'ebal' package and empirical likelihood based on codes from Wu (2005) <https://www150.statcan.gc.ca/n1/pub/12-001-x/2005002/article/9051-eng.pdf> can be used. See the paper by Ber\u0119sewicz and Szymkowiak (2023) for details <arXiv:2308.13281>.",
    "version": "0.1.0",
    "maintainer": "Maciej Ber\u0119sewicz <maciej.beresewicz@ue.poznan.pl>",
    "author": "Maciej Ber\u0119sewicz [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8281-4301>)",
    "url": "https://github.com/ncn-foreigners/jointCalib,\nhttps://ncn-foreigners.github.io/jointCalib/",
    "bug_reports": "https://github.com/ncn-foreigners/jointCalib/issues",
    "repository": "https://cran.r-project.org/package=jointCalib",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jointCalib A Joint Calibration of Totals and Quantiles A small package containing functions to perform a joint calibration of totals and quantiles. The calibration for totals is based on Deville and S\u00e4rndal (1992) <doi:10.1080/01621459.1992.10475217>, the calibration for quantiles is based on Harms and Duchesne (2006) <https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X20060019255>. The package uses standard calibration via the 'survey', 'sampling' or 'laeken' packages. In addition, entropy balancing via the 'ebal' package and empirical likelihood based on codes from Wu (2005) <https://www150.statcan.gc.ca/n1/pub/12-001-x/2005002/article/9051-eng.pdf> can be used. See the paper by Ber\u0119sewicz and Szymkowiak (2023) for details <arXiv:2308.13281>.  "
  },
  {
    "id": 14779,
    "package_name": "jstable",
    "title": "Create Tables from Different Types of Regression",
    "description": "Create regression tables from generalized linear model(GLM), generalized estimating equation(GEE), generalized linear mixed-effects model(GLMM), Cox proportional hazards model, survey-weighted generalized linear model(svyglm) and survey-weighted Cox model results for publication.",
    "version": "1.3.19",
    "maintainer": "Jinseob Kim <jinseob2kim@gmail.com>",
    "author": "Jinseob Kim [aut, cre] (ORCID: <https://orcid.org/0000-0002-9403-605X>),\n  Zarathu [cph, fnd],\n  Yoonkyoung Jeon [aut],\n  Jaehun Shon [aut],\n  Hyojong Myung [aut],\n  Hyungwoo Jo [aut],\n  Sungho Choi [aut],\n  Jaewoong Heo [aut],\n  Mingu Jee [aut],\n  Yujeong Yoon [aut],\n  Minhyuk Kim [aut]",
    "url": "https://github.com/jinseob2kim/jstable,\nhttps://jinseob2kim.github.io/jstable/",
    "bug_reports": "https://github.com/jinseob2kim/jstable/issues",
    "repository": "https://cran.r-project.org/package=jstable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jstable Create Tables from Different Types of Regression Create regression tables from generalized linear model(GLM), generalized estimating equation(GEE), generalized linear mixed-effects model(GLMM), Cox proportional hazards model, survey-weighted generalized linear model(svyglm) and survey-weighted Cox model results for publication.  "
  },
  {
    "id": 14783,
    "package_name": "jtools",
    "title": "Analysis and Presentation of Social Scientific Data",
    "description": "This is a collection of tools for more efficiently understanding \n  and sharing the results of (primarily) regression analyses. There are also a\n  number of miscellaneous functions for statistical and programming purposes. \n  Support for models produced by the survey and lme4 packages are points of \n  emphasis.",
    "version": "2.3.0",
    "maintainer": "Jacob A. Long <jacob.long@sc.edu>",
    "author": "Jacob A. Long [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1582-6214>)",
    "url": "https://jtools.jacob-long.com",
    "bug_reports": "https://github.com/jacob-long/jtools/issues",
    "repository": "https://cran.r-project.org/package=jtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "jtools Analysis and Presentation of Social Scientific Data This is a collection of tools for more efficiently understanding \n  and sharing the results of (primarily) regression analyses. There are also a\n  number of miscellaneous functions for statistical and programming purposes. \n  Support for models produced by the survey and lme4 packages are points of \n  emphasis.  "
  },
  {
    "id": 14817,
    "package_name": "kbal",
    "title": "Kernel Balancing",
    "description": "Provides a weighting approach that employs kernels to make one group have a similar distribution to another group on covariates. This method matches not only means or marginal distributions but also higher-order transformations implied by the choice of kernel. 'kbal' is applicable to both treatment effect estimation and survey reweighting problems. Based on Hazlett, C. (2020) \"Kernel Balancing: A flexible non-parametric weighting procedure for estimating causal effects.\" Statistica Sinica. <https://www.researchgate.net/publication/299013953_Kernel_Balancing_A_flexible_non-parametric_weighting_procedure_for_estimating_causal_effects>.",
    "version": "0.1.3",
    "maintainer": "Borna Bateni <borna@ucla.edu>",
    "author": "Chad Hazlett [aut, cph],\n  Ciara Sterbenz [aut],\n  Erin Hartman [ctb],\n  Alex Kravetz [ctb],\n  Borna Bateni [aut, cre]",
    "url": "https://github.com/chadhazlett/kbal",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=kbal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kbal Kernel Balancing Provides a weighting approach that employs kernels to make one group have a similar distribution to another group on covariates. This method matches not only means or marginal distributions but also higher-order transformations implied by the choice of kernel. 'kbal' is applicable to both treatment effect estimation and survey reweighting problems. Based on Hazlett, C. (2020) \"Kernel Balancing: A flexible non-parametric weighting procedure for estimating causal effects.\" Statistica Sinica. <https://www.researchgate.net/publication/299013953_Kernel_Balancing_A_flexible_non-parametric_weighting_procedure_for_estimating_causal_effects>.  "
  },
  {
    "id": 14879,
    "package_name": "kim",
    "title": "A Toolkit for Behavioral Scientists",
    "description": "A collection of functions for analyzing data typically collected \n    or used by behavioral scientists. Examples of the functions include\n    a function that compares groups in a factorial experimental design,\n    a function that conducts two-way analysis of variance (ANOVA),\n    and a function that cleans a data set generated by Qualtrics surveys.\n    Some of the functions will require installing additional package(s).\n    Such packages and other references are cited within the section\n    describing the relevant functions. Many functions in this package\n    rely heavily on these two popular R packages:\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Wickham et al. (2021) <https://CRAN.R-project.org/package=ggplot2>.",
    "version": "0.6.1",
    "maintainer": "Jin Kim <jinkim@aya.yale.edu>",
    "author": "Jin Kim [aut, cre] (ORCID: <https://orcid.org/0000-0002-5013-3958>)",
    "url": "https://github.com/jinkim3/kim, https://jinkim.science",
    "bug_reports": "https://github.com/jinkim3/kim/issues",
    "repository": "https://cran.r-project.org/package=kim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kim A Toolkit for Behavioral Scientists A collection of functions for analyzing data typically collected \n    or used by behavioral scientists. Examples of the functions include\n    a function that compares groups in a factorial experimental design,\n    a function that conducts two-way analysis of variance (ANOVA),\n    and a function that cleans a data set generated by Qualtrics surveys.\n    Some of the functions will require installing additional package(s).\n    Such packages and other references are cited within the section\n    describing the relevant functions. Many functions in this package\n    rely heavily on these two popular R packages:\n    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.\n    Wickham et al. (2021) <https://CRAN.R-project.org/package=ggplot2>.  "
  },
  {
    "id": 14916,
    "package_name": "knfi",
    "title": "Analysis of Korean National Forest Inventory Database",
    "description": "Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.",
    "version": "1.0.1.9",
    "maintainer": "Sinyoung Park <youngsin0306@kookmin.ac.kr>",
    "author": "Sinyoung Park [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3658-0935>),\n  Wonhee Cho [aut, ctb] (ORCID: <https://orcid.org/0000-0002-9598-6188>),\n  Inyoo Kim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-7709-8224>),\n  Wontaek Lim [aut, ctb] (ORCID: <https://orcid.org/0000-0002-5872-1121>),\n  Dongwook W. Ko [aut, ths] (ORCID:\n    <https://orcid.org/0000-0002-6944-0261>)",
    "url": "https://github.com/SYOUNG9836/knfi,\nhttps://syoung9836.github.io/knfi/",
    "bug_reports": "https://github.com/SYOUNG9836/knfi/issues",
    "repository": "https://cran.r-project.org/package=knfi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "knfi Analysis of Korean National Forest Inventory Database Understanding the current status of forest resources is essential for monitoring changes \n    in forest ecosystems and generating related statistics. In South Korea, the National Forest\n    Inventory (NFI) surveys over 4,500 sample plots nationwide every five years and records 70 items,\n    including forest stand, forest resource, and forest vegetation surveys. Many researchers use NFI \n    as the primary data for research, such as biomass estimation or analyzing the importance value of\n    each species over time and space, depending on the research purpose. However, the large volume\n    of accumulated forest survey data from across the country can make it challenging to manage and\n    utilize such a vast dataset. To address this issue, we developed an R package that efficiently\n    handles large-scale NFI data across time and space. The package offers a comprehensive \n    workflow for NFI data analysis. It starts with data processing, where read_nfi() function \n    reconstructs NFI data according to the researcher's needs while performing basic integrity checks\n    for data quality.Following this, the package provides analytical tools that operate on the verified\n    data. These include functions like summary_nfi() for summary statistics, diversity_nfi() for\n    biodiversity analysis, iv_nfi() for calculating species importance value, and biomass_nfi() and\n    cwd_biomass_nfi() for biomass estimation. Finally, for visualization, the tsvis_nfi() function\n    generates graphs and maps, allowing users to visualize forest ecosystem changes across various\n    spatial and temporal scales. This integrated approach and its specialized functions can enhance\n    the efficiency of processing and analyzing NFI data, providing researchers with insights into\n    forest ecosystems. The NFI Excel files (.xlsx) are not included in the R package and must be \n    downloaded  separately. Users can access these NFI Excel files by visiting \n    the Korea Forest Service Forestry Statistics Platform <https://kfss.forest.go.kr/stat/ptl/article/articleList.do?curMenu=11694&bbsId=microdataboard>\n    to download the annual NFI Excel files, which are bundled in .zip archives. Please note that this \n    website is only available in Korean, and direct download links can be found in the notes section \n    of the read_nfi() function.  "
  },
  {
    "id": 14967,
    "package_name": "kuzuR",
    "title": "Interface to 'kuzu' Graph Database",
    "description": "Provides a high-performance 'R' interface to the 'kuzu' graph database.\n    It uses the 'reticulate' package to wrap the official 'Python' client\n    ('kuzu', 'pandas', and 'networkx'), allowing users to interact with 'kuzu'\n    seamlessly from within 'R'. Key features include managing database\n    connections, executing 'Cypher' queries, and efficiently loading data from\n    'R' data frames. It also provides seamless integration with the 'R' ecosystem\n    by converting query results directly into popular 'R' data structures,\n    including 'tibble', 'igraph', 'tidygraph', and 'g6R' objects, making\n    'kuzu's powerful graph computation capabilities readily available for data\n    analysis and visualization workflows in 'R'.\n    The 'kuzu' documentation can be found at <https://kuzudb.github.io/docs/>.",
    "version": "0.2.3",
    "maintainer": "Manuel Wick-Eckl <manuel.wick@gmail.com>",
    "author": "Manuel Wick-Eckl [aut, cre]",
    "url": "https://github.com/WickM/kuzuR, https://wickm.github.io/kuzuR/",
    "bug_reports": "https://github.com/WickM/kuzuR/issues",
    "repository": "https://cran.r-project.org/package=kuzuR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "kuzuR Interface to 'kuzu' Graph Database Provides a high-performance 'R' interface to the 'kuzu' graph database.\n    It uses the 'reticulate' package to wrap the official 'Python' client\n    ('kuzu', 'pandas', and 'networkx'), allowing users to interact with 'kuzu'\n    seamlessly from within 'R'. Key features include managing database\n    connections, executing 'Cypher' queries, and efficiently loading data from\n    'R' data frames. It also provides seamless integration with the 'R' ecosystem\n    by converting query results directly into popular 'R' data structures,\n    including 'tibble', 'igraph', 'tidygraph', and 'g6R' objects, making\n    'kuzu's powerful graph computation capabilities readily available for data\n    analysis and visualization workflows in 'R'.\n    The 'kuzu' documentation can be found at <https://kuzudb.github.io/docs/>.  "
  },
  {
    "id": 15036,
    "package_name": "latent2likert",
    "title": "Converting Latent Variables into Likert Scale Responses",
    "description": "Effectively simulates the discretization process inherent to\n    Likert scales while minimizing distortion.  It converts continuous\n    latent variables into ordinal categories to generate Likert scale item\n    responses.  Particularly useful for accurately modeling and analyzing\n    survey data that use Likert scales, especially when applying\n    statistical techniques that require metric data.",
    "version": "1.2.1",
    "maintainer": "Marko Lalovic <marko@lalovic.io>",
    "author": "Marko Lalovic [aut, cre]",
    "url": "https://lalovic.io/latent2likert/",
    "bug_reports": "https://github.com/markolalovic/latent2likert/issues/",
    "repository": "https://cran.r-project.org/package=latent2likert",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "latent2likert Converting Latent Variables into Likert Scale Responses Effectively simulates the discretization process inherent to\n    Likert scales while minimizing distortion.  It converts continuous\n    latent variables into ordinal categories to generate Likert scale item\n    responses.  Particularly useful for accurately modeling and analyzing\n    survey data that use Likert scales, especially when applying\n    statistical techniques that require metric data.  "
  },
  {
    "id": 15125,
    "package_name": "lefko3",
    "title": "Historical and Ahistorical Population Projection Matrix Analysis",
    "description": "Complete analytical environment for the construction and analysis\n             of matrix population models and integral projection models.\n             Includes the ability to construct historical matrices, which are\n             2d matrices comprising 3 consecutive times of demographic\n             information. Estimates both raw and function-based forms of\n             historical and standard ahistorical matrices. It also estimates\n             function-based age-by-stage matrices and raw and function-based\n             Leslie matrices.",
    "version": "6.6.0",
    "maintainer": "Richard P. Shefferson <cdorm@g.ecc.u-tokyo.ac.jp>",
    "author": "Richard P. Shefferson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5234-3131>),\n  Johan Ehrlen [aut] (ORCID: <https://orcid.org/0000-0001-8539-8967>)",
    "url": "https://github.com/dormancy1/lefko3",
    "bug_reports": "https://github.com/dormancy1/lefko3/issues",
    "repository": "https://cran.r-project.org/package=lefko3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lefko3 Historical and Ahistorical Population Projection Matrix Analysis Complete analytical environment for the construction and analysis\n             of matrix population models and integral projection models.\n             Includes the ability to construct historical matrices, which are\n             2d matrices comprising 3 consecutive times of demographic\n             information. Estimates both raw and function-based forms of\n             historical and standard ahistorical matrices. It also estimates\n             function-based age-by-stage matrices and raw and function-based\n             Leslie matrices.  "
  },
  {
    "id": 15128,
    "package_name": "legislatoR",
    "title": "Interface to the Comparative Legislators Database",
    "description": "Facilitates access to the Comparative Legislators Database (CLD). The CLD includes political, sociodemographic, career, online presence, public attention, and visual information for over 67,000 contemporary and historical politicians from 16 countries.",
    "version": "1.1.0",
    "maintainer": "Sascha Goebel <sascha.goebel@soz.uni-frankfurt.de>",
    "author": "Sascha Goebel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9032-5874>),\n  Simon Munzert [aut]",
    "url": "https://github.com/saschagobel/legislatoR",
    "bug_reports": "https://github.com/saschagobel/legislatoR/issues",
    "repository": "https://cran.r-project.org/package=legislatoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "legislatoR Interface to the Comparative Legislators Database Facilitates access to the Comparative Legislators Database (CLD). The CLD includes political, sociodemographic, career, online presence, public attention, and visual information for over 67,000 contemporary and historical politicians from 16 countries.  "
  },
  {
    "id": 15130,
    "package_name": "lehdr",
    "title": "Grab Longitudinal Employer-Household Dynamics (LEHD) Flat Files",
    "description": "Designed to query Longitudinal Employer-Household Dynamics (LEHD) \n    workplace/residential association and origin-destination flat files and \n    optionally aggregate Census block-level data to block group, tract, county, \n    or state. Data comes from the LODES FTP server <https://lehd.ces.census.gov/data/lodes/LODES8/>.",
    "version": "1.1.4",
    "maintainer": "Jamaal Green <jamaal.green@gmail.com>",
    "author": "Jamaal Green [cre, aut],\n  Liming Wang [aut],\n  Dillon Mahmoudi [aut],\n  Matthew Rogers [ctb],\n  Kyle Walker [ctb]",
    "url": "https://github.com/jamgreen/lehdr/",
    "bug_reports": "https://github.com/jamgreen/lehdr/issues/",
    "repository": "https://cran.r-project.org/package=lehdr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lehdr Grab Longitudinal Employer-Household Dynamics (LEHD) Flat Files Designed to query Longitudinal Employer-Household Dynamics (LEHD) \n    workplace/residential association and origin-destination flat files and \n    optionally aggregate Census block-level data to block group, tract, county, \n    or state. Data comes from the LODES FTP server <https://lehd.ces.census.gov/data/lodes/LODES8/>.  "
  },
  {
    "id": 15189,
    "package_name": "lifecontingencies",
    "title": "Financial and Actuarial Mathematics for Life Contingencies",
    "description": "Classes and methods that allow the user to manage life table,\n    actuarial tables (also multiple decrements tables). Moreover, functions to easily\n    perform demographic, financial and actuarial mathematics on life contingencies\n    insurances calculations are contained therein. See Spedicato (2013)\t<doi:10.18637/jss.v055.i10>.",
    "version": "1.4.4",
    "maintainer": "Giorgio Alfredo Spedicato <spedicato_giorgio@yahoo.it>",
    "author": "Giorgio Alfredo Spedicato [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0315-8888>),\n  Christophe Dutang [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6732-1501>),\n  Reinhold Kainhofer [ctb] (ORCID:\n    <https://orcid.org/0000-0002-7895-1311>),\n  Kevin J Owens [ctb],\n  Ernesto Schirmacher [ctb],\n  Gian Paolo Clemente [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6795-4595>),\n  Ivan Williams [ctb]",
    "url": "https://github.com/spedygiorgio/lifecontingencies",
    "bug_reports": "https://github.com/spedygiorgio/lifecontingencies/issues",
    "repository": "https://cran.r-project.org/package=lifecontingencies",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lifecontingencies Financial and Actuarial Mathematics for Life Contingencies Classes and methods that allow the user to manage life table,\n    actuarial tables (also multiple decrements tables). Moreover, functions to easily\n    perform demographic, financial and actuarial mathematics on life contingencies\n    insurances calculations are contained therein. See Spedicato (2013)\t<doi:10.18637/jss.v055.i10>.  "
  },
  {
    "id": 15209,
    "package_name": "limonaid",
    "title": "Working with 'LimeSurvey' Surveys and Responses",
    "description": "'LimeSurvey' is Free/Libre Open Source Software for\n  the development and administrations of online studies, using\n  sophisticated tailoring capabilities to support multiple study\n  designs (see <https://www.limesurvey.org>). This package supports\n  programmatic creation of surveys that can then be imported into\n  'LimeSurvey', as well as user friendly import of responses from\n  'LimeSurvey' studies.",
    "version": "25.5.5",
    "maintainer": "Gjalt-Jorn Peters <limonaid@opens.science>",
    "author": "Gjalt-Jorn Peters [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0336-9589>),\n  Andrew Heiss [aut] (ORCID: <https://orcid.org/0000-0002-3948-3914>),\n  Urs Wilke [aut] (ORCID: <https://orcid.org/0000-0001-7257-2524>)",
    "url": "https://limonaid.opens.science",
    "bug_reports": "https://codeberg.org/R-packages/limonaid/issues",
    "repository": "https://cran.r-project.org/package=limonaid",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "limonaid Working with 'LimeSurvey' Surveys and Responses 'LimeSurvey' is Free/Libre Open Source Software for\n  the development and administrations of online studies, using\n  sophisticated tailoring capabilities to support multiple study\n  designs (see <https://www.limesurvey.org>). This package supports\n  programmatic creation of surveys that can then be imported into\n  'LimeSurvey', as well as user friendly import of responses from\n  'LimeSurvey' studies.  "
  },
  {
    "id": 15245,
    "package_name": "list",
    "title": "Statistical Methods for the Item Count Technique and List\nExperiment",
    "description": "Allows researchers to conduct multivariate\n    statistical analyses of survey data with list experiments. This\n    survey methodology is also known as the item count technique or\n    the unmatched count technique and is an alternative to the commonly\n    used randomized response method. The package implements the methods\n    developed by Imai (2011) <doi:10.1198/jasa.2011.ap10415>, \n    Blair and Imai (2012) <doi:10.1093/pan/mpr048>, \n    Blair, Imai, and Lyall (2013) <doi:10.1111/ajps.12086>, \n    Imai, Park, and Greene (2014) <doi:10.1093/pan/mpu017>,\n    Aronow, Coppock, Crawford, and Green (2015) <doi:10.1093/jssam/smu023>, \n    Chou, Imai, and Rosenfeld (2017) <doi:10.1177/0049124117729711>, and \n    Blair, Chou, and Imai (2018) <https://imai.fas.harvard.edu/research/files/listerror.pdf>. \n    This includes a Bayesian MCMC implementation of regression for the \n    standard and multiple sensitive item list experiment designs and a \n    random effects setup, a Bayesian MCMC hierarchical regression model \n    with up to three hierarchical groups, the combined list experiment \n    and endorsement experiment regression model, a joint model of the \n    list experiment that enables the analysis of the list experiment as \n    a predictor in outcome regression models, a method for combining \n    list experiments with direct questions, and methods for diagnosing and\n    adjusting for response error. In addition, the package implements the \n    statistical test that is designed to detect certain failures of list \n    experiments, and a placebo test for the list experiment using data from \n    direct questions.",
    "version": "9.2.6",
    "maintainer": "Graeme Blair <graeme.blair@gmail.com>",
    "author": "Graeme Blair [aut, cre],\n  Winston Chou [aut],\n  Kosuke Imai [aut],\n  Bethany Park [ctb],\n  Alexander Coppock [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=list",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "list Statistical Methods for the Item Count Technique and List\nExperiment Allows researchers to conduct multivariate\n    statistical analyses of survey data with list experiments. This\n    survey methodology is also known as the item count technique or\n    the unmatched count technique and is an alternative to the commonly\n    used randomized response method. The package implements the methods\n    developed by Imai (2011) <doi:10.1198/jasa.2011.ap10415>, \n    Blair and Imai (2012) <doi:10.1093/pan/mpr048>, \n    Blair, Imai, and Lyall (2013) <doi:10.1111/ajps.12086>, \n    Imai, Park, and Greene (2014) <doi:10.1093/pan/mpu017>,\n    Aronow, Coppock, Crawford, and Green (2015) <doi:10.1093/jssam/smu023>, \n    Chou, Imai, and Rosenfeld (2017) <doi:10.1177/0049124117729711>, and \n    Blair, Chou, and Imai (2018) <https://imai.fas.harvard.edu/research/files/listerror.pdf>. \n    This includes a Bayesian MCMC implementation of regression for the \n    standard and multiple sensitive item list experiment designs and a \n    random effects setup, a Bayesian MCMC hierarchical regression model \n    with up to three hierarchical groups, the combined list experiment \n    and endorsement experiment regression model, a joint model of the \n    list experiment that enables the analysis of the list experiment as \n    a predictor in outcome regression models, a method for combining \n    list experiments with direct questions, and methods for diagnosing and\n    adjusting for response error. In addition, the package implements the \n    statistical test that is designed to detect certain failures of list \n    experiments, and a placebo test for the list experiment using data from \n    direct questions.  "
  },
  {
    "id": 15255,
    "package_name": "litRiddle",
    "title": "Dataset and Tools to Research the Riddle of Literary Quality",
    "description": "Dataset and functions to explore quality of literary novels. The package is a part of the Riddle of Literary Quality project, and it contains the data of a reader survey about fiction in Dutch, a description of the novels the readers rated, and the results of stylistic measurements of the novels. The package also contains functions to combine, analyze, and visualize these data. For more details, see: Eder M, van Zundert J, Lensink S, van Dalen-Oskam K (2022). Replicating The Riddle of Literary Quality: The litRiddle package for R. In _Digital Humanities 2022: Conference Abstracts_, 636-637.",
    "version": "1.0.0",
    "maintainer": "Maciej Eder <maciejeder@gmail.com>",
    "author": "Maciej Eder [aut, cre],\n  Joris van Zundert [aut],\n  Karina van Dalen-Oskam [aut],\n  Saskia Lensink [aut]",
    "url": "https://literaryquality.huygens.knaw.nl/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=litRiddle",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "litRiddle Dataset and Tools to Research the Riddle of Literary Quality Dataset and functions to explore quality of literary novels. The package is a part of the Riddle of Literary Quality project, and it contains the data of a reader survey about fiction in Dutch, a description of the novels the readers rated, and the results of stylistic measurements of the novels. The package also contains functions to combine, analyze, and visualize these data. For more details, see: Eder M, van Zundert J, Lensink S, van Dalen-Oskam K (2022). Replicating The Riddle of Literary Quality: The litRiddle package for R. In _Digital Humanities 2022: Conference Abstracts_, 636-637.  "
  },
  {
    "id": 15319,
    "package_name": "localboot",
    "title": "Local Bootstrap Methods for Various Networks",
    "description": "Network analysis usually requires estimating the uncertainty of\n    graph statistics. Through this package, we provide tools to bootstrap \n    various networks via local bootstrap procedure. Additionally, it includes \n    functions for generating probability matrices, creating network adjacency \n    matrices from probability matrices, and plotting network structures. \n    The reference will be updated soon.",
    "version": "0.9.2",
    "maintainer": "Tianhai Zu <zuti@mail.uc.edu>",
    "author": "Tianhai Zu [aut, cre],\n  Yichen Qin [aut, ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=localboot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "localboot Local Bootstrap Methods for Various Networks Network analysis usually requires estimating the uncertainty of\n    graph statistics. Through this package, we provide tools to bootstrap \n    various networks via local bootstrap procedure. Additionally, it includes \n    functions for generating probability matrices, creating network adjacency \n    matrices from probability matrices, and plotting network structures. \n    The reference will be updated soon.  "
  },
  {
    "id": 15362,
    "package_name": "logmult",
    "title": "Log-Multiplicative Models, Including Association Models",
    "description": "Functions to fit log-multiplicative models using 'gnm', with\n  support for convenient printing, plots, and jackknife/bootstrap\n  standard errors. For complex survey data, models can be fitted from\n  design objects from the 'survey' package. Currently supported models\n  include UNIDIFF (Erikson & Goldthorpe, 1992),\n  a.k.a. log-multiplicative layer effect model (Xie, 1992)\n  <doi:10.2307/2096242>, and several association models:\n  Goodman (1979) <doi:10.2307/2286971>\n  row-column association models of the RC(M) and RC(M)-L families\n  with one or several dimensions; two skew-symmetric association\n  models proposed by Yamaguchi (1990) <doi:10.2307/271086>\n  and by van der Heijden & Mooijaart (1995) <doi:10.1177/0049124195024001002>\n  Functions allow computing the intrinsic association coefficient\n  (see Bouchet-Valat (2022) <doi:10.1177/0049124119852389>)\n  and the Altham (1970) index <doi:10.1111/j.2517-6161.1970.tb00816.x>,\n  including via the Bayes shrinkage estimator proposed\n  by Zhou (2015) <doi:10.1177/0081175015570097>;\n  and the RAS/IPF/Deming-Stephan algorithm.",
    "version": "0.7.5",
    "maintainer": "Milan Bouchet-Valat <nalimilan@club.fr>",
    "author": "Milan Bouchet-Valat [aut, cre],\n  Heather Turner [ctb],\n  Michael Friendly [ctb],\n  Jim Lemon [cph],\n  Gabor Csardi [cph]",
    "url": "https://github.com/nalimilan/logmult",
    "bug_reports": "https://github.com/nalimilan/logmult/issues",
    "repository": "https://cran.r-project.org/package=logmult",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "logmult Log-Multiplicative Models, Including Association Models Functions to fit log-multiplicative models using 'gnm', with\n  support for convenient printing, plots, and jackknife/bootstrap\n  standard errors. For complex survey data, models can be fitted from\n  design objects from the 'survey' package. Currently supported models\n  include UNIDIFF (Erikson & Goldthorpe, 1992),\n  a.k.a. log-multiplicative layer effect model (Xie, 1992)\n  <doi:10.2307/2096242>, and several association models:\n  Goodman (1979) <doi:10.2307/2286971>\n  row-column association models of the RC(M) and RC(M)-L families\n  with one or several dimensions; two skew-symmetric association\n  models proposed by Yamaguchi (1990) <doi:10.2307/271086>\n  and by van der Heijden & Mooijaart (1995) <doi:10.1177/0049124195024001002>\n  Functions allow computing the intrinsic association coefficient\n  (see Bouchet-Valat (2022) <doi:10.1177/0049124119852389>)\n  and the Altham (1970) index <doi:10.1111/j.2517-6161.1970.tb00816.x>,\n  including via the Bayes shrinkage estimator proposed\n  by Zhou (2015) <doi:10.1177/0081175015570097>;\n  and the RAS/IPF/Deming-Stephan algorithm.  "
  },
  {
    "id": 15404,
    "package_name": "lorenz",
    "title": "Tools for Deriving Income Inequality Estimates from Grouped\nIncome Data",
    "description": "Provides two methods of estimating income inequality statistics from binned income data, such as the income data provided in the Census.\n  These methods use different interpolation techniques to infer the distribution of incomes within income bins.  One method is an implementation of \n  Jargowsky and Wheeler's mean-constrained integration over brackets (MCIB).  The other method is based on a new technique, Lorenz interpolation, \n  which estimates income inequality by constructing an interpolated Lorenz curve based on the binned income data.  These methods can be used to \n  estimate three income inequality measures: the Gini (the default measure returned), the Theil, and the Atkinson's index.  \n  Jargowsky and Wheeler (2018) <doi:10.1177/0081175018782579>.",
    "version": "0.1.0",
    "maintainer": "Andrew Carr <andrew.carr@duke.edu>",
    "author": "Andrew Carr [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lorenz",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lorenz Tools for Deriving Income Inequality Estimates from Grouped\nIncome Data Provides two methods of estimating income inequality statistics from binned income data, such as the income data provided in the Census.\n  These methods use different interpolation techniques to infer the distribution of incomes within income bins.  One method is an implementation of \n  Jargowsky and Wheeler's mean-constrained integration over brackets (MCIB).  The other method is based on a new technique, Lorenz interpolation, \n  which estimates income inequality by constructing an interpolated Lorenz curve based on the binned income data.  These methods can be used to \n  estimate three income inequality measures: the Gini (the default measure returned), the Theil, and the Atkinson's index.  \n  Jargowsky and Wheeler (2018) <doi:10.1177/0081175018782579>.  "
  },
  {
    "id": 15417,
    "package_name": "lpdensity",
    "title": "Local Polynomial Density Estimation and Inference",
    "description": "Without imposing stringent distributional assumptions or shape restrictions, nonparametric estimation has been popular in economics and other social sciences for counterfactual analysis, program evaluation, and policy recommendations. This package implements a novel density (and derivatives) estimator based on local polynomial regressions, documented in Cattaneo, Jansson and Ma (2022) <doi:10.18637/jss.v101.i02>: lpdensity() to construct local polynomial based density (and derivatives) estimator, and lpbwdensity() to perform data-driven bandwidth selection. ",
    "version": "2.5",
    "maintainer": "Xinwei Ma <x1ma@ucsd.edu>",
    "author": "Matias D. Cattaneo [aut],\n  Michael Jansson [aut],\n  Xinwei Ma [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lpdensity",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lpdensity Local Polynomial Density Estimation and Inference Without imposing stringent distributional assumptions or shape restrictions, nonparametric estimation has been popular in economics and other social sciences for counterfactual analysis, program evaluation, and policy recommendations. This package implements a novel density (and derivatives) estimator based on local polynomial regressions, documented in Cattaneo, Jansson and Ma (2022) <doi:10.18637/jss.v101.i02>: lpdensity() to construct local polynomial based density (and derivatives) estimator, and lpbwdensity() to perform data-driven bandwidth selection.   "
  },
  {
    "id": 15458,
    "package_name": "lucas",
    "title": "Package to Download and Create the DB of LUCAS Data Harmonized",
    "description": "Reproduces the harmonized DB of the ESTAT survey of the same name. The survey data is served as separate spreadsheets with noticeable differences in the collected attributes. The tool here presented carries out a series of instructions that harmonize the attributes in terms of name, meaning, and occurrence, while also introducing a series of new variables, instrumental to adding value to the product. Outputs include one harmonized table with all the years, and three separate geometries, corresponding to the theoretical point, the gps location where the measurement was made and the 250m east-facing transect.",
    "version": "1.0",
    "maintainer": "Momchil Yordanov <momchilyordanov@abv.bg>",
    "author": "Momchil Yordanov [cre],\n  Laura Martinez [aut],\n  Raphael dAndrimont [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=lucas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "lucas Package to Download and Create the DB of LUCAS Data Harmonized Reproduces the harmonized DB of the ESTAT survey of the same name. The survey data is served as separate spreadsheets with noticeable differences in the collected attributes. The tool here presented carries out a series of instructions that harmonize the attributes in terms of name, meaning, and occurrence, while also introducing a series of new variables, instrumental to adding value to the product. Outputs include one harmonized table with all the years, and three separate geometries, corresponding to the theoretical point, the gps location where the measurement was made and the 250m east-facing transect.  "
  },
  {
    "id": 15492,
    "package_name": "mMARCH.AC",
    "title": "Processing of Accelerometry Data with 'GGIR' in mMARCH",
    "description": "Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.",
    "version": "3.2.0.1",
    "maintainer": "Wei Guo <wei.guo3@nih.gov>",
    "author": "Wei Guo [aut, cre],\n  Andrew Leroux [aut],\n  Vadim Zipunnikov [aut],\n  Kathleen Merikangas [aut]",
    "url": "https://github.com/WeiGuoNIMH/mMARCH.AC",
    "bug_reports": "https://github.com/WeiGuoNIMH/mMARCH.AC/issues",
    "repository": "https://cran.r-project.org/package=mMARCH.AC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mMARCH.AC Processing of Accelerometry Data with 'GGIR' in mMARCH Mobile Motor Activity Research Consortium for Health (mMARCH) is a collaborative network of studies of clinical and community samples that employ common clinical, biological, and digital mobile measures across involved studies. One of the main scientific goals of mMARCH sites is developing a better understanding of the inter-relationships between accelerometry-measured physical activity (PA), sleep (SL), and circadian rhythmicity (CR) and mental and physical health in children, adolescents, and adults. Currently, there is no consensus on a standard procedure for a data processing pipeline of raw accelerometry data, and few open-source tools to facilitate their development. The R package 'GGIR' is the most prominent open-source software package that offers great functionality and tremendous user flexibility to process raw accelerometry data. However, even with 'GGIR', processing done in a harmonized and reproducible fashion requires a non-trivial amount of expertise combined with a careful implementation. In addition, novel accelerometry-derived features of PA/SL/CR capturing multiscale, time-series, functional, distributional and other complimentary aspects of accelerometry data being constantly proposed and become available via non-GGIR R implementations.  To address these issues, mMARCH developed a streamlined harmonized and reproducible pipeline for loading and cleaning raw accelerometry data, extracting features available through 'GGIR' as well as through non-GGIR R packages, implementing several data and feature quality checks, merging all features of PA/SL/CR together, and performing multiple analyses including Joint Individual Variation Explained (JIVE), an unsupervised machine learning dimension reduction technique that identifies latent factors capturing joint across and individual to each of three domains of PA/SL/CR.  In detail, the pipeline generates all necessary R/Rmd/shell files for data processing after running 'GGIR' for accelerometer data. In module 1, all csv files in the 'GGIR' output directory were read, transformed and then merged. In module 2, the 'GGIR' output files were checked and summarized in one excel sheet. In module 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In module 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.  Reference: Guo W, Leroux A, Shou S, Cui L, Kang S, Strippoli MP, Preisig M, Zipunnikov V, Merikangas K (2022) Processing of accelerometry data with GGIR in Motor Activity Research Consortium for Health (mMARCH) Journal for the Measurement of Physical Behaviour, 6(1): 37-44.  "
  },
  {
    "id": 15512,
    "package_name": "mactivate",
    "title": "Multiplicative Activation",
    "description": "Provides methods and classes for adding m-activation (\"multiplicative activation\") layers to MLR or multivariate logistic regression models.  M-activation layers created in this library detect and add input interaction (polynomial) effects into a predictive model.  M-activation can detect high-order interactions -- a traditionally non-trivial challenge.  Details concerning application, methodology, and relevant survey literature can be found in this library's vignette, \"About.\"",
    "version": "0.6.6",
    "maintainer": "Dave Zes <zesdave@gmail.com>",
    "author": "Dave Zes",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mactivate",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mactivate Multiplicative Activation Provides methods and classes for adding m-activation (\"multiplicative activation\") layers to MLR or multivariate logistic regression models.  M-activation layers created in this library detect and add input interaction (polynomial) effects into a predictive model.  M-activation can detect high-order interactions -- a traditionally non-trivial challenge.  Details concerning application, methodology, and relevant survey literature can be found in this library's vignette, \"About.\"  "
  },
  {
    "id": 15550,
    "package_name": "malariaAtlas",
    "title": "An R Interface to Open-Access Malaria Data, Hosted by the\n'Malaria Atlas Project'",
    "description": "A suite of tools to allow you to download all \n  publicly available parasite rate survey points, mosquito occurrence points and raster surfaces from \n  the 'Malaria Atlas Project' <https://malariaatlas.org/> servers as well as utility functions for plotting\n  the downloaded data.",
    "version": "1.6.4",
    "maintainer": "Mauricio van den Berg <mauricio.vandenberg@thekids.org.au>",
    "author": "Mauricio van den Berg [aut, cre],\n  Daniel Pfeffer [aut] (ORCID: <https://orcid.org/0000-0002-2204-3488>),\n  Tim Lucas [aut] (ORCID: <https://orcid.org/0000-0003-4694-8107>),\n  Daniel May [aut] (ORCID: <https://orcid.org/0000-0003-0005-2452>),\n  Suzanne Keddie [aut] (ORCID: <https://orcid.org/0000-0003-1254-7794>),\n  Jen Rozier [aut] (ORCID: <https://orcid.org/0000-0002-2610-7557>),\n  Oliver Watson [aut] (ORCID: <https://orcid.org/0000-0003-2374-0741>),\n  Harry Gibson [aut] (ORCID: <https://orcid.org/0000-0001-6779-3250>),\n  Nick Golding [ctb],\n  David Smith [ctb]",
    "url": "https://github.com/malaria-atlas-project/malariaAtlas",
    "bug_reports": "https://github.com/malaria-atlas-project/malariaAtlas/issues",
    "repository": "https://cran.r-project.org/package=malariaAtlas",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "malariaAtlas An R Interface to Open-Access Malaria Data, Hosted by the\n'Malaria Atlas Project' A suite of tools to allow you to download all \n  publicly available parasite rate survey points, mosquito occurrence points and raster surfaces from \n  the 'Malaria Atlas Project' <https://malariaatlas.org/> servers as well as utility functions for plotting\n  the downloaded data.  "
  },
  {
    "id": 15567,
    "package_name": "mantar",
    "title": "Missingness Alleviation for Network Analysis",
    "description": "Provides functionality for estimating cross-sectional network structures representing partial correlations in R, while accounting for missing values in the data. Networks are estimated via neighborhood selection, i.e., node-wise multiple regression, with model selection guided by information criteria. Missing data can be handled primarily via multiple imputation or a maximum likelihood-based approach; deletion techniques are available but secondary <doi:10.31234/osf.io/qpj35>.",
    "version": "0.1.0",
    "maintainer": "Kai Jannik Nehler <nehler@psych.uni-frankfurt.de>",
    "author": "Kai Jannik Nehler [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3764-761X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mantar",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mantar Missingness Alleviation for Network Analysis Provides functionality for estimating cross-sectional network structures representing partial correlations in R, while accounting for missing values in the data. Networks are estimated via neighborhood selection, i.e., node-wise multiple regression, with model selection guided by information criteria. Missing data can be handled primarily via multiple imputation or a maximum likelihood-based approach; deletion techniques are available but secondary <doi:10.31234/osf.io/qpj35>.  "
  },
  {
    "id": 15572,
    "package_name": "manynet",
    "title": "Many Ways to Make, Modify, Mark, and Measure Myriad Networks",
    "description": "Many tools for making, modifying, marking, measuring, \n   and motifs and memberships of many different types of networks.\n   All functions operate with matrices, edge lists, and 'igraph', 'network', and 'tidygraph' objects,\n   on directed, multiplex, multimodal, signed, and other networks.\n   The package includes functions for importing and exporting, creating and generating networks,\n   modifying networks and node and tie attributes,\n   and describing networks with sensible defaults.",
    "version": "1.7.0",
    "maintainer": "James Hollway <james.hollway@graduateinstitute.ch>",
    "author": "James Hollway [cre, aut, ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0002-8361-9647>),\n  Henrique Sposito [ctb] (ORCID: <https://orcid.org/0000-0003-3420-6085>),\n  Christian Steglich [ctb]",
    "url": "https://stocnet.github.io/manynet/",
    "bug_reports": "https://github.com/stocnet/manynet/issues",
    "repository": "https://cran.r-project.org/package=manynet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "manynet Many Ways to Make, Modify, Mark, and Measure Myriad Networks Many tools for making, modifying, marking, measuring, \n   and motifs and memberships of many different types of networks.\n   All functions operate with matrices, edge lists, and 'igraph', 'network', and 'tidygraph' objects,\n   on directed, multiplex, multimodal, signed, and other networks.\n   The package includes functions for importing and exporting, creating and generating networks,\n   modifying networks and node and tie attributes,\n   and describing networks with sensible defaults.  "
  },
  {
    "id": 15576,
    "package_name": "mapStats",
    "title": "Geographic Display of Survey Data Statistics",
    "description": "Automated calculation and visualization of survey data statistics on a color-coded (choropleth) map.",
    "version": "3.2",
    "maintainer": "Samuel Ackerman <smackrmn@gmail.com>",
    "author": "Samuel Ackerman [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mapStats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mapStats Geographic Display of Survey Data Statistics Automated calculation and visualization of survey data statistics on a color-coded (choropleth) map.  "
  },
  {
    "id": 15641,
    "package_name": "mase",
    "title": "Model-Assisted Survey Estimators",
    "description": "A set of model-assisted survey estimators and corresponding\n    variance estimators for single stage, unequal probability, without replacement\n    sampling designs.  All of the estimators can be written as a generalized \n    regression estimator with the Horvitz-Thompson, ratio, post-stratified, and \n    regression estimators summarized by Sarndal et al. (1992, ISBN:978-0-387-40620-6).\n    Two of the estimators employ a statistical learning model as the assisting model:\n    the elastic net regression estimator, which is an extension of the lasso regression\n    estimator given by McConville et al. (2017) <doi:10.1093/jssam/smw041>, and the \n    regression tree estimator described in McConville and Toth (2017) <arXiv:1712.05708>. \n    The variance estimators which approximate the joint inclusion probabilities can\n    be found in Berger and Tille (2009) <doi:10.1016/S0169-7161(08)00002-3> and the\n    bootstrap variance estimator is presented in Mashreghi et al. (2016) \n    <doi:10.1214/16-SS113>.",
    "version": "0.1.5.2",
    "maintainer": "Kelly McConville <kmcconville@fas.harvard.edu>",
    "author": "Kelly McConville [cre, aut, cph],\n  Josh Yamamoto [aut],\n  Becky Tang [aut],\n  George Zhu [aut],\n  Sida Li [ctb],\n  Shirley Chueng [ctb],\n  Daniell Toth [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mase",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mase Model-Assisted Survey Estimators A set of model-assisted survey estimators and corresponding\n    variance estimators for single stage, unequal probability, without replacement\n    sampling designs.  All of the estimators can be written as a generalized \n    regression estimator with the Horvitz-Thompson, ratio, post-stratified, and \n    regression estimators summarized by Sarndal et al. (1992, ISBN:978-0-387-40620-6).\n    Two of the estimators employ a statistical learning model as the assisting model:\n    the elastic net regression estimator, which is an extension of the lasso regression\n    estimator given by McConville et al. (2017) <doi:10.1093/jssam/smw041>, and the \n    regression tree estimator described in McConville and Toth (2017) <arXiv:1712.05708>. \n    The variance estimators which approximate the joint inclusion probabilities can\n    be found in Berger and Tille (2009) <doi:10.1016/S0169-7161(08)00002-3> and the\n    bootstrap variance estimator is presented in Mashreghi et al. (2016) \n    <doi:10.1214/16-SS113>.  "
  },
  {
    "id": 15758,
    "package_name": "mcmcse",
    "title": "Monte Carlo Standard Errors for MCMC",
    "description": "Provides tools for computing Monte Carlo standard errors (MCSE) in\n    Markov chain Monte Carlo (MCMC) settings (survey in <doi:10.1201/b10905>,\n    Chapter 7). MCSE computation for expectation and quantile estimators is\n    supported as well as multivariate estimations. The package also provides\n    functions for computing effective sample size and for plotting Monte Carlo\n    estimates versus sample size.",
    "version": "1.5-1",
    "maintainer": "Dootika Vats <dootika@iitk.ac.in>",
    "author": "James M. Flegal [aut],\n  John Hughes [aut],\n  Dootika Vats [aut, cre],\n  Ning Dai [aut],\n  Kushagra Gupta [aut],\n  Uttiya Maji [aut]",
    "url": "https://github.com/dvats/mcmcse",
    "bug_reports": "https://github.com/dvats/mcmcse/issues",
    "repository": "https://cran.r-project.org/package=mcmcse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcmcse Monte Carlo Standard Errors for MCMC Provides tools for computing Monte Carlo standard errors (MCSE) in\n    Markov chain Monte Carlo (MCMC) settings (survey in <doi:10.1201/b10905>,\n    Chapter 7). MCSE computation for expectation and quantile estimators is\n    supported as well as multivariate estimations. The package also provides\n    functions for computing effective sample size and for plotting Monte Carlo\n    estimates versus sample size.  "
  },
  {
    "id": 15760,
    "package_name": "mcmsupply",
    "title": "Estimating Public and Private Sector Contraceptive Market Supply\nShares",
    "description": "Family Planning programs and initiatives typically use nationally representative surveys to estimate key indicators of a country\u2019s family planning progress. However, in recent years, routinely collected family planning services data (Service Statistics) have been used as a supplementary data source to bridge gaps in the surveys. The use of service statistics comes with the caveat that adjustments need to be made for missing private sector contributions to the contraceptive method supply chain. Evaluating the supply source of modern contraceptives often relies on Demographic Health Surveys (DHS), where many countries do not have recent data beyond 2015/16. Fortunately, in the absence of recent surveys we can rely on statistical model-based estimates and projections to fill the knowledge gap. We present a Bayesian, hierarchical, penalized-spline model with multivariate-normal spline coefficients, to account for across method correlations, to produce country-specific,annual estimates for the proportion of modern contraceptive methods coming from the public and private sectors. This package provides a quick and convenient way for users to access the DHS modern contraceptive supply share data at national and subnational administration levels, estimate, evaluate and plot annual estimates with uncertainty for a sample of low- and middle-income countries. Methods for the estimation of method supply shares at the national level are described in Comiskey, Alkema, Cahill (2022) <arXiv:2212.03844>.",
    "version": "1.1.1",
    "maintainer": "Hannah Comiskey <hannah.comiskey.2015@mumail.ie>",
    "author": "Hannah Comiskey [aut, cre],\n  Niamh Cahill [aut],\n  Leontine Alkema [aut]",
    "url": "https://hannahcomiskey.github.io/mcmsupply/,\nhttps://hannahcomiskey.github.io/mcmsupply/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mcmsupply",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcmsupply Estimating Public and Private Sector Contraceptive Market Supply\nShares Family Planning programs and initiatives typically use nationally representative surveys to estimate key indicators of a country\u2019s family planning progress. However, in recent years, routinely collected family planning services data (Service Statistics) have been used as a supplementary data source to bridge gaps in the surveys. The use of service statistics comes with the caveat that adjustments need to be made for missing private sector contributions to the contraceptive method supply chain. Evaluating the supply source of modern contraceptives often relies on Demographic Health Surveys (DHS), where many countries do not have recent data beyond 2015/16. Fortunately, in the absence of recent surveys we can rely on statistical model-based estimates and projections to fill the knowledge gap. We present a Bayesian, hierarchical, penalized-spline model with multivariate-normal spline coefficients, to account for across method correlations, to produce country-specific,annual estimates for the proportion of modern contraceptive methods coming from the public and private sectors. This package provides a quick and convenient way for users to access the DHS modern contraceptive supply share data at national and subnational administration levels, estimate, evaluate and plot annual estimates with uncertainty for a sample of low- and middle-income countries. Methods for the estimation of method supply shares at the national level are described in Comiskey, Alkema, Cahill (2022) <arXiv:2212.03844>.  "
  },
  {
    "id": 15777,
    "package_name": "mcwr",
    "title": "Markov Chains with Rewards",
    "description": "In the context of multistate models, which are popular in sociology,\n    demography, and epidemiology, Markov chain with rewards calculations can\n    help to refine transition timings and so obtain more accurate estimates. The\n    package code accommodates up to nine transient states and irregular age (time)\n    intervals. Traditional demographic life tables result as a special case.\n    Formulas and methods involved are explained in detail in the accompanying\n    article: Schneider / Myrskyla / van Raalte (2021): Flexible Transition Timing\n    in Discrete-Time Multistate Life Tables Using Markov Chains with Rewards,\n    MPIDR Working Paper WP-2021-002.",
    "version": "1.0.0",
    "maintainer": "Daniel Schneider <schneider@demogr.mpg.de>",
    "author": "Daniel Schneider [aut, cre],\n  Mikko Myrskyla [ctb],\n  Alyson van Raalte [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mcwr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mcwr Markov Chains with Rewards In the context of multistate models, which are popular in sociology,\n    demography, and epidemiology, Markov chain with rewards calculations can\n    help to refine transition timings and so obtain more accurate estimates. The\n    package code accommodates up to nine transient states and irregular age (time)\n    intervals. Traditional demographic life tables result as a special case.\n    Formulas and methods involved are explained in detail in the accompanying\n    article: Schneider / Myrskyla / van Raalte (2021): Flexible Transition Timing\n    in Discrete-Time Multistate Life Tables Using Markov Chains with Rewards,\n    MPIDR Working Paper WP-2021-002.  "
  },
  {
    "id": 15840,
    "package_name": "memisc",
    "title": "Management of Survey Data and Presentation of Analysis Results",
    "description": "An infrastructure for the management of survey data including\n        value labels, definable missing values, recoding of variables,\n        production of code books, and import of (subsets of) 'SPSS' and\n        'Stata' files is provided. Further, the package allows to produce\n        tables and data frames of arbitrary descriptive statistics and\n        (almost) publication-ready tables of regression model\n        estimates, which can be exported to 'LaTeX' and HTML.",
    "version": "0.99.31.8.3",
    "maintainer": "Martin Elff <memisc@elff.eu>",
    "author": "Martin Elff [aut, cre],\n  Christopher N. Lawrence [ctb],\n  Dave Atkins [ctb],\n  Jason W. Morgan [ctb],\n  Achim Zeileis [ctb],\n  Mael Astruc-Le Souder [ctb],\n  Kiril Mueller [ctb],\n  Pieter Schoonees [ctb]",
    "url": "https://melff.github.io/memisc/,https://github.com/melff/memisc/",
    "bug_reports": "https://github.com/melff/memisc/issues",
    "repository": "https://cran.r-project.org/package=memisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "memisc Management of Survey Data and Presentation of Analysis Results An infrastructure for the management of survey data including\n        value labels, definable missing values, recoding of variables,\n        production of code books, and import of (subsets of) 'SPSS' and\n        'Stata' files is provided. Further, the package allows to produce\n        tables and data frames of arbitrary descriptive statistics and\n        (almost) publication-ready tables of regression model\n        estimates, which can be exported to 'LaTeX' and HTML.  "
  },
  {
    "id": 15887,
    "package_name": "metabup",
    "title": "Bayesian Meta-Analysis Using Basic Uncertain Pooling",
    "description": "Contains functions that allow Bayesian meta-analysis (1) with binomial data, counts(y) and total counts (n) or, (2) with user-supplied point estimates and associated variances.   Case (1) provides an analysis based on the logit transformation of the sample proportion. This methodology is also appropriate for combining data from sample surveys and related sources. The functions can  calculate the corresponding similarity matrix. More details can be found in Cahoy and Sedransk (2023), Cahoy and Sedransk (2022)  <doi:10.1007/s42519-018-0027-2>, Evans and Sedransk (2001) <doi:10.1093/biomet/88.3.643>, and Malec and Sedransk (1992) <doi:10.1093/biomet/79.3.593>.",
    "version": "0.1.3",
    "maintainer": "Dexter Cahoy <dexter.cahoy@gmail.com>",
    "author": "Dexter Cahoy [aut, cre],\n  Joseph Sedransk [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=metabup",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "metabup Bayesian Meta-Analysis Using Basic Uncertain Pooling Contains functions that allow Bayesian meta-analysis (1) with binomial data, counts(y) and total counts (n) or, (2) with user-supplied point estimates and associated variances.   Case (1) provides an analysis based on the logit transformation of the sample proportion. This methodology is also appropriate for combining data from sample surveys and related sources. The functions can  calculate the corresponding similarity matrix. More details can be found in Cahoy and Sedransk (2023), Cahoy and Sedransk (2022)  <doi:10.1007/s42519-018-0027-2>, Evans and Sedransk (2001) <doi:10.1093/biomet/88.3.643>, and Malec and Sedransk (1992) <doi:10.1093/biomet/79.3.593>.  "
  },
  {
    "id": 16019,
    "package_name": "microeco",
    "title": "Microbial Community Ecology Data Analysis",
    "description": "A series of statistical and plotting approaches in microbial community ecology based on the R6 class. The classes are designed for data preprocessing, taxa abundance plotting, alpha diversity analysis, beta diversity analysis, differential abundance test, null model analysis, network analysis, machine learning, environmental data analysis and functional analysis.",
    "version": "1.16.0",
    "maintainer": "Chi Liu <liuchi0426@126.com>",
    "author": "Chi Liu [aut, cre],\n  Felipe R. P. Mansoldo [ctb],\n  Minjie Yao [ctb],\n  Xiangzhen Li [ctb]",
    "url": "https://github.com/ChiLiubio/microeco",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=microeco",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "microeco Microbial Community Ecology Data Analysis A series of statistical and plotting approaches in microbial community ecology based on the R6 class. The classes are designed for data preprocessing, taxa abundance plotting, alpha diversity analysis, beta diversity analysis, differential abundance test, null model analysis, network analysis, machine learning, environmental data analysis and functional analysis.  "
  },
  {
    "id": 16025,
    "package_name": "micronutr",
    "title": "Determining Vitamin and Mineral Status of Populations",
    "description": "Vitamin and mineral deficiencies continue to be a significant \n    public health problem. This is particularly critical in developing countries\n    where deficiencies to vitamin A, iron, iodine, and other micronutrients\n    lead to adverse health consequences. Cross-sectional surveys are helpful in\n    answering questions related to the magnitude and distribution of\n    deficiencies of selected vitamins and minerals. This package provides tools\n    for calculating and determining select vitamin and mineral deficiencies\n    based on World Health Organization (WHO) guidelines found at\n    <https://www.who.int/teams/nutrition-and-food-safety/databases/vitamin-and-mineral-nutrition-information-system>.",
    "version": "0.1.1",
    "maintainer": "Ernest Guevarra <ernest@guevarra.io>",
    "author": "Ernest Guevarra [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4887-4415>),\n  Nicholus Tint Zaw [aut, cph]",
    "url": "https://nutriverse.io/micronutr/,\nhttps://github.com/nutriverse/micronutr",
    "bug_reports": "https://github.com/nutriverse/micronutr/issues",
    "repository": "https://cran.r-project.org/package=micronutr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "micronutr Determining Vitamin and Mineral Status of Populations Vitamin and mineral deficiencies continue to be a significant \n    public health problem. This is particularly critical in developing countries\n    where deficiencies to vitamin A, iron, iodine, and other micronutrients\n    lead to adverse health consequences. Cross-sectional surveys are helpful in\n    answering questions related to the magnitude and distribution of\n    deficiencies of selected vitamins and minerals. This package provides tools\n    for calculating and determining select vitamin and mineral deficiencies\n    based on World Health Organization (WHO) guidelines found at\n    <https://www.who.int/teams/nutrition-and-food-safety/databases/vitamin-and-mineral-nutrition-information-system>.  "
  },
  {
    "id": 16049,
    "package_name": "migraph",
    "title": "Inferential Methods for Multimodal and Other Networks",
    "description": "A set of tools for testing networks.\n   It includes functions for univariate and multivariate \n   conditional uniform graph and quadratic assignment procedure testing,\n   and network regression.\n   The package is a complement to \n   'Multimodal Political Networks' (2021, ISBN:9781108985000),\n   and includes various datasets used in the book.\n   Built on the 'manynet' package, all functions operate with matrices, \n   edge lists, and 'igraph', 'network', and 'tidygraph' objects,\n   and on one-mode and two-mode (bipartite) networks.",
    "version": "1.5.6",
    "maintainer": "James Hollway <james.hollway@graduateinstitute.ch>",
    "author": "James Hollway [cre, aut, ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0002-8361-9647>),\n  Henrique Sposito [ctb] (IHEID, ORCID:\n    <https://orcid.org/0000-0003-3420-6085>),\n  Jael Tan [ctb] (IHEID, ORCID: <https://orcid.org/0000-0002-6234-9764>),\n  Bernhard Bieri [ctb] (ORCID: <https://orcid.org/0000-0001-5943-9059>)",
    "url": "https://stocnet.github.io/migraph/",
    "bug_reports": "https://github.com/stocnet/migraph/issues",
    "repository": "https://cran.r-project.org/package=migraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "migraph Inferential Methods for Multimodal and Other Networks A set of tools for testing networks.\n   It includes functions for univariate and multivariate \n   conditional uniform graph and quadratic assignment procedure testing,\n   and network regression.\n   The package is a complement to \n   'Multimodal Political Networks' (2021, ISBN:9781108985000),\n   and includes various datasets used in the book.\n   Built on the 'manynet' package, all functions operate with matrices, \n   edge lists, and 'igraph', 'network', and 'tidygraph' objects,\n   and on one-mode and two-mode (bipartite) networks.  "
  },
  {
    "id": 16139,
    "package_name": "mitre",
    "title": "Cybersecurity MITRE Standards Data and Digraphs",
    "description": "Extract, transform and load MITRE standards.\n    This package gives you an approach to cybersecurity data sets.\n    All data sets are build on runtime downloading raw data from MITRE public services.\n    MITRE <https://www.mitre.org/> is a government-funded research organization \n    based in Bedford and McLean. Current version includes most used standards as\n    data frames. It also provide a list of nodes and edges with all relationships.",
    "version": "1.0.0",
    "maintainer": "Humbert Costas <humbert.costas@gmail.com>",
    "author": "Humbert Costas [aut, cre]",
    "url": "https://github.com/motherhack3r/mitre",
    "bug_reports": "https://github.com/motherhack3r/mitre/issues",
    "repository": "https://cran.r-project.org/package=mitre",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mitre Cybersecurity MITRE Standards Data and Digraphs Extract, transform and load MITRE standards.\n    This package gives you an approach to cybersecurity data sets.\n    All data sets are build on runtime downloading raw data from MITRE public services.\n    MITRE <https://www.mitre.org/> is a government-funded research organization \n    based in Bedford and McLean. Current version includes most used standards as\n    data frames. It also provide a list of nodes and edges with all relationships.  "
  },
  {
    "id": 16253,
    "package_name": "mlspatial",
    "title": "Machine Learning and Mapping for Spatial Epidemiology",
    "description": "Provides tools for the integration, visualisation, and modelling of spatial epidemiological data using the method described in Azeez, A., & Noel, C. (2025). 'Predictive Modelling and Spatial Distribution of Pancreatic Cancer in Africa Using Machine Learning-Based Spatial Model' <doi:10.5281/zenodo.16529986> and <doi:10.5281/zenodo.16529016>. It facilitates the analysis of geographic health data by combining modern spatial mapping tools with advanced machine learning (ML) algorithms. 'mlspatial' enables users to import and pre-process shapefile and associated demographic or disease incidence data, generate richly annotated thematic maps, and apply predictive models, including Random Forest, 'XGBoost', and Support Vector Regression, to identify spatial patterns and risk factors. It is suited for spatial epidemiologists, public health researchers, and GIS analysts aiming to uncover hidden geographic patterns in health-related outcomes and inform evidence-based interventions.",
    "version": "0.1.0",
    "maintainer": "Adeboye Azeez <azizadeboye@gmail.com>",
    "author": "Adeboye Azeez [aut, cre],\n  Colin Noel [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mlspatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mlspatial Machine Learning and Mapping for Spatial Epidemiology Provides tools for the integration, visualisation, and modelling of spatial epidemiological data using the method described in Azeez, A., & Noel, C. (2025). 'Predictive Modelling and Spatial Distribution of Pancreatic Cancer in Africa Using Machine Learning-Based Spatial Model' <doi:10.5281/zenodo.16529986> and <doi:10.5281/zenodo.16529016>. It facilitates the analysis of geographic health data by combining modern spatial mapping tools with advanced machine learning (ML) algorithms. 'mlspatial' enables users to import and pre-process shapefile and associated demographic or disease incidence data, generate richly annotated thematic maps, and apply predictive models, including Random Forest, 'XGBoost', and Support Vector Regression, to identify spatial patterns and risk factors. It is suited for spatial epidemiologists, public health researchers, and GIS analysts aiming to uncover hidden geographic patterns in health-related outcomes and inform evidence-based interventions.  "
  },
  {
    "id": 16297,
    "package_name": "mnt",
    "title": "Affine Invariant Tests of Multivariate Normality",
    "description": "Various affine invariant multivariate normality tests are provided. It is designed to accompany the survey article Ebner, B. and Henze, N. (2020) <arXiv:2004.07332> titled \"Tests for multivariate normality -- a critical review with emphasis on weighted L^2-statistics\". We implement new and time honoured L^2-type tests of multivariate normality, such as the Baringhaus-Henze-Epps-Pulley (BHEP) test, the Henze-Zirkler test, the test of Henze-Jim\u00e9nes-Gamero, the test of Henze-Jim\u00e9nes-Gamero-Meintanis, the test of Henze-Visage, the D\u00f6rr-Ebner-Henze test based on harmonic oscillator and the D\u00f6rr-Ebner-Henze test based on a double estimation in a PDE. Secondly, we include the measures of multivariate skewness and kurtosis by Mardia, Koziol, Malkovich and Afifi and M\u00f3ri, Rohatgi and Sz\u00e9kely, as well as the associated tests. Thirdly, we include the tests of multivariate normality by Cox and Small, the 'energy' test of Sz\u00e9kely and Rizzo, the tests based on spherical harmonics by Manzotti and Quiroz and the test of Pudelko. All the functions and tests need the data to be a n x d matrix where n is the samplesize (number of rows) and d is the dimension (number of columns).",
    "version": "1.3",
    "maintainer": "Bruno Ebner <bruno.ebner@kit.edu>",
    "author": "Lucas Butsch [aut],\n  Bruno Ebner [aut, cre],\n  Jaco Visagie [ctb],\n  Johann Siemens [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=mnt",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mnt Affine Invariant Tests of Multivariate Normality Various affine invariant multivariate normality tests are provided. It is designed to accompany the survey article Ebner, B. and Henze, N. (2020) <arXiv:2004.07332> titled \"Tests for multivariate normality -- a critical review with emphasis on weighted L^2-statistics\". We implement new and time honoured L^2-type tests of multivariate normality, such as the Baringhaus-Henze-Epps-Pulley (BHEP) test, the Henze-Zirkler test, the test of Henze-Jim\u00e9nes-Gamero, the test of Henze-Jim\u00e9nes-Gamero-Meintanis, the test of Henze-Visage, the D\u00f6rr-Ebner-Henze test based on harmonic oscillator and the D\u00f6rr-Ebner-Henze test based on a double estimation in a PDE. Secondly, we include the measures of multivariate skewness and kurtosis by Mardia, Koziol, Malkovich and Afifi and M\u00f3ri, Rohatgi and Sz\u00e9kely, as well as the associated tests. Thirdly, we include the tests of multivariate normality by Cox and Small, the 'energy' test of Sz\u00e9kely and Rizzo, the tests based on spherical harmonics by Manzotti and Quiroz and the test of Pudelko. All the functions and tests need the data to be a n x d matrix where n is the samplesize (number of rows) and d is the dimension (number of columns).  "
  },
  {
    "id": 16336,
    "package_name": "modi",
    "title": "Multivariate Outlier Detection and Imputation for Incomplete\nSurvey Data",
    "description": "Algorithms for multivariate outlier detection when missing values\n    occur. Algorithms are based on Mahalanobis distance or data depth.\n    Imputation is based on the multivariate normal model or uses nearest\n    neighbour donors. The algorithms take sample designs, in particular\n    weighting, into account. The methods are described in Bill and Hulliger\n    (2016) <doi:10.17713/ajs.v45i1.86>.",
    "version": "0.1.3",
    "maintainer": "Beat Hulliger <beat.hulliger@fhnw.ch>",
    "author": "Beat Hulliger [aut, cre],\n  Martin Sterchi [ctb],\n  Tobias Schoch [ctb]",
    "url": "https://github.com/martinSter/modi",
    "bug_reports": "https://github.com/martinSter/modi/issues",
    "repository": "https://cran.r-project.org/package=modi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "modi Multivariate Outlier Detection and Imputation for Incomplete\nSurvey Data Algorithms for multivariate outlier detection when missing values\n    occur. Algorithms are based on Mahalanobis distance or data depth.\n    Imputation is based on the multivariate normal model or uses nearest\n    neighbour donors. The algorithms take sample designs, in particular\n    weighting, into account. The methods are described in Bill and Hulliger\n    (2016) <doi:10.17713/ajs.v45i1.86>.  "
  },
  {
    "id": 16362,
    "package_name": "monitoR",
    "title": "Acoustic Template Detection in R",
    "description": "Acoustic template detection and monitoring database interface. Create, modify, save, and use templates for detection of animal vocalizations. View, verify, and extract results. Upload a MySQL schema to a existing instance, manage survey metadata, write and read templates and detections locally or to the database. ",
    "version": "1.2",
    "maintainer": "Sasha D. Hafner <sasha.hafner@bce.au.dk>",
    "author": "Sasha D. Hafner [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0955-0327>),\n  Jon Katz [aut],\n  Jerome Sueur [aut] (seewave package author (code from Fourier transform\n    used in monitoR)),\n  Thierry Aubin [aut] (seewave package author (code from Fourier\n    transform used in monitoR)),\n  Caroline Simonis [aut] (seewave package author (code from Fourier\n    transform used in monitoR)),\n  Uwe Ligges [aut] (tuneR package author (code from readMP3() used in\n    monitoR)),\n  Therese Donovan [ctb] (creative direction and database design support)",
    "url": "https://github.com/jonkatz2/monitor",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=monitoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "monitoR Acoustic Template Detection in R Acoustic template detection and monitoring database interface. Create, modify, save, and use templates for detection of animal vocalizations. View, verify, and extract results. Upload a MySQL schema to a existing instance, manage survey metadata, write and read templates and detections locally or to the database.   "
  },
  {
    "id": 16380,
    "package_name": "moonBook",
    "title": "Functions and Datasets for the Book by Keon-Woong Moon",
    "description": "Several analysis-related functions for the book entitled \"R\n    statistics and graph for medical articles\" (written in Korean), version 1,\n    by Keon-Woong Moon with Korean demographic data with several plot\n    functions.",
    "version": "0.3.1",
    "maintainer": "Keon-Woong Moon <cardiomoon@gmail.com>",
    "author": "Keon-Woong Moon [aut, cre]",
    "url": "https://github.com/cardiomoon/moonBook",
    "bug_reports": "https://github.com/cardiomoon/moonBook/issues",
    "repository": "https://cran.r-project.org/package=moonBook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "moonBook Functions and Datasets for the Book by Keon-Woong Moon Several analysis-related functions for the book entitled \"R\n    statistics and graph for medical articles\" (written in Korean), version 1,\n    by Keon-Woong Moon with Korean demographic data with several plot\n    functions.  "
  },
  {
    "id": 16397,
    "package_name": "mortAAR",
    "title": "Analysis of Archaeological Mortality Data",
    "description": "A collection of functions for the analysis of archaeological mortality\n    data (on the topic see e.g. Chamberlain 2006 \n    <https://books.google.de/books?id=nG5FoO_becAC&lpg=PA27&ots=LG0b_xrx6O&dq=life%20table%20archaeology&pg=PA27#v=onepage&q&f=false>). \n    It takes demographic data in different formats and displays the result in a standard life table\n    as well as plots the relevant indices (percentage of deaths, survivorship, probability of death, \n    life expectancy, percentage of population). It also checks for possible biases in the age \n    structure and applies corrections to life tables.",
    "version": "1.1.8",
    "maintainer": "Nils Mueller-Scheessel <nils.mueller-scheessel@ufg.uni-kiel.de>",
    "author": "Nils Mueller-Scheessel [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-7992-8722>),\n  Martin Hinz [aut],\n  Clemens Schmid [aut],\n  Christoph Rinne [aut],\n  Daniel Knitter [aut],\n  Wolfgang Hamer [aut],\n  Dirk Seidensticker [aut],\n  Franziska Faupel [aut],\n  Carolin Tietze [aut],\n  Nicole Grunert [aut]",
    "url": "https://github.com/ISAAKiel/mortAAR,\nhttps://isaakiel.github.io/mortAAR/",
    "bug_reports": "https://github.com/ISAAKiel/mortAAR/issues",
    "repository": "https://cran.r-project.org/package=mortAAR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mortAAR Analysis of Archaeological Mortality Data A collection of functions for the analysis of archaeological mortality\n    data (on the topic see e.g. Chamberlain 2006 \n    <https://books.google.de/books?id=nG5FoO_becAC&lpg=PA27&ots=LG0b_xrx6O&dq=life%20table%20archaeology&pg=PA27#v=onepage&q&f=false>). \n    It takes demographic data in different formats and displays the result in a standard life table\n    as well as plots the relevant indices (percentage of deaths, survivorship, probability of death, \n    life expectancy, percentage of population). It also checks for possible biases in the age \n    structure and applies corrections to life tables.  "
  },
  {
    "id": 16434,
    "package_name": "mpitbR",
    "title": "Calculate Alkire-Foster Multidimensional Poverty Measures",
    "description": "\n    Estimate Multidimensional Poverty Indices disaggregated by population subgroups based on the Alkire and Foster method (2011) <doi:10.1016/j.jpubeco.2010.11.006>. This includes the calculation of standard errors and confidence intervals. Other partial indices such as incidence, intensity and indicator-specific measures as well as intertemporal changes analysis can also be estimated. The standard errors and confidence intervals are calculated considering the complex survey design. ",
    "version": "1.0.1",
    "maintainer": "Ignacio Girela <ignacio.girela@unc.edu.ar>",
    "author": "Ignacio Girela [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3297-3854>),\n  CONICET [fnd]",
    "url": "https://github.com/girelaignacio/mpitbR",
    "bug_reports": "https://github.com/girelaignacio/mpitbR/issues",
    "repository": "https://cran.r-project.org/package=mpitbR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mpitbR Calculate Alkire-Foster Multidimensional Poverty Measures \n    Estimate Multidimensional Poverty Indices disaggregated by population subgroups based on the Alkire and Foster method (2011) <doi:10.1016/j.jpubeco.2010.11.006>. This includes the calculation of standard errors and confidence intervals. Other partial indices such as incidence, intensity and indicator-specific measures as well as intertemporal changes analysis can also be estimated. The standard errors and confidence intervals are calculated considering the complex survey design.   "
  },
  {
    "id": 16567,
    "package_name": "multigraph",
    "title": "Plot and Manipulate Multigraphs",
    "description": "Functions to plot and manipulate multigraphs, signed and valued graphs, bipartite graphs, multilevel graphs, and Cayley graphs with various layout options. ",
    "version": "0.99-3",
    "maintainer": "Antonio Rivero Ostoic <multiplex@post.com>",
    "author": "Antonio Rivero Ostoic [aut, cre]",
    "url": "https://github.com/mplex/multigraph/",
    "bug_reports": "https://github.com/mplex/multigraph/issues/",
    "repository": "https://cran.r-project.org/package=multigraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multigraph Plot and Manipulate Multigraphs Functions to plot and manipulate multigraphs, signed and valued graphs, bipartite graphs, multilevel graphs, and Cayley graphs with various layout options.   "
  },
  {
    "id": 16568,
    "package_name": "multigraphr",
    "title": "Probability Models and Statistical Analysis of Random\nMultigraphs",
    "description": "Methods and models for analysing multigraphs as introduced by Shafie (2015) <doi:10.21307/joss-2019-011>, including methods to study local and global properties <doi:10.1080/0022250X.2016.1219732> and goodness of fit tests.",
    "version": "0.2.0",
    "maintainer": "Termeh Shafie <termeh.shafie@uni-konstanz.de>",
    "author": "Termeh Shafie [aut, cre],\n  David Schoch [ctb] (ORCID: <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://github.com/termehs/multigraphr",
    "bug_reports": "https://github.com/termehs/multigraphr/issues",
    "repository": "https://cran.r-project.org/package=multigraphr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multigraphr Probability Models and Statistical Analysis of Random\nMultigraphs Methods and models for analysing multigraphs as introduced by Shafie (2015) <doi:10.21307/joss-2019-011>, including methods to study local and global properties <doi:10.1080/0022250X.2016.1219732> and goodness of fit tests.  "
  },
  {
    "id": 16579,
    "package_name": "multimark",
    "title": "Capture-Mark-Recapture Analysis using Multiple Non-Invasive\nMarks",
    "description": "Traditional and spatial capture-mark-recapture analysis with\n    multiple non-invasive marks. The models implemented in 'multimark' combine\n    encounter history data arising from two different non-invasive \"marks\",\n    such as images of left-sided and right-sided pelage patterns of bilaterally\n    asymmetrical species, to estimate abundance and related demographic\n    parameters while accounting for imperfect detection. Bayesian models are\n    specified using simple formulae and fitted using Markov chain Monte Carlo.\n    Addressing deficiencies in currently available software, 'multimark' also\n    provides a user-friendly interface for performing Bayesian multimodel\n    inference using non-spatial or spatial capture-recapture data consisting of a single\n    conventional mark or multiple non-invasive marks. See McClintock (2015) <doi:10.1002/ece3.1676> and Maronde et al. (2020) <doi:10.1002/ece3.6990>.",
    "version": "2.1.7",
    "maintainer": "Brett T. McClintock <brett.mcclintock@noaa.gov>",
    "author": "Brett T. McClintock [aut, cre],\n  Acho Arnold [ctb, cph] (C original matrix library,\n    https://github.com/najela/matrix.h),\n  Barry Brown [ctb] (Fortran original ranlib library),\n  James Lovato [ctb] (Fortran original ranlib library),\n  John Burkardt [ctb] (C original ranlib library,\n    http://people.sc.fsu.edu/~jburkardt/c_src/ranlib),\n  Cleve Moler [ctb] (C original linpack library,\n    http://www.kkant.net/geist/ranlib/),\n  Arjun Gopalaswamy [ctb] (modified snippets of R package SPACECAP code)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=multimark",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multimark Capture-Mark-Recapture Analysis using Multiple Non-Invasive\nMarks Traditional and spatial capture-mark-recapture analysis with\n    multiple non-invasive marks. The models implemented in 'multimark' combine\n    encounter history data arising from two different non-invasive \"marks\",\n    such as images of left-sided and right-sided pelage patterns of bilaterally\n    asymmetrical species, to estimate abundance and related demographic\n    parameters while accounting for imperfect detection. Bayesian models are\n    specified using simple formulae and fitted using Markov chain Monte Carlo.\n    Addressing deficiencies in currently available software, 'multimark' also\n    provides a user-friendly interface for performing Bayesian multimodel\n    inference using non-spatial or spatial capture-recapture data consisting of a single\n    conventional mark or multiple non-invasive marks. See McClintock (2015) <doi:10.1002/ece3.1676> and Maronde et al. (2020) <doi:10.1002/ece3.6990>.  "
  },
  {
    "id": 16588,
    "package_name": "multinets",
    "title": "Multilevel Networks Analysis",
    "description": "Analyze multilevel networks as described in Lazega et al (2008)\n    <doi:10.1016/j.socnet.2008.02.001> and in Lazega and Snijders \n    (2016, ISBN:978-3-319-24520-1). The package was developed essentially as an \n    extension to 'igraph'.",
    "version": "0.2.2",
    "maintainer": "Neylson Crepalde <neylsoncrepalde@gmail.com>",
    "author": "Neylson Crepalde [aut, cre]",
    "url": "https://github.com/neylsoncrepalde/multinets",
    "bug_reports": "https://github.com/neylsoncrepalde/multinets/issues",
    "repository": "https://cran.r-project.org/package=multinets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multinets Multilevel Networks Analysis Analyze multilevel networks as described in Lazega et al (2008)\n    <doi:10.1016/j.socnet.2008.02.001> and in Lazega and Snijders \n    (2016, ISBN:978-3-319-24520-1). The package was developed essentially as an \n    extension to 'igraph'.  "
  },
  {
    "id": 16618,
    "package_name": "multpois",
    "title": "Analyze Nominal Response Data with the Multinomial-Poisson Trick",
    "description": "Dichotomous responses having two categories can be analyzed\n    with stats::glm() or lme4::glmer() using the family=binomial option.\n    Unfortunately, polytomous responses with three or more unordered\n    categories cannot be analyzed similarly because there is no analogous\n    family=multinomial option. For between-subjects data,\n    nnet::multinom() can address this need, but it cannot handle random\n    factors and therefore cannot handle repeated measures. To address this\n    gap, we transform nominal response data into counts for each categorical \n    alternative. These counts are then analyzed using (mixed) Poisson regression\n    as per Baker (1994) <doi:10.2307/2348134>. Omnibus analyses of variance can be \n    run along with post hoc pairwise comparisons. For users wishing to analyze nominal \n    responses from surveys or experiments, the functions in this package essentially \n    act as though stats::glm() or lme4::glmer() provide a family=multinomial option.",
    "version": "0.3.3",
    "maintainer": "Jacob O. Wobbrock <wobbrock@uw.edu>",
    "author": "Jacob O. Wobbrock [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-3675-5491>)",
    "url": "https://github.com/wobbrock/multpois/",
    "bug_reports": "https://github.com/wobbrock/multpois/issues",
    "repository": "https://cran.r-project.org/package=multpois",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "multpois Analyze Nominal Response Data with the Multinomial-Poisson Trick Dichotomous responses having two categories can be analyzed\n    with stats::glm() or lme4::glmer() using the family=binomial option.\n    Unfortunately, polytomous responses with three or more unordered\n    categories cannot be analyzed similarly because there is no analogous\n    family=multinomial option. For between-subjects data,\n    nnet::multinom() can address this need, but it cannot handle random\n    factors and therefore cannot handle repeated measures. To address this\n    gap, we transform nominal response data into counts for each categorical \n    alternative. These counts are then analyzed using (mixed) Poisson regression\n    as per Baker (1994) <doi:10.2307/2348134>. Omnibus analyses of variance can be \n    run along with post hoc pairwise comparisons. For users wishing to analyze nominal \n    responses from surveys or experiments, the functions in this package essentially \n    act as though stats::glm() or lme4::glmer() provide a family=multinomial option.  "
  },
  {
    "id": 16635,
    "package_name": "mutualinf",
    "title": "Computation and Decomposition of the Mutual Information Index",
    "description": "The Mutual Information Index (M) introduced to social science literature by\n    Theil and Finizza (1971) <doi:10.1080/0022250X.1971.9989795> is a multigroup\n    segregation measure that is highly decomposable and that according to Frankel\n    and Volij (2011) <doi:10.1016/j.jet.2010.10.008> and Mora and Ruiz-Castillo\n    (2011) <doi:10.1111/j.1467-9531.2011.01237.x> satisfies the Strong Unit\n    Decomposability and Strong Group Decomposability properties. This package allows\n    computing and decomposing the total index value into its \"between\" and\n    \"within\" terms. These last terms can also be decomposed into their\n    contributions, either by group or unit characteristics. The factors that produce\n    each \"within\" term can also be displayed at the user's request. The results can\n    be computed considering a variable or sets of variables that define separate\n    clusters.",
    "version": "2.0.4",
    "maintainer": "Cristian Angulo-Gonzalez <cristian_world@hotmail.cl>",
    "author": "Cristian Angulo-Gonzalez [aut, cre],\n  Rafael Fuentealba-Chaura [aut],\n  Ricardo Mora [aut],\n  Julio Rojas-Mora [aut],\n  FONDECYT/ANID Project 11170583 [fnd],\n  MCIN/AEI/10.13039/501100011033 (Project no. PID2019-108576RB-I00) [fnd],\n  UCT VIP Project FEQUIP2019-INRN-03 [fnd]",
    "url": "https://github.com/RafaelFuentealbaC/mutualinf",
    "bug_reports": "https://github.com/RafaelFuentealbaC/mutualinf/issues",
    "repository": "https://cran.r-project.org/package=mutualinf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "mutualinf Computation and Decomposition of the Mutual Information Index The Mutual Information Index (M) introduced to social science literature by\n    Theil and Finizza (1971) <doi:10.1080/0022250X.1971.9989795> is a multigroup\n    segregation measure that is highly decomposable and that according to Frankel\n    and Volij (2011) <doi:10.1016/j.jet.2010.10.008> and Mora and Ruiz-Castillo\n    (2011) <doi:10.1111/j.1467-9531.2011.01237.x> satisfies the Strong Unit\n    Decomposability and Strong Group Decomposability properties. This package allows\n    computing and decomposing the total index value into its \"between\" and\n    \"within\" terms. These last terms can also be decomposed into their\n    contributions, either by group or unit characteristics. The factors that produce\n    each \"within\" term can also be displayed at the user's request. The results can\n    be computed considering a variable or sets of variables that define separate\n    clusters.  "
  },
  {
    "id": 16776,
    "package_name": "ndi",
    "title": "Neighborhood Deprivation Indices",
    "description": "Computes various geospatial indices of socioeconomic deprivation and disparity\n             in the United States. Some indices are considered \"spatial\" because they \n             consider the values of neighboring (i.e., adjacent) census geographies in\n             their computation, while other indices are \"aspatial\" because they only \n             consider the value within each census geography. Two types of aspatial \n             neighborhood deprivation indices (NDI) are available: including:\n             (1) based on Messer et al. (2006) <doi:10.1007/s11524-006-9094-x>\n             and (2) based on Andrews et al. (2020) <doi:10.1080/17445647.2020.1750066> \n             and Slotman et al. (2022) <doi:10.1016/j.dib.2022.108002>\n             who use variables chosen by Roux and Mair (2010)\n             <doi:10.1111/j.1749-6632.2009.05333.x>. Both are a decomposition of multiple\n             demographic characteristics from the U.S. Census Bureau American Community \n             Survey 5-year estimates (ACS-5; 2006-2010 onward). Using data from the ACS-5\n             (2005-2009 onward), the package can also compute indices of racial or ethnic\n             residential segregation, including but limited to those discussed in Massey \n             & Denton (1988) <doi:10.1093/sf/67.2.281>, and additional indices of \n             socioeconomic disparity.",
    "version": "0.2.1",
    "maintainer": "Ian D. Buller <ian.buller@alumni.emory.edu>",
    "author": "Ian D. Buller [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-9477-8582>),\n  NCI [cph, fnd]",
    "url": "https://github.com/idblr/ndi",
    "bug_reports": "https://github.com/idblr/ndi/issues",
    "repository": "https://cran.r-project.org/package=ndi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ndi Neighborhood Deprivation Indices Computes various geospatial indices of socioeconomic deprivation and disparity\n             in the United States. Some indices are considered \"spatial\" because they \n             consider the values of neighboring (i.e., adjacent) census geographies in\n             their computation, while other indices are \"aspatial\" because they only \n             consider the value within each census geography. Two types of aspatial \n             neighborhood deprivation indices (NDI) are available: including:\n             (1) based on Messer et al. (2006) <doi:10.1007/s11524-006-9094-x>\n             and (2) based on Andrews et al. (2020) <doi:10.1080/17445647.2020.1750066> \n             and Slotman et al. (2022) <doi:10.1016/j.dib.2022.108002>\n             who use variables chosen by Roux and Mair (2010)\n             <doi:10.1111/j.1749-6632.2009.05333.x>. Both are a decomposition of multiple\n             demographic characteristics from the U.S. Census Bureau American Community \n             Survey 5-year estimates (ACS-5; 2006-2010 onward). Using data from the ACS-5\n             (2005-2009 onward), the package can also compute indices of racial or ethnic\n             residential segregation, including but limited to those discussed in Massey \n             & Denton (1988) <doi:10.1093/sf/67.2.281>, and additional indices of \n             socioeconomic disparity.  "
  },
  {
    "id": 16818,
    "package_name": "netUtils",
    "title": "A Collection of Tools for Network Analysis",
    "description": "Provides a collection of network analytic (convenience) functions which are missing in other standard packages. This includes triad census with attributes <doi:10.1016/j.socnet.2019.04.003>, core-periphery models <doi:10.1016/S0378-8733(99)00019-2>, and several graph generators. Most functions are build upon 'igraph'.  ",
    "version": "0.8.3",
    "maintainer": "David Schoch <david@schochastics.net>",
    "author": "David Schoch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://github.com/schochastics/netUtils/,\nhttps://schochastics.github.io/netUtils/",
    "bug_reports": "https://github.com/schochastics/netUtils/issues",
    "repository": "https://cran.r-project.org/package=netUtils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netUtils A Collection of Tools for Network Analysis Provides a collection of network analytic (convenience) functions which are missing in other standard packages. This includes triad census with attributes <doi:10.1016/j.socnet.2019.04.003>, core-periphery models <doi:10.1016/S0378-8733(99)00019-2>, and several graph generators. Most functions are build upon 'igraph'.    "
  },
  {
    "id": 16827,
    "package_name": "netknitr",
    "title": "Knit Network Map for any Dataset",
    "description": "Designed to create interactive and visually compelling network maps using R Shiny. It allows users to quickly analyze CSV files and visualize complex relationships, structures, and connections within data by leveraging powerful network analysis libraries and dynamic web interfaces.",
    "version": "0.2.1",
    "maintainer": "Jayachandra N <itsjay510@gmail.com>",
    "author": "Jayachandra N [aut, cre],\n  Pushker Ravindra [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=netknitr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netknitr Knit Network Map for any Dataset Designed to create interactive and visually compelling network maps using R Shiny. It allows users to quickly analyze CSV files and visualize complex relationships, structures, and connections within data by leveraging powerful network analysis libraries and dynamic web interfaces.  "
  },
  {
    "id": 16828,
    "package_name": "netmap",
    "title": "Represent Network Objects on a Map",
    "description": "Represent 'network' or 'igraph' objects whose vertices can be represented by features in an 'sf' object as a network graph surmising a 'sf' plot. Fits into 'ggplot2' grammar.",
    "version": "0.1.4",
    "maintainer": "Matteo Dimai <matteo.dimai@phd.units.it>",
    "author": "Matteo Dimai [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1126-5234>)",
    "url": "https://github.com/artod83/netmap",
    "bug_reports": "https://github.com/artod83/netmap/issues",
    "repository": "https://cran.r-project.org/package=netmap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netmap Represent Network Objects on a Map Represent 'network' or 'igraph' objects whose vertices can be represented by features in an 'sf' object as a network graph surmising a 'sf' plot. Fits into 'ggplot2' grammar.  "
  },
  {
    "id": 16832,
    "package_name": "netplot",
    "title": "Beautiful Graph Drawing",
    "description": "A graph visualization engine that emphasizes on \n  aesthetics at the same time providing default parameters that yield\n  out-of-the-box-nice visualizations. The package is built on top of\n  'The Grid Graphics Package' and seamlessly work with 'igraph' and \n  'network' objects.",
    "version": "0.3-0",
    "maintainer": "George Vega Yon <g.vegayon@gmail.com>",
    "author": "George Vega Yon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3171-0844>),\n  Porter Bischoff [aut] (ORCID: <https://orcid.org/0009-0004-6742-6281>)",
    "url": "https://github.com/USCCANA/netplot",
    "bug_reports": "https://github.com/USCCANA/netplot/issues",
    "repository": "https://cran.r-project.org/package=netplot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "netplot Beautiful Graph Drawing A graph visualization engine that emphasizes on \n  aesthetics at the same time providing default parameters that yield\n  out-of-the-box-nice visualizations. The package is built on top of\n  'The Grid Graphics Package' and seamlessly work with 'igraph' and \n  'network' objects.  "
  },
  {
    "id": 16840,
    "package_name": "nett",
    "title": "Network Analysis and Community Detection",
    "description": "Features tools for the network data analysis and community detection. \n    Provides multiple methods for fitting, model selection and goodness-of-fit testing in degree-corrected stochastic blocks models. \n    Most of the computations are fast and scalable for sparse networks, esp. for Poisson versions of the models.\n    Implements the following: \n    Amini, Chen, Bickel and Levina (2013) <doi:10.1214/13-AOS1138>\n    Bickel and Sarkar (2015) <doi:10.1111/rssb.12117>\n    Lei (2016) <doi:10.1214/15-AOS1370>\n    Wang and Bickel (2017) <doi:10.1214/16-AOS1457>\n    Zhang and Amini (2020) <arXiv:2012.15047>\n    Le and Levina (2022) <doi:10.1214/21-EJS1971>.",
    "version": "1.0.0",
    "maintainer": "Arash A. Amini <aaamini@ucla.edu>",
    "author": "Arash A. Amini [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2808-8310>),\n  Linfan Zhang [aut]",
    "url": "https://github.com/aaamini/nett",
    "bug_reports": "https://github.com/aaamini/nett/issues",
    "repository": "https://cran.r-project.org/package=nett",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nett Network Analysis and Community Detection Features tools for the network data analysis and community detection. \n    Provides multiple methods for fitting, model selection and goodness-of-fit testing in degree-corrected stochastic blocks models. \n    Most of the computations are fast and scalable for sparse networks, esp. for Poisson versions of the models.\n    Implements the following: \n    Amini, Chen, Bickel and Levina (2013) <doi:10.1214/13-AOS1138>\n    Bickel and Sarkar (2015) <doi:10.1111/rssb.12117>\n    Lei (2016) <doi:10.1214/15-AOS1370>\n    Wang and Bickel (2017) <doi:10.1214/16-AOS1457>\n    Zhang and Amini (2020) <arXiv:2012.15047>\n    Le and Levina (2022) <doi:10.1214/21-EJS1971>.  "
  },
  {
    "id": 16845,
    "package_name": "networkDynamic",
    "title": "Dynamic Extensions for Network Objects",
    "description": "Simple interface routines to facilitate the handling of network objects with complex intertemporal data. This is a part of the \"statnet\" suite of packages for network analysis.",
    "version": "0.11.5",
    "maintainer": "Skye Bender-deMoll <skyebend@uw.edu>",
    "author": "Carter T. Butts [aut],\n  Ayn Leslie-Cook [aut],\n  Pavel N. Krivitsky [aut],\n  Skye Bender-deMoll [aut, cre],\n  Zack Almquist [ctb],\n  David R. Hunter [ctb],\n  Li Wang [ctb],\n  Kirk Li [ctb],\n  Steven M. Goodreau [ctb],\n  Jeffrey Horner [ctb],\n  Martina Morris [ctb]",
    "url": "https://statnet.org/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=networkDynamic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "networkDynamic Dynamic Extensions for Network Objects Simple interface routines to facilitate the handling of network objects with complex intertemporal data. This is a part of the \"statnet\" suite of packages for network analysis.  "
  },
  {
    "id": 16848,
    "package_name": "networkLite",
    "title": "An Simplified Implementation of the 'network' Package\nFunctionality",
    "description": "An implementation of some of the core 'network' package functionality based on a \n    simplified data structure that is faster in many research applications. This package is designed \n    for back-end use in the 'statnet' family of packages, including 'EpiModel'. Support is provided for\n    binary and weighted, directed and undirected, bipartite and unipartite networks; no current \n    support for multigraphs, hypergraphs, or loops.",
    "version": "1.1.0",
    "maintainer": "Samuel Jenness <samuel.m.jenness@emory.edu>",
    "author": "Samuel Jenness [cre, aut],\n  Steven M. Goodreau [aut],\n  Martina Morris [aut],\n  Adrien Le Guillou [aut],\n  Chad Klumb [aut],\n  Skye Bender-deMoll [ctb],\n  Pavel N. Krivitsky [ctb] (ORCID:\n    <https://orcid.org/0000-0002-9101-3362>)",
    "url": "https://github.com/EpiModel/networkLite/",
    "bug_reports": "https://github.com/EpiModel/networkLite/issues",
    "repository": "https://cran.r-project.org/package=networkLite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "networkLite An Simplified Implementation of the 'network' Package\nFunctionality An implementation of some of the core 'network' package functionality based on a \n    simplified data structure that is faster in many research applications. This package is designed \n    for back-end use in the 'statnet' family of packages, including 'EpiModel'. Support is provided for\n    binary and weighted, directed and undirected, bipartite and unipartite networks; no current \n    support for multigraphs, hypergraphs, or loops.  "
  },
  {
    "id": 16849,
    "package_name": "networkR",
    "title": "Network Analysis and Visualization",
    "description": "Collection of functions for fast manipulation, handling, and analysis of large-scale\n    networks based on family and social data. Functions are utility functions used to manipulate data\n    in three \"formats\": sparse adjacency matrices, pedigree trio family data, and pedigree family data.\n    When possible, the functions should be able to handle millions of data points quickly for use in combination\n    with data from large public national registers and databases.\n    Kenneth Lange (2003, ISBN:978-8181281135).",
    "version": "0.1.5",
    "maintainer": "Claus Thorn Ekstr\u00f8m <ekstrom@sund.ku.dk>",
    "author": "Claus Thorn Ekstr\u00f8m [aut, cre],\n  Bendix Carstensen [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=networkR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "networkR Network Analysis and Visualization Collection of functions for fast manipulation, handling, and analysis of large-scale\n    networks based on family and social data. Functions are utility functions used to manipulate data\n    in three \"formats\": sparse adjacency matrices, pedigree trio family data, and pedigree family data.\n    When possible, the functions should be able to handle millions of data points quickly for use in combination\n    with data from large public national registers and databases.\n    Kenneth Lange (2003, ISBN:978-8181281135).  "
  },
  {
    "id": 16852,
    "package_name": "networktools",
    "title": "Tools for Identifying Important Nodes in Networks",
    "description": "Includes assorted tools for network analysis. Bridge centrality; goldbricker; MDS, PCA, & eigenmodel network plotting.",
    "version": "1.6.0",
    "maintainer": "Payton Jones <paytonjjones@gmail.com>",
    "author": "Payton Jones [aut, cre]",
    "url": "https://CRAN.R-project.org/package=networktools",
    "bug_reports": "https://github.com/paytonjjones/networktools/issues",
    "repository": "https://cran.r-project.org/package=networktools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "networktools Tools for Identifying Important Nodes in Networks Includes assorted tools for network analysis. Bridge centrality; goldbricker; MDS, PCA, & eigenmodel network plotting.  "
  },
  {
    "id": 16867,
    "package_name": "neutroSurvey",
    "title": "Neutrosophic Survey Data Analysis",
    "description": "Apply neutrosophic regression type estimator and performs neutrosophic interval analysis including metric calculations for survey data.",
    "version": "0.1.0",
    "maintainer": "Pankaj Das <pankaj.iasri@gmail.com>",
    "author": "Neha Purwar [aut],\n  Kaustav Aditya [aut],\n  Pankaj Das [aut, cre] (ORCID: <https://orcid.org/0000-0003-1672-2502>),\n  Bharti Bharti [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=neutroSurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "neutroSurvey Neutrosophic Survey Data Analysis Apply neutrosophic regression type estimator and performs neutrosophic interval analysis including metric calculations for survey data.  "
  },
  {
    "id": 16895,
    "package_name": "nhanesA",
    "title": "NHANES Data Retrieval",
    "description": "Utility to retrieve data from the National Health and Nutrition \n\tExamination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/>.",
    "version": "1.4.1",
    "maintainer": "Deepayan Sarkar <deepayan.sarkar@r-project.org>",
    "author": "Christopher Endres [aut] (original author),\n  Laha Ale [aut] (ORCID: <https://orcid.org/0000-0002-4070-5289>),\n  Robert Gentleman [aut] (ORCID: <https://orcid.org/0000-0003-4505-9893>),\n  Deepayan Sarkar [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-4107-1553>)",
    "url": "https://cran.r-project.org/package=nhanesA",
    "bug_reports": "https://github.com/cjendres1/nhanes/issues",
    "repository": "https://cran.r-project.org/package=nhanesA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nhanesA NHANES Data Retrieval Utility to retrieve data from the National Health and Nutrition \n\tExamination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/>.  "
  },
  {
    "id": 16918,
    "package_name": "nimbleCarbon",
    "title": "Bayesian Analyses of Radiocarbon Dates with NIMBLE",
    "description": "Provides utility functions and custom probability distribution for Bayesian analyses of radiocarbon dates within the 'nimble' modelling framework.  It includes various population growth models, nimbleFunction objects, as well as a suite of functions for prior and posterior predictive checks for demographic inference (Crema and Shoda (2021) <doi:10.1371/journal.pone.0251695>) and other analyses.",
    "version": "0.2.6",
    "maintainer": "Enrico Crema <enrico.crema@gmail.com>",
    "author": "Enrico Crema [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6727-5138>),\n  Robert Di Napoli [ctb] (ORCID: <https://orcid.org/0000-0003-2180-2195>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nimbleCarbon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nimbleCarbon Bayesian Analyses of Radiocarbon Dates with NIMBLE Provides utility functions and custom probability distribution for Bayesian analyses of radiocarbon dates within the 'nimble' modelling framework.  It includes various population growth models, nimbleFunction objects, as well as a suite of functions for prior and posterior predictive checks for demographic inference (Crema and Shoda (2021) <doi:10.1371/journal.pone.0251695>) and other analyses.  "
  },
  {
    "id": 16985,
    "package_name": "nna",
    "title": "Nearest-Neighbor Analysis",
    "description": "Calculates spatial pattern analysis using a T-square sample procedure.\n  This method is based on two measures \"x\" and \"y\".\n  \"x\" - Distance from the random point to the nearest individual.\n  \"y\" - Distance from individual to its nearest neighbor.\n  This is a methodology commonly used in phytosociology or marine benthos ecology to analyze the species' distribution (random, uniform or clumped patterns).\n  Ludwig & Reynolds (1988, ISBN:0471832359).",
    "version": "0.0.2.1",
    "maintainer": "Cristiano Pereira <cristianomp@gmail.com>",
    "author": "Cristiano Pereira [aut, cre],\n  Clovis Castro [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nna",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nna Nearest-Neighbor Analysis Calculates spatial pattern analysis using a T-square sample procedure.\n  This method is based on two measures \"x\" and \"y\".\n  \"x\" - Distance from the random point to the nearest individual.\n  \"y\" - Distance from individual to its nearest neighbor.\n  This is a methodology commonly used in phytosociology or marine benthos ecology to analyze the species' distribution (random, uniform or clumped patterns).\n  Ludwig & Reynolds (1988, ISBN:0471832359).  "
  },
  {
    "id": 16987,
    "package_name": "nndiagram",
    "title": "Generator of 'LaTeX' Code for Drawing Neural Network Diagrams\nwith 'TikZ'",
    "description": "Generates 'LaTeX' code for drawing well-formatted neural network diagrams with 'TikZ'. Users have to define number of neurons on each layer, and optionally define neuron connections they would like to keep or omit, layers they consider to be oversized and neurons they would like to draw with lighter color. They can also specify the title of diagram, color, opacity of figure, labels of layers, input and output neurons. In addition, this package helps to produce 'LaTeX' code for drawing activation functions which are crucial in neural network analysis. To make the code work in a 'LaTeX' editor, users need to install and import some 'TeX' packages including 'TikZ' in the setting of 'TeX' file.",
    "version": "1.0.0",
    "maintainer": "Chencheng Fang <ccfang@uni-bonn.de>",
    "author": "Chencheng Fang [aut, cre]",
    "url": "https://github.com/ccfang2/nndiagram",
    "bug_reports": "https://github.com/ccfang2/nndiagram/issues",
    "repository": "https://cran.r-project.org/package=nndiagram",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nndiagram Generator of 'LaTeX' Code for Drawing Neural Network Diagrams\nwith 'TikZ' Generates 'LaTeX' code for drawing well-formatted neural network diagrams with 'TikZ'. Users have to define number of neurons on each layer, and optionally define neuron connections they would like to keep or omit, layers they consider to be oversized and neurons they would like to draw with lighter color. They can also specify the title of diagram, color, opacity of figure, labels of layers, input and output neurons. In addition, this package helps to produce 'LaTeX' code for drawing activation functions which are crucial in neural network analysis. To make the code work in a 'LaTeX' editor, users need to install and import some 'TeX' packages including 'TikZ' in the setting of 'TeX' file.  "
  },
  {
    "id": 17016,
    "package_name": "nomisdata",
    "title": "Access 'Nomis' UK Labour Market Data and Statistics",
    "description": "Interface to the 'Nomis' database (<https://www.nomisweb.co.uk>), a comprehensive resource of United Kingdom labour market statistics provided by the Office for National Statistics (ONS). Facilitates programmatic access to census data, labour force surveys, benefit statistics, and socioeconomic indicators through a modern HTTP client with intelligent caching, automatic query pagination, and tidy data principles. Includes spatial data integration, interactive helpers, and visualization utilities. Independent implementation unaffiliated with ONS or Durham University.",
    "version": "0.1.1",
    "maintainer": "Cheryl Isabella Lim <cheryl.academic@gmail.com>",
    "author": "Cheryl Isabella Lim [aut, cre] (ORCID:\n    <https://orcid.org/0009-0004-5766-1392>)",
    "url": "https://github.com/cherylisabella/nomisdata",
    "bug_reports": "https://github.com/cherylisabella/nomisdata/issues",
    "repository": "https://cran.r-project.org/package=nomisdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nomisdata Access 'Nomis' UK Labour Market Data and Statistics Interface to the 'Nomis' database (<https://www.nomisweb.co.uk>), a comprehensive resource of United Kingdom labour market statistics provided by the Office for National Statistics (ONS). Facilitates programmatic access to census data, labour force surveys, benefit statistics, and socioeconomic indicators through a modern HTTP client with intelligent caching, automatic query pagination, and tidy data principles. Includes spatial data integration, interactive helpers, and visualization utilities. Independent implementation unaffiliated with ONS or Durham University.  "
  },
  {
    "id": 17048,
    "package_name": "normalr",
    "title": "Normalisation of Multiple Variables in Large-Scale Datasets",
    "description": "The robustness of many of the statistical techniques, such as factor analysis, applied in \n          the social sciences rests upon the assumption of item-level normality. However, when dealing \n          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)\n          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for \n          large datasets of continuous variables, its application in current software programs is cumbersome\n          with analysts having to take several steps to normalise each variable. We present an R package \n          'normalr' that enables researchers to make convenient optimal transformations of multiple variables\n          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their \n          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, \n          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their \n          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, \n          kurtosis, and other inferential assessments of normality.",
    "version": "1.0.0",
    "maintainer": "Kevin Chang <k.chang@auckland.ac.nz>",
    "author": "Kevin Chang [aut, cre],\n  Matthew Courtney [aut]",
    "url": "https://github.com/kcha193/normalr",
    "bug_reports": "https://github.com/kcha193/normalr/issues",
    "repository": "https://cran.r-project.org/package=normalr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "normalr Normalisation of Multiple Variables in Large-Scale Datasets The robustness of many of the statistical techniques, such as factor analysis, applied in \n          the social sciences rests upon the assumption of item-level normality. However, when dealing \n          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)\n          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for \n          large datasets of continuous variables, its application in current software programs is cumbersome\n          with analysts having to take several steps to normalise each variable. We present an R package \n          'normalr' that enables researchers to make convenient optimal transformations of multiple variables\n          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their \n          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, \n          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their \n          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, \n          kurtosis, and other inferential assessments of normality.  "
  },
  {
    "id": 17065,
    "package_name": "np",
    "title": "Nonparametric Kernel Smoothing Methods for Mixed Data Types",
    "description": "Nonparametric (and semiparametric) kernel methods that seamlessly handle a mix of continuous, unordered, and ordered factor data types. We would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <https://www.nserc-crsng.gc.ca/>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <https://www.sshrc-crsh.gc.ca/>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://sharcnet.ca/>). We would also like to acknowledge the contributions of the GNU GSL authors. In particular, we adapt the GNU GSL B-spline routine gsl_bspline.c adding automated support for quantile knots (in addition to uniform knots), providing missing functionality for derivatives, and for extending the splines beyond their endpoints.",
    "version": "0.60-18",
    "maintainer": "Jeffrey S. Racine <racinej@mcmaster.ca>",
    "author": "Jeffrey S. Racine [aut, cre],\n  Tristen Hayfield [aut]",
    "url": "https://github.com/JeffreyRacine/R-Package-np",
    "bug_reports": "https://github.com/JeffreyRacine/R-Package-np/issues",
    "repository": "https://cran.r-project.org/package=np",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "np Nonparametric Kernel Smoothing Methods for Mixed Data Types Nonparametric (and semiparametric) kernel methods that seamlessly handle a mix of continuous, unordered, and ordered factor data types. We would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <https://www.nserc-crsng.gc.ca/>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <https://www.sshrc-crsh.gc.ca/>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://sharcnet.ca/>). We would also like to acknowledge the contributions of the GNU GSL authors. In particular, we adapt the GNU GSL B-spline routine gsl_bspline.c adding automated support for quantile knots (in addition to uniform knots), providing missing functionality for derivatives, and for extending the splines beyond their endpoints.  "
  },
  {
    "id": 17112,
    "package_name": "nrba",
    "title": "Methods for Conducting Nonresponse Bias Analysis (NRBA)",
    "description": "Facilitates nonresponse bias analysis (NRBA) \n    for survey data.  Such data may arise from a complex\n    sampling design with features such as stratification, clustering, or\n    unequal probabilities of selection. Multiple types of analyses may be\n    conducted: comparisons of response rates across subgroups; comparisons\n    of estimates before and after weighting adjustments; comparisons of\n    sample-based estimates to external population totals; tests of\n    systematic differences in covariate means between respondents\n    and full samples; tests of independence between response status\n    and covariates; and modeling of outcomes and response status as a \n    function of covariates. Extensive documentation and references are\n    provided for each type of analysis. Krenzke, Van de Kerckhove,\n    and Mohadjer (2005) <http://www.asasrms.org/Proceedings/y2005/files/JSM2005-000572.pdf>\n    and Lohr and Riddles (2016) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2016002/article/14677-eng.pdf?st=q7PyNsGR>\n    provide an overview of the methods implemented in this package.",
    "version": "0.3.1",
    "maintainer": "Ben Schneider <BenjaminSchneider@westat.com>",
    "author": "Ben Schneider [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0406-8470>),\n  Jim Green [aut],\n  Shelley Brock [aut] (Author of original SAS macro, WesNRBA),\n  Tom Krenzke [aut] (Author of original SAS macro, WesNRBA),\n  Michael Jones [aut] (Author of original SAS macro, WesNRBA),\n  Wendy Van de Kerckhove [aut] (Author of original SAS macro, WesNRBA),\n  David Ferraro [aut] (Author of original SAS macro, WesNRBA),\n  Laura Alvarez-Rojas [aut] (Author of original SAS macro, WesNRBA),\n  Katie Hubbell [aut] (Author of original SAS macro, WesNRBA),\n  Westat [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=nrba",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "nrba Methods for Conducting Nonresponse Bias Analysis (NRBA) Facilitates nonresponse bias analysis (NRBA) \n    for survey data.  Such data may arise from a complex\n    sampling design with features such as stratification, clustering, or\n    unequal probabilities of selection. Multiple types of analyses may be\n    conducted: comparisons of response rates across subgroups; comparisons\n    of estimates before and after weighting adjustments; comparisons of\n    sample-based estimates to external population totals; tests of\n    systematic differences in covariate means between respondents\n    and full samples; tests of independence between response status\n    and covariates; and modeling of outcomes and response status as a \n    function of covariates. Extensive documentation and references are\n    provided for each type of analysis. Krenzke, Van de Kerckhove,\n    and Mohadjer (2005) <http://www.asasrms.org/Proceedings/y2005/files/JSM2005-000572.pdf>\n    and Lohr and Riddles (2016) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2016002/article/14677-eng.pdf?st=q7PyNsGR>\n    provide an overview of the methods implemented in this package.  "
  },
  {
    "id": 17160,
    "package_name": "oaqc",
    "title": "Computation of the Orbit-Aware Quad Census",
    "description": "Implements the efficient algorithm by Ortmann and Brandes (2017)\n  <doi:10.1007/s41109-017-0027-2> to compute the orbit-aware frequency distribution of induced and non-induced quads, i.e. subgraphs of size four. Given an edge matrix, data frame, or a graph object (e.g., 'igraph'), the orbit-aware counts are computed respective each of the edges and nodes.",
    "version": "2.0.0",
    "maintainer": "David Schoch <david@schochastics.net>",
    "author": "Mark Ortmann [aut],\n  Felix Schoenenberger [aut],\n  David Schoch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://github.com/schochastics/oaqc",
    "bug_reports": "https://github.com/schochastics/oaqc/issues",
    "repository": "https://cran.r-project.org/package=oaqc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oaqc Computation of the Orbit-Aware Quad Census Implements the efficient algorithm by Ortmann and Brandes (2017)\n  <doi:10.1007/s41109-017-0027-2> to compute the orbit-aware frequency distribution of induced and non-induced quads, i.e. subgraphs of size four. Given an edge matrix, data frame, or a graph object (e.g., 'igraph'), the orbit-aware counts are computed respective each of the edges and nodes.  "
  },
  {
    "id": 17164,
    "package_name": "obfuscatoR",
    "title": "Obfuscation Game Designs",
    "description": "When people make decisions, they may do so using a wide variety of decision rules. The package allows users to easily create obfuscation games to test the obfuscation hypothesis. It provides an easy to use interface and multiple options designed to vary the difficulty of the game and tailor it to the user's needs. For more detail: Chorus et al., 2021, Obfuscation maximization-based decision-making: Theory, methodology and first empirical evidence, Mathematical Social Sciences, 109, 28-44, <doi:10.1016/j.mathsocsci.2020.10.002>. ",
    "version": "0.2.2",
    "maintainer": "Erlend Dancke Sandorf <erlend.dancke.sandorf@nmbu.no>",
    "author": "Erlend Dancke Sandorf [aut, cre],\n  Caspar Chorus [aut],\n  Sander van Cranenburgh [aut]",
    "url": "https://obfuscator.edsandorf.me,\nhttps://github.com/edsandorf/obfuscatoR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=obfuscatoR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "obfuscatoR Obfuscation Game Designs When people make decisions, they may do so using a wide variety of decision rules. The package allows users to easily create obfuscation games to test the obfuscation hypothesis. It provides an easy to use interface and multiple options designed to vary the difficulty of the game and tailor it to the user's needs. For more detail: Chorus et al., 2021, Obfuscation maximization-based decision-making: Theory, methodology and first empirical evidence, Mathematical Social Sciences, 109, 28-44, <doi:10.1016/j.mathsocsci.2020.10.002>.   "
  },
  {
    "id": 17173,
    "package_name": "occumb",
    "title": "Site Occupancy Modeling for Environmental DNA Metabarcoding",
    "description": "Fits community site occupancy models to environmental DNA\n    metabarcoding data collected using spatially-replicated survey design.\n    Model fitting results can be used to evaluate and compare the effectiveness\n    of species detection to find an efficient survey design.\n    Reference: Fukaya et al. (2022) <doi:10.1111/2041-210X.13732>,\n    Fukaya and Hasebe (2025) <doi:10.1002/1438-390X.12219>.",
    "version": "1.2.1",
    "maintainer": "Keiichi Fukaya <fukayak99@gmail.com>",
    "author": "Keiichi Fukaya [aut, cre],\n  Ken Kellner [cph] (summary method for occumbFit class),\n  Mika Takahashi [aut]",
    "url": "https://fukayak.github.io/occumb/,\nhttps://github.com/fukayak/occumb",
    "bug_reports": "https://github.com/fukayak/occumb/issues",
    "repository": "https://cran.r-project.org/package=occumb",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "occumb Site Occupancy Modeling for Environmental DNA Metabarcoding Fits community site occupancy models to environmental DNA\n    metabarcoding data collected using spatially-replicated survey design.\n    Model fitting results can be used to evaluate and compare the effectiveness\n    of species detection to find an efficient survey design.\n    Reference: Fukaya et al. (2022) <doi:10.1111/2041-210X.13732>,\n    Fukaya and Hasebe (2025) <doi:10.1002/1438-390X.12219>.  "
  },
  {
    "id": 17196,
    "package_name": "odbr",
    "title": "Download Data from Brazil's Origin Destination Surveys",
    "description": "Download data from Brazil's Origin Destination Surveys. The package covers both data from household travel surveys, dictionaries of variables, and the spatial geometries of surveys conducted in different years and across various urban areas in Brazil. For some cities, the package will include enhanced versions of the data sets with variables \"harmonized\" across different years.",
    "version": "0.1.1",
    "maintainer": "Haydee Svab <hsvab@hsvab.eng.br>",
    "author": "Haydee Svab [aut, cre],\n  Beatriz Milz [aut] (ORCID: <https://orcid.org/0000-0002-3064-4486>),\n  Diego Rabatone Oliveira [aut],\n  Rafael H. M. Pereira [aut] (ORCID:\n    <https://orcid.org/0000-0003-2125-7465>)",
    "url": "https://hsvab.github.io/odbr/, https://github.com/hsvab/odbr",
    "bug_reports": "https://github.com/hsvab/odbr/issues",
    "repository": "https://cran.r-project.org/package=odbr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "odbr Download Data from Brazil's Origin Destination Surveys Download data from Brazil's Origin Destination Surveys. The package covers both data from household travel surveys, dictionaries of variables, and the spatial geometries of surveys conducted in different years and across various urban areas in Brazil. For some cities, the package will include enhanced versions of the data sets with variables \"harmonized\" across different years.  "
  },
  {
    "id": 17225,
    "package_name": "oii",
    "title": "Crosstab and Statistical Tests for OII MSc Stats Course",
    "description": "Provides simple crosstab output with optional statistics (e.g., Goodman-Kruskal Gamma, Somers' d, and Kendall's tau-b) as well as two-way and one-way tables. The package is used within the statistics component of the Masters of Science (MSc) in Social Science of the Internet at the Oxford Internet Institute (OII), University of Oxford, but the functions should be useful for general data analysis and especially for analysis of categorical and ordinal data.",
    "version": "1.0.2.1",
    "maintainer": "Scott Hale <scott.hale@oii.ox.ac.uk>",
    "author": "Scott Hale [aut, cre],\n  Jon Bright [aut],\n  Grant Blank [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=oii",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "oii Crosstab and Statistical Tests for OII MSc Stats Course Provides simple crosstab output with optional statistics (e.g., Goodman-Kruskal Gamma, Somers' d, and Kendall's tau-b) as well as two-way and one-way tables. The package is used within the statistics component of the Masters of Science (MSc) in Social Science of the Internet at the Oxford Internet Institute (OII), University of Oxford, but the functions should be useful for general data analysis and especially for analysis of categorical and ordinal data.  "
  },
  {
    "id": 17245,
    "package_name": "onadata",
    "title": "Data Sets for Keith McNulty's Handbook of Graphs and Networks in\nPeople Analytics",
    "description": "Data sets for network analysis related to People Analytics.  \n  Contains various data sets from the book 'Handbook of Graphs and Networks in People Analytics' \n  by Keith McNulty (2021).",
    "version": "0.1",
    "maintainer": "Keith McNulty <keith.mcnulty@gmail.com>",
    "author": "Keith McNulty [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2332-1654>)",
    "url": "https://ona-book.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=onadata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "onadata Data Sets for Keith McNulty's Handbook of Graphs and Networks in\nPeople Analytics Data sets for network analysis related to People Analytics.  \n  Contains various data sets from the book 'Handbook of Graphs and Networks in People Analytics' \n  by Keith McNulty (2021).  "
  },
  {
    "id": 17267,
    "package_name": "onmaRg",
    "title": "Import Public Health Ontario's Ontario Marginalization Index",
    "description": "The Ontario Marginalization Index is a socioeconomic model that is built on Statistics Canada census data.\n    The model consists of four dimensions: In 2021, these dimensions were updated to \"Material Resources\" (previously called \"Material Deprivation\"), \"Households and Dwellings\" (previously called \"Residential Instability\"), \"Age and Labour Force\" (previously called \"Dependency\"), and \"Racialized and Newcomer Populations\" (previously called \"Ethnic Concentration\").\n    This update reflects a movement away from deficit-based language. 2021 data will load with these new dimension names, wheras 2011 and 2016 data will load with the historical dimension names.\n    Each of these dimensions are imported for a variety of geographic levels (DA, CD, etc.) for the 2021, 2011 and 2016 administrations of the census.\n    These data sets contribute to community analysis of equity with respect to Ontario's Anti-Racism Act.\n    The Ontario Marginalization Index data is retrieved from the Public Health Ontario website: <https://www.publichealthontario.ca/en/data-and-analysis/health-equity/ontario-marginalization-index>.\n    The shapefile data is retrieved from the Statistics Canada website: <https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-eng.cfm>.",
    "version": "1.0.3",
    "maintainer": "William Conley <william@cconley.ca>",
    "author": "William Conley [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=onmaRg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "onmaRg Import Public Health Ontario's Ontario Marginalization Index The Ontario Marginalization Index is a socioeconomic model that is built on Statistics Canada census data.\n    The model consists of four dimensions: In 2021, these dimensions were updated to \"Material Resources\" (previously called \"Material Deprivation\"), \"Households and Dwellings\" (previously called \"Residential Instability\"), \"Age and Labour Force\" (previously called \"Dependency\"), and \"Racialized and Newcomer Populations\" (previously called \"Ethnic Concentration\").\n    This update reflects a movement away from deficit-based language. 2021 data will load with these new dimension names, wheras 2011 and 2016 data will load with the historical dimension names.\n    Each of these dimensions are imported for a variety of geographic levels (DA, CD, etc.) for the 2021, 2011 and 2016 administrations of the census.\n    These data sets contribute to community analysis of equity with respect to Ontario's Anti-Racism Act.\n    The Ontario Marginalization Index data is retrieved from the Public Health Ontario website: <https://www.publichealthontario.ca/en/data-and-analysis/health-equity/ontario-marginalization-index>.\n    The shapefile data is retrieved from the Statistics Canada website: <https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-eng.cfm>.  "
  },
  {
    "id": 17346,
    "package_name": "optimStrat",
    "title": "Choosing the Sample Strategy",
    "description": "Intended to assist in the choice of the sampling strategy to implement in a survey.",
    "version": "2.4",
    "maintainer": "Edgar Bueno <edgar.bueno@stat.su.se>",
    "author": "Edgar Bueno <edgar.bueno@stat.su.se>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=optimStrat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optimStrat Choosing the Sample Strategy Intended to assist in the choice of the sampling strategy to implement in a survey.  "
  },
  {
    "id": 17348,
    "package_name": "optimall",
    "title": "Allocate Samples Among Strata",
    "description": "Functions for the design process of survey sampling, with specific tools for multi-wave and multi-phase designs. Perform optimum allocation using Neyman (1934) <doi:10.2307/2342192> or Wright (2012) <doi:10.1080/00031305.2012.733679> allocation, split strata based on quantiles or values of known variables, randomly select samples from strata, allocate sampling waves iteratively, and organize a complex survey design. Also includes a Shiny application for observing the effects of different strata splits. A paper on this package was published in the Journal of Statistical Software <doi:10.18637/jss.v114.i10>.",
    "version": "1.3.0",
    "maintainer": "Jasper Yang <jbyang@uw.edu>",
    "author": "Jasper Yang [aut, cre],\n  Pamela Shaw [aut],\n  Bryan Shepherd [ctb],\n  Thomas Lumley [ctb],\n  Gustavo Amorim [rev]",
    "url": "https://github.com/yangjasp/optimall",
    "bug_reports": "https://github.com/yangjasp/optimall/issues",
    "repository": "https://cran.r-project.org/package=optimall",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "optimall Allocate Samples Among Strata Functions for the design process of survey sampling, with specific tools for multi-wave and multi-phase designs. Perform optimum allocation using Neyman (1934) <doi:10.2307/2342192> or Wright (2012) <doi:10.1080/00031305.2012.733679> allocation, split strata based on quantiles or values of known variables, randomly select samples from strata, allocate sampling waves iteratively, and organize a complex survey design. Also includes a Shiny application for observing the effects of different strata splits. A paper on this package was published in the Journal of Statistical Software <doi:10.18637/jss.v114.i10>.  "
  },
  {
    "id": 17374,
    "package_name": "ordbetareg",
    "title": "Ordered Beta Regression Models with 'brms'",
    "description": "Implements ordered beta regression models, which are for modeling continuous variables with upper and lower bounds, such as\n   survey sliders, dose-response relationships and indexes. For more information, see\n   Kubinec (2023) <doi:10.31235/osf.io/2sx6y>. The package is a front-end to the R package 'brms', which \n   facilitates a range of regression specifications, including hierarchical, dynamic and\n   multivariate modeling.",
    "version": "0.8",
    "maintainer": "Robert Kubinec <bobkubinec@gmail.com>",
    "author": "Robert Kubinec [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6655-4119>)",
    "url": "",
    "bug_reports": "https://github.com/saudiwin/ordbetareg_pack/issues",
    "repository": "https://cran.r-project.org/package=ordbetareg",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ordbetareg Ordered Beta Regression Models with 'brms' Implements ordered beta regression models, which are for modeling continuous variables with upper and lower bounds, such as\n   survey sliders, dose-response relationships and indexes. For more information, see\n   Kubinec (2023) <doi:10.31235/osf.io/2sx6y>. The package is a front-end to the R package 'brms', which \n   facilitates a range of regression specifications, including hierarchical, dynamic and\n   multivariate modeling.  "
  },
  {
    "id": 17417,
    "package_name": "osbng",
    "title": "Geospatial Grid Indexing with the British National Grid",
    "description": "Offers a streamlined programmatic interface to Ordnance Survey's \n    British National Grid (BNG) index system, enabling efficient spatial \n    indexing and analysis based on grid references. It supports a range of \n    geospatial applications, including statistical aggregation, data \n    visualisation, and interoperability across datasets. Designed for \n    developers and analysts working with geospatial data in Great Britain, \n    'osbng' simplifies integration with geospatial workflows and provides \n    intuitive tools for exploring the structure and logic of the BNG system.",
    "version": "0.2.0",
    "maintainer": "Chris Jochem <chris.jochem@os.uk>",
    "author": "Chris Jochem [cre, aut],\n  Ordnance Survey Ltd [cph, fnd],\n  Steve Kingston [ctb],\n  Kate New [ctb],\n  Tom Peterken [ctb]",
    "url": "https://ordnancesurvey.github.io/osbng-r/,\nhttps://github.com/OrdnanceSurvey/osbng-r",
    "bug_reports": "https://github.com/OrdnanceSurvey/osbng-r/issues",
    "repository": "https://cran.r-project.org/package=osbng",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "osbng Geospatial Grid Indexing with the British National Grid Offers a streamlined programmatic interface to Ordnance Survey's \n    British National Grid (BNG) index system, enabling efficient spatial \n    indexing and analysis based on grid references. It supports a range of \n    geospatial applications, including statistical aggregation, data \n    visualisation, and interoperability across datasets. Designed for \n    developers and analysts working with geospatial data in Great Britain, \n    'osbng' simplifies integration with geospatial workflows and provides \n    intuitive tools for exploring the structure and logic of the BNG system.  "
  },
  {
    "id": 17421,
    "package_name": "osdatahub",
    "title": "Easier Interaction with the Ordnance Survey Data Hub",
    "description": "Ordnance Survey ('OS') is the national mapping agency for Great \n    Britain and produces a large variety of mapping and geospatial products. \n    Much of OS's data is available via the OS Data Hub <https://osdatahub.os.uk/>, \n    a platform that hosts both free and premium data products. 'osdatahub' \n    provides a user-friendly way to access, query, and download these data.",
    "version": "0.3.0",
    "maintainer": "Chris Jochem <chris.jochem@os.uk>",
    "author": "Chris Jochem [cre, aut],\n  Ordnance Survey Ltd [cph, fnd]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=osdatahub",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "osdatahub Easier Interaction with the Ordnance Survey Data Hub Ordnance Survey ('OS') is the national mapping agency for Great \n    Britain and produces a large variety of mapping and geospatial products. \n    Much of OS's data is available via the OS Data Hub <https://osdatahub.os.uk/>, \n    a platform that hosts both free and premium data products. 'osdatahub' \n    provides a user-friendly way to access, query, and download these data.  "
  },
  {
    "id": 17440,
    "package_name": "ouladFormat",
    "title": "Loads and Formats the Open University Learning Analytics Dataset\nfor Data Analysis",
    "description": "The Open University Learning Analytics Dataset (OULAD) is available from \n    Kuzilek et al. (2017) <doi:10.1038/sdata.2017.171>.  The 'ouladFormat' \n    package loads, cleans and formats the OULAD for data analysis (each row of the\n    returned data set is an individual student). The package\u2019s main function,\n    combined_dataset(), allows the user to choose whether the returned\n    data set includes assessment, demographics, virtual learning environment (VLE),\n    or registration variables etc.",
    "version": "1.2.2",
    "maintainer": "Emma Howard <emhoward@tcd.ie>",
    "author": "Emma Howard [aut, cre] (ORCID: <https://orcid.org/0000-0002-8104-1351>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ouladFormat",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ouladFormat Loads and Formats the Open University Learning Analytics Dataset\nfor Data Analysis The Open University Learning Analytics Dataset (OULAD) is available from \n    Kuzilek et al. (2017) <doi:10.1038/sdata.2017.171>.  The 'ouladFormat' \n    package loads, cleans and formats the OULAD for data analysis (each row of the\n    returned data set is an individual student). The package\u2019s main function,\n    combined_dataset(), allows the user to choose whether the returned\n    data set includes assessment, demographics, virtual learning environment (VLE),\n    or registration variables etc.  "
  },
  {
    "id": 17522,
    "package_name": "palaeoverse",
    "title": "Prepare and Explore Data for Palaeobiological Analyses",
    "description": "Provides functionality to support data preparation and exploration for\n  palaeobiological analyses, improving code reproducibility and accessibility. The\n  wider aim of 'palaeoverse' is to bring the palaeobiological community together \n  to establish agreed standards. The package currently includes functionality for \n  data cleaning, binning (time and space), exploration, summarisation and \n  visualisation. Reference datasets (i.e. Geological Time Scales <https://stratigraphy.org/chart>)\n  and auxiliary functions are also provided. Details can be found in:\n  Jones et al., (2023) <doi: 10.1111/2041-210X.14099>.",
    "version": "1.4.0",
    "maintainer": "Lewis A. Jones <LewisA.Jones@outlook.com>",
    "author": "Lewis A. Jones [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3902-8986>),\n  William Gearty [aut] (ORCID: <https://orcid.org/0000-0003-0076-3262>),\n  Bethany J. Allen [aut] (ORCID: <https://orcid.org/0000-0003-0282-6407>),\n  Kilian Eichenseer [aut] (ORCID:\n    <https://orcid.org/0000-0002-0477-8878>),\n  Christopher D. Dean [aut] (ORCID:\n    <https://orcid.org/0000-0001-6471-6903>),\n  Sofia Galvan [ctb] (ORCID: <https://orcid.org/0000-0002-3092-4314>),\n  Miranta Kouvari [ctb] (ORCID: <https://orcid.org/0000-0002-5442-6221>),\n  Pedro L. Godoy [ctb] (ORCID: <https://orcid.org/0000-0003-4519-5094>),\n  Cecily Nicholl [ctb] (ORCID: <https://orcid.org/0000-0003-2860-2604>),\n  Lucas Buffan [ctb] (ORCID: <https://orcid.org/0000-0002-2353-1432>),\n  Erin M. Dillon [ctb] (ORCID: <https://orcid.org/0000-0003-0249-027X>),\n  Joseph T. Flannery-Sutherland [aut] (ORCID:\n    <https://orcid.org/0000-0001-8232-6773>),\n  A. Alessandro Chiarenza [ctb] (ORCID:\n    <https://orcid.org/0000-0001-5525-6730>)",
    "url": "https://palaeoverse.palaeoverse.org,\nhttps://github.com/palaeoverse/palaeoverse,\nhttps://palaeoverse.org",
    "bug_reports": "https://github.com/palaeoverse/palaeoverse/issues",
    "repository": "https://cran.r-project.org/package=palaeoverse",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "palaeoverse Prepare and Explore Data for Palaeobiological Analyses Provides functionality to support data preparation and exploration for\n  palaeobiological analyses, improving code reproducibility and accessibility. The\n  wider aim of 'palaeoverse' is to bring the palaeobiological community together \n  to establish agreed standards. The package currently includes functionality for \n  data cleaning, binning (time and space), exploration, summarisation and \n  visualisation. Reference datasets (i.e. Geological Time Scales <https://stratigraphy.org/chart>)\n  and auxiliary functions are also provided. Details can be found in:\n  Jones et al., (2023) <doi: 10.1111/2041-210X.14099>.  "
  },
  {
    "id": 17526,
    "package_name": "paleoDiv",
    "title": "Extracting and Visualizing Paleobiodiversity",
    "description": "Contains various tools for conveniently downloading and editing taxon-specific datasets from the Paleobiology Database <https://paleobiodb.org>, extracting information on abundance, temporal distribution of subtaxa and taxonomic diversity through deep time, and visualizing these data in relation to phylogeny and stratigraphy.",
    "version": "0.4.6",
    "maintainer": "Darius Nau <dariusnau@gmx.at>",
    "author": "Darius Nau [aut, cre] (ORCID: <https://orcid.org/0009-0000-4343-6830>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=paleoDiv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paleoDiv Extracting and Visualizing Paleobiodiversity Contains various tools for conveniently downloading and editing taxon-specific datasets from the Paleobiology Database <https://paleobiodb.org>, extracting information on abundance, temporal distribution of subtaxa and taxonomic diversity through deep time, and visualizing these data in relation to phylogeny and stratigraphy.  "
  },
  {
    "id": 17531,
    "package_name": "paleotree",
    "title": "Paleontological and Phylogenetic Analyses of Evolution",
    "description": "Provides tools for transforming, a posteriori time-scaling, and\n    modifying phylogenies containing extinct (i.e. fossil) lineages. In particular,\n    most users are interested in the functions timePaleoPhy, bin_timePaleoPhy,\n    cal3TimePaleoPhy and bin_cal3TimePaleoPhy, which date cladograms of\n    fossil taxa using stratigraphic data. This package also contains a large number\n    of likelihood functions for estimating sampling and diversification rates from\n    different types of data available from the fossil record (e.g. range data,\n    occurrence data, etc). paleotree users can also simulate diversification and\n    sampling in the fossil record using the function simFossilRecord, which is a\n    detailed simulator for branching birth-death-sampling processes composed of\n    discrete taxonomic units arranged in ancestor-descendant relationships. Users\n    can use simFossilRecord to simulate diversification in incompletely sampled\n    fossil records, under various models of morphological differentiation (i.e.\n    the various patterns by which morphotaxa originate from one another), and\n    with time-dependent, longevity-dependent and/or diversity-dependent rates of\n    diversification, extinction and sampling. Additional functions allow users to\n    translate simulated ancestor-descendant data from simFossilRecord into standard\n    time-scaled phylogenies or unscaled cladograms that reflect the relationships\n    among taxon units.",
    "version": "3.4.7",
    "maintainer": "David W. Bapst <dwbapst@gmail.com>",
    "author": "David W. Bapst, Peter J. Wagner",
    "url": "https://github.com/dwbapst/paleotree",
    "bug_reports": "https://github.com/dwbapst/paleotree/issues",
    "repository": "https://cran.r-project.org/package=paleotree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paleotree Paleontological and Phylogenetic Analyses of Evolution Provides tools for transforming, a posteriori time-scaling, and\n    modifying phylogenies containing extinct (i.e. fossil) lineages. In particular,\n    most users are interested in the functions timePaleoPhy, bin_timePaleoPhy,\n    cal3TimePaleoPhy and bin_cal3TimePaleoPhy, which date cladograms of\n    fossil taxa using stratigraphic data. This package also contains a large number\n    of likelihood functions for estimating sampling and diversification rates from\n    different types of data available from the fossil record (e.g. range data,\n    occurrence data, etc). paleotree users can also simulate diversification and\n    sampling in the fossil record using the function simFossilRecord, which is a\n    detailed simulator for branching birth-death-sampling processes composed of\n    discrete taxonomic units arranged in ancestor-descendant relationships. Users\n    can use simFossilRecord to simulate diversification in incompletely sampled\n    fossil records, under various models of morphological differentiation (i.e.\n    the various patterns by which morphotaxa originate from one another), and\n    with time-dependent, longevity-dependent and/or diversity-dependent rates of\n    diversification, extinction and sampling. Additional functions allow users to\n    translate simulated ancestor-descendant data from simFossilRecord into standard\n    time-scaled phylogenies or unscaled cladograms that reflect the relationships\n    among taxon units.  "
  },
  {
    "id": 17539,
    "package_name": "palm",
    "title": "Fitting Point Process Models via the Palm Likelihood",
    "description": "Functions to fit point process models using the Palm likelihood. First proposed by Tanaka, Ogata, and Stoyan (2008) <DOI:10.1002/bimj.200610339>, maximisation of the Palm likelihood can provide computationally efficient parameter estimation for point process models in situations where the full likelihood is intractable. This package is chiefly focused on Neyman-Scott point processes, but can also fit the void processes proposed by Jones-Todd et al. (2019) <DOI:10.1002/sim.8046>. The development of this package was motivated by the analysis of capture-recapture surveys on which individuals cannot be identified---the data from which can conceptually be seen as a clustered point process (Stevenson, Borchers, and Fewster, 2019 <DOI:10.1111/biom.12983>). As such, some of the functions in this package are specifically for the estimation of cetacean density from two-camera aerial surveys.",
    "version": "1.1.6",
    "maintainer": "Ben Stevenson <ben.stevenson@auckland.ac.nz>",
    "author": "Ben Stevenson [aut, cre]",
    "url": "https://github.com/b-steve/palm",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=palm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "palm Fitting Point Process Models via the Palm Likelihood Functions to fit point process models using the Palm likelihood. First proposed by Tanaka, Ogata, and Stoyan (2008) <DOI:10.1002/bimj.200610339>, maximisation of the Palm likelihood can provide computationally efficient parameter estimation for point process models in situations where the full likelihood is intractable. This package is chiefly focused on Neyman-Scott point processes, but can also fit the void processes proposed by Jones-Todd et al. (2019) <DOI:10.1002/sim.8046>. The development of this package was motivated by the analysis of capture-recapture surveys on which individuals cannot be identified---the data from which can conceptually be seen as a clustered point process (Stevenson, Borchers, and Fewster, 2019 <DOI:10.1111/biom.12983>). As such, some of the functions in this package are specifically for the estimation of cetacean density from two-camera aerial surveys.  "
  },
  {
    "id": 17562,
    "package_name": "pannotator",
    "title": "Visualisation and Annotation of 360 Degree Imagery",
    "description": "Provides a customisable R 'shiny' app for immersively\n    visualising, mapping and annotating panospheric (360 degree) imagery.\n    The flexible interface allows annotation of any geocoded images using\n    up to 4 user specified dropdown menus. The app uses 'leaflet' to\n    render maps that display the geo-locations of images and panellum\n    <https://pannellum.org/>, a lightweight panorama viewer for the web,\n    to render images in virtual 360 degree viewing mode. Key functions\n    include the ability to draw on & export parts of 360 images for\n    downstream applications. Users can also draw polygons and points on\n    map imagery related to the panoramic images and export them for\n    further analysis. Downstream applications include using annotations to\n    train Artificial Intelligence/Machine Learning (AI/ML) models and\n    geospatial modelling and analysis of camera based survey data.",
    "version": "1.0.0.4",
    "maintainer": "Nunzio Knerr <Nunzio.Knerr@csiro.au>",
    "author": "Nunzio Knerr [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0562-9479>),\n  Robert Godfree [aut] (ORCID: <https://orcid.org/0000-0002-4263-2917>),\n  Matthew Petroff [ctb],\n  CSIRO [cph]",
    "url": "https://github.com/NunzioKnerr/pannotator_package_source",
    "bug_reports": "https://github.com/NunzioKnerr/pannotator_package_source/issues",
    "repository": "https://cran.r-project.org/package=pannotator",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pannotator Visualisation and Annotation of 360 Degree Imagery Provides a customisable R 'shiny' app for immersively\n    visualising, mapping and annotating panospheric (360 degree) imagery.\n    The flexible interface allows annotation of any geocoded images using\n    up to 4 user specified dropdown menus. The app uses 'leaflet' to\n    render maps that display the geo-locations of images and panellum\n    <https://pannellum.org/>, a lightweight panorama viewer for the web,\n    to render images in virtual 360 degree viewing mode. Key functions\n    include the ability to draw on & export parts of 360 images for\n    downstream applications. Users can also draw polygons and points on\n    map imagery related to the panoramic images and export them for\n    further analysis. Downstream applications include using annotations to\n    train Artificial Intelligence/Machine Learning (AI/ML) models and\n    geospatial modelling and analysis of camera based survey data.  "
  },
  {
    "id": 17563,
    "package_name": "panstarrs",
    "title": "Interface to the Pan-STARRS API",
    "description": "An interface to the API for 'Pan-STARRS1', a data archive of\n    the PS1 wide-field astronomical survey.  The package allows access to\n    the PS1 catalog and to the PS1 images.  (see\n    <https://outerspace.stsci.edu/display/PANSTARRS/> for more\n    information).  You can use it to plan astronomical observations, make\n    guidance pictures, find magnitudes in five broadband filters (g, r, i,\n    z, y) and more.",
    "version": "0.2.3",
    "maintainer": "Grigory Uskov <uskov.russia@gmail.com>",
    "author": "Grigory Uskov [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-0274-1350>)",
    "url": "https://uskovgs.github.io/PanSTARRS/",
    "bug_reports": "https://github.com/uskovgs/PanSTARRS/issues",
    "repository": "https://cran.r-project.org/package=panstarrs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "panstarrs Interface to the Pan-STARRS API An interface to the API for 'Pan-STARRS1', a data archive of\n    the PS1 wide-field astronomical survey.  The package allows access to\n    the PS1 catalog and to the PS1 images.  (see\n    <https://outerspace.stsci.edu/display/PANSTARRS/> for more\n    information).  You can use it to plan astronomical observations, make\n    guidance pictures, find magnitudes in five broadband filters (g, r, i,\n    z, y) and more.  "
  },
  {
    "id": 17579,
    "package_name": "paramDemo",
    "title": "Parametric and Non-Parametric Demographic Functions and\nApplications",
    "description": "Calculate parametric mortality and Fertility models, following packages 'BaSTA' in Colchero, Jones and Rebke (2012) <doi:10.1111/j.2041-210X.2012.00186.x> and 'BaFTA' <https://github.com/fercol/BaFTA>, summary statistics (e.g. ageing rates, life expectancy, lifespan equality, etc.), life table and product limit estimators from census data.",
    "version": "1.0.2",
    "maintainer": "Fernando Colchero <fernando_colchero@eva.mpg.de>",
    "author": "Fernando Colchero [aut, cre]",
    "url": "",
    "bug_reports": "https://github.com/fercol/paramDemo/issues",
    "repository": "https://cran.r-project.org/package=paramDemo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "paramDemo Parametric and Non-Parametric Demographic Functions and\nApplications Calculate parametric mortality and Fertility models, following packages 'BaSTA' in Colchero, Jones and Rebke (2012) <doi:10.1111/j.2041-210X.2012.00186.x> and 'BaFTA' <https://github.com/fercol/BaFTA>, summary statistics (e.g. ageing rates, life expectancy, lifespan equality, etc.), life table and product limit estimators from census data.  "
  },
  {
    "id": 17648,
    "package_name": "pawacc",
    "title": "Physical Activity with Accelerometers",
    "description": "Functions to process, format and store ActiGraph GT1M and GT3X accelerometer data.",
    "version": "1.2.4",
    "maintainer": "Marco Geraci <marco.geraci@uniroma1.it>",
    "author": "Marco Geraci [aut, cph, cre] (ORCID:\n    <https://orcid.org/0000-0002-6311-8685>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pawacc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pawacc Physical Activity with Accelerometers Functions to process, format and store ActiGraph GT1M and GT3X accelerometer data.  "
  },
  {
    "id": 17694,
    "package_name": "pcds",
    "title": "Proximity Catch Digraphs and Their Applications",
    "description": "Contains the functions for construction and visualization of various families \n    of the proximity catch digraphs (PCDs), see (Ceyhan (2005) ISBN:978-3-639-19063-2),\n    for computing the graph invariants for testing the patterns of segregation and association against complete spatial randomness (CSR)\n    or uniformity in one, two and three dimensional cases.\n    The package also has tools for generating points from these spatial patterns.\n    The graph invariants used in testing spatial point data are the domination number (Ceyhan (2011)\n    <doi:10.1080/03610921003597211>) and arc density (Ceyhan et al. (2006) <doi:10.1016/j.csda.2005.03.002>;\n    Ceyhan et al. (2007) <doi:10.1002/cjs.5550350106>). The PCD families considered are Arc-Slice PCDs,\n    Proportional-Edge PCDs, and Central Similarity PCDs. ",
    "version": "0.1.8",
    "maintainer": "Elvan Ceyhan <elvanceyhan@gmail.com>",
    "author": "Elvan Ceyhan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pcds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pcds Proximity Catch Digraphs and Their Applications Contains the functions for construction and visualization of various families \n    of the proximity catch digraphs (PCDs), see (Ceyhan (2005) ISBN:978-3-639-19063-2),\n    for computing the graph invariants for testing the patterns of segregation and association against complete spatial randomness (CSR)\n    or uniformity in one, two and three dimensional cases.\n    The package also has tools for generating points from these spatial patterns.\n    The graph invariants used in testing spatial point data are the domination number (Ceyhan (2011)\n    <doi:10.1080/03610921003597211>) and arc density (Ceyhan et al. (2006) <doi:10.1016/j.csda.2005.03.002>;\n    Ceyhan et al. (2007) <doi:10.1002/cjs.5550350106>). The PCD families considered are Arc-Slice PCDs,\n    Proportional-Edge PCDs, and Central Similarity PCDs.   "
  },
  {
    "id": 17695,
    "package_name": "pcds.ugraph",
    "title": "Underlying Graphs of Proximity Catch Digraphs and Their\nApplications",
    "description": "Contains the functions for construction and visualization of underlying and reflexivity graphs of \n            the three families of the proximity catch digraphs (PCDs), see (Ceyhan (2005) ISBN:978-3-639-19063-2),\n            and for computing the edge density of these PCD-based graphs which are then\n            used for testing the patterns of segregation and association against complete spatial randomness (CSR))\n            or uniformity in one and two dimensional cases. \n            The PCD families considered are Arc-Slice PCDs, Proportional-Edge (PE) PCDs (Ceyhan et al. (2006) <doi:10.1016/j.csda.2005.03.002>) \n            and Central Similarity PCDs (Ceyhan et al. (2007) <doi:10.1002/cjs.5550350106>). \n            See also (Ceyhan (2016) <doi:10.1016/j.stamet.2016.07.003>) for edge density of the underlying and \n            reflexivity graphs of PE-PCDs.\n            The package also has tools for visualization of PCD-based graphs for one, two, and three dimensional data. ",
    "version": "0.1.1",
    "maintainer": "Elvan Ceyhan <elvanceyhan@gmail.com>",
    "author": "Elvan Ceyhan [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pcds.ugraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pcds.ugraph Underlying Graphs of Proximity Catch Digraphs and Their\nApplications Contains the functions for construction and visualization of underlying and reflexivity graphs of \n            the three families of the proximity catch digraphs (PCDs), see (Ceyhan (2005) ISBN:978-3-639-19063-2),\n            and for computing the edge density of these PCD-based graphs which are then\n            used for testing the patterns of segregation and association against complete spatial randomness (CSR))\n            or uniformity in one and two dimensional cases. \n            The PCD families considered are Arc-Slice PCDs, Proportional-Edge (PE) PCDs (Ceyhan et al. (2006) <doi:10.1016/j.csda.2005.03.002>) \n            and Central Similarity PCDs (Ceyhan et al. (2007) <doi:10.1002/cjs.5550350106>). \n            See also (Ceyhan (2016) <doi:10.1016/j.stamet.2016.07.003>) for edge density of the underlying and \n            reflexivity graphs of PE-PCDs.\n            The package also has tools for visualization of PCD-based graphs for one, two, and three dimensional data.   "
  },
  {
    "id": 17814,
    "package_name": "persval",
    "title": "Computing Personal Values Scores",
    "description": "Compute personal values scores from various questionnaires based on the theoretical constructs proposed by professor Shalom H. Schwartz. Designed for researchers and practitioners in psychology, sociology, and related fields, the package facilitates the quantification and visualization of different dimensions related to personal values from survey data. It incorporates the recommended statistical adjustment to enhance the accuracy and interpretation of the results.   ",
    "version": "1.1.2",
    "maintainer": "Giuseppe Corbelli <giuseppe.corbelli@uninettunouniversity.net>",
    "author": "Giuseppe Corbelli [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2864-3548>)",
    "url": "https://github.com/g-corbelli/persval",
    "bug_reports": "https://github.com/g-corbelli/persval/issues",
    "repository": "https://cran.r-project.org/package=persval",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "persval Computing Personal Values Scores Compute personal values scores from various questionnaires based on the theoretical constructs proposed by professor Shalom H. Schwartz. Designed for researchers and practitioners in psychology, sociology, and related fields, the package facilitates the quantification and visualization of different dimensions related to personal values from survey data. It incorporates the recommended statistical adjustment to enhance the accuracy and interpretation of the results.     "
  },
  {
    "id": 17824,
    "package_name": "pewdata",
    "title": "Reproducible Retrieval of Pew Research Center Datasets",
    "description": "Reproducible, programmatic retrieval of survey datasets from the\n    Pew Research Center.",
    "version": "0.3.2",
    "maintainer": "Frederick Solt <frederick-solt@uiowa.edu>",
    "author": "Frederick Solt [aut, cre],\n  Yue Hu [aut],\n  Eric Persson [ctb]",
    "url": "https://github.com/fsolt/pewdata",
    "bug_reports": "https://github.com/fsolt/pewdata/issues",
    "repository": "https://cran.r-project.org/package=pewdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pewdata Reproducible Retrieval of Pew Research Center Datasets Reproducible, programmatic retrieval of survey datasets from the\n    Pew Research Center.  "
  },
  {
    "id": 17936,
    "package_name": "pickmax",
    "title": "Split and Coalesce Duplicated Records",
    "description": "Deduplicates datasets by retaining the most complete and informative records. Identifies duplicated entries based on a specified key column, calculates completeness scores for each row, and compares values within groups. When differences between duplicates exceed a user-defined threshold, records are split into unique IDs; otherwise, they are coalesced into a single, most complete entry. Returns a list containing the original duplicates, the split entries, and the final coalesced dataset. Useful for cleaning survey or administrative data where duplicated IDs may reflect minor data entry inconsistencies.",
    "version": "0.1.0",
    "maintainer": "Sbonelo Chamane <SChamane@hsrc.ac.za>",
    "author": "Sbonelo Chamane [aut, cre] (ORCID: 0000-0001-5350-5203),\n  Musawenkosi Mabaso [aut],\n  Ronel Sewpaul [aut],\n  Sean Jooste [aut],\n  Kutloano Skhosana [aut],\n  Khangelani Zuma [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pickmax",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pickmax Split and Coalesce Duplicated Records Deduplicates datasets by retaining the most complete and informative records. Identifies duplicated entries based on a specified key column, calculates completeness scores for each row, and compares values within groups. When differences between duplicates exceed a user-defined threshold, records are split into unique IDs; otherwise, they are coalesced into a single, most complete entry. Returns a list containing the original duplicates, the split entries, and the final coalesced dataset. Useful for cleaning survey or administrative data where duplicated IDs may reflect minor data entry inconsistencies.  "
  },
  {
    "id": 17988,
    "package_name": "pkggraph",
    "title": "A Consistent and Intuitive Platform to Explore the Dependencies\nof Packages on the Comprehensive R Archive Network Like\nRepositories",
    "description": "Interactively explore various dependencies of a package(s) (on the Comprehensive R Archive Network Like repositories) and perform analysis using tidy philosophy. Most of the functions return a 'tibble' object (enhancement of 'dataframe') which can be used for further analysis. The package offers functions to produce 'network' and 'igraph' dependency graphs. The 'plot' method produces a static plot based on 'ggnetwork' and 'plotd3' function produces an interactive D3 plot based on 'networkD3'.",
    "version": "0.2.3",
    "maintainer": "KS Srikanth <sri.teach@gmail.com>",
    "author": "KS Srikanth [aut, cre],\n  Singh Nikhil [aut]",
    "url": "https://github.com/talegari/pkggraph",
    "bug_reports": "https://github.com/talegari/pkggraph/issues",
    "repository": "https://cran.r-project.org/package=pkggraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pkggraph A Consistent and Intuitive Platform to Explore the Dependencies\nof Packages on the Comprehensive R Archive Network Like\nRepositories Interactively explore various dependencies of a package(s) (on the Comprehensive R Archive Network Like repositories) and perform analysis using tidy philosophy. Most of the functions return a 'tibble' object (enhancement of 'dataframe') which can be used for further analysis. The package offers functions to produce 'network' and 'igraph' dependency graphs. The 'plot' method produces a static plot based on 'ggnetwork' and 'plotd3' function produces an interactive D3 plot based on 'networkD3'.  "
  },
  {
    "id": 18113,
    "package_name": "poems",
    "title": "Pattern-Oriented Ensemble Modeling System",
    "description": "A framework of interoperable R6 classes (Chang, 2020, <https://CRAN.R-project.org/package=R6>) for building ensembles of viable models via the pattern-oriented modeling (POM) approach (Grimm et al.,2005, <doi:10.1126/science.1116681>). The package includes classes for encapsulating and generating model parameters, and managing the POM workflow. The workflow includes: model setup; generating model parameters via Latin hyper-cube sampling (Iman & Conover, 1980, <doi:10.1080/03610928008827996>); running multiple sampled model simulations; collating summary results; and validating and selecting an ensemble of models that best match known patterns. By default, model validation and selection utilizes an approximate Bayesian computation (ABC) approach (Beaumont et al., 2002, <doi:10.1093/genetics/162.4.2025>), although alternative user-defined functionality could be employed. The package includes a spatially explicit demographic population model simulation engine, which incorporates default functionality for density dependence, correlated environmental stochasticity, stage-based transitions, and distance-based dispersal. The user may customize the simulator by defining functionality for translocations, harvesting, mortality, and other processes, as well as defining the sequence order for the simulator processes. The framework could also be adapted for use with other model simulators by utilizing its extendable (inheritable) base classes.",
    "version": "1.4.0",
    "maintainer": "July Pilowsky <pilowskyj@caryinstitute.org>",
    "author": "Sean Haythorne [aut],\n  Damien Fordham [aut],\n  Stuart Brown [aut] (ORCID: <https://orcid.org/0000-0002-0669-1418>),\n  Jessie Buettel [aut],\n  Barry Brook [aut],\n  July Pilowsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6376-2585>)",
    "url": "https://github.com/GlobalEcologyLab/poems,\nhttps://globalecologylab.github.io/poems/",
    "bug_reports": "https://github.com/GlobalEcologyLab/poems/issues",
    "repository": "https://cran.r-project.org/package=poems",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "poems Pattern-Oriented Ensemble Modeling System A framework of interoperable R6 classes (Chang, 2020, <https://CRAN.R-project.org/package=R6>) for building ensembles of viable models via the pattern-oriented modeling (POM) approach (Grimm et al.,2005, <doi:10.1126/science.1116681>). The package includes classes for encapsulating and generating model parameters, and managing the POM workflow. The workflow includes: model setup; generating model parameters via Latin hyper-cube sampling (Iman & Conover, 1980, <doi:10.1080/03610928008827996>); running multiple sampled model simulations; collating summary results; and validating and selecting an ensemble of models that best match known patterns. By default, model validation and selection utilizes an approximate Bayesian computation (ABC) approach (Beaumont et al., 2002, <doi:10.1093/genetics/162.4.2025>), although alternative user-defined functionality could be employed. The package includes a spatially explicit demographic population model simulation engine, which incorporates default functionality for density dependence, correlated environmental stochasticity, stage-based transitions, and distance-based dispersal. The user may customize the simulator by defining functionality for translocations, harvesting, mortality, and other processes, as well as defining the sequence order for the simulator processes. The framework could also be adapted for use with other model simulators by utilizing its extendable (inheritable) base classes.  "
  },
  {
    "id": 18138,
    "package_name": "politeness",
    "title": "Detecting Politeness Features in Text",
    "description": "Detecting markers of politeness in English natural language. This package allows researchers to easily visualize and quantify politeness between groups of documents. This package combines prior research on the linguistic markers of politeness. We thank the Spencer Foundation, the Hewlett Foundation, and Harvard's Institute for Quantitative Social Science for support.",
    "version": "0.9.4",
    "maintainer": "Mike Yeomans <mk.yeomans@gmail.com>",
    "author": "Mike Yeomans [aut, cre],\n  Alejandro Kantor [aut],\n  Dustin Tingley [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=politeness",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "politeness Detecting Politeness Features in Text Detecting markers of politeness in English natural language. This package allows researchers to easily visualize and quantify politeness between groups of documents. This package combines prior research on the linguistic markers of politeness. We thank the Spencer Foundation, the Hewlett Foundation, and Harvard's Institute for Quantitative Social Science for support.  "
  },
  {
    "id": 18186,
    "package_name": "popbayes",
    "title": "Bayesian Model to Estimate Population Trends from Counts Series",
    "description": "Infers the trends of one or several animal populations over time \n    from series of counts. It does so by accounting for count precision \n    (provided or inferred based on expert knowledge, e.g. guesstimates), \n    smoothing the population rate of increase over time, and accounting for the\n    maximum demographic potential of species. Inference is carried out in a \n    Bayesian framework. This work is part of the FRB-CESAB working group\n    AfroBioDrivers \n    <https://www.fondationbiodiversite.fr/en/the-frb-in-action/programs-and-projects/le-cesab/afrobiodrivers/>.",
    "version": "1.2.0",
    "maintainer": "Nicolas Casajus <nicolas.casajus@fondationbiodiversite.fr>",
    "author": "Nicolas Casajus [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5537-5294>),\n  Roger Pradel [aut] (ORCID: <https://orcid.org/0000-0002-2684-9251>)",
    "url": "https://frbcesab.github.io/popbayes/,\nhttps://github.com/frbcesab/popbayes",
    "bug_reports": "https://github.com/frbcesab/popbayes/issues",
    "repository": "https://cran.r-project.org/package=popbayes",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "popbayes Bayesian Model to Estimate Population Trends from Counts Series Infers the trends of one or several animal populations over time \n    from series of counts. It does so by accounting for count precision \n    (provided or inferred based on expert knowledge, e.g. guesstimates), \n    smoothing the population rate of increase over time, and accounting for the\n    maximum demographic potential of species. Inference is carried out in a \n    Bayesian framework. This work is part of the FRB-CESAB working group\n    AfroBioDrivers \n    <https://www.fondationbiodiversite.fr/en/the-frb-in-action/programs-and-projects/le-cesab/afrobiodrivers/>.  "
  },
  {
    "id": 18188,
    "package_name": "popdemo",
    "title": "Demographic Modelling Using Projection Matrices",
    "description": "Tools for modelling populations and demography using matrix projection models,\n with deterministic and stochastic model implementations. Includes population projection,\n indices of short- and long-term population size and growth, perturbation analysis,\n convergence to stability or stationarity, and diagnostic and manipulation tools.",
    "version": "1.3-2",
    "maintainer": "Iain Stott <iainmstott@gmail.com>",
    "author": "Iain Stott [aut, cre],\n  Dave Hodgson [aut],\n  Stuart Townley [aut],\n  Stephen Ellner [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=popdemo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "popdemo Demographic Modelling Using Projection Matrices Tools for modelling populations and demography using matrix projection models,\n with deterministic and stochastic model implementations. Includes population projection,\n indices of short- and long-term population size and growth, perturbation analysis,\n convergence to stability or stationarity, and diagnostic and manipulation tools.  "
  },
  {
    "id": 18193,
    "package_name": "popstudy",
    "title": "Applied Techniques to Demographic and Time Series Analysis",
    "description": "The use of overparameterization is proposed with combinatorial analysis to test a broader spectrum of possible ARIMA models.\n    In the selection of ARIMA models, the most traditional methods such as correlograms or others, do not usually cover many alternatives to define the number of coefficients to be estimated in the model, which represents an estimation method that is not the best.\n    The popstudy package contains several tools for statistical analysis in demography and time series based in Shryock research (Shryock et. al. (1980) <https://books.google.co.cr/books?id=8Oo6AQAAMAAJ>).",
    "version": "1.0.2",
    "maintainer": "Cesar Gamboa-Sanabria <info@cesargamboasanabria.com>",
    "author": "Cesar Gamboa-Sanabria [aut, mdc, cph, cre] (ORCID:\n    <https://orcid.org/0000-0001-6733-4759>)",
    "url": "https://www.cesargamboasanabria.com",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=popstudy",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "popstudy Applied Techniques to Demographic and Time Series Analysis The use of overparameterization is proposed with combinatorial analysis to test a broader spectrum of possible ARIMA models.\n    In the selection of ARIMA models, the most traditional methods such as correlograms or others, do not usually cover many alternatives to define the number of coefficients to be estimated in the model, which represents an estimation method that is not the best.\n    The popstudy package contains several tools for statistical analysis in demography and time series based in Shryock research (Shryock et. al. (1980) <https://books.google.co.cr/books?id=8Oo6AQAAMAAJ>).  "
  },
  {
    "id": 18194,
    "package_name": "poptrend",
    "title": "Estimate Smooth and Linear Trends from Population Count Survey\nData",
    "description": "Functions to estimate and plot smooth or linear population trends, or population indices, \n    from animal or plant count survey data.",
    "version": "0.2.0",
    "maintainer": "Jonas Knape <jonas.knape@slu.se>",
    "author": "Jonas Knape [aut, cre]",
    "url": "https://github.com/jknape/poptrend",
    "bug_reports": "https://github.com/jknape/poptrend/issues",
    "repository": "https://cran.r-project.org/package=poptrend",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "poptrend Estimate Smooth and Linear Trends from Population Count Survey\nData Functions to estimate and plot smooth or linear population trends, or population indices, \n    from animal or plant count survey data.  "
  },
  {
    "id": 18195,
    "package_name": "populR",
    "title": "Population Downscaling Using Areal Interpolation",
    "description": "Given a \n    set of source zone polygons such as\n    census tracts or city blocks alongside with population counts and a \n    target zone of incogruent yet superimposed polygon features (such as\n    individual buildings) populR transforms population counts from the \n    former to the latter using Areal Interpolation methods.",
    "version": "0.2.1",
    "maintainer": "Marios Batsaris <m.batsaris@aegean.gr>",
    "author": "Marios Batsaris",
    "url": "https://github.com/mbatsaris/populR/",
    "bug_reports": "https://github.com/mbatsaris/populR/issues/",
    "repository": "https://cran.r-project.org/package=populR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "populR Population Downscaling Using Areal Interpolation Given a \n    set of source zone polygons such as\n    census tracts or city blocks alongside with population counts and a \n    target zone of incogruent yet superimposed polygon features (such as\n    individual buildings) populR transforms population counts from the \n    former to the latter using Areal Interpolation methods.  "
  },
  {
    "id": 18198,
    "package_name": "poputils",
    "title": "Demographic Analysis and Data Manipulation",
    "description": "Perform tasks commonly encountered when\n    preparing and analysing demographic data.\n    Some functions are intended for end users, and\n    others for developers. Includes functions for\n    working with life tables.",
    "version": "0.4.2",
    "maintainer": "John Bryant <john@bayesiandemography.com>",
    "author": "John Bryant [aut, cre],\n  Bayesian Demography Limited [cph]",
    "url": "https://bayesiandemography.github.io/poputils/,\nhttps://github.com/bayesiandemography/poputils",
    "bug_reports": "https://github.com/bayesiandemography/poputils/issues",
    "repository": "https://cran.r-project.org/package=poputils",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "poputils Demographic Analysis and Data Manipulation Perform tasks commonly encountered when\n    preparing and analysing demographic data.\n    Some functions are intended for end users, and\n    others for developers. Includes functions for\n    working with life tables.  "
  },
  {
    "id": 18213,
    "package_name": "postGGIR",
    "title": "Data Processing after Running 'GGIR' for Accelerometer Data",
    "description": "Generate all necessary R/Rmd/shell files for data processing after running 'GGIR' (v2.4.0) for accelerometer data. In part 1, all csv files in the GGIR output directory were read, transformed and then merged. In part 2, the GGIR output files were checked and summarized in one excel sheet. In part 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In part 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data. ",
    "version": "2.4.0.2",
    "maintainer": "Wei Guo <wei.guo3@nih.gov>",
    "author": "Wei Guo [aut, cre],\n  Andrew Leroux [aut],\n  Vadim Zipunnikov [aut],\n  Kathleen Merikangas [aut]",
    "url": "https://github.com/dora201888/postGGIR",
    "bug_reports": "https://github.com/dora201888/postGGIR/issues",
    "repository": "https://cran.r-project.org/package=postGGIR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "postGGIR Data Processing after Running 'GGIR' for Accelerometer Data Generate all necessary R/Rmd/shell files for data processing after running 'GGIR' (v2.4.0) for accelerometer data. In part 1, all csv files in the GGIR output directory were read, transformed and then merged. In part 2, the GGIR output files were checked and summarized in one excel sheet. In part 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In part 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data.   "
  },
  {
    "id": 18255,
    "package_name": "ppcSpatial",
    "title": "Spatial Analysis of Pakistan Population Census",
    "description": "Spatial Analysis for exploration of Pakistan Population Census 2017 (<https://www.pbs.gov.pk/content/population-census>). It uses data from R package 'PakPC2017'.",
    "version": "0.3.0",
    "maintainer": "Muhammad Yaseen <myaseen208@gmail.com>",
    "author": "Muhammad Yaseen [aut, cre],\n  Muhammad Arfan Dilber [aut, ctb]",
    "url": "https://github.com/MYaseen208/ppcSpatial",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=ppcSpatial",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ppcSpatial Spatial Analysis of Pakistan Population Census Spatial Analysis for exploration of Pakistan Population Census 2017 (<https://www.pbs.gov.pk/content/population-census>). It uses data from R package 'PakPC2017'.  "
  },
  {
    "id": 18270,
    "package_name": "ppmf",
    "title": "Read Census Privacy Protected Microdata Files",
    "description": "Implements data processing described in <doi:10.1126/sciadv.abk3283>\n    to align modern differentially private data with formatting of older US Census\n    data releases. The primary goal is to read in Census Privacy Protected Microdata\n    Files data in a reproducible way. This includes tools for aggregating to relevant\n    levels of geography by creating geographic identifiers which match the US Census\n    Bureau's numbering. Additionally, there are tools for grouping race numeric\n    identifiers into categories, consistent with OMB (Office of Management and Budget)\n    classifications. Functions exist for downloading and linking to existing\n    sources of privacy protected microdata.",
    "version": "0.2.1",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>)",
    "url": "https://github.com/christopherkenny/ppmf/,\nhttps://christophertkenny.com/ppmf/",
    "bug_reports": "https://github.com/christopherkenny/ppmf/issues",
    "repository": "https://cran.r-project.org/package=ppmf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ppmf Read Census Privacy Protected Microdata Files Implements data processing described in <doi:10.1126/sciadv.abk3283>\n    to align modern differentially private data with formatting of older US Census\n    data releases. The primary goal is to read in Census Privacy Protected Microdata\n    Files data in a reproducible way. This includes tools for aggregating to relevant\n    levels of geography by creating geographic identifiers which match the US Census\n    Bureau's numbering. Additionally, there are tools for grouping race numeric\n    identifiers into categories, consistent with OMB (Office of Management and Budget)\n    classifications. Functions exist for downloading and linking to existing\n    sources of privacy protected microdata.  "
  },
  {
    "id": 18273,
    "package_name": "pps",
    "title": "PPS Sampling",
    "description": "Functions to select samples using PPS (probability proportional to size) sampling. The package also includes a function for stratified simple random sampling, a function to compute joint inclusion probabilities for Sampford's method of PPS sampling, and a few utility functions. The user's guide pps-ug.pdf is included in the .../pps/doc directory. The methods are described in standard survey sampling theory books such as Cochran's \"Sampling Techniques\"; see the user's guide for references.",
    "version": "1.0",
    "maintainer": "Jack G. Gambino <jack.gambino@gmail.com>",
    "author": "Jack G. Gambino <jack.gambino@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pps PPS Sampling Functions to select samples using PPS (probability proportional to size) sampling. The package also includes a function for stratified simple random sampling, a function to compute joint inclusion probabilities for Sampford's method of PPS sampling, and a few utility functions. The user's guide pps-ug.pdf is included in the .../pps/doc directory. The methods are described in standard survey sampling theory books such as Cochran's \"Sampling Techniques\"; see the user's guide for references.  "
  },
  {
    "id": 18311,
    "package_name": "predictrace",
    "title": "Predict the Race and Gender of a Given Name Using Census and\nSocial Security Administration Data",
    "description": "Predicts the most common race of a surname and based on U.S. Census\n    data, and the most common first named based on U.S. Social Security Administration data.",
    "version": "2.0.1",
    "maintainer": "Jacob Kaplan <jkkaplan6@gmail.com>",
    "author": "Jacob Kaplan [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0601-0387>)",
    "url": "https://github.com/jacobkap/predictrace",
    "bug_reports": "https://github.com/jacobkap/predictrace/issues",
    "repository": "https://cran.r-project.org/package=predictrace",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "predictrace Predict the Race and Gender of a Given Name Using Census and\nSocial Security Administration Data Predicts the most common race of a surname and based on U.S. Census\n    data, and the most common first named based on U.S. Social Security Administration data.  "
  },
  {
    "id": 18345,
    "package_name": "prevR",
    "title": "Estimating Regional Trends of a Prevalence from a DHS and\nSimilar Surveys",
    "description": "Spatial estimation of a prevalence surface\n    or a relative risks surface, using data from a Demographic and Health\n    Survey (DHS) or an analog survey, see Larmarange et al. (2011)\n    <doi:10.4000/cybergeo.24606>.",
    "version": "5.0.0",
    "maintainer": "Joseph Larmarange <joseph.larmarange@ird.fr>",
    "author": "Joseph Larmarange [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7097-700X>)",
    "url": "https://github.com/larmarange/prevR/",
    "bug_reports": "https://github.com/larmarange/prevR/issues",
    "repository": "https://cran.r-project.org/package=prevR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prevR Estimating Regional Trends of a Prevalence from a DHS and\nSimilar Surveys Spatial estimation of a prevalence surface\n    or a relative risks surface, using data from a Demographic and Health\n    Survey (DHS) or an analog survey, see Larmarange et al. (2011)\n    <doi:10.4000/cybergeo.24606>.  "
  },
  {
    "id": 18353,
    "package_name": "pricesensitivitymeter",
    "title": "Van Westendorp Price Sensitivity Meter Analysis",
    "description": "An implementation of the van Westendorp Price\n    Sensitivity Meter in R, which is a survey-based approach\n\tto analyze consumer price preferences and sensitivity\n    (van Westendorp 1976, isbn:9789283100386).",
    "version": "1.3.3",
    "maintainer": "Max Alletsee <max.alletsee@gmail.com>",
    "author": "Max Alletsee [aut, cre]",
    "url": "https://max-alletsee.github.io/pricesensitivitymeter/,\nhttps://github.com/max-alletsee/pricesensitivitymeter",
    "bug_reports": "https://github.com/max-alletsee/pricesensitivitymeter/issues",
    "repository": "https://cran.r-project.org/package=pricesensitivitymeter",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pricesensitivitymeter Van Westendorp Price Sensitivity Meter Analysis An implementation of the van Westendorp Price\n    Sensitivity Meter in R, which is a survey-based approach\n\tto analyze consumer price preferences and sensitivity\n    (van Westendorp 1976, isbn:9789283100386).  "
  },
  {
    "id": 18360,
    "package_name": "primer",
    "title": "Functions and Data for the Book, a Primer of Ecology with R",
    "description": "Functions are primarily functions for systems of ordinary differential equations, difference equations, and eigenanalysis and projection of demographic matrices; data are for examples.",
    "version": "1.2.0",
    "maintainer": "Hank Stevens <hank.stevens@miamioh.edu>",
    "author": "M H H Stevens",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=primer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "primer Functions and Data for the Book, a Primer of Ecology with R Functions are primarily functions for systems of ordinary differential equations, difference equations, and eigenanalysis and projection of demographic matrices; data are for examples.  "
  },
  {
    "id": 18381,
    "package_name": "prmisc",
    "title": "Miscellaneous Printing of Numeric and Statistical Output in R\nMarkdown and Quarto Documents",
    "description": "Miscellaneous printing of numeric or statistical results in R Markdown or Quarto documents according to guidelines of the \"Publication Manual\" of the American Psychological Association (2020, ISBN: 978-1-4338-3215-4). These guidelines are usually referred to as APA style (<https://apastyle.apa.org/>) and include specific rules on the formatting of numbers and statistical test results. APA style has to be implemented when submitting scientific reports in a wide range of research fields, especially in the social sciences. The default output of numbers in the R console or R Markdown and Quarto documents does not meet the APA style requirements, and reformatting results manually can be cumbersome and error-prone. This package covers the automatic conversion of R objects to textual representations that meet the APA style requirements, which can be included in R Markdown or Quarto documents. It covers some basic statistical tests (t-test, ANOVA, correlation, chi-squared test, Wilcoxon test) as well as some basic number printing manipulations (formatting p-values, removing leading zeros for numbers that cannot be greater than one, and others). Other packages exist for formatting numbers and tests according to the APA style guidelines, such as 'papaja' (<https://cran.r-project.org/package=papaja>) and 'apa' (<https://cran.r-project.org/package=apa>), but they do not offer all convenience functionality included in 'prmisc'. The vignette has an overview of most of the functions included in the package.",
    "version": "0.0.3",
    "maintainer": "Martin Papenberg <martin.papenberg@hhu.de>",
    "author": "Martin Papenberg [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9900-4268>),\n  Juliane V. Nagel [aut] (ORCID: <https://orcid.org/0000-0002-5310-8088>)",
    "url": "https://github.com/m-Py/prmisc",
    "bug_reports": "https://github.com/m-Py/prmisc/issues",
    "repository": "https://cran.r-project.org/package=prmisc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prmisc Miscellaneous Printing of Numeric and Statistical Output in R\nMarkdown and Quarto Documents Miscellaneous printing of numeric or statistical results in R Markdown or Quarto documents according to guidelines of the \"Publication Manual\" of the American Psychological Association (2020, ISBN: 978-1-4338-3215-4). These guidelines are usually referred to as APA style (<https://apastyle.apa.org/>) and include specific rules on the formatting of numbers and statistical test results. APA style has to be implemented when submitting scientific reports in a wide range of research fields, especially in the social sciences. The default output of numbers in the R console or R Markdown and Quarto documents does not meet the APA style requirements, and reformatting results manually can be cumbersome and error-prone. This package covers the automatic conversion of R objects to textual representations that meet the APA style requirements, which can be included in R Markdown or Quarto documents. It covers some basic statistical tests (t-test, ANOVA, correlation, chi-squared test, Wilcoxon test) as well as some basic number printing manipulations (formatting p-values, removing leading zeros for numbers that cannot be greater than one, and others). Other packages exist for formatting numbers and tests according to the APA style guidelines, such as 'papaja' (<https://cran.r-project.org/package=papaja>) and 'apa' (<https://cran.r-project.org/package=apa>), but they do not offer all convenience functionality included in 'prmisc'. The vignette has an overview of most of the functions included in the package.  "
  },
  {
    "id": 18382,
    "package_name": "prnsamplr",
    "title": "Permanent Random Number Sampling",
    "description": "Survey sampling using permanent random numbers (PRN's). A solution\n    to the problem of unknown overlap between survey samples, which leads to a\n    low precision in estimates when the survey is repeated or combined with\n    other surveys. The PRN solution is to supply the U(0, 1) random numbers to\n    the sampling procedure, instead of having the sampling procedure generate\n    them. In Lindblom (2014) <doi:10.2478/jos-2014-0047>, and therein cited\n    papers, it is shown how this is carried out and how it improves the\n    estimates. This package supports two common fixed-size sampling procedures\n    (simple random sampling and probability-proportional-to-size sampling) and\n    includes a function for transforming the PRN's in order to control the\n    sample overlap.",
    "version": "1.1.0",
    "maintainer": "Kira Coder Gylling <kira.gylling@gmail.com>",
    "author": "Kira Coder Gylling [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9070-8381>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=prnsamplr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "prnsamplr Permanent Random Number Sampling Survey sampling using permanent random numbers (PRN's). A solution\n    to the problem of unknown overlap between survey samples, which leads to a\n    low precision in estimates when the survey is repeated or combined with\n    other surveys. The PRN solution is to supply the U(0, 1) random numbers to\n    the sampling procedure, instead of having the sampling procedure generate\n    them. In Lindblom (2014) <doi:10.2478/jos-2014-0047>, and therein cited\n    papers, it is shown how this is carried out and how it improves the\n    estimates. This package supports two common fixed-size sampling procedures\n    (simple random sampling and probability-proportional-to-size sampling) and\n    includes a function for transforming the PRN's in order to control the\n    sample overlap.  "
  },
  {
    "id": 18420,
    "package_name": "projoint",
    "title": "Conjoint Analysis with Reliability Correction and Visualization",
    "description": "Provides tools for analyzing data generated from conjoint survey experiments, a method widely used in the social sciences for studying multidimensional preferences. The package implements estimation of marginal means (MMs) and average marginal component effects (AMCEs), with corrections for measurement error. Methods include profile-level and choice-level estimators, bias correction using intra-respondent reliability (IRR), and visualization utilities. For details on the methodology, see Clayton, Horiuchi, Kaufman, King, and Komisarchik (2025) <https://gking.harvard.edu/conjointE>.",
    "version": "1.0.6",
    "maintainer": "Yusaku Horiuchi <yusaku.horiuchi@gmail.com>",
    "author": "Yusaku Horiuchi [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0295-4089>),\n  Aaron Kaufman [aut] (ORCID: <https://orcid.org/0000-0003-3688-0428>),\n  Gary King [aut] (ORCID: <https://orcid.org/0000-0002-5327-7631>)",
    "url": "https://yhoriuchi.github.io/projoint/",
    "bug_reports": "https://github.com/yhoriuchi/projoint/issues",
    "repository": "https://cran.r-project.org/package=projoint",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "projoint Conjoint Analysis with Reliability Correction and Visualization Provides tools for analyzing data generated from conjoint survey experiments, a method widely used in the social sciences for studying multidimensional preferences. The package implements estimation of marginal means (MMs) and average marginal component effects (AMCEs), with corrections for measurement error. Methods include profile-level and choice-level estimators, bias correction using intra-respondent reliability (IRR), and visualization utilities. For details on the methodology, see Clayton, Horiuchi, Kaufman, King, and Komisarchik (2025) <https://gking.harvard.edu/conjointE>.  "
  },
  {
    "id": 18430,
    "package_name": "promptr",
    "title": "Format and Complete Few-Shot LLM Prompts",
    "description": "Format and submit few-shot prompts to OpenAI's Large Language Models (LLMs). Designed to be particularly useful for text classification problems in the social sciences. Methods are described in Ornstein, Blasingame, and Truscott (2024) <https://joeornstein.github.io/publications/ornstein-blasingame-truscott.pdf>.",
    "version": "1.0.0",
    "maintainer": "Joe Ornstein <jornstein@uga.edu>",
    "author": "Joe Ornstein [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-5704-2098>)",
    "url": "https://github.com/joeornstein/promptr",
    "bug_reports": "https://github.com/joeornstein/promptr/issues",
    "repository": "https://cran.r-project.org/package=promptr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "promptr Format and Complete Few-Shot LLM Prompts Format and submit few-shot prompts to OpenAI's Large Language Models (LLMs). Designed to be particularly useful for text classification problems in the social sciences. Methods are described in Ornstein, Blasingame, and Truscott (2024) <https://joeornstein.github.io/publications/ornstein-blasingame-truscott.pdf>.  "
  },
  {
    "id": 18492,
    "package_name": "psidR",
    "title": "Build Panel Data Sets from PSID Raw Data",
    "description": "Makes it easy to build panel data in wide format from Panel Survey\n    of Income Dynamics (PSID) delivered raw data. Downloads data directly from\n    the PSID server using the 'SAScii' package. 'psidR' takes care of merging\n    data from each wave onto a cross-period index file, so that individuals can be\n    followed over time. The user must specify which years they are interested in,\n    and the 'PSID' variable names (e.g. ER21003) for each year (they differ in each\n    year). The package offers helper functions to retrieve variable names from different\n    waves. There are different panel data designs and sample subsetting criteria\n    implemented (\"SRC\", \"SEO\", \"immigrant\" and \"latino\" samples). More information about \n    the PSID can be obtained at <https://simba.isr.umich.edu/data/data.aspx>.",
    "version": "2.3",
    "maintainer": "Florian Oswald <florian.oswald@gmail.com>",
    "author": "Florian Oswald [aut, cre]",
    "url": "https://github.com/floswald/psidR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=psidR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "psidR Build Panel Data Sets from PSID Raw Data Makes it easy to build panel data in wide format from Panel Survey\n    of Income Dynamics (PSID) delivered raw data. Downloads data directly from\n    the PSID server using the 'SAScii' package. 'psidR' takes care of merging\n    data from each wave onto a cross-period index file, so that individuals can be\n    followed over time. The user must specify which years they are interested in,\n    and the 'PSID' variable names (e.g. ER21003) for each year (they differ in each\n    year). The package offers helper functions to retrieve variable names from different\n    waves. There are different panel data designs and sample subsetting criteria\n    implemented (\"SRC\", \"SEO\", \"immigrant\" and \"latino\" samples). More information about \n    the PSID can be obtained at <https://simba.isr.umich.edu/data/data.aspx>.  "
  },
  {
    "id": 18518,
    "package_name": "psychonetrics",
    "title": "Structural Equation Modeling and Confirmatory Network Analysis",
    "description": "Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.",
    "version": "0.13.2",
    "maintainer": "Sacha Epskamp <mail@sachaepskamp.com>",
    "author": "Sacha Epskamp [aut, cre]",
    "url": "http://psychonetrics.org/",
    "bug_reports": "https://github.com/SachaEpskamp/psychonetrics/issues",
    "repository": "https://cran.r-project.org/package=psychonetrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "psychonetrics Structural Equation Modeling and Confirmatory Network Analysis Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.  "
  },
  {
    "id": 18584,
    "package_name": "pwrss",
    "title": "Statistical Power and Sample Size Calculation Tools",
    "description": "\n  The 'pwrss' R package provides flexible and comprehensive functions for\n  statistical power and minimum required sample size calculations across a wide\n  range of commonly used hypothesis tests in psychological, biomedical, and\n  social sciences.",
    "version": "1.0.0",
    "maintainer": "Metin Bulus <bulusmetin@gmail.com>",
    "author": "Metin Bulus [aut, cre],\n  Sebastian Jentschke [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=pwrss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "pwrss Statistical Power and Sample Size Calculation Tools \n  The 'pwrss' R package provides flexible and comprehensive functions for\n  statistical power and minimum required sample size calculations across a wide\n  range of commonly used hypothesis tests in psychological, biomedical, and\n  social sciences.  "
  },
  {
    "id": 18729,
    "package_name": "quantification",
    "title": "Quantification of Qualitative Survey Data",
    "description": "Provides different functions for quantifying qualitative survey data. It supports the Carlson-Parkin method, the regression approach, the balance approach and the conditional expectations method.",
    "version": "0.2.0",
    "maintainer": "Joachim Zuckarelli <joachim@zuckarelli.de>",
    "author": "Joachim Zuckarelli <joachim@zuckarelli.de>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=quantification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "quantification Quantification of Qualitative Survey Data Provides different functions for quantifying qualitative survey data. It supports the Carlson-Parkin method, the regression approach, the balance approach and the conditional expectations method.  "
  },
  {
    "id": 18755,
    "package_name": "questionr",
    "title": "Functions to Make Surveys Processing Easier",
    "description": "Set of functions to make the processing and analysis of\n    surveys easier : interactive shiny apps and addins for data recoding,\n    contingency tables, dataset metadata handling, and several convenience\n    functions.",
    "version": "0.8.1",
    "maintainer": "Julien Barnier <julien.barnier@cnrs.fr>",
    "author": "Julien Barnier [aut, cre],\n  Fran\u00e7ois Briatte [aut],\n  Joseph Larmarange [aut]",
    "url": "https://juba.github.io/questionr/,\nhttps://github.com/juba/questionr",
    "bug_reports": "https://github.com/juba/questionr/issues",
    "repository": "https://cran.r-project.org/package=questionr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "questionr Functions to Make Surveys Processing Easier Set of functions to make the processing and analysis of\n    surveys easier : interactive shiny apps and addins for data recoding,\n    contingency tables, dataset metadata handling, and several convenience\n    functions.  "
  },
  {
    "id": 18843,
    "package_name": "rENA",
    "title": "Epistemic Network Analysis",
    "description": "ENA (Shaffer, D. W. (2017) Quantitative Ethnography. ISBN: 0578191687) is a method used to identify meaningful and quantifiable patterns in discourse or reasoning. ENA moves beyond the traditional frequency-based assessments by examining the structure of the co-occurrence, or connections in coded data. Moreover, compared to other methodological approaches, ENA has the novelty of (1) modeling whole networks of connections and (2) affording both quantitative and qualitative comparisons between different network models.   Shaffer, D.W., Collier, W., & Ruis, A.R. (2016).",
    "version": "0.3.0",
    "maintainer": "Cody L Marquart <cody.marquart@wisc.edu>",
    "author": "Cody L Marquart [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3387-6792>),\n  Zachari Swiecki [aut],\n  Wesley Collier [aut],\n  Brendan Eagan [aut],\n  Roman Woodward [aut],\n  David Williamson Shaffer [aut]",
    "url": "https://gitlab.com/epistemic-analytics/qe-packages/rENA",
    "bug_reports": "https://gitlab.com/epistemic-analytics/qe-packages/rENA/-/issues",
    "repository": "https://cran.r-project.org/package=rENA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rENA Epistemic Network Analysis ENA (Shaffer, D. W. (2017) Quantitative Ethnography. ISBN: 0578191687) is a method used to identify meaningful and quantifiable patterns in discourse or reasoning. ENA moves beyond the traditional frequency-based assessments by examining the structure of the co-occurrence, or connections in coded data. Moreover, compared to other methodological approaches, ENA has the novelty of (1) modeling whole networks of connections and (2) affording both quantitative and qualitative comparisons between different network models.   Shaffer, D.W., Collier, W., & Ruis, A.R. (2016).  "
  },
  {
    "id": 18851,
    "package_name": "rGhanaCensus",
    "title": "2021 Ghana Population and Housing Census Results as Data Frames",
    "description": "Datasets from the 2021 Ghana Population and Housing Census Results. Users can access results as 'tidyverse' and 'sf'-Ready Data Frames.    The data in this package is scraped from pdf reports released by the Ghana Statistical Service website <https://census2021.statsghana.gov.gh/> . The package currently only contains datasets from the literacy and education reports. Namely, school attendance data for respondents aged 3 years and above.",
    "version": "0.1.0",
    "maintainer": "Ama Owusu-Darko <aowusuda@asu.edu>",
    "author": "Ama Owusu-Darko [cre, aut]",
    "url": "https://github.com/ktemadarko/rGhanaCensus",
    "bug_reports": "https://github.com/ktemadarko/rGhanaCensus/issues",
    "repository": "https://cran.r-project.org/package=rGhanaCensus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rGhanaCensus 2021 Ghana Population and Housing Census Results as Data Frames Datasets from the 2021 Ghana Population and Housing Census Results. Users can access results as 'tidyverse' and 'sf'-Ready Data Frames.    The data in this package is scraped from pdf reports released by the Ghana Statistical Service website <https://census2021.statsghana.gov.gh/> . The package currently only contains datasets from the literacy and education reports. Namely, school attendance data for respondents aged 3 years and above.  "
  },
  {
    "id": 19013,
    "package_name": "rarms",
    "title": "Access Data from the USDA ARMS Data API",
    "description": "Interface to easily access data via the United States Department of Agriculture (USDA)'s Agricultural Resource Management Survey (ARMS) \n  Data API <https://www.ers.usda.gov/developer/data-apis/arms-data-api/>. The downloaded data can be saved for later off-line use. \n  Also provide relevant information and metadata for each of the input variables needed for sending the data inquery.   ",
    "version": "1.0.0",
    "maintainer": "Bowen Chen <bwchen0719@gmail.com>",
    "author": "Bowen Chen [aut, cre] (ORCID: <https://orcid.org/0000-0003-0370-2756>),\n  Benjamin Gramig [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rarms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rarms Access Data from the USDA ARMS Data API Interface to easily access data via the United States Department of Agriculture (USDA)'s Agricultural Resource Management Survey (ARMS) \n  Data API <https://www.ers.usda.gov/developer/data-apis/arms-data-api/>. The downloaded data can be saved for later off-line use. \n  Also provide relevant information and metadata for each of the input variables needed for sending the data inquery.     "
  },
  {
    "id": 19022,
    "package_name": "rasterbc",
    "title": "Access Forest Ecology Layers for British Columbia in 2001-2018",
    "description": "R-based access to a large set of data variables relevant to forest ecology in British Columbia (BC), Canada. Layers\n    are in raster format at 100m resolution in the BC Albers projection, hosted at the Federated Research Data Repository (FRDR)\n    with <doi:10.20383/101.0283>. The collection includes: elevation; biogeoclimatic zone; wildfire; cutblocks; forest attributes from\n    Hansen et al. (2013) <doi:10.1139/cjfr-2013-0401> and Beaudoin et al. (2017) <doi:10.1139/cjfr-2017-0184>; and rasterized\n    Forest Insect and Disease Survey (FIDS) maps for a number of insect pest species, all covering the period 2001-2018.\n    Users supply a polygon or point location in the province of BC, and 'rasterbc' will download the overlapping raster tiles\n    hosted at FRDR, merging them as needed and returning the result in R as a 'SpatRaster' object. Metadata associated with these\n    layers, and code for downloading them from their original sources can be found in the 'github' repository\n    <https://github.com/deankoch/rasterbc_src>.",
    "version": "1.0.2",
    "maintainer": "Dean Koch <dkoch@ualberta.ca>",
    "author": "Dean Koch [aut, cre] (ORCID: <https://orcid.org/0000-0002-8849-859X>)",
    "url": "https://github.com/deankoch/rasterbc,\nhttps://github.com/deankoch/rasterbc_src",
    "bug_reports": "https://github.com/deankoch/rasterbc/issues",
    "repository": "https://cran.r-project.org/package=rasterbc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rasterbc Access Forest Ecology Layers for British Columbia in 2001-2018 R-based access to a large set of data variables relevant to forest ecology in British Columbia (BC), Canada. Layers\n    are in raster format at 100m resolution in the BC Albers projection, hosted at the Federated Research Data Repository (FRDR)\n    with <doi:10.20383/101.0283>. The collection includes: elevation; biogeoclimatic zone; wildfire; cutblocks; forest attributes from\n    Hansen et al. (2013) <doi:10.1139/cjfr-2013-0401> and Beaudoin et al. (2017) <doi:10.1139/cjfr-2017-0184>; and rasterized\n    Forest Insect and Disease Survey (FIDS) maps for a number of insect pest species, all covering the period 2001-2018.\n    Users supply a polygon or point location in the province of BC, and 'rasterbc' will download the overlapping raster tiles\n    hosted at FRDR, merging them as needed and returning the result in R as a 'SpatRaster' object. Metadata associated with these\n    layers, and code for downloading them from their original sources can be found in the 'github' repository\n    <https://github.com/deankoch/rasterbc_src>.  "
  },
  {
    "id": 19082,
    "package_name": "rcarbon",
    "title": "Calibration and Analysis of Radiocarbon Dates",
    "description": "Enables the calibration and analysis of radiocarbon dates, often but not exclusively for the purposes of archaeological research. It includes functions not only for basic calibration, uncalibration, and plotting of one or more dates, but also a statistical framework for building demographic and related longitudinal inferences from aggregate radiocarbon date lists, including: Monte-Carlo simulation test (Timpson et al 2014 <doi:10.1016/j.jas.2014.08.011>), random mark permutation test (Crema et al 2016 <doi:10.1371/journal.pone.0154809>) and spatial permutation tests (Crema, Bevan, and Shennan 2017 <doi:10.1016/j.jas.2017.09.007>).  ",
    "version": "1.5.2",
    "maintainer": "Enrico Crema <enrico.crema@gmail.com>",
    "author": "Andrew Bevan [aut] (ORCID: <https://orcid.org/0000-0001-7967-3117>),\n  Enrico Crema [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6727-5138>),\n  R. Kyle Bocinsky [ctb],\n  Martin Hinz [ctb],\n  Philip Riris [ctb],\n  Fabio Silva [ctb]",
    "url": "https://github.com/ahb108/rcarbon/",
    "bug_reports": "https://github.com/ahb108/rcarbon/issues",
    "repository": "https://cran.r-project.org/package=rcarbon",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcarbon Calibration and Analysis of Radiocarbon Dates Enables the calibration and analysis of radiocarbon dates, often but not exclusively for the purposes of archaeological research. It includes functions not only for basic calibration, uncalibration, and plotting of one or more dates, but also a statistical framework for building demographic and related longitudinal inferences from aggregate radiocarbon date lists, including: Monte-Carlo simulation test (Timpson et al 2014 <doi:10.1016/j.jas.2014.08.011>), random mark permutation test (Crema et al 2016 <doi:10.1371/journal.pone.0154809>) and spatial permutation tests (Crema, Bevan, and Shennan 2017 <doi:10.1016/j.jas.2017.09.007>).    "
  },
  {
    "id": 19084,
    "package_name": "rcausim",
    "title": "Generate Causally-Simulated Data",
    "description": "Generate causally-simulated data to serve as ground truth for evaluating methods in causal discovery and effect estimation. The package provides tools to assist in defining functions based on specified edges, and conversely, defining edges based on functions. It enables the generation of data according to these predefined functions and causal structures. This is particularly useful for researchers in fields such as artificial intelligence, statistics, biology, medicine, epidemiology, economics, and social sciences, who are developing a general or a domain-specific methods to discover causal structures and estimate causal effects. Data simulation adheres to principles of structural causal modeling. Detailed methodologies and examples are documented in our vignette, available at <https://htmlpreview.github.io/?https://github.com/herdiantrisufriyana/rcausim/blob/master/doc/causal_simulation_exemplar.html>.",
    "version": "0.1.1",
    "maintainer": "Herdiantri Sufriyana <herdi@tmu.edu.tw>",
    "author": "Herdiantri Sufriyana [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9178-0222>),\n  Emily Chia-Yu Su [aut] (ORCID: <https://orcid.org/0000-0003-4801-5159>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rcausim",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcausim Generate Causally-Simulated Data Generate causally-simulated data to serve as ground truth for evaluating methods in causal discovery and effect estimation. The package provides tools to assist in defining functions based on specified edges, and conversely, defining edges based on functions. It enables the generation of data according to these predefined functions and causal structures. This is particularly useful for researchers in fields such as artificial intelligence, statistics, biology, medicine, epidemiology, economics, and social sciences, who are developing a general or a domain-specific methods to discover causal structures and estimate causal effects. Data simulation adheres to principles of structural causal modeling. Detailed methodologies and examples are documented in our vignette, available at <https://htmlpreview.github.io/?https://github.com/herdiantrisufriyana/rcausim/blob/master/doc/causal_simulation_exemplar.html>.  "
  },
  {
    "id": 19089,
    "package_name": "rcccd",
    "title": "Class Cover Catch Digraph Classification",
    "description": "Fit Class Cover Catch Digraph Classification models that can be \n    used in machine learning. Pure and proper and random walk approaches are \n    available. Methods are explained in Priebe et al. (2001) \n    <doi:10.1016/S0167-7152(01)00129-8>, Priebe et al. (2003) \n    <doi:10.1007/s00357-003-0003-7>, and Manukyan and Ceyhan (2016) \n    <doi:10.48550/arXiv.1904.04564>.",
    "version": "0.3.2",
    "maintainer": "Fatih Saglam <saglamf89@gmail.com>",
    "author": "Fatih Saglam [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2084-2008>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rcccd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rcccd Class Cover Catch Digraph Classification Fit Class Cover Catch Digraph Classification models that can be \n    used in machine learning. Pure and proper and random walk approaches are \n    available. Methods are explained in Priebe et al. (2001) \n    <doi:10.1016/S0167-7152(01)00129-8>, Priebe et al. (2003) \n    <doi:10.1007/s00357-003-0003-7>, and Manukyan and Ceyhan (2016) \n    <doi:10.48550/arXiv.1904.04564>.  "
  },
  {
    "id": 19123,
    "package_name": "rct3",
    "title": "Predict Fish Year-Class Strength from Survey Data",
    "description": "Predict fish year-class strength by calibration\n  regression analysis of multiple recruitment index series.",
    "version": "1.0.4",
    "maintainer": "Colin Millar <colin.millar@ices.dk>",
    "author": "Colin Millar [aut, cre],\n  Marc Taylor [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rct3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rct3 Predict Fish Year-Class Strength from Survey Data Predict fish year-class strength by calibration\n  regression analysis of multiple recruitment index series.  "
  },
  {
    "id": 19154,
    "package_name": "rdss",
    "title": "Companion Datasets and Functions for Research Design in the\nSocial Sciences",
    "description": "Helper functions to accompany the Blair, Coppock, and Humphreys (2022) \"Research Design in the Social Sciences: Declaration, Diagnosis, and Redesign\" <https://book.declaredesign.org>. 'rdss' includes datasets, helper functions, and plotting components to enable use and replication of the book. ",
    "version": "1.0.14",
    "maintainer": "Graeme Blair <graeme.blair@gmail.com>",
    "author": "Graeme Blair [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9164-2102>),\n  Alexander Coppock [aut] (ORCID:\n    <https://orcid.org/0000-0002-5733-2386>),\n  Macartan Humphreys [aut] (ORCID:\n    <https://orcid.org/0000-0001-7029-2326>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rdss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdss Companion Datasets and Functions for Research Design in the\nSocial Sciences Helper functions to accompany the Blair, Coppock, and Humphreys (2022) \"Research Design in the Social Sciences: Declaration, Diagnosis, and Redesign\" <https://book.declaredesign.org>. 'rdss' includes datasets, helper functions, and plotting components to enable use and replication of the book.   "
  },
  {
    "id": 19157,
    "package_name": "rdwplus",
    "title": "Inverse Distance Weighted Percent Land Use for Streams",
    "description": "Compute spatially explicit land-use metrics for stream survey sites in GRASS GIS and R as an open-source implementation of IDW-PLUS (Inverse Distance Weighted Percent Land Use for Streams). The package includes functions for preprocessing digital elevation and streams data, and one function to compute all the spatially explicit land use metrics described in Peterson et al. (2011) <doi:10.1111/j.1365-2427.2010.02507.x> and previously implemented by Peterson and Pearse (2017) <doi:10.1111/1752-1688.12558> in ArcGIS-Python as IDW-PLUS. ",
    "version": "1.0.1",
    "maintainer": "Alan Pearse <alan.pearse@unimelb.edu.au>",
    "author": "Alan Pearse [aut, cre],\n  Grace Heron [aut],\n  Erin Peterson [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rdwplus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rdwplus Inverse Distance Weighted Percent Land Use for Streams Compute spatially explicit land-use metrics for stream survey sites in GRASS GIS and R as an open-source implementation of IDW-PLUS (Inverse Distance Weighted Percent Land Use for Streams). The package includes functions for preprocessing digital elevation and streams data, and one function to compute all the spatially explicit land use metrics described in Peterson et al. (2011) <doi:10.1111/j.1365-2427.2010.02507.x> and previously implemented by Peterson and Pearse (2017) <doi:10.1111/1752-1688.12558> in ArcGIS-Python as IDW-PLUS.   "
  },
  {
    "id": 19168,
    "package_name": "read.gt3x",
    "title": "Parse 'ActiGraph' 'GT3X'/'GT3X+' 'Accelerometer' Data",
    "description": "Implements a high performance C++ parser \n    for 'ActiGraph' 'GT3X'/'GT3X+' data format (with extension '.gt3x') \n    for 'accelerometer' samples. Activity samples can be easily read into a\n    matrix or data.frame.  This allows for storing the raw 'accelerometer' \n    samples in the original binary format to reserve space.",
    "version": "1.2.0",
    "maintainer": "Tuomo Nieminen <tuomo.a.nieminen@gmail.com>",
    "author": "Tuomo Nieminen [aut, cre],\n  John Muschelli [aut] (ORCID: <https://orcid.org/0000-0001-6469-1750>),\n  Patrick Bos [ctb] (ORCID: <https://orcid.org/0000-0002-6033-960X>),\n  Vincent van Hees [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=read.gt3x",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "read.gt3x Parse 'ActiGraph' 'GT3X'/'GT3X+' 'Accelerometer' Data Implements a high performance C++ parser \n    for 'ActiGraph' 'GT3X'/'GT3X+' data format (with extension '.gt3x') \n    for 'accelerometer' samples. Activity samples can be easily read into a\n    matrix or data.frame.  This allows for storing the raw 'accelerometer' \n    samples in the original binary format to reserve space.  "
  },
  {
    "id": 19186,
    "package_name": "readmission",
    "title": "Hospital Readmission Data for Patients with Diabetes",
    "description": "Clinical care data from 130 U.S. hospitals in the years 1999-2008\n    adapted from the study Strack et al. (2014) <doi:10.1155/2014/781670>. \n    Each row describes an \"encounter\" with a patient with diabetes, including \n    variables on demographics, medications, patient history, diagnostics, \n    payment, and readmission.",
    "version": "0.1.0",
    "maintainer": "Simon Couch <simonpatrickcouch@gmail.com>",
    "author": "Simon Couch [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=readmission",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "readmission Hospital Readmission Data for Patients with Diabetes Clinical care data from 130 U.S. hospitals in the years 1999-2008\n    adapted from the study Strack et al. (2014) <doi:10.1155/2014/781670>. \n    Each row describes an \"encounter\" with a patient with diabetes, including \n    variables on demographics, medications, patient history, diagnostics, \n    payment, and readmission.  "
  },
  {
    "id": 19245,
    "package_name": "redcapAPI",
    "title": "Interface to 'REDCap'",
    "description": "Access data stored in 'REDCap' databases using the Application\n    Programming Interface (API).  'REDCap' (Research Electronic Data CAPture;\n    <https://projectredcap.org>, Harris, et al. (2009) <doi:10.1016/j.jbi.2008.08.010>, \n    Harris, et al. (2019) <doi:10.1016/j.jbi.2019.103208>) is\n    a web application for building and managing online surveys and databases\n    developed at Vanderbilt University.  The API allows users to access data\n    and project meta data (such as the data dictionary) from the web\n    programmatically. The 'redcapAPI' package facilitates the process of\n    accessing data with options to prepare an analysis-ready data set\n    consistent with the definitions in a database's data dictionary.",
    "version": "2.11.5",
    "maintainer": "Shawn Garbett <shawn.garbett@vumc.org>",
    "author": "Benjamin Nutter [ctb, aut],\n  Shawn Garbett [cre, ctb] (ORCID:\n    <https://orcid.org/0000-0003-4079-5621>),\n  Savannah Obregon [ctb],\n  Thomas Obadia [ctb],\n  Marcus Lehr [ctb],\n  Brian High [ctb],\n  Stephen Lane [ctb],\n  Will Beasley [ctb],\n  Will Gray [ctb],\n  Nick Kennedy [ctb],\n  Tan Hsi-Nien [ctb],\n  Jeffrey Horner [aut],\n  Jeremy Stephens [ctb],\n  Cole Beck [ctb],\n  Bradley Johnson [ctb],\n  Philip Chase [ctb],\n  Paddy Tobias [ctb],\n  Michael Chirico [ctb],\n  William Sharp [ctb]",
    "url": "https://github.com/vubiostat/redcapAPI",
    "bug_reports": "https://github.com/vubiostat/redcapAPI/issues",
    "repository": "https://cran.r-project.org/package=redcapAPI",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "redcapAPI Interface to 'REDCap' Access data stored in 'REDCap' databases using the Application\n    Programming Interface (API).  'REDCap' (Research Electronic Data CAPture;\n    <https://projectredcap.org>, Harris, et al. (2009) <doi:10.1016/j.jbi.2008.08.010>, \n    Harris, et al. (2019) <doi:10.1016/j.jbi.2019.103208>) is\n    a web application for building and managing online surveys and databases\n    developed at Vanderbilt University.  The API allows users to access data\n    and project meta data (such as the data dictionary) from the web\n    programmatically. The 'redcapAPI' package facilitates the process of\n    accessing data with options to prepare an analysis-ready data set\n    consistent with the definitions in a database's data dictionary.  "
  },
  {
    "id": 19269,
    "package_name": "refugees",
    "title": "UNHCR Refugee Population Statistics Database",
    "description": "The Refugee Population Statistics Database published by\n    The Office of The United Nations High Commissioner for Refugees (UNHCR)\n    contains information about forcibly displaced populations\n    spanning more than 70 years of statistical activities.\n    It covers displaced populations such as refugees, asylum-seekers and\n    internally displaced people, including their demographics.\n    Stateless people are also included, most of who have never been displaced.\n    The database also reflects the different types of solutions\n    for displaced populations such as repatriation or resettlement. \n    More information on the data and methodology can be found on\n    the UNHCR Refugee Data Finder <https://www.unhcr.org/refugee-statistics/>.",
    "version": "2025.06.0",
    "maintainer": "Janis Kreuder <kreuder@unhcr.org>",
    "author": "Hisham Galal [aut],\n  Ahmadou Dicko [aut],\n  Janis Kreuder [cre],\n  UNHCR [cph]",
    "url": "https://populationstatistics.github.io/refugees/,\nhttps://github.com/PopulationStatistics/refugees",
    "bug_reports": "https://github.com/PopulationStatistics/refugees/issues",
    "repository": "https://cran.r-project.org/package=refugees",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "refugees UNHCR Refugee Population Statistics Database The Refugee Population Statistics Database published by\n    The Office of The United Nations High Commissioner for Refugees (UNHCR)\n    contains information about forcibly displaced populations\n    spanning more than 70 years of statistical activities.\n    It covers displaced populations such as refugees, asylum-seekers and\n    internally displaced people, including their demographics.\n    Stateless people are also included, most of who have never been displaced.\n    The database also reflects the different types of solutions\n    for displaced populations such as repatriation or resettlement. \n    More information on the data and methodology can be found on\n    the UNHCR Refugee Data Finder <https://www.unhcr.org/refugee-statistics/>.  "
  },
  {
    "id": 19287,
    "package_name": "regmhmm",
    "title": "'regmhmm' Fits Hidden Markov Models with Regularization",
    "description": "Designed for longitudinal data analysis using Hidden Markov Models (HMMs). Tailored for applications in healthcare, social sciences, and economics, the main emphasis of this package is on regularization techniques for fitting HMMs. Additionally, it provides an implementation for fitting HMMs without regularization, referencing Zucchini et al. (2017, ISBN:9781315372488).",
    "version": "1.0.0",
    "maintainer": "Man Chong Leong <mc.leong26@gmail.com>",
    "author": "Man Chong Leong [cre, aut] (ORCID:\n    <https://orcid.org/0000-0003-3895-9527>)",
    "url": "https://github.com/HenryLeongStat/regmhmm",
    "bug_reports": "https://github.com/HenryLeongStat/regmhmm/issues",
    "repository": "https://cran.r-project.org/package=regmhmm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "regmhmm 'regmhmm' Fits Hidden Markov Models with Regularization Designed for longitudinal data analysis using Hidden Markov Models (HMMs). Tailored for applications in healthcare, social sciences, and economics, the main emphasis of this package is on regularization techniques for fitting HMMs. Additionally, it provides an implementation for fitting HMMs without regularization, referencing Zucchini et al. (2017, ISBN:9781315372488).  "
  },
  {
    "id": 19314,
    "package_name": "reldist",
    "title": "Relative Distribution Methods",
    "description": "Tools for the comparison of distributions. This includes nonparametric estimation of the relative distribution PDF and CDF and numerical summaries as described in \"Relative Distribution Methods in the Social Sciences\" by Mark S. Handcock and Martina Morris, Springer-Verlag, 1999, Springer-Verlag, ISBN 0387987789.",
    "version": "1.7-2",
    "maintainer": "Mark S. Handcock <handcock@stat.ucla.edu>",
    "author": "Mark S. Handcock <handcock@stat.ucla.edu>",
    "url": "http://www.stat.ucla.edu/~handcock/RelDist/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=reldist",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "reldist Relative Distribution Methods Tools for the comparison of distributions. This includes nonparametric estimation of the relative distribution PDF and CDF and numerical summaries as described in \"Relative Distribution Methods in the Social Sciences\" by Mark S. Handcock and Martina Morris, Springer-Verlag, 1999, Springer-Verlag, ISBN 0387987789.  "
  },
  {
    "id": 19401,
    "package_name": "responsePatterns",
    "title": "Screening for Careless Responding Patterns",
    "description": "Some survey participants tend to respond carelessly which complicates data analysis. This package provides functions that make it easier to explore responses and identify those that may be problematic. See Gottfried et al. (2022) <doi:10.7275/vyxb-gt24> for more information.",
    "version": "0.1.1",
    "maintainer": "Tomas Rihacek <rihacek@fss.muni.cz>",
    "author": "Tomas Rihacek [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5893-9289>),\n  Jaroslav Gottfried [aut] (ORCID:\n    <https://orcid.org/0000-0002-6076-1632>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=responsePatterns",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "responsePatterns Screening for Careless Responding Patterns Some survey participants tend to respond carelessly which complicates data analysis. This package provides functions that make it easier to explore responses and identify those that may be problematic. See Gottfried et al. (2022) <doi:10.7275/vyxb-gt24> for more information.  "
  },
  {
    "id": 19402,
    "package_name": "resquin",
    "title": "Response Quality Indicators for Survey Research",
    "description": "Calculate common survey data quality indicators for multi-item scales \n             and matrix questions. Currently supports the calculation of\n             response style indicators and response distribution indicators.\n             For an overview on response quality indicators see Bhaktha N,\n             Henning S, Clemens L (2024). 'Characterizing response quality\n             in surveys with multi-item scales: A unified framework'\n             <https://osf.io/9gs67/>.",
    "version": "0.1.1",
    "maintainer": "Matthias Roth <matthias.roth@gesis.org>",
    "author": "Matthias Roth [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-4369-8106>),\n  Nivedita Bhaktha [aut, ctb],\n  Matthias Bluemke [aut, ctb],\n  Thomas Knopf [aut, ctb],\n  Fabienne Kr\u00e4mer [aut, ctb],\n  Clemens Lechner [aut, ctb],\n  \u00c7a\u011fla Yildiz [aut, ctb]",
    "url": "https://github.com/MatRoth/resquin,\nhttps://matroth.github.io/resquin/",
    "bug_reports": "https://github.com/MatRoth/resquin/issues",
    "repository": "https://cran.r-project.org/package=resquin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "resquin Response Quality Indicators for Survey Research Calculate common survey data quality indicators for multi-item scales \n             and matrix questions. Currently supports the calculation of\n             response style indicators and response distribution indicators.\n             For an overview on response quality indicators see Bhaktha N,\n             Henning S, Clemens L (2024). 'Characterizing response quality\n             in surveys with multi-item scales: A unified framework'\n             <https://osf.io/9gs67/>.  "
  },
  {
    "id": 19404,
    "package_name": "restatis",
    "title": "R Wrapper to Access a Wide Range of Germany's Federal\nStatistical System Databases Based on the GENESIS Web Service\nRESTful API of the German Federal Statistical Office\n(Statistisches Bundesamt/Destatis)",
    "description": "A RESTful API wrapper for accessing the GENESIS database of\n    the German Federal Statistical Office (Destatis) as well as its Census \n    Database and the database of Germany's regional statistics. Supports data \n    search functions, credential management, result caching, and handling \n    remote background jobs for large datasets.",
    "version": "0.3.0",
    "maintainer": "Yannik Buhl <ybuhl@posteo.de>",
    "author": "Yannik Buhl [aut, cre],\n  Zoran Kovacevic [aut] (ORCID: <https://orcid.org/0009-0002-0156-0862>),\n  Dorian Le Jeune [aut],\n  Long Nguyen [aut] (ORCID: <https://orcid.org/0000-0001-8878-7386>),\n  Johannes Ritter [aut]",
    "url": "https://correlaid.github.io/restatis/,\nhttps://github.com/CorrelAid/restatis",
    "bug_reports": "https://github.com/CorrelAid/restatis/issues",
    "repository": "https://cran.r-project.org/package=restatis",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "restatis R Wrapper to Access a Wide Range of Germany's Federal\nStatistical System Databases Based on the GENESIS Web Service\nRESTful API of the German Federal Statistical Office\n(Statistisches Bundesamt/Destatis) A RESTful API wrapper for accessing the GENESIS database of\n    the German Federal Statistical Office (Destatis) as well as its Census \n    Database and the database of Germany's regional statistics. Supports data \n    search functions, credential management, result caching, and handling \n    remote background jobs for large datasets.  "
  },
  {
    "id": 19421,
    "package_name": "retroharmonize",
    "title": "Ex Post Survey Data Harmonization",
    "description": "Assist in reproducible retrospective (ex-post) harmonization\n    of data, particularly individual level survey data, by providing tools\n    for organizing metadata, standardizing the coding of variables, and\n    variable names and value labels, including missing values, and\n    documenting the data transformations, with the help of comprehensive\n    s3 classes.",
    "version": "0.2.0",
    "maintainer": "Daniel Antal <daniel.antal@ceemid.eu>",
    "author": "Daniel Antal [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7513-6760>),\n  Marta Kolczynska [ctb] (ORCID: <https://orcid.org/0000-0003-4981-0437>),\n  Pyry Kantanen [ctb] (ORCID: <https://orcid.org/0000-0003-2853-2765>),\n  Diego Hernang\u00f3mez Herrero [ctb] (ORCID:\n    <https://orcid.org/0000-0001-8457-4658>)",
    "url": "https://retroharmonize.dataobservatory.eu/,\nhttps://ropengov.github.io/retroharmonize/,\nhttps://github.com/rOpenGov/retroharmonize",
    "bug_reports": "https://github.com/rOpenGov/retroharmonize/issues",
    "repository": "https://cran.r-project.org/package=retroharmonize",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "retroharmonize Ex Post Survey Data Harmonization Assist in reproducible retrospective (ex-post) harmonization\n    of data, particularly individual level survey data, by providing tools\n    for organizing metadata, standardizing the coding of variables, and\n    variable names and value labels, including missing values, and\n    documenting the data transformations, with the help of comprehensive\n    s3 classes.  "
  },
  {
    "id": 19428,
    "package_name": "revengc",
    "title": "Reverse Engineering Summarized Data",
    "description": "Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec function reverse engineers summarized data into an uncensored bivariate table of probabilities.",
    "version": "1.0.4",
    "maintainer": "Samantha Duchscherer <sam.duchscherer@gmail.com>",
    "author": "Samantha Duchscherer [aut, cre],\n  UT-Battelle, LLC [cph]",
    "url": "https://github.com/GIST-ORNL/revengc",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=revengc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "revengc Reverse Engineering Summarized Data Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec function reverse engineers summarized data into an uncensored bivariate table of probabilities.  "
  },
  {
    "id": 19468,
    "package_name": "rgexf",
    "title": "Build, Import, and Export GEXF Graph Files",
    "description": "Create, read, and write 'GEXF' (Graph Exchange 'XML' Format) graph files (used in 'Gephi' and others). Using the 'XML' package, rgexf allows reading and writing GEXF files, including attributes, 'GEXF' visual attributes (such as color, size, and position), network dynamics (for both edges and nodes), and edges' weights. Users can build/handle graphs element-by-element or massively through data frames, visualize the graph on a web browser through 'gexf-js' (a 'javascript' library), and interact with the 'igraph' package.",
    "version": "0.16.3",
    "maintainer": "George Vega Yon <g.vegayon@gmail.com>",
    "author": "George Vega Yon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3171-0844>),\n  Jorge F\u00e1brega Lacoa [ctb],\n  Joshua Kunst [ctb],\n  Rapha\u00ebl Velt [cph] (gexf-js library),\n  Gephi Consortium [cph] (GEXF language),\n  Cornelius Fritz [rev] (what: JOSS reviewer),\n  Jonathan Cardoso Silva [rev] (what: JOSS reviewer)",
    "url": "https://gvegayon.github.io/rgexf/",
    "bug_reports": "https://github.com/gvegayon/rgexf/issues",
    "repository": "https://cran.r-project.org/package=rgexf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rgexf Build, Import, and Export GEXF Graph Files Create, read, and write 'GEXF' (Graph Exchange 'XML' Format) graph files (used in 'Gephi' and others). Using the 'XML' package, rgexf allows reading and writing GEXF files, including attributes, 'GEXF' visual attributes (such as color, size, and position), network dynamics (for both edges and nodes), and edges' weights. Users can build/handle graphs element-by-element or massively through data frames, visualize the graph on a web browser through 'gexf-js' (a 'javascript' library), and interact with the 'igraph' package.  "
  },
  {
    "id": 19478,
    "package_name": "rgraph6",
    "title": "Representing Graphs as 'graph6', 'digraph6' or 'sparse6' Strings",
    "description": "Encode network data as strings of printable ASCII characters. Implemented \n    functions include encoding and decoding adjacency matrices, edgelists, igraph, and\n    network objects to/from formats 'graph6', 'sparse6', and 'digraph6'. The formats and\n    methods are described in McKay, B.D. and Piperno, A (2014)\n    <doi:10.1016/j.jsc.2013.09.003>.",
    "version": "2.0-5",
    "maintainer": "Michal Bojanowski <michal2992@gmail.com>",
    "author": "Michal Bojanowski [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7503-852X>, affil: Kozminski\n    University),\n  David Schoch [aut] (ORCID: <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://mbojan.github.io/rgraph6/",
    "bug_reports": "https://github.com/mbojan/rgraph6/issues",
    "repository": "https://cran.r-project.org/package=rgraph6",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rgraph6 Representing Graphs as 'graph6', 'digraph6' or 'sparse6' Strings Encode network data as strings of printable ASCII characters. Implemented \n    functions include encoding and decoding adjacency matrices, edgelists, igraph, and\n    network objects to/from formats 'graph6', 'sparse6', and 'digraph6'. The formats and\n    methods are described in McKay, B.D. and Piperno, A (2014)\n    <doi:10.1016/j.jsc.2013.09.003>.  "
  },
  {
    "id": 19517,
    "package_name": "rineq",
    "title": "Concentration Index and Decomposition for Health Inequalities",
    "description": "Relative, generalized, and Erreygers corrected concentration index; plot Lorenz curves; and decompose health\n    inequalities into contributing factors. The package currently works with (generalized) linear models, survival models, complex survey models, and marginal effects probit models.\n    originally forked by Brecht Devleesschauwer from the 'decomp' package  (no longer on CRAN), 'rineq' is now maintained by Kaspar Walter Meili. Compared to the earlier 'rineq' version on 'github' by Brecht Devleesschauwer (<https://github.com/brechtdv/rineq>), the regression tree functionality has been removed.\n    Improvements compared to earlier versions include improved plotting of decomposition and concentration, added functionality to calculate the concentration index with different methods, calculation of robust standard errors, and support for the decomposition analysis using marginal effects probit regression models. The development version is available at <https://github.com/kdevkdev/rineq>.",
    "version": "0.3.0",
    "maintainer": "Kaspar Meili <meilikaspar@yahoo.de>",
    "author": "Brecht Devleesschauwer [aut, cph],\n  Saveria Willim\u00e8s [aut, cph],\n  Carine Van Malderen [aut, cph],\n  Peter Konings [aut, cph],\n  Niko Speybroeck [aut, cph],\n  Kaspar Meili [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9889-4406>)",
    "url": "https://github.com/kdevkdev/rineq",
    "bug_reports": "https://github.com/kdevkdev/rineq/issues",
    "repository": "https://cran.r-project.org/package=rineq",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rineq Concentration Index and Decomposition for Health Inequalities Relative, generalized, and Erreygers corrected concentration index; plot Lorenz curves; and decompose health\n    inequalities into contributing factors. The package currently works with (generalized) linear models, survival models, complex survey models, and marginal effects probit models.\n    originally forked by Brecht Devleesschauwer from the 'decomp' package  (no longer on CRAN), 'rineq' is now maintained by Kaspar Walter Meili. Compared to the earlier 'rineq' version on 'github' by Brecht Devleesschauwer (<https://github.com/brechtdv/rineq>), the regression tree functionality has been removed.\n    Improvements compared to earlier versions include improved plotting of decomposition and concentration, added functionality to calculate the concentration index with different methods, calculation of robust standard errors, and support for the decomposition analysis using marginal effects probit regression models. The development version is available at <https://github.com/kdevkdev/rineq>.  "
  },
  {
    "id": 19648,
    "package_name": "roads",
    "title": "Road Network Projection",
    "description": "Iterative least cost path and minimum spanning tree methods for projecting \n    forest road networks. The methods connect a set of target points to an existing \n    road network using 'igraph' <https://igraph.org> to identify least cost routes.\n    The cost of constructing a road segment between adjacent pixels is determined\n    by a user supplied weight raster and a weight function; options include the\n    average of adjacent weight raster values, and a function of the elevation \n    differences between adjacent cells that penalizes steep grades. These road\n    network projection methods are intended for integration into R workflows and \n    modelling frameworks used for forecasting forest change, and can be applied \n    over multiple time-steps without rebuilding a graph at each time-step.",
    "version": "1.2.0",
    "maintainer": "Sarah Endicott <sarah.endicott@ec.gc.ca>",
    "author": "Sarah Endicott [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-9644-5343>),\n  Kyle Lochhead [aut],\n  Josie Hughes [aut],\n  Patrick Kirby [aut],\n  Her Majesty the Queen in Right of Canada as represented by the Minister\n    of the Environment [cph] (Copyright holder for included functions\n    buildSimList, getLandingsFromTarget, pathsToLines, plotRoads,\n    projectRoads, rasterizeLine, rasterToLineSegments),\n  Province of British Columbia [cph] (Copyright holder for included\n    functions getGraph, lcpList, mstList, shortestPaths,\n    getClosestRoad, buildSnapRoads)",
    "url": "https://github.com/LandSciTech/roads,\nhttps://landscitech.github.io/roads/",
    "bug_reports": "https://github.com/LandSciTech/roads/issues",
    "repository": "https://cran.r-project.org/package=roads",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "roads Road Network Projection Iterative least cost path and minimum spanning tree methods for projecting \n    forest road networks. The methods connect a set of target points to an existing \n    road network using 'igraph' <https://igraph.org> to identify least cost routes.\n    The cost of constructing a road segment between adjacent pixels is determined\n    by a user supplied weight raster and a weight function; options include the\n    average of adjacent weight raster values, and a function of the elevation \n    differences between adjacent cells that penalizes steep grades. These road\n    network projection methods are intended for integration into R workflows and \n    modelling frameworks used for forecasting forest change, and can be applied \n    over multiple time-steps without rebuilding a graph at each time-step.  "
  },
  {
    "id": 19676,
    "package_name": "robsurvey",
    "title": "Robust Survey Statistics Estimation",
    "description": "Robust (outlier-resistant) estimators of finite population\n    characteristics like of means, totals, ratios, regression, etc. Available\n    methods are M- and GM-estimators of regression, weight reduction,\n    trimming, and winsorization. The package extends the 'survey'\n    <https://CRAN.R-project.org/package=survey> package.",
    "version": "0.7",
    "maintainer": "Tobias Schoch <tobias.schoch@fhnw.ch>",
    "author": "Beat Hulliger [aut] (ORCID: <https://orcid.org/0000-0001-5252-8606>),\n  Tobias Schoch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-1640-3395>),\n  Martin Sterchi [ctr, com],\n  R-core [ctb, cph] (for zeroin2.c)",
    "url": "https://github.com/tobiasschoch/robsurvey",
    "bug_reports": "https://github.com/tobiasschoch/robsurvey/issues",
    "repository": "https://cran.r-project.org/package=robsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "robsurvey Robust Survey Statistics Estimation Robust (outlier-resistant) estimators of finite population\n    characteristics like of means, totals, ratios, regression, etc. Available\n    methods are M- and GM-estimators of regression, weight reduction,\n    trimming, and winsorization. The package extends the 'survey'\n    <https://CRAN.R-project.org/package=survey> package.  "
  },
  {
    "id": 19729,
    "package_name": "rollupTree",
    "title": "Perform Recursive Computations",
    "description": "Mass rollup for a Bill of Materials is an example of a class of computations in which elements are arranged in a tree structure and some property of each element is a computed function of the corresponding values of its child elements. Leaf elements, i.e., those with no children, have values assigned. In many cases, the combining function is simple arithmetic sum; in other cases (e.g., mass properties), the combiner may involve other information such as the geometric relationship between parent and child, or statistical relations such as root-sum-of-squares (RSS). This package implements a general function for such problems. It is adapted to specific recursive computations by functional programming techniques; the caller passes a function as the update parameter to rollup() (or, at a lower level, passes functions as the get, set, combine, and override parameters to update_prop()) at runtime to specify the desired operations. The implementation relies on graph-theoretic algorithms from the 'igraph' package of Cs\u00e1rdi, et al. (2006 <doi:10.5281/zenodo.7682609>).",
    "version": "0.3.2",
    "maintainer": "James Steven Jenkins <sjenkins@studioj.us>",
    "author": "James Steven Jenkins [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0725-0884>)",
    "url": "https://jsjuni.github.io/rollupTree/,\nhttps://github.com/jsjuni/rollupTree",
    "bug_reports": "https://github.com/jsjuni/rollupTree/issues",
    "repository": "https://cran.r-project.org/package=rollupTree",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rollupTree Perform Recursive Computations Mass rollup for a Bill of Materials is an example of a class of computations in which elements are arranged in a tree structure and some property of each element is a computed function of the corresponding values of its child elements. Leaf elements, i.e., those with no children, have values assigned. In many cases, the combining function is simple arithmetic sum; in other cases (e.g., mass properties), the combiner may involve other information such as the geometric relationship between parent and child, or statistical relations such as root-sum-of-squares (RSS). This package implements a general function for such problems. It is adapted to specific recursive computations by functional programming techniques; the caller passes a function as the update parameter to rollup() (or, at a lower level, passes functions as the get, set, combine, and override parameters to update_prop()) at runtime to specify the desired operations. The implementation relies on graph-theoretic algorithms from the 'igraph' package of Cs\u00e1rdi, et al. (2006 <doi:10.5281/zenodo.7682609>).  "
  },
  {
    "id": 19789,
    "package_name": "rpm",
    "title": "Modeling of Revealed Preferences Matchings",
    "description": "Statistical estimation of revealed preference models from data collected on bipartite matchings. The models are for matchings within a bipartite population where individuals have utility for people based on known and unknown characteristics. People can form a partnership or remain unpartnered. The model represents both the availability of potential partners of different types and preferences of individuals for such people. The software estimates preference parameters based on sample survey data on partnerships and population composition. The simulation of matchings and goodness-of-fit are considered.  See Goyal, Handcock, Jackson, Rendall and Yeung (2022) <doi:10.1093/jrsssa/qnad031>.",
    "version": "0.7-4",
    "maintainer": "Mark S. Handcock <handcock@stat.ucla.edu>",
    "author": "Mark S. Handcock [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9985-2785>),\n  Ryan M. Admiraal [ctb],\n  Fiona C. Yeung [ctb],\n  Heide M. Jackson [ctb],\n  Michael S. Rendall [ctb],\n  Shuchi Goyal [ctb]",
    "url": "https://github.com/handcock/rpm",
    "bug_reports": "https://github.com/handcock/rpm/issues",
    "repository": "https://cran.r-project.org/package=rpm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rpm Modeling of Revealed Preferences Matchings Statistical estimation of revealed preference models from data collected on bipartite matchings. The models are for matchings within a bipartite population where individuals have utility for people based on known and unknown characteristics. People can form a partnership or remain unpartnered. The model represents both the availability of potential partners of different types and preferences of individuals for such people. The software estimates preference parameters based on sample survey data on partnerships and population composition. The simulation of matchings and goodness-of-fit are considered.  See Goyal, Handcock, Jackson, Rendall and Yeung (2022) <doi:10.1093/jrsssa/qnad031>.  "
  },
  {
    "id": 19791,
    "package_name": "rpms",
    "title": "Recursive Partitioning for Modeling Survey Data",
    "description": "Functions to allow users to build and analyze design consistent \n    tree and random forest models using survey data from a complex sample \n    design.  The tree model algorithm can fit a linear model to survey data \n    in each node obtained by recursively partitioning the data.  The splitting \n    variables and selected splits are obtained using a randomized permutation \n    test procedure which adjusted for complex sample design features used to \n    obtain the data. Likewise the model fitting algorithm produces \n    design-consistent coefficients to any specified least squares linear model \n    between the dependent and independent variables used in the end nodes.\n    The main functions return the resulting binary tree or random forest as \n    an object of \"rpms\" or \"rpms_forest\" type. The package also provides methods\n    modeling a \"boosted\" tree or forest model and a tree model for zero-inflated\n    data as well as a number of functions and methods available for use with \n    these object types.",
    "version": "0.5.1",
    "maintainer": "Daniell Toth <danielltoth@yahoo.com>",
    "author": "Daniell Toth [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rpms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rpms Recursive Partitioning for Modeling Survey Data Functions to allow users to build and analyze design consistent \n    tree and random forest models using survey data from a complex sample \n    design.  The tree model algorithm can fit a linear model to survey data \n    in each node obtained by recursively partitioning the data.  The splitting \n    variables and selected splits are obtained using a randomized permutation \n    test procedure which adjusted for complex sample design features used to \n    obtain the data. Likewise the model fitting algorithm produces \n    design-consistent coefficients to any specified least squares linear model \n    between the dependent and independent variables used in the end nodes.\n    The main functions return the resulting binary tree or random forest as \n    an object of \"rpms\" or \"rpms_forest\" type. The package also provides methods\n    modeling a \"boosted\" tree or forest model and a tree model for zero-inflated\n    data as well as a number of functions and methods available for use with \n    these object types.  "
  },
  {
    "id": 19809,
    "package_name": "rr",
    "title": "Statistical Methods for the Randomized Response Technique",
    "description": "Enables researchers to conduct multivariate statistical analyses\n    of survey data with randomized response technique items from several designs,\n    including mirrored question, forced question, and unrelated question. This\n    includes regression with the randomized response as the outcome and logistic\n    regression with the randomized response item as a predictor. In addition,\n    tools for conducting power analysis for designing randomized response items\n    are included. The package implements methods described in Blair, Imai, and Zhou\n    (2015) ''Design and Analysis of the Randomized Response Technique,'' Journal\n    of the American Statistical Association \n    <https://graemeblair.com/papers/randresp.pdf>.",
    "version": "1.4.2",
    "maintainer": "Graeme Blair <graeme.blair@gmail.com>",
    "author": "Graeme Blair [aut, cre],\n  Yang-Yang Zhou [aut],\n  Kosuke Imai [aut],\n  Winston Chou [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rr Statistical Methods for the Randomized Response Technique Enables researchers to conduct multivariate statistical analyses\n    of survey data with randomized response technique items from several designs,\n    including mirrored question, forced question, and unrelated question. This\n    includes regression with the randomized response as the outcome and logistic\n    regression with the randomized response item as a predictor. In addition,\n    tools for conducting power analysis for designing randomized response items\n    are included. The package implements methods described in Blair, Imai, and Zhou\n    (2015) ''Design and Analysis of the Randomized Response Technique,'' Journal\n    of the American Statistical Association \n    <https://graemeblair.com/papers/randresp.pdf>.  "
  },
  {
    "id": 19858,
    "package_name": "rsocialwatcher",
    "title": "'Facebook Marketing API' Social Watcher",
    "description": "Facilitates querying data from the \u2018Facebook Marketing API', particularly for social science research <https://developers.facebook.com/docs/marketing-apis/>. Data from the 'Facebook Marketing API' has been used for a variety of social science applications, such as for poverty estimation (Marty and Duhaut (2024) <doi:10.1038/s41598-023-49564-6>), disease surveillance (Araujo et al. (2017) <doi:10.48550/arXiv.1705.04045>), and measuring migration (Alexander, Polimis, and Zagheni (2020) <doi:10.1007/s11113-020-09599-3>). The package facilitates querying the number of Facebook daily/monthly active users for multiple location types (e.g., from around a specific coordinate to an administrative region) and for a number of attribute types (e.g., interests, behaviors, education level, etc). The package supports making complex queries within one API call and making multiple API calls across different locations and/or parameters.",
    "version": "0.1.1",
    "maintainer": "Robert Marty <rmarty@worldbank.org>",
    "author": "Robert Marty [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3164-3813>)",
    "url": "https://worldbank.github.io/rsocialwatcher/",
    "bug_reports": "https://github.com/worldbank/rsocialwatcher/issues",
    "repository": "https://cran.r-project.org/package=rsocialwatcher",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rsocialwatcher 'Facebook Marketing API' Social Watcher Facilitates querying data from the \u2018Facebook Marketing API', particularly for social science research <https://developers.facebook.com/docs/marketing-apis/>. Data from the 'Facebook Marketing API' has been used for a variety of social science applications, such as for poverty estimation (Marty and Duhaut (2024) <doi:10.1038/s41598-023-49564-6>), disease surveillance (Araujo et al. (2017) <doi:10.48550/arXiv.1705.04045>), and measuring migration (Alexander, Polimis, and Zagheni (2020) <doi:10.1007/s11113-020-09599-3>). The package facilitates querying the number of Facebook daily/monthly active users for multiple location types (e.g., from around a specific coordinate to an administrative region) and for a number of attribute types (e.g., interests, behaviors, education level, etc). The package supports making complex queries within one API call and making multiple API calls across different locations and/or parameters.  "
  },
  {
    "id": 19866,
    "package_name": "rspiro",
    "title": "Implementation of Spirometry Equations",
    "description": "Implementation of various spirometry equations\n    in R, currently the GLI-2012 (Global Lung Initiative;\n    Quanjer et al. 2012 <doi:10.1183/09031936.00080312>),\n    the race-neutral GLI global 2022 (Global Lung Initiative;\n    Bowerman et al. 2023 <doi:10.1164/rccm.202205-0963OC>), the\n    NHANES3 (National Health and Nutrition Examination Survey;\n    Hankinson et al. 1999 <doi:10.1164/ajrccm.159.1.9712108>)\n    and the JRS 2014 (Japanese Respiratory Society; Kubota\n    et al. 2014 <doi:10.1016/j.resinv.2014.03.003>) equations.\n    Also the GLI-2017 diffusing capacity equations \n    <doi:10.1183/13993003.00010-2017> are implemented.\n    Contains user-friendly functions to calculate predicted \n    and LLN (Lower Limit of Normal) values for different \n    spirometric parameters such as FEV1 (Forced Expiratory \n    Volume in 1 second), FVC (Forced Vital Capacity), etc, \n    and to convert absolute spirometry measurements \n    to percent (%) predicted and z-scores.",
    "version": "0.5",
    "maintainer": "Theodore Lytras <thlytras@gmail.com>",
    "author": "Theodore Lytras",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rspiro",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rspiro Implementation of Spirometry Equations Implementation of various spirometry equations\n    in R, currently the GLI-2012 (Global Lung Initiative;\n    Quanjer et al. 2012 <doi:10.1183/09031936.00080312>),\n    the race-neutral GLI global 2022 (Global Lung Initiative;\n    Bowerman et al. 2023 <doi:10.1164/rccm.202205-0963OC>), the\n    NHANES3 (National Health and Nutrition Examination Survey;\n    Hankinson et al. 1999 <doi:10.1164/ajrccm.159.1.9712108>)\n    and the JRS 2014 (Japanese Respiratory Society; Kubota\n    et al. 2014 <doi:10.1016/j.resinv.2014.03.003>) equations.\n    Also the GLI-2017 diffusing capacity equations \n    <doi:10.1183/13993003.00010-2017> are implemented.\n    Contains user-friendly functions to calculate predicted \n    and LLN (Lower Limit of Normal) values for different \n    spirometric parameters such as FEV1 (Forced Expiratory \n    Volume in 1 second), FVC (Forced Vital Capacity), etc, \n    and to convert absolute spirometry measurements \n    to percent (%) predicted and z-scores.  "
  },
  {
    "id": 19885,
    "package_name": "rsurveycto",
    "title": "Interact with Data on 'SurveyCTO'",
    "description": "'SurveyCTO' is a platform for mobile data collection in offline settings.\n  The 'rsurveycto' R package uses the 'SurveyCTO' REST API\n  <https://docs.surveycto.com/05-exporting-and-publishing-data/05-api-access/01.api-access.html>\n  to read datasets and forms from a 'SurveyCTO' server into R as 'data.table's\n  and to download file attachments. The package also has limited support to\n  write datasets to a server.",
    "version": "0.2.2",
    "maintainer": "Jake Hughey <jake@agency.fund>",
    "author": "Jake Hughey [aut, cre],\n  Robert On [aut]",
    "url": "https://agency-fund.github.io/rsurveycto/,\nhttps://github.com/agency-fund/rsurveycto",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rsurveycto",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rsurveycto Interact with Data on 'SurveyCTO' 'SurveyCTO' is a platform for mobile data collection in offline settings.\n  The 'rsurveycto' R package uses the 'SurveyCTO' REST API\n  <https://docs.surveycto.com/05-exporting-and-publishing-data/05-api-access/01.api-access.html>\n  to read datasets and forms from a 'SurveyCTO' server into R as 'data.table's\n  and to download file attachments. The package also has limited support to\n  write datasets to a server.  "
  },
  {
    "id": 19911,
    "package_name": "rtip",
    "title": "Inequality, Welfare and Poverty Indices and Curves using the\nEU-SILC Data",
    "description": "R tools to measure and compare inequality, welfare and poverty using the EU statistics on income and living conditions surveys.",
    "version": "1.1.1",
    "maintainer": "Angel Berihuete <angel.berihuete@uca.es>",
    "author": "Angel Berihuete [aut, cre],\n  Carmen Dolores Ramos [aut],\n  Miguel Angel Sordo [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=rtip",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "rtip Inequality, Welfare and Poverty Indices and Curves using the\nEU-SILC Data R tools to measure and compare inequality, welfare and poverty using the EU statistics on income and living conditions surveys.  "
  },
  {
    "id": 20024,
    "package_name": "sae2",
    "title": "Small Area Estimation: Time-Series Models",
    "description": "Time series area-level models for small area estimation. \n      The package supplements the functionality of the sae package. Specifically, it includes\n      EBLUP fitting of the Rao-Yu model in the original form without a spatial component. \n      The package also offers a modified (\"dynamic\") version of the Rao-Yu model, replacing\n      the assumption of stationarity. Both univariate and multivariate applications are\n      supported. Of particular note is the allowance for covariance of the area-level sample \n      estimates over time, as encountered in rotating panel designs such as the U.S. National \n      Crime Victimization Survey or present in a time-series of 5-year estimates from the \n      American Community Survey. Key references to the methods include\n      J.N.K. Rao and I. Molina (2015, ISBN:9781118735787),\n      J.N.K. Rao and M. Yu (1994) <doi:10.2307/3315407>, and\n      R.E. Fay and R.A. Herriot (1979) <doi:10.1080/01621459.1979.10482505>.",
    "version": "1.2-2",
    "maintainer": "Robert Fay <bobfay@hotmail.com>",
    "author": "Robert Fay [aut, cre],\n  Mamadou Diallo [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sae2",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sae2 Small Area Estimation: Time-Series Models Time series area-level models for small area estimation. \n      The package supplements the functionality of the sae package. Specifically, it includes\n      EBLUP fitting of the Rao-Yu model in the original form without a spatial component. \n      The package also offers a modified (\"dynamic\") version of the Rao-Yu model, replacing\n      the assumption of stationarity. Both univariate and multivariate applications are\n      supported. Of particular note is the allowance for covariance of the area-level sample \n      estimates over time, as encountered in rotating panel designs such as the U.S. National \n      Crime Victimization Survey or present in a time-series of 5-year estimates from the \n      American Community Survey. Key references to the methods include\n      J.N.K. Rao and I. Molina (2015, ISBN:9781118735787),\n      J.N.K. Rao and M. Yu (1994) <doi:10.2307/3315407>, and\n      R.E. Fay and R.A. Herriot (1979) <doi:10.1080/01621459.1979.10482505>.  "
  },
  {
    "id": 20025,
    "package_name": "sae4health",
    "title": "Small Area Estimation for Key Health and Demographic Indicators\nfrom Household Surveys",
    "description": "Enables small area estimation (SAE) of health and demographic indicators in low- and middle-income countries (LMICs). It powers an R 'shiny' application for generating subnational estimates and prevalence maps of 150+ binary indicators from Demographic and Health Surveys (DHS). It builds on the SAE analysis workflow from the 'surveyPrev' package. For documentation, visit <https://sae4health.stat.uw.edu/>. Methodological details can be found at Wu et al. (2025) <doi:10.48550/arXiv.2505.01467>.",
    "version": "1.2.3",
    "maintainer": "Yunhan Wu <wu-thomas@outlook.com>",
    "author": "Yunhan Wu [cre, aut],\n  Qianyu Dong [aut],\n  Zehang R Li [aut],\n  Jon Wakefield [aut]",
    "url": "https://sae4health.stat.uw.edu/,\nhttps://github.com/wu-thomas/sae4health",
    "bug_reports": "https://github.com/wu-thomas/sae4health/issues",
    "repository": "https://cran.r-project.org/package=sae4health",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sae4health Small Area Estimation for Key Health and Demographic Indicators\nfrom Household Surveys Enables small area estimation (SAE) of health and demographic indicators in low- and middle-income countries (LMICs). It powers an R 'shiny' application for generating subnational estimates and prevalence maps of 150+ binary indicators from Demographic and Health Surveys (DHS). It builds on the SAE analysis workflow from the 'surveyPrev' package. For documentation, visit <https://sae4health.stat.uw.edu/>. Methodological details can be found at Wu et al. (2025) <doi:10.48550/arXiv.2505.01467>.  "
  },
  {
    "id": 20042,
    "package_name": "saeTrafo",
    "title": "Transformations for Unit-Level Small Area Models",
    "description": "The aim of this package is to offer new methodology for unit-level \n    small area models under transformations and limited population auxiliary \n    information. In addition to this new methodology, the widely used nested \n    error regression model without transformations (see \"An Error-Components \n    Model for Prediction of County Crop Areas Using Survey and Satellite Data\" \n    by Battese, Harter and Fuller (1988) <doi:10.1080/01621459.1988.10478561>) \n    and its well-known uncertainty estimate (see \"The estimation of the mean \n    squared error of small-area estimators\" by Prasad and Rao (1990) \n    <doi:10.1080/01621459.1995.10476570>) are provided. In this package, the \n    log transformation and the data-driven log-shift transformation are \n    provided. If a transformation is selected, an appropriate method is chosen \n    depending on the respective input of the population data: Individual \n    population data (see \"Empirical best prediction under a nested error model \n    with log transformation\" by Molina and Mart\u00edn (2018) \n    <doi:10.1214/17-aos1608>) but also aggregated population data (see \n    \"Estimating regional income indicators under transformations and access to \n    limited population auxiliary information\" by W\u00fcrz, Schmid and Tzavidis \n    <unpublished>) can be entered. Especially under limited data access, new \n    methodologies are provided in saeTrafo. Several options are available to \n    assess the used model and to judge, present and export its results. For a \n    detailed description of the package and the methods used see the \n    corresponding vignette.",
    "version": "1.0.6",
    "maintainer": "Nora W\u00fcrz <nora.wuerz@uni-bamberg.de>",
    "author": "Nora W\u00fcrz [aut, cre]",
    "url": "https://github.com/NoraWuerz/saeTrafo",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=saeTrafo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "saeTrafo Transformations for Unit-Level Small Area Models The aim of this package is to offer new methodology for unit-level \n    small area models under transformations and limited population auxiliary \n    information. In addition to this new methodology, the widely used nested \n    error regression model without transformations (see \"An Error-Components \n    Model for Prediction of County Crop Areas Using Survey and Satellite Data\" \n    by Battese, Harter and Fuller (1988) <doi:10.1080/01621459.1988.10478561>) \n    and its well-known uncertainty estimate (see \"The estimation of the mean \n    squared error of small-area estimators\" by Prasad and Rao (1990) \n    <doi:10.1080/01621459.1995.10476570>) are provided. In this package, the \n    log transformation and the data-driven log-shift transformation are \n    provided. If a transformation is selected, an appropriate method is chosen \n    depending on the respective input of the population data: Individual \n    population data (see \"Empirical best prediction under a nested error model \n    with log transformation\" by Molina and Mart\u00edn (2018) \n    <doi:10.1214/17-aos1608>) but also aggregated population data (see \n    \"Estimating regional income indicators under transformations and access to \n    limited population auxiliary information\" by W\u00fcrz, Schmid and Tzavidis \n    <unpublished>) can be entered. Especially under limited data access, new \n    methodologies are provided in saeTrafo. Several options are available to \n    assess the used model and to judge, present and export its results. For a \n    detailed description of the package and the methods used see the \n    corresponding vignette.  "
  },
  {
    "id": 20071,
    "package_name": "sampcompR",
    "title": "Comparing and Visualizing Differences Between Surveys",
    "description": "Easily analyze and visualize differences between samples (e.g., benchmark comparisons, nonresponse comparisons in surveys) on three levels. The comparisons can be univariate, bivariate or multivariate. On univariate level the variables of interest of a survey and a comparison survey (i.e. benchmark) are compared, by calculating one of several difference measures (e.g., relative difference in mean), and an average difference between the surveys. On bivariate level a function can calculate significant differences in correlations for the surveys. And on multivariate levels a function can calculate significant differences in model coefficients between the surveys of comparison. All of those differences can be easily plotted and outputted as a table. For more  detailed information on the methods and example use see Rohr, B., Silber, H., & Felderer, B. (2024). Comparing the Accuracy of Univariate, Bivariate, and Multivariate Estimates across Probability and Nonprobability Surveys with Population Benchmarks. Sociological Methodology <doi:10.1177/00811750241280963>.",
    "version": "0.3.2",
    "maintainer": "Bjoern Rohr <bjoern.rohr@gesis.org>",
    "author": "Bjoern Rohr [aut, cre, cph],\n  Barbara Felderer [aut]",
    "url": "https://bjoernrohr.github.io/sampcompR/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sampcompR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sampcompR Comparing and Visualizing Differences Between Surveys Easily analyze and visualize differences between samples (e.g., benchmark comparisons, nonresponse comparisons in surveys) on three levels. The comparisons can be univariate, bivariate or multivariate. On univariate level the variables of interest of a survey and a comparison survey (i.e. benchmark) are compared, by calculating one of several difference measures (e.g., relative difference in mean), and an average difference between the surveys. On bivariate level a function can calculate significant differences in correlations for the surveys. And on multivariate levels a function can calculate significant differences in model coefficients between the surveys of comparison. All of those differences can be easily plotted and outputted as a table. For more  detailed information on the methods and example use see Rohr, B., Silber, H., & Felderer, B. (2024). Comparing the Accuracy of Univariate, Bivariate, and Multivariate Estimates across Probability and Nonprobability Surveys with Population Benchmarks. Sociological Methodology <doi:10.1177/00811750241280963>.  "
  },
  {
    "id": 20074,
    "package_name": "sampledatasets",
    "title": "A Collection of Sample Datasets",
    "description": "Provides a collection of sample datasets \n    on various fields such as automotive performance and safety data to historical demographics and socioeconomic indicators, as well as recreational data.\n    It serves as a resource for researchers and analysts seeking to perform analyses and derive insights from classic data sets in R.",
    "version": "0.1.0",
    "maintainer": "Renzo Caceres Rossi <arenzocaceresrossi@gmail.com>",
    "author": "Renzo Caceres Rossi [aut, cre]",
    "url": "https://github.com/lightbluetitan/sampledatasets",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sampledatasets",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sampledatasets A Collection of Sample Datasets Provides a collection of sample datasets \n    on various fields such as automotive performance and safety data to historical demographics and socioeconomic indicators, as well as recreational data.\n    It serves as a resource for researchers and analysts seeking to perform analyses and derive insights from classic data sets in R.  "
  },
  {
    "id": 20077,
    "package_name": "samplesize4surveys",
    "title": "Sample Size Calculations for Complex Surveys",
    "description": "Computes the required sample size for estimation of totals, means\n    and proportions under complex sampling designs.",
    "version": "4.1.1",
    "maintainer": "Hugo Andres Gutierrez Rojas <hagutierrezro@gmail.com>",
    "author": "Hugo Andres Gutierrez Rojas",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=samplesize4surveys",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samplesize4surveys Sample Size Calculations for Complex Surveys Computes the required sample size for estimation of totals, means\n    and proportions under complex sampling designs.  "
  },
  {
    "id": 20081,
    "package_name": "samplex",
    "title": "Shiny Tool for Sample Size Calculation",
    "description": "An interactive 'shiny' application to assist in determining\n    sample sizes for common survey designs such as 'simple random\n    sampling', 'stratified sampling', and 'cluster sampling'. It includes\n    formulas, helper calculators, and illustrative examples.",
    "version": "0.3.0",
    "maintainer": "Gustavo Ramirez-Valverde <gramirez@colpos.mx>",
    "author": "Gustavo Ramirez-Valverde [aut, cre],\n  Benito Ramirez-Valverde [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=samplex",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samplex Shiny Tool for Sample Size Calculation An interactive 'shiny' application to assist in determining\n    sample sizes for common survey designs such as 'simple random\n    sampling', 'stratified sampling', and 'cluster sampling'. It includes\n    formulas, helper calculators, and illustrative examples.  "
  },
  {
    "id": 20083,
    "package_name": "sampling",
    "title": "Survey Sampling",
    "description": "Functions to draw random samples using different sampling schemes are available. Functions are also provided to obtain (generalized) calibration weights, different estimators, as well some variance estimators.  ",
    "version": "2.11",
    "maintainer": "Alina Matei <alina.matei@unine.ch>",
    "author": "Yves Till\u00e9 [aut],\n  Alina Matei [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sampling",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sampling Survey Sampling Functions to draw random samples using different sampling schemes are available. Functions are also provided to obtain (generalized) calibration weights, different estimators, as well some variance estimators.    "
  },
  {
    "id": 20087,
    "package_name": "samplingbook",
    "title": "Survey Sampling Procedures",
    "description": "Sampling procedures from the book 'Stichproben - Methoden und praktische Umsetzung mit R' by Goeran Kauermann and Helmut Kuechenhoff (2010).",
    "version": "1.2.4",
    "maintainer": "Juliane Manitz <r@manitz.org>",
    "author": "Juliane Manitz [aut,cre], Mark Hempelmann [ctb], Goeran Kauermann [ctb], Helmut Kuechenhoff [aut],  Shuai Shao [ctb], Cornelia Oberhauser [ctb], Nina Westerheide [ctb], Manuel Wiesenfarth [ctb]",
    "url": "https://www.samplingbook.manitz.org",
    "bug_reports": "https://github.com/jmanitz/samplingbook/issues",
    "repository": "https://cran.r-project.org/package=samplingbook",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samplingbook Survey Sampling Procedures Sampling procedures from the book 'Stichproben - Methoden und praktische Umsetzung mit R' by Goeran Kauermann and Helmut Kuechenhoff (2010).  "
  },
  {
    "id": 20088,
    "package_name": "samplingin",
    "title": "Dynamic Survey Sampling Solutions",
    "description": "A robust solution employing the SRS (Simple Random Sampling),\n    systematic and PPS (Probability Proportional to Size) sampling\n    methods, ensuring a methodical and representative selection of data.\n    Seamlessly allocate predetermined allocations to smaller levels.",
    "version": "1.1.1",
    "maintainer": "Choerul Afifanto <choerulafifanto@gmail.com>",
    "author": "Choerul Afifanto [aut, cre, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=samplingin",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "samplingin Dynamic Survey Sampling Solutions A robust solution employing the SRS (Simple Random Sampling),\n    systematic and PPS (Probability Proportional to Size) sampling\n    methods, ensuring a methodical and representative selection of data.\n    Seamlessly allocate predetermined allocations to smaller levels.  "
  },
  {
    "id": 20114,
    "package_name": "saros",
    "title": "Semi-Automatic Reporting of Ordinary Surveys",
    "description": "Offers a systematic way for conditional reporting of figures and tables for many\n    (and bivariate combinations of) variables, typically from survey data.\n    Contains interactive 'ggiraph'-based \n    (<https://CRAN.R-project.org/package=ggiraph>) plotting functions and\n    data frame-based summary tables (bivariate significance tests, \n    frequencies/proportions, unique open ended responses, etc) with\n    many arguments for customization, and extensions possible. Uses a global \n    options() system for neatly reducing redundant code.\n    Also contains tools for immediate saving of objects and returning a hashed link to the object,\n    useful for creating download links to high resolution images upon rendering in 'Quarto'. \n    Suitable for highly customized reports, primarily intended for survey\n    research.",
    "version": "1.6.0",
    "maintainer": "Stephan Daus <stephus.daus@gmail.com>",
    "author": "Stephan Daus [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0230-6997>),\n  Julia Silge [ctb] (Author of internal scale_x_reordered),\n  David Robinson [ctb] (Author of internal scale_x_reordered),\n  Nordic Institute for The Studies of Innovation, Research and Education\n    (NIFU) [fnd],\n  Kristiania University College [fnd]",
    "url": "https://nifu-no.github.io/saros/, https://github.com/NIFU-NO/saros",
    "bug_reports": "https://github.com/NIFU-NO/saros/issues",
    "repository": "https://cran.r-project.org/package=saros",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "saros Semi-Automatic Reporting of Ordinary Surveys Offers a systematic way for conditional reporting of figures and tables for many\n    (and bivariate combinations of) variables, typically from survey data.\n    Contains interactive 'ggiraph'-based \n    (<https://CRAN.R-project.org/package=ggiraph>) plotting functions and\n    data frame-based summary tables (bivariate significance tests, \n    frequencies/proportions, unique open ended responses, etc) with\n    many arguments for customization, and extensions possible. Uses a global \n    options() system for neatly reducing redundant code.\n    Also contains tools for immediate saving of objects and returning a hashed link to the object,\n    useful for creating download links to high resolution images upon rendering in 'Quarto'. \n    Suitable for highly customized reports, primarily intended for survey\n    research.  "
  },
  {
    "id": 20115,
    "package_name": "saros.base",
    "title": "Base Tools for Semi-Automatic Reporting of Ordinary Surveys",
    "description": "Scaffold an entire web-based report using template chunks, based on a small chapter overview and a dataset. \n    Highly adaptable with prefixes, suffixes, translations, etc. Also contains tools for password-protecting,\n    e.g. for each organization's report on a website. Developed for the common case of a survey across multiple organizations/sites\n    where each organization wants to obtain results for their organization compared with everyone else.\n    See 'saros' (<https://CRAN.R-project.org/package=saros>) for tools used for authors in the drafted reports.",
    "version": "1.2.0",
    "maintainer": "Stephan Daus <stephus.daus@gmail.com>",
    "author": "Stephan Daus [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-0230-6997>),\n  Nordic Institute for The Studies of Innovation, Research and Education\n    (NIFU) [fnd],\n  Kristiania University College [fnd]",
    "url": "https://nifu-no.github.io/saros.base/,\nhttps://github.com/NIFU-NO/saros.base",
    "bug_reports": "https://github.com/NIFU-NO/saros.base/issues",
    "repository": "https://cran.r-project.org/package=saros.base",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "saros.base Base Tools for Semi-Automatic Reporting of Ordinary Surveys Scaffold an entire web-based report using template chunks, based on a small chapter overview and a dataset. \n    Highly adaptable with prefixes, suffixes, translations, etc. Also contains tools for password-protecting,\n    e.g. for each organization's report on a website. Developed for the common case of a survey across multiple organizations/sites\n    where each organization wants to obtain results for their organization compared with everyone else.\n    See 'saros' (<https://CRAN.R-project.org/package=saros>) for tools used for authors in the drafted reports.  "
  },
  {
    "id": 20116,
    "package_name": "sarp.snowprofile",
    "title": "Snow Profile Analysis for Snowpack and Avalanche Research",
    "description": "Analysis and plotting tools for snow profile data produced from manual snowpack \n  observations and physical snowpack models. The functions in this package support snowpack \n  and avalanche research by reading various formats of data (including CAAML, SMET,\n  generic csv, and outputs from the snow cover model SNOWPACK), manipulate the data, and \n  produce graphics such as stratigraphy and time series profiles. Package developed by \n  the Simon Fraser University Avalanche Research Program <http://www.avalancheresearch.ca>. \n  Graphics apply visualization concepts from Horton, Nowak, and Haegeli (2020, \n  <doi:10.5194/nhess-20-1557-2020>).",
    "version": "1.3.2",
    "maintainer": "Pascal Haegeli <pascal_haegeli@sfu.ca>",
    "author": "Pascal Haegeli [aut, cre],\n  Simon Horton [aut],\n  Florian Herla [aut],\n  SFU Avalanche Research Program [fnd]",
    "url": "http://www.avalancheresearch.ca",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sarp.snowprofile",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sarp.snowprofile Snow Profile Analysis for Snowpack and Avalanche Research Analysis and plotting tools for snow profile data produced from manual snowpack \n  observations and physical snowpack models. The functions in this package support snowpack \n  and avalanche research by reading various formats of data (including CAAML, SMET,\n  generic csv, and outputs from the snow cover model SNOWPACK), manipulate the data, and \n  produce graphics such as stratigraphy and time series profiles. Package developed by \n  the Simon Fraser University Avalanche Research Program <http://www.avalancheresearch.ca>. \n  Graphics apply visualization concepts from Horton, Nowak, and Haegeli (2020, \n  <doi:10.5194/nhess-20-1557-2020>).  "
  },
  {
    "id": 20117,
    "package_name": "sarp.snowprofile.alignment",
    "title": "Snow Profile Alignment, Aggregation, and Clustering",
    "description": "Snow profiles describe the vertical (1D) stratigraphy of layered \n    snow with different layer characteristics, such as grain type, hardness, \n    deposition date, and many more. Hence, they represent a data format similar \n    to multivariate time series containing categorical, ordinal, and numerical \n    data types. Use this package to align snow profiles by matching their \n    individual layers based on Dynamic Time Warping (DTW). The aligned profiles \n    can then be assessed with an independent, global similarity measure that is \n    geared towards avalanche hazard assessment. Finally, through exploiting data\n    aggregation and clustering methods, the similarity measure provides the\n    foundation for grouping and summarizing snow profiles according to similar\n    hazard conditions. In particular, this package allows for averaging large\n    numbers of snow profiles with DTW Barycenter Averaging and thereby \n    facilitates the computation of individual layer distributions and summary \n    statistics that are relevant for avalanche forecasting purposes. \n    For more background information refer to Herla, Horton, Mair,\n    and Haegeli (2021) <doi:10.5194/gmd-14-239-2021>, Herla, Mair, and Haegeli \n    (2022) <doi:10.5194/tc-16-3149-2022>, and Horton, Herla, and Haegeli (2024)\n    <doi:10.5194/egusphere-2024-1609>.",
    "version": "2.0.2",
    "maintainer": "Florian Herla <fherla@sfu.ca>",
    "author": "Florian Herla [aut, cre],\n  Pascal Haegeli [aut],\n  Simon Horton [aut],\n  Paul Billecocq [aut],\n  SFU Avalanche Research Program [fnd]",
    "url": "https://avalancheresearch.ca/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sarp.snowprofile.alignment",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sarp.snowprofile.alignment Snow Profile Alignment, Aggregation, and Clustering Snow profiles describe the vertical (1D) stratigraphy of layered \n    snow with different layer characteristics, such as grain type, hardness, \n    deposition date, and many more. Hence, they represent a data format similar \n    to multivariate time series containing categorical, ordinal, and numerical \n    data types. Use this package to align snow profiles by matching their \n    individual layers based on Dynamic Time Warping (DTW). The aligned profiles \n    can then be assessed with an independent, global similarity measure that is \n    geared towards avalanche hazard assessment. Finally, through exploiting data\n    aggregation and clustering methods, the similarity measure provides the\n    foundation for grouping and summarizing snow profiles according to similar\n    hazard conditions. In particular, this package allows for averaging large\n    numbers of snow profiles with DTW Barycenter Averaging and thereby \n    facilitates the computation of individual layer distributions and summary \n    statistics that are relevant for avalanche forecasting purposes. \n    For more background information refer to Herla, Horton, Mair,\n    and Haegeli (2021) <doi:10.5194/gmd-14-239-2021>, Herla, Mair, and Haegeli \n    (2022) <doi:10.5194/tc-16-3149-2022>, and Horton, Herla, and Haegeli (2024)\n    <doi:10.5194/egusphere-2024-1609>.  "
  },
  {
    "id": 20126,
    "package_name": "satellite",
    "title": "Handling and Manipulating Remote Sensing Data",
    "description": "Herein, we provide a broad variety of functions which are useful\n    for handling, manipulating, and visualizing satellite-based remote sensing \n    data. These operations range from mere data import and layer handling (eg \n    subsetting), over Raster* typical data wrangling (eg crop, extend), to more \n    sophisticated (pre-)processing tasks typically applied to satellite imagery \n    (eg atmospheric and topographic correction). This functionality is \n    complemented by a full access to the satellite layers' metadata at any \n    stage and the documentation of performed actions in a separate log file. \n    Currently available sensors include Landsat 4-5 (TM), 7 (ETM+), and 8 \n    (OLI/TIRS Combined), and additional compatibility is ensured for the Landsat \n    Global Land Survey data set. ",
    "version": "1.0.6",
    "maintainer": "Florian Detsch <fdetsch@web.de>",
    "author": "Thomas Nauss [aut],\n  Hanna Meyer [aut],\n  Tim Appelhans [aut],\n  Florian Detsch [aut, cre]",
    "url": "https://github.com/environmentalinformatics-marburg/satellite",
    "bug_reports": "https://github.com/environmentalinformatics-marburg/satellite/issues",
    "repository": "https://cran.r-project.org/package=satellite",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "satellite Handling and Manipulating Remote Sensing Data Herein, we provide a broad variety of functions which are useful\n    for handling, manipulating, and visualizing satellite-based remote sensing \n    data. These operations range from mere data import and layer handling (eg \n    subsetting), over Raster* typical data wrangling (eg crop, extend), to more \n    sophisticated (pre-)processing tasks typically applied to satellite imagery \n    (eg atmospheric and topographic correction). This functionality is \n    complemented by a full access to the satellite layers' metadata at any \n    stage and the documentation of performed actions in a separate log file. \n    Currently available sensors include Landsat 4-5 (TM), 7 (ETM+), and 8 \n    (OLI/TIRS Combined), and additional compatibility is ensured for the Landsat \n    Global Land Survey data set.   "
  },
  {
    "id": 20144,
    "package_name": "sbtools",
    "title": "USGS ScienceBase Tools",
    "description": "Tools for interacting with U.S. Geological Survey ScienceBase\n    <https://www.sciencebase.gov> interfaces. ScienceBase is a data cataloging and\n    collaborative data management platform. Functions included for querying\n    ScienceBase, and creating and fetching datasets.",
    "version": "1.4.1",
    "maintainer": "David Blodgett <dblodgett@usgs.gov>",
    "author": "David Blodgett [cre],\n  Luke Winslow [aut],\n  Scott Chamberlain [ctb],\n  Alison Appling [ctb],\n  Jordan Read [ctb]",
    "url": "https://github.com/DOI-USGS/sbtools,\nhttps://doi-usgs.github.io/sbtools/",
    "bug_reports": "https://github.com/DOI-USGS/sbtools/issues",
    "repository": "https://cran.r-project.org/package=sbtools",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sbtools USGS ScienceBase Tools Tools for interacting with U.S. Geological Survey ScienceBase\n    <https://www.sciencebase.gov> interfaces. ScienceBase is a data cataloging and\n    collaborative data management platform. Functions included for querying\n    ScienceBase, and creating and fetching datasets.  "
  },
  {
    "id": 20146,
    "package_name": "sc2sc",
    "title": "Spatial Transfer of Statistics among Spanish Census Sections",
    "description": "Transfers/imputes statistics among Spanish spatial polygons (census sections or postal code areas) from different moments in time (2001-2023) without need of spatial files, just linking statistics to the ID codes of the spatial units. \n    The data available in the census sections of a partition/division (cartography) into force in a moment of time is transferred to the census sections of another partition/division employing the geometric approach (also known as areal weighting or polygon overlay). \n    References: \n    Goerlich (2022) <doi:10.12842/WPIVIE_0322>.\n    Pav\u00eda and Cantarino (2017a, b) <doi:10.1111/gean.12112>, <doi:10.1016/j.apgeog.2017.06.021>.\n    P\u00e9rez and Pav\u00eda (2024a, b) <doi:10.4995/CARMA2024.2024.17796>, <doi:10.38191/iirr-jorr.24.057>.\n    Acknowledgements:\n    The authors wish to thank Conseller\u00eda de Educaci\u00f3n, Cultura, Universidades y Empleo, Generalitat Valenciana (grant CIACIO/2023/031), Conseller\u00eda de Educaci\u00f3n, Universidades y Empleo, Generalitat Valenciana (grant AICO/2021/257), Ministerio de Econom\u00eda e Innovaci\u00f3n (grant PID2021-128228NB-I00) and Fundaci\u00f3n Mapfre for supporting this research.",
    "version": "0.0.1-18",
    "maintainer": "Jose M. Pav\u00eda <jose.m.pavia@uv.es>",
    "author": "Virgilio P\u00e9rez [aut] (ORCID: <https://orcid.org/0000-0002-7628-2855>),\n  Jose M. Pav\u00eda [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0129-726X>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sc2sc",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sc2sc Spatial Transfer of Statistics among Spanish Census Sections Transfers/imputes statistics among Spanish spatial polygons (census sections or postal code areas) from different moments in time (2001-2023) without need of spatial files, just linking statistics to the ID codes of the spatial units. \n    The data available in the census sections of a partition/division (cartography) into force in a moment of time is transferred to the census sections of another partition/division employing the geometric approach (also known as areal weighting or polygon overlay). \n    References: \n    Goerlich (2022) <doi:10.12842/WPIVIE_0322>.\n    Pav\u00eda and Cantarino (2017a, b) <doi:10.1111/gean.12112>, <doi:10.1016/j.apgeog.2017.06.021>.\n    P\u00e9rez and Pav\u00eda (2024a, b) <doi:10.4995/CARMA2024.2024.17796>, <doi:10.38191/iirr-jorr.24.057>.\n    Acknowledgements:\n    The authors wish to thank Conseller\u00eda de Educaci\u00f3n, Cultura, Universidades y Empleo, Generalitat Valenciana (grant CIACIO/2023/031), Conseller\u00eda de Educaci\u00f3n, Universidades y Empleo, Generalitat Valenciana (grant AICO/2021/257), Ministerio de Econom\u00eda e Innovaci\u00f3n (grant PID2021-128228NB-I00) and Fundaci\u00f3n Mapfre for supporting this research.  "
  },
  {
    "id": 20207,
    "package_name": "scf",
    "title": "Analyzing the Survey of Consumer Finances",
    "description": "Analyze public-use micro data from the Survey of Consumer Finances.\n  Provides tools to download prepared data files, construct replicate-weighted\n  multiply imputed survey designs, compute descriptive statistics and model\n  estimates, and produce plots and tables. Methods follow design-based inference\n  for complex surveys and pooling across multiple imputations. See the package\n  website and the code book for background.",
    "version": "1.0.5",
    "maintainer": "Joseph Cohen <joseph.cohen@qc.cuny.edu>",
    "author": "Joseph Cohen [aut, cre]",
    "url": "https://github.com/jncohen/scf",
    "bug_reports": "https://github.com/jncohen/scf/issues",
    "repository": "https://cran.r-project.org/package=scf",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "scf Analyzing the Survey of Consumer Finances Analyze public-use micro data from the Survey of Consumer Finances.\n  Provides tools to download prepared data files, construct replicate-weighted\n  multiply imputed survey designs, compute descriptive statistics and model\n  estimates, and produce plots and tables. Methods follow design-based inference\n  for complex surveys and pooling across multiple imputations. See the package\n  website and the code book for background.  "
  },
  {
    "id": 20296,
    "package_name": "sdstudio",
    "title": "Companion Application for the 'surveydown' Survey Platform",
    "description": "Companion package that supports the 'surveydown' survey platform (<https://surveydown.org>). The default method for working with a 'surveydown' survey is to edit the plain text 'survey.qmd' and 'app.R' files. With 'sdstudio', you can create, preview and manage surveys with a 'shiny' application as a graphical user interface.",
    "version": "0.1.4",
    "maintainer": "Pingfan Hu <pingfan0727@gmail.com>",
    "author": "Pingfan Hu [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0001-4877-4844>),\n  John Paul Helveston [aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-2657-9191>),\n  Bogdan Bunea [aut, cph] (ORCID:\n    <https://orcid.org/0009-0006-2942-0588>)",
    "url": "https://sdstudio.surveydown.org",
    "bug_reports": "https://github.com/surveydown-dev/sdstudio/issues",
    "repository": "https://cran.r-project.org/package=sdstudio",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sdstudio Companion Application for the 'surveydown' Survey Platform Companion package that supports the 'surveydown' survey platform (<https://surveydown.org>). The default method for working with a 'surveydown' survey is to edit the plain text 'survey.qmd' and 'app.R' files. With 'sdstudio', you can create, preview and manage surveys with a 'shiny' application as a graphical user interface.  "
  },
  {
    "id": 20308,
    "package_name": "seasonal",
    "title": "R Interface to X-13-ARIMA-SEATS",
    "description": "Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment\n    software by the US Census Bureau. It offers full access to almost all\n    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model\n    search, outlier detection and support for user defined holiday variables,\n    such as Chinese New Year or Indian Diwali. A graphical user interface can be\n    used through the 'seasonalview' package. Uses the X-13-binaries from the\n    'x13binary' package.",
    "version": "1.10.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7192-7044>),\n  Dirk Eddelbuettel [ctb] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Andrea Ranzato [ctb]",
    "url": "http://www.seasonal.website",
    "bug_reports": "https://github.com/christophsax/seasonal/issues",
    "repository": "https://cran.r-project.org/package=seasonal",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonal R Interface to X-13-ARIMA-SEATS Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment\n    software by the US Census Bureau. It offers full access to almost all\n    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model\n    search, outlier detection and support for user defined holiday variables,\n    such as Chinese New Year or Indian Diwali. A graphical user interface can be\n    used through the 'seasonalview' package. Uses the X-13-binaries from the\n    'x13binary' package.  "
  },
  {
    "id": 20310,
    "package_name": "seasonalview",
    "title": "Graphical User Interface for Seasonal Adjustment",
    "description": "A graphical user interface to the 'seasonal' package and\n  'X-13ARIMA-SEATS', the U.S. Census Bureau's seasonal adjustment software.",
    "version": "1.0.0",
    "maintainer": "Christoph Sax <christoph.sax@gmail.com>",
    "author": "Christoph Sax [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7192-7044>)",
    "url": "http://www.seasonal.website",
    "bug_reports": "https://github.com/christophsax/seasonalview/issues",
    "repository": "https://cran.r-project.org/package=seasonalview",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "seasonalview Graphical User Interface for Seasonal Adjustment A graphical user interface to the 'seasonal' package and\n  'X-13ARIMA-SEATS', the U.S. Census Bureau's seasonal adjustment software.  "
  },
  {
    "id": 20353,
    "package_name": "selectiongain",
    "title": "A Tool for Calculation and Optimization of the Expected Gain\nfrom Multi-Stage Selection",
    "description": "Multi-stage selection is practiced in numerous fields of life\n    and social sciences and particularly in breeding. A special characteristic of\n    multi-stage selection is that candidates are evaluated in successive stages\n    with increasing intensity and effort, and only a fraction of the superior\n    candidates is selected and promoted to the next stage. For the optimum design\n    of such selection programs, the selection gain plays a crucial role. It can be\n    calculated by integration of a truncated multivariate normal (MVN) distribution.\n    While mathematical formulas for calculating the selection gain and the variance\n    among selected candidates were developed long time ago, solutions for numerical\n    calculation were not available. This package can also be used for optimizing\n    multi-stage selection programs for a given total budget and different costs of\n    evaluating the candidates in each stage.",
    "version": "2.0.710",
    "maintainer": "Xuefei Mi <mi_xue_fei@hotmail.com>",
    "author": "Xuefei Mi, Jose Marulanda, H. Friedrich Utz, Albrecht E. Melchinger\n    (Project contact person: Melchinger@uni-hohenheim.de )",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=selectiongain",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "selectiongain A Tool for Calculation and Optimization of the Expected Gain\nfrom Multi-Stage Selection Multi-stage selection is practiced in numerous fields of life\n    and social sciences and particularly in breeding. A special characteristic of\n    multi-stage selection is that candidates are evaluated in successive stages\n    with increasing intensity and effort, and only a fraction of the superior\n    candidates is selected and promoted to the next stage. For the optimum design\n    of such selection programs, the selection gain plays a crucial role. It can be\n    calculated by integration of a truncated multivariate normal (MVN) distribution.\n    While mathematical formulas for calculating the selection gain and the variance\n    among selected candidates were developed long time ago, solutions for numerical\n    calculation were not available. This package can also be used for optimizing\n    multi-stage selection programs for a given total budget and different costs of\n    evaluating the candidates in each stage.  "
  },
  {
    "id": 20399,
    "package_name": "senseweight",
    "title": "Sensitivity Analysis for Weighted Estimators",
    "description": "Provides tools to conduct interpretable sensitivity analyses for weighted estimators,\n    introduced in Huang (2024) <doi:10.1093/jrsssa/qnae012> and \n    Hartman and Huang (2024) <doi:10.1017/pan.2023.12>. \n    The package allows researchers to generate the set of recommended sensitivity summaries\n    to evaluate the sensitivity in their underlying weighting estimators to omitted moderators or confounders. \n    The tools can be flexibly applied in causal inference settings (i.e., in external and internal validity contexts)\n    or survey contexts. ",
    "version": "0.0.1",
    "maintainer": "Melody Huang <melody.huang@yale.edu>",
    "author": "Melody Huang [aut, cre]",
    "url": "https://melodyyhuang.github.io/senseweight/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=senseweight",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "senseweight Sensitivity Analysis for Weighted Estimators Provides tools to conduct interpretable sensitivity analyses for weighted estimators,\n    introduced in Huang (2024) <doi:10.1093/jrsssa/qnae012> and \n    Hartman and Huang (2024) <doi:10.1017/pan.2023.12>. \n    The package allows researchers to generate the set of recommended sensitivity summaries\n    to evaluate the sensitivity in their underlying weighting estimators to omitted moderators or confounders. \n    The tools can be flexibly applied in causal inference settings (i.e., in external and internal validity contexts)\n    or survey contexts.   "
  },
  {
    "id": 20422,
    "package_name": "sepkoski",
    "title": "Sepkoski's Fossil Marine Animal Genera Compendium",
    "description": "Stratigraphic ranges of fossil marine animal genera from Sepkoski's\n    (2002) published compendium. No changes have been made to any taxonomic \n    names. However, first and last appearance intervals have been updated to be\n    consistent with stages of the International Geological Timescale. \n    Functionality for generating a plot of Sepkoski's evolutionary fauna is also\n    included. For specific details on the compendium see:\n    Sepkoski, J. J. (2002). A compendium of fossil marine animal genera.\n    Bulletins of American Paleontology, 363, pp. 1\u2013560 (ISBN 0-87710-450-6).\n    Access: <https://www.biodiversitylibrary.org/item/40634#page/5/mode/1up>.",
    "version": "0.0.1",
    "maintainer": "Lewis A. Jones <LewisA.Jones@outlook.com>",
    "author": "Lewis A. Jones [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3902-8986>)",
    "url": "https://github.com/LewisAJones/sepkoski",
    "bug_reports": "https://github.com/LewisAJones/sepkoski/issues",
    "repository": "https://cran.r-project.org/package=sepkoski",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sepkoski Sepkoski's Fossil Marine Animal Genera Compendium Stratigraphic ranges of fossil marine animal genera from Sepkoski's\n    (2002) published compendium. No changes have been made to any taxonomic \n    names. However, first and last appearance intervals have been updated to be\n    consistent with stages of the International Geological Timescale. \n    Functionality for generating a plot of Sepkoski's evolutionary fauna is also\n    included. For specific details on the compendium see:\n    Sepkoski, J. J. (2002). A compendium of fossil marine animal genera.\n    Bulletins of American Paleontology, 363, pp. 1\u2013560 (ISBN 0-87710-450-6).\n    Access: <https://www.biodiversitylibrary.org/item/40634#page/5/mode/1up>.  "
  },
  {
    "id": 20444,
    "package_name": "serosv",
    "title": "Model Infectious Disease Parameters from Serosurveys",
    "description": "An easy-to-use and efficient tool to estimate infectious diseases parameters using serological data. Implemented models include SIR models (basic_sir_model(), static_sir_model(), mseir_model(), sir_subpops_model()), parametric models (polynomial_model(), fp_model()), nonparametric models (lp_model()), semiparametric models (penalized_splines_model()), hierarchical models (hierarchical_bayesian_model()).\n  The package is based on the book \"Modeling Infectious Disease Parameters Based on Serological and Social Contact Data: A Modern Statistical Perspective\" (Hens, Niel & Shkedy, Ziv & Aerts, Marc & Faes, Christel & Damme, Pierre & Beutels, Philippe., 2013) <doi:10.1007/978-1-4614-4072-7>. ",
    "version": "1.1.0",
    "maintainer": "Anh Phan Truong Quynh <anhptq@oucru.org>",
    "author": "Anh Phan Truong Quynh [aut, cre],\n  Nguyen Pham Nguyen The [aut],\n  Long Bui Thanh [aut],\n  Tuyen Huynh [aut],\n  Thinh Ong [aut] (ORCID: <https://orcid.org/0000-0001-6772-9291>),\n  Marc Choisy [aut] (ORCID: <https://orcid.org/0000-0002-5187-6390>)",
    "url": "https://oucru-modelling.github.io/serosv/,\nhttps://github.com/OUCRU-Modelling/serosv",
    "bug_reports": "https://github.com/OUCRU-Modelling/serosv/issues",
    "repository": "https://cran.r-project.org/package=serosv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "serosv Model Infectious Disease Parameters from Serosurveys An easy-to-use and efficient tool to estimate infectious diseases parameters using serological data. Implemented models include SIR models (basic_sir_model(), static_sir_model(), mseir_model(), sir_subpops_model()), parametric models (polynomial_model(), fp_model()), nonparametric models (lp_model()), semiparametric models (penalized_splines_model()), hierarchical models (hierarchical_bayesian_model()).\n  The package is based on the book \"Modeling Infectious Disease Parameters Based on Serological and Social Contact Data: A Modern Statistical Perspective\" (Hens, Niel & Shkedy, Ziv & Aerts, Marc & Faes, Christel & Damme, Pierre & Beutels, Philippe., 2013) <doi:10.1007/978-1-4614-4072-7>.   "
  },
  {
    "id": 20477,
    "package_name": "sfnetworks",
    "title": "Tidy Geospatial Networks",
    "description": "Provides a tidy approach to spatial network\n    analysis, in the form of classes and functions that enable a seamless\n    interaction between the network analysis package 'tidygraph' and the\n    spatial analysis package 'sf'.",
    "version": "0.6.5",
    "maintainer": "Lucas van der Meer <luukvandermeer@live.nl>",
    "author": "Lucas van der Meer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6336-8628>),\n  Lorena Abad [aut] (ORCID: <https://orcid.org/0000-0003-0554-734X>),\n  Andrea Gilardi [aut] (ORCID: <https://orcid.org/0000-0002-9424-7439>),\n  Robin Lovelace [aut] (ORCID: <https://orcid.org/0000-0001-5679-6536>)",
    "url": "https://luukvdmeer.github.io/sfnetworks/,\nhttps://github.com/luukvdmeer/sfnetworks",
    "bug_reports": "https://github.com/luukvdmeer/sfnetworks/issues/",
    "repository": "https://cran.r-project.org/package=sfnetworks",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sfnetworks Tidy Geospatial Networks Provides a tidy approach to spatial network\n    analysis, in the form of classes and functions that enable a seamless\n    interaction between the network analysis package 'tidygraph' and the\n    spatial analysis package 'sf'.  "
  },
  {
    "id": 20494,
    "package_name": "sgo",
    "title": "Simple Geographical Operations (with OSGB36)",
    "description": "Methods focused in performing the OSGB36/ETRS89 transformation \n  (Great Britain and the Isle of Man only) by using the Ordnance Survey's \n  OSTN15/OSGM15 transformation model. Calculation of distances and areas from \n  sets of points defined in any of the supported Coordinated Systems is also\n  available.",
    "version": "0.9.2",
    "maintainer": "Carlos Lozano Ruiz <carloslozanoruiz@outlook.com>",
    "author": "Carlos Lozano Ruiz [aut, cre]",
    "url": "https://github.com/clozanoruiz/sgo",
    "bug_reports": "https://github.com/clozanoruiz/sgo/issues",
    "repository": "https://cran.r-project.org/package=sgo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sgo Simple Geographical Operations (with OSGB36) Methods focused in performing the OSGB36/ETRS89 transformation \n  (Great Britain and the Isle of Man only) by using the Ordnance Survey's \n  OSTN15/OSGM15 transformation model. Calculation of distances and areas from \n  sets of points defined in any of the supported Coordinated Systems is also\n  available.  "
  },
  {
    "id": 20500,
    "package_name": "sgraph",
    "title": "Network Visualization Using 'sigma.js'",
    "description": "Interactive visualizations of graphs created with the 'igraph' package using a 'htmlwidgets' wrapper for the 'sigma.js' network visualization v2.4.0 <https://www.sigmajs.org/>, enabling to display several thousands of nodes. While several 'R' packages have been developed to interface 'sigma.js', all were developed for v1.x.x and none have migrated to v2.4.0 nor are they planning to. This package builds upon the 'sigmaNet' package, and users familiar with it will recognize the similar design approach. Two extensions have been added to the classic 'sigma.js' visualizations by overriding the underlying 'JavaScript' code, enabling to draw a frame around node labels, and to display labels on multiple lines by parsing line breaks. Other additional functionalities that did not require overriding 'sigma.js' code include toggling node visibility when clicked using a node attribute and highlighting specific edges. 'sigma.js' is currently preparing a stable release v3.0.0, and this package plans to update to it when it is available.",
    "version": "1.1.0",
    "maintainer": "Thomas Charlon <charlon@protonmail.com>",
    "author": "Thomas Charlon [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7497-0470>),\n  CELEHS [aut] (<https://celehs.hms.harvard.edu>),\n  PARSE Health [aut] (<https://parse-health.org>)",
    "url": "https://gitlab.com/thomaschln/sgraph",
    "bug_reports": "https://gitlab.com/thomaschln/sgraph/-/issues",
    "repository": "https://cran.r-project.org/package=sgraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sgraph Network Visualization Using 'sigma.js' Interactive visualizations of graphs created with the 'igraph' package using a 'htmlwidgets' wrapper for the 'sigma.js' network visualization v2.4.0 <https://www.sigmajs.org/>, enabling to display several thousands of nodes. While several 'R' packages have been developed to interface 'sigma.js', all were developed for v1.x.x and none have migrated to v2.4.0 nor are they planning to. This package builds upon the 'sigmaNet' package, and users familiar with it will recognize the similar design approach. Two extensions have been added to the classic 'sigma.js' visualizations by overriding the underlying 'JavaScript' code, enabling to draw a frame around node labels, and to display labels on multiple lines by parsing line breaks. Other additional functionalities that did not require overriding 'sigma.js' code include toggling node visibility when clicked using a node attribute and highlighting specific edges. 'sigma.js' is currently preparing a stable release v3.0.0, and this package plans to update to it when it is available.  "
  },
  {
    "id": 20524,
    "package_name": "sharpshootR",
    "title": "A Soil Survey Toolkit",
    "description": "A collection of data processing, visualization, and export functions to support soil survey operations. Many of the functions build on the `SoilProfileCollection` S4 class provided by the aqp package, extending baseline visualization to more elaborate depictions in the context of spatial and taxonomic data. While this package is primarily developed by and for the USDA-NRCS, in support of the National Cooperative Soil Survey, the authors strive for generalization sufficient to support any soil survey operation. Many of the included functions are used by the SoilWeb suite of websites and movile applications. These functions are provided here, with additional documentation, to enable others to replicate high quality versions of these figures for their own purposes.",
    "version": "2.4",
    "maintainer": "Dylan Beaudette <dylan.beaudette@usda.gov>",
    "author": "Dylan Beaudette [cre, aut],\n  Jay Skovlin [aut],\n  Stephen Roecker [aut],\n  Andrew Brown [aut],\n  USDA-NRCS Soil Survey Staff [ctb]",
    "url": "https://github.com/ncss-tech/sharpshootR",
    "bug_reports": "https://github.com/ncss-tech/sharpshootR/issues",
    "repository": "https://cran.r-project.org/package=sharpshootR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sharpshootR A Soil Survey Toolkit A collection of data processing, visualization, and export functions to support soil survey operations. Many of the functions build on the `SoilProfileCollection` S4 class provided by the aqp package, extending baseline visualization to more elaborate depictions in the context of spatial and taxonomic data. While this package is primarily developed by and for the USDA-NRCS, in support of the National Cooperative Soil Survey, the authors strive for generalization sufficient to support any soil survey operation. Many of the included functions are used by the SoilWeb suite of websites and movile applications. These functions are provided here, with additional documentation, to enable others to replicate high quality versions of these figures for their own purposes.  "
  },
  {
    "id": 20628,
    "package_name": "shinymrp",
    "title": "Interface for Multilevel Regression and Poststratification",
    "description": "Dual interfaces, graphical and programmatic, designed for\n    intuitive applications of Multilevel Regression and Poststratification (MRP).\n    Users can apply the method to a variety of datasets, from electronic health records\n    to sample survey data, through an end-to-end Bayesian data analysis workflow.\n    The package provides robust tools for data cleaning, exploratory analysis,\n    flexible model building, and insightful result visualization. For more details, see\n    Si et al. (2020) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2020002/article/00003-eng.pdf?st=iF1_Fbrh>\n    and Si (2025) <doi:10.1214/24-STS932>.",
    "version": "0.10.0",
    "maintainer": "Toan Tran <trannttoan97@gmail.com>",
    "author": "Toan Tran [cre, aut, cph],\n  Jonah Gabry [aut, cph],\n  Yajuan Si [aut, cph]",
    "url": "https://mrp-interface.github.io/shinymrp/",
    "bug_reports": "https://github.com/mrp-interface/shinymrp/issues",
    "repository": "https://cran.r-project.org/package=shinymrp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shinymrp Interface for Multilevel Regression and Poststratification Dual interfaces, graphical and programmatic, designed for\n    intuitive applications of Multilevel Regression and Poststratification (MRP).\n    Users can apply the method to a variety of datasets, from electronic health records\n    to sample survey data, through an end-to-end Bayesian data analysis workflow.\n    The package provides robust tools for data cleaning, exploratory analysis,\n    flexible model building, and insightful result visualization. For more details, see\n    Si et al. (2020) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2020002/article/00003-eng.pdf?st=iF1_Fbrh>\n    and Si (2025) <doi:10.1214/24-STS932>.  "
  },
  {
    "id": 20655,
    "package_name": "shp2graph",
    "title": "Convert a 'SpatialLinesDataFrame' -Class Object to an\n'igraph'-Class Object",
    "description": "Functions for converting and processing network data from a\n        'SpatialLinesDataFrame' -Class object to an 'igraph'-Class object.",
    "version": "1-0",
    "maintainer": "Binbin Lu <binbinlu@whu.edu.cn>",
    "author": "Binbin Lu",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=shp2graph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "shp2graph Convert a 'SpatialLinesDataFrame' -Class Object to an\n'igraph'-Class Object Functions for converting and processing network data from a\n        'SpatialLinesDataFrame' -Class object to an 'igraph'-Class object.  "
  },
  {
    "id": 20713,
    "package_name": "simPop",
    "title": "Simulation of Complex Synthetic Data Information",
    "description": "Tools and methods to simulate populations for surveys based\n    on auxiliary data. The tools include model-based methods, calibration and\n    combinatorial optimization algorithms, see Templ, Kowarik and Meindl (2017) <doi:10.18637/jss.v079.i10>) and\n    Templ (2017) <doi:10.1007/978-3-319-50272-4>. The package was developed with support of\n    the International Household Survey Network, DFID Trust Fund TF011722 and funds\n    from the World bank.",
    "version": "2.1.3",
    "maintainer": "Matthias Templ <matthias.templ@gmail.com>",
    "author": "Matthias Templ [aut, cre],\n  Alexander Kowarik [aut] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>),\n  Bernhard Meindl [aut],\n  Andreas Alfons [aut],\n  Mathieu Ribatet [ctb],\n  Johannes Gussenbauer [ctb],\n  Siro Fritzmann [ctb]",
    "url": "https://github.com/statistikat/simPop",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=simPop",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "simPop Simulation of Complex Synthetic Data Information Tools and methods to simulate populations for surveys based\n    on auxiliary data. The tools include model-based methods, calibration and\n    combinatorial optimization algorithms, see Templ, Kowarik and Meindl (2017) <doi:10.18637/jss.v079.i10>) and\n    Templ (2017) <doi:10.1007/978-3-319-50272-4>. The package was developed with support of\n    the International Household Survey Network, DFID Trust Fund TF011722 and funds\n    from the World bank.  "
  },
  {
    "id": 20817,
    "package_name": "sjPlot",
    "title": "Data Visualization for Statistics in Social Science",
    "description": "Collection of plotting and table output functions for data\n    visualization. Results of various statistical analyses (that are commonly used\n    in social sciences) can be visualized using this package, including simple and\n    cross tabulated frequencies, histograms, box plots, (generalized) linear models,\n    mixed effects models, principal component analysis and correlation matrices,\n    cluster analyses, scatter plots, stacked scales, effects plots of regression\n    models (including interaction terms) and much more. This package supports\n    labelled data.",
    "version": "2.9.0",
    "maintainer": "Daniel L\u00fcdecke <d.luedecke@uke.de>",
    "author": "Daniel L\u00fcdecke [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-8895-3206>),\n  Alexander Bartel [ctb] (ORCID: <https://orcid.org/0000-0002-1280-6138>),\n  Carsten Schwemmer [ctb],\n  Chuck Powell [ctb] (ORCID: <https://orcid.org/0000-0002-3606-2188>),\n  Amir Djalovski [ctb],\n  Johannes Titz [ctb] (ORCID: <https://orcid.org/0000-0002-1102-5719>)",
    "url": "https://strengejacke.github.io/sjPlot/",
    "bug_reports": "https://github.com/strengejacke/sjPlot/issues",
    "repository": "https://cran.r-project.org/package=sjPlot",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sjPlot Data Visualization for Statistics in Social Science Collection of plotting and table output functions for data\n    visualization. Results of various statistical analyses (that are commonly used\n    in social sciences) can be visualized using this package, including simple and\n    cross tabulated frequencies, histograms, box plots, (generalized) linear models,\n    mixed effects models, principal component analysis and correlation matrices,\n    cluster analyses, scatter plots, stacked scales, effects plots of regression\n    models (including interaction terms) and much more. This package supports\n    labelled data.  "
  },
  {
    "id": 20897,
    "package_name": "smicd",
    "title": "Statistical Methods for Interval-Censored Data",
    "description": "Functions that provide statistical methods for interval-censored (grouped) data. The package supports the estimation of linear and linear mixed regression models with interval-censored dependent variables. Parameter estimates are obtained by a stochastic expectation maximization algorithm. Furthermore, the package enables the direct (without covariates) estimation of statistical indicators from interval-censored data via an iterative kernel density algorithm. Survey and Organisation for Economic Co-operation and Development (OECD) weights can be included into the direct estimation (see, Walter, P. (2019) <doi:10.17169/refubium-1621>).",
    "version": "1.1.5",
    "maintainer": "Paul Walter <paul.w@gmx.net>",
    "author": "Paul Walter",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=smicd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smicd Statistical Methods for Interval-Censored Data Functions that provide statistical methods for interval-censored (grouped) data. The package supports the estimation of linear and linear mixed regression models with interval-censored dependent variables. Parameter estimates are obtained by a stochastic expectation maximization algorithm. Furthermore, the package enables the direct (without covariates) estimation of statistical indicators from interval-censored data via an iterative kernel density algorithm. Survey and Organisation for Economic Co-operation and Development (OECD) weights can be included into the direct estimation (see, Walter, P. (2019) <doi:10.17169/refubium-1621>).  "
  },
  {
    "id": 20926,
    "package_name": "sms",
    "title": "Spatial Microsimulation",
    "description": "Produce small area population estimates by fitting census data to\n    survey data.",
    "version": "2.3.1",
    "maintainer": "Dimitris Kavroudakis <dimitris123@gmail.com>",
    "author": "Dimitris Kavroudakis <dimitris123@gmail.com>",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sms",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sms Spatial Microsimulation Produce small area population estimates by fitting census data to\n    survey data.  "
  },
  {
    "id": 20928,
    "package_name": "smss",
    "title": "Datasets for Agresti and Finlay's \"Statistical Methods for the\nSocial Sciences\"",
    "description": "Datasets used in \"Statistical Methods for the Social Sciences\"\n    (SMSS) by Alan Agresti and Barbara Finlay.",
    "version": "1.0-2",
    "maintainer": "Jeffrey B. Arnold <jeffrey.arnold@gmail.com>",
    "author": "Jeffrey B. Arnold [aut, cre],\n  Alan Agresti [cph],\n  Barbara Finlay [cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=smss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "smss Datasets for Agresti and Finlay's \"Statistical Methods for the\nSocial Sciences\" Datasets used in \"Statistical Methods for the Social Sciences\"\n    (SMSS) by Alan Agresti and Barbara Finlay.  "
  },
  {
    "id": 20935,
    "package_name": "sna",
    "title": "Tools for Social Network Analysis",
    "description": "A range of tools for social network analysis, including node and graph-level indices, structural distance and covariance methods, structural equivalence detection, network regression, random graph generation, and 2D/3D network visualization.",
    "version": "2.8",
    "maintainer": "Carter T. Butts <buttsc@uci.edu>",
    "author": "Carter T. Butts [aut, cre, cph]",
    "url": "https://statnet.org",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sna",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sna Tools for Social Network Analysis A range of tools for social network analysis, including node and graph-level indices, structural distance and covariance methods, structural equivalence detection, network regression, random graph generation, and 2D/3D network visualization.  "
  },
  {
    "id": 20936,
    "package_name": "snahelper",
    "title": "'RStudio' Addin for Network Analysis and Visualization",
    "description": "'RStudio' addin which provides a GUI to visualize and analyse networks. \n    After finishing a session, the code to produce the plot is inserted in the current script.\n    Alternatively, the function SNAhelperGadget() can be used directly from the console.\n    Additional addins include the Netreader() for reading network files, Netbuilder() to create\n    small networks via point and click, and the Componentlayouter() to layout networks with many components manually.",
    "version": "1.4.2",
    "maintainer": "David Schoch <david@schochastics.net>",
    "author": "David Schoch [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-2952-4812>)",
    "url": "https://github.com/schochastics/snahelper,\nhttps://schochastics.github.io/snahelper/",
    "bug_reports": "https://github.com/schochastics/snahelper/issues",
    "repository": "https://cran.r-project.org/package=snahelper",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "snahelper 'RStudio' Addin for Network Analysis and Visualization 'RStudio' addin which provides a GUI to visualize and analyse networks. \n    After finishing a session, the code to produce the plot is inserted in the current script.\n    Alternatively, the function SNAhelperGadget() can be used directly from the console.\n    Additional addins include the Netreader() for reading network files, Netbuilder() to create\n    small networks via point and click, and the Componentlayouter() to layout networks with many components manually.  "
  },
  {
    "id": 20948,
    "package_name": "snotelr",
    "title": "Calculate and Visualize 'SNOTEL' Snow Data and Seasonality",
    "description": "Programmatic interface to the 'SNOTEL' snow data\n  (<https://www.nrcs.usda.gov/programs-initiatives/sswsf-snow-survey-and-water-supply-forecasting-program>). Provides easy downloads of snow \n  data into your R work space or a local directory. Additional post-processing \n  routines to extract snow season indexes are provided.",
    "version": "1.5.2",
    "maintainer": "Koen Hufkens <koen.hufkens@gmail.com>",
    "author": "Koen Hufkens [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-5070-8109>),\n  BlueGreen Labs [cph, fnd]",
    "url": "https://github.com/bluegreen-labs/snotelr,\nhttps://bluegreen-labs.github.io/snotelr/",
    "bug_reports": "https://github.com/bluegreen-labs/snotelr/issues",
    "repository": "https://cran.r-project.org/package=snotelr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "snotelr Calculate and Visualize 'SNOTEL' Snow Data and Seasonality Programmatic interface to the 'SNOTEL' snow data\n  (<https://www.nrcs.usda.gov/programs-initiatives/sswsf-snow-survey-and-water-supply-forecasting-program>). Provides easy downloads of snow \n  data into your R work space or a local directory. Additional post-processing \n  routines to extract snow season indexes are provided.  "
  },
  {
    "id": 20963,
    "package_name": "soc.ca",
    "title": "Specific Correspondence Analysis for the Social Sciences",
    "description": "Specific and class specific multiple correspondence analysis on\n    survey-like data. Soc.ca is optimized to the needs of the social scientist and\n    presents easily interpretable results in near publication ready quality.",
    "version": "0.8.1",
    "maintainer": "Anton Grau Larsen <agraul@ruc.dk>",
    "author": "Anton Grau Larsen [aut, cre],\n  Jacob Lunding [aut],\n  Stefan Andrade [aut]",
    "url": "https://github.com/Rsoc/soc.ca",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=soc.ca",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "soc.ca Specific Correspondence Analysis for the Social Sciences Specific and class specific multiple correspondence analysis on\n    survey-like data. Soc.ca is optimized to the needs of the social scientist and\n    presents easily interpretable results in near publication ready quality.  "
  },
  {
    "id": 20975,
    "package_name": "soilDB",
    "title": "Soil Database Interface",
    "description": "A collection of functions for reading soil data from U.S. Department of Agriculture Natural Resources Conservation Service (USDA-NRCS) and National Cooperative Soil Survey (NCSS) databases.",
    "version": "2.8.13",
    "maintainer": "Andrew Brown <andrew.g.brown@usda.gov>",
    "author": "Dylan Beaudette [aut] (ORCID: <https://orcid.org/0009-0008-2780-4785>),\n  Jay Skovlin [aut],\n  Stephen Roecker [aut],\n  Andrew Brown [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4565-533X>)",
    "url": "https://github.com/ncss-tech/soilDB/,\nhttps://ncss-tech.github.io/soilDB/,\nhttps://ncss-tech.github.io/AQP/",
    "bug_reports": "https://github.com/ncss-tech/soilDB/issues",
    "repository": "https://cran.r-project.org/package=soilDB",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "soilDB Soil Database Interface A collection of functions for reading soil data from U.S. Department of Agriculture Natural Resources Conservation Service (USDA-NRCS) and National Cooperative Soil Survey (NCSS) databases.  "
  },
  {
    "id": 21081,
    "package_name": "sparseGFM",
    "title": "Sparse Generalized Factor Models with Multiple Penalty Functions",
    "description": "Implements sparse generalized factor models (sparseGFM) for dimension reduction\n    and variable selection in high-dimensional data with automatic adaptation to weak factor\n    scenarios. The package supports multiple data types (continuous, count, binary) through\n    generalized linear model frameworks and handles missing values automatically. It provides\n    12 different penalty functions including Least Absolute Shrinkage and Selection Operator (Lasso),\n    adaptive Lasso, Smoothly Clipped Absolute Deviation (SCAD), Minimax Concave Penalty (MCP), group Lasso,\n    and their adaptive versions for inducing row-wise sparsity in factor loadings. Key features\n    include cross-validation for regularization parameter selection using Sparsity Information\n    Criterion (SIC), automatic determination of the number of factors via multiple information\n    criteria, and specialized algorithms for row-sparse loading structures. The methodology\n    employs alternating minimization with Singular Value Decomposition (SVD)-based identifiability\n    constraints and is particularly effective for high-dimensional applications in genomics, economics,\n    and social sciences where interpretable sparse dimension reduction is crucial.\n    For penalty functions, see Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x>,\n    Fan and Li (2001) <doi:10.1198/016214501753382273>, and Zhang (2010) <doi:10.1214/09-AOS729>.",
    "version": "0.1.0",
    "maintainer": "Zhijing Wang <wangzhijing@sjtu.edu.cn>",
    "author": "Zhijing Wang [aut, cre]",
    "url": "https://github.com/zjwang1013/sparseGFM",
    "bug_reports": "https://github.com/zjwang1013/sparseGFM/issues",
    "repository": "https://cran.r-project.org/package=sparseGFM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sparseGFM Sparse Generalized Factor Models with Multiple Penalty Functions Implements sparse generalized factor models (sparseGFM) for dimension reduction\n    and variable selection in high-dimensional data with automatic adaptation to weak factor\n    scenarios. The package supports multiple data types (continuous, count, binary) through\n    generalized linear model frameworks and handles missing values automatically. It provides\n    12 different penalty functions including Least Absolute Shrinkage and Selection Operator (Lasso),\n    adaptive Lasso, Smoothly Clipped Absolute Deviation (SCAD), Minimax Concave Penalty (MCP), group Lasso,\n    and their adaptive versions for inducing row-wise sparsity in factor loadings. Key features\n    include cross-validation for regularization parameter selection using Sparsity Information\n    Criterion (SIC), automatic determination of the number of factors via multiple information\n    criteria, and specialized algorithms for row-sparse loading structures. The methodology\n    employs alternating minimization with Singular Value Decomposition (SVD)-based identifiability\n    constraints and is particularly effective for high-dimensional applications in genomics, economics,\n    and social sciences where interpretable sparse dimension reduction is crucial.\n    For penalty functions, see Tibshirani (1996) <doi:10.1111/j.2517-6161.1996.tb02080.x>,\n    Fan and Li (2001) <doi:10.1198/016214501753382273>, and Zhang (2010) <doi:10.1214/09-AOS729>.  "
  },
  {
    "id": 21156,
    "package_name": "speakeasyR",
    "title": "Fast and Robust Multi-Scale Graph Clustering",
    "description": "A graph community detection algorithm that aims to be performant\n    on large graphs and robust, returning consistent results across runs.\n    SpeakEasy 2 (SE2), the underlying algorithm, is described in Chris Gaiteri,\n    David R. Connell & Faraz A. Sultan et al. (2023)\n    <doi:10.1186/s13059-023-03062-0>. The core algorithm is written in 'C',\n    providing speed and keeping the memory requirements low. This implementation\n    can take advantage of multiple computing cores without increasing memory\n    usage. SE2 can detect community structure across scales, making it a good\n    choice for biological data, which often has hierarchical structure. Graphs\n    can be passed to the algorithm as adjacency matrices using base 'R'\n    matrices, the 'Matrix' library, 'igraph' graphs, or any data that can be\n    coerced into a matrix.",
    "version": "0.1.8",
    "maintainer": "David Connell <david32@dcon.addy.io>",
    "author": "David Connell [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-4841-6756>),\n  Chris Gaiteri [cph] (Author of original SpeakEasy 2 algorithm.),\n  G\u00e1bor Cs\u00e1rdi [cph, ctb] (Author of igraph C library.),\n  Tam\u00e1s Nepusz [cph, ctb] (Author of igraph C library.),\n  Szabolcs Horv\u00e1t [cph, ctb] (Author of igraph C library.),\n  Vincent Traag [cph, ctb] (Author of igraph C library.),\n  Fabio Zanini [cph, ctb] (Author of igraph C library.),\n  Daniel Noom [cph, ctb] (Author of igraph C library.),\n  The igraph development team [cph] (Copyright holder of igraph C\n    library.),\n  Free Software Foundation, Inc. [cph] (Copyright holder of GPL\n    licenses.),\n  Ross Ihaka [cph, ctb] (Author of Mathlib.),\n  The R Development Core Team [cph] (Copyright holder of Mathlib.),\n  Royal Statistical Society [cph] (Copyright holder of Mathlib.),\n  The R Core Team [cph] (Copyright holder of Mathlib.),\n  The Regents of the University of California [cph] (Copyright holder of\n    stdlib's qsort.),\n  Timothy Davis [cph, ctb] (Author of CXSPARSE (cs).),\n  Richard Lehoucq [cph, ctb] (Author of arpack.),\n  Danny Scrensen [cph, ctb] (Author of arpack and lapack.),\n  Phuong Vu [cph, ctb] (Author of arpack.),\n  Chao Yang [cph, ctb] (Author of arpack.),\n  Allan Cornet [cph, ctb] (Author of arpack.),\n  Sylvestre Ledru [cph, ctb] (Author of arpack.),\n  Chao Yang [cph, ctb] (Author of arpack.),\n  Rice University [cph] (Copyright holder of arpack.),\n  Scilab Enterprises [cph] (Copyright holder of arpack-ng.),\n  Melissa O'Neill [cph, ctb] (Author of PCG random number generator.),\n  Steven Johnson [cph, ctb] (Author of ax_pthread.),\n  Daniel G. [cph, ctb] (Author of ax_pthread.),\n  Marc Stevens [cph, ctb] (Author of ax_pthread.),\n  Minh Nguyen [cph, ctb] (Author of ax_pthread.),\n  Elliot Paquette [cph, ctb] (Contributor to igraph.),\n  Pascal Pons [cph, ctb] (Contributor to igraph.),\n  Jordi Hermoso [cph, ctb] (Contributor to arpack.),\n  S\u00e9bastien Fabbro [cph, ctb] (Contributor to arpack.),\n  Shinya Tasaki [cph, ctb] (Provided code used in the gene clustering\n    example.)",
    "url": "https://github.com/SpeakEasy-2/speakeasyR",
    "bug_reports": "https://github.com/SpeakEasy-2/speakeasyR/issues",
    "repository": "https://cran.r-project.org/package=speakeasyR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "speakeasyR Fast and Robust Multi-Scale Graph Clustering A graph community detection algorithm that aims to be performant\n    on large graphs and robust, returning consistent results across runs.\n    SpeakEasy 2 (SE2), the underlying algorithm, is described in Chris Gaiteri,\n    David R. Connell & Faraz A. Sultan et al. (2023)\n    <doi:10.1186/s13059-023-03062-0>. The core algorithm is written in 'C',\n    providing speed and keeping the memory requirements low. This implementation\n    can take advantage of multiple computing cores without increasing memory\n    usage. SE2 can detect community structure across scales, making it a good\n    choice for biological data, which often has hierarchical structure. Graphs\n    can be passed to the algorithm as adjacency matrices using base 'R'\n    matrices, the 'Matrix' library, 'igraph' graphs, or any data that can be\n    coerced into a matrix.  "
  },
  {
    "id": 21198,
    "package_name": "sphereML",
    "title": "Analyzing Students' Performance Dataset in Physics Education\nResearch (SPHERE) using Machine Learning (ML)",
    "description": "A simple package facilitating ML based analysis for physics education research (PER) purposes. The implemented machine learning technique is random forest optimized by item response theory (IRT) for feature selection and genetic algorithm (GA) for hyperparameter tuning. The data analyzed here has been made available in the CRAN repository through the 'spheredata' package. The SPHERE stands for Students' Performance in Physics Education Research (PER). The students are the eleventh graders learning physics at the high school curriculum. We follow the stream of multidimensional students' assessment as probed by some research based assessments in PER. The goal is to predict the students' performance at the end of the learning process. Three learning domains are measured including conceptual understanding, scientific ability, and scientific attitude. Furthermore, demographic backgrounds and potential variables predicting students' performance on physics are also demonstrated.",
    "version": "0.1.1",
    "maintainer": "Purwoko Haryadi Santoso <purwokoharyadisantoso@unsulbar.ac.id>",
    "author": "Purwoko Haryadi Santoso [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7093-5309>),\n  Edi Istiyono [ctb],\n  Haryanto Haryanto [ctb]",
    "url": "https://github.com/santosoph/sphereML",
    "bug_reports": "https://github.com/santosoph/sphereML/issues",
    "repository": "https://cran.r-project.org/package=sphereML",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sphereML Analyzing Students' Performance Dataset in Physics Education\nResearch (SPHERE) using Machine Learning (ML) A simple package facilitating ML based analysis for physics education research (PER) purposes. The implemented machine learning technique is random forest optimized by item response theory (IRT) for feature selection and genetic algorithm (GA) for hyperparameter tuning. The data analyzed here has been made available in the CRAN repository through the 'spheredata' package. The SPHERE stands for Students' Performance in Physics Education Research (PER). The students are the eleventh graders learning physics at the high school curriculum. We follow the stream of multidimensional students' assessment as probed by some research based assessments in PER. The goal is to predict the students' performance at the end of the learning process. Three learning domains are measured including conceptual understanding, scientific ability, and scientific attitude. Furthermore, demographic backgrounds and potential variables predicting students' performance on physics are also demonstrated.  "
  },
  {
    "id": 21199,
    "package_name": "spheredata",
    "title": "Students' Performance Dataset in Physics Education Research\n(SPHERE)",
    "description": "A multidimensional dataset of students' performance assessment in high school physics. The SPHERE dataset was collected from 497 students in four public high schools specifically measuring their conceptual understanding, scientific ability, and attitude toward physics [see Santoso et al. (2024) <doi:10.17632/88d7m2fv7p.1>]. The data collection was conducted using some research based assessments established by the physics education research community. They include the Force Concept Inventory, the Force and Motion Conceptual Evaluation, the Rotational and Rolling Motion Conceptual Survey, the Fluid Mechanics Concept Inventory, the Mechanical Waves Conceptual Survey, the Thermal Concept Evaluation, the Survey of Thermodynamic Processes and First and Second Laws, the Scientific Abilities Assessment Rubrics, and the Colorado Learning Attitudes about Science Survey. Students' attributes related to gender, age, socioeconomic status, domicile, literacy, physics identity, and test results administered using teachers' developed items are also reported in this dataset.",
    "version": "0.1.3",
    "maintainer": "Purwoko Haryadi Santoso <purwokoharyadisantoso@unsulbar.ac.id>",
    "author": "Purwoko Haryadi Santoso [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7093-5309>),\n  Edi Istiyono [ctb],\n  Haryanto Haryanto [ctb]",
    "url": "https://github.com/santosoph/spheredata",
    "bug_reports": "https://github.com/santosoph/spheredata/issues",
    "repository": "https://cran.r-project.org/package=spheredata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spheredata Students' Performance Dataset in Physics Education Research\n(SPHERE) A multidimensional dataset of students' performance assessment in high school physics. The SPHERE dataset was collected from 497 students in four public high schools specifically measuring their conceptual understanding, scientific ability, and attitude toward physics [see Santoso et al. (2024) <doi:10.17632/88d7m2fv7p.1>]. The data collection was conducted using some research based assessments established by the physics education research community. They include the Force Concept Inventory, the Force and Motion Conceptual Evaluation, the Rotational and Rolling Motion Conceptual Survey, the Fluid Mechanics Concept Inventory, the Mechanical Waves Conceptual Survey, the Thermal Concept Evaluation, the Survey of Thermodynamic Processes and First and Second Laws, the Scientific Abilities Assessment Rubrics, and the Colorado Learning Attitudes about Science Survey. Students' attributes related to gender, age, socioeconomic status, domicile, literacy, physics identity, and test results administered using teachers' developed items are also reported in this dataset.  "
  },
  {
    "id": 21267,
    "package_name": "sps",
    "title": "Sequential Poisson Sampling",
    "description": "Sequential Poisson sampling is a variation of Poisson sampling for\n    drawing probability-proportional-to-size samples with a given number of\n    units, and is commonly used for price-index surveys. This package gives\n    functions to draw stratified sequential Poisson samples according to the\n    method by Ohlsson (1998, ISSN:0282-423X), as well as other order sample\n    designs by Ros\u00e9n (1997, <doi:10.1016/S0378-3758(96)00186-3>), and generate\n    approximate bootstrap replicate weights according to the generalized\n    bootstrap method by Beaumont and Patak\n    (2012, <doi:10.1111/j.1751-5823.2011.00166.x>).",
    "version": "0.6.3",
    "maintainer": "Steve Martin <marberts@protonmail.com>",
    "author": "Steve Martin [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2544-9480>),\n  Justin Francis [ctb]",
    "url": "https://marberts.github.io/sps/, https://github.com/marberts/sps",
    "bug_reports": "https://github.com/marberts/sps/issues",
    "repository": "https://cran.r-project.org/package=sps",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sps Sequential Poisson Sampling Sequential Poisson sampling is a variation of Poisson sampling for\n    drawing probability-proportional-to-size samples with a given number of\n    units, and is commonly used for price-index surveys. This package gives\n    functions to draw stratified sequential Poisson samples according to the\n    method by Ohlsson (1998, ISSN:0282-423X), as well as other order sample\n    designs by Ros\u00e9n (1997, <doi:10.1016/S0378-3758(96)00186-3>), and generate\n    approximate bootstrap replicate weights according to the generalized\n    bootstrap method by Beaumont and Patak\n    (2012, <doi:10.1111/j.1751-5823.2011.00166.x>).  "
  },
  {
    "id": 21273,
    "package_name": "spsurvey",
    "title": "Spatial Sampling Design and Analysis",
    "description": "A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more. For additional details, see Dumelle et al. (2023) <doi:10.18637/jss.v105.i03>.",
    "version": "5.6.0",
    "maintainer": "Michael Dumelle <Dumelle.Michael@epa.gov>",
    "author": "Michael Dumelle [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-3393-5529>),\n  Tom Kincaid [aut],\n  Anthony (Tony) R. Olsen [aut],\n  Marc Weber [aut],\n  Don Stevens [ctb],\n  Denis White [ctb],\n  Amanda M. Nahlik [ctb],\n  Sarah Lehmann [ctb]",
    "url": "https://usepa.github.io/spsurvey/,\nhttps://github.com/USEPA/spsurvey",
    "bug_reports": "https://github.com/USEPA/spsurvey/issues",
    "repository": "https://cran.r-project.org/package=spsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "spsurvey Spatial Sampling Design and Analysis A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more. For additional details, see Dumelle et al. (2023) <doi:10.18637/jss.v105.i03>.  "
  },
  {
    "id": 21298,
    "package_name": "sregsurvey",
    "title": "Semiparametric Model-Assisted Estimation in Finite Populations",
    "description": "It is a framework to fit semiparametric regression estimators for the total parameter of a finite population when the interest variable is asymmetric distributed. The main references for this package are Sarndal C.E., Swensson B., and Wretman J. (2003,ISBN: 978-0-387-40620-6, \"Model Assisted Survey Sampling.\" Springer-Verlag) \n  Cardozo C.A, Paula G.A. and Vanegas L.H. (2022) \"Generalized log-gamma additive partial linear mdoels with P-spline smoothing\", Statistical Papers. \n  Cardozo C.A and Alonso-Malaver C.E. (2022). \"Semi-parametric model assisted estimation in finite populations.\" In preparation.    ",
    "version": "0.1.3",
    "maintainer": "Carlos Alberto Cardozo Delgado <cardozorpackages@gmail.com>",
    "author": "Carlos Alberto Cardozo Delgado [aut, cre, cph],\n  Carlos E. Alonso-Malaver [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=sregsurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sregsurvey Semiparametric Model-Assisted Estimation in Finite Populations It is a framework to fit semiparametric regression estimators for the total parameter of a finite population when the interest variable is asymmetric distributed. The main references for this package are Sarndal C.E., Swensson B., and Wretman J. (2003,ISBN: 978-0-387-40620-6, \"Model Assisted Survey Sampling.\" Springer-Verlag) \n  Cardozo C.A, Paula G.A. and Vanegas L.H. (2022) \"Generalized log-gamma additive partial linear mdoels with P-spline smoothing\", Statistical Papers. \n  Cardozo C.A and Alonso-Malaver C.E. (2022). \"Semi-parametric model assisted estimation in finite populations.\" In preparation.      "
  },
  {
    "id": 21304,
    "package_name": "srvyr",
    "title": "'dplyr'-Like Syntax for Summary Statistics of Survey Data",
    "description": "Use piping, verbs like 'group_by' and 'summarize', and other\n    'dplyr' inspired syntactic style when calculating summary statistics on survey\n    data using functions from the 'survey' package.",
    "version": "1.3.0",
    "maintainer": "Greg Freedman Ellis <greg.freedman@gmail.com>",
    "author": "Greg Freedman Ellis [aut, cre],\n  Thomas Lumley [ctb],\n  Tomasz \u017b\u00f3\u0142tak [ctb],\n  Ben Schneider [aut, ctb],\n  Pavel N. Krivitsky [ctb]",
    "url": "http://gdfe.co/srvyr/, https://github.com/gergness/srvyr/",
    "bug_reports": "https://github.com/gergness/srvyr/issues",
    "repository": "https://cran.r-project.org/package=srvyr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "srvyr 'dplyr'-Like Syntax for Summary Statistics of Survey Data Use piping, verbs like 'group_by' and 'summarize', and other\n    'dplyr' inspired syntactic style when calculating summary statistics on survey\n    data using functions from the 'survey' package.  "
  },
  {
    "id": 21336,
    "package_name": "sss",
    "title": "Import Files in the Triple-s (Standard Survey Structure) Format",
    "description": "Tools to import survey files in the '.sss' (triple-s) format. \n    The package provides the function 'read.sss()' that reads the '.asc' \n    (or '.csv') and '.sss' files of a triple-s survey data file. \n    See also <https://triple-s.org/>.",
    "version": "0.2.2",
    "maintainer": "Andrie de Vries <apdevries@gmail.com>",
    "author": "Andrie de Vries [aut, cre]",
    "url": "http://andrie.github.io/sss/, https://andrie.github.io/sss/",
    "bug_reports": "https://github.com/andrie/sss/issues",
    "repository": "https://cran.r-project.org/package=sss",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "sss Import Files in the Triple-s (Standard Survey Structure) Format Tools to import survey files in the '.sss' (triple-s) format. \n    The package provides the function 'read.sss()' that reads the '.asc' \n    (or '.csv') and '.sss' files of a triple-s survey data file. \n    See also <https://triple-s.org/>.  "
  },
  {
    "id": 21416,
    "package_name": "statnet",
    "title": "Software Tools for the Statistical Analysis of Network Data",
    "description": "Statnet is a collection of packages for statistical network analysis that are \n  designed to work together because they share common data representations and 'API' \n  design.  They provide an integrated set of tools for the representation, \n  visualization, analysis, and simulation of many different forms of network data.  \n  This package is designed to make it easy to install and load the \n  key 'statnet' packages in a single step.  Learn more about 'statnet' \n  at <http://www.statnet.org>.  Tutorials for many packages can be found \n  at <https://github.com/statnet/Workshops/wiki>.  For an introduction to functions in this package, \n  type help(package='statnet').",
    "version": "2019.6",
    "maintainer": "Martina Morris <morrism@uw.edu>",
    "author": "Mark S. Handcock [aut],\n  David R. Hunter [aut],\n  Carter T. Butts [aut],\n  Steven M. Goodreau [aut],\n  Pavel N. Krivitsky [aut] (ORCID:\n    <https://orcid.org/0000-0002-9101-3362>),\n  Skye Bender-deMoll [aut],\n  Martina Morris [aut, cre]",
    "url": "http://statnet.org",
    "bug_reports": "https://github.com/statnet/statnet/issues",
    "repository": "https://cran.r-project.org/package=statnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "statnet Software Tools for the Statistical Analysis of Network Data Statnet is a collection of packages for statistical network analysis that are \n  designed to work together because they share common data representations and 'API' \n  design.  They provide an integrated set of tools for the representation, \n  visualization, analysis, and simulation of many different forms of network data.  \n  This package is designed to make it easy to install and load the \n  key 'statnet' packages in a single step.  Learn more about 'statnet' \n  at <http://www.statnet.org>.  Tutorials for many packages can be found \n  at <https://github.com/statnet/Workshops/wiki>.  For an introduction to functions in this package, \n  type help(package='statnet').  "
  },
  {
    "id": 21452,
    "package_name": "stepmetrics",
    "title": "Calculate Step and Cadence Metrics from Wearable Data",
    "description": "Provides functions to calculate step- and cadence-based metrics from \n    timestamped accelerometer and wearable device data. Supports CSV and AGD files from \n    'ActiGraph' devices, CSV files from 'Fitbit' devices, and step counts derived   \n    with R package 'GGIR' <https://github.com/wadpac/GGIR>, with automatic handling \n    of epoch lengths from 1 to 60 seconds. Metrics include total steps, cadence \n    peaks, minutes and steps in predefined cadence bands, and time and steps in \n    moderate-to-vigorous physical activity (MVPA). Methods and thresholds are \n    informed by the literature, e.g., \n    Tudor-Locke and Rowe (2012) <doi:10.2165/11599170-000000000-00000>, \n    Barreira et al. (2012) <doi:10.1249/MSS.0b013e318254f2a3>, \n    and Tudor-Locke et al. (2018) <doi:10.1136/bjsports-2017-097628>. \n    The package record is also available on Zenodo (2023) <doi:10.5281/zenodo.7858094>.",
    "version": "1.0.3",
    "maintainer": "Jairo H Migueles <jairo@jhmigueles.com>",
    "author": "Jairo H Migueles [aut, cre],\n  Elroy J Aguiar [fnd] (Funding and data support),\n  University of Alabama [fnd]",
    "url": "https://github.com/jhmigueles/stepmetrics",
    "bug_reports": "https://github.com/jhmigueles/stepmetrics/issues",
    "repository": "https://cran.r-project.org/package=stepmetrics",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stepmetrics Calculate Step and Cadence Metrics from Wearable Data Provides functions to calculate step- and cadence-based metrics from \n    timestamped accelerometer and wearable device data. Supports CSV and AGD files from \n    'ActiGraph' devices, CSV files from 'Fitbit' devices, and step counts derived   \n    with R package 'GGIR' <https://github.com/wadpac/GGIR>, with automatic handling \n    of epoch lengths from 1 to 60 seconds. Metrics include total steps, cadence \n    peaks, minutes and steps in predefined cadence bands, and time and steps in \n    moderate-to-vigorous physical activity (MVPA). Methods and thresholds are \n    informed by the literature, e.g., \n    Tudor-Locke and Rowe (2012) <doi:10.2165/11599170-000000000-00000>, \n    Barreira et al. (2012) <doi:10.1249/MSS.0b013e318254f2a3>, \n    and Tudor-Locke et al. (2018) <doi:10.1136/bjsports-2017-097628>. \n    The package record is also available on Zenodo (2023) <doi:10.5281/zenodo.7858094>.  "
  },
  {
    "id": 21508,
    "package_name": "strap",
    "title": "Stratigraphic Tree Analysis for Palaeontology",
    "description": "Functions for the stratigraphic analysis of phylogenetic trees.",
    "version": "1.6-1",
    "maintainer": "Graeme T. Lloyd <graemetlloyd@gmail.com>",
    "author": "Mark A. Bell [aut, cph],\n  Graeme T. Lloyd [aut, cre, cph]",
    "url": "https://github.com/graemetlloyd/strap",
    "bug_reports": "https://github.com/graemetlloyd/strap/issues",
    "repository": "https://cran.r-project.org/package=strap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "strap Stratigraphic Tree Analysis for Palaeontology Functions for the stratigraphic analysis of phylogenetic trees.  "
  },
  {
    "id": 21513,
    "package_name": "stratallo",
    "title": "Optimum Sample Allocation in Stratified Sampling",
    "description": "Functions in this package provide solution to classical problem in\n  survey methodology - an optimum sample allocation in stratified sampling. In\n  this context, the optimum allocation is in the classical Tschuprow-Neyman's\n  sense and it satisfies additional lower or upper bounds restrictions imposed\n  on sample sizes in strata. There are few different algorithms available to\n  use, and one them is based on popular sample allocation method that applies\n  Neyman allocation to recursively reduced set of strata.\n  This package also provides the function that computes a solution to the\n  minimum cost allocation problem, which is a minor modification of the\n  classical optimum sample allocation. This problem lies in the determination\n  of a vector of strata sample sizes that minimizes total cost of the survey,\n  under assumed fixed level of the stratified estimator's variance. As in the\n  case of the classical optimum allocation, the problem of minimum cost\n  allocation can be complemented by imposing upper-bounds constraints on sample\n  sizes in strata.",
    "version": "2.2.1",
    "maintainer": "Wojciech W\u00f3jciak <wojciech.wojciak@gmail.com>",
    "author": "Wojciech W\u00f3jciak [aut, cre],\n  Jacek Weso\u0142owski [sad],\n  Robert Wieczorkowski [ctb]",
    "url": "https://github.com/wwojciech/stratallo",
    "bug_reports": "https://github.com/wwojciech/stratallo/issues",
    "repository": "https://cran.r-project.org/package=stratallo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stratallo Optimum Sample Allocation in Stratified Sampling Functions in this package provide solution to classical problem in\n  survey methodology - an optimum sample allocation in stratified sampling. In\n  this context, the optimum allocation is in the classical Tschuprow-Neyman's\n  sense and it satisfies additional lower or upper bounds restrictions imposed\n  on sample sizes in strata. There are few different algorithms available to\n  use, and one them is based on popular sample allocation method that applies\n  Neyman allocation to recursively reduced set of strata.\n  This package also provides the function that computes a solution to the\n  minimum cost allocation problem, which is a minor modification of the\n  classical optimum sample allocation. This problem lies in the determination\n  of a vector of strata sample sizes that minimizes total cost of the survey,\n  under assumed fixed level of the stratified estimator's variance. As in the\n  case of the classical optimum allocation, the problem of minimum cost\n  allocation can be complemented by imposing upper-bounds constraints on sample\n  sizes in strata.  "
  },
  {
    "id": 21515,
    "package_name": "stratastats",
    "title": "Stratified Analysis of 2x2 Contingency Tables",
    "description": "Offers a comprehensive approach for analysing stratified 2x2 contingency tables. It facilitates the calculation of odds ratios, 95% confidence intervals, and conducts chi-squared, Cochran-Mantel-Haenszel, Mantel-Haenszel, and Breslow-Day-Tarone tests. The package is particularly useful in fields like epidemiology and social sciences where stratified analysis is essential. The package also provides interpretative insights into the results, aiding in the understanding of statistical outcomes.",
    "version": "0.2",
    "maintainer": "Gianmarco Alberti <gianmarcoalberti@gmail.com>",
    "author": "Gianmarco Alberti [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stratastats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stratastats Stratified Analysis of 2x2 Contingency Tables Offers a comprehensive approach for analysing stratified 2x2 contingency tables. It facilitates the calculation of odds ratios, 95% confidence intervals, and conducts chi-squared, Cochran-Mantel-Haenszel, Mantel-Haenszel, and Breslow-Day-Tarone tests. The package is particularly useful in fields like epidemiology and social sciences where stratified analysis is essential. The package also provides interpretative insights into the results, aiding in the understanding of statistical outcomes.  "
  },
  {
    "id": 21517,
    "package_name": "stratcols",
    "title": "Stratigraphic Columns and Order Metrics",
    "description": "Quantify stratigraphic disorder using the metrics defined by Burgess (2016) <doi:10.2110/jsr.2016.10>. Contains a range of utility tools to construct and manipulate stratigraphic columns.",
    "version": "1.0.0",
    "maintainer": "Niklas Hohmann <N.H.Hohmann@uu.nl>",
    "author": "Niklas Hohmann [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-1559-1838>)",
    "url": "https://mindthegap-erc.github.io/stratcols/,\nhttps://github.com/MindTheGap-ERC/stratcols",
    "bug_reports": "https://github.com/MindTheGap-ERC/stratcols/issues",
    "repository": "https://cran.r-project.org/package=stratcols",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stratcols Stratigraphic Columns and Order Metrics Quantify stratigraphic disorder using the metrics defined by Burgess (2016) <doi:10.2110/jsr.2016.10>. Contains a range of utility tools to construct and manipulate stratigraphic columns.  "
  },
  {
    "id": 21519,
    "package_name": "stratification",
    "title": "Univariate Stratification of Survey Populations",
    "description": "Univariate stratification of survey populations with a generalization of the \n  Lavallee-Hidiroglou method of stratum construction. The generalized method takes into account \n  a discrepancy between the stratification variable and the survey variable. The determination \n  of the optimal boundaries also incorporate, if desired, an anticipated non-response, a take-all \n  stratum for large units, a take-none stratum for small units, and a certainty stratum to ensure \n  that some specific units are in the sample. The well known cumulative root frequency rule of \n  Dalenius and Hodges and the geometric rule of Gunning and Horgan are also implemented. ",
    "version": "2.2-7",
    "maintainer": "Louis-Paul Rivest <Louis-Paul.Rivest@mat.ulaval.ca>",
    "author": "Louis-Paul Rivest [aut, cre],\n  Sophie Baillargeon [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=stratification",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "stratification Univariate Stratification of Survey Populations Univariate stratification of survey populations with a generalization of the \n  Lavallee-Hidiroglou method of stratum construction. The generalized method takes into account \n  a discrepancy between the stratification variable and the survey variable. The determination \n  of the optimal boundaries also incorporate, if desired, an anticipated non-response, a take-all \n  stratum for large units, a take-none stratum for small units, and a certainty stratum to ensure \n  that some specific units are in the sample. The well known cumulative root frequency rule of \n  Dalenius and Hodges and the geometric rule of Gunning and Horgan are also implemented.   "
  },
  {
    "id": 21532,
    "package_name": "streetscape",
    "title": "Collect and Investigate Street Views for Urban Science",
    "description": "A collection of functions to search and download street view imagery \n             ('Mapilary' <https://www.mapillary.com/developer/api-documentation>) and \n             to extract, quantify, and visualize visual features. Moreover, there are \n             functions provided to generate Qualtrics survey in TXT format using \n             the collection of street views for various research purposes. ",
    "version": "1.0.5",
    "maintainer": "Xiaohao Yang <xiaohaoy@umich.edu>",
    "author": "Xiaohao Yang [aut, cre, cph],\n  Derek Van Berkel [aut],\n  Mark Lindquist [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=streetscape",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "streetscape Collect and Investigate Street Views for Urban Science A collection of functions to search and download street view imagery \n             ('Mapilary' <https://www.mapillary.com/developer/api-documentation>) and \n             to extract, quantify, and visualize visual features. Moreover, there are \n             functions provided to generate Qualtrics survey in TXT format using \n             the collection of street views for various research purposes.   "
  },
  {
    "id": 21558,
    "package_name": "studentlife",
    "title": "Tidy Handling and Navigation of the Student-Life Dataset",
    "description": "Download, navigate and analyse the Student-Life dataset. \n    The Student-Life dataset contains passive and automatic sensing data \n    from the phones of a class of 48 Dartmouth college students. \n    It was collected over a 10 week term. Additionally, the dataset contains ecological \n    momentary assessment results along with pre-study and post-study mental  \n    health surveys. The intended use is to assess \n    mental health, academic performance and behavioral trends. \n    The raw dataset and additional information is \n    available at <https://studentlife.cs.dartmouth.edu/>.",
    "version": "1.1.0",
    "maintainer": "Daniel Fryer <d.fryer@latrobe.edu.au>",
    "author": "Daniel Fryer [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6032-0522>),\n  Hien Nguyen [aut] (ORCID: <https://orcid.org/0000-0002-9958-432X>),\n  Pierre Orban [aut]",
    "url": "https://github.com/Frycast/studentlife",
    "bug_reports": "https://github.com/Frycast/studentlife/issues",
    "repository": "https://cran.r-project.org/package=studentlife",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "studentlife Tidy Handling and Navigation of the Student-Life Dataset Download, navigate and analyse the Student-Life dataset. \n    The Student-Life dataset contains passive and automatic sensing data \n    from the phones of a class of 48 Dartmouth college students. \n    It was collected over a 10 week term. Additionally, the dataset contains ecological \n    momentary assessment results along with pre-study and post-study mental  \n    health surveys. The intended use is to assess \n    mental health, academic performance and behavioral trends. \n    The raw dataset and additional information is \n    available at <https://studentlife.cs.dartmouth.edu/>.  "
  },
  {
    "id": 21615,
    "package_name": "support.BWS3",
    "title": "Tools for Case 3 Best-Worst Scaling",
    "description": "Provides basic functions that support an implementation of multi-profile case (Case 3) best-worst scaling (BWS). Case 3 BWS is a question-based survey method to elicit people's preferences for attribute levels. Case 3 BWS constructs various combinations of attribute levels (profiles) and then asks respondents to select the best and worst profiles in each choice set. A main function creates a dataset for the analysis from the choice sets and the responses to the questions. For details on Case 3 BWS, refer to Louviere et al. (2015) <doi:10.1017/CBO9781107337855>.",
    "version": "0.2-1",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=support.BWS3",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "support.BWS3 Tools for Case 3 Best-Worst Scaling Provides basic functions that support an implementation of multi-profile case (Case 3) best-worst scaling (BWS). Case 3 BWS is a question-based survey method to elicit people's preferences for attribute levels. Case 3 BWS constructs various combinations of attribute levels (profiles) and then asks respondents to select the best and worst profiles in each choice set. A main function creates a dataset for the analysis from the choice sets and the responses to the questions. For details on Case 3 BWS, refer to Louviere et al. (2015) <doi:10.1017/CBO9781107337855>.  "
  },
  {
    "id": 21616,
    "package_name": "support.CEs",
    "title": "Basic Functions for Supporting an Implementation of Choice\nExperiments",
    "description": "Provides basic functions that support an implementation of (discrete) choice experiments (CEs). CEs is a question-based survey method measuring people's preferences for goods/services and their characteristics. Refer to Louviere et al. (2000) <doi:10.1017/CBO9780511753831> for details on CEs, and Aizaki (2012) <doi:10.18637/jss.v050.c02> for the package.",
    "version": "0.7-0",
    "maintainer": "Hideo Aizaki <azk-r@spa.nifty.com>",
    "author": "Hideo Aizaki",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=support.CEs",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "support.CEs Basic Functions for Supporting an Implementation of Choice\nExperiments Provides basic functions that support an implementation of (discrete) choice experiments (CEs). CEs is a question-based survey method measuring people's preferences for goods/services and their characteristics. Refer to Louviere et al. (2000) <doi:10.1017/CBO9780511753831> for details on CEs, and Aizaki (2012) <doi:10.18637/jss.v050.c02> for the package.  "
  },
  {
    "id": 21657,
    "package_name": "surveyCV",
    "title": "Cross Validation Based on Survey Design",
    "description": "Functions to generate K-fold cross validation (CV) folds\n    and CV test error estimates that take into account\n    how a survey dataset's sampling design was constructed\n    (SRS, clustering, stratification, and/or unequal sampling weights).\n    You can input linear and logistic regression models, along with data and a \n    type of survey design in order to get an output that can help you determine\n    which model best fits the data using K-fold cross validation.\n    Our paper on \"K-Fold Cross-Validation for Complex Sample Surveys\"\n    by Wieczorek, Guerin, and McMahon (2022)\n    <doi:10.1002/sta4.454>\n    explains why differing how we take folds based on survey design is useful.",
    "version": "0.2.0",
    "maintainer": "Jerzy Wieczorek <jawieczo@colby.edu>",
    "author": "Cole Guerin [aut],\n  Thomas McMahon [aut],\n  Jerzy Wieczorek [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-2859-6534>),\n  Hunter Ratliff [ctb]",
    "url": "https://github.com/ColbyStatSvyRsch/surveyCV/",
    "bug_reports": "https://github.com/ColbyStatSvyRsch/surveyCV/issues",
    "repository": "https://cran.r-project.org/package=surveyCV",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveyCV Cross Validation Based on Survey Design Functions to generate K-fold cross validation (CV) folds\n    and CV test error estimates that take into account\n    how a survey dataset's sampling design was constructed\n    (SRS, clustering, stratification, and/or unequal sampling weights).\n    You can input linear and logistic regression models, along with data and a \n    type of survey design in order to get an output that can help you determine\n    which model best fits the data using K-fold cross validation.\n    Our paper on \"K-Fold Cross-Validation for Complex Sample Surveys\"\n    by Wieczorek, Guerin, and McMahon (2022)\n    <doi:10.1002/sta4.454>\n    explains why differing how we take folds based on survey design is useful.  "
  },
  {
    "id": 21658,
    "package_name": "surveyPrev",
    "title": "Mapping the Prevalence of Binary Indicators using Survey Data in\nSmall Areas",
    "description": "Provides a pipeline to perform small area estimation and prevalence mapping of binary indicators using health and demographic survey data, described in Fuglstad et al. (2022) <doi:10.48550/arXiv.2110.09576> and Wakefield et al. (2020) <doi:10.1111/insr.12400>.",
    "version": "1.0.0",
    "maintainer": "Qianyu Dong <qdong14@ucsc.edu>",
    "author": "Qianyu Dong [cre, aut],\n  Zehang R Li [aut],\n  Yunhan Wu [aut],\n  Andrea Boskovic [aut],\n  Jon Wakefield [aut]",
    "url": "https://github.com/richardli/surveyPrev",
    "bug_reports": "https://github.com/richardli/surveyPrev/issues",
    "repository": "https://cran.r-project.org/package=surveyPrev",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveyPrev Mapping the Prevalence of Binary Indicators using Survey Data in\nSmall Areas Provides a pipeline to perform small area estimation and prevalence mapping of binary indicators using health and demographic survey data, described in Fuglstad et al. (2022) <doi:10.48550/arXiv.2110.09576> and Wakefield et al. (2020) <doi:10.1111/insr.12400>.  "
  },
  {
    "id": 21659,
    "package_name": "surveySimR",
    "title": "Estimation of Population Total under Complex Sampling Design",
    "description": "Sample surveys use scientific methods to draw inferences about population parameters by observing a representative part of the population, called sample. The SRSWOR (Simple Random Sampling Without Replacement) is one of the most widely used probability sampling designs, wherein every unit has an equal chance of being selected and units are not repeated.This function draws multiple SRSWOR samples from a finite population and estimates the population parameter i.e. total of HT, Ratio, and Regression estimators. Repeated simulations (e.g., 500 times) are used to assess and compare estimators using metrics such as percent relative bias (%RB), percent relative root means square error (%RRMSE).For details on sampling methodology,\n             see, Cochran (1977) \"Sampling Techniques\" <https://archive.org/details/samplingtechniqu0000coch_t4x6>.",
    "version": "0.1.0",
    "maintainer": "Nobin Chandra Paul <ncp375@gmail.com>",
    "author": "Nobin Chandra Paul [aut, cre, cph],\n  Santosha Rathod [aut, cph],\n  Navyasree Ponnaganti [aut, cph]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=surveySimR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveySimR Estimation of Population Total under Complex Sampling Design Sample surveys use scientific methods to draw inferences about population parameters by observing a representative part of the population, called sample. The SRSWOR (Simple Random Sampling Without Replacement) is one of the most widely used probability sampling designs, wherein every unit has an equal chance of being selected and units are not repeated.This function draws multiple SRSWOR samples from a finite population and estimates the population parameter i.e. total of HT, Ratio, and Regression estimators. Repeated simulations (e.g., 500 times) are used to assess and compare estimators using metrics such as percent relative bias (%RB), percent relative root means square error (%RRMSE).For details on sampling methodology,\n             see, Cochran (1977) \"Sampling Techniques\" <https://archive.org/details/samplingtechniqu0000coch_t4x6>.  "
  },
  {
    "id": 21660,
    "package_name": "surveybootstrap",
    "title": "Bootstrap with Survey Data",
    "description": "Implements different kinds of bootstraps\n    to estimate sampling variation from survey data with \n    complex designs. Includes the rescaled bootstrap\n    described in Rust and Rao (1996) <doi:10.1177/096228029600500305> and\n    Rao and Wu (1988) <doi:10.1080/01621459.1988.10478591>. ",
    "version": "0.0.3",
    "maintainer": "Dennis M. Feehan <feehan@berkeley.edu>",
    "author": "Dennis M. Feehan [aut, cre],\n  Matthew J. Salganik [ths]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=surveybootstrap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveybootstrap Bootstrap with Survey Data Implements different kinds of bootstraps\n    to estimate sampling variation from survey data with \n    complex designs. Includes the rescaled bootstrap\n    described in Rust and Rao (1996) <doi:10.1177/096228029600500305> and\n    Rao and Wu (1988) <doi:10.1080/01621459.1988.10478591>.   "
  },
  {
    "id": 21661,
    "package_name": "surveydata",
    "title": "Tools to Work with Survey Data",
    "description": "Data obtained from surveys contains information not only about the\n    survey responses, but also the survey metadata, e.g. the original survey\n    questions and the answer options. The 'surveydata' package makes it easy to\n    keep track of this metadata, and to easily extract columns with\n    specific questions.",
    "version": "0.2.7",
    "maintainer": "Andrie de Vries <apdevries@gmail.com>",
    "author": "Andrie de Vries [aut, cre, cph],\n  Evan Odell [ctb]",
    "url": "https://github.com/andrie/surveydata,\nhttps://andrie.github.io/surveydata/",
    "bug_reports": "https://github.com/andrie/surveydata/issues",
    "repository": "https://cran.r-project.org/package=surveydata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveydata Tools to Work with Survey Data Data obtained from surveys contains information not only about the\n    survey responses, but also the survey metadata, e.g. the original survey\n    questions and the answer options. The 'surveydata' package makes it easy to\n    keep track of this metadata, and to easily extract columns with\n    specific questions.  "
  },
  {
    "id": 21662,
    "package_name": "surveydown",
    "title": "Markdown-Based Programmable Surveys Using 'Quarto' and 'shiny'",
    "description": "Generate programmable surveys using markdown and R code chunks. Surveys\n    are composed of two files: a survey.qmd 'Quarto' file defining the\n    survey content (pages, questions, etc), and an app.R file defining a\n    'shiny' app with global settings (libraries, database configuration,\n    etc.) and server configuration options (e.g., conditional skipping /\n    display, etc.). Survey data collected from respondents is stored in a\n    'PostgreSQL' database. Features include controls for conditional skip\n    logic (skip to a page based on an answer to a question), conditional\n    display logic (display a question based on an answer to a question), a\n    customizable progress bar, and a wide variety of question types,\n    including multiple choice (single choice and multiple choices),\n    select, text, numeric, multiple choice buttons, text area, and dates.\n    Because the surveys render into a 'shiny' app, designers can also\n    leverage the reactive capabilities of 'shiny' to create dynamic and\n    interactive surveys.",
    "version": "0.14.0",
    "maintainer": "John Paul Helveston <john.helveston@gmail.com>",
    "author": "John Paul Helveston [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-2657-9191>),\n  Pingfan Hu [aut, cph] (ORCID: <https://orcid.org/0009-0001-4877-4844>),\n  Bogdan Bunea [aut, cph] (ORCID:\n    <https://orcid.org/0009-0006-2942-0588>),\n  Stefan Munnes [ctb]",
    "url": "https://pkg.surveydown.org",
    "bug_reports": "https://github.com/surveydown-dev/surveydown/issues",
    "repository": "https://cran.r-project.org/package=surveydown",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveydown Markdown-Based Programmable Surveys Using 'Quarto' and 'shiny' Generate programmable surveys using markdown and R code chunks. Surveys\n    are composed of two files: a survey.qmd 'Quarto' file defining the\n    survey content (pages, questions, etc), and an app.R file defining a\n    'shiny' app with global settings (libraries, database configuration,\n    etc.) and server configuration options (e.g., conditional skipping /\n    display, etc.). Survey data collected from respondents is stored in a\n    'PostgreSQL' database. Features include controls for conditional skip\n    logic (skip to a page based on an answer to a question), conditional\n    display logic (display a question based on an answer to a question), a\n    customizable progress bar, and a wide variety of question types,\n    including multiple choice (single choice and multiple choices),\n    select, text, numeric, multiple choice buttons, text area, and dates.\n    Because the surveys render into a 'shiny' app, designers can also\n    leverage the reactive capabilities of 'shiny' to create dynamic and\n    interactive surveys.  "
  },
  {
    "id": 21663,
    "package_name": "surveyexplorer",
    "title": "Quickly Explore Complex Survey Data",
    "description": "Visualize and tabulate single-choice, multiple-choice, matrix-style questions from survey data. \n    Includes ability to group cross-tabulations, frequency distributions, and plots by categorical variables and \n    to integrate survey weights. Ideal for quickly uncovering descriptive patterns in survey data.",
    "version": "0.2.0",
    "maintainer": "Liam Haller <liamhllr2@gmail.com>",
    "author": "Liam Haller [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0001-8033-6599>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=surveyexplorer",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveyexplorer Quickly Explore Complex Survey Data Visualize and tabulate single-choice, multiple-choice, matrix-style questions from survey data. \n    Includes ability to group cross-tabulations, frequency distributions, and plots by categorical variables and \n    to integrate survey weights. Ideal for quickly uncovering descriptive patterns in survey data.  "
  },
  {
    "id": 21664,
    "package_name": "surveygraph",
    "title": "Network Representations of Attitudes",
    "description": "A tool for computing network representations of attitudes,\n  extracted from tabular data such as sociological surveys. Development of\n  surveygraph software and training materials was initially funded by the\n  European Union under the ERC Proof-of-concept programme (ERC,\n  Attitude-Maps-4-All, project number: 101069264). Views and opinions expressed\n  are however those of the author(s) only and do not necessarily reflect those\n  of the European Union or the European Research Council Executive Agency.\n  Neither the European Union nor the granting authority can be held responsible\n  for them.",
    "version": "1.0.0",
    "maintainer": "Samuel Unicomb <samuelunicomb@gmail.com>",
    "author": "Samuel Unicomb [aut, cre],\n  Ana Jovancevic [aut],\n  Caoimhe O'Reilly [aut],\n  Alejandro Dinkelberg [aut],\n  P\u00e1draig MacCarron [aut],\n  David O'Sullivan [aut],\n  Paul Maher [aut],\n  Mike Quayle [aut]",
    "url": "https://github.com/surveygraph/surveygraphr,\nhttps://surveygraph.ie/",
    "bug_reports": "https://github.com/surveygraph/surveygraphr/issues",
    "repository": "https://cran.r-project.org/package=surveygraph",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveygraph Network Representations of Attitudes A tool for computing network representations of attitudes,\n  extracted from tabular data such as sociological surveys. Development of\n  surveygraph software and training materials was initially funded by the\n  European Union under the ERC Proof-of-concept programme (ERC,\n  Attitude-Maps-4-All, project number: 101069264). Views and opinions expressed\n  are however those of the author(s) only and do not necessarily reflect those\n  of the European Union or the European Research Council Executive Agency.\n  Neither the European Union nor the granting authority can be held responsible\n  for them.  "
  },
  {
    "id": 21665,
    "package_name": "surveynnet",
    "title": "Neural Network for Complex Survey Data",
    "description": "The goal of 'surveynnet' is to extend the functionality of 'nnet', \n  which already supports survey weights, by enabling it to handle clustered\n  and stratified data. It achieves this by incorporating design effects \n  through the use of effective sample sizes as outlined by Chen\n  and Rust (2017), <doi:10.1093/jssam/smw036>, and performed by  \n  'deffCR' in the package 'PracTools' (Valliant, Dever, and Kreuter (2018), \n  <doi:10.1007/978-3-319-93632-1>).",
    "version": "1.0.0",
    "maintainer": "Aaron Cohen <cohenaa@iu.edu>",
    "author": "Aaron Cohen [aut, cre] (ORCID: <https://orcid.org/0009-0003-1971-1072>),\n  Raul Cruz-Cano [aut] (ORCID: <https://orcid.org/0000-0001-7715-1198>)",
    "url": "https://github.com/237triangle/surveynnet",
    "bug_reports": "https://github.com/237triangle/surveynnet/issues",
    "repository": "https://cran.r-project.org/package=surveynnet",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveynnet Neural Network for Complex Survey Data The goal of 'surveynnet' is to extend the functionality of 'nnet', \n  which already supports survey weights, by enabling it to handle clustered\n  and stratified data. It achieves this by incorporating design effects \n  through the use of effective sample sizes as outlined by Chen\n  and Rust (2017), <doi:10.1093/jssam/smw036>, and performed by  \n  'deffCR' in the package 'PracTools' (Valliant, Dever, and Kreuter (2018), \n  <doi:10.1007/978-3-319-93632-1>).  "
  },
  {
    "id": 21666,
    "package_name": "surveyplanning",
    "title": "Survey Planning Tools",
    "description": "Tools for sample survey planning, including sample size calculation, estimation of expected precision for the estimates of totals, and calculation of optimal sample size allocation.",
    "version": "4.0",
    "maintainer": "Juris Breidaks <rcsb@csb.gov.lv>",
    "author": "Juris Breidaks [aut, cre],\n  Martins Liberts [aut],\n  Janis Jukams [aut]",
    "url": "https://csblatvia.github.io/surveyplanning/",
    "bug_reports": "https://github.com/CSBLatvia/surveyplanning/issues/",
    "repository": "https://cran.r-project.org/package=surveyplanning",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveyplanning Survey Planning Tools Tools for sample survey planning, including sample size calculation, estimation of expected precision for the estimates of totals, and calculation of optimal sample size allocation.  "
  },
  {
    "id": 21667,
    "package_name": "surveysd",
    "title": "Survey Standard Error Estimation for Cumulated Estimates and\ntheir Differences in Complex Panel Designs",
    "description": "Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <https://statistikat.github.io/surveysd/articles/methodology.html>.",
    "version": "2.0.0",
    "maintainer": "Johannes Gussenbauer <Johannes.Gussenbauer@statistik.gv.at>",
    "author": "Johannes Gussenbauer [aut, cre],\n  Alexander Kowarik [aut] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>),\n  Eileen Vattheuer [aut],\n  Gregor de Cillia [aut],\n  Matthias Till [ctb]",
    "url": "https://github.com/statistikat/surveysd",
    "bug_reports": "https://github.com/statistikat/surveysd/issues",
    "repository": "https://cran.r-project.org/package=surveysd",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveysd Survey Standard Error Estimation for Cumulated Estimates and\ntheir Differences in Complex Panel Designs Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <https://statistikat.github.io/surveysd/articles/methodology.html>.  "
  },
  {
    "id": 21668,
    "package_name": "surveytable",
    "title": "Streamlining Complex Survey Estimation and Reliability\nAssessment in R",
    "description": "Short and understandable commands that generate tabulated, \n    formatted, and rounded survey estimates. Mostly a wrapper for the \n    'survey' package (Lumley (2004) <doi:10.18637/jss.v009.i08> \n    <https://CRAN.R-project.org/package=survey>) that identifies \n    low-precision estimates using the National Center for Health \n    Statistics (NCHS) presentation standards (Parker et al. (2017) \n    <https://www.cdc.gov/nchs/data/series/sr_02/sr02_175.pdf>,\n    Parker et al. (2023) <doi:10.15620/cdc:124368>).",
    "version": "0.9.10",
    "maintainer": "Alex Strashny <alex.strashny@gmail.com>",
    "author": "Alex Strashny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-6408-7745>)",
    "url": "https://cdcgov.github.io/surveytable/,\nhttps://github.com/CDCgov/surveytable",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=surveytable",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveytable Streamlining Complex Survey Estimation and Reliability\nAssessment in R Short and understandable commands that generate tabulated, \n    formatted, and rounded survey estimates. Mostly a wrapper for the \n    'survey' package (Lumley (2004) <doi:10.18637/jss.v009.i08> \n    <https://CRAN.R-project.org/package=survey>) that identifies \n    low-precision estimates using the National Center for Health \n    Statistics (NCHS) presentation standards (Parker et al. (2017) \n    <https://www.cdc.gov/nchs/data/series/sr_02/sr02_175.pdf>,\n    Parker et al. (2023) <doi:10.15620/cdc:124368>).  "
  },
  {
    "id": 21669,
    "package_name": "surveyvoi",
    "title": "Survey Value of Information",
    "description": "Decision support tool for prioritizing sites for ecological\n    surveys based on their potential to improve plans for conserving\n    biodiversity (e.g. plans for establishing protected areas). Given a set of\n    sites that could potentially be acquired for conservation management,\n    it can be used to generate and evaluate plans for surveying additional\n    sites. Specifically, plans for ecological surveys can be\n    generated using various conventional approaches (e.g. maximizing expected\n    species richness, geographic coverage, diversity of sampled environmental\n    algorithms. After generating such survey plans, they can be evaluated using\n    conditions) and maximizing value of information. Please note that several\n    functions depend on the 'Gurobi' optimization software (available from\n    <https://www.gurobi.com>). Additionally, the 'JAGS' software (available from\n    <https://mcmc-jags.sourceforge.io/>) is required to fit hierarchical\n    generalized linear models. For further details, see Hanson et al. (2023) <doi:10.1111/1365-2664.14309>.",
    "version": "1.1.1",
    "maintainer": "Jeffrey O Hanson <jeffrey.hanson@uqconnect.edu.au>",
    "author": "Jeffrey O Hanson [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4716-6134>),\n  Iadine Chad\u00e8s [aut] (ORCID: <https://orcid.org/0000-0002-7442-2850>),\n  Emma J Hudgins [aut] (ORCID: <https://orcid.org/0000-0002-8402-5111>),\n  Joseph R Bennett [aut] (ORCID: <https://orcid.org/0000-0002-3901-9513>)",
    "url": "https://prioritizr.github.io/surveyvoi/",
    "bug_reports": "https://github.com/prioritizr/surveyvoi/issues",
    "repository": "https://cran.r-project.org/package=surveyvoi",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "surveyvoi Survey Value of Information Decision support tool for prioritizing sites for ecological\n    surveys based on their potential to improve plans for conserving\n    biodiversity (e.g. plans for establishing protected areas). Given a set of\n    sites that could potentially be acquired for conservation management,\n    it can be used to generate and evaluate plans for surveying additional\n    sites. Specifically, plans for ecological surveys can be\n    generated using various conventional approaches (e.g. maximizing expected\n    species richness, geographic coverage, diversity of sampled environmental\n    algorithms. After generating such survey plans, they can be evaluated using\n    conditions) and maximizing value of information. Please note that several\n    functions depend on the 'Gurobi' optimization software (available from\n    <https://www.gurobi.com>). Additionally, the 'JAGS' software (available from\n    <https://mcmc-jags.sourceforge.io/>) is required to fit hierarchical\n    generalized linear models. For further details, see Hanson et al. (2023) <doi:10.1111/1365-2664.14309>.  "
  },
  {
    "id": 21691,
    "package_name": "susographql",
    "title": "Comprehensive Interface to the Survey Solutions 'GraphQL' API",
    "description": "Provides a complete suite of tools for interacting\n    with the Survey Solutions 'GraphQL' API\n    <https://demo.mysurvey.solutions/graphql/>. This package encompasses\n    all currently available queries and mutations, including the latest\n    features for map uploads. It is built on the modern 'httr2' package,\n    offering a streamlined and efficient interface without relying on\n    external 'GraphQL' client packages. In addition to core API\n    functionalities, the package includes a range of helper functions\n    designed to facilitate the use of available query filters.",
    "version": "0.1.6",
    "maintainer": "Michael Wild <mwild@worldbank.org>",
    "author": "Michael Wild [cre, aut, cph]",
    "url": "https://michael-cw.github.io/susographql/",
    "bug_reports": "https://github.com/michael-cw/susographql/issues",
    "repository": "https://cran.r-project.org/package=susographql",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "susographql Comprehensive Interface to the Survey Solutions 'GraphQL' API Provides a complete suite of tools for interacting\n    with the Survey Solutions 'GraphQL' API\n    <https://demo.mysurvey.solutions/graphql/>. This package encompasses\n    all currently available queries and mutations, including the latest\n    features for map uploads. It is built on the modern 'httr2' package,\n    offering a streamlined and efficient interface without relying on\n    external 'GraphQL' client packages. In addition to core API\n    functionalities, the package includes a range of helper functions\n    designed to facilitate the use of available query filters.  "
  },
  {
    "id": 21713,
    "package_name": "svrep",
    "title": "Tools for Creating, Updating, and Analyzing Survey Replicate\nWeights",
    "description": "Provides tools for creating and working with survey replicate weights,\n  extending functionality of the 'survey' package from Lumley (2004) <doi:10.18637/jss.v009.i08>.\n  Implements bootstrap methods for complex surveys, including the generalized survey bootstrap\n  as described by Beaumont and Patak (2012) <doi:10.1111/j.1751-5823.2011.00166.x>.\n  Methods are provided for applying nonresponse adjustments to\n  both full-sample and replicate weights as described by \n  Rust and Rao (1996) <doi:10.1177/096228029600500305>.\n  Implements methods for sample-based calibration described by Opsomer and Erciulescu (2021) \n  <https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm>.\n  Diagnostic functions are included to compare weights and weighted estimates\n  from different sets of replicate weights.",
    "version": "0.9.1",
    "maintainer": "Ben Schneider <benjamin.julius.schneider@gmail.com>",
    "author": "Ben Schneider [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0406-8470>)",
    "url": "https://bschneidr.github.io/svrep/,\nhttps://github.com/bschneidr/svrep",
    "bug_reports": "https://github.com/bschneidr/svrep/issues",
    "repository": "https://cran.r-project.org/package=svrep",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svrep Tools for Creating, Updating, and Analyzing Survey Replicate\nWeights Provides tools for creating and working with survey replicate weights,\n  extending functionality of the 'survey' package from Lumley (2004) <doi:10.18637/jss.v009.i08>.\n  Implements bootstrap methods for complex surveys, including the generalized survey bootstrap\n  as described by Beaumont and Patak (2012) <doi:10.1111/j.1751-5823.2011.00166.x>.\n  Methods are provided for applying nonresponse adjustments to\n  both full-sample and replicate weights as described by \n  Rust and Rao (1996) <doi:10.1177/096228029600500305>.\n  Implements methods for sample-based calibration described by Opsomer and Erciulescu (2021) \n  <https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm>.\n  Diagnostic functions are included to compare weights and weighted estimates\n  from different sets of replicate weights.  "
  },
  {
    "id": 21716,
    "package_name": "svyROC",
    "title": "Estimation of the ROC Curve and the AUC for Complex Survey Data",
    "description": "Estimate the receiver operating characteristic (ROC) curve, area under the curve (AUC) and optimal cut-off points for individual classification taking into account complex sampling designs when working with complex survey data. Methods implemented in this package are described in: A. Iparragirre, I. Barrio, I. Arostegui (2024) <doi:10.1002/sta4.635>; A. Iparragirre, I. Barrio, J. Aramendi, I. Arostegui (2022) <doi:10.2436/20.8080.02.121>; A. Iparragirre, I. Barrio (2024) <doi:10.1007/978-3-031-65723-8_7>.",
    "version": "1.0.0",
    "maintainer": "Amaia Iparragirre <amaia.iparragirre@ehu.eus>",
    "author": "Amaia Iparragirre [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0660-6535>),\n  Irantzu Barrio [aut],\n  Inmaculada Arostegui [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svyROC",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svyROC Estimation of the ROC Curve and the AUC for Complex Survey Data Estimate the receiver operating characteristic (ROC) curve, area under the curve (AUC) and optimal cut-off points for individual classification taking into account complex sampling designs when working with complex survey data. Methods implemented in this package are described in: A. Iparragirre, I. Barrio, I. Arostegui (2024) <doi:10.1002/sta4.635>; A. Iparragirre, I. Barrio, J. Aramendi, I. Arostegui (2022) <doi:10.2436/20.8080.02.121>; A. Iparragirre, I. Barrio (2024) <doi:10.1007/978-3-031-65723-8_7>.  "
  },
  {
    "id": 21717,
    "package_name": "svyVGAM",
    "title": "Design-Based Inference in Vector Generalised Linear Models",
    "description": "Provides inference based on the survey package for the wide range of parametric models in the 'VGAM' package.",
    "version": "1.2-17",
    "maintainer": "Thomas Lumley <t.lumley@auckland.ac.nz>",
    "author": "Thomas Lumley [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svyVGAM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svyVGAM Design-Based Inference in Vector Generalised Linear Models Provides inference based on the survey package for the wide range of parametric models in the 'VGAM' package.  "
  },
  {
    "id": 21718,
    "package_name": "svyVarSel",
    "title": "Variable Selection for Complex Survey Data",
    "description": "Fit design-based linear and logistic elastic nets with complex survey data considering the sampling design when defining training and test sets using replicate weights. Methods implemented in this package are described in: A. Iparragirre, T. Lumley, I. Barrio, I. Arostegui (2024) <doi:10.1002/sta4.578>.",
    "version": "1.0.1",
    "maintainer": "Amaia Iparragirre <amaia.iparragirre@ehu.eus>",
    "author": "Amaia Iparragirre [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-0660-6535>),\n  Thomas Lumley [aut],\n  Irantzu Barrio [aut],\n  Inmaculada Arostegui [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svyVarSel",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svyVarSel Variable Selection for Complex Survey Data Fit design-based linear and logistic elastic nets with complex survey data considering the sampling design when defining training and test sets using replicate weights. Methods implemented in this package are described in: A. Iparragirre, T. Lumley, I. Barrio, I. Arostegui (2024) <doi:10.1002/sta4.578>.  "
  },
  {
    "id": 21719,
    "package_name": "svycdiff",
    "title": "Controlled Difference Estimation for Complex Surveys",
    "description": "Estimates the population average controlled difference for a given outcome between levels of a binary treatment, exposure, or other group membership variable of interest for clustered, stratified survey samples where sample selection depends on the comparison group. Provides three methods for estimation, namely outcome modeling and two factorizations of inverse probability weighting. Under stronger assumptions, these methods estimate the causal population average treatment effect. Salerno et al., (2024) <doi:10.48550/arXiv.2406.19597>. ",
    "version": "0.2.0",
    "maintainer": "Stephen Salerno <ssalerno@fredhutch.org>",
    "author": "Stephen Salerno [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-2763-0494>),\n  Emily K Roberts [aut],\n  Tyler H McCormick [aut],\n  Fan Li [aut],\n  Bhramar Mukherjee [aut],\n  Xu Shi [aut]",
    "url": "https://github.com/salernos/svycdiff,\nhttps://salernos.github.io/svycdiff/",
    "bug_reports": "https://github.com/salernos/svycdiff/issues",
    "repository": "https://cran.r-project.org/package=svycdiff",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svycdiff Controlled Difference Estimation for Complex Surveys Estimates the population average controlled difference for a given outcome between levels of a binary treatment, exposure, or other group membership variable of interest for clustered, stratified survey samples where sample selection depends on the comparison group. Provides three methods for estimation, namely outcome modeling and two factorizations of inverse probability weighting. Under stronger assumptions, these methods estimate the causal population average treatment effect. Salerno et al., (2024) <doi:10.48550/arXiv.2406.19597>.   "
  },
  {
    "id": 21720,
    "package_name": "svycoxme",
    "title": "Mixed-Effects Cox Models for Complex Samples",
    "description": "Mixed-effect proportional hazards models for multistage stratified, \n   cluster-sampled, unequally weighted survey samples. Provides variance \n   estimation by Taylor series linearisation or replicate weights. ",
    "version": "1.0.0",
    "maintainer": "Bradley Drayton <brad.drayton@auckland.ac.nz>",
    "author": "Bradley Drayton [aut, cre, cph]",
    "url": "https://github.com/bdrayton/svycoxme",
    "bug_reports": "https://github.com/bdrayton/svycoxme/issues",
    "repository": "https://cran.r-project.org/package=svycoxme",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svycoxme Mixed-Effects Cox Models for Complex Samples Mixed-effect proportional hazards models for multistage stratified, \n   cluster-sampled, unequally weighted survey samples. Provides variance \n   estimation by Taylor series linearisation or replicate weights.   "
  },
  {
    "id": 21721,
    "package_name": "svydiags",
    "title": "Regression Model Diagnostics for Survey Data",
    "description": "Diagnostics for fixed effects linear and general linear regression models fitted with survey data. Extensions of standard diagnostics to complex survey data are included: standardized residuals, leverages, Cook's D, dfbetas, dffits, condition indexes, and variance inflation factors as found in Li and Valliant (Surv. Meth., 2009, 35(1), pp. 15-24; Jnl. of Off. Stat., 2011, 27(1), pp. 99-119; Jnl. of Off. Stat., 2015, 31(1), pp. 61-75); Liao and Valliant (Surv. Meth., 2012, 38(1), pp. 53-62; Surv. Meth., 2012, 38(2), pp. 189-202).  Variance inflation factors and condition indexes are also computed for some general linear models as described in Liao (U. Maryland thesis, 2010).",
    "version": "0.7",
    "maintainer": "Richard Valliant <valliant@umich.edu>",
    "author": "Richard Valliant [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svydiags",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svydiags Regression Model Diagnostics for Survey Data Diagnostics for fixed effects linear and general linear regression models fitted with survey data. Extensions of standard diagnostics to complex survey data are included: standardized residuals, leverages, Cook's D, dfbetas, dffits, condition indexes, and variance inflation factors as found in Li and Valliant (Surv. Meth., 2009, 35(1), pp. 15-24; Jnl. of Off. Stat., 2011, 27(1), pp. 99-119; Jnl. of Off. Stat., 2015, 31(1), pp. 61-75); Liao and Valliant (Surv. Meth., 2012, 38(1), pp. 53-62; Surv. Meth., 2012, 38(2), pp. 189-202).  Variance inflation factors and condition indexes are also computed for some general linear models as described in Liao (U. Maryland thesis, 2010).  "
  },
  {
    "id": 21722,
    "package_name": "svylme",
    "title": "Linear Mixed Models for Complex Survey Data",
    "description": "Linear mixed models for complex survey data, by pairwise composite likelihood, as described in Lumley & Huang (2023) <arXiv:2311.13048>. Supports nested and crossed random effects, and correlated random effects as in genetic models.  Allows for multistage sampling and for other designs where pairwise sampling probabilities are specified or can be calculated. ",
    "version": "1.5-1",
    "maintainer": "Thomas Lumley <t.lumley@auckland.ac.nz>",
    "author": "Thomas Lumley [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svylme",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svylme Linear Mixed Models for Complex Survey Data Linear mixed models for complex survey data, by pairwise composite likelihood, as described in Lumley & Huang (2023) <arXiv:2311.13048>. Supports nested and crossed random effects, and correlated random effects as in genetic models.  Allows for multistage sampling and for other designs where pairwise sampling probabilities are specified or can be calculated.   "
  },
  {
    "id": 21723,
    "package_name": "svytest",
    "title": "Survey Weight Diagnostic Tests",
    "description": "Provides diagnostic tests for assessing the informativeness of survey weights in regression models. Implements difference-in-coefficients tests (Hausman 1978 <doi:10.2307/1913827>; Pfeffermann 1993 <doi:10.2307/1403631>), weight-association tests (DuMouchel and Duncan 1983 <doi:10.2307/2288185>; Pfeffermann and Sverchkov 1999 <https://www.jstor.org/stable/25051118>; Pfeffermann and Sverchkov 2003 <ISBN:9780470845672>; Wu and Fuller 2005 <https://www.jstor.org/stable/27590461>), estimating equations tests (Pfeffermann and Sverchkov 2003 <ISBN:9780470845672>), and non-parametric permutation tests. Includes simulation utilities replicating Wang et al. (2023 <doi:10.1111/insr.12509>) and extensions.",
    "version": "1.1.0",
    "maintainer": "Corbin Lubianski <cnlubianski@yahoo.com>",
    "author": "Corbin Lubianski [aut, cre, cph] (ORCID:\n    <https://orcid.org/0009-0009-0547-3249>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svytest",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svytest Survey Weight Diagnostic Tests Provides diagnostic tests for assessing the informativeness of survey weights in regression models. Implements difference-in-coefficients tests (Hausman 1978 <doi:10.2307/1913827>; Pfeffermann 1993 <doi:10.2307/1403631>), weight-association tests (DuMouchel and Duncan 1983 <doi:10.2307/2288185>; Pfeffermann and Sverchkov 1999 <https://www.jstor.org/stable/25051118>; Pfeffermann and Sverchkov 2003 <ISBN:9780470845672>; Wu and Fuller 2005 <https://www.jstor.org/stable/27590461>), estimating equations tests (Pfeffermann and Sverchkov 2003 <ISBN:9780470845672>), and non-parametric permutation tests. Includes simulation utilities replicating Wang et al. (2023 <doi:10.1111/insr.12509>) and extensions.  "
  },
  {
    "id": 21724,
    "package_name": "svyweight",
    "title": "Quick and Flexible Survey Weighting",
    "description": "Quickly and flexibly calculates weights for survey data, in order to correct\n    for survey non-response or other sampling issues. Uses rake weighting, a common technique \n    also know as rim weighting or iterative proportional fitting.  This technique allows for weighting \n    on multiple variables, even when the interlocked distribution of the two\n    variables is not known. Interacts with Thomas Lumley's 'survey' package, as described in \n    Lumley, Thomas (2011, ISBN:978-1-118-21093-2). Adds additional functionality, more adaptable syntax, and error-checking\n    to the base weighting functionality in 'survey.'",
    "version": "0.1.0",
    "maintainer": "Ben Mainwaring <mainwaringb@gmail.com>",
    "author": "Ben Mainwaring [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=svyweight",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "svyweight Quick and Flexible Survey Weighting Quickly and flexibly calculates weights for survey data, in order to correct\n    for survey non-response or other sampling issues. Uses rake weighting, a common technique \n    also know as rim weighting or iterative proportional fitting.  This technique allows for weighting \n    on multiple variables, even when the interlocked distribution of the two\n    variables is not known. Interacts with Thomas Lumley's 'survey' package, as described in \n    Lumley, Thomas (2011, ISBN:978-1-118-21093-2). Adds additional functionality, more adaptable syntax, and error-checking\n    to the base weighting functionality in 'survey.'  "
  },
  {
    "id": 21794,
    "package_name": "tab",
    "title": "Create Summary Tables for Statistical Reports",
    "description": "Contains functions for creating various types of summary tables, e.g. comparing characteristics across levels of a categorical variable and summarizing fitted generalized linear models, generalized estimating equations, and Cox proportional hazards models. Functions are available to handle data from simple random samples as well as complex surveys.",
    "version": "5.1.1",
    "maintainer": "Dane R. Van Domelen <vandomed@gmail.com>",
    "author": "Dane R. Van Domelen",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tab",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tab Create Summary Tables for Statistical Reports Contains functions for creating various types of summary tables, e.g. comparing characteristics across levels of a categorical variable and summarizing fitted generalized linear models, generalized estimating equations, and Cox proportional hazards models. Functions are available to handle data from simple random samples as well as complex surveys.  "
  },
  {
    "id": 21808,
    "package_name": "tableone",
    "title": "Create 'Table 1' to Describe Baseline Characteristics with or\nwithout Propensity Score Weights",
    "description": "Creates 'Table 1', i.e., description of baseline patient\n    characteristics, which is essential in every medical research.\n    Supports both continuous and categorical variables, as well as\n    p-values and standardized mean differences. Weighted data are\n    supported via the 'survey' package.",
    "version": "0.13.2",
    "maintainer": "Kazuki Yoshida <kazukiyoshida@mail.harvard.edu>",
    "author": "Kazuki Yoshida [cre, aut] (ORCID:\n    <https://orcid.org/0000-0002-2030-3549>),\n  Alexander Bartel [ctb, aut] (ORCID:\n    <https://orcid.org/0000-0002-1280-6138>),\n  Jonathan J Chipman [ctb],\n  Justin Bohn [ctb],\n  Lucy DAgostino McGowan [ctb],\n  Malcolm Barrett [ctb],\n  Rune Haubo B Christensen [ctb],\n  gbouzill [ctb]",
    "url": "https://github.com/kaz-yos/tableone",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tableone",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tableone Create 'Table 1' to Describe Baseline Characteristics with or\nwithout Propensity Score Weights Creates 'Table 1', i.e., description of baseline patient\n    characteristics, which is essential in every medical research.\n    Supports both continuous and categorical variables, as well as\n    p-values and standardized mean differences. Weighted data are\n    supported via the 'survey' package.  "
  },
  {
    "id": 21867,
    "package_name": "tbea",
    "title": "Pre- And Post-Processing in Bayesian Evolutionary Analyses",
    "description": "Functions are provided for prior specification in divergence time\n    estimation using fossils as well as other kinds of data. It\n    provides tools for interacting with the input and output of Bayesian\n    platforms in evolutionary biology such as 'BEAST2', 'MrBayes', 'RevBayes',\n    or 'MCMCTree'.\n    It Implements a simple measure similarity between probability\n    density functions for comparing prior and\n    posterior Bayesian densities, as well as code for calculating the\n    combination of distributions using conflation of Hill (2008). Functions for estimating the\n    origination time in collections of distributions using the x-intercept (e.g., Draper and Smith, 1998) and\n    stratigraphic intervals (Marshall 2010) are also available.\n    Hill, T. 2008. \"Conflations of probability distributions\". Transactions of the American Mathematical Society, 363:3351-3372. <doi:10.48550/arXiv.0808.1808>,\n    Draper, N. R. and Smith, H. 1998. \"Applied Regression Analysis\". 1--706. Wiley Interscience, New York. <DOI:10.1002/9781118625590>,\n    Marshall, C. R. 2010. \"Using confidence intervals to quantify the uncertainty in the end-points of stratigraphic ranges\". Quantitative Methods in Paleobiology, 291--316. <DOI:10.1017/S1089332600001911>.",
    "version": "1.7.0",
    "maintainer": "Gustavo A. Ballen <gustavo.a.ballen@gmail.com>",
    "author": "Gustavo A. Ballen [aut, cre],\n  Sandra Reinales [aut]",
    "url": "https://github.com/gaballench/tbea,\nhttps://gaballench.github.io/tbea/",
    "bug_reports": "https://github.com/gaballench/tbea/issues",
    "repository": "https://cran.r-project.org/package=tbea",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tbea Pre- And Post-Processing in Bayesian Evolutionary Analyses Functions are provided for prior specification in divergence time\n    estimation using fossils as well as other kinds of data. It\n    provides tools for interacting with the input and output of Bayesian\n    platforms in evolutionary biology such as 'BEAST2', 'MrBayes', 'RevBayes',\n    or 'MCMCTree'.\n    It Implements a simple measure similarity between probability\n    density functions for comparing prior and\n    posterior Bayesian densities, as well as code for calculating the\n    combination of distributions using conflation of Hill (2008). Functions for estimating the\n    origination time in collections of distributions using the x-intercept (e.g., Draper and Smith, 1998) and\n    stratigraphic intervals (Marshall 2010) are also available.\n    Hill, T. 2008. \"Conflations of probability distributions\". Transactions of the American Mathematical Society, 363:3351-3372. <doi:10.48550/arXiv.0808.1808>,\n    Draper, N. R. and Smith, H. 1998. \"Applied Regression Analysis\". 1--706. Wiley Interscience, New York. <DOI:10.1002/9781118625590>,\n    Marshall, C. R. 2010. \"Using confidence intervals to quantify the uncertainty in the end-points of stratigraphic ranges\". Quantitative Methods in Paleobiology, 291--316. <DOI:10.1017/S1089332600001911>.  "
  },
  {
    "id": 21879,
    "package_name": "tcv",
    "title": "Determining the Number of Factors in Poisson Factor Models via\nThinning Cross-Validation",
    "description": "Implements methods for selecting the number of factors in Poisson\n  factor models, with a primary focus on Thinning Cross-Validation (TCV). The\n  TCV method is based on the 'data thinning' technique, which probabilistically\n  partitions each count observation into training and test sets while preserving\n  the underlying factor structure. The Poisson factor model is then fit on the\n  training set, and model selection is performed by comparing predictive\n  performance on the test set. This toolkit is designed for researchers working\n  with high-dimensional count data in fields such as genomics, text mining, and\n  social sciences. The data thinning methodology is detailed in Dharamshi et al.\n  (2025) <doi:10.1080/01621459.2024.2353948> and Wang et al. (2025)\n  <doi:10.1080/01621459.2025.2546577>.",
    "version": "0.1.0",
    "maintainer": "Zhijing Wang <wangzhijing@sjtu.edu.cn>",
    "author": "Zhijing Wang [aut, cre],\n  Heng Peng [aut],\n  Peirong Xu [aut]",
    "url": "https://github.com/Wangzhijingwzj/tcv",
    "bug_reports": "https://github.com/Wangzhijingwzj/tcv/issues",
    "repository": "https://cran.r-project.org/package=tcv",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tcv Determining the Number of Factors in Poisson Factor Models via\nThinning Cross-Validation Implements methods for selecting the number of factors in Poisson\n  factor models, with a primary focus on Thinning Cross-Validation (TCV). The\n  TCV method is based on the 'data thinning' technique, which probabilistically\n  partitions each count observation into training and test sets while preserving\n  the underlying factor structure. The Poisson factor model is then fit on the\n  training set, and model selection is performed by comparing predictive\n  performance on the test set. This toolkit is designed for researchers working\n  with high-dimensional count data in fields such as genomics, text mining, and\n  social sciences. The data thinning methodology is detailed in Dharamshi et al.\n  (2025) <doi:10.1080/01621459.2024.2353948> and Wang et al. (2025)\n  <doi:10.1080/01621459.2025.2546577>.  "
  },
  {
    "id": 21884,
    "package_name": "tdarec",
    "title": "A 'recipes' Extension for Persistent Homology and Its\nVectorizations",
    "description": "Topological data analytic methods in machine learning rely on\n    vectorizations of the persistence diagrams that encode persistent\n    homology, as surveyed by Ali &al (2000)\n    <doi:10.48550/arXiv.2212.09703>.  Persistent homology can be computed\n    using 'TDA' and 'ripserr' and vectorized using 'TDAvec'.  The\n    Tidymodels package collection modularizes machine learning in R for\n    straightforward extensibility; see Kuhn & Silge (2022,\n    ISBN:978-1-4920-9644-3).  These 'recipe' steps and 'dials' tuners make\n    efficient algorithms for computing and vectorizing persistence\n    diagrams available for Tidymodels workflows.",
    "version": "0.2.0",
    "maintainer": "Jason Cory Brunson <cornelioid@gmail.com>",
    "author": "Jason Cory Brunson [cre, aut]",
    "url": "https://github.com/tdaverse/tdarec",
    "bug_reports": "https://github.com/tdaverse/tdarec/issues",
    "repository": "https://cran.r-project.org/package=tdarec",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tdarec A 'recipes' Extension for Persistent Homology and Its\nVectorizations Topological data analytic methods in machine learning rely on\n    vectorizations of the persistence diagrams that encode persistent\n    homology, as surveyed by Ali &al (2000)\n    <doi:10.48550/arXiv.2212.09703>.  Persistent homology can be computed\n    using 'TDA' and 'ripserr' and vectorized using 'TDAvec'.  The\n    Tidymodels package collection modularizes machine learning in R for\n    straightforward extensibility; see Kuhn & Silge (2022,\n    ISBN:978-1-4920-9644-3).  These 'recipe' steps and 'dials' tuners make\n    efficient algorithms for computing and vectorizing persistence\n    diagrams available for Tidymodels workflows.  "
  },
  {
    "id": 21934,
    "package_name": "tergm",
    "title": "Fit, Simulate and Diagnose Models for Network Evolution Based on\nExponential-Family Random Graph Models",
    "description": "An integrated set of extensions to the 'ergm' package to analyze and simulate network evolution based on exponential-family random graph models (ERGM). 'tergm' is a part of the 'statnet' suite of packages for network analysis. See Krivitsky and Handcock (2014) <doi:10.1111/rssb.12014> and Carnegie, Krivitsky, Hunter, and Goodreau (2015) <doi:10.1080/10618600.2014.903087>.",
    "version": "4.2.2",
    "maintainer": "Pavel N. Krivitsky <pavel@statnet.org>",
    "author": "Pavel N. Krivitsky [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9101-3362>),\n  Mark S. Handcock [aut, ths],\n  David R. Hunter [ctb],\n  Steven M. Goodreau [ctb, ths],\n  Martina Morris [ctb, ths],\n  Nicole Bohme Carnegie [ctb],\n  Carter T. Butts [ctb],\n  Ayn Leslie-Cook [ctb],\n  Skye Bender-deMoll [ctb],\n  Li Wang [ctb],\n  Kirk Li [ctb],\n  Chad Klumb [ctb],\n  Adrien Le Guillou [ctb] (ORCID:\n    <https://orcid.org/0000-0002-4791-418X>)",
    "url": "https://statnet.org",
    "bug_reports": "https://github.com/statnet/tergm/issues",
    "repository": "https://cran.r-project.org/package=tergm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tergm Fit, Simulate and Diagnose Models for Network Evolution Based on\nExponential-Family Random Graph Models An integrated set of extensions to the 'ergm' package to analyze and simulate network evolution based on exponential-family random graph models (ERGM). 'tergm' is a part of the 'statnet' suite of packages for network analysis. See Krivitsky and Handcock (2014) <doi:10.1111/rssb.12014> and Carnegie, Krivitsky, Hunter, and Goodreau (2015) <doi:10.1080/10618600.2014.903087>.  "
  },
  {
    "id": 21945,
    "package_name": "test2norm",
    "title": "Normative Standards for Cognitive Tests",
    "description": "Package test2norm contains functions to generate formulas for \n    normative standards applied to cognitive tests. It takes raw test scores \n    (e.g., number of correct responses) and converts them to scaled scores and \n    demographically adjusted scores, using methods described in Heaton et al. \n    (2003) <doi:10.1016/B978-012703570-3/50010-9> & Heaton et al. (2009, \n    ISBN:9780199702800). The scaled scores are calculated as quantiles of the \n    raw test scores, scaled to have the mean of 10 and standard deviation of 3, \n    such that higher values always correspond to better performance on the test. \n    The demographically adjusted scores are calculated from the residuals of a \n    model that regresses scaled scores on demographic predictors (e.g., age). \n    The norming procedure makes use of the mfp2() function from the 'mfp2' \n    package to explore nonlinear associations between cognition and demographic \n    variables.",
    "version": "0.3.0.1",
    "maintainer": "Anya Umlauf <aumlauf@health.ucsd.edu>",
    "author": "Anya Umlauf [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=test2norm",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "test2norm Normative Standards for Cognitive Tests Package test2norm contains functions to generate formulas for \n    normative standards applied to cognitive tests. It takes raw test scores \n    (e.g., number of correct responses) and converts them to scaled scores and \n    demographically adjusted scores, using methods described in Heaton et al. \n    (2003) <doi:10.1016/B978-012703570-3/50010-9> & Heaton et al. (2009, \n    ISBN:9780199702800). The scaled scores are calculated as quantiles of the \n    raw test scores, scaled to have the mean of 10 and standard deviation of 3, \n    such that higher values always correspond to better performance on the test. \n    The demographically adjusted scores are calculated from the residuals of a \n    model that regresses scaled scores on demographic predictors (e.g., age). \n    The norming procedure makes use of the mfp2() function from the 'mfp2' \n    package to explore nonlinear associations between cognition and demographic \n    variables.  "
  },
  {
    "id": 22054,
    "package_name": "tidyEdSurvey",
    "title": "Integration of 'dplyr' and 'ggplot2' with 'EdSurvey'",
    "description": "Takes objects of class edsurvey.data.frame and converts them to a data.frame within the calling environment of 'dplyr' and 'ggplot2' functions. Additionally, for plotting with 'ggplot2', users can map aesthetics to subject scales and all plausible values will be used. This package supports student level data; to work with school or teacher level data, see '?EdSurvey::getData'.",
    "version": "0.1.4",
    "maintainer": "Paul Bailey <pbailey@air.org>",
    "author": "Paul Bailey [cre, ctb] (ORCID: <https://orcid.org/0000-0003-0989-8729>),\n  Blue Webb [aut] (ORCID: <https://orcid.org/0009-0004-4080-9864>),\n  Tom Fink [ctb] (ORCID: <https://orcid.org/0009-0003-9308-2833>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidyEdSurvey",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidyEdSurvey Integration of 'dplyr' and 'ggplot2' with 'EdSurvey' Takes objects of class edsurvey.data.frame and converts them to a data.frame within the calling environment of 'dplyr' and 'ggplot2' functions. Additionally, for plotting with 'ggplot2', users can map aesthetics to subject scales and all plausible values will be used. This package supports student level data; to work with school or teacher level data, see '?EdSurvey::getData'.  "
  },
  {
    "id": 22059,
    "package_name": "tidyREDCap",
    "title": "Helper Functions for Working with 'REDCap' Data",
    "description": "\n    Helper functions for processing 'REDCap' data in R. 'REDCap' is a \n    web-enabled application for building and managing surveys and databases \n    developed at Vanderbilt University.",
    "version": "1.1.2",
    "maintainer": "Raymond Balise <balise@miami.edu>",
    "author": "Raymond Balise [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9856-5901>),\n  Gabriel Odom [aut] (ORCID: <https://orcid.org/0000-0003-1341-4555>),\n  Anna Calderon [aut] (ORCID: <https://orcid.org/0000-0002-0139-3841>),\n  Layla Bouzoubaa [aut] (ORCID: <https://orcid.org/0000-0002-6616-0950>),\n  Wayne DeFreitas [aut] (ORCID: <https://orcid.org/0000-0002-2584-6278>),\n  Lauren Nahodyl [ctb] (ORCID: <https://orcid.org/0000-0001-6241-2615>),\n  Kyle Grealis [aut] (ORCID: <https://orcid.org/0000-0002-9223-8854>)",
    "url": "https://raymondbalise.github.io/tidyREDCap/index.html",
    "bug_reports": "https://github.com/RaymondBalise/tidyREDCap/issues",
    "repository": "https://cran.r-project.org/package=tidyREDCap",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidyREDCap Helper Functions for Working with 'REDCap' Data \n    Helper functions for processing 'REDCap' data in R. 'REDCap' is a \n    web-enabled application for building and managing surveys and databases \n    developed at Vanderbilt University.  "
  },
  {
    "id": 22061,
    "package_name": "tidySEM",
    "title": "Tidy Structural Equation Modeling",
    "description": "A tidy workflow for generating, estimating, reporting,\n    and plotting structural equation models using 'lavaan', 'OpenMx', or\n    'Mplus'. Throughout this workflow, elements of syntax, results, and graphs\n    are represented as 'tidy' data, making them easy to customize.\n    Includes functionality to estimate latent class analyses, and to plot\n    'dagitty' and 'igraph' objects.",
    "version": "0.2.9",
    "maintainer": "Caspar J. van Lissa <c.j.vanlissa@tilburguniversity.edu>",
    "author": "Caspar J. van Lissa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-0808-5024>),\n  Mauricio Garnier-Villarreal [ctb] (ORCID:\n    <https://orcid.org/0000-0002-2951-6647>),\n  Frank C Gootjes [ctb] (ORCID: <https://orcid.org/0000-0002-0639-1001>)",
    "url": "https://cjvanlissa.github.io/tidySEM/",
    "bug_reports": "https://github.com/cjvanlissa/tidySEM/issues",
    "repository": "https://cran.r-project.org/package=tidySEM",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidySEM Tidy Structural Equation Modeling A tidy workflow for generating, estimating, reporting,\n    and plotting structural equation models using 'lavaan', 'OpenMx', or\n    'Mplus'. Throughout this workflow, elements of syntax, results, and graphs\n    are represented as 'tidy' data, making them easy to customize.\n    Includes functionality to estimate latent class analyses, and to plot\n    'dagitty' and 'igraph' objects.  "
  },
  {
    "id": 22063,
    "package_name": "tidyUSDA",
    "title": "A Minimal Tool Set for Gathering USDA Quick Stat Data for\nAnalysis and Visualization",
    "description": "Provides a consistent API to pull United States Department of\n    Agriculture census and survey data from the National Agricultural\n    Statistics Service (NASS) QuickStats service.",
    "version": "0.4.1",
    "maintainer": "Brad Lindblad <me@bradlindblad.com>",
    "author": "Brad Lindblad [aut, cre],\n  Michael Thomas [ctb],\n  Alex Mindeman [ctb]",
    "url": "https://bradlindblad.github.io/tidyUSDA/,\nhttps://github.com/bradlindblad/tidyUSDA/",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidyUSDA",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidyUSDA A Minimal Tool Set for Gathering USDA Quick Stat Data for\nAnalysis and Visualization Provides a consistent API to pull United States Department of\n    Agriculture census and survey data from the National Agricultural\n    Statistics Service (NASS) QuickStats service.  "
  },
  {
    "id": 22067,
    "package_name": "tidycensus",
    "title": "Load US Census Boundary and Attribute Data as 'tidyverse' and\n'sf'-Ready Data Frames",
    "description": "An integrated R interface to several United States Census Bureau \n    APIs (<https://www.census.gov/data/developers/data-sets.html>) and the US Census Bureau's \n    geographic boundary files. Allows R users to return Census and ACS data as \n    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for mapping \n    and spatial analysis. ",
    "version": "1.7.3",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "author": "Kyle Walker [aut, cre],\n  Matt Herman [aut],\n  Kris Eberwein [ctb]",
    "url": "https://walker-data.com/tidycensus/",
    "bug_reports": "https://github.com/walkerke/tidycensus/issues",
    "repository": "https://cran.r-project.org/package=tidycensus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidycensus Load US Census Boundary and Attribute Data as 'tidyverse' and\n'sf'-Ready Data Frames An integrated R interface to several United States Census Bureau \n    APIs (<https://www.census.gov/data/developers/data-sets.html>) and the US Census Bureau's \n    geographic boundary files. Allows R users to return Census and ACS data as \n    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for mapping \n    and spatial analysis.   "
  },
  {
    "id": 22068,
    "package_name": "tidycensuskr",
    "title": "Easy Access for South Korea Census Data and Boundaries",
    "description": "\n    Census and administrative data in South Korea are a basic source of\n    quantitative and mixed-methods research for social and urban scientists.\n    This package provides a 'sf' (Pebesma et al., 2024 <doi:10.32614/CRAN.package.sf>) \n    based standardized workflow based on direct open API access to the major census and\n    administrative data sources and pre-generated files in South Korea.",
    "version": "0.2.5",
    "maintainer": "Insang Song <geoissong@snu.ac.kr>",
    "author": "Insang Song [aut, cre] (ORCID: <https://orcid.org/0000-0001-8732-3256>),\n  Sohyun Park [aut, ctb] (ORCID: <https://orcid.org/0000-0002-1231-5662>),\n  Hyesop Shin [aut, ctb] (ORCID: <https://orcid.org/0000-0003-2637-7933>)",
    "url": "https://github.com/sigmafelix/tidycensuskr,\nhttps://sigmafelix.github.io/tidycensuskr/,\nhttps://sigmafelix.r-universe.dev/tidycensuskr/",
    "bug_reports": "https://github.com/sigmafelix/tidycensuskr/issues",
    "repository": "https://cran.r-project.org/package=tidycensuskr",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidycensuskr Easy Access for South Korea Census Data and Boundaries \n    Census and administrative data in South Korea are a basic source of\n    quantitative and mixed-methods research for social and urban scientists.\n    This package provides a 'sf' (Pebesma et al., 2024 <doi:10.32614/CRAN.package.sf>) \n    based standardized workflow based on direct open API access to the major census and\n    administrative data sources and pre-generated files in South Korea.  "
  },
  {
    "id": 22107,
    "package_name": "tidypaleo",
    "title": "Tidy Tools for Paleoenvironmental Archives",
    "description": "Provides a set of functions with a common framework for age-depth model management, \n  stratigraphic visualization, and common statistical transformations. The focus of the\n  package is stratigraphic visualization, for which 'ggplot2' components are provided\n  to reproduce the scales, geometries, facets, and theme elements commonly used in\n  publication-quality stratigraphic diagrams. Helpers are also provided to reproduce\n  the exploratory statistical summaries that are frequently included on\n  stratigraphic diagrams. See Dunnington et al. (2021) <doi:10.18637/jss.v101.i07>.",
    "version": "0.1.4",
    "maintainer": "Dewey Dunnington <dewey@fishandwhistle.net>",
    "author": "Dewey Dunnington [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9415-4582>)",
    "url": "https://paleolimbot.github.io/tidypaleo/,\nhttps://github.com/paleolimbot/tidypaleo",
    "bug_reports": "https://github.com/paleolimbot/tidypaleo/issues",
    "repository": "https://cran.r-project.org/package=tidypaleo",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidypaleo Tidy Tools for Paleoenvironmental Archives Provides a set of functions with a common framework for age-depth model management, \n  stratigraphic visualization, and common statistical transformations. The focus of the\n  package is stratigraphic visualization, for which 'ggplot2' components are provided\n  to reproduce the scales, geometries, facets, and theme elements commonly used in\n  publication-quality stratigraphic diagrams. Helpers are also provided to reproduce\n  the exploratory statistical summaries that are frequently included on\n  stratigraphic diagrams. See Dunnington et al. (2021) <doi:10.18637/jss.v101.i07>.  "
  },
  {
    "id": 22131,
    "package_name": "tidytitanic",
    "title": "Dataframes Based on Titanic Passengers and Crew",
    "description": "A version of the Titanic survival data tailored for people analytics demonstrations and practice. While another package, 'titanic', reproduces the Kaggle competition files with minimal preprocessing, 'tidytitanic' combines the train and test datasets into the single dataset, 'passengers', for exploration and summary across all passengers. It also extracts personal identifiers\u2014such as first names, last names, and titles from the raw 'name' field, enabling demographic analysis. The 'passengers' data does not cover the crew, but this package also provides the more bare-bones, crew-containing datasets 'tidy_titanic' and 'flat_titanic' based on the 'Titanic' data set from 'datasets' for further exploration. This human-centered data package is designed to support exploratory data analysis, feature engineering, and pedagogical use cases.",
    "version": "0.0.1",
    "maintainer": "Evangeline Reynolds <evangeline.mae@gmail.com>",
    "author": "Evangeline Reynolds [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tidytitanic",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tidytitanic Dataframes Based on Titanic Passengers and Crew A version of the Titanic survival data tailored for people analytics demonstrations and practice. While another package, 'titanic', reproduces the Kaggle competition files with minimal preprocessing, 'tidytitanic' combines the train and test datasets into the single dataset, 'passengers', for exploration and summary across all passengers. It also extracts personal identifiers\u2014such as first names, last names, and titles from the raw 'name' field, enabling demographic analysis. The 'passengers' data does not cover the crew, but this package also provides the more bare-bones, crew-containing datasets 'tidy_titanic' and 'flat_titanic' based on the 'Titanic' data set from 'datasets' for further exploration. This human-centered data package is designed to support exploratory data analysis, feature engineering, and pedagogical use cases.  "
  },
  {
    "id": 22149,
    "package_name": "tigris",
    "title": "Load Census TIGER/Line Shapefiles",
    "description": "Download TIGER/Line shapefiles from the United States Census Bureau\n    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>)\n    and load into R as 'sf' objects.",
    "version": "2.2.1",
    "maintainer": "Kyle Walker <kyle@walker-data.com>",
    "author": "Kyle Walker [aut, cre],\n  Bob Rudis [ctb]",
    "url": "https://github.com/walkerke/tigris",
    "bug_reports": "https://github.com/walkerke/tigris/issues",
    "repository": "https://cran.r-project.org/package=tigris",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tigris Load Census TIGER/Line Shapefiles Download TIGER/Line shapefiles from the United States Census Bureau\n    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>)\n    and load into R as 'sf' objects.  "
  },
  {
    "id": 22172,
    "package_name": "timeordered",
    "title": "Time-Ordered and Time-Aggregated Network Analyses",
    "description": "Approaches for incorporating time into network analysis. Methods include: construction of time-ordered networks (temporal graphs); shortest-time and shortest-path-length analyses; resource spread calculations; data resampling and rarefaction for null model construction; reduction to time-aggregated networks with variable window sizes; application of common descriptive statistics to these networks; vector clock latencies; and plotting functionalities. The package supports <doi:10.1371/journal.pone.0020298>. ",
    "version": "1.0.3",
    "maintainer": "Benjamin Wong Blonder <benjamin.blonder@berkeley.edu>",
    "author": "Benjamin Wong Blonder [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=timeordered",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "timeordered Time-Ordered and Time-Aggregated Network Analyses Approaches for incorporating time into network analysis. Methods include: construction of time-ordered networks (temporal graphs); shortest-time and shortest-path-length analyses; resource spread calculations; data resampling and rarefaction for null model construction; reduction to time-aggregated networks with variable window sizes; application of common descriptive statistics to these networks; vector clock latencies; and plotting functionalities. The package supports <doi:10.1371/journal.pone.0020298>.   "
  },
  {
    "id": 22196,
    "package_name": "tinytiger",
    "title": "Lightweight Interface to TIGER/Line Shapefiles",
    "description": "Download geographic shapes from the United States Census Bureau \n    TIGER/Line Shapefiles <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>.\n    Functions support downloading and reading in geographic boundary data.\n    All downloads can be set up with a cache to avoid multiple downloads.\n    Data is available back to 2000 for most geographies.",
    "version": "0.0.11",
    "maintainer": "Christopher T. Kenny <ctkenny@proton.me>",
    "author": "Christopher T. Kenny [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-9386-6860>),\n  Cory McCartan [aut]",
    "url": "https://github.com/alarm-redist/tinytiger,\nhttps://alarm-redist.org/tinytiger/",
    "bug_reports": "https://github.com/alarm-redist/tinytiger/issues",
    "repository": "https://cran.r-project.org/package=tinytiger",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tinytiger Lightweight Interface to TIGER/Line Shapefiles Download geographic shapes from the United States Census Bureau \n    TIGER/Line Shapefiles <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>.\n    Functions support downloading and reading in geographic boundary data.\n    All downloads can be set up with a cache to avoid multiple downloads.\n    Data is available back to 2000 for most geographies.  "
  },
  {
    "id": 22246,
    "package_name": "tna",
    "title": "Transition Network Analysis (TNA)",
    "description": "Provides tools for performing Transition Network Analysis (TNA) to \n    study relational dynamics, including functions for building and plotting TNA \n    models, calculating centrality measures, and identifying dominant events and \n    patterns. TNA statistical techniques (e.g., bootstrapping and permutation \n    tests) ensure the reliability of observed insights and confirm that \n    identified dynamics are meaningful. See (Saqr et al., 2025) \n    <doi:10.1145/3706468.3706513> for more details on TNA.",
    "version": "1.1.0",
    "maintainer": "Sonsoles L\u00f3pez-Pernas <sonsoles.lopez@uef.fi>",
    "author": "Mohammed Saqr [aut],\n  Santtu Tikka [aut],\n  Sonsoles L\u00f3pez-Pernas [aut, cre]",
    "url": "https://github.com/sonsoleslp/tna/, http://sonsoles.me/tna/",
    "bug_reports": "https://github.com/sonsoleslp/tna/issues/",
    "repository": "https://cran.r-project.org/package=tna",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tna Transition Network Analysis (TNA) Provides tools for performing Transition Network Analysis (TNA) to \n    study relational dynamics, including functions for building and plotting TNA \n    models, calculating centrality measures, and identifying dominant events and \n    patterns. TNA statistical techniques (e.g., bootstrapping and permutation \n    tests) ensure the reliability of observed insights and confirm that \n    identified dynamics are meaningful. See (Saqr et al., 2025) \n    <doi:10.1145/3706468.3706513> for more details on TNA.  "
  },
  {
    "id": 22258,
    "package_name": "tongfen",
    "title": "Make Data Based on Different Geographies Comparable",
    "description": "Several functions to allow comparisons of data across different geographies, in particular for Canadian census data from different censuses.",
    "version": "0.3.6",
    "maintainer": "Jens von Bergmann <jens@mountainmath.ca>",
    "author": "Jens von Bergmann [aut, cre] (creator and maintainer)",
    "url": "https://github.com/mountainMath/tongfen,\nhttps://mountainmath.github.io/tongfen/",
    "bug_reports": "https://github.com/mountainMath/tongfen/issues",
    "repository": "https://cran.r-project.org/package=tongfen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tongfen Make Data Based on Different Geographies Comparable Several functions to allow comparisons of data across different geographies, in particular for Canadian census data from different censuses.  "
  },
  {
    "id": 22275,
    "package_name": "toporanga",
    "title": "Topological Sort-Based Hierarchy Inference",
    "description": "Deciphering hierarchy of agents exhibiting observable dominance events is a crucial problem in several disciplines, in particular in behavioural analysis of social animals, but also in social sciences and game theory. This package implements an inference approach based on graph theory, namely to extract the optimal acyclic subset of a weighted graph of dominance; this allows for hierarchy estimation through topological sorting. The package also contains infrastructure to investigate partially defined hierarchies and hierarchy dynamics.",
    "version": "1.0.0",
    "maintainer": "Miron B. Kursa <m@mbq.me>",
    "author": "Miron B. Kursa [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-7672-648X>)",
    "url": "https://gitlab.com/mbq/toporanga",
    "bug_reports": "https://gitlab.com/mbq/toporanga/-/issues",
    "repository": "https://cran.r-project.org/package=toporanga",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "toporanga Topological Sort-Based Hierarchy Inference Deciphering hierarchy of agents exhibiting observable dominance events is a crucial problem in several disciplines, in particular in behavioural analysis of social animals, but also in social sciences and game theory. This package implements an inference approach based on graph theory, namely to extract the optimal acyclic subset of a weighted graph of dominance; this allows for hierarchy estimation through topological sorting. The package also contains infrastructure to investigate partially defined hierarchies and hierarchy dynamics.  "
  },
  {
    "id": 22293,
    "package_name": "totalcensus",
    "title": "Extract Decennial Census and American Community Survey Data",
    "description": "Download summary files from Census Bureau <https://www2.census.gov/> \n    and extract data, in particular high resolution data at \n    block, block group, and tract level, from decennial census and \n    American Community Survey 1-year and 5-year estimates.",
    "version": "0.6.6",
    "maintainer": "Guanglai Li <liguanglai@gmail.com>",
    "author": "Guanglai Li",
    "url": "https://github.com/GL-Li/totalcensus",
    "bug_reports": "https://github.com/GL-Li/totalcensus/issues",
    "repository": "https://cran.r-project.org/package=totalcensus",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "totalcensus Extract Decennial Census and American Community Survey Data Download summary files from Census Bureau <https://www2.census.gov/> \n    and extract data, in particular high resolution data at \n    block, block group, and tract level, from decennial census and \n    American Community Survey 1-year and 5-year estimates.  "
  },
  {
    "id": 22310,
    "package_name": "tr.iatgen",
    "title": "Translate 'iatgen' Generated QSF Files",
    "description": "Automates translating the instructions of 'iatgen' generated qsf\n             (Qualtrics survey files) to other languages using either officially\n             supported or user-supplied translations (for tutorial see Santos\n             et al., 2023 <doi:10.17504/protocols.io.kxygx34jdg8j/v1>).",
    "version": "1.1.0",
    "maintainer": "Michal Kouril <Michal.Kouril@cchmc.org>",
    "author": "Michal Kouril [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4786-7934>),\n  Jo\u00e3o O. Santos [aut] (ORCID: <https://orcid.org/0000-0001-6640-126X>)",
    "url": "https://github.com/iatgen/tr.iatgen",
    "bug_reports": "https://github.com/iatgen/tr.iatgen/issues",
    "repository": "https://cran.r-project.org/package=tr.iatgen",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tr.iatgen Translate 'iatgen' Generated QSF Files Automates translating the instructions of 'iatgen' generated qsf\n             (Qualtrics survey files) to other languages using either officially\n             supported or user-supplied translations (for tutorial see Santos\n             et al., 2023 <doi:10.17504/protocols.io.kxygx34jdg8j/v1>).  "
  },
  {
    "id": 22375,
    "package_name": "treebalance",
    "title": "Computation of Tree (Im)Balance Indices",
    "description": "The aim of the 'R' package 'treebalance' is to provide functions for the computation of \n    a large variety of (im)balance indices for rooted trees. The package accompanies the book \n    ''Tree balance indices: a comprehensive survey'' by M. Fischer, L. Herbst, S. Kersting, \n    L. Kuehn and K. Wicke (2023) <ISBN: 978-3-031-39799-8>, <doi:10.1007/978-3-031-39800-1>, which gives a precise definition for the terms 'balance index' and 'imbalance index' (Chapter 4)\n    and provides an overview of the terminology in this manual (Chapter 2). For further information \n    on (im)balance indices, see also Fischer et al. (2021) <https://treebalance.wordpress.com>.\n    Considering both established and new (im)balance indices, 'treebalance' provides (among \n    others) functions for calculating the following 18 established indices and index families: the \n    average leaf depth, the B1 and B2 index, the Colijn-Plazzotta rank, the normal, corrected, \n    quadratic and equal weights Colless index, the family of Colless-like indices, the family of \n    I-based indices, the Rogers J index, the Furnas rank, the rooted quartet index, the s-shape \n    statistic, the Sackin index, the symmetry nodes index, the total cophenetic index and the \n    variance of leaf depths. Additionally, we include 9 tree shape statistics that satisfy the \n    definition of an (im)balance index but have not been thoroughly analyzed in terms of tree \n    balance in the literature yet. These are: the total internal path length, the total path length, \n    the average vertex depth, the maximum width, the modified maximum difference in widths, the \n    maximum depth, the maximum width over maximum depth, the stairs1 and the stairs2 index. \n    As input, most functions of 'treebalance' require a rooted (phylogenetic) tree in 'phylo' format \n    (as introduced in 'ape' 1.9 in November 2006). 'phylo' is used to store (phylogenetic) trees \n    with no vertices of out-degree one. For further information on the format we kindly refer the \n    reader to E. Paradis (2012) <http://ape-package.ird.fr/misc/FormatTreeR_24Oct2012.pdf>.",
    "version": "1.2.0",
    "maintainer": "Luise Kuehn <treebalanceindices@gmail.com>",
    "author": "Mareike Fischer [aut],\n  Lina Herbst [aut],\n  Sophie Kersting [aut],\n  Luise Kuehn [aut, cre],\n  Kristina Wicke [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=treebalance",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "treebalance Computation of Tree (Im)Balance Indices The aim of the 'R' package 'treebalance' is to provide functions for the computation of \n    a large variety of (im)balance indices for rooted trees. The package accompanies the book \n    ''Tree balance indices: a comprehensive survey'' by M. Fischer, L. Herbst, S. Kersting, \n    L. Kuehn and K. Wicke (2023) <ISBN: 978-3-031-39799-8>, <doi:10.1007/978-3-031-39800-1>, which gives a precise definition for the terms 'balance index' and 'imbalance index' (Chapter 4)\n    and provides an overview of the terminology in this manual (Chapter 2). For further information \n    on (im)balance indices, see also Fischer et al. (2021) <https://treebalance.wordpress.com>.\n    Considering both established and new (im)balance indices, 'treebalance' provides (among \n    others) functions for calculating the following 18 established indices and index families: the \n    average leaf depth, the B1 and B2 index, the Colijn-Plazzotta rank, the normal, corrected, \n    quadratic and equal weights Colless index, the family of Colless-like indices, the family of \n    I-based indices, the Rogers J index, the Furnas rank, the rooted quartet index, the s-shape \n    statistic, the Sackin index, the symmetry nodes index, the total cophenetic index and the \n    variance of leaf depths. Additionally, we include 9 tree shape statistics that satisfy the \n    definition of an (im)balance index but have not been thoroughly analyzed in terms of tree \n    balance in the literature yet. These are: the total internal path length, the total path length, \n    the average vertex depth, the maximum width, the modified maximum difference in widths, the \n    maximum depth, the maximum width over maximum depth, the stairs1 and the stairs2 index. \n    As input, most functions of 'treebalance' require a rooted (phylogenetic) tree in 'phylo' format \n    (as introduced in 'ape' 1.9 in November 2006). 'phylo' is used to store (phylogenetic) trees \n    with no vertices of out-degree one. For further information on the format we kindly refer the \n    reader to E. Paradis (2012) <http://ape-package.ird.fr/misc/FormatTreeR_24Oct2012.pdf>.  "
  },
  {
    "id": 22406,
    "package_name": "trigpoints",
    "title": "Data Set of Trig Points in Great Britain in British National\nGrid Coordinates",
    "description": "A complete data set of historic GB trig points in British National Grid (OSGB36) coordinate reference system. Trig points (aka triangulation stations) are fixed survey points used to improve the accuracy of map making in Great Britain during the 20th Century. Trig points are typically located on hilltops so still serve as a useful navigational aid for walkers and hikers today.",
    "version": "1.0.0",
    "maintainer": "Phil Mike Jones <philmikejones@gmail.com>",
    "author": "Phil Mike Jones [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-5173-3245>)",
    "url": "https://philmikejones.github.io/trigpoints/",
    "bug_reports": "https://github.com/philmikejones/trigpoints/issues",
    "repository": "https://cran.r-project.org/package=trigpoints",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "trigpoints Data Set of Trig Points in Great Britain in British National\nGrid Coordinates A complete data set of historic GB trig points in British National Grid (OSGB36) coordinate reference system. Trig points (aka triangulation stations) are fixed survey points used to improve the accuracy of map making in Great Britain during the 20th Century. Trig points are typically located on hilltops so still serve as a useful navigational aid for walkers and hikers today.  "
  },
  {
    "id": 22479,
    "package_name": "tsna",
    "title": "Tools for Temporal Social Network Analysis",
    "description": "Temporal SNA tools for continuous- and discrete-time longitudinal networks having vertex, edge, and attribute dynamics stored in the 'networkDynamic' format. This work was supported by grant R01HD68395 from the National Institute of Health.",
    "version": "0.3.6",
    "maintainer": "Skye Bender-deMoll <skyebend@uw.edu>",
    "author": "Skye Bender-deMoll [aut, cre],\n  Martina Morris [aut],\n  James Moody [ctb]",
    "url": "https://statnet.org/",
    "bug_reports": "https://github.com/statnet/tsna/issues",
    "repository": "https://cran.r-project.org/package=tsna",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tsna Tools for Temporal Social Network Analysis Temporal SNA tools for continuous- and discrete-time longitudinal networks having vertex, edge, and attribute dynamics stored in the 'networkDynamic' format. This work was supported by grant R01HD68395 from the National Institute of Health.  "
  },
  {
    "id": 22528,
    "package_name": "tvem",
    "title": "Time-Varying Effect Models",
    "description": "Fits time-varying effect models (TVEM). These are a kind of application of varying-coefficient models in the context of longitudinal data, allowing the strength of linear, logistic, or Poisson regression relationships to change over time.  These models are described further in Tan, Shiyko, Li, Li & Dierker (2012) <doi:10.1037/a0025814>.  We thank Kaylee Litson, Patricia Berglund, Yajnaseni Chakraborti, and Hanjoo Kim for their valuable help with testing the package and the documentation. The development of this package was part of a research project supported by National Institutes of Health grants P50 DA039838 from the National Institute of Drug Abuse and 1R01 CA229542-01 from the National Cancer Institute and the NIH Office of Behavioral and Social Science Research. Content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions mentioned above. This software is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.",
    "version": "1.4.1",
    "maintainer": "John J. Dziak <dziakj1@gmail.com>",
    "author": "John J. Dziak [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-0762-5495>),\n  Donna L. Coffman [aut] (ORCID: <https://orcid.org/0000-0001-6305-6579>),\n  Runze Li [aut] (ORCID: <https://orcid.org/0000-0002-0154-2202>),\n  Kaylee Litson [aut] (ORCID: <https://orcid.org/0000-0003-1296-4811>),\n  Yajnaseni Chakraborti [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=tvem",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "tvem Time-Varying Effect Models Fits time-varying effect models (TVEM). These are a kind of application of varying-coefficient models in the context of longitudinal data, allowing the strength of linear, logistic, or Poisson regression relationships to change over time.  These models are described further in Tan, Shiyko, Li, Li & Dierker (2012) <doi:10.1037/a0025814>.  We thank Kaylee Litson, Patricia Berglund, Yajnaseni Chakraborti, and Hanjoo Kim for their valuable help with testing the package and the documentation. The development of this package was part of a research project supported by National Institutes of Health grants P50 DA039838 from the National Institute of Drug Abuse and 1R01 CA229542-01 from the National Cancer Institute and the NIH Office of Behavioral and Social Science Research. Content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions mentioned above. This software is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.  "
  },
  {
    "id": 22578,
    "package_name": "uavRmp",
    "title": "UAV Mission Planner",
    "description": "The Unmanned Aerial Vehicle Mission Planner provides an easy to use work flow for planning autonomous obstacle avoiding surveys of ready to fly unmanned aerial vehicles to retrieve aerial or spot related data. It creates either intermediate flight control files for the DJI-Litchi supported series or ready to upload control files for the pixhawk-based flight controller. Additionally it contains some useful tools for digitizing and data manipulation.",
    "version": "0.7",
    "maintainer": "Chris Reudenbach <reudenbach@uni-marburg.de>",
    "author": "Chris Reudenbach [cre, aut],\n  Marvin Ludwig [ctb],\n  Sebastian Richter [ctb],\n  Florian Detsch [ctb],\n  Hanna Meyer [ctb]",
    "url": "https://github.com/gisma/uavRmp",
    "bug_reports": "https://github.com/gisma/uavRmp/issues",
    "repository": "https://cran.r-project.org/package=uavRmp",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "uavRmp UAV Mission Planner The Unmanned Aerial Vehicle Mission Planner provides an easy to use work flow for planning autonomous obstacle avoiding surveys of ready to fly unmanned aerial vehicles to retrieve aerial or spot related data. It creates either intermediate flight control files for the DJI-Litchi supported series or ready to upload control files for the pixhawk-based flight controller. Additionally it contains some useful tools for digitizing and data manipulation.  "
  },
  {
    "id": 22613,
    "package_name": "uncertainUCDP",
    "title": "Parametric Mixture Models for Uncertainty Estimation of\nFatalities in UCDP Conflict Data",
    "description": "Provides functions for estimating uncertainty in the number of fatalities in the Uppsala Conflict Data Program (UCDP) data. The package implements a parametric reported-value Gumbel mixture distribution that accounts for the uncertainty in the number of fatalities in the UCDP data. The model is based on information from a survey on UCDP coders and how they view the uncertainty of the number of fatalities from UCDP events. The package provides functions for making random draws of fatalities from the mixture distribution, as well as to estimate percentiles, quantiles, means, and other statistics of the distribution. Full details on the survey and estimation procedure can be found in Vesco et al (2024).",
    "version": "0.6.1",
    "maintainer": "David Randahl <david.randahl@pcr.uu.se>",
    "author": "David Randahl [cre, aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=uncertainUCDP",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "uncertainUCDP Parametric Mixture Models for Uncertainty Estimation of\nFatalities in UCDP Conflict Data Provides functions for estimating uncertainty in the number of fatalities in the Uppsala Conflict Data Program (UCDP) data. The package implements a parametric reported-value Gumbel mixture distribution that accounts for the uncertainty in the number of fatalities in the UCDP data. The model is based on information from a survey on UCDP coders and how they view the uncertainty of the number of fatalities from UCDP events. The package provides functions for making random draws of fatalities from the mixture distribution, as well as to estimate percentiles, quantiles, means, and other statistics of the distribution. Full details on the survey and estimation procedure can be found in Vesco et al (2024).  "
  },
  {
    "id": 22621,
    "package_name": "ungroup",
    "title": "Penalized Composite Link Model for Efficient Estimation of\nSmooth Distributions from Coarsely Binned Data",
    "description": "Versatile method for ungrouping histograms (binned count data) \n assuming that counts are Poisson distributed and that the underlying sequence \n on a fine grid to be estimated is smooth. The method is based on the composite \n link model and estimation is achieved by maximizing a penalized likelihood. \n Smooth detailed sequences of counts and rates are so estimated from the binned \n counts. Ungrouping binned data can be desirable for many reasons: Bins can be \n too coarse to allow for accurate analysis; comparisons can be hindered when \n different grouping approaches are used in different histograms; and the last \n interval is often wide and open-ended and, thus, covers a lot of information \n in the tail area. Age-at-death distributions grouped in age classes and \n abridged life tables are examples of binned data. Because of modest assumptions, \n the approach is suitable for many demographic and epidemiological applications. \n For a detailed description of the method and applications see \n Rizzi et al. (2015) <doi:10.1093/aje/kwv020>.",
    "version": "1.4.4",
    "maintainer": "Marius D. Pascariu <rpascariu@outlook.com>",
    "author": "Marius D. Pascariu [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-2568-6489>),\n  Silvia Rizzi [aut],\n  Jonas Schoeley [aut] (ORCID: <https://orcid.org/0000-0002-3340-8518>),\n  Maciej J. Danko [aut] (ORCID: <https://orcid.org/0000-0002-7924-9022>)",
    "url": "https://github.com/mpascariu/ungroup",
    "bug_reports": "https://github.com/mpascariu/ungroup/issues",
    "repository": "https://cran.r-project.org/package=ungroup",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "ungroup Penalized Composite Link Model for Efficient Estimation of\nSmooth Distributions from Coarsely Binned Data Versatile method for ungrouping histograms (binned count data) \n assuming that counts are Poisson distributed and that the underlying sequence \n on a fine grid to be estimated is smooth. The method is based on the composite \n link model and estimation is achieved by maximizing a penalized likelihood. \n Smooth detailed sequences of counts and rates are so estimated from the binned \n counts. Ungrouping binned data can be desirable for many reasons: Bins can be \n too coarse to allow for accurate analysis; comparisons can be hindered when \n different grouping approaches are used in different histograms; and the last \n interval is often wide and open-ended and, thus, covers a lot of information \n in the tail area. Age-at-death distributions grouped in age classes and \n abridged life tables are examples of binned data. Because of modest assumptions, \n the approach is suitable for many demographic and epidemiological applications. \n For a detailed description of the method and applications see \n Rizzi et al. (2015) <doi:10.1093/aje/kwv020>.  "
  },
  {
    "id": 22645,
    "package_name": "univOutl",
    "title": "Detection of Univariate Outliers",
    "description": "Well known outlier detection techniques in the univariate case. Methods to deal with skewed distribution are included too. The Hidiroglou-Berthelot (1986) method to search for outliers in ratios of historical data is implemented as well. When available, survey weights can be used in outliers detection.",
    "version": "0.4",
    "maintainer": "Marcello D'Orazio <mdo.statmatch@gmail.com>",
    "author": "Marcello D'Orazio",
    "url": "https://github.com/marcellodo/univOutl",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=univOutl",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "univOutl Detection of Univariate Outliers Well known outlier detection techniques in the univariate case. Methods to deal with skewed distribution are included too. The Hidiroglou-Berthelot (1986) method to search for outliers in ratios of historical data is implemented as well. When available, survey weights can be used in outliers detection.  "
  },
  {
    "id": 22651,
    "package_name": "unmarked",
    "title": "Models for Data from Unmarked Animals",
    "description": "Fits hierarchical models of animal abundance and occurrence to data collected using survey methods such as point counts, site occupancy sampling, distance sampling, removal sampling, and double observer sampling. Parameters governing the state and observation processes can be modeled as functions of covariates. References: Kellner et al. (2023) <doi:10.1111/2041-210X.14123>, Fiske and Chandler (2011) <doi:10.18637/jss.v043.i10>.",
    "version": "1.5.1",
    "maintainer": "Ken Kellner <contact@kenkellner.com>",
    "author": "Richard Chandler [aut],\n  Ken Kellner [cre, aut],\n  Ian Fiske [aut],\n  David Miller [aut],\n  Andy Royle [aut],\n  Jeff Hostetler [aut],\n  Rebecca Hutchinson [aut],\n  Adam Smith [aut],\n  Lea Pautrel [aut],\n  Marc Kery [ctb],\n  Mike Meredith [ctb],\n  Auriel Fournier [ctb],\n  Ariel Muldoon [ctb],\n  Chris Baker [ctb]",
    "url": "https://groups.google.com/d/forum/unmarked,\nhttps://ecoverseR.github.io/unmarked/",
    "bug_reports": "https://github.com/ecoverseR/unmarked/issues",
    "repository": "https://cran.r-project.org/package=unmarked",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "unmarked Models for Data from Unmarked Animals Fits hierarchical models of animal abundance and occurrence to data collected using survey methods such as point counts, site occupancy sampling, distance sampling, removal sampling, and double observer sampling. Parameters governing the state and observation processes can be modeled as functions of covariates. References: Kellner et al. (2023) <doi:10.1111/2041-210X.14123>, Fiske and Chandler (2011) <doi:10.18637/jss.v043.i10>.  "
  },
  {
    "id": 22682,
    "package_name": "us.census.geoheader",
    "title": "US 2010 Census SF2 Geographic Header Summary Levels 010-050",
    "description": "A simple interface to the Geographic Header information\n  from the \"2010 US Census Summary File 2\".  The entire Summary File 2\n  is described at\n  <https://catalog.data.gov/dataset/census-2000-summary-file-2-sf2>,\n  but note that this package only provides access to parts of the\n  geographic header ('geoheader') of the file.  In particular, only\n  the first 101 columns of the geoheader are included and, more\n  importantly, only rows with summary levels (SUMLEVs) 010 through 050\n  (nation down through county level) are included.  In addition to\n  access to (part of) the geoheader, the package also provides a\n  decode function that takes a column name and value and, for certain\n  columns, returns \"the meaning\" of that column (i.e., a \"SUMLEV\"\n  value of 40 means \"State\"); without a value, the decode function\n  attempts to describe the column itself.",
    "version": "1.0.2",
    "maintainer": "Greg Minshall <minshall@acm.org>",
    "author": "Greg Minshall [aut, cph, cre],\n  United States Census Bureau [dtc]",
    "url": "https://gitlab.com/minshall/us-census-geoheader",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=us.census.geoheader",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "us.census.geoheader US 2010 Census SF2 Geographic Header Summary Levels 010-050 A simple interface to the Geographic Header information\n  from the \"2010 US Census Summary File 2\".  The entire Summary File 2\n  is described at\n  <https://catalog.data.gov/dataset/census-2000-summary-file-2-sf2>,\n  but note that this package only provides access to parts of the\n  geographic header ('geoheader') of the file.  In particular, only\n  the first 101 columns of the geoheader are included and, more\n  importantly, only rows with summary levels (SUMLEVs) 010 through 050\n  (nation down through county level) are included.  In addition to\n  access to (part of) the geoheader, the package also provides a\n  decode function that takes a column name and value and, for certain\n  columns, returns \"the meaning\" of that column (i.e., a \"SUMLEV\"\n  value of 40 means \"State\"); without a value, the decode function\n  attempts to describe the column itself.  "
  },
  {
    "id": 22683,
    "package_name": "usa",
    "title": "Updated US State Facts and Figures",
    "description": "Updated versions of the 1970's \"US State Facts and Figures\"\n    objects from the 'datasets' package included with R. The new data is\n    compiled from a number of sources, primarily from United States Census\n    Bureau or the relevant federal agency.",
    "version": "0.1.3",
    "maintainer": "Kiernan Nicholls <k5cents@gmail.com>",
    "author": "Kiernan Nicholls [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0002-9229-7897>)",
    "url": "https://k5cents.github.io/usa/, https://github.com/k5cents/usa",
    "bug_reports": "https://github.com/k5cents/usa/issues",
    "repository": "https://cran.r-project.org/package=usa",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "usa Updated US State Facts and Figures Updated versions of the 1970's \"US State Facts and Figures\"\n    objects from the 'datasets' package included with R. The new data is\n    compiled from a number of sources, primarily from United States Census\n    Bureau or the relevant federal agency.  "
  },
  {
    "id": 22688,
    "package_name": "usdata",
    "title": "Data on the States and Counties of the United States",
    "description": "Demographic data on the United States at the county and state levels spanning multiple years.",
    "version": "0.3.1",
    "maintainer": "Mine \u00c7etinkaya-Rundel <cetinkaya.mine@gmail.com>",
    "author": "Mine \u00c7etinkaya-Rundel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6452-2420>),\n  David Diez [aut],\n  Leah Dorazio [aut]",
    "url": "https://github.com/OpenIntroStat/usdata,\nhttps://openintrostat.github.io/usdata/",
    "bug_reports": "https://github.com/OpenIntroStat/usdata/issues",
    "repository": "https://cran.r-project.org/package=usdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "usdata Data on the States and Counties of the United States Demographic data on the United States at the county and state levels spanning multiple years.  "
  },
  {
    "id": 22702,
    "package_name": "usmapdata",
    "title": "Mapping Data for 'usmap' Package",
    "description": "Provides a container for data used by the 'usmap' package.\n    The data used by 'usmap' has been extracted into this package so that the\n    file size of the 'usmap' package can be reduced greatly. The data in this\n    package will be updated roughly once per year as new map data files are\n    provided by the US Census Bureau.",
    "version": "1.0.0",
    "maintainer": "Paolo Di Lorenzo <paolo@dilorenzo.org>",
    "author": "Paolo Di Lorenzo [aut, cre]",
    "url": "https://usmap.dev",
    "bug_reports": "https://github.com/pdil/usmapdata/issues",
    "repository": "https://cran.r-project.org/package=usmapdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "usmapdata Mapping Data for 'usmap' Package Provides a container for data used by the 'usmap' package.\n    The data used by 'usmap' has been extracted into this package so that the\n    file size of the 'usmap' package can be reduced greatly. The data in this\n    package will be updated roughly once per year as new map data files are\n    provided by the US Census Bureau.  "
  },
  {
    "id": 22723,
    "package_name": "vacalibration",
    "title": "Calibration of Computer-Coded Verbal Autopsy Algorithm",
    "description": "Calibrates cause-specific mortality fractions (CSMF) estimates generated by computer-coded verbal autopsy (CCVA) algorithms from WHO-standardized verbal autopsy (VA) survey data. It leverages data from the multi-country Child Health and Mortality Prevention Surveillance (CHAMPS) project <https://champshealth.org/>, which determines gold standard causes of death via Minimally Invasive Tissue Sampling (MITS). By modeling the CHAMPS data using the misclassification matrix modeling framework proposed in Pramanik et al. (2025, <doi:10.1214/24-AOAS2006>), the package includes an inventory of 48 uncertainty-quantified misclassification matrices for three CCVA algorithms (EAVA, InSilicoVA, InterVA), two age groups (neonates aged 0-27 days and children aged 1-59 months), and eight \"countries\" (seven countries in CHAMPS -- Bangladesh, Ethiopia, Kenya, Mali, Mozambique, Sierra Leone, South Africa -- and an estimate for countries not in CHAMPS). Given a VA-only data for an age group, CCVA algorithm, and country, the package uses the corresponding uncertainty-quantified misclassification matrix estimates as an informative prior, and utilizes the modular VA-calibration to produce calibrated CSMF estimates. It also supports ensemble calibration when VA-only data are provided for multiple algorithms. More generally, the package can be applied to calibrate predictions from a discrete classifier (or ensemble of classifiers) utilizing user-provided fixed or uncertainty-quantified misclassification matrices. This work is supported by the Bill and Melinda Gates Foundation Grant INV-034842.",
    "version": "2.0",
    "maintainer": "Sandipan Pramanik <sandy.pramanik@gmail.com>",
    "author": "Sandipan Pramanik [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-7196-155X>),\n  Emily Wilson [aut],\n  Jacob Fiksel [aut],\n  Brian Gilbert [aut],\n  Abhirup Datta [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vacalibration",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vacalibration Calibration of Computer-Coded Verbal Autopsy Algorithm Calibrates cause-specific mortality fractions (CSMF) estimates generated by computer-coded verbal autopsy (CCVA) algorithms from WHO-standardized verbal autopsy (VA) survey data. It leverages data from the multi-country Child Health and Mortality Prevention Surveillance (CHAMPS) project <https://champshealth.org/>, which determines gold standard causes of death via Minimally Invasive Tissue Sampling (MITS). By modeling the CHAMPS data using the misclassification matrix modeling framework proposed in Pramanik et al. (2025, <doi:10.1214/24-AOAS2006>), the package includes an inventory of 48 uncertainty-quantified misclassification matrices for three CCVA algorithms (EAVA, InSilicoVA, InterVA), two age groups (neonates aged 0-27 days and children aged 1-59 months), and eight \"countries\" (seven countries in CHAMPS -- Bangladesh, Ethiopia, Kenya, Mali, Mozambique, Sierra Leone, South Africa -- and an estimate for countries not in CHAMPS). Given a VA-only data for an age group, CCVA algorithm, and country, the package uses the corresponding uncertainty-quantified misclassification matrix estimates as an informative prior, and utilizes the modular VA-calibration to produce calibrated CSMF estimates. It also supports ensemble calibration when VA-only data are provided for multiple algorithms. More generally, the package can be applied to calibrate predictions from a discrete classifier (or ensemble of classifiers) utilizing user-provided fixed or uncertainty-quantified misclassification matrices. This work is supported by the Bill and Melinda Gates Foundation Grant INV-034842.  "
  },
  {
    "id": 22756,
    "package_name": "vannstats",
    "title": "Simplified Statistical Procedures for Social Sciences",
    "description": "Simplifies functions assess normality for bivariate and multivariate statistical techniques. Includes functions designed to replicate plots and tables that would result from similar calls in 'SPSS', including hst(), box(), qq(), tab(), cormat(), and residplot(). Also includes simplified formulae, such as mode(), scatter(), p.corr(), ow.anova(), and rm.anova().",
    "version": "1.5.4.07",
    "maintainer": "Burrel Vann Jr <bvannjr@sdsu.edu>",
    "author": "Burrel Vann Jr [aut, cre] (ORCID:\n    <https://orcid.org/0000-0003-3066-5815>)",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vannstats",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vannstats Simplified Statistical Procedures for Social Sciences Simplifies functions assess normality for bivariate and multivariate statistical techniques. Includes functions designed to replicate plots and tables that would result from similar calls in 'SPSS', including hst(), box(), qq(), tab(), cormat(), and residplot(). Also includes simplified formulae, such as mode(), scatter(), p.corr(), ow.anova(), and rm.anova().  "
  },
  {
    "id": 22767,
    "package_name": "vardpoor",
    "title": "Variance Estimation for Sample Surveys by the Ultimate Cluster\nMethod",
    "description": "Generation of domain variables, linearization of several non-linear population statistics (the ratio of two totals, weighted income percentile, relative median income ratio, at-risk-of-poverty rate, at-risk-of-poverty threshold, Gini coefficient, gender pay gap, the aggregate replacement ratio, the relative median income ratio, median income below at-risk-of-poverty gap, income quintile share ratio, relative median at-risk-of-poverty gap), computation of regression residuals in case of weight calibration, variance estimation of sample surveys by the ultimate cluster method (Hansen, Hurwitz and Madow, Sample Survey Methods And Theory, vol. I: Methods and Applications; vol. II: Theory. 1953, New York: John Wiley and Sons), variance estimation for longitudinal, cross-sectional measures and measures of change for single and multistage stage cluster sampling designs (Berger, Y. G., 2015, <doi:10.1111/rssa.12116>). Several other precision measures are derived - standard error, the coefficient of variation, the margin of error, confidence interval, design effect.",
    "version": "0.20.1",
    "maintainer": "Martins Liberts <martins.liberts@csb.gov.lv>",
    "author": "Juris Breidaks [aut],\n  Martins Liberts [aut, cre],\n  Santa Ivanova [aut],\n  Aleksis Jursevskis [ctb],\n  Anthony Damico [ctb],\n  Central Statistical Bureau of Latvia [cph, fnd]",
    "url": "https://csblatvia.github.io/vardpoor/,\nhttps://github.com/CSBLatvia/vardpoor/",
    "bug_reports": "https://github.com/CSBLatvia/vardpoor/issues/",
    "repository": "https://cran.r-project.org/package=vardpoor",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vardpoor Variance Estimation for Sample Surveys by the Ultimate Cluster\nMethod Generation of domain variables, linearization of several non-linear population statistics (the ratio of two totals, weighted income percentile, relative median income ratio, at-risk-of-poverty rate, at-risk-of-poverty threshold, Gini coefficient, gender pay gap, the aggregate replacement ratio, the relative median income ratio, median income below at-risk-of-poverty gap, income quintile share ratio, relative median at-risk-of-poverty gap), computation of regression residuals in case of weight calibration, variance estimation of sample surveys by the ultimate cluster method (Hansen, Hurwitz and Madow, Sample Survey Methods And Theory, vol. I: Methods and Applications; vol. II: Theory. 1953, New York: John Wiley and Sons), variance estimation for longitudinal, cross-sectional measures and measures of change for single and multistage stage cluster sampling designs (Berger, Y. G., 2015, <doi:10.1111/rssa.12116>). Several other precision measures are derived - standard error, the coefficient of variation, the margin of error, confidence interval, design effect.  "
  },
  {
    "id": 22784,
    "package_name": "vaxpmx",
    "title": "Vaccines Pharmacometrics",
    "description": "Estimate vaccine efficacy (VE) using immunogenicity data.\n    The inclusion of immunogenicity data in regression models can increase precision in VE. \n    The methods are described in the publications \"Elucidating vaccine efficacy using a correlate of protection, demographics, and logistic regression\" and \"Improving precision of vaccine efficacy evaluation using immune correlate data in time-to-event models\" by Julie Dudasova, Zdenek Valenta, and Jeffrey R. Sachs (2024).",
    "version": "0.0.6",
    "maintainer": "Julie Dudasova (MSD) <julie.dudasova@merck.com>",
    "author": "Julie Dudasova (MSD) [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=vaxpmx",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vaxpmx Vaccines Pharmacometrics Estimate vaccine efficacy (VE) using immunogenicity data.\n    The inclusion of immunogenicity data in regression models can increase precision in VE. \n    The methods are described in the publications \"Elucidating vaccine efficacy using a correlate of protection, demographics, and logistic regression\" and \"Improving precision of vaccine efficacy evaluation using immune correlate data in time-to-event models\" by Julie Dudasova, Zdenek Valenta, and Jeffrey R. Sachs (2024).  "
  },
  {
    "id": 22897,
    "package_name": "vivainsights",
    "title": "Analyze and Visualize Data from 'Microsoft Viva Insights'",
    "description": "Provides a versatile range of functions, including exploratory data analysis, time-series analysis, organizational network analysis, and data validation, whilst at the same time implements a set of best practices in analyzing and visualizing data specific to 'Microsoft Viva Insights'.",
    "version": "0.7.0",
    "maintainer": "Martin Chan <martin.chan@microsoft.com>",
    "author": "Martin Chan [aut, cre],\n  Carlos Morales [aut]",
    "url": "https://microsoft.github.io/vivainsights/",
    "bug_reports": "https://github.com/microsoft/vivainsights/issues/",
    "repository": "https://cran.r-project.org/package=vivainsights",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "vivainsights Analyze and Visualize Data from 'Microsoft Viva Insights' Provides a versatile range of functions, including exploratory data analysis, time-series analysis, organizational network analysis, and data validation, whilst at the same time implements a set of best practices in analyzing and visualizing data specific to 'Microsoft Viva Insights'.  "
  },
  {
    "id": 22912,
    "package_name": "voiceR",
    "title": "Voice Analytics for Social Scientists",
    "description": "Simplifies and largely automates practical voice analytics for social science research. This package offers an accessible and easy-to-use interface, including an interactive Shiny app, that simplifies the processing, extraction, analysis, and reporting of voice recording data in the behavioral and social sciences. The package includes batch processing capabilities to read and analyze multiple voice files in parallel, automates the extraction of key vocal features for further analysis, and automatically generates APA formatted reports for typical between-group comparisons in experimental social science research. A more extensive methodological introduction that inspired the development of the 'voiceR' package is provided in Hildebrand et al. 2020 <doi:10.1016/j.jbusres.2020.09.020>.  ",
    "version": "0.1.0",
    "maintainer": "Francesc Busquet <francesc.busquet@unisg.ch>",
    "author": "Francesc Busquet [aut, cre],\n  Christian Hildebrand [aut]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=voiceR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "voiceR Voice Analytics for Social Scientists Simplifies and largely automates practical voice analytics for social science research. This package offers an accessible and easy-to-use interface, including an interactive Shiny app, that simplifies the processing, extraction, analysis, and reporting of voice recording data in the behavioral and social sciences. The package includes batch processing capabilities to read and analyze multiple voice files in parallel, automates the extraction of key vocal features for further analysis, and automatically generates APA formatted reports for typical between-group comparisons in experimental social science research. A more extensive methodological introduction that inspired the development of the 'voiceR' package is provided in Hildebrand et al. 2020 <doi:10.1016/j.jbusres.2020.09.020>.    "
  },
  {
    "id": 22918,
    "package_name": "volker",
    "title": "High-Level Functions for Tabulating, Charting and Reporting\nSurvey Data",
    "description": "Craft polished tables and plots in Markdown reports. \n             Simply choose whether to treat your data as counts or metrics, \n             and the package will automatically generate well-designed default tables and plots for you.\n             Boiled down to the basics, with labeling features and simple interactive reports.\n             All functions are 'tidyverse' compatible.",
    "version": "3.2.0",
    "maintainer": "Jakob J\u00fcnger <jakob.juenger@uni-muenster.de>",
    "author": "Jakob J\u00fcnger [aut, cre, cph] (ORCID:\n    <https://orcid.org/0000-0003-1860-6695>),\n  Henrieke Kotthoff [aut, ctb],\n  Chantal G\u00e4rtner [ctb] (ORCID: <https://orcid.org/0000-0002-3653-6013>)",
    "url": "https://github.com/strohne/volker,\nhttps://strohne.github.io/volker/",
    "bug_reports": "https://github.com/strohne/volker/issues",
    "repository": "https://cran.r-project.org/package=volker",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "volker High-Level Functions for Tabulating, Charting and Reporting\nSurvey Data Craft polished tables and plots in Markdown reports. \n             Simply choose whether to treat your data as counts or metrics, \n             and the package will automatically generate well-designed default tables and plots for you.\n             Boiled down to the basics, with labeling features and simple interactive reports.\n             All functions are 'tidyverse' compatible.  "
  },
  {
    "id": 22990,
    "package_name": "washdata",
    "title": "Urban Water and Sanitation Survey Dataset",
    "description": "Urban water and sanitation survey dataset collected by Water and\n    Sanitation for the Urban Poor (WSUP) with technical support from \n    Valid International. These citywide surveys have been collecting data \n    allowing water and sanitation service levels across the entire city to be \n    characterised, while also allowing more detailed data to be collected in \n    areas of the city of particular interest. These surveys are intended to \n    generate useful information for others working in the water and sanitation\n    sector. Current release version includes datasets collected from a survey \n    conducted in Dhaka, Bangladesh in March 2017. This survey in Dhaka is one of \n    a series of surveys to be conducted by WSUP in various\n    cities in which they operate including Accra, Ghana; Nakuru, Kenya; \n    Antananarivo, Madagascar; Maputo, Mozambique; and, Lusaka, Zambia. This \n    package will be updated once the surveys in other cities are completed and \n    datasets have been made available.",
    "version": "0.1.4",
    "maintainer": "Ernest Guevarra <ernestgmd@gmail.com>",
    "author": "Ernest Guevarra [aut, cre],\n  Valid International [cph],\n  Water and Sanitation for the Urban Poor [cph]",
    "url": "https://github.com/katilingban/washdata/,\nhttps://katilingban.io/washdata/",
    "bug_reports": "https://github.com/katilingban/washdata/issues",
    "repository": "https://cran.r-project.org/package=washdata",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "washdata Urban Water and Sanitation Survey Dataset Urban water and sanitation survey dataset collected by Water and\n    Sanitation for the Urban Poor (WSUP) with technical support from \n    Valid International. These citywide surveys have been collecting data \n    allowing water and sanitation service levels across the entire city to be \n    characterised, while also allowing more detailed data to be collected in \n    areas of the city of particular interest. These surveys are intended to \n    generate useful information for others working in the water and sanitation\n    sector. Current release version includes datasets collected from a survey \n    conducted in Dhaka, Bangladesh in March 2017. This survey in Dhaka is one of \n    a series of surveys to be conducted by WSUP in various\n    cities in which they operate including Accra, Ghana; Nakuru, Kenya; \n    Antananarivo, Madagascar; Maputo, Mozambique; and, Lusaka, Zambia. This \n    package will be updated once the surveys in other cities are completed and \n    datasets have been made available.  "
  },
  {
    "id": 23018,
    "package_name": "wcde",
    "title": "Download Data from the Wittgenstein Centre Human Capital Data\nExplorer",
    "description": "Download and plot education specific demographic data from the Wittgenstein Centre for Demography and Human Capital Data Explorer <http://dataexplorer.wittgensteincentre.org/>.",
    "version": "0.0.7",
    "maintainer": "Guy J. Abel <g.j.abel@gmail.com>",
    "author": "Guy J. Abel [aut, cre, ctb] (ORCID:\n    <https://orcid.org/0000-0002-4893-5687>),\n  Samir K.C. [ctb] (ORCID: <https://orcid.org/0000-0002-5213-9181>),\n  Michaela Potancokova [ctb],\n  Claudia Reiter [ctb] (ORCID: <https://orcid.org/0000-0002-1485-3851>),\n  Andrea Tamburini [ctb],\n  Dilek Yildiz [ctb] (ORCID: <https://orcid.org/0000-0001-6192-0634>)",
    "url": "https://guyabel.github.io/wcde/",
    "bug_reports": "https://github.com/guyabel/wcde/issues/",
    "repository": "https://cran.r-project.org/package=wcde",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wcde Download Data from the Wittgenstein Centre Human Capital Data\nExplorer Download and plot education specific demographic data from the Wittgenstein Centre for Demography and Human Capital Data Explorer <http://dataexplorer.wittgensteincentre.org/>.  "
  },
  {
    "id": 23057,
    "package_name": "weights",
    "title": "Weighting and Weighted Statistics",
    "description": "Provides a variety of functions for producing simple weighted statistics, such as weighted Pearson's correlations, partial correlations, Chi-Squared statistics, histograms, and t-tests as well as simple weighting graphics including weighted histograms, box plots, bar plots, and violin plots.  Also includes software for quickly recoding survey data and plotting estimates from interaction terms in regressions (and multiply imputed regressions) both with and without weights and summarizing various types of regressions. Some portions of this package were assisted by AI-generated suggestions using OpenAI's GPT model, with human review and integration.",
    "version": "1.1.2",
    "maintainer": "Josh Pasek <josh@joshpasek.com>",
    "author": "Josh Pasek [aut, cre] (ORCID: <https://orcid.org/0000-0001-6099-6119>),\n  Alex Tahk [ctb] (ORCID: <https://orcid.org/0000-0001-7895-9420>),\n  Gene Culter [ctb],\n  Marcus Schwemmle [ctb],\n  Some code modified from R-core [ctb]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=weights",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "weights Weighting and Weighted Statistics Provides a variety of functions for producing simple weighted statistics, such as weighted Pearson's correlations, partial correlations, Chi-Squared statistics, histograms, and t-tests as well as simple weighting graphics including weighted histograms, box plots, bar plots, and violin plots.  Also includes software for quickly recoding survey data and plotting estimates from interaction terms in regressions (and multiply imputed regressions) both with and without weights and summarizing various types of regressions. Some portions of this package were assisted by AI-generated suggestions using OpenAI's GPT model, with human review and integration.  "
  },
  {
    "id": 23085,
    "package_name": "whitebox",
    "title": "'WhiteboxTools' R Frontend",
    "description": "An R frontend for the 'WhiteboxTools' library, which is an advanced geospatial data analysis platform developed by Prof. John Lindsay at the University of Guelph's Geomorphometry and Hydrogeomatics Research Group. 'WhiteboxTools' can be used to perform common geographical information systems (GIS) analysis operations, such as cost-distance analysis, distance buffering, and raster reclassification. Remote sensing and image processing tasks include image enhancement (e.g. panchromatic sharpening, contrast adjustments), image mosaicing, numerous filtering operations, simple classification (k-means), and common image transformations. 'WhiteboxTools' also contains advanced tooling for spatial hydrological analysis (e.g. flow-accumulation, watershed delineation, stream network analysis, sink removal), terrain analysis (e.g. common terrain indices such as slope, curvatures, wetness index, hillshading; hypsometric analysis; multi-scale topographic position analysis), and LiDAR data processing. Suggested citation: Lindsay (2016) <doi:10.1016/j.cageo.2016.07.003>.",
    "version": "2.4.3",
    "maintainer": "Andrew Brown <brown.andrewg@gmail.com>",
    "author": "Qiusheng Wu [aut],\n  Andrew Brown [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4565-533X>)",
    "url": "https://whiteboxr.gishub.org/,\nhttps://github.com/opengeos/whiteboxR",
    "bug_reports": "https://github.com/opengeos/whiteboxR/issues",
    "repository": "https://cran.r-project.org/package=whitebox",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "whitebox 'WhiteboxTools' R Frontend An R frontend for the 'WhiteboxTools' library, which is an advanced geospatial data analysis platform developed by Prof. John Lindsay at the University of Guelph's Geomorphometry and Hydrogeomatics Research Group. 'WhiteboxTools' can be used to perform common geographical information systems (GIS) analysis operations, such as cost-distance analysis, distance buffering, and raster reclassification. Remote sensing and image processing tasks include image enhancement (e.g. panchromatic sharpening, contrast adjustments), image mosaicing, numerous filtering operations, simple classification (k-means), and common image transformations. 'WhiteboxTools' also contains advanced tooling for spatial hydrological analysis (e.g. flow-accumulation, watershed delineation, stream network analysis, sink removal), terrain analysis (e.g. common terrain indices such as slope, curvatures, wetness index, hillshading; hypsometric analysis; multi-scale topographic position analysis), and LiDAR data processing. Suggested citation: Lindsay (2016) <doi:10.1016/j.cageo.2016.07.003>.  "
  },
  {
    "id": 23089,
    "package_name": "whitewater",
    "title": "Parallel Processing Options for Package 'dataRetrieval'",
    "description": "Provides methods for retrieving United States Geological Survey (USGS) water data using sequential and parallel processing (Bengtsson, 2022 <doi:10.32614/RJ-2021-048>). In addition to parallel methods, data wrangling and additional statistical attributes are provided. ",
    "version": "0.1.3",
    "maintainer": "Josh Erickson <joshualerickson@gmail.com>",
    "author": "Josh Erickson [aut, cre, cph]",
    "url": "https://github.com/joshualerickson/whitewater/,\nhttps://joshualerickson.github.io/whitewater/",
    "bug_reports": "https://github.com/joshualerickson/whitewater/issues/",
    "repository": "https://cran.r-project.org/package=whitewater",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "whitewater Parallel Processing Options for Package 'dataRetrieval' Provides methods for retrieving United States Geological Survey (USGS) water data using sequential and parallel processing (Bengtsson, 2022 <doi:10.32614/RJ-2021-048>). In addition to parallel methods, data wrangling and additional statistical attributes are provided.   "
  },
  {
    "id": 23091,
    "package_name": "whomds",
    "title": "Calculate Results from WHO Model Disability Survey Data",
    "description": "The Model Disability Survey (MDS) <https://www.who.int/activities/collection-of-data-on-disability> is a World Health Organization (WHO) general population survey\n    instrument to assess the distribution of disability within a country or \n    region, grounded in the International Classification of Functioning, \n    Disability and Health <https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health>. This package provides fit-for-purpose functions \n    for calculating and presenting the results from this survey, as used by \n    the WHO. The package primarily provides functions for implementing\n    Rasch Analysis (see Andrich (2011) <doi:10.1586/erp.11.59>) to\n    calculate a metric scale for disability.",
    "version": "1.1.1",
    "maintainer": "Lindsay Lee <lindsayevanslee@gmail.com>",
    "author": "Lindsay Lee [aut, cre],\n  Carolina Fellinghauer [ctb],\n  World Health Organization [cph]",
    "url": "https://github.com/lindsayevanslee/whomds",
    "bug_reports": "https://github.com/lindsayevanslee/whomds/issues",
    "repository": "https://cran.r-project.org/package=whomds",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "whomds Calculate Results from WHO Model Disability Survey Data The Model Disability Survey (MDS) <https://www.who.int/activities/collection-of-data-on-disability> is a World Health Organization (WHO) general population survey\n    instrument to assess the distribution of disability within a country or \n    region, grounded in the International Classification of Functioning, \n    Disability and Health <https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health>. This package provides fit-for-purpose functions \n    for calculating and presenting the results from this survey, as used by \n    the WHO. The package primarily provides functions for implementing\n    Rasch Analysis (see Andrich (2011) <doi:10.1586/erp.11.59>) to\n    calculate a metric scale for disability.  "
  },
  {
    "id": 23183,
    "package_name": "wru",
    "title": "Who are You? Bayesian Prediction of Racial Category Using\nSurname, First Name, Middle Name, and Geolocation",
    "description": "Predicts individual race/ethnicity using surname, first name,\n    middle name, geolocation, and other attributes, such as gender and\n    age. The method utilizes Bayes' Rule (with optional measurement error\n    correction) to compute the posterior probability of each racial\n    category for any given individual. The package implements methods\n    described in Imai and Khanna (2016) \"Improving Ecological Inference by\n    Predicting Individual Ethnicity from Voter Registration Records\"\n    Political Analysis <DOI:10.1093/pan/mpw001> and Imai, Olivella, and\n    Rosenman (2022) \"Addressing census data problems in race imputation\n    via fully Bayesian Improved Surname Geocoding and name supplements\"\n    <DOI:10.1126/sciadv.adc9824>.  The package also incorporates the data\n    described in Rosenman, Olivella, and Imai (2023) \"Race and ethnicity\n    data for first, middle, and surnames\"\n    <DOI:10.1038/s41597-023-02202-2>.",
    "version": "3.0.3",
    "maintainer": "Brandon Bertelsen <brandon@bertelsen.ca>",
    "author": "Kabir Khanna [aut],\n  Brandon Bertelsen [aut, cre],\n  Santiago Olivella [aut],\n  Evan Rosenman [aut],\n  Alexander Rossell Hayes [aut],\n  Kosuke Imai [aut]",
    "url": "https://github.com/kosukeimai/wru",
    "bug_reports": "https://github.com/kosukeimai/wru/issues",
    "repository": "https://cran.r-project.org/package=wru",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "wru Who are You? Bayesian Prediction of Racial Category Using\nSurname, First Name, Middle Name, and Geolocation Predicts individual race/ethnicity using surname, first name,\n    middle name, geolocation, and other attributes, such as gender and\n    age. The method utilizes Bayes' Rule (with optional measurement error\n    correction) to compute the posterior probability of each racial\n    category for any given individual. The package implements methods\n    described in Imai and Khanna (2016) \"Improving Ecological Inference by\n    Predicting Individual Ethnicity from Voter Registration Records\"\n    Political Analysis <DOI:10.1093/pan/mpw001> and Imai, Olivella, and\n    Rosenman (2022) \"Addressing census data problems in race imputation\n    via fully Bayesian Improved Surname Geocoding and name supplements\"\n    <DOI:10.1126/sciadv.adc9824>.  The package also incorporates the data\n    described in Rosenman, Olivella, and Imai (2023) \"Race and ethnicity\n    data for first, middle, and surnames\"\n    <DOI:10.1038/s41597-023-02202-2>.  "
  },
  {
    "id": 23198,
    "package_name": "x12",
    "title": "Interface to 'X12-ARIMA'/'X13-ARIMA-SEATS' and Structure for\nBatch Processing of Seasonal Adjustment",
    "description": "The 'X13-ARIMA-SEATS' <https://www.census.gov/data/software/x13as.html> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.",
    "version": "1.11.0",
    "maintainer": "Alexander Kowarik <alexander.kowarik@statistik.gv.at>",
    "author": "Alexander Kowarik [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-8598-4130>),\n  Angelika Meraner [aut]",
    "url": "https://github.com/statistikat/x12",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=x12",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "x12 Interface to 'X12-ARIMA'/'X13-ARIMA-SEATS' and Structure for\nBatch Processing of Seasonal Adjustment The 'X13-ARIMA-SEATS' <https://www.census.gov/data/software/x13as.html> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.  "
  },
  {
    "id": 23199,
    "package_name": "x13binary",
    "title": "Provide the 'x13ashtml' Seasonal Adjustment Binary",
    "description": "The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.",
    "version": "1.1.61.1",
    "maintainer": "Dirk Eddelbuettel <edd@debian.org>",
    "author": "Dirk Eddelbuettel [aut, cre] (ORCID:\n    <https://orcid.org/0000-0001-6419-907X>),\n  Christoph Sax [aut] (ORCID: <https://orcid.org/0000-0002-7192-7044>),\n  Kirill M\u00fcller [ctb] (ORCID: <https://orcid.org/0000-0002-1416-3412>),\n  Jeroen Ooms [ctb] (ORCID: <https://orcid.org/0000-0002-4035-0289>),\n  Michael Antonov [ctb]",
    "url": "https://github.com/x13org/x13binary",
    "bug_reports": "https://github.com/x13org/x13binary/issues/",
    "repository": "https://cran.r-project.org/package=x13binary",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "x13binary Provide the 'x13ashtml' Seasonal Adjustment Binary The US Census Bureau provides a seasonal adjustment program now\n called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and\n X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau\n offers both source and binary versions -- which this package integrates for\n use by other R packages.  "
  },
  {
    "id": 23218,
    "package_name": "xegaGeGene",
    "title": "Grammatical Evolution",
    "description": "Grammatical evolution  (see O'Neil, M. and \n        Ryan, C.  (2003,ISBN:1-4020-7444-1)) uses decoders to \n        convert linear (binary or integer genes) into programs.  \n        In addition, automatic determination of codon precision \n        with a limited rule choice bias is provided.\n        For a recent survey of grammatical evolution, \n        see Ryan, C., O'Neill, M., and Collins, J. J. (2018)\n        <doi:10.1007/978-3-319-78717-6>.",
    "version": "1.0.0.3",
    "maintainer": "Andreas Geyer-Schulz <Andreas.Geyer-Schulz@kit.edu>",
    "author": "Andreas Geyer-Schulz [aut, cre] (ORCID:\n    <https://orcid.org/0009-0000-5237-3579>)",
    "url": "https://github.com/ageyerschulz/xegaGeGene",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xegaGeGene",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xegaGeGene Grammatical Evolution Grammatical evolution  (see O'Neil, M. and \n        Ryan, C.  (2003,ISBN:1-4020-7444-1)) uses decoders to \n        convert linear (binary or integer genes) into programs.  \n        In addition, automatic determination of codon precision \n        with a limited rule choice bias is provided.\n        For a recent survey of grammatical evolution, \n        see Ryan, C., O'Neill, M., and Collins, J. J. (2018)\n        <doi:10.1007/978-3-319-78717-6>.  "
  },
  {
    "id": 23230,
    "package_name": "xkcdcolors",
    "title": "Color Names from the XKCD Color Survey",
    "description": "The XKCD color survey asked participants to name colours. Randall Munroe published the top thousand(roughly) names and their sRGB hex values. This package lets you use them.",
    "version": "1.0",
    "maintainer": "Thomas Lumley <t.lumley@auckland.ac.nz>",
    "author": "Thomas Lumley, using data from Randall Munroe and about 2.2e5 survey participants",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xkcdcolors",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xkcdcolors Color Names from the XKCD Color Survey The XKCD color survey asked participants to name colours. Randall Munroe published the top thousand(roughly) names and their sRGB hex values. This package lets you use them.  "
  },
  {
    "id": 23234,
    "package_name": "xlsform2word",
    "title": "Convert 'XLSForm' to Structured 'Word' Document",
    "description": "Converts an 'XLSForm' (survey in 'Excel') into a well-structured 'Word' document, including sections, skip logic, options, and question labels.\n    Designed to support survey documentation, training materials, and data collection workflows.\n    The package was developed based on field experience with 'XLSForm' and humanitarian operations, aiming to streamline documentation and enhance training efficiency.",
    "version": "0.1.0",
    "maintainer": "NyAvo RATOVO-ANDRIANARISOA <ratovoandry1@gmail.com>",
    "author": "NyAvo RATOVO-ANDRIANARISOA [aut, cre]",
    "url": "",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=xlsform2word",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "xlsform2word Convert 'XLSForm' to Structured 'Word' Document Converts an 'XLSForm' (survey in 'Excel') into a well-structured 'Word' document, including sections, skip logic, options, and question labels.\n    Designed to support survey documentation, training materials, and data collection workflows.\n    The package was developed based on field experience with 'XLSForm' and humanitarian operations, aiming to streamline documentation and enhance training efficiency.  "
  },
  {
    "id": 23298,
    "package_name": "z22",
    "title": "Official Gridded Data from the German Census 2022",
    "description": "Provides fast and easy access to German census grid data\n    from the 2011 and 2022 censuses <https://www.zensus2022.de/>, including a\n    wide range of socio-economic indicators at multiple spatial resolutions\n    (100m, 1km, 10km). Enables efficient download, processing, and analysis\n    of large census datasets covering population, households, families,\n    dwellings, and buildings. Harmonized data structures allow direct\n    comparison with the 2011 census, supporting temporal and spatial analyses.\n    Facilitates conversion of data into common formats for spatial analysis and\n    mapping ('terra', 'sf', 'ggplot2').",
    "version": "1.1.0",
    "maintainer": "Jonas Lieth <jonas.lieth@gesis.org>",
    "author": "Jonas Lieth [cre, aut, cph] (ORCID:\n    <https://orcid.org/0000-0002-3451-3176>)",
    "url": "https://github.com/jslth/z22/, https://jslth.github.io/z22/",
    "bug_reports": "https://github.com/jslth/z22/issues",
    "repository": "https://cran.r-project.org/package=z22",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "z22 Official Gridded Data from the German Census 2022 Provides fast and easy access to German census grid data\n    from the 2011 and 2022 censuses <https://www.zensus2022.de/>, including a\n    wide range of socio-economic indicators at multiple spatial resolutions\n    (100m, 1km, 10km). Enables efficient download, processing, and analysis\n    of large census datasets covering population, households, families,\n    dwellings, and buildings. Harmonized data structures allow direct\n    comparison with the 2011 census, supporting temporal and spatial analyses.\n    Facilitates conversion of data into common formats for spatial analysis and\n    mapping ('terra', 'sf', 'ggplot2').  "
  },
  {
    "id": 23303,
    "package_name": "zctaCrosswalk",
    "title": "Crosswalk Between 2020 Census ZIP Code Tabulation Areas (ZCTAs),\nStates and Counties",
    "description": "Contains the US Census Bureau's 2020 ZCTA to County Relationship \n    File, as well as convenience functions to translate between States, Counties\n    and ZIP Code Tabulation Areas (ZCTAs).",
    "version": "2.0.0",
    "maintainer": "Ari Lamstein <alamstein@market-bridge.com>",
    "author": "Ari Lamstein [aut, cre],\n  MarketBridge LLC [cph, fnd]",
    "url": "https://github.com/MarketBridge/zctaCrosswalk",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=zctaCrosswalk",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zctaCrosswalk Crosswalk Between 2020 Census ZIP Code Tabulation Areas (ZCTAs),\nStates and Counties Contains the US Census Bureau's 2020 ZCTA to County Relationship \n    File, as well as convenience functions to translate between States, Counties\n    and ZIP Code Tabulation Areas (ZCTAs).  "
  },
  {
    "id": 23321,
    "package_name": "zipcodeR",
    "title": "Data & Functions for Working with US ZIP Codes",
    "description": "Make working with ZIP codes in R painless with an integrated dataset of U.S. ZIP codes and functions for working with them. \n             Search ZIP codes by multiple geographies, including state, county, city & across time zones. Also included are functions for relating\n             ZIP codes to Census data, geocoding & distance calculations.",
    "version": "0.3.5",
    "maintainer": "Gavin Rozzi <gr@gavinrozzi.com>",
    "author": "Gavin Rozzi [aut, cre] (ORCID: <https://orcid.org/0000-0002-9969-8175>)",
    "url": "https://github.com/gavinrozzi/zipcodeR/,\nhttps://www.gavinrozzi.com/project/zipcoder/",
    "bug_reports": "https://github.com/gavinrozzi/zipcodeR/issues/",
    "repository": "https://cran.r-project.org/package=zipcodeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zipcodeR Data & Functions for Working with US ZIP Codes Make working with ZIP codes in R painless with an integrated dataset of U.S. ZIP codes and functions for working with them. \n             Search ZIP codes by multiple geographies, including state, county, city & across time zones. Also included are functions for relating\n             ZIP codes to Census data, geocoding & distance calculations.  "
  },
  {
    "id": 23323,
    "package_name": "zippeR",
    "title": "Working with United States ZIP Code and ZIP Code Tabulation Area\nData",
    "description": "Provides a set of functions for working with American postal codes,\n   which are known as ZIP Codes. These include accessing ZIP Code to ZIP Code \n   Tabulation Area (ZCTA) crosswalks, retrieving demographic data for ZCTAs, and \n   tabulating demographic data for three-digit ZCTAs.",
    "version": "0.1.2",
    "maintainer": "Christopher Prener <Christopher.Prener@pfizer.com>",
    "author": "Christopher Prener [aut, cre] (ORCID:\n    <https://orcid.org/0000-0002-4310-9888>),\n  Timothy Wiemken [aut] (ORCID: <https://orcid.org/0000-0002-8251-3007>),\n  Angela Cook [aut]",
    "url": "https://github.com/pfizer-opensource/zippeR",
    "bug_reports": "",
    "repository": "https://cran.r-project.org/package=zippeR",
    "exports": [],
    "topics": [],
    "score": "NA",
    "stars": 0,
    "primary_category": "general",
    "source_universe": "cran-direct",
    "search_text": "zippeR Working with United States ZIP Code and ZIP Code Tabulation Area\nData Provides a set of functions for working with American postal codes,\n   which are known as ZIP Codes. These include accessing ZIP Code to ZIP Code \n   Tabulation Area (ZCTA) crosswalks, retrieving demographic data for ZCTAs, and \n   tabulating demographic data for three-digit ZCTAs.  "
  }
]